2024-07-02 14:17:14 root INFO     loading model + tokenizer
2024-07-02 14:17:31 root INFO     model + tokenizer loaded
2024-07-02 14:17:31 __main__ INFO     starting test: <class 'lre.operators.JacobianIclMeanEstimator'> on meronyms - member
2024-07-02 14:17:33 root INFO     building operator meronyms - member
2024-07-02 14:17:34 root INFO     h_layer_name='transformer.h.5.ln_1' z_layer_name='transformer.h.27'
2024-07-02 14:17:34 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.9561, -0.2229, -0.6147,  ...,  0.7466, -0.5278, -0.7432],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.2032,  0.3909, -0.1995,  ..., -0.3113, -0.2749,  0.1635],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 6.5781, -0.0238,  0.1260,  ...,  0.2793,  3.0078,  1.6221],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 4.8125, -1.6416,  0.9834,  ..., -1.3828,  2.4863,  1.2100],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-02 14:17:34 root INFO     [order_1_approx] starting weight calculation for A college is a member of a university
A member is a member of a club
A wolf is a member of a pack
A soldier is a member of a army
A musician is a member of a orchestra
A calf is a member of a cattle
A antelope is a member of a herd
A citizen is a member of a
2024-07-02 14:17:34 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5.ln_1
2024-07-02 14:22:20 root INFO     loading model + tokenizer
2024-07-02 14:22:41 root INFO     loading model + tokenizer
2024-07-02 14:22:50 root INFO     loading model + tokenizer
2024-07-02 14:23:07 root INFO     model + tokenizer loaded
2024-07-02 14:23:07 __main__ INFO     starting test: <class 'lre.operators.JacobianIclMeanEstimator'> on meronyms - member
2024-07-02 14:23:10 root INFO     building operator meronyms - member
2024-07-02 14:23:10 root INFO     h_layer_name='transformer.h.5.ln_1' z_layer_name='transformer.h.27'
2024-07-02 14:25:59 root INFO     loading model + tokenizer
2024-07-02 14:26:15 root INFO     model + tokenizer loaded
2024-07-02 14:26:15 __main__ INFO     starting test: <class 'lre.operators.JacobianIclMeanEstimator'> on meronyms - member
2024-07-02 14:26:18 root INFO     building operator meronyms - member
2024-07-02 14:26:18 root INFO     h_layer_name='transformer.h.5.ln_1' z_layer_name='transformer.h.27'
2024-07-02 14:26:18 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.1836,  0.1316,  0.2158,  ...,  1.3047, -0.5908,  0.3213],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.1716,  0.6055, -0.0693,  ..., -0.0417, -0.1960,  0.3450],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 4.9336,  4.6211, -4.1562,  ...,  0.8760,  0.8101,  1.5879],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 2.7793,  3.5586, -4.6562,  ...,  0.2959, -1.5527,  3.5898],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-02 14:26:18 root INFO     [order_1_approx] starting weight calculation for A crow is a member of a murder
A song is a member of a album
A division is a member of a company
A college is a member of a university
A person is a member of a society
A listener is a member of a audience
A goose is a member of a gaggle
A sheep is a member of a
2024-07-02 14:26:46 root INFO     loading model + tokenizer
2024-07-02 14:27:03 root INFO     model + tokenizer loaded
2024-07-02 14:27:03 __main__ INFO     starting test: <class 'lre.operators.JacobianIclMeanEstimator'> on meronyms - member
2024-07-02 14:27:06 root INFO     building operator meronyms - member
2024-07-02 14:27:06 root INFO     h_layer_name='transformer.h.5.ln_1' z_layer_name='transformer.h.27'
2024-07-02 14:27:06 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.0080,  0.2319, -0.6475,  ...,  0.0232, -0.6763,  0.4480],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.1781,  0.3918, -0.0934,  ..., -0.1915, -0.0943,  0.5273],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 2.3809,  0.9502, -1.1768,  ..., -2.7715,  0.9321,  3.7930],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 1.2939, -2.4004, -1.2949,  ..., -1.4414, -0.4263,  0.8584],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-02 14:27:06 root INFO     [order_1_approx] starting weight calculation for A spouse is a member of a couple
A member is a member of a club
A wolf is a member of a pack
A car is a member of a train
A bee is a member of a swarm
A song is a member of a album
A nomad is a member of a horde
A division is a member of a
2024-07-02 14:27:06 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[1., 0., 0.,  ..., 0., 0., 0.],
        [0., 1., 0.,  ..., 0., 0., 0.],
        [0., 0., 1.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 0.,  ..., 1., 0., 0.],
        [0., 0., 0.,  ..., 0., 1., 0.],
        [0., 0., 0.,  ..., 0., 0., 1.]], device='cuda:0', dtype=torch.float16) 

                    
2024-07-02 14:27:07 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A spouse is a member of a couple
A member is a member of a club
A wolf is a member of a pack
A car is a member of a train
A bee is a member of a swarm
A song is a member of a album
A nomad is a member of a horde
A division is a member of a
2024-07-02 14:27:07 root INFO     h_layer_name='transformer.h.5.ln_1' z_layer_name='transformer.h.27'
2024-07-02 14:27:07 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.2217, -1.0342, -0.2666,  ...,  0.3555,  0.5459, -1.0820],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.2615,  0.5151, -0.1089,  ..., -0.1511,  0.1182,  0.4622],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 3.0918,  0.4497, -3.2695,  ...,  2.3633,  0.5596, -3.6602],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-1.0938,  3.5352,  0.0176,  ...,  2.2598,  3.6738, -5.7305],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-02 14:27:07 root INFO     [order_1_approx] starting weight calculation for A car is a member of a train
A spouse is a member of a couple
A wolf is a member of a pack
A member is a member of a club
A division is a member of a company
A nomad is a member of a horde
A bee is a member of a swarm
A song is a member of a
2024-07-02 14:27:07 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[1., 0., 0.,  ..., 0., 0., 0.],
        [0., 1., 0.,  ..., 0., 0., 0.],
        [0., 0., 1.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 0.,  ..., 1., 0., 0.],
        [0., 0., 0.,  ..., 0., 1., 0.],
        [0., 0., 0.,  ..., 0., 0., 1.]], device='cuda:0', dtype=torch.float16) 

                    
2024-07-02 14:27:08 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A car is a member of a train
A spouse is a member of a couple
A wolf is a member of a pack
A member is a member of a club
A division is a member of a company
A nomad is a member of a horde
A bee is a member of a swarm
A song is a member of a
2024-07-02 14:27:08 root INFO     h_layer_name='transformer.h.5.ln_1' z_layer_name='transformer.h.27'
2024-07-02 14:27:08 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.6011, -0.7319, -0.6255,  ...,  0.1996, -0.2725, -0.2322],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.4580,  0.4614,  0.0325,  ..., -0.3372, -0.1571,  0.3560],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 4.0586,  1.5469, -3.4258,  ...,  0.1924,  1.7529,  4.6172],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-2.4531, -2.6289, -3.3789,  ...,  0.9458,  0.6011, -0.3599],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-02 14:27:08 root INFO     [order_1_approx] starting weight calculation for A bee is a member of a swarm
A nomad is a member of a horde
A division is a member of a company
A song is a member of a album
A wolf is a member of a pack
A spouse is a member of a couple
A member is a member of a club
A car is a member of a
2024-07-02 14:27:08 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[1., 0., 0.,  ..., 0., 0., 0.],
        [0., 1., 0.,  ..., 0., 0., 0.],
        [0., 0., 1.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 0.,  ..., 1., 0., 0.],
        [0., 0., 0.,  ..., 0., 1., 0.],
        [0., 0., 0.,  ..., 0., 0., 1.]], device='cuda:0', dtype=torch.float16) 

                    
2024-07-02 14:27:09 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A bee is a member of a swarm
A nomad is a member of a horde
A division is a member of a company
A song is a member of a album
A wolf is a member of a pack
A spouse is a member of a couple
A member is a member of a club
A car is a member of a
2024-07-02 14:27:09 root INFO     h_layer_name='transformer.h.5.ln_1' z_layer_name='transformer.h.27'
2024-07-02 14:27:09 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.6470, -1.3965, -0.7412,  ...,  0.4033, -0.6343, -0.1737],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.3333,  0.4453, -0.0645,  ..., -0.3264, -0.0401,  0.2617],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 3.6133,  1.5645, -3.1328,  ..., -0.2612,  1.9375,  4.8477],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.6968, -0.7368, -2.6934,  ...,  0.9946,  0.3530,  3.2344],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-02 14:27:09 root INFO     [order_1_approx] starting weight calculation for A division is a member of a company
A bee is a member of a swarm
A spouse is a member of a couple
A car is a member of a train
A song is a member of a album
A nomad is a member of a horde
A member is a member of a club
A wolf is a member of a
2024-07-02 14:27:09 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[1., 0., 0.,  ..., 0., 0., 0.],
        [0., 1., 0.,  ..., 0., 0., 0.],
        [0., 0., 1.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 0.,  ..., 1., 0., 0.],
        [0., 0., 0.,  ..., 0., 1., 0.],
        [0., 0., 0.,  ..., 0., 0., 1.]], device='cuda:0', dtype=torch.float16) 

                    
2024-07-02 14:27:10 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A division is a member of a company
A bee is a member of a swarm
A spouse is a member of a couple
A car is a member of a train
A song is a member of a album
A nomad is a member of a horde
A member is a member of a club
A wolf is a member of a
2024-07-02 14:27:10 root INFO     h_layer_name='transformer.h.5.ln_1' z_layer_name='transformer.h.27'
2024-07-02 14:27:11 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.0498, -1.3262,  0.2493,  ..., -0.1581, -0.7622, -1.0127],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.1223,  0.4500, -0.1372,  ..., -0.2361, -0.1257,  0.4121],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 3.9062,  1.2451, -1.9238,  ..., -3.2461,  2.6562,  4.7812],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-3.2891,  0.7080, -1.7773,  ...,  0.7080,  1.3867,  1.7441],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-02 14:27:11 root INFO     [order_1_approx] starting weight calculation for A song is a member of a album
A spouse is a member of a couple
A car is a member of a train
A member is a member of a club
A division is a member of a company
A bee is a member of a swarm
A wolf is a member of a pack
A nomad is a member of a
2024-07-02 14:27:11 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[1., 0., 0.,  ..., 0., 0., 0.],
        [0., 1., 0.,  ..., 0., 0., 0.],
        [0., 0., 1.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 0.,  ..., 1., 0., 0.],
        [0., 0., 0.,  ..., 0., 1., 0.],
        [0., 0., 0.,  ..., 0., 0., 1.]], device='cuda:0', dtype=torch.float16) 

                    
2024-07-02 14:27:11 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A song is a member of a album
A spouse is a member of a couple
A car is a member of a train
A member is a member of a club
A division is a member of a company
A bee is a member of a swarm
A wolf is a member of a pack
A nomad is a member of a
2024-07-02 14:27:11 root INFO     h_layer_name='transformer.h.5.ln_1' z_layer_name='transformer.h.27'
2024-07-02 14:27:12 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 1.0322,  0.6201,  1.2139,  ...,  0.4492, -0.9443,  0.0636],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.2467,  0.2390, -0.0599,  ..., -0.3232, -0.0165,  0.4402],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 5.1094,  2.6562,  1.7129,  ..., -0.2070,  1.9893,  5.2109],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-1.5947, -1.3359,  0.3115,  ..., -3.5234,  1.4551,  2.8086],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-02 14:27:12 root INFO     [order_1_approx] starting weight calculation for A bee is a member of a swarm
A wolf is a member of a pack
A car is a member of a train
A division is a member of a company
A member is a member of a club
A song is a member of a album
A nomad is a member of a horde
A spouse is a member of a
2024-07-02 14:27:12 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[1., 0., 0.,  ..., 0., 0., 0.],
        [0., 1., 0.,  ..., 0., 0., 0.],
        [0., 0., 1.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 0.,  ..., 1., 0., 0.],
        [0., 0., 0.,  ..., 0., 1., 0.],
        [0., 0., 0.,  ..., 0., 0., 1.]], device='cuda:0', dtype=torch.float16) 

                    
2024-07-02 14:27:12 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A bee is a member of a swarm
A wolf is a member of a pack
A car is a member of a train
A division is a member of a company
A member is a member of a club
A song is a member of a album
A nomad is a member of a horde
A spouse is a member of a
2024-07-02 14:27:12 root INFO     h_layer_name='transformer.h.5.ln_1' z_layer_name='transformer.h.27'
2024-07-02 14:27:13 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.1862, -0.5312,  0.6138,  ..., -0.3608, -1.0664,  0.7769],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.1345,  0.1455, -0.0484,  ..., -0.2756, -0.1924,  0.1580],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 4.5352, -0.2280,  2.5391,  ..., -0.6875,  2.2539,  3.2363],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 4.1367, -3.0859, -1.6318,  ..., -1.2578,  2.1875,  1.9512],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-02 14:27:13 root INFO     [order_1_approx] starting weight calculation for A bee is a member of a swarm
A car is a member of a train
A wolf is a member of a pack
A song is a member of a album
A spouse is a member of a couple
A division is a member of a company
A nomad is a member of a horde
A member is a member of a
2024-07-02 14:27:13 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[1., 0., 0.,  ..., 0., 0., 0.],
        [0., 1., 0.,  ..., 0., 0., 0.],
        [0., 0., 1.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 0.,  ..., 1., 0., 0.],
        [0., 0., 0.,  ..., 0., 1., 0.],
        [0., 0., 0.,  ..., 0., 0., 1.]], device='cuda:0', dtype=torch.float16) 

                    
2024-07-02 14:27:13 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A bee is a member of a swarm
A car is a member of a train
A wolf is a member of a pack
A song is a member of a album
A spouse is a member of a couple
A division is a member of a company
A nomad is a member of a horde
A member is a member of a
2024-07-02 14:27:14 root INFO     h_layer_name='transformer.h.5.ln_1' z_layer_name='transformer.h.27'
2024-07-02 14:27:14 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.3218, -0.3547, -0.6289,  ...,  0.3896, -0.4670,  0.9219],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.2854,  0.4934, -0.0515,  ..., -0.2379, -0.1219,  0.2291],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 2.5742,  5.3398, -4.0586,  ..., -0.4768, -0.7114,  5.9609],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-2.1562,  2.5488, -3.0000,  ...,  1.5215,  1.1934,  2.5273],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-02 14:27:14 root INFO     [order_1_approx] starting weight calculation for A song is a member of a album
A nomad is a member of a horde
A division is a member of a company
A spouse is a member of a couple
A wolf is a member of a pack
A member is a member of a club
A car is a member of a train
A bee is a member of a
2024-07-02 14:27:14 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[1., 0., 0.,  ..., 0., 0., 0.],
        [0., 1., 0.,  ..., 0., 0., 0.],
        [0., 0., 1.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 0.,  ..., 1., 0., 0.],
        [0., 0., 0.,  ..., 0., 1., 0.],
        [0., 0., 0.,  ..., 0., 0., 1.]], device='cuda:0', dtype=torch.float16) 

                    
2024-07-02 14:27:14 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A song is a member of a album
A nomad is a member of a horde
A division is a member of a company
A spouse is a member of a couple
A wolf is a member of a pack
A member is a member of a club
A car is a member of a train
A bee is a member of a
2024-07-02 14:27:14 root INFO     total operator prediction time: 8.638710737228394 seconds
2024-07-02 14:28:10 root INFO     loading model + tokenizer
2024-07-02 14:28:26 root INFO     model + tokenizer loaded
2024-07-02 14:28:27 __main__ INFO     starting test: <class 'lre.operators.JacobianIclMeanEstimator'> on meronyms - member
2024-07-02 14:28:29 root INFO     building operator meronyms - member
2024-07-02 14:28:29 root INFO     h_layer_name='transformer.h.5.ln_1' z_layer_name='transformer.h.27'
2024-07-02 14:28:30 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.2489, -0.7207,  0.0424,  ...,  0.9194, -0.6855, -0.1109],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.2092,  0.6240,  0.0382,  ..., -0.3792, -0.3801,  0.3901],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 4.0547,  3.7461, -0.6772,  ...,  1.6025,  1.0967, -2.0059],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.0850,  1.5801, -2.3320,  ...,  2.0625,  0.3430, -0.8486],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-02 14:28:30 root INFO     [order_1_approx] starting weight calculation for A calf is a member of a cattle
A crow is a member of a murder
A antelope is a member of a herd
A cow is a member of a herd
A star is a member of a constellation
A listener is a member of a audience
A tree is a member of a forest
A bird is a member of a
2024-07-02 14:28:30 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5.ln_1
2024-07-02 14:32:40 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0040, -0.0045, -0.0023,  ...,  0.0110, -0.0107, -0.0004],
        [ 0.0030,  0.0033,  0.0006,  ..., -0.0075,  0.0029,  0.0030],
        [ 0.0017,  0.0001,  0.0002,  ...,  0.0037, -0.0031,  0.0040],
        ...,
        [-0.0085, -0.0056, -0.0090,  ...,  0.0025, -0.0051,  0.0046],
        [-0.0052,  0.0043,  0.0045,  ..., -0.0020, -0.0009, -0.0040],
        [ 0.0021,  0.0044, -0.0091,  ...,  0.0017,  0.0042,  0.0019]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-02 14:32:44 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A calf is a member of a cattle
A crow is a member of a murder
A antelope is a member of a herd
A cow is a member of a herd
A star is a member of a constellation
A listener is a member of a audience
A tree is a member of a forest
A bird is a member of a
2024-07-02 14:32:47 root INFO     h_layer_name='transformer.h.5.ln_1' z_layer_name='transformer.h.27'
2024-07-02 14:32:47 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.3660, -0.2377,  0.7583,  ...,  0.3704, -0.9111,  0.2681],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.2351,  0.5220,  0.0449,  ..., -0.3638, -0.2147,  0.4854],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 3.7852,  4.9609, -2.5078,  ..., -1.8086,  1.0986,  3.8320],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 0.1589,  4.4375, -3.4375,  ...,  0.5396,  0.0625,  1.3828],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-02 14:32:47 root INFO     [order_1_approx] starting weight calculation for A calf is a member of a cattle
A crow is a member of a murder
A tree is a member of a forest
A listener is a member of a audience
A cow is a member of a herd
A bird is a member of a flock
A star is a member of a constellation
A antelope is a member of a
2024-07-02 14:32:47 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5.ln_1
2024-07-02 14:36:59 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 1.3065e-03,  6.4373e-05,  1.1360e-02,  ...,  3.7670e-04,
          4.7188e-03, -1.4183e-02],
        [ 4.7569e-03,  1.4420e-03,  8.2397e-04,  ..., -6.2218e-03,
         -1.5163e-03, -3.2749e-03],
        [-7.1239e-04,  2.4948e-03,  4.1351e-03,  ...,  4.3259e-03,
         -2.0809e-03,  3.6964e-03],
        ...,
        [-3.3455e-03, -4.3411e-03,  4.4823e-03,  ...,  5.9624e-03,
          5.3520e-03, -7.3051e-03],
        [ 8.6136e-03,  4.7226e-03,  6.5231e-03,  ...,  1.7262e-03,
         -1.5022e-02, -1.0777e-03],
        [ 3.1700e-03, -9.7809e-03, -9.8572e-03,  ...,  7.9193e-03,
          1.6296e-02, -8.2397e-03]], device='cuda:0', dtype=torch.float16) 

                    
2024-07-02 14:36:59 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A calf is a member of a cattle
A crow is a member of a murder
A tree is a member of a forest
A listener is a member of a audience
A cow is a member of a herd
A bird is a member of a flock
A star is a member of a constellation
A antelope is a member of a
2024-07-02 14:37:00 root INFO     h_layer_name='transformer.h.5.ln_1' z_layer_name='transformer.h.27'
2024-07-02 14:37:00 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.3425,  0.6460, -0.0066,  ...,  0.7080,  0.4167,  0.5957],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.0673,  0.5186, -0.1456,  ..., -0.3320, -0.1146,  0.0124],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([4.1367, 2.4238, 3.8301,  ..., 2.2520, 0.4951, 4.7422], device='cuda:0',
       dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 2.1133,  2.5215, -0.1064,  ..., -0.7881,  1.9941,  2.8789],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-02 14:37:00 root INFO     [order_1_approx] starting weight calculation for A calf is a member of a cattle
A star is a member of a constellation
A bird is a member of a flock
A antelope is a member of a herd
A tree is a member of a forest
A cow is a member of a herd
A crow is a member of a murder
A listener is a member of a
2024-07-02 14:37:00 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5.ln_1
2024-07-02 14:41:12 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0109, -0.0106, -0.0001,  ...,  0.0195, -0.0046, -0.0128],
        [-0.0062, -0.0131,  0.0037,  ...,  0.0108,  0.0043,  0.0148],
        [ 0.0059,  0.0017,  0.0128,  ...,  0.0059, -0.0027, -0.0005],
        ...,
        [ 0.0028,  0.0004,  0.0025,  ...,  0.0219,  0.0010,  0.0094],
        [ 0.0091,  0.0144,  0.0028,  ..., -0.0156,  0.0006, -0.0079],
        [ 0.0064,  0.0022, -0.0072,  ...,  0.0099,  0.0019,  0.0030]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-02 14:41:13 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A calf is a member of a cattle
A star is a member of a constellation
A bird is a member of a flock
A antelope is a member of a herd
A tree is a member of a forest
A cow is a member of a herd
A crow is a member of a murder
A listener is a member of a
2024-07-02 14:41:13 root INFO     h_layer_name='transformer.h.5.ln_1' z_layer_name='transformer.h.27'
2024-07-02 14:41:14 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.3242, -0.2471, -0.4363,  ...,  0.8877,  0.0466,  1.0859],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.1752,  0.6289,  0.1075,  ..., -0.3838, -0.2659,  0.3091],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 2.9180,  4.1523, -1.9668,  ..., -0.4077,  0.3391,  3.6699],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 3.2070,  3.4258, -1.7432,  ..., -2.0879,  0.5771,  0.6250],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-02 14:41:14 root INFO     [order_1_approx] starting weight calculation for A crow is a member of a murder
A calf is a member of a cattle
A bird is a member of a flock
A star is a member of a constellation
A listener is a member of a audience
A tree is a member of a forest
A antelope is a member of a herd
A cow is a member of a
2024-07-02 14:41:14 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5.ln_1
2024-07-02 14:45:27 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 0.0003,  0.0052, -0.0006,  ...,  0.0089,  0.0002,  0.0028],
        [ 0.0120,  0.0050,  0.0031,  ...,  0.0016, -0.0024, -0.0004],
        [-0.0004,  0.0013,  0.0051,  ..., -0.0072, -0.0015, -0.0050],
        ...,
        [-0.0007,  0.0017, -0.0070,  ...,  0.0081,  0.0038, -0.0032],
        [-0.0039,  0.0088, -0.0094,  ...,  0.0002,  0.0188,  0.0051],
        [-0.0070,  0.0061, -0.0023,  ...,  0.0021, -0.0021,  0.0068]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-02 14:45:28 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A crow is a member of a murder
A calf is a member of a cattle
A bird is a member of a flock
A star is a member of a constellation
A listener is a member of a audience
A tree is a member of a forest
A antelope is a member of a herd
A cow is a member of a
2024-07-02 14:45:28 root INFO     h_layer_name='transformer.h.5.ln_1' z_layer_name='transformer.h.27'
2024-07-02 14:45:28 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 1.6143, -1.1963, -0.3958,  ...,  0.8340, -0.3911,  0.2593],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.2397,  0.5791,  0.0606,  ..., -0.2944, -0.1150,  0.4243],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([4.7891, 2.2422, 0.0898,  ..., 2.1582, 1.2695, 2.1191], device='cuda:0',
       dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-1.5244,  1.3564,  0.9834,  ...,  3.1230,  1.6270,  2.6738],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-02 14:45:28 root INFO     [order_1_approx] starting weight calculation for A star is a member of a constellation
A cow is a member of a herd
A calf is a member of a cattle
A tree is a member of a forest
A listener is a member of a audience
A antelope is a member of a herd
A bird is a member of a flock
A crow is a member of a
2024-07-02 14:45:28 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5.ln_1
2024-07-02 14:49:40 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0037, -0.0011, -0.0054,  ...,  0.0069, -0.0146,  0.0001],
        [ 0.0055, -0.0007, -0.0015,  ...,  0.0039,  0.0052,  0.0028],
        [-0.0100, -0.0067,  0.0007,  ...,  0.0008, -0.0073, -0.0094],
        ...,
        [-0.0015, -0.0115, -0.0070,  ...,  0.0003,  0.0004,  0.0104],
        [ 0.0131,  0.0109,  0.0006,  ...,  0.0091,  0.0044,  0.0009],
        [-0.0040,  0.0052,  0.0006,  ...,  0.0032,  0.0093,  0.0098]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-02 14:49:41 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A star is a member of a constellation
A cow is a member of a herd
A calf is a member of a cattle
A tree is a member of a forest
A listener is a member of a audience
A antelope is a member of a herd
A bird is a member of a flock
A crow is a member of a
2024-07-02 14:49:42 root INFO     h_layer_name='transformer.h.5.ln_1' z_layer_name='transformer.h.27'
2024-07-02 14:49:42 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.1416,  0.3308,  0.3818,  ..., -0.0827,  0.0031,  0.1949],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.1774,  0.4875, -0.2661,  ..., -0.3167, -0.0793,  0.2932],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 8.3281,  6.1602, -1.6523,  ..., -0.9023,  2.4727,  3.3047],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-2.0430,  2.2891,  4.7539,  ..., -1.5771, -2.6797,  2.4316],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-02 14:49:42 root INFO     [order_1_approx] starting weight calculation for A calf is a member of a cattle
A listener is a member of a audience
A bird is a member of a flock
A tree is a member of a forest
A antelope is a member of a herd
A cow is a member of a herd
A crow is a member of a murder
A star is a member of a
2024-07-02 14:49:42 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5.ln_1
2024-07-02 15:05:44 root INFO     loading model + tokenizer
2024-07-02 15:06:01 root INFO     model + tokenizer loaded
2024-07-02 15:06:01 __main__ INFO     starting test: <class 'lre.operators.JacobianIclMeanEstimator'> on meronyms - member
2024-07-02 15:06:04 root INFO     building operator meronyms - member
2024-07-02 15:06:31 root INFO     loading model + tokenizer
2024-07-02 15:06:48 root INFO     model + tokenizer loaded
2024-07-02 15:06:48 __main__ INFO     starting test: <class 'lre.operators.JacobianIclMeanEstimator'> on meronyms - member
2024-07-02 15:06:50 root INFO     building operator meronyms - member
2024-07-02 15:06:51 root INFO     h_layer_name='transformer.h.5.ln_1' z_layer_name='transformer.h.27'
2024-07-02 15:10:42 root INFO     loading model + tokenizer
2024-07-02 15:11:14 root INFO     loading model + tokenizer
2024-07-02 15:11:31 root INFO     model + tokenizer loaded
2024-07-02 15:11:31 __main__ INFO     starting test: <class 'lre.operators.JacobianIclMeanEstimator'> on meronyms - member
2024-07-02 15:11:33 root INFO     building operator meronyms - member
2024-07-02 15:11:33 root INFO     h_layer_name='transformer.h.5.ln_1' z_layer_name='transformer.h.27'
2024-07-02 15:12:12 root INFO     loading model + tokenizer
2024-07-02 15:12:29 root INFO     model + tokenizer loaded
2024-07-02 15:12:29 __main__ INFO     starting test: <class 'lre.operators.JacobianIclMeanEstimator'> on meronyms - member
2024-07-02 15:12:32 root INFO     building operator meronyms - member
2024-07-02 15:12:32 root INFO     h_layer_name='transformer.h.5.ln_1' z_layer_name='transformer.h.27'
2024-07-02 15:14:28 root INFO     loading model + tokenizer
2024-07-02 15:14:44 root INFO     model + tokenizer loaded
2024-07-02 15:14:44 __main__ INFO     starting test: <class 'lre.operators.JacobianIclMeanEstimator'> on meronyms - member
2024-07-02 15:14:47 root INFO     building operator meronyms - member
2024-07-02 15:14:47 root INFO     h_layer_name='transformer.h.5.ln_1' z_layer_name='transformer.h.27'
2024-07-02 15:14:47 root INFO     [order_1_approx] starting weight calculation for A member is a member of a club
A galaxy is a member of a universe
A elephant is a member of a herd
A song is a member of a album
A photo is a member of a album
A star is a member of a constellation
A secretary is a member of a staff
A sheep is a member of a
2024-07-02 15:14:47 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5.ln_1
2024-07-02 15:19:06 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0030,  0.0018, -0.0043,  ...,  0.0051, -0.0015,  0.0096],
        [-0.0004,  0.0010, -0.0090,  ..., -0.0034, -0.0062,  0.0085],
        [-0.0065, -0.0043, -0.0069,  ..., -0.0025,  0.0032,  0.0092],
        ...,
        [-0.0009,  0.0089, -0.0071,  ...,  0.0020, -0.0002, -0.0105],
        [ 0.0028,  0.0051,  0.0035,  ..., -0.0061, -0.0030,  0.0078],
        [ 0.0002, -0.0012, -0.0012,  ..., -0.0056, -0.0029,  0.0024]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-02 15:19:07 root INFO     h_layer_name='transformer.h.5' z_layer_name='transformer.h.27'
2024-07-02 15:19:07 root INFO     [order_1_approx] starting weight calculation for A member is a member of a club
A galaxy is a member of a universe
A elephant is a member of a herd
A song is a member of a album
A photo is a member of a album
A star is a member of a constellation
A secretary is a member of a staff
A sheep is a member of a
2024-07-02 15:19:07 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5
2024-07-02 15:23:18 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 0.0034, -0.0008,  0.0003,  ...,  0.0081, -0.0195,  0.0199],
        [-0.0184,  0.0073,  0.0046,  ...,  0.0251, -0.0031, -0.0097],
        [-0.0050,  0.0040, -0.0011,  ..., -0.0090,  0.0074, -0.0116],
        ...,
        [ 0.0153,  0.0079, -0.0013,  ...,  0.0107, -0.0120,  0.0034],
        [ 0.0213, -0.0125,  0.0042,  ...,  0.0099, -0.0129, -0.0114],
        [-0.0165, -0.0280,  0.0014,  ...,  0.0091, -0.0151,  0.0092]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-02 15:23:19 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A member is a member of a club
A galaxy is a member of a universe
A elephant is a member of a herd
A song is a member of a album
A photo is a member of a album
A star is a member of a constellation
A secretary is a member of a staff
A sheep is a member of a
2024-07-02 15:23:19 root INFO     h_layer_name='transformer.h.5.ln_1' z_layer_name='transformer.h.27'
2024-07-02 15:23:19 root INFO     [order_1_approx] starting weight calculation for A photo is a member of a album
A star is a member of a constellation
A secretary is a member of a staff
A elephant is a member of a herd
A member is a member of a club
A song is a member of a album
A sheep is a member of a flock
A galaxy is a member of a
2024-07-02 15:23:19 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5.ln_1
2024-07-02 15:27:39 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0045, -0.0023,  0.0056,  ..., -0.0022, -0.0038,  0.0021],
        [-0.0050,  0.0022,  0.0088,  ..., -0.0008, -0.0052,  0.0094],
        [ 0.0030,  0.0075,  0.0109,  ..., -0.0060, -0.0024,  0.0061],
        ...,
        [-0.0091,  0.0030,  0.0058,  ...,  0.0121, -0.0044, -0.0005],
        [-0.0089, -0.0047,  0.0028,  ...,  0.0122, -0.0033,  0.0030],
        [ 0.0021,  0.0027, -0.0129,  ...,  0.0086, -0.0024, -0.0035]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-02 15:27:40 root INFO     h_layer_name='transformer.h.5' z_layer_name='transformer.h.27'
2024-07-02 15:27:40 root INFO     [order_1_approx] starting weight calculation for A photo is a member of a album
A star is a member of a constellation
A secretary is a member of a staff
A elephant is a member of a herd
A member is a member of a club
A song is a member of a album
A sheep is a member of a flock
A galaxy is a member of a
2024-07-02 15:27:40 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5
2024-07-02 15:31:50 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-1.9836e-02, -8.3160e-03,  1.9073e-05,  ...,  1.1597e-02,
          7.0953e-04,  1.1703e-02],
        [ 2.4857e-02, -9.3536e-03,  3.6221e-03,  ..., -1.1856e-02,
          2.1992e-03, -2.3773e-02],
        [-2.0432e-02, -9.8267e-03, -1.6769e-02,  ...,  3.1281e-04,
          1.5060e-02, -1.1391e-02],
        ...,
        [ 1.7136e-02, -5.1918e-03,  7.3471e-03,  ..., -2.1210e-02,
          8.7967e-03, -1.4610e-03],
        [ 4.1138e-02, -3.3569e-04,  2.3926e-02,  ..., -8.7051e-03,
          1.3332e-03,  7.3967e-03],
        [-1.0849e-02, -8.9264e-04,  1.5015e-02,  ...,  1.9363e-02,
          2.5787e-02,  2.3178e-02]], device='cuda:0', dtype=torch.float16) 

                    
2024-07-02 15:31:51 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A photo is a member of a album
A star is a member of a constellation
A secretary is a member of a staff
A elephant is a member of a herd
A member is a member of a club
A song is a member of a album
A sheep is a member of a flock
A galaxy is a member of a
2024-07-02 15:31:51 root INFO     h_layer_name='transformer.h.5.ln_1' z_layer_name='transformer.h.27'
2024-07-02 15:31:51 root INFO     [order_1_approx] starting weight calculation for A secretary is a member of a staff
A galaxy is a member of a universe
A sheep is a member of a flock
A song is a member of a album
A photo is a member of a album
A star is a member of a constellation
A member is a member of a club
A elephant is a member of a
2024-07-02 15:31:51 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5.ln_1
2024-07-02 15:36:11 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 0.0009,  0.0063, -0.0046,  ...,  0.0060,  0.0017, -0.0121],
        [-0.0059,  0.0011,  0.0028,  ...,  0.0005, -0.0042, -0.0021],
        [-0.0055,  0.0041,  0.0006,  ...,  0.0045,  0.0065, -0.0122],
        ...,
        [ 0.0051, -0.0073, -0.0059,  ...,  0.0026,  0.0090,  0.0034],
        [-0.0032,  0.0075, -0.0047,  ...,  0.0036, -0.0079, -0.0035],
        [-0.0037,  0.0081,  0.0039,  ..., -0.0076,  0.0072,  0.0007]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-02 15:36:12 root INFO     h_layer_name='transformer.h.5' z_layer_name='transformer.h.27'
2024-07-02 15:36:12 root INFO     [order_1_approx] starting weight calculation for A secretary is a member of a staff
A galaxy is a member of a universe
A sheep is a member of a flock
A song is a member of a album
A photo is a member of a album
A star is a member of a constellation
A member is a member of a club
A elephant is a member of a
2024-07-02 15:36:12 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5
2024-07-02 15:40:20 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0205, -0.0134, -0.0090,  ...,  0.0066, -0.0280,  0.0134],
        [-0.0060, -0.0064, -0.0145,  ...,  0.0168,  0.0010, -0.0067],
        [ 0.0202, -0.0091, -0.0042,  ..., -0.0347,  0.0081,  0.0146],
        ...,
        [-0.0090, -0.0056, -0.0107,  ...,  0.0025, -0.0035,  0.0014],
        [ 0.0010, -0.0184,  0.0025,  ..., -0.0121, -0.0234, -0.0008],
        [-0.0072,  0.0058, -0.0127,  ...,  0.0152, -0.0280,  0.0047]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-02 15:40:22 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A secretary is a member of a staff
A galaxy is a member of a universe
A sheep is a member of a flock
A song is a member of a album
A photo is a member of a album
A star is a member of a constellation
A member is a member of a club
A elephant is a member of a
2024-07-02 15:40:22 root INFO     h_layer_name='transformer.h.5.ln_1' z_layer_name='transformer.h.27'
2024-07-02 15:40:22 root INFO     [order_1_approx] starting weight calculation for A galaxy is a member of a universe
A sheep is a member of a flock
A elephant is a member of a herd
A star is a member of a constellation
A photo is a member of a album
A song is a member of a album
A secretary is a member of a staff
A member is a member of a
2024-07-02 15:40:22 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5.ln_1
2024-07-02 15:44:42 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 2.2335e-03, -5.1575e-03,  1.7891e-03,  ..., -1.7605e-03,
          1.8635e-03,  5.4169e-04],
        [-1.1549e-03, -2.4300e-03, -1.8425e-03,  ..., -1.4820e-03,
         -1.4591e-04,  2.5139e-03],
        [-2.4357e-03,  5.0812e-03,  2.4223e-03,  ...,  4.7636e-04,
         -1.1398e-02,  8.7690e-04],
        ...,
        [ 9.3889e-04, -3.7785e-03,  4.0894e-03,  ..., -3.0041e-03,
         -1.8978e-03, -4.0460e-04],
        [ 1.3790e-03,  5.5084e-03, -3.8357e-03,  ..., -4.2076e-03,
         -4.1962e-05,  2.6913e-03],
        [-1.3113e-04,  1.7757e-03, -4.2572e-03,  ...,  2.3537e-03,
         -8.8024e-04,  1.5812e-03]], device='cuda:0', dtype=torch.float16) 

                    
2024-07-02 15:44:43 root INFO     h_layer_name='transformer.h.5' z_layer_name='transformer.h.27'
2024-07-02 15:44:43 root INFO     [order_1_approx] starting weight calculation for A galaxy is a member of a universe
A sheep is a member of a flock
A elephant is a member of a herd
A star is a member of a constellation
A photo is a member of a album
A song is a member of a album
A secretary is a member of a staff
A member is a member of a
2024-07-02 15:44:43 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5
2024-07-02 15:48:51 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0022, -0.0041,  0.0018,  ..., -0.0040, -0.0044, -0.0063],
        [ 0.0106,  0.0015,  0.0054,  ...,  0.0052, -0.0045, -0.0046],
        [-0.0046, -0.0115, -0.0034,  ...,  0.0044,  0.0065, -0.0008],
        ...,
        [-0.0086,  0.0015,  0.0043,  ...,  0.0007,  0.0081, -0.0021],
        [-0.0033, -0.0056,  0.0077,  ...,  0.0173, -0.0006,  0.0144],
        [-0.0045,  0.0025, -0.0045,  ..., -0.0073,  0.0035,  0.0075]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-02 15:48:52 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A galaxy is a member of a universe
A sheep is a member of a flock
A elephant is a member of a herd
A star is a member of a constellation
A photo is a member of a album
A song is a member of a album
A secretary is a member of a staff
A member is a member of a
2024-07-02 15:48:52 root INFO     h_layer_name='transformer.h.5.ln_1' z_layer_name='transformer.h.27'
2024-07-02 15:48:52 root INFO     [order_1_approx] starting weight calculation for A song is a member of a album
A star is a member of a constellation
A sheep is a member of a flock
A galaxy is a member of a universe
A member is a member of a club
A elephant is a member of a herd
A secretary is a member of a staff
A photo is a member of a
2024-07-02 15:48:52 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5.ln_1
2024-07-02 15:53:12 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0092, -0.0027,  0.0034,  ...,  0.0055,  0.0031, -0.0004],
        [-0.0045,  0.0052, -0.0046,  ..., -0.0001,  0.0063, -0.0048],
        [-0.0006,  0.0190,  0.0004,  ...,  0.0051, -0.0056, -0.0017],
        ...,
        [-0.0008,  0.0057, -0.0027,  ...,  0.0031, -0.0047, -0.0019],
        [-0.0112,  0.0084, -0.0045,  ...,  0.0072,  0.0061, -0.0043],
        [ 0.0033, -0.0030,  0.0024,  ..., -0.0136, -0.0049, -0.0020]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-02 15:53:14 root INFO     h_layer_name='transformer.h.5' z_layer_name='transformer.h.27'
2024-07-02 15:53:14 root INFO     [order_1_approx] starting weight calculation for A song is a member of a album
A star is a member of a constellation
A sheep is a member of a flock
A galaxy is a member of a universe
A member is a member of a club
A elephant is a member of a herd
A secretary is a member of a staff
A photo is a member of a
2024-07-02 15:53:14 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5
2024-07-02 15:57:27 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 0.0036, -0.0028,  0.0031,  ..., -0.0191, -0.0113,  0.0041],
        [ 0.0005, -0.0075,  0.0051,  ..., -0.0012, -0.0195,  0.0094],
        [-0.0116, -0.0190, -0.0300,  ...,  0.0021,  0.0038,  0.0112],
        ...,
        [-0.0276, -0.0143, -0.0156,  ..., -0.0107,  0.0008, -0.0043],
        [ 0.0149, -0.0129,  0.0104,  ...,  0.0042, -0.0093, -0.0007],
        [-0.0235,  0.0085, -0.0103,  ..., -0.0062,  0.0142,  0.0235]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-02 15:57:28 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A song is a member of a album
A star is a member of a constellation
A sheep is a member of a flock
A galaxy is a member of a universe
A member is a member of a club
A elephant is a member of a herd
A secretary is a member of a staff
A photo is a member of a
2024-07-02 15:57:28 root INFO     h_layer_name='transformer.h.5.ln_1' z_layer_name='transformer.h.27'
2024-07-02 15:57:28 root INFO     [order_1_approx] starting weight calculation for A elephant is a member of a herd
A photo is a member of a album
A sheep is a member of a flock
A secretary is a member of a staff
A galaxy is a member of a universe
A member is a member of a club
A star is a member of a constellation
A song is a member of a
2024-07-02 15:57:28 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5.ln_1
2024-07-02 16:01:50 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0006, -0.0011, -0.0078,  ...,  0.0107,  0.0077, -0.0024],
        [-0.0005,  0.0038, -0.0030,  ...,  0.0074, -0.0008,  0.0026],
        [-0.0079,  0.0043, -0.0081,  ...,  0.0080,  0.0055,  0.0174],
        ...,
        [-0.0110, -0.0003, -0.0057,  ...,  0.0132,  0.0100,  0.0066],
        [-0.0008, -0.0013, -0.0022,  ..., -0.0007,  0.0112,  0.0078],
        [-0.0036, -0.0062, -0.0070,  ...,  0.0090,  0.0054, -0.0019]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-02 16:01:51 root INFO     h_layer_name='transformer.h.5' z_layer_name='transformer.h.27'
2024-07-02 16:01:51 root INFO     [order_1_approx] starting weight calculation for A elephant is a member of a herd
A photo is a member of a album
A sheep is a member of a flock
A secretary is a member of a staff
A galaxy is a member of a universe
A member is a member of a club
A star is a member of a constellation
A song is a member of a
2024-07-02 16:01:51 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5
2024-07-02 16:06:00 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0023,  0.0071, -0.0053,  ...,  0.0035,  0.0081, -0.0025],
        [ 0.0016, -0.0113,  0.0127,  ..., -0.0080, -0.0037, -0.0018],
        [ 0.0030,  0.0164, -0.0206,  ...,  0.0020,  0.0128,  0.0097],
        ...,
        [-0.0004,  0.0051, -0.0035,  ...,  0.0145, -0.0018,  0.0158],
        [ 0.0068, -0.0068, -0.0014,  ..., -0.0004, -0.0172, -0.0068],
        [-0.0078, -0.0047, -0.0085,  ...,  0.0235,  0.0120,  0.0117]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-02 16:06:01 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A elephant is a member of a herd
A photo is a member of a album
A sheep is a member of a flock
A secretary is a member of a staff
A galaxy is a member of a universe
A member is a member of a club
A star is a member of a constellation
A song is a member of a
2024-07-02 16:06:01 root INFO     h_layer_name='transformer.h.5.ln_1' z_layer_name='transformer.h.27'
2024-07-02 16:06:01 root INFO     [order_1_approx] starting weight calculation for A photo is a member of a album
A sheep is a member of a flock
A galaxy is a member of a universe
A song is a member of a album
A member is a member of a club
A star is a member of a constellation
A elephant is a member of a herd
A secretary is a member of a
2024-07-02 16:06:01 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5.ln_1
2024-07-02 16:10:21 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0025, -0.0043, -0.0082,  ..., -0.0039, -0.0079, -0.0168],
        [ 0.0089, -0.0044, -0.0070,  ...,  0.0211,  0.0046,  0.0089],
        [ 0.0030, -0.0046,  0.0025,  ..., -0.0186, -0.0122,  0.0043],
        ...,
        [ 0.0074,  0.0062,  0.0087,  ...,  0.0087,  0.0014,  0.0008],
        [-0.0015, -0.0120, -0.0184,  ...,  0.0083,  0.0243, -0.0070],
        [-0.0064, -0.0109, -0.0015,  ..., -0.0041, -0.0008, -0.0084]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-02 16:10:22 root INFO     h_layer_name='transformer.h.5' z_layer_name='transformer.h.27'
2024-07-02 16:10:22 root INFO     [order_1_approx] starting weight calculation for A photo is a member of a album
A sheep is a member of a flock
A galaxy is a member of a universe
A song is a member of a album
A member is a member of a club
A star is a member of a constellation
A elephant is a member of a herd
A secretary is a member of a
2024-07-02 16:10:22 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5
2024-07-02 16:14:33 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0043,  0.0029,  0.0086,  ..., -0.0029, -0.0009, -0.0093],
        [-0.0011,  0.0168,  0.0101,  ..., -0.0022, -0.0061,  0.0115],
        [-0.0192, -0.0164, -0.0132,  ...,  0.0158, -0.0372, -0.0233],
        ...,
        [-0.0346, -0.0045, -0.0099,  ..., -0.0105, -0.0007,  0.0290],
        [ 0.0335, -0.0034, -0.0198,  ..., -0.0221,  0.0043,  0.0044],
        [-0.0041, -0.0095, -0.0097,  ...,  0.0183,  0.0146,  0.0130]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-02 16:14:34 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A photo is a member of a album
A sheep is a member of a flock
A galaxy is a member of a universe
A song is a member of a album
A member is a member of a club
A star is a member of a constellation
A elephant is a member of a herd
A secretary is a member of a
2024-07-02 16:14:34 root INFO     h_layer_name='transformer.h.5.ln_1' z_layer_name='transformer.h.27'
2024-07-02 16:14:34 root INFO     [order_1_approx] starting weight calculation for A galaxy is a member of a universe
A photo is a member of a album
A elephant is a member of a herd
A sheep is a member of a flock
A secretary is a member of a staff
A song is a member of a album
A member is a member of a club
A star is a member of a
2024-07-02 16:14:34 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5.ln_1
2024-07-02 16:18:54 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0005, -0.0024, -0.0039,  ...,  0.0006,  0.0048, -0.0046],
        [ 0.0025,  0.0012,  0.0016,  ...,  0.0020,  0.0041, -0.0033],
        [-0.0010,  0.0069, -0.0059,  ..., -0.0036, -0.0029, -0.0008],
        ...,
        [-0.0029,  0.0107,  0.0028,  ..., -0.0005,  0.0053,  0.0107],
        [ 0.0039, -0.0074, -0.0056,  ..., -0.0013,  0.0037, -0.0006],
        [-0.0031,  0.0059,  0.0029,  ..., -0.0015, -0.0038, -0.0096]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-02 16:18:55 root INFO     h_layer_name='transformer.h.5' z_layer_name='transformer.h.27'
2024-07-02 16:18:55 root INFO     [order_1_approx] starting weight calculation for A galaxy is a member of a universe
A photo is a member of a album
A elephant is a member of a herd
A sheep is a member of a flock
A secretary is a member of a staff
A song is a member of a album
A member is a member of a club
A star is a member of a
2024-07-02 16:18:55 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5
2024-07-02 16:23:06 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0268, -0.0277,  0.0071,  ...,  0.0109, -0.0129, -0.0072],
        [ 0.0047, -0.0109, -0.0037,  ..., -0.0140, -0.0043, -0.0003],
        [-0.0119,  0.0034,  0.0030,  ...,  0.0002,  0.0181, -0.0029],
        ...,
        [ 0.0024, -0.0096,  0.0013,  ...,  0.0024,  0.0103,  0.0021],
        [ 0.0169,  0.0021,  0.0004,  ..., -0.0201, -0.0025,  0.0286],
        [ 0.0017,  0.0015,  0.0062,  ...,  0.0067,  0.0141,  0.0096]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-02 16:23:07 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A galaxy is a member of a universe
A photo is a member of a album
A elephant is a member of a herd
A sheep is a member of a flock
A secretary is a member of a staff
A song is a member of a album
A member is a member of a club
A star is a member of a
2024-07-02 16:23:07 root INFO     total operator prediction time: 4099.545314311981 seconds
2024-07-02 17:35:25 root INFO     loading model + tokenizer
2024-07-02 17:35:43 root INFO     model + tokenizer loaded
2024-07-02 17:35:43 __main__ INFO     starting test: <class 'lre.operators.JacobianIclMeanEstimator'> on male - female
2024-07-02 17:35:45 root INFO     building operator male - female
2024-07-02 17:35:45 root INFO     h_layer_name='transformer.h.5.ln_1' z_layer_name='transformer.h.27'
2024-07-02 17:35:46 root INFO     [order_1_approx] starting weight calculation for A female father is known as a mother
A female grandson is known as a granddaughter
A female ram is known as a ewe
A female boy is known as a girl
A female prince is known as a princess
A female gentleman is known as a lady
A female son is known as a daughter
A female sir is known as a
2024-07-02 17:35:46 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5.ln_1
2024-07-02 17:35:52 root INFO     loading model + tokenizer
2024-07-02 17:36:08 root INFO     model + tokenizer loaded
2024-07-02 17:36:08 __main__ INFO     starting test: <class 'lre.operators.JacobianIclMeanEstimator'> on un+adj_reg
2024-07-02 17:36:11 root INFO     building operator un+adj_reg
2024-07-02 17:36:11 root INFO     h_layer_name='transformer.h.5.ln_1' z_layer_name='transformer.h.27'
2024-07-02 17:36:11 root INFO     [order_1_approx] starting weight calculation for The opposite of veiled is unveiled
The opposite of reliable is unreliable
The opposite of changed is unchanged
The opposite of restricted is unrestricted
The opposite of noticed is unnoticed
The opposite of related is unrelated
The opposite of available is unavailable
The opposite of conditional is
2024-07-02 17:36:11 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5.ln_1
2024-07-02 17:40:14 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 0.0018,  0.0194, -0.0004,  ..., -0.0022,  0.0040,  0.0141],
        [ 0.0115, -0.0068,  0.0035,  ..., -0.0057, -0.0079,  0.0074],
        [ 0.0089,  0.0148, -0.0035,  ...,  0.0006, -0.0078,  0.0050],
        ...,
        [-0.0065, -0.0105,  0.0061,  ..., -0.0035, -0.0035, -0.0070],
        [ 0.0023, -0.0046, -0.0021,  ..., -0.0027,  0.0175,  0.0051],
        [-0.0078, -0.0054, -0.0039,  ...,  0.0043,  0.0117,  0.0052]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-02 17:40:15 root INFO     h_layer_name='transformer.h.5' z_layer_name='transformer.h.27'
2024-07-02 17:40:15 root INFO     [order_1_approx] starting weight calculation for The opposite of veiled is unveiled
The opposite of reliable is unreliable
The opposite of changed is unchanged
The opposite of restricted is unrestricted
The opposite of noticed is unnoticed
The opposite of related is unrelated
The opposite of available is unavailable
The opposite of conditional is
2024-07-02 17:40:15 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5
2024-07-02 17:44:11 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0537, -0.0244,  0.0006,  ..., -0.0057, -0.0159, -0.0280],
        [-0.0159, -0.0214, -0.0079,  ...,  0.0011,  0.0110,  0.0225],
        [-0.0301, -0.0204, -0.0430,  ...,  0.0031, -0.0188,  0.0089],
        ...,
        [-0.0055, -0.0253, -0.0119,  ..., -0.0589,  0.0164,  0.0168],
        [ 0.0078, -0.0037,  0.0008,  ..., -0.0181, -0.0333, -0.0187],
        [ 0.0369,  0.0317, -0.0030,  ..., -0.0111, -0.0254, -0.0349]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-02 17:44:12 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of veiled is unveiled
The opposite of reliable is unreliable
The opposite of changed is unchanged
The opposite of restricted is unrestricted
The opposite of noticed is unnoticed
The opposite of related is unrelated
The opposite of available is unavailable
The opposite of conditional is
2024-07-02 17:44:12 root INFO     h_layer_name='transformer.h.5.ln_1' z_layer_name='transformer.h.27'
2024-07-02 17:44:12 root INFO     [order_1_approx] starting weight calculation for The opposite of noticed is unnoticed
The opposite of restricted is unrestricted
The opposite of reliable is unreliable
The opposite of available is unavailable
The opposite of conditional is unconditional
The opposite of changed is unchanged
The opposite of veiled is unveiled
The opposite of related is
2024-07-02 17:44:12 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5.ln_1
2024-07-02 17:48:16 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-9.3460e-05,  3.3493e-03,  1.3351e-04,  ...,  7.3814e-03,
         -2.2232e-02,  1.9104e-02],
        [-5.4398e-03, -1.3245e-02, -7.4463e-03,  ..., -4.1428e-03,
         -9.7275e-03,  1.2756e-02],
        [ 6.1913e-03,  3.6755e-03, -7.3776e-03,  ...,  1.9627e-03,
          2.0826e-04, -2.5291e-03],
        ...,
        [-1.3618e-03, -2.4643e-03, -3.6507e-03,  ...,  3.9444e-03,
         -1.9436e-03, -4.0932e-03],
        [-5.4016e-03,  1.2962e-02, -6.8426e-04,  ..., -2.4033e-03,
         -4.3907e-03, -1.1307e-02],
        [-1.0406e-02, -1.0643e-02, -1.5228e-02,  ..., -1.6266e-02,
         -1.6632e-02,  1.0788e-02]], device='cuda:0', dtype=torch.float16) 

                    
2024-07-02 17:48:17 root INFO     h_layer_name='transformer.h.5' z_layer_name='transformer.h.27'
2024-07-02 17:48:17 root INFO     [order_1_approx] starting weight calculation for The opposite of noticed is unnoticed
The opposite of restricted is unrestricted
The opposite of reliable is unreliable
The opposite of available is unavailable
The opposite of conditional is unconditional
The opposite of changed is unchanged
The opposite of veiled is unveiled
The opposite of related is
2024-07-02 17:48:17 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5
2024-07-02 17:52:13 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0252,  0.0029,  0.0211,  ..., -0.0181, -0.0232, -0.0272],
        [-0.0004, -0.0071, -0.0284,  ...,  0.0251,  0.0057, -0.0033],
        [ 0.0327, -0.0013, -0.0471,  ..., -0.0133, -0.0188,  0.0165],
        ...,
        [ 0.0158, -0.0247, -0.0077,  ..., -0.0275,  0.0242,  0.0251],
        [-0.0157, -0.0098,  0.0191,  ...,  0.0035, -0.0464,  0.0056],
        [ 0.0220,  0.0225, -0.0142,  ..., -0.0135,  0.0552, -0.0119]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-02 17:52:14 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of noticed is unnoticed
The opposite of restricted is unrestricted
The opposite of reliable is unreliable
The opposite of available is unavailable
The opposite of conditional is unconditional
The opposite of changed is unchanged
The opposite of veiled is unveiled
The opposite of related is
2024-07-02 17:52:14 root INFO     h_layer_name='transformer.h.5.ln_1' z_layer_name='transformer.h.27'
2024-07-02 17:52:14 root INFO     [order_1_approx] starting weight calculation for The opposite of noticed is unnoticed
The opposite of related is unrelated
The opposite of changed is unchanged
The opposite of reliable is unreliable
The opposite of conditional is unconditional
The opposite of available is unavailable
The opposite of restricted is unrestricted
The opposite of veiled is
2024-07-02 17:52:14 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5.ln_1
2024-07-02 17:56:18 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-9.3460e-03,  3.5820e-03,  3.5191e-04,  ..., -3.8948e-03,
         -2.5730e-03,  7.8659e-03],
        [ 8.1406e-03, -2.7237e-03,  1.7843e-03,  ..., -8.4686e-04,
         -9.9640e-03, -4.6005e-03],
        [-9.5215e-03,  1.0929e-03, -5.5504e-03,  ..., -2.0256e-03,
          7.3204e-03, -1.2283e-03],
        ...,
        [ 1.2993e-02, -9.8648e-03, -1.2253e-02,  ...,  1.1778e-03,
         -1.3588e-02,  1.4824e-02],
        [-1.1093e-02,  2.2888e-05, -2.6443e-02,  ...,  7.5226e-03,
         -4.6883e-03, -4.4594e-03],
        [-2.0401e-02,  3.0975e-02, -1.4587e-02,  ..., -2.5177e-02,
          1.1620e-02,  2.7405e-02]], device='cuda:0', dtype=torch.float16) 

                    
2024-07-02 17:56:19 root INFO     h_layer_name='transformer.h.5' z_layer_name='transformer.h.27'
2024-07-02 17:56:19 root INFO     [order_1_approx] starting weight calculation for The opposite of noticed is unnoticed
The opposite of related is unrelated
The opposite of changed is unchanged
The opposite of reliable is unreliable
The opposite of conditional is unconditional
The opposite of available is unavailable
The opposite of restricted is unrestricted
The opposite of veiled is
2024-07-02 17:56:19 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5
2024-07-02 18:00:15 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0269, -0.0244, -0.0104,  ...,  0.0224, -0.0049, -0.0019],
        [-0.0431, -0.0411, -0.0123,  ..., -0.0116, -0.0198,  0.0107],
        [-0.0055, -0.0208, -0.0450,  ...,  0.0006,  0.0042,  0.0476],
        ...,
        [ 0.0083,  0.0136,  0.0133,  ..., -0.0307, -0.0010,  0.0327],
        [ 0.0265,  0.0115,  0.0316,  ..., -0.0221, -0.0217,  0.0060],
        [ 0.0322,  0.0065, -0.0030,  ..., -0.0094,  0.0263, -0.0230]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-02 18:00:15 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of noticed is unnoticed
The opposite of related is unrelated
The opposite of changed is unchanged
The opposite of reliable is unreliable
The opposite of conditional is unconditional
The opposite of available is unavailable
The opposite of restricted is unrestricted
The opposite of veiled is
2024-07-02 18:00:16 root INFO     h_layer_name='transformer.h.5.ln_1' z_layer_name='transformer.h.27'
2024-07-02 18:00:16 root INFO     [order_1_approx] starting weight calculation for The opposite of conditional is unconditional
The opposite of available is unavailable
The opposite of reliable is unreliable
The opposite of related is unrelated
The opposite of veiled is unveiled
The opposite of restricted is unrestricted
The opposite of changed is unchanged
The opposite of noticed is
2024-07-02 18:00:16 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5.ln_1
2024-07-02 18:04:20 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0116,  0.0025,  0.0198,  ...,  0.0019, -0.0077,  0.0088],
        [-0.0088, -0.0196, -0.0008,  ..., -0.0024, -0.0106,  0.0136],
        [ 0.0055, -0.0073,  0.0034,  ..., -0.0087, -0.0300,  0.0077],
        ...,
        [ 0.0090,  0.0097,  0.0133,  ..., -0.0068,  0.0095, -0.0219],
        [ 0.0036,  0.0120,  0.0066,  ..., -0.0058,  0.0099, -0.0224],
        [ 0.0026, -0.0185, -0.0224,  ..., -0.0101,  0.0104,  0.0050]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-02 18:04:21 root INFO     h_layer_name='transformer.h.5' z_layer_name='transformer.h.27'
2024-07-02 18:04:21 root INFO     [order_1_approx] starting weight calculation for The opposite of conditional is unconditional
The opposite of available is unavailable
The opposite of reliable is unreliable
The opposite of related is unrelated
The opposite of veiled is unveiled
The opposite of restricted is unrestricted
The opposite of changed is unchanged
The opposite of noticed is
2024-07-02 18:04:21 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5
2024-07-02 18:08:18 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0128,  0.0217, -0.0158,  ...,  0.0176, -0.0147,  0.0087],
        [ 0.0112, -0.0260, -0.0032,  ..., -0.0152, -0.0208,  0.0118],
        [-0.0135, -0.0278, -0.0507,  ...,  0.0295, -0.0050, -0.0046],
        ...,
        [-0.0134,  0.0118, -0.0101,  ..., -0.0563,  0.0287,  0.0316],
        [ 0.0196,  0.0484,  0.0040,  ...,  0.0043, -0.0316, -0.0179],
        [ 0.0119, -0.0227, -0.0045,  ..., -0.0128,  0.0200, -0.0291]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-02 18:08:19 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of conditional is unconditional
The opposite of available is unavailable
The opposite of reliable is unreliable
The opposite of related is unrelated
The opposite of veiled is unveiled
The opposite of restricted is unrestricted
The opposite of changed is unchanged
The opposite of noticed is
2024-07-02 18:08:19 root INFO     h_layer_name='transformer.h.5.ln_1' z_layer_name='transformer.h.27'
2024-07-02 18:08:19 root INFO     [order_1_approx] starting weight calculation for The opposite of changed is unchanged
The opposite of veiled is unveiled
The opposite of noticed is unnoticed
The opposite of related is unrelated
The opposite of available is unavailable
The opposite of restricted is unrestricted
The opposite of conditional is unconditional
The opposite of reliable is
2024-07-02 18:08:19 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5.ln_1
2024-07-02 18:12:24 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0006, -0.0107, -0.0013,  ..., -0.0087,  0.0089,  0.0145],
        [ 0.0040, -0.0029, -0.0122,  ..., -0.0014,  0.0393, -0.0140],
        [ 0.0034, -0.0026, -0.0064,  ..., -0.0043,  0.0034, -0.0070],
        ...,
        [ 0.0017,  0.0063, -0.0009,  ..., -0.0097,  0.0041, -0.0135],
        [ 0.0092,  0.0121, -0.0027,  ...,  0.0012,  0.0114,  0.0234],
        [-0.0213, -0.0071,  0.0073,  ..., -0.0058, -0.0030,  0.0294]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-02 18:12:25 root INFO     h_layer_name='transformer.h.5' z_layer_name='transformer.h.27'
2024-07-02 18:12:25 root INFO     [order_1_approx] starting weight calculation for The opposite of changed is unchanged
The opposite of veiled is unveiled
The opposite of noticed is unnoticed
The opposite of related is unrelated
The opposite of available is unavailable
The opposite of restricted is unrestricted
The opposite of conditional is unconditional
The opposite of reliable is
2024-07-02 18:12:25 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5
2024-07-02 18:16:19 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-1.7426e-02, -1.4030e-02,  2.8572e-03,  ...,  4.3869e-05,
         -5.0125e-03,  1.5335e-03],
        [-2.6642e-02, -2.9114e-02, -3.3569e-03,  ..., -9.1629e-03,
         -3.1738e-02,  1.0063e-02],
        [-9.3536e-03, -1.3786e-02, -2.1622e-02,  ..., -2.5909e-02,
         -3.7567e-02,  1.2711e-02],
        ...,
        [ 1.4389e-02, -1.7242e-02, -8.7204e-03,  ..., -1.9363e-02,
          2.4979e-02,  5.3635e-03],
        [ 3.2120e-03, -9.3079e-04,  1.2032e-02,  ...,  1.0727e-02,
         -2.1423e-02, -2.7847e-03],
        [-1.5747e-02,  5.3406e-04, -8.1558e-03,  ..., -3.4607e-02,
         -1.3580e-02, -3.9398e-02]], device='cuda:0', dtype=torch.float16) 

                    
2024-07-02 18:16:20 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of changed is unchanged
The opposite of veiled is unveiled
The opposite of noticed is unnoticed
The opposite of related is unrelated
The opposite of available is unavailable
The opposite of restricted is unrestricted
The opposite of conditional is unconditional
The opposite of reliable is
2024-07-02 18:16:20 root INFO     h_layer_name='transformer.h.5.ln_1' z_layer_name='transformer.h.27'
2024-07-02 18:16:20 root INFO     [order_1_approx] starting weight calculation for The opposite of available is unavailable
The opposite of conditional is unconditional
The opposite of restricted is unrestricted
The opposite of veiled is unveiled
The opposite of related is unrelated
The opposite of reliable is unreliable
The opposite of noticed is unnoticed
The opposite of changed is
2024-07-02 18:16:20 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5.ln_1
2024-07-02 18:20:21 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0012,  0.0041,  0.0052,  ...,  0.0066, -0.0124,  0.0132],
        [-0.0129,  0.0008, -0.0033,  ...,  0.0072, -0.0070, -0.0205],
        [-0.0140,  0.0131, -0.0052,  ...,  0.0074, -0.0100,  0.0093],
        ...,
        [ 0.0146,  0.0014, -0.0067,  ..., -0.0067, -0.0104,  0.0056],
        [ 0.0049,  0.0075, -0.0058,  ..., -0.0039,  0.0118, -0.0032],
        [-0.0125, -0.0062,  0.0022,  ..., -0.0040, -0.0072, -0.0060]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-02 18:20:22 root INFO     h_layer_name='transformer.h.5' z_layer_name='transformer.h.27'
2024-07-02 18:20:22 root INFO     [order_1_approx] starting weight calculation for The opposite of available is unavailable
The opposite of conditional is unconditional
The opposite of restricted is unrestricted
The opposite of veiled is unveiled
The opposite of related is unrelated
The opposite of reliable is unreliable
The opposite of noticed is unnoticed
The opposite of changed is
2024-07-02 18:20:22 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5
2024-07-02 18:24:18 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0459, -0.0163, -0.0065,  ..., -0.0064, -0.0378,  0.0056],
        [-0.0037, -0.0298,  0.0054,  ..., -0.0075,  0.0145, -0.0037],
        [ 0.0207, -0.0168, -0.0296,  ...,  0.0009, -0.0156,  0.0129],
        ...,
        [ 0.0121, -0.0166, -0.0041,  ..., -0.0081,  0.0138, -0.0076],
        [ 0.0161, -0.0043,  0.0015,  ...,  0.0026, -0.0454,  0.0102],
        [-0.0007,  0.0299, -0.0081,  ..., -0.0302,  0.0141, -0.0450]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-02 18:24:19 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of available is unavailable
The opposite of conditional is unconditional
The opposite of restricted is unrestricted
The opposite of veiled is unveiled
The opposite of related is unrelated
The opposite of reliable is unreliable
The opposite of noticed is unnoticed
The opposite of changed is
2024-07-02 18:24:19 root INFO     h_layer_name='transformer.h.5.ln_1' z_layer_name='transformer.h.27'
2024-07-02 18:24:19 root INFO     [order_1_approx] starting weight calculation for The opposite of conditional is unconditional
The opposite of related is unrelated
The opposite of noticed is unnoticed
The opposite of reliable is unreliable
The opposite of veiled is unveiled
The opposite of restricted is unrestricted
The opposite of changed is unchanged
The opposite of available is
2024-07-02 18:24:19 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5.ln_1
2024-07-02 18:28:23 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 3.6602e-03,  1.1238e-02, -9.7656e-03,  ..., -2.7046e-03,
          5.7220e-03,  1.1383e-02],
        [-7.3242e-04, -6.6299e-03, -7.0572e-04,  ...,  1.1589e-02,
          5.7030e-03, -1.5259e-02],
        [ 5.5885e-03,  3.7022e-03, -3.1471e-05,  ...,  1.5472e-02,
          5.4855e-03,  1.4830e-03],
        ...,
        [-4.2953e-03, -8.8072e-04, -3.4351e-03,  ..., -1.1902e-02,
          1.3077e-02, -1.5533e-02],
        [ 8.6975e-03,  1.3184e-02, -3.2654e-03,  ..., -9.0485e-03,
          4.1885e-03,  1.3361e-03],
        [-1.0208e-02, -1.9211e-02,  1.0414e-03,  ...,  7.9956e-03,
         -5.1498e-03,  4.4556e-03]], device='cuda:0', dtype=torch.float16) 

                    
2024-07-02 18:28:24 root INFO     h_layer_name='transformer.h.5' z_layer_name='transformer.h.27'
2024-07-02 18:28:24 root INFO     [order_1_approx] starting weight calculation for The opposite of conditional is unconditional
The opposite of related is unrelated
The opposite of noticed is unnoticed
The opposite of reliable is unreliable
The opposite of veiled is unveiled
The opposite of restricted is unrestricted
The opposite of changed is unchanged
The opposite of available is
2024-07-02 18:28:24 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5
2024-07-02 18:32:20 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0106, -0.0339,  0.0122,  ...,  0.0123, -0.0048,  0.0196],
        [-0.0021, -0.0178, -0.0220,  ..., -0.0284,  0.0131,  0.0052],
        [-0.0001,  0.0139, -0.0309,  ..., -0.0216, -0.0076,  0.0011],
        ...,
        [-0.0151, -0.0071, -0.0094,  ..., -0.0119, -0.0138,  0.0330],
        [-0.0018,  0.0008,  0.0055,  ...,  0.0004, -0.0383,  0.0096],
        [ 0.0211,  0.0221, -0.0276,  ..., -0.0473,  0.0225, -0.0271]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-02 18:32:21 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of conditional is unconditional
The opposite of related is unrelated
The opposite of noticed is unnoticed
The opposite of reliable is unreliable
The opposite of veiled is unveiled
The opposite of restricted is unrestricted
The opposite of changed is unchanged
The opposite of available is
2024-07-02 18:32:21 root INFO     h_layer_name='transformer.h.5.ln_1' z_layer_name='transformer.h.27'
2024-07-02 18:32:21 root INFO     [order_1_approx] starting weight calculation for The opposite of changed is unchanged
The opposite of available is unavailable
The opposite of reliable is unreliable
The opposite of noticed is unnoticed
The opposite of conditional is unconditional
The opposite of related is unrelated
The opposite of veiled is unveiled
The opposite of restricted is
2024-07-02 18:32:21 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5.ln_1
2024-07-02 18:36:26 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-2.1118e-02,  1.8219e-02, -5.6610e-03,  ..., -8.4400e-05,
          4.3373e-03,  1.2520e-02],
        [ 5.4665e-03, -8.3923e-03,  3.3512e-03,  ..., -7.3242e-03,
         -6.6757e-04, -5.3978e-03],
        [-6.0349e-03,  3.0136e-02, -1.1215e-02,  ..., -4.3564e-03,
         -7.4921e-03,  2.0142e-03],
        ...,
        [ 1.0643e-02, -2.6352e-02,  9.8572e-03,  ...,  3.1281e-04,
         -5.8975e-03,  2.0477e-02],
        [ 1.6129e-02,  5.9624e-03, -4.8599e-03,  ..., -2.5635e-03,
         -2.8000e-03, -8.5449e-03],
        [ 5.3902e-03,  1.6617e-02,  1.5707e-03,  ..., -2.5806e-03,
         -3.2082e-03,  1.0834e-02]], device='cuda:0', dtype=torch.float16) 

                    
2024-07-02 18:36:27 root INFO     h_layer_name='transformer.h.5' z_layer_name='transformer.h.27'
2024-07-02 18:36:27 root INFO     [order_1_approx] starting weight calculation for The opposite of changed is unchanged
The opposite of available is unavailable
The opposite of reliable is unreliable
The opposite of noticed is unnoticed
The opposite of conditional is unconditional
The opposite of related is unrelated
The opposite of veiled is unveiled
The opposite of restricted is
2024-07-02 18:36:27 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5
2024-07-02 18:40:25 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0209, -0.0121,  0.0034,  ..., -0.0069, -0.0333, -0.0192],
        [-0.0111, -0.0247, -0.0011,  ..., -0.0072, -0.0117,  0.0161],
        [-0.0247, -0.0259, -0.0391,  ..., -0.0020, -0.0164, -0.0019],
        ...,
        [ 0.0087,  0.0249, -0.0063,  ..., -0.0449, -0.0072,  0.0084],
        [-0.0057, -0.0132,  0.0313,  ..., -0.0039, -0.0096,  0.0053],
        [-0.0164, -0.0219, -0.0374,  ...,  0.0015,  0.0569, -0.0234]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-02 18:40:26 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of changed is unchanged
The opposite of available is unavailable
The opposite of reliable is unreliable
The opposite of noticed is unnoticed
The opposite of conditional is unconditional
The opposite of related is unrelated
The opposite of veiled is unveiled
The opposite of restricted is
2024-07-02 18:40:26 root INFO     total operator prediction time: 3854.402337551117 seconds
2024-07-02 18:40:26 __main__ INFO     starting test: <class 'lre.operators.JacobianIclMeanEstimator'> on things - color
2024-07-02 18:40:28 root INFO     building operator things - color
2024-07-02 18:40:28 root INFO     h_layer_name='transformer.h.5.ln_1' z_layer_name='transformer.h.27'
2024-07-02 18:40:28 root INFO     [order_1_approx] starting weight calculation for A female paper is known as a white
A female emerald is known as a green
A female celery is known as a green
A female crow is known as a black
A female ruby is known as a red
A female ant is known as a black
A female broccoli is known as a green
A female radish is known as a
2024-07-02 18:40:28 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5.ln_1
2024-07-02 18:44:33 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0062, -0.0063,  0.0031,  ...,  0.0010, -0.0014,  0.0021],
        [-0.0065,  0.0045,  0.0020,  ...,  0.0015,  0.0165, -0.0160],
        [ 0.0107,  0.0078,  0.0113,  ...,  0.0032, -0.0105, -0.0084],
        ...,
        [-0.0074, -0.0047,  0.0102,  ...,  0.0085,  0.0020,  0.0100],
        [ 0.0053, -0.0051,  0.0051,  ...,  0.0062,  0.0121, -0.0018],
        [ 0.0012,  0.0064,  0.0087,  ..., -0.0016,  0.0070, -0.0048]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-02 18:44:34 root INFO     h_layer_name='transformer.h.5' z_layer_name='transformer.h.27'
2024-07-02 18:44:34 root INFO     [order_1_approx] starting weight calculation for A female paper is known as a white
A female emerald is known as a green
A female celery is known as a green
A female crow is known as a black
A female ruby is known as a red
A female ant is known as a black
A female broccoli is known as a green
A female radish is known as a
2024-07-02 18:44:34 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5
2024-07-02 18:48:30 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 0.0072, -0.0104,  0.0015,  ...,  0.0181, -0.0005, -0.0194],
        [-0.0060,  0.0250,  0.0022,  ..., -0.0031, -0.0062,  0.0009],
        [-0.0202,  0.0103, -0.0019,  ...,  0.0099,  0.0085,  0.0191],
        ...,
        [ 0.0191, -0.0061,  0.0062,  ...,  0.0107,  0.0140, -0.0096],
        [-0.0014, -0.0044, -0.0315,  ...,  0.0019, -0.0010,  0.0238],
        [ 0.0024, -0.0066, -0.0219,  ..., -0.0191,  0.0118, -0.0009]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-02 18:48:31 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A female paper is known as a white
A female emerald is known as a green
A female celery is known as a green
A female crow is known as a black
A female ruby is known as a red
A female ant is known as a black
A female broccoli is known as a green
A female radish is known as a
2024-07-02 18:48:31 root INFO     h_layer_name='transformer.h.5.ln_1' z_layer_name='transformer.h.27'
2024-07-02 18:48:31 root INFO     [order_1_approx] starting weight calculation for A female ant is known as a black
A female broccoli is known as a green
A female ruby is known as a red
A female paper is known as a white
A female crow is known as a black
A female celery is known as a green
A female radish is known as a red
A female emerald is known as a
2024-07-02 18:48:31 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5.ln_1
2024-07-02 18:52:39 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-7.4921e-03, -6.2637e-03,  6.9189e-04,  ..., -1.4557e-02,
         -7.7209e-03,  2.7065e-03],
        [ 2.7657e-05, -9.5215e-03, -3.0327e-04,  ...,  1.8854e-03,
         -5.1270e-03,  5.1041e-03],
        [ 7.8201e-05, -7.1678e-03,  5.9547e-03,  ...,  3.0994e-03,
         -1.3367e-02, -1.4572e-02],
        ...,
        [ 2.6360e-03, -6.2275e-04, -4.1533e-04,  ...,  1.3321e-02,
         -1.0452e-02, -1.1803e-02],
        [ 8.8501e-03,  2.0111e-02, -1.4832e-02,  ...,  1.4095e-03,
          3.2654e-03, -2.2980e-02],
        [-8.1253e-03,  7.3624e-04, -1.5736e-05,  ...,  8.2064e-04,
          8.5068e-03,  1.4210e-03]], device='cuda:0', dtype=torch.float16) 

                    
2024-07-02 18:52:39 root INFO     h_layer_name='transformer.h.5' z_layer_name='transformer.h.27'
2024-07-02 18:52:39 root INFO     [order_1_approx] starting weight calculation for A female ant is known as a black
A female broccoli is known as a green
A female ruby is known as a red
A female paper is known as a white
A female crow is known as a black
A female celery is known as a green
A female radish is known as a red
A female emerald is known as a
2024-07-02 18:52:40 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5
2024-07-02 18:56:36 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 5.8289e-03, -7.3929e-03, -8.3313e-03,  ..., -1.4076e-03,
          2.2797e-02, -2.1915e-03],
        [-8.1711e-03, -6.9008e-03,  3.4142e-04,  ..., -2.0676e-03,
          4.5776e-05, -1.3435e-02],
        [-1.2732e-03, -7.0648e-03,  1.3367e-02,  ..., -1.9455e-03,
          9.0027e-03,  6.7902e-03],
        ...,
        [ 2.1881e-02, -4.5700e-03, -6.2637e-03,  ...,  1.2169e-02,
         -1.7761e-02,  2.0615e-02],
        [-3.4561e-03, -1.0391e-02,  1.8341e-02,  ..., -5.6572e-03,
         -2.6672e-02,  7.5531e-03],
        [-1.9226e-03,  1.6556e-02, -3.8910e-04,  ..., -1.4030e-02,
         -2.5711e-03, -7.2479e-03]], device='cuda:0', dtype=torch.float16) 

                    
2024-07-02 18:56:37 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A female ant is known as a black
A female broccoli is known as a green
A female ruby is known as a red
A female paper is known as a white
A female crow is known as a black
A female celery is known as a green
A female radish is known as a red
A female emerald is known as a
2024-07-02 18:56:37 root INFO     h_layer_name='transformer.h.5.ln_1' z_layer_name='transformer.h.27'
2024-07-02 18:56:37 root INFO     [order_1_approx] starting weight calculation for A female ruby is known as a red
A female celery is known as a green
A female ant is known as a black
A female radish is known as a red
A female emerald is known as a green
A female crow is known as a black
A female broccoli is known as a green
A female paper is known as a
2024-07-02 18:56:37 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5.ln_1
2024-07-02 19:00:43 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-2.3766e-03, -1.0910e-02,  8.7881e-04,  ...,  3.4065e-03,
         -6.9466e-03, -2.5787e-03],
        [ 3.7766e-03, -8.4457e-03,  1.1177e-03,  ...,  5.9700e-04,
         -1.1263e-03,  3.8643e-03],
        [-2.1019e-03,  3.8567e-03, -7.9880e-03,  ...,  3.6716e-03,
         -9.1324e-03, -3.8261e-03],
        ...,
        [ 1.0033e-03,  4.3488e-03, -1.4427e-02,  ...,  4.1847e-03,
         -8.2855e-03, -1.8101e-03],
        [ 2.7103e-03,  6.9389e-03, -5.2299e-03,  ...,  3.8261e-03,
          1.3489e-02,  9.5069e-05],
        [-8.4763e-03, -4.1413e-04, -3.8395e-03,  ...,  9.7504e-03,
          1.7052e-03, -6.6948e-03]], device='cuda:0', dtype=torch.float16) 

                    
2024-07-02 19:00:43 root INFO     h_layer_name='transformer.h.5' z_layer_name='transformer.h.27'
2024-07-02 19:00:43 root INFO     [order_1_approx] starting weight calculation for A female ruby is known as a red
A female celery is known as a green
A female ant is known as a black
A female radish is known as a red
A female emerald is known as a green
A female crow is known as a black
A female broccoli is known as a green
A female paper is known as a
2024-07-02 19:00:43 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5
2024-07-02 19:04:41 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 1.5511e-02, -3.5919e-02,  6.7673e-03,  ...,  8.5144e-03,
         -2.2926e-03,  5.4016e-03],
        [ 1.2512e-02,  7.7209e-03,  9.3918e-03,  ...,  1.5106e-03,
         -1.4427e-02,  1.0681e-03],
        [-6.2790e-03,  7.5760e-03,  1.9196e-02,  ...,  1.7185e-03,
          1.0704e-02, -7.9269e-03],
        ...,
        [-2.9302e-04, -1.3458e-02,  1.6937e-02,  ...,  1.6766e-03,
         -8.2626e-03,  2.1378e-02],
        [ 1.1215e-02,  1.4687e-03,  8.2016e-05,  ..., -2.4689e-02,
         -1.9806e-02, -2.9640e-03],
        [-3.1403e-02, -6.9199e-03, -1.0666e-02,  ...,  1.0033e-02,
          2.1851e-02,  2.8778e-02]], device='cuda:0', dtype=torch.float16) 

                    
2024-07-02 19:04:42 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A female ruby is known as a red
A female celery is known as a green
A female ant is known as a black
A female radish is known as a red
A female emerald is known as a green
A female crow is known as a black
A female broccoli is known as a green
A female paper is known as a
2024-07-02 19:04:42 root INFO     h_layer_name='transformer.h.5.ln_1' z_layer_name='transformer.h.27'
2024-07-02 19:04:42 root INFO     [order_1_approx] starting weight calculation for A female crow is known as a black
A female paper is known as a white
A female emerald is known as a green
A female ruby is known as a red
A female radish is known as a red
A female broccoli is known as a green
A female celery is known as a green
A female ant is known as a
2024-07-02 19:04:42 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5.ln_1
2024-07-02 19:08:48 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 1.6251e-03,  3.1662e-03,  1.3374e-02,  ...,  4.2915e-03,
         -1.2150e-03, -1.1559e-03],
        [-3.5286e-05,  1.1368e-03,  5.9547e-03,  ..., -1.1616e-03,
          2.7332e-03, -8.1940e-03],
        [-2.3575e-03,  1.6880e-03, -3.8376e-03,  ...,  3.4499e-04,
          7.3509e-03, -5.2910e-03],
        ...,
        [ 2.7809e-03,  1.2215e-02,  3.7441e-03,  ...,  6.3057e-03,
          1.3718e-02, -1.9836e-03],
        [-6.6185e-03, -2.4605e-04, -1.2901e-02,  ..., -6.4812e-03,
         -1.3062e-02, -4.7226e-03],
        [ 1.2112e-03,  5.9090e-03, -3.0994e-03,  ..., -6.0844e-04,
          1.3107e-02,  4.8637e-04]], device='cuda:0', dtype=torch.float16) 

                    
2024-07-02 19:08:49 root INFO     h_layer_name='transformer.h.5' z_layer_name='transformer.h.27'
2024-07-02 19:08:49 root INFO     [order_1_approx] starting weight calculation for A female crow is known as a black
A female paper is known as a white
A female emerald is known as a green
A female ruby is known as a red
A female radish is known as a red
A female broccoli is known as a green
A female celery is known as a green
A female ant is known as a
2024-07-02 19:08:49 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5
2024-07-02 19:12:45 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0012, -0.0057,  0.0092,  ...,  0.0142, -0.0129,  0.0039],
        [-0.0047, -0.0224,  0.0114,  ...,  0.0092, -0.0030,  0.0064],
        [-0.0024,  0.0063,  0.0009,  ..., -0.0078,  0.0088,  0.0042],
        ...,
        [-0.0039, -0.0135, -0.0006,  ..., -0.0198, -0.0210, -0.0067],
        [ 0.0069, -0.0250, -0.0006,  ...,  0.0095,  0.0119,  0.0084],
        [-0.0090, -0.0107, -0.0074,  ...,  0.0047,  0.0019,  0.0219]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-02 19:12:46 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A female crow is known as a black
A female paper is known as a white
A female emerald is known as a green
A female ruby is known as a red
A female radish is known as a red
A female broccoli is known as a green
A female celery is known as a green
A female ant is known as a
2024-07-02 19:12:46 root INFO     h_layer_name='transformer.h.5.ln_1' z_layer_name='transformer.h.27'
2024-07-02 19:12:46 root INFO     [order_1_approx] starting weight calculation for A female paper is known as a white
A female ant is known as a black
A female radish is known as a red
A female emerald is known as a green
A female crow is known as a black
A female ruby is known as a red
A female broccoli is known as a green
A female celery is known as a
2024-07-02 19:12:46 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5.ln_1
2024-07-02 19:16:52 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 0.0060, -0.0090,  0.0056,  ...,  0.0035, -0.0054, -0.0068],
        [ 0.0154,  0.0111, -0.0084,  ...,  0.0154,  0.0036,  0.0108],
        [ 0.0120,  0.0058, -0.0009,  ...,  0.0059,  0.0040,  0.0062],
        ...,
        [-0.0147, -0.0030,  0.0003,  ...,  0.0173,  0.0048, -0.0020],
        [ 0.0044,  0.0018, -0.0123,  ...,  0.0085,  0.0076,  0.0097],
        [-0.0004, -0.0100,  0.0049,  ..., -0.0077,  0.0057,  0.0206]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-02 19:16:52 root INFO     h_layer_name='transformer.h.5' z_layer_name='transformer.h.27'
2024-07-02 19:16:53 root INFO     [order_1_approx] starting weight calculation for A female paper is known as a white
A female ant is known as a black
A female radish is known as a red
A female emerald is known as a green
A female crow is known as a black
A female ruby is known as a red
A female broccoli is known as a green
A female celery is known as a
2024-07-02 19:16:53 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5
2024-07-02 19:20:49 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0028, -0.0168,  0.0180,  ...,  0.0092,  0.0042, -0.0078],
        [ 0.0138,  0.0063,  0.0124,  ...,  0.0051, -0.0081,  0.0032],
        [-0.0090,  0.0016,  0.0090,  ...,  0.0067,  0.0046,  0.0025],
        ...,
        [-0.0070,  0.0003, -0.0075,  ...,  0.0052, -0.0140, -0.0003],
        [-0.0016, -0.0191, -0.0099,  ...,  0.0097,  0.0048,  0.0159],
        [-0.0018,  0.0276, -0.0012,  ..., -0.0173,  0.0177,  0.0027]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-02 19:20:49 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A female paper is known as a white
A female ant is known as a black
A female radish is known as a red
A female emerald is known as a green
A female crow is known as a black
A female ruby is known as a red
A female broccoli is known as a green
A female celery is known as a
2024-07-02 19:20:50 root INFO     h_layer_name='transformer.h.5.ln_1' z_layer_name='transformer.h.27'
2024-07-02 19:20:50 root INFO     [order_1_approx] starting weight calculation for A female celery is known as a green
A female ant is known as a black
A female paper is known as a white
A female crow is known as a black
A female radish is known as a red
A female ruby is known as a red
A female emerald is known as a green
A female broccoli is known as a
2024-07-02 19:20:50 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5.ln_1
2024-07-02 19:24:57 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0090,  0.0107, -0.0043,  ..., -0.0034,  0.0042,  0.0086],
        [ 0.0105,  0.0103, -0.0055,  ..., -0.0162,  0.0056, -0.0049],
        [-0.0052,  0.0061, -0.0033,  ..., -0.0011,  0.0024,  0.0017],
        ...,
        [-0.0012,  0.0044,  0.0075,  ..., -0.0019, -0.0021, -0.0133],
        [ 0.0011, -0.0049,  0.0041,  ..., -0.0071, -0.0038, -0.0044],
        [-0.0050, -0.0054,  0.0013,  ..., -0.0064, -0.0013, -0.0099]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-02 19:24:58 root INFO     h_layer_name='transformer.h.5' z_layer_name='transformer.h.27'
2024-07-02 19:24:58 root INFO     [order_1_approx] starting weight calculation for A female celery is known as a green
A female ant is known as a black
A female paper is known as a white
A female crow is known as a black
A female radish is known as a red
A female ruby is known as a red
A female emerald is known as a green
A female broccoli is known as a
2024-07-02 19:24:58 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5
2024-07-02 19:28:55 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 0.0117, -0.0076,  0.0046,  ...,  0.0059,  0.0164, -0.0049],
        [-0.0182,  0.0128,  0.0088,  ..., -0.0091,  0.0019, -0.0018],
        [-0.0190,  0.0094,  0.0029,  ..., -0.0172,  0.0080,  0.0230],
        ...,
        [-0.0077,  0.0061, -0.0072,  ...,  0.0013,  0.0173,  0.0138],
        [-0.0047, -0.0174, -0.0063,  ...,  0.0043, -0.0102,  0.0004],
        [-0.0072,  0.0127, -0.0049,  ..., -0.0126,  0.0172,  0.0357]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-02 19:28:56 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A female celery is known as a green
A female ant is known as a black
A female paper is known as a white
A female crow is known as a black
A female radish is known as a red
A female ruby is known as a red
A female emerald is known as a green
A female broccoli is known as a
2024-07-02 19:28:56 root INFO     h_layer_name='transformer.h.5.ln_1' z_layer_name='transformer.h.27'
2024-07-02 19:28:56 root INFO     [order_1_approx] starting weight calculation for A female paper is known as a white
A female broccoli is known as a green
A female radish is known as a red
A female emerald is known as a green
A female crow is known as a black
A female celery is known as a green
A female ant is known as a black
A female ruby is known as a
2024-07-02 19:28:56 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5.ln_1
2024-07-02 19:33:02 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-2.2602e-03,  1.9226e-03, -2.1915e-03,  ...,  3.2282e-04,
         -3.2635e-03,  9.2864e-05],
        [ 4.5624e-03,  6.4545e-03, -1.2001e-02,  ...,  1.5358e-02,
          1.3474e-02, -3.5667e-03],
        [-3.8586e-03, -1.0338e-02, -7.4768e-03,  ..., -9.2602e-04,
         -4.1885e-03, -1.7349e-02],
        ...,
        [ 3.1891e-03, -2.4223e-04,  6.4926e-03,  ...,  1.0109e-02,
         -6.0463e-04, -1.1688e-02],
        [ 4.1809e-03,  2.5291e-03, -5.0354e-03,  ...,  1.4862e-02,
          1.0918e-02, -1.2695e-02],
        [-7.4539e-03, -5.0507e-03,  3.8815e-03,  ..., -1.1856e-02,
          3.8834e-03,  8.5306e-04]], device='cuda:0', dtype=torch.float16) 

                    
2024-07-02 19:33:03 root INFO     h_layer_name='transformer.h.5' z_layer_name='transformer.h.27'
2024-07-02 19:33:03 root INFO     [order_1_approx] starting weight calculation for A female paper is known as a white
A female broccoli is known as a green
A female radish is known as a red
A female emerald is known as a green
A female crow is known as a black
A female celery is known as a green
A female ant is known as a black
A female ruby is known as a
2024-07-02 19:33:04 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5
2024-07-02 19:36:59 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 1.0849e-02, -1.3962e-02, -1.3756e-02,  ..., -7.6141e-03,
          1.1009e-02, -1.9073e-05],
        [ 8.2550e-03, -1.4687e-02,  3.6144e-03,  ..., -9.0256e-03,
         -9.7504e-03, -1.9043e-02],
        [ 3.0441e-03,  1.4992e-02,  1.3870e-02,  ...,  1.5625e-02,
          1.5617e-02,  2.4170e-02],
        ...,
        [ 2.8305e-03, -9.6436e-03, -2.1927e-02,  ..., -1.8646e-02,
         -1.1162e-02,  3.0411e-02],
        [-3.6354e-03, -3.9139e-03,  5.3520e-03,  ..., -4.7989e-03,
         -3.1281e-02,  7.5684e-03],
        [-1.2627e-02, -5.0507e-03,  1.6632e-02,  ..., -7.0763e-04,
          5.4321e-03, -3.3073e-03]], device='cuda:0', dtype=torch.float16) 

                    
2024-07-02 19:37:00 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A female paper is known as a white
A female broccoli is known as a green
A female radish is known as a red
A female emerald is known as a green
A female crow is known as a black
A female celery is known as a green
A female ant is known as a black
A female ruby is known as a
2024-07-02 19:37:00 root INFO     h_layer_name='transformer.h.5.ln_1' z_layer_name='transformer.h.27'
2024-07-02 19:37:00 root INFO     [order_1_approx] starting weight calculation for A female broccoli is known as a green
A female ruby is known as a red
A female emerald is known as a green
A female radish is known as a red
A female ant is known as a black
A female celery is known as a green
A female paper is known as a white
A female crow is known as a
2024-07-02 19:37:00 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5.ln_1
2024-07-02 19:41:05 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 4.2267e-03, -2.3632e-03, -6.4812e-03,  ..., -5.0812e-03,
          6.9885e-03, -3.9291e-03],
        [-4.7922e-04, -4.3259e-03, -7.5607e-03,  ...,  9.2239e-03,
         -2.8152e-03,  3.1586e-03],
        [-1.2150e-03,  4.8332e-03, -7.0114e-03,  ...,  8.6594e-03,
         -6.5994e-03, -3.3703e-03],
        ...,
        [ 9.4833e-03, -2.0790e-03,  2.1667e-03,  ..., -1.3016e-02,
         -3.4542e-03, -8.7662e-03],
        [ 1.6766e-03, -8.7738e-03, -1.4305e-05,  ..., -2.7122e-03,
         -2.8267e-03, -7.3547e-03],
        [-7.0457e-03,  2.0065e-03, -3.4714e-03,  ..., -2.3842e-03,
          3.7174e-03,  9.7370e-04]], device='cuda:0', dtype=torch.float16) 

                    
2024-07-02 19:41:06 root INFO     h_layer_name='transformer.h.5' z_layer_name='transformer.h.27'
2024-07-02 19:41:06 root INFO     [order_1_approx] starting weight calculation for A female broccoli is known as a green
A female ruby is known as a red
A female emerald is known as a green
A female radish is known as a red
A female ant is known as a black
A female celery is known as a green
A female paper is known as a white
A female crow is known as a
2024-07-02 19:41:06 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5
2024-07-02 19:45:03 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0078, -0.0192, -0.0040,  ...,  0.0039, -0.0193, -0.0186],
        [ 0.0086,  0.0124,  0.0255,  ...,  0.0169,  0.0077,  0.0171],
        [-0.0005, -0.0135,  0.0089,  ..., -0.0062,  0.0071,  0.0029],
        ...,
        [-0.0041, -0.0285, -0.0052,  ..., -0.0056,  0.0161,  0.0077],
        [-0.0163, -0.0039, -0.0075,  ...,  0.0058,  0.0110,  0.0125],
        [-0.0212, -0.0002, -0.0118,  ...,  0.0063, -0.0022,  0.0163]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-02 19:45:04 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A female broccoli is known as a green
A female ruby is known as a red
A female emerald is known as a green
A female radish is known as a red
A female ant is known as a black
A female celery is known as a green
A female paper is known as a white
A female crow is known as a
2024-07-02 19:45:04 root INFO     total operator prediction time: 3875.7933900356293 seconds
2024-07-02 19:45:04 __main__ INFO     starting test: <class 'lre.operators.JacobianIclMeanEstimator'> on meronyms - part
2024-07-02 19:45:06 root INFO     building operator meronyms - part
2024-07-02 19:45:06 root INFO     h_layer_name='transformer.h.5.ln_1' z_layer_name='transformer.h.27'
2024-07-02 19:45:06 root INFO     [order_1_approx] starting weight calculation for A part of a deer is a antler
A part of a academia is a college
A part of a comb is a teeth
A part of a jail is a cell
A part of a torso is a chest
A part of a byte is a bit
A part of a window is a pane
A part of a teapot is a
2024-07-02 19:45:06 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5.ln_1
2024-07-02 19:49:11 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0070,  0.0016,  0.0069,  ...,  0.0008, -0.0009,  0.0020],
        [ 0.0081, -0.0222, -0.0204,  ..., -0.0091, -0.0088, -0.0016],
        [-0.0092,  0.0164,  0.0050,  ...,  0.0049, -0.0224,  0.0080],
        ...,
        [ 0.0029, -0.0066,  0.0181,  ...,  0.0071,  0.0158, -0.0013],
        [-0.0116, -0.0083,  0.0020,  ...,  0.0097, -0.0125,  0.0014],
        [-0.0034, -0.0240,  0.0010,  ..., -0.0058,  0.0145,  0.0150]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-02 19:49:12 root INFO     h_layer_name='transformer.h.5' z_layer_name='transformer.h.27'
2024-07-02 19:49:12 root INFO     [order_1_approx] starting weight calculation for A part of a deer is a antler
A part of a academia is a college
A part of a comb is a teeth
A part of a jail is a cell
A part of a torso is a chest
A part of a byte is a bit
A part of a window is a pane
A part of a teapot is a
2024-07-02 19:49:12 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5
2024-07-02 19:53:11 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 3.3340e-03, -2.3575e-02,  7.9575e-03,  ...,  1.3184e-02,
         -1.2589e-03, -1.9684e-02],
        [-3.7750e-02,  1.5793e-02,  2.0813e-02,  ...,  4.4312e-02,
         -1.9958e-02,  4.0955e-02],
        [ 2.7542e-03, -1.3557e-02,  4.0680e-02,  ..., -7.5455e-03,
          9.2010e-03,  2.2522e-02],
        ...,
        [ 2.5345e-02,  7.8278e-03, -6.9160e-03,  ...,  7.8201e-05,
         -4.9011e-02, -8.8959e-03],
        [ 8.4229e-03,  1.1091e-03,  1.9226e-02,  ...,  3.5797e-02,
         -4.0970e-03,  1.1993e-02],
        [-6.7635e-03, -7.5798e-03, -1.3939e-02,  ..., -1.5274e-02,
          2.4155e-02,  4.3762e-02]], device='cuda:0', dtype=torch.float16) 

                    
2024-07-02 19:53:12 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A part of a deer is a antler
A part of a academia is a college
A part of a comb is a teeth
A part of a jail is a cell
A part of a torso is a chest
A part of a byte is a bit
A part of a window is a pane
A part of a teapot is a
2024-07-02 19:53:12 root INFO     h_layer_name='transformer.h.5.ln_1' z_layer_name='transformer.h.27'
2024-07-02 19:53:12 root INFO     [order_1_approx] starting weight calculation for A part of a jail is a cell
A part of a torso is a chest
A part of a academia is a college
A part of a byte is a bit
A part of a teapot is a spout
A part of a window is a pane
A part of a comb is a teeth
A part of a deer is a
2024-07-02 19:53:12 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5.ln_1
2024-07-02 19:57:19 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0039,  0.0003, -0.0106,  ..., -0.0087, -0.0108,  0.0056],
        [ 0.0039, -0.0049, -0.0115,  ..., -0.0002, -0.0125,  0.0021],
        [-0.0017,  0.0099, -0.0029,  ..., -0.0007,  0.0023,  0.0026],
        ...,
        [ 0.0057, -0.0010, -0.0178,  ..., -0.0043, -0.0004, -0.0087],
        [ 0.0036,  0.0034, -0.0094,  ..., -0.0014,  0.0076, -0.0061],
        [ 0.0027,  0.0016, -0.0159,  ...,  0.0021,  0.0065, -0.0035]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-02 19:57:20 root INFO     h_layer_name='transformer.h.5' z_layer_name='transformer.h.27'
2024-07-02 19:57:20 root INFO     [order_1_approx] starting weight calculation for A part of a jail is a cell
A part of a torso is a chest
A part of a academia is a college
A part of a byte is a bit
A part of a teapot is a spout
A part of a window is a pane
A part of a comb is a teeth
A part of a deer is a
2024-07-02 19:57:20 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5
2024-07-02 20:01:17 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0171, -0.0191,  0.0105,  ...,  0.0225,  0.0145,  0.0005],
        [-0.0145,  0.0153,  0.0091,  ...,  0.0245, -0.0058,  0.0035],
        [-0.0034,  0.0144,  0.0167,  ..., -0.0316,  0.0240,  0.0136],
        ...,
        [-0.0088, -0.0070, -0.0084,  ...,  0.0237, -0.0257,  0.0295],
        [ 0.0055, -0.0002, -0.0043,  ...,  0.0148, -0.0072,  0.0278],
        [-0.0055, -0.0060,  0.0135,  ...,  0.0074,  0.0005,  0.0206]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-02 20:01:17 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A part of a jail is a cell
A part of a torso is a chest
A part of a academia is a college
A part of a byte is a bit
A part of a teapot is a spout
A part of a window is a pane
A part of a comb is a teeth
A part of a deer is a
2024-07-02 20:01:18 root INFO     h_layer_name='transformer.h.5.ln_1' z_layer_name='transformer.h.27'
2024-07-02 20:01:18 root INFO     [order_1_approx] starting weight calculation for A part of a torso is a chest
A part of a deer is a antler
A part of a teapot is a spout
A part of a comb is a teeth
A part of a jail is a cell
A part of a window is a pane
A part of a byte is a bit
A part of a academia is a
2024-07-02 20:01:18 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5.ln_1
2024-07-02 20:05:23 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-6.2675e-03, -1.1452e-02,  6.1455e-03,  ..., -3.9825e-03,
         -5.7907e-03,  3.2349e-03],
        [-8.7051e-03,  8.0185e-03,  1.3161e-02,  ...,  5.6419e-03,
          7.0992e-03, -5.7030e-04],
        [-3.9024e-03, -2.5291e-03, -2.1210e-02,  ...,  3.5248e-03,
         -4.8065e-03, -8.5297e-03],
        ...,
        [-1.5221e-02,  1.0386e-03, -3.4904e-03,  ...,  8.1787e-03,
         -1.4181e-03, -2.4357e-03],
        [ 3.1586e-03,  1.9958e-02,  2.0638e-03,  ..., -3.3607e-03,
          6.3286e-03, -6.4697e-03],
        [-7.1716e-03,  8.4457e-03,  4.0512e-03,  ...,  5.7220e-06,
          7.5417e-03,  7.8201e-03]], device='cuda:0', dtype=torch.float16) 

                    
2024-07-02 20:05:24 root INFO     h_layer_name='transformer.h.5' z_layer_name='transformer.h.27'
2024-07-02 20:05:24 root INFO     [order_1_approx] starting weight calculation for A part of a torso is a chest
A part of a deer is a antler
A part of a teapot is a spout
A part of a comb is a teeth
A part of a jail is a cell
A part of a window is a pane
A part of a byte is a bit
A part of a academia is a
2024-07-02 20:05:24 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5
2024-07-02 20:09:16 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 0.0078,  0.0011, -0.0015,  ...,  0.0099,  0.0105, -0.0156],
        [ 0.0161,  0.0116, -0.0113,  ...,  0.0163, -0.0255, -0.0060],
        [ 0.0190, -0.0152,  0.0045,  ..., -0.0161, -0.0285, -0.0012],
        ...,
        [-0.0161, -0.0301, -0.0114,  ..., -0.0179, -0.0185,  0.0073],
        [ 0.0118, -0.0166,  0.0002,  ..., -0.0108, -0.0153, -0.0019],
        [-0.0278,  0.0092, -0.0060,  ...,  0.0016,  0.0257, -0.0063]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-02 20:09:17 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A part of a torso is a chest
A part of a deer is a antler
A part of a teapot is a spout
A part of a comb is a teeth
A part of a jail is a cell
A part of a window is a pane
A part of a byte is a bit
A part of a academia is a
2024-07-02 20:09:18 root INFO     h_layer_name='transformer.h.5.ln_1' z_layer_name='transformer.h.27'
2024-07-02 20:09:18 root INFO     [order_1_approx] starting weight calculation for A part of a academia is a college
A part of a comb is a teeth
A part of a jail is a cell
A part of a teapot is a spout
A part of a deer is a antler
A part of a window is a pane
A part of a byte is a bit
A part of a torso is a
2024-07-02 20:09:18 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5.ln_1
2024-07-02 20:13:22 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0084,  0.0122,  0.0089,  ...,  0.0168, -0.0030,  0.0137],
        [ 0.0101, -0.0038, -0.0062,  ..., -0.0036, -0.0104,  0.0098],
        [ 0.0049,  0.0110,  0.0112,  ..., -0.0122,  0.0027, -0.0077],
        ...,
        [-0.0193, -0.0119, -0.0004,  ..., -0.0170,  0.0006,  0.0119],
        [ 0.0153, -0.0110, -0.0089,  ..., -0.0115,  0.0124, -0.0007],
        [-0.0096,  0.0035,  0.0076,  ..., -0.0078, -0.0047, -0.0280]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-02 20:13:23 root INFO     h_layer_name='transformer.h.5' z_layer_name='transformer.h.27'
2024-07-02 20:13:23 root INFO     [order_1_approx] starting weight calculation for A part of a academia is a college
A part of a comb is a teeth
A part of a jail is a cell
A part of a teapot is a spout
A part of a deer is a antler
A part of a window is a pane
A part of a byte is a bit
A part of a torso is a
2024-07-02 20:13:23 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5
2024-07-02 20:17:18 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-1.1826e-03, -9.6588e-03, -5.5923e-03,  ..., -4.1695e-03,
          1.0094e-02, -3.7445e-02],
        [-3.0346e-03,  3.2692e-03,  5.5542e-03,  ..., -5.0697e-03,
         -4.9591e-04,  4.0894e-03],
        [ 2.7161e-02,  2.6093e-02,  1.5587e-02,  ...,  1.7914e-02,
         -7.0801e-03,  6.6605e-03],
        ...,
        [ 1.0918e-02,  9.4681e-03, -2.5787e-02,  ...,  1.7548e-02,
         -2.2720e-02, -6.7902e-04],
        [-1.5015e-02, -2.5543e-02, -5.0659e-03,  ...,  8.7738e-05,
          7.6294e-03,  6.8665e-03],
        [-2.6352e-02, -1.1566e-02,  5.3253e-03,  ..., -2.2217e-02,
          4.1718e-02,  3.7964e-02]], device='cuda:0', dtype=torch.float16) 

                    
2024-07-02 20:17:19 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A part of a academia is a college
A part of a comb is a teeth
A part of a jail is a cell
A part of a teapot is a spout
A part of a deer is a antler
A part of a window is a pane
A part of a byte is a bit
A part of a torso is a
2024-07-02 20:17:19 root INFO     h_layer_name='transformer.h.5.ln_1' z_layer_name='transformer.h.27'
2024-07-02 20:17:19 root INFO     [order_1_approx] starting weight calculation for A part of a academia is a college
A part of a window is a pane
A part of a torso is a chest
A part of a teapot is a spout
A part of a comb is a teeth
A part of a jail is a cell
A part of a deer is a antler
A part of a byte is a
2024-07-02 20:17:19 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5.ln_1
2024-07-02 20:21:24 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0211, -0.0018,  0.0048,  ..., -0.0031, -0.0017,  0.0003],
        [ 0.0119, -0.0102, -0.0057,  ..., -0.0021,  0.0055,  0.0036],
        [ 0.0117,  0.0076,  0.0172,  ...,  0.0048,  0.0152, -0.0094],
        ...,
        [-0.0021,  0.0116, -0.0172,  ..., -0.0197,  0.0176, -0.0044],
        [ 0.0019,  0.0053,  0.0098,  ..., -0.0095,  0.0025, -0.0203],
        [ 0.0036,  0.0020, -0.0051,  ...,  0.0098,  0.0094,  0.0069]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-02 20:21:25 root INFO     h_layer_name='transformer.h.5' z_layer_name='transformer.h.27'
2024-07-02 20:21:25 root INFO     [order_1_approx] starting weight calculation for A part of a academia is a college
A part of a window is a pane
A part of a torso is a chest
A part of a teapot is a spout
A part of a comb is a teeth
A part of a jail is a cell
A part of a deer is a antler
A part of a byte is a
2024-07-02 20:21:25 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5
2024-07-02 20:25:20 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0225,  0.0086, -0.0302,  ...,  0.0092,  0.0071, -0.0404],
        [-0.0033,  0.0043, -0.0007,  ..., -0.0130, -0.0188, -0.0155],
        [ 0.0050, -0.0201, -0.0115,  ...,  0.0294, -0.0209,  0.0459],
        ...,
        [ 0.0107, -0.0367,  0.0222,  ..., -0.0362,  0.0192, -0.0003],
        [ 0.0055, -0.0226,  0.0018,  ...,  0.0315, -0.0478,  0.0087],
        [-0.0162,  0.0015, -0.0022,  ...,  0.0209,  0.0166,  0.0013]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-02 20:25:20 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A part of a academia is a college
A part of a window is a pane
A part of a torso is a chest
A part of a teapot is a spout
A part of a comb is a teeth
A part of a jail is a cell
A part of a deer is a antler
A part of a byte is a
2024-07-02 20:25:21 root INFO     h_layer_name='transformer.h.5.ln_1' z_layer_name='transformer.h.27'
2024-07-02 20:25:21 root INFO     [order_1_approx] starting weight calculation for A part of a teapot is a spout
A part of a window is a pane
A part of a deer is a antler
A part of a byte is a bit
A part of a academia is a college
A part of a jail is a cell
A part of a torso is a chest
A part of a comb is a
2024-07-02 20:25:21 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5.ln_1
2024-07-02 20:29:26 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0282,  0.0159,  0.0043,  ..., -0.0012, -0.0056,  0.0051],
        [ 0.0199,  0.0104, -0.0234,  ..., -0.0267, -0.0043,  0.0125],
        [-0.0244,  0.0243, -0.0028,  ..., -0.0032,  0.0215,  0.0058],
        ...,
        [ 0.0161, -0.0008, -0.0016,  ...,  0.0051, -0.0116, -0.0037],
        [ 0.0119,  0.0002,  0.0214,  ...,  0.0086,  0.0027,  0.0026],
        [ 0.0158, -0.0241,  0.0280,  ..., -0.0174,  0.0019, -0.0147]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-02 20:29:27 root INFO     h_layer_name='transformer.h.5' z_layer_name='transformer.h.27'
2024-07-02 20:29:27 root INFO     [order_1_approx] starting weight calculation for A part of a teapot is a spout
A part of a window is a pane
A part of a deer is a antler
A part of a byte is a bit
A part of a academia is a college
A part of a jail is a cell
A part of a torso is a chest
A part of a comb is a
2024-07-02 20:29:27 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5
2024-07-02 20:33:21 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0263, -0.0155, -0.0005,  ..., -0.0041,  0.0217, -0.0152],
        [-0.0366,  0.0021,  0.0219,  ..., -0.0073, -0.0271,  0.0026],
        [-0.0161,  0.0029,  0.0133,  ...,  0.0043,  0.0197,  0.0175],
        ...,
        [ 0.0034, -0.0004, -0.0188,  ...,  0.0262,  0.0032, -0.0029],
        [ 0.0118, -0.0069, -0.0097,  ..., -0.0093,  0.0032,  0.0157],
        [-0.0262,  0.0464,  0.0207,  ..., -0.0037,  0.0189,  0.0083]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-02 20:33:22 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A part of a teapot is a spout
A part of a window is a pane
A part of a deer is a antler
A part of a byte is a bit
A part of a academia is a college
A part of a jail is a cell
A part of a torso is a chest
A part of a comb is a
2024-07-02 20:33:22 root INFO     h_layer_name='transformer.h.5.ln_1' z_layer_name='transformer.h.27'
2024-07-02 20:33:22 root INFO     [order_1_approx] starting weight calculation for A part of a teapot is a spout
A part of a byte is a bit
A part of a comb is a teeth
A part of a torso is a chest
A part of a jail is a cell
A part of a academia is a college
A part of a deer is a antler
A part of a window is a
2024-07-02 20:33:22 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5.ln_1
2024-07-02 20:37:25 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-6.3972e-03,  7.9117e-03,  1.1435e-03,  ..., -2.3232e-03,
         -9.9373e-04, -6.0730e-03],
        [ 8.5373e-03,  2.3918e-03, -2.4109e-03,  ..., -1.8654e-03,
          4.2152e-03, -8.1062e-06],
        [-8.8930e-04, -3.8433e-04,  1.9398e-03,  ..., -1.2245e-02,
          3.4904e-03,  6.0368e-04],
        ...,
        [ 6.8703e-03,  3.6068e-03, -9.5463e-04,  ..., -5.9357e-03,
         -5.7602e-03,  7.2632e-03],
        [-1.4973e-03, -1.4992e-02, -1.1339e-03,  ..., -9.7733e-03,
          2.5177e-03, -1.9569e-03],
        [ 5.8517e-03, -9.1400e-03,  1.5774e-03,  ...,  5.3673e-03,
         -9.6283e-03,  6.5613e-03]], device='cuda:0', dtype=torch.float16) 

                    
2024-07-02 20:37:26 root INFO     h_layer_name='transformer.h.5' z_layer_name='transformer.h.27'
2024-07-02 20:37:26 root INFO     [order_1_approx] starting weight calculation for A part of a teapot is a spout
A part of a byte is a bit
A part of a comb is a teeth
A part of a torso is a chest
A part of a jail is a cell
A part of a academia is a college
A part of a deer is a antler
A part of a window is a
2024-07-02 20:37:26 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5
2024-07-02 20:41:23 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0066, -0.0165,  0.0080,  ..., -0.0107,  0.0005, -0.0141],
        [-0.0033,  0.0040,  0.0070,  ...,  0.0133, -0.0176, -0.0047],
        [-0.0034, -0.0039,  0.0029,  ..., -0.0070, -0.0068,  0.0123],
        ...,
        [-0.0042,  0.0035, -0.0059,  ..., -0.0094, -0.0025, -0.0013],
        [ 0.0190, -0.0146,  0.0069,  ..., -0.0016,  0.0004,  0.0143],
        [-0.0125, -0.0052, -0.0062,  ..., -0.0006,  0.0211,  0.0164]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-02 20:41:24 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A part of a teapot is a spout
A part of a byte is a bit
A part of a comb is a teeth
A part of a torso is a chest
A part of a jail is a cell
A part of a academia is a college
A part of a deer is a antler
A part of a window is a
2024-07-02 20:41:24 root INFO     h_layer_name='transformer.h.5.ln_1' z_layer_name='transformer.h.27'
2024-07-02 20:41:24 root INFO     [order_1_approx] starting weight calculation for A part of a teapot is a spout
A part of a academia is a college
A part of a comb is a teeth
A part of a byte is a bit
A part of a deer is a antler
A part of a window is a pane
A part of a torso is a chest
A part of a jail is a
2024-07-02 20:41:24 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5.ln_1
2024-07-02 20:45:29 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-4.1428e-03, -1.4620e-03,  4.4785e-03,  ...,  4.0741e-03,
         -1.2100e-02, -3.6392e-03],
        [ 4.9515e-03,  4.4632e-04,  5.9967e-03,  ..., -3.8147e-05,
          3.8872e-03,  1.5926e-04],
        [ 3.1776e-03, -1.0208e-02, -5.3177e-03,  ...,  8.5163e-04,
         -1.2589e-04, -2.0275e-03],
        ...,
        [ 8.1024e-03, -9.2392e-03, -9.1553e-03,  ..., -1.0262e-02,
         -6.9351e-03,  1.1673e-02],
        [-1.7185e-03,  8.0948e-03, -7.0095e-04,  ...,  3.2845e-03,
          1.0920e-04, -7.5493e-03],
        [-4.1962e-03,  7.2021e-03,  8.3771e-03,  ..., -1.2102e-03,
          8.2092e-03, -1.7365e-02]], device='cuda:0', dtype=torch.float16) 

                    
2024-07-02 20:45:30 root INFO     h_layer_name='transformer.h.5' z_layer_name='transformer.h.27'
2024-07-02 20:45:30 root INFO     [order_1_approx] starting weight calculation for A part of a teapot is a spout
A part of a academia is a college
A part of a comb is a teeth
A part of a byte is a bit
A part of a deer is a antler
A part of a window is a pane
A part of a torso is a chest
A part of a jail is a
2024-07-02 20:45:30 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5
2024-07-02 20:49:26 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0139, -0.0149,  0.0014,  ..., -0.0007,  0.0101, -0.0002],
        [ 0.0058,  0.0149, -0.0098,  ...,  0.0009, -0.0139, -0.0136],
        [-0.0060, -0.0095,  0.0146,  ..., -0.0045,  0.0113,  0.0175],
        ...,
        [ 0.0033, -0.0117, -0.0063,  ...,  0.0061,  0.0021,  0.0053],
        [ 0.0046, -0.0018,  0.0045,  ...,  0.0199,  0.0031,  0.0210],
        [-0.0114, -0.0287,  0.0032,  ..., -0.0139,  0.0019,  0.0207]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-02 20:49:26 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A part of a teapot is a spout
A part of a academia is a college
A part of a comb is a teeth
A part of a byte is a bit
A part of a deer is a antler
A part of a window is a pane
A part of a torso is a chest
A part of a jail is a
2024-07-02 20:49:26 root INFO     total operator prediction time: 3860.626551628113 seconds
2024-07-02 20:49:26 __main__ INFO     starting test: <class 'lre.operators.JacobianIclMeanEstimator'> on name - occupation
2024-07-02 20:49:29 root INFO     building operator name - occupation
2024-07-02 20:49:29 root INFO     h_layer_name='transformer.h.5.ln_1' z_layer_name='transformer.h.27'
2024-07-02 20:49:29 root INFO     [order_1_approx] starting weight calculation for hawking was known for their work as a  physicist
edison was known for their work as a  inventor
euler was known for their work as a  mathematician
strauss was known for their work as a  composer
kepler was known for their work as a  mathematician
aristotle was known for their work as a  philosopher
goethe was known for their work as a  poet
plato was known for their work as a 
2024-07-02 20:49:29 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5.ln_1
2024-07-02 20:53:35 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 0.0019,  0.0030, -0.0025,  ...,  0.0017,  0.0051,  0.0124],
        [ 0.0102, -0.0081, -0.0040,  ..., -0.0045,  0.0021,  0.0025],
        [-0.0100, -0.0079,  0.0045,  ..., -0.0098,  0.0105, -0.0024],
        ...,
        [-0.0045,  0.0081, -0.0005,  ..., -0.0078, -0.0183, -0.0071],
        [ 0.0058,  0.0011,  0.0038,  ...,  0.0051,  0.0093,  0.0023],
        [-0.0047, -0.0081, -0.0030,  ...,  0.0037,  0.0035, -0.0114]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-02 20:53:36 root INFO     h_layer_name='transformer.h.5' z_layer_name='transformer.h.27'
2024-07-02 20:53:36 root INFO     [order_1_approx] starting weight calculation for hawking was known for their work as a  physicist
edison was known for their work as a  inventor
euler was known for their work as a  mathematician
strauss was known for their work as a  composer
kepler was known for their work as a  mathematician
aristotle was known for their work as a  philosopher
goethe was known for their work as a  poet
plato was known for their work as a 
2024-07-02 20:53:36 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5
2024-07-02 20:57:32 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0148, -0.0118, -0.0201,  ..., -0.0223,  0.0102, -0.0101],
        [-0.0083,  0.0158,  0.0184,  ...,  0.0141, -0.0099, -0.0117],
        [ 0.0211,  0.0086,  0.0036,  ...,  0.0003,  0.0262, -0.0128],
        ...,
        [ 0.0047, -0.0084, -0.0087,  ...,  0.0004, -0.0064,  0.0317],
        [ 0.0202, -0.0094, -0.0044,  ...,  0.0085, -0.0170,  0.0189],
        [-0.0149,  0.0088,  0.0191,  ..., -0.0049,  0.0187, -0.0045]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-02 20:57:33 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for hawking was known for their work as a  physicist
edison was known for their work as a  inventor
euler was known for their work as a  mathematician
strauss was known for their work as a  composer
kepler was known for their work as a  mathematician
aristotle was known for their work as a  philosopher
goethe was known for their work as a  poet
plato was known for their work as a 
2024-07-02 20:57:34 root INFO     h_layer_name='transformer.h.5.ln_1' z_layer_name='transformer.h.27'
2024-07-02 20:57:34 root INFO     [order_1_approx] starting weight calculation for plato was known for their work as a  philosopher
aristotle was known for their work as a  philosopher
edison was known for their work as a  inventor
goethe was known for their work as a  poet
hawking was known for their work as a  physicist
euler was known for their work as a  mathematician
strauss was known for their work as a  composer
kepler was known for their work as a 
2024-07-02 20:57:34 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5.ln_1
2024-07-02 21:01:42 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0080, -0.0023, -0.0018,  ..., -0.0087, -0.0106, -0.0044],
        [ 0.0032, -0.0098,  0.0073,  ...,  0.0020,  0.0165, -0.0242],
        [ 0.0216,  0.0212,  0.0004,  ...,  0.0124, -0.0263,  0.0075],
        ...,
        [-0.0115, -0.0098,  0.0100,  ...,  0.0038,  0.0092, -0.0229],
        [ 0.0080, -0.0076, -0.0092,  ..., -0.0065, -0.0129,  0.0119],
        [ 0.0181,  0.0033, -0.0024,  ...,  0.0069,  0.0123,  0.0166]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-02 21:01:43 root INFO     h_layer_name='transformer.h.5' z_layer_name='transformer.h.27'
2024-07-02 21:01:43 root INFO     [order_1_approx] starting weight calculation for plato was known for their work as a  philosopher
aristotle was known for their work as a  philosopher
edison was known for their work as a  inventor
goethe was known for their work as a  poet
hawking was known for their work as a  physicist
euler was known for their work as a  mathematician
strauss was known for their work as a  composer
kepler was known for their work as a 
2024-07-02 21:01:43 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5
2024-07-02 21:05:39 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0424, -0.0140,  0.0021,  ...,  0.0109,  0.0049,  0.0099],
        [-0.0096,  0.0311,  0.0275,  ...,  0.0308,  0.0009, -0.0405],
        [ 0.0236, -0.0092, -0.0321,  ..., -0.0086,  0.0467,  0.0264],
        ...,
        [-0.0456, -0.0034, -0.0002,  ...,  0.0485, -0.0284,  0.0087],
        [-0.0010, -0.0050,  0.0043,  ..., -0.0134, -0.0136,  0.0067],
        [ 0.0089,  0.0106, -0.0031,  ...,  0.0072,  0.0207,  0.0078]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-02 21:05:40 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for plato was known for their work as a  philosopher
aristotle was known for their work as a  philosopher
edison was known for their work as a  inventor
goethe was known for their work as a  poet
hawking was known for their work as a  physicist
euler was known for their work as a  mathematician
strauss was known for their work as a  composer
kepler was known for their work as a 
2024-07-02 21:05:40 root INFO     h_layer_name='transformer.h.5.ln_1' z_layer_name='transformer.h.27'
2024-07-02 21:05:41 root INFO     [order_1_approx] starting weight calculation for euler was known for their work as a  mathematician
hawking was known for their work as a  physicist
plato was known for their work as a  philosopher
goethe was known for their work as a  poet
aristotle was known for their work as a  philosopher
kepler was known for their work as a  mathematician
edison was known for their work as a  inventor
strauss was known for their work as a 
2024-07-02 21:05:41 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5.ln_1
2024-07-02 21:09:46 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0050, -0.0084,  0.0040,  ..., -0.0051,  0.0132,  0.0148],
        [-0.0077, -0.0170, -0.0096,  ..., -0.0033,  0.0261,  0.0030],
        [-0.0240, -0.0222,  0.0043,  ..., -0.0222,  0.0416,  0.0173],
        ...,
        [-0.0316, -0.0109,  0.0114,  ..., -0.0094,  0.0261,  0.0159],
        [ 0.0078, -0.0077,  0.0013,  ...,  0.0240, -0.0155, -0.0104],
        [ 0.0210, -0.0287,  0.0183,  ..., -0.0047,  0.0302, -0.0238]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-02 21:09:47 root INFO     h_layer_name='transformer.h.5' z_layer_name='transformer.h.27'
2024-07-02 21:09:47 root INFO     [order_1_approx] starting weight calculation for euler was known for their work as a  mathematician
hawking was known for their work as a  physicist
plato was known for their work as a  philosopher
goethe was known for their work as a  poet
aristotle was known for their work as a  philosopher
kepler was known for their work as a  mathematician
edison was known for their work as a  inventor
strauss was known for their work as a 
2024-07-02 21:09:47 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5
2024-07-02 21:13:46 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 0.0050,  0.0004,  0.0180,  ...,  0.0055,  0.0210, -0.0106],
        [-0.0430,  0.0402,  0.0070,  ...,  0.0539,  0.0495,  0.0274],
        [-0.0101,  0.0229,  0.0106,  ...,  0.0230,  0.0429, -0.0199],
        ...,
        [-0.0229, -0.0126,  0.0161,  ...,  0.0513, -0.0010,  0.0263],
        [ 0.0019, -0.0464, -0.0037,  ..., -0.0086, -0.0047,  0.0261],
        [ 0.0235,  0.0319, -0.0148,  ..., -0.0013,  0.0197,  0.0218]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-02 21:13:47 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for euler was known for their work as a  mathematician
hawking was known for their work as a  physicist
plato was known for their work as a  philosopher
goethe was known for their work as a  poet
aristotle was known for their work as a  philosopher
kepler was known for their work as a  mathematician
edison was known for their work as a  inventor
strauss was known for their work as a 
2024-07-02 21:13:47 root INFO     h_layer_name='transformer.h.5.ln_1' z_layer_name='transformer.h.27'
2024-07-02 21:13:47 root INFO     [order_1_approx] starting weight calculation for plato was known for their work as a  philosopher
hawking was known for their work as a  physicist
edison was known for their work as a  inventor
euler was known for their work as a  mathematician
kepler was known for their work as a  mathematician
goethe was known for their work as a  poet
strauss was known for their work as a  composer
aristotle was known for their work as a 
2024-07-02 21:13:47 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5.ln_1
2024-07-02 21:17:54 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0048,  0.0055,  0.0063,  ...,  0.0072,  0.0055,  0.0018],
        [ 0.0006, -0.0049, -0.0069,  ..., -0.0100, -0.0034, -0.0148],
        [ 0.0041, -0.0143,  0.0076,  ..., -0.0092,  0.0046,  0.0122],
        ...,
        [-0.0111,  0.0049, -0.0103,  ..., -0.0103, -0.0251, -0.0058],
        [ 0.0092, -0.0093, -0.0036,  ..., -0.0037, -0.0048, -0.0013],
        [ 0.0010,  0.0045,  0.0056,  ...,  0.0021,  0.0061,  0.0001]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-02 21:17:55 root INFO     h_layer_name='transformer.h.5' z_layer_name='transformer.h.27'
2024-07-02 21:17:55 root INFO     [order_1_approx] starting weight calculation for plato was known for their work as a  philosopher
hawking was known for their work as a  physicist
edison was known for their work as a  inventor
euler was known for their work as a  mathematician
kepler was known for their work as a  mathematician
goethe was known for their work as a  poet
strauss was known for their work as a  composer
aristotle was known for their work as a 
2024-07-02 21:17:55 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5
2024-07-02 21:21:50 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0246, -0.0086, -0.0101,  ..., -0.0092,  0.0156, -0.0051],
        [-0.0016,  0.0093,  0.0006,  ...,  0.0104,  0.0001,  0.0119],
        [ 0.0101, -0.0011, -0.0034,  ..., -0.0095,  0.0334, -0.0110],
        ...,
        [ 0.0106, -0.0052,  0.0174,  ...,  0.0065, -0.0359,  0.0149],
        [ 0.0009, -0.0237,  0.0029,  ...,  0.0063, -0.0066, -0.0096],
        [ 0.0076, -0.0217, -0.0080,  ..., -0.0063,  0.0228, -0.0072]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-02 21:21:51 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for plato was known for their work as a  philosopher
hawking was known for their work as a  physicist
edison was known for their work as a  inventor
euler was known for their work as a  mathematician
kepler was known for their work as a  mathematician
goethe was known for their work as a  poet
strauss was known for their work as a  composer
aristotle was known for their work as a 
2024-07-02 21:21:51 root INFO     h_layer_name='transformer.h.5.ln_1' z_layer_name='transformer.h.27'
2024-07-02 21:21:51 root INFO     [order_1_approx] starting weight calculation for strauss was known for their work as a  composer
aristotle was known for their work as a  philosopher
plato was known for their work as a  philosopher
edison was known for their work as a  inventor
goethe was known for their work as a  poet
hawking was known for their work as a  physicist
kepler was known for their work as a  mathematician
euler was known for their work as a 
2024-07-02 21:21:51 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5.ln_1
2024-07-02 21:25:59 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0104, -0.0112,  0.0108,  ..., -0.0018,  0.0117, -0.0090],
        [ 0.0170,  0.0155,  0.0103,  ...,  0.0101, -0.0184, -0.0111],
        [-0.0040,  0.0106,  0.0203,  ...,  0.0085,  0.0030,  0.0088],
        ...,
        [-0.0074, -0.0015,  0.0008,  ..., -0.0061, -0.0176, -0.0069],
        [ 0.0146,  0.0133, -0.0012,  ..., -0.0168, -0.0005,  0.0104],
        [ 0.0139,  0.0006, -0.0019,  ...,  0.0008,  0.0225,  0.0110]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-02 21:26:00 root INFO     h_layer_name='transformer.h.5' z_layer_name='transformer.h.27'
2024-07-02 21:26:00 root INFO     [order_1_approx] starting weight calculation for strauss was known for their work as a  composer
aristotle was known for their work as a  philosopher
plato was known for their work as a  philosopher
edison was known for their work as a  inventor
goethe was known for their work as a  poet
hawking was known for their work as a  physicist
kepler was known for their work as a  mathematician
euler was known for their work as a 
2024-07-02 21:26:00 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5
2024-07-02 21:29:59 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 0.0245,  0.0025, -0.0156,  ...,  0.0036,  0.0287, -0.0363],
        [ 0.0040,  0.0278, -0.0102,  ...,  0.0231,  0.0272,  0.0168],
        [ 0.0367,  0.0130, -0.0360,  ..., -0.0119,  0.0174,  0.0116],
        ...,
        [-0.0071,  0.0006, -0.0133,  ...,  0.0268, -0.0394,  0.0139],
        [-0.0241, -0.0265,  0.0081,  ..., -0.0009, -0.0297, -0.0045],
        [-0.0166,  0.0249, -0.0324,  ..., -0.0061,  0.0029, -0.0274]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-02 21:29:59 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for strauss was known for their work as a  composer
aristotle was known for their work as a  philosopher
plato was known for their work as a  philosopher
edison was known for their work as a  inventor
goethe was known for their work as a  poet
hawking was known for their work as a  physicist
kepler was known for their work as a  mathematician
euler was known for their work as a 
2024-07-02 21:30:00 root INFO     h_layer_name='transformer.h.5.ln_1' z_layer_name='transformer.h.27'
2024-07-02 21:30:00 root INFO     [order_1_approx] starting weight calculation for euler was known for their work as a  mathematician
strauss was known for their work as a  composer
kepler was known for their work as a  mathematician
plato was known for their work as a  philosopher
hawking was known for their work as a  physicist
edison was known for their work as a  inventor
aristotle was known for their work as a  philosopher
goethe was known for their work as a 
2024-07-02 21:30:00 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5.ln_1
2024-07-02 21:34:07 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 0.0089, -0.0004, -0.0039,  ..., -0.0001, -0.0123,  0.0012],
        [-0.0013,  0.0081,  0.0367,  ..., -0.0075,  0.0004, -0.0015],
        [ 0.0185, -0.0031,  0.0020,  ..., -0.0014,  0.0062, -0.0039],
        ...,
        [-0.0066, -0.0120,  0.0158,  ...,  0.0078, -0.0048, -0.0037],
        [-0.0019,  0.0057,  0.0088,  ...,  0.0194, -0.0108,  0.0059],
        [-0.0016, -0.0323, -0.0179,  ...,  0.0143,  0.0051, -0.0080]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-02 21:34:08 root INFO     h_layer_name='transformer.h.5' z_layer_name='transformer.h.27'
2024-07-02 21:34:08 root INFO     [order_1_approx] starting weight calculation for euler was known for their work as a  mathematician
strauss was known for their work as a  composer
kepler was known for their work as a  mathematician
plato was known for their work as a  philosopher
hawking was known for their work as a  physicist
edison was known for their work as a  inventor
aristotle was known for their work as a  philosopher
goethe was known for their work as a 
2024-07-02 21:34:08 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5
2024-07-02 21:38:05 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 1.5083e-02, -2.0477e-02, -2.1912e-02,  ..., -5.4359e-03,
          8.3160e-03, -3.5767e-02],
        [ 2.0004e-02,  1.8372e-02,  1.5259e-05,  ...,  4.0710e-02,
         -1.5656e-02, -2.5116e-02],
        [ 2.1072e-02, -6.9885e-03, -5.8975e-03,  ...,  1.3588e-02,
         -1.1902e-02, -2.7733e-03],
        ...,
        [ 1.0345e-02, -1.3092e-02, -2.3117e-02,  ...,  1.0048e-02,
          8.4076e-03,  5.4016e-03],
        [-7.9117e-03, -3.4332e-02, -2.7145e-02,  ..., -3.3016e-03,
         -3.4851e-02,  2.2125e-03],
        [-1.5289e-02, -3.9215e-03, -1.0277e-02,  ..., -8.0185e-03,
          9.4070e-03,  1.8478e-02]], device='cuda:0', dtype=torch.float16) 

                    
2024-07-02 21:38:06 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for euler was known for their work as a  mathematician
strauss was known for their work as a  composer
kepler was known for their work as a  mathematician
plato was known for their work as a  philosopher
hawking was known for their work as a  physicist
edison was known for their work as a  inventor
aristotle was known for their work as a  philosopher
goethe was known for their work as a 
2024-07-02 21:38:06 root INFO     h_layer_name='transformer.h.5.ln_1' z_layer_name='transformer.h.27'
2024-07-02 21:38:06 root INFO     [order_1_approx] starting weight calculation for kepler was known for their work as a  mathematician
strauss was known for their work as a  composer
euler was known for their work as a  mathematician
aristotle was known for their work as a  philosopher
goethe was known for their work as a  poet
hawking was known for their work as a  physicist
plato was known for their work as a  philosopher
edison was known for their work as a 
2024-07-02 21:38:06 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5.ln_1
2024-07-02 21:42:13 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 0.0051,  0.0059, -0.0249,  ...,  0.0029, -0.0164,  0.0073],
        [ 0.0130,  0.0237,  0.0113,  ..., -0.0262, -0.0023,  0.0192],
        [ 0.0094,  0.0410, -0.0016,  ..., -0.0087, -0.0269, -0.0125],
        ...,
        [ 0.0078, -0.0153,  0.0041,  ..., -0.0104,  0.0024, -0.0004],
        [ 0.0099, -0.0066,  0.0081,  ...,  0.0264, -0.0081, -0.0176],
        [ 0.0060, -0.0042, -0.0014,  ...,  0.0040, -0.0169, -0.0216]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-02 21:42:14 root INFO     h_layer_name='transformer.h.5' z_layer_name='transformer.h.27'
2024-07-02 21:42:14 root INFO     [order_1_approx] starting weight calculation for kepler was known for their work as a  mathematician
strauss was known for their work as a  composer
euler was known for their work as a  mathematician
aristotle was known for their work as a  philosopher
goethe was known for their work as a  poet
hawking was known for their work as a  physicist
plato was known for their work as a  philosopher
edison was known for their work as a 
2024-07-02 21:42:14 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5
2024-07-02 21:46:12 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 0.0309, -0.0197,  0.0139,  ..., -0.0206,  0.0014, -0.0181],
        [-0.0008,  0.0000, -0.0082,  ...,  0.0229, -0.0057,  0.0051],
        [ 0.0100,  0.0133,  0.0036,  ..., -0.0113,  0.0251, -0.0203],
        ...,
        [-0.0145,  0.0239, -0.0095,  ...,  0.0274, -0.0616,  0.0449],
        [-0.0068, -0.0243, -0.0174,  ..., -0.0142,  0.0139,  0.0284],
        [-0.0255,  0.0417, -0.0043,  ..., -0.0084,  0.0299,  0.0200]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-02 21:46:13 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for kepler was known for their work as a  mathematician
strauss was known for their work as a  composer
euler was known for their work as a  mathematician
aristotle was known for their work as a  philosopher
goethe was known for their work as a  poet
hawking was known for their work as a  physicist
plato was known for their work as a  philosopher
edison was known for their work as a 
2024-07-02 21:46:13 root INFO     h_layer_name='transformer.h.5.ln_1' z_layer_name='transformer.h.27'
2024-07-02 21:46:13 root INFO     [order_1_approx] starting weight calculation for plato was known for their work as a  philosopher
kepler was known for their work as a  mathematician
euler was known for their work as a  mathematician
edison was known for their work as a  inventor
goethe was known for their work as a  poet
aristotle was known for their work as a  philosopher
strauss was known for their work as a  composer
hawking was known for their work as a 
2024-07-02 21:46:14 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5.ln_1
2024-07-02 21:50:20 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0010, -0.0192, -0.0061,  ..., -0.0108,  0.0001, -0.0200],
        [-0.0016,  0.0223,  0.0012,  ...,  0.0242, -0.0179,  0.0134],
        [ 0.0243, -0.0700, -0.0190,  ..., -0.0154, -0.0478,  0.0822],
        ...,
        [-0.0182, -0.0070, -0.0106,  ..., -0.0384, -0.0403,  0.0064],
        [ 0.0087, -0.0157,  0.0119,  ...,  0.0068, -0.0110, -0.0021],
        [ 0.0071, -0.0071, -0.0436,  ..., -0.0093, -0.0247, -0.0100]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-02 21:50:21 root INFO     h_layer_name='transformer.h.5' z_layer_name='transformer.h.27'
2024-07-02 21:50:21 root INFO     [order_1_approx] starting weight calculation for plato was known for their work as a  philosopher
kepler was known for their work as a  mathematician
euler was known for their work as a  mathematician
edison was known for their work as a  inventor
goethe was known for their work as a  poet
aristotle was known for their work as a  philosopher
strauss was known for their work as a  composer
hawking was known for their work as a 
2024-07-02 21:50:21 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5
2024-07-02 21:54:18 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 0.0072,  0.0099,  0.0064,  ..., -0.0419, -0.0186, -0.0644],
        [-0.0135,  0.0732,  0.0234,  ...,  0.0602,  0.0120,  0.0119],
        [ 0.1215,  0.0117,  0.0202,  ...,  0.0620, -0.0969, -0.0170],
        ...,
        [-0.0405,  0.0219,  0.0025,  ...,  0.0408, -0.0428,  0.0277],
        [ 0.0202, -0.0451, -0.0129,  ...,  0.0402,  0.0371,  0.0447],
        [ 0.0131,  0.0191,  0.0013,  ..., -0.0117,  0.0974,  0.0183]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-02 21:54:19 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for plato was known for their work as a  philosopher
kepler was known for their work as a  mathematician
euler was known for their work as a  mathematician
edison was known for their work as a  inventor
goethe was known for their work as a  poet
aristotle was known for their work as a  philosopher
strauss was known for their work as a  composer
hawking was known for their work as a 
2024-07-02 21:54:19 root INFO     total operator prediction time: 3890.0566079616547 seconds
2024-07-02 21:54:19 __main__ INFO     starting test: <class 'lre.operators.JacobianIclMeanEstimator'> on noun - plural_reg
2024-07-02 21:54:21 root INFO     building operator noun - plural_reg
2024-07-02 21:54:21 root INFO     h_layer_name='transformer.h.5.ln_1' z_layer_name='transformer.h.27'
2024-07-02 21:54:21 root INFO     [order_1_approx] starting weight calculation for The plural form of friend is friends
The plural form of resource is resources
The plural form of town is towns
The plural form of product is products
The plural form of fact is facts
The plural form of period is periods
The plural form of example is examples
The plural form of death is
2024-07-02 21:54:21 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5.ln_1
2024-07-02 21:58:26 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 0.0135,  0.0057, -0.0113,  ..., -0.0099, -0.0076,  0.0044],
        [ 0.0152,  0.0091,  0.0014,  ..., -0.0041,  0.0009, -0.0209],
        [-0.0042,  0.0010,  0.0034,  ..., -0.0052,  0.0170,  0.0030],
        ...,
        [-0.0056,  0.0015, -0.0003,  ..., -0.0070,  0.0006,  0.0071],
        [ 0.0025,  0.0077, -0.0189,  ...,  0.0025,  0.0143,  0.0008],
        [-0.0096, -0.0095,  0.0121,  ...,  0.0032,  0.0185,  0.0037]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-02 21:58:27 root INFO     h_layer_name='transformer.h.5' z_layer_name='transformer.h.27'
2024-07-02 21:58:27 root INFO     [order_1_approx] starting weight calculation for The plural form of friend is friends
The plural form of resource is resources
The plural form of town is towns
The plural form of product is products
The plural form of fact is facts
The plural form of period is periods
The plural form of example is examples
The plural form of death is
2024-07-02 21:58:27 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5
2024-07-02 22:02:20 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0381,  0.0029,  0.0186,  ...,  0.0053, -0.0160, -0.0179],
        [-0.0189, -0.0267, -0.0113,  ..., -0.0055,  0.0273,  0.0214],
        [ 0.0107,  0.0122, -0.0509,  ...,  0.0164, -0.0121, -0.0077],
        ...,
        [-0.0197, -0.0204,  0.0078,  ..., -0.0183, -0.0012,  0.0104],
        [-0.0079, -0.0022,  0.0251,  ..., -0.0072, -0.0486,  0.0247],
        [-0.0058,  0.0354,  0.0038,  ..., -0.0181,  0.0230, -0.0643]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-02 22:02:21 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of friend is friends
The plural form of resource is resources
The plural form of town is towns
The plural form of product is products
The plural form of fact is facts
The plural form of period is periods
The plural form of example is examples
The plural form of death is
2024-07-02 22:02:21 root INFO     h_layer_name='transformer.h.5.ln_1' z_layer_name='transformer.h.27'
2024-07-02 22:02:21 root INFO     [order_1_approx] starting weight calculation for The plural form of fact is facts
The plural form of resource is resources
The plural form of death is deaths
The plural form of town is towns
The plural form of example is examples
The plural form of friend is friends
The plural form of product is products
The plural form of period is
2024-07-02 22:02:21 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5.ln_1
2024-07-02 22:06:26 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 5.8289e-03, -1.0773e-02, -5.4245e-03,  ...,  1.1314e-02,
          2.7523e-03, -5.5084e-03],
        [-3.1281e-03, -6.1073e-03, -1.6785e-02,  ...,  8.3923e-05,
          3.8147e-03,  5.8289e-03],
        [ 1.3832e-02,  1.0185e-03, -1.3380e-03,  ...,  8.1406e-03,
          3.7155e-03, -2.9030e-03],
        ...,
        [-9.0218e-04, -3.0184e-04, -2.4124e-02,  ...,  1.5869e-03,
          1.2865e-03,  5.0888e-03],
        [ 1.5289e-02, -3.1204e-03, -2.6672e-02,  ...,  5.0354e-04,
          5.0011e-03, -2.2522e-02],
        [-6.4583e-03, -1.2978e-02, -4.4250e-03,  ..., -2.1683e-02,
          1.4343e-03,  3.0403e-03]], device='cuda:0', dtype=torch.float16) 

                    
2024-07-02 22:06:26 root INFO     h_layer_name='transformer.h.5' z_layer_name='transformer.h.27'
2024-07-02 22:06:27 root INFO     [order_1_approx] starting weight calculation for The plural form of fact is facts
The plural form of resource is resources
The plural form of death is deaths
The plural form of town is towns
The plural form of example is examples
The plural form of friend is friends
The plural form of product is products
The plural form of period is
2024-07-02 22:06:27 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5
2024-07-02 22:10:21 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-1.8311e-02, -2.9541e-02,  5.4871e-02,  ...,  1.1993e-02,
         -6.1035e-05, -2.3529e-02],
        [-1.5480e-02, -1.0193e-02, -1.7014e-02,  ...,  6.6757e-03,
          8.7585e-03,  6.9733e-03],
        [-1.6876e-02, -2.2163e-03, -3.5156e-02,  ..., -3.1311e-02,
          1.5350e-02,  1.5244e-02],
        ...,
        [ 2.3743e-02, -4.9591e-03,  2.2308e-02,  ..., -1.0452e-02,
          3.2043e-03,  2.6703e-03],
        [ 8.7166e-04, -1.7578e-02,  1.2367e-02,  ...,  2.7176e-02,
         -4.1382e-02,  2.7100e-02],
        [-2.3438e-02,  1.5373e-02,  1.0651e-02,  ..., -7.9575e-03,
          5.0629e-02, -3.8544e-02]], device='cuda:0', dtype=torch.float16) 

                    
2024-07-02 22:10:21 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of fact is facts
The plural form of resource is resources
The plural form of death is deaths
The plural form of town is towns
The plural form of example is examples
The plural form of friend is friends
The plural form of product is products
The plural form of period is
2024-07-02 22:10:22 root INFO     h_layer_name='transformer.h.5.ln_1' z_layer_name='transformer.h.27'
2024-07-02 22:10:22 root INFO     [order_1_approx] starting weight calculation for The plural form of product is products
The plural form of town is towns
The plural form of friend is friends
The plural form of fact is facts
The plural form of death is deaths
The plural form of example is examples
The plural form of period is periods
The plural form of resource is
2024-07-02 22:10:22 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5.ln_1
2024-07-02 22:14:23 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0047, -0.0004, -0.0099,  ...,  0.0068,  0.0136, -0.0011],
        [ 0.0011, -0.0026, -0.0051,  ..., -0.0067,  0.0043,  0.0005],
        [ 0.0065,  0.0101, -0.0072,  ..., -0.0034,  0.0071, -0.0108],
        ...,
        [-0.0037,  0.0070,  0.0017,  ...,  0.0055, -0.0040,  0.0098],
        [ 0.0004,  0.0122, -0.0066,  ..., -0.0041,  0.0024, -0.0023],
        [-0.0010,  0.0138,  0.0050,  ..., -0.0119,  0.0018,  0.0052]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-02 22:14:24 root INFO     h_layer_name='transformer.h.5' z_layer_name='transformer.h.27'
2024-07-02 22:14:24 root INFO     [order_1_approx] starting weight calculation for The plural form of product is products
The plural form of town is towns
The plural form of friend is friends
The plural form of fact is facts
The plural form of death is deaths
The plural form of example is examples
The plural form of period is periods
The plural form of resource is
2024-07-02 22:14:24 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5
2024-07-02 22:18:18 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-3.5095e-02, -3.1204e-02,  2.5223e-02,  ..., -1.0529e-02,
         -3.4485e-02, -4.0283e-02],
        [ 5.8479e-03,  9.9030e-03, -4.1962e-04,  ...,  6.4659e-03,
          6.2637e-03,  1.0738e-03],
        [-1.1581e-02, -8.1177e-03, -3.4698e-02,  ..., -1.9608e-03,
          1.3275e-02, -1.1482e-03],
        ...,
        [-7.9346e-03, -2.9083e-02, -1.3405e-02,  ..., -2.8717e-02,
          5.0774e-03, -1.0132e-02],
        [-2.0996e-02, -1.5656e-02,  3.0228e-02,  ..., -6.1264e-03,
         -4.2358e-02, -4.5776e-05],
        [-7.6981e-03,  1.4458e-02, -2.0599e-03,  ..., -1.3458e-02,
          1.5976e-02, -1.7227e-02]], device='cuda:0', dtype=torch.float16) 

                    
2024-07-02 22:18:19 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of product is products
The plural form of town is towns
The plural form of friend is friends
The plural form of fact is facts
The plural form of death is deaths
The plural form of example is examples
The plural form of period is periods
The plural form of resource is
2024-07-02 22:18:19 root INFO     h_layer_name='transformer.h.5.ln_1' z_layer_name='transformer.h.27'
2024-07-02 22:18:19 root INFO     [order_1_approx] starting weight calculation for The plural form of friend is friends
The plural form of town is towns
The plural form of death is deaths
The plural form of period is periods
The plural form of fact is facts
The plural form of product is products
The plural form of resource is resources
The plural form of example is
2024-07-02 22:18:19 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5.ln_1
2024-07-02 22:22:24 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0037, -0.0003,  0.0066,  ...,  0.0046, -0.0005,  0.0022],
        [-0.0011,  0.0072, -0.0007,  ..., -0.0010, -0.0076, -0.0130],
        [-0.0027,  0.0047, -0.0039,  ...,  0.0075,  0.0040, -0.0044],
        ...,
        [ 0.0033,  0.0015, -0.0121,  ..., -0.0084,  0.0009, -0.0018],
        [ 0.0135, -0.0045, -0.0114,  ..., -0.0024,  0.0090,  0.0091],
        [-0.0010, -0.0145,  0.0095,  ..., -0.0036,  0.0120, -0.0045]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-02 22:22:25 root INFO     h_layer_name='transformer.h.5' z_layer_name='transformer.h.27'
2024-07-02 22:22:25 root INFO     [order_1_approx] starting weight calculation for The plural form of friend is friends
The plural form of town is towns
The plural form of death is deaths
The plural form of period is periods
The plural form of fact is facts
The plural form of product is products
The plural form of resource is resources
The plural form of example is
2024-07-02 22:22:25 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5
2024-07-02 22:26:20 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0186, -0.0290,  0.0258,  ..., -0.0127, -0.0133, -0.0394],
        [-0.0087, -0.0085,  0.0102,  ..., -0.0085, -0.0017,  0.0215],
        [ 0.0059, -0.0157, -0.0419,  ...,  0.0085,  0.0015,  0.0051],
        ...,
        [-0.0011, -0.0228,  0.0065,  ..., -0.0370,  0.0239, -0.0440],
        [ 0.0060,  0.0032, -0.0043,  ..., -0.0241, -0.0458,  0.0115],
        [ 0.0029,  0.0378, -0.0053,  ..., -0.0073,  0.0031, -0.0045]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-02 22:26:20 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of friend is friends
The plural form of town is towns
The plural form of death is deaths
The plural form of period is periods
The plural form of fact is facts
The plural form of product is products
The plural form of resource is resources
The plural form of example is
2024-07-02 22:26:21 root INFO     h_layer_name='transformer.h.5.ln_1' z_layer_name='transformer.h.27'
2024-07-02 22:26:21 root INFO     [order_1_approx] starting weight calculation for The plural form of period is periods
The plural form of death is deaths
The plural form of town is towns
The plural form of example is examples
The plural form of resource is resources
The plural form of product is products
The plural form of friend is friends
The plural form of fact is
2024-07-02 22:26:21 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5.ln_1
2024-07-02 22:30:26 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 0.0195, -0.0035,  0.0034,  ..., -0.0113, -0.0004,  0.0149],
        [ 0.0073,  0.0041, -0.0070,  ..., -0.0036, -0.0038, -0.0089],
        [ 0.0015,  0.0115, -0.0080,  ..., -0.0062, -0.0050, -0.0024],
        ...,
        [-0.0059,  0.0040,  0.0043,  ...,  0.0029, -0.0088, -0.0004],
        [ 0.0073,  0.0032, -0.0215,  ..., -0.0062, -0.0076,  0.0011],
        [-0.0199, -0.0001,  0.0120,  ...,  0.0009,  0.0080, -0.0094]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-02 22:30:27 root INFO     h_layer_name='transformer.h.5' z_layer_name='transformer.h.27'
2024-07-02 22:30:27 root INFO     [order_1_approx] starting weight calculation for The plural form of period is periods
The plural form of death is deaths
The plural form of town is towns
The plural form of example is examples
The plural form of resource is resources
The plural form of product is products
The plural form of friend is friends
The plural form of fact is
2024-07-02 22:30:27 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5
2024-07-02 22:34:22 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0451, -0.0299,  0.0200,  ...,  0.0038, -0.0113, -0.0386],
        [-0.0186, -0.0142,  0.0063,  ..., -0.0139,  0.0175, -0.0014],
        [-0.0011, -0.0032, -0.0452,  ...,  0.0108, -0.0034,  0.0192],
        ...,
        [-0.0240, -0.0083, -0.0006,  ..., -0.0294,  0.0068, -0.0014],
        [ 0.0178, -0.0107,  0.0088,  ..., -0.0022, -0.0389,  0.0059],
        [ 0.0015,  0.0381,  0.0132,  ...,  0.0047, -0.0053, -0.0201]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-02 22:34:23 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of period is periods
The plural form of death is deaths
The plural form of town is towns
The plural form of example is examples
The plural form of resource is resources
The plural form of product is products
The plural form of friend is friends
The plural form of fact is
2024-07-02 22:34:23 root INFO     h_layer_name='transformer.h.5.ln_1' z_layer_name='transformer.h.27'
2024-07-02 22:34:23 root INFO     [order_1_approx] starting weight calculation for The plural form of fact is facts
The plural form of period is periods
The plural form of product is products
The plural form of resource is resources
The plural form of example is examples
The plural form of death is deaths
The plural form of friend is friends
The plural form of town is
2024-07-02 22:34:23 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5.ln_1
2024-07-02 22:38:26 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 5.3253e-03, -3.8338e-03,  1.9360e-03,  ..., -1.1566e-02,
          1.4782e-05,  3.2330e-03],
        [ 6.7472e-04,  4.6611e-04,  9.0933e-04,  ..., -4.2038e-03,
         -1.6651e-03, -5.9967e-03],
        [ 1.5965e-03,  1.4641e-02,  1.2451e-02,  ...,  1.2608e-03,
          5.7335e-03, -1.0040e-02],
        ...,
        [-1.5564e-03,  5.9776e-03,  8.3466e-03,  ..., -1.3790e-03,
         -6.2218e-03,  7.3738e-03],
        [ 1.0353e-02, -7.8583e-03, -3.3661e-02,  ...,  2.5082e-03,
         -5.3253e-03,  1.1612e-02],
        [-1.6956e-03, -3.4351e-03,  6.0272e-03,  ...,  4.4327e-03,
          1.7502e-02, -2.6657e-02]], device='cuda:0', dtype=torch.float16) 

                    
2024-07-02 22:38:27 root INFO     h_layer_name='transformer.h.5' z_layer_name='transformer.h.27'
2024-07-02 22:38:27 root INFO     [order_1_approx] starting weight calculation for The plural form of fact is facts
The plural form of period is periods
The plural form of product is products
The plural form of resource is resources
The plural form of example is examples
The plural form of death is deaths
The plural form of friend is friends
The plural form of town is
2024-07-02 22:38:27 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5
2024-07-02 22:42:23 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0441, -0.0267,  0.0172,  ...,  0.0145, -0.0220, -0.0230],
        [-0.0089, -0.0282, -0.0077,  ...,  0.0130,  0.0075,  0.0103],
        [-0.0091,  0.0011, -0.0448,  ..., -0.0016,  0.0226,  0.0197],
        ...,
        [-0.0190, -0.0224, -0.0152,  ..., -0.0376,  0.0209,  0.0171],
        [-0.0095, -0.0230,  0.0056,  ..., -0.0182, -0.0711,  0.0107],
        [-0.0438, -0.0018,  0.0078,  ..., -0.0146,  0.0169, -0.0475]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-02 22:42:24 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of fact is facts
The plural form of period is periods
The plural form of product is products
The plural form of resource is resources
The plural form of example is examples
The plural form of death is deaths
The plural form of friend is friends
The plural form of town is
2024-07-02 22:42:24 root INFO     h_layer_name='transformer.h.5.ln_1' z_layer_name='transformer.h.27'
2024-07-02 22:42:24 root INFO     [order_1_approx] starting weight calculation for The plural form of death is deaths
The plural form of fact is facts
The plural form of period is periods
The plural form of friend is friends
The plural form of resource is resources
The plural form of town is towns
The plural form of example is examples
The plural form of product is
2024-07-02 22:42:24 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5.ln_1
2024-07-02 22:46:25 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0054,  0.0002,  0.0072,  ...,  0.0113,  0.0083,  0.0047],
        [ 0.0023,  0.0131, -0.0038,  ...,  0.0061, -0.0054, -0.0044],
        [-0.0059, -0.0083, -0.0022,  ...,  0.0003, -0.0068, -0.0045],
        ...,
        [-0.0086,  0.0067,  0.0011,  ...,  0.0141, -0.0057,  0.0003],
        [ 0.0081,  0.0182, -0.0084,  ..., -0.0120,  0.0019, -0.0091],
        [-0.0001, -0.0151,  0.0006,  ..., -0.0158,  0.0124,  0.0058]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-02 22:46:26 root INFO     h_layer_name='transformer.h.5' z_layer_name='transformer.h.27'
2024-07-02 22:46:26 root INFO     [order_1_approx] starting weight calculation for The plural form of death is deaths
The plural form of fact is facts
The plural form of period is periods
The plural form of friend is friends
The plural form of resource is resources
The plural form of town is towns
The plural form of example is examples
The plural form of product is
2024-07-02 22:46:26 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5
2024-07-02 22:50:20 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0376, -0.0139,  0.0324,  ..., -0.0102, -0.0202, -0.0270],
        [-0.0037, -0.0095,  0.0039,  ...,  0.0181,  0.0025, -0.0027],
        [ 0.0181,  0.0128, -0.0319,  ..., -0.0103,  0.0208, -0.0005],
        ...,
        [ 0.0106, -0.0291, -0.0012,  ..., -0.0443,  0.0145, -0.0115],
        [-0.0151, -0.0057,  0.0097,  ...,  0.0082, -0.0306,  0.0010],
        [-0.0327,  0.0098,  0.0029,  ..., -0.0158,  0.0025, -0.0327]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-02 22:50:21 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of death is deaths
The plural form of fact is facts
The plural form of period is periods
The plural form of friend is friends
The plural form of resource is resources
The plural form of town is towns
The plural form of example is examples
The plural form of product is
2024-07-02 22:50:21 root INFO     h_layer_name='transformer.h.5.ln_1' z_layer_name='transformer.h.27'
2024-07-02 22:50:21 root INFO     [order_1_approx] starting weight calculation for The plural form of fact is facts
The plural form of period is periods
The plural form of example is examples
The plural form of death is deaths
The plural form of town is towns
The plural form of resource is resources
The plural form of product is products
The plural form of friend is
2024-07-02 22:50:21 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5.ln_1
2024-07-02 22:54:24 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 0.0075, -0.0080,  0.0033,  ...,  0.0049,  0.0069, -0.0122],
        [-0.0014,  0.0009, -0.0047,  ..., -0.0009,  0.0048,  0.0040],
        [ 0.0047,  0.0117,  0.0060,  ..., -0.0006, -0.0019,  0.0067],
        ...,
        [ 0.0017, -0.0021,  0.0018,  ...,  0.0073,  0.0026, -0.0043],
        [ 0.0044,  0.0071, -0.0185,  ..., -0.0090, -0.0003, -0.0133],
        [ 0.0129,  0.0015, -0.0159,  ..., -0.0131,  0.0170,  0.0027]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-02 22:54:25 root INFO     h_layer_name='transformer.h.5' z_layer_name='transformer.h.27'
2024-07-02 22:54:25 root INFO     [order_1_approx] starting weight calculation for The plural form of fact is facts
The plural form of period is periods
The plural form of example is examples
The plural form of death is deaths
The plural form of town is towns
The plural form of resource is resources
The plural form of product is products
The plural form of friend is
2024-07-02 22:54:25 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5
2024-07-02 22:58:19 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-2.3453e-02, -1.2772e-02,  1.7822e-02,  ...,  9.7961e-03,
          1.2589e-04, -1.1414e-02],
        [ 1.6907e-02, -1.7639e-02,  3.0117e-03,  ...,  7.6637e-03,
          9.2392e-03,  2.1362e-02],
        [-1.8951e-02, -5.6877e-03, -4.3732e-02,  ..., -1.9455e-03,
         -1.5926e-03,  7.2937e-03],
        ...,
        [-1.6876e-02, -7.3471e-03,  9.8648e-03,  ..., -3.1921e-02,
          7.3776e-03, -4.8790e-03],
        [-1.5472e-02, -1.6830e-02,  1.1108e-02,  ..., -1.3481e-02,
         -2.3834e-02,  6.1035e-05],
        [-3.0579e-02,  1.9646e-03, -1.8860e-02,  ..., -2.2736e-02,
          6.3248e-03, -3.2928e-02]], device='cuda:0', dtype=torch.float16) 

                    
2024-07-02 22:58:20 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of fact is facts
The plural form of period is periods
The plural form of example is examples
The plural form of death is deaths
The plural form of town is towns
The plural form of resource is resources
The plural form of product is products
The plural form of friend is
2024-07-02 22:58:20 root INFO     total operator prediction time: 3839.144371509552 seconds
2024-07-02 22:58:20 __main__ INFO     starting test: <class 'lre.operators.JacobianIclMeanEstimator'> on noun - plural_irreg
2024-07-02 22:58:22 root INFO     building operator noun - plural_irreg
2024-07-02 22:58:22 root INFO     h_layer_name='transformer.h.5.ln_1' z_layer_name='transformer.h.27'
2024-07-02 22:58:22 root INFO     [order_1_approx] starting weight calculation for The plural form of memory is memories
The plural form of theory is theories
The plural form of ability is abilities
The plural form of activity is activities
The plural form of family is families
The plural form of history is histories
The plural form of country is countries
The plural form of library is
2024-07-02 22:58:22 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5.ln_1
2024-07-02 23:02:25 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 1.6907e-02,  5.6219e-04, -1.0895e-02,  ..., -2.8286e-03,
          6.9923e-03,  3.3607e-03],
        [ 1.0824e-03,  1.1578e-03, -1.6212e-04,  ...,  1.3832e-02,
          6.3992e-04, -3.9387e-04],
        [-1.0271e-03, -1.4286e-03, -5.4836e-05,  ...,  1.2253e-02,
          8.6975e-04, -9.8648e-03],
        ...,
        [ 1.4954e-02,  7.4539e-03, -1.7685e-02,  ..., -2.3422e-03,
         -1.0843e-03, -6.4430e-03],
        [ 2.6073e-03, -4.7684e-04,  4.6706e-04,  ..., -6.8169e-03,
          2.2469e-03, -2.2564e-03],
        [ 5.0735e-03,  5.7678e-03, -5.6381e-03,  ..., -2.3766e-03,
          1.3641e-02,  2.0256e-03]], device='cuda:0', dtype=torch.float16) 

                    
2024-07-02 23:02:26 root INFO     h_layer_name='transformer.h.5' z_layer_name='transformer.h.27'
2024-07-02 23:02:26 root INFO     [order_1_approx] starting weight calculation for The plural form of memory is memories
The plural form of theory is theories
The plural form of ability is abilities
The plural form of activity is activities
The plural form of family is families
The plural form of history is histories
The plural form of country is countries
The plural form of library is
2024-07-02 23:02:26 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5
2024-07-02 23:06:21 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0256, -0.0311,  0.0210,  ..., -0.0187, -0.0061, -0.0281],
        [ 0.0133, -0.0195,  0.0154,  ..., -0.0002, -0.0050,  0.0069],
        [ 0.0193,  0.0112, -0.0149,  ...,  0.0157,  0.0128,  0.0105],
        ...,
        [-0.0286, -0.0243,  0.0169,  ..., -0.0172,  0.0261,  0.0018],
        [-0.0033, -0.0117,  0.0028,  ...,  0.0018, -0.0288,  0.0021],
        [-0.0167, -0.0119,  0.0077,  ..., -0.0277, -0.0082, -0.0319]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-02 23:06:22 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of memory is memories
The plural form of theory is theories
The plural form of ability is abilities
The plural form of activity is activities
The plural form of family is families
The plural form of history is histories
The plural form of country is countries
The plural form of library is
2024-07-02 23:06:22 root INFO     h_layer_name='transformer.h.5.ln_1' z_layer_name='transformer.h.27'
2024-07-02 23:06:22 root INFO     [order_1_approx] starting weight calculation for The plural form of library is libraries
The plural form of family is families
The plural form of activity is activities
The plural form of ability is abilities
The plural form of memory is memories
The plural form of theory is theories
The plural form of country is countries
The plural form of history is
2024-07-02 23:06:22 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5.ln_1
2024-07-02 23:10:24 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 1.3290e-02, -3.9768e-04,  2.6379e-03,  ..., -7.7400e-03,
         -4.2686e-03,  1.2161e-02],
        [-2.9659e-03,  6.3515e-03,  7.4463e-03,  ..., -1.0818e-02,
          2.4338e-03,  2.3632e-03],
        [ 1.0567e-02,  7.7057e-03, -5.9662e-03,  ...,  1.2131e-03,
          1.4038e-02, -1.7471e-02],
        ...,
        [ 1.3527e-02, -5.6152e-03, -4.0131e-03,  ..., -9.6054e-03,
         -7.6294e-06, -7.4234e-03],
        [ 1.4305e-04,  1.0597e-02, -2.6154e-02,  ..., -7.8812e-03,
          2.3499e-03, -6.5804e-04],
        [ 1.3237e-03, -1.2566e-02,  2.6970e-03,  ..., -3.8567e-03,
         -6.6948e-04, -9.3536e-03]], device='cuda:0', dtype=torch.float16) 

                    
2024-07-02 23:10:25 root INFO     h_layer_name='transformer.h.5' z_layer_name='transformer.h.27'
2024-07-02 23:10:25 root INFO     [order_1_approx] starting weight calculation for The plural form of library is libraries
The plural form of family is families
The plural form of activity is activities
The plural form of ability is abilities
The plural form of memory is memories
The plural form of theory is theories
The plural form of country is countries
The plural form of history is
2024-07-02 23:10:25 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5
2024-07-02 23:14:19 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-3.1433e-02, -1.3206e-02,  2.1454e-02,  ...,  1.0620e-02,
          8.5678e-03, -1.8799e-02],
        [-7.1716e-04, -2.3682e-02, -7.5188e-03,  ...,  1.8072e-03,
          8.6670e-03,  8.1778e-05],
        [-7.3471e-03, -1.1993e-02, -1.5457e-02,  ..., -6.5994e-03,
          1.3641e-02,  2.0050e-02],
        ...,
        [ 3.4008e-03, -1.8463e-02,  1.3557e-02,  ..., -2.4963e-02,
          4.6082e-02, -3.6697e-03],
        [-1.1391e-02, -1.9821e-02, -1.3390e-02,  ..., -2.6207e-03,
         -6.1890e-02,  2.3041e-03],
        [ 1.7319e-03,  1.0727e-02,  1.5114e-02,  ..., -1.9791e-02,
          1.7761e-02, -2.2415e-02]], device='cuda:0', dtype=torch.float16) 

                    
2024-07-02 23:14:20 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of library is libraries
The plural form of family is families
The plural form of activity is activities
The plural form of ability is abilities
The plural form of memory is memories
The plural form of theory is theories
The plural form of country is countries
The plural form of history is
2024-07-02 23:14:20 root INFO     h_layer_name='transformer.h.5.ln_1' z_layer_name='transformer.h.27'
2024-07-02 23:14:21 root INFO     [order_1_approx] starting weight calculation for The plural form of theory is theories
The plural form of memory is memories
The plural form of country is countries
The plural form of history is histories
The plural form of ability is abilities
The plural form of library is libraries
The plural form of activity is activities
The plural form of family is
2024-07-02 23:14:21 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5.ln_1
2024-07-02 23:18:25 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 0.0101, -0.0102, -0.0037,  ...,  0.0073, -0.0078, -0.0067],
        [ 0.0054, -0.0002,  0.0012,  ...,  0.0010,  0.0020,  0.0004],
        [ 0.0050, -0.0012, -0.0064,  ...,  0.0007,  0.0078, -0.0049],
        ...,
        [ 0.0073, -0.0038, -0.0056,  ..., -0.0070, -0.0050, -0.0114],
        [-0.0076, -0.0007, -0.0231,  ..., -0.0078, -0.0039,  0.0001],
        [-0.0029, -0.0170,  0.0113,  ..., -0.0035,  0.0353, -0.0079]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-02 23:18:26 root INFO     h_layer_name='transformer.h.5' z_layer_name='transformer.h.27'
2024-07-02 23:18:26 root INFO     [order_1_approx] starting weight calculation for The plural form of theory is theories
The plural form of memory is memories
The plural form of country is countries
The plural form of history is histories
The plural form of ability is abilities
The plural form of library is libraries
The plural form of activity is activities
The plural form of family is
2024-07-02 23:18:26 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5
2024-07-02 23:22:16 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-2.8778e-02, -1.8921e-02,  2.2629e-02,  ..., -9.6893e-03,
         -5.1117e-03, -2.8625e-02],
        [ 1.2962e-02,  1.1063e-03, -6.1874e-03,  ...,  1.4221e-02,
          1.3565e-02, -1.2207e-02],
        [ 2.2812e-02, -1.5602e-03, -2.4071e-03,  ..., -5.6038e-03,
         -2.1019e-03,  6.0272e-04],
        ...,
        [-8.1863e-03, -1.7487e-02, -5.2414e-03,  ..., -2.7100e-02,
          1.5572e-02, -2.5696e-02],
        [-1.0155e-02, -3.5034e-02,  8.3466e-03,  ..., -1.1856e-02,
         -5.1270e-02,  5.1727e-03],
        [-3.3997e-02,  1.4847e-02, -2.1179e-02,  ..., -1.1017e-02,
          1.5259e-05, -1.0193e-02]], device='cuda:0', dtype=torch.float16) 

                    
2024-07-02 23:22:17 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of theory is theories
The plural form of memory is memories
The plural form of country is countries
The plural form of history is histories
The plural form of ability is abilities
The plural form of library is libraries
The plural form of activity is activities
The plural form of family is
2024-07-02 23:22:18 root INFO     h_layer_name='transformer.h.5.ln_1' z_layer_name='transformer.h.27'
2024-07-02 23:22:18 root INFO     [order_1_approx] starting weight calculation for The plural form of country is countries
The plural form of history is histories
The plural form of memory is memories
The plural form of family is families
The plural form of library is libraries
The plural form of ability is abilities
The plural form of theory is theories
The plural form of activity is
2024-07-02 23:22:18 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5.ln_1
2024-07-02 23:26:22 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 0.0018, -0.0039, -0.0032,  ..., -0.0007, -0.0164,  0.0017],
        [ 0.0010,  0.0138,  0.0013,  ...,  0.0097,  0.0055, -0.0058],
        [ 0.0068,  0.0036,  0.0054,  ...,  0.0030, -0.0079,  0.0050],
        ...,
        [-0.0037,  0.0040,  0.0036,  ...,  0.0044, -0.0163, -0.0023],
        [-0.0017,  0.0125, -0.0170,  ...,  0.0034, -0.0103, -0.0090],
        [-0.0123, -0.0080,  0.0027,  ...,  0.0067,  0.0051, -0.0197]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-02 23:26:23 root INFO     h_layer_name='transformer.h.5' z_layer_name='transformer.h.27'
2024-07-02 23:26:23 root INFO     [order_1_approx] starting weight calculation for The plural form of country is countries
The plural form of history is histories
The plural form of memory is memories
The plural form of family is families
The plural form of library is libraries
The plural form of ability is abilities
The plural form of theory is theories
The plural form of activity is
2024-07-02 23:26:23 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5
2024-07-02 23:30:18 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0309, -0.0216,  0.0356,  ..., -0.0027, -0.0031, -0.0212],
        [ 0.0066, -0.0164, -0.0147,  ..., -0.0066,  0.0239,  0.0065],
        [ 0.0109,  0.0203, -0.0209,  ..., -0.0082,  0.0138,  0.0074],
        ...,
        [-0.0164, -0.0149,  0.0072,  ..., -0.0193,  0.0206, -0.0027],
        [-0.0255, -0.0250,  0.0193,  ...,  0.0020, -0.0458,  0.0183],
        [-0.0020,  0.0327, -0.0007,  ..., -0.0142,  0.0036, -0.0272]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-02 23:30:19 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of country is countries
The plural form of history is histories
The plural form of memory is memories
The plural form of family is families
The plural form of library is libraries
The plural form of ability is abilities
The plural form of theory is theories
The plural form of activity is
2024-07-02 23:30:19 root INFO     h_layer_name='transformer.h.5.ln_1' z_layer_name='transformer.h.27'
2024-07-02 23:30:19 root INFO     [order_1_approx] starting weight calculation for The plural form of memory is memories
The plural form of activity is activities
The plural form of theory is theories
The plural form of history is histories
The plural form of ability is abilities
The plural form of family is families
The plural form of library is libraries
The plural form of country is
2024-07-02 23:30:19 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5.ln_1
2024-07-02 23:34:23 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 0.0150,  0.0065, -0.0019,  ...,  0.0059,  0.0002,  0.0001],
        [-0.0020,  0.0050,  0.0064,  ...,  0.0001,  0.0042,  0.0022],
        [ 0.0065,  0.0044,  0.0075,  ...,  0.0121, -0.0005, -0.0007],
        ...,
        [-0.0054,  0.0017,  0.0040,  ...,  0.0008,  0.0008, -0.0006],
        [ 0.0045,  0.0052, -0.0184,  ..., -0.0055,  0.0129, -0.0080],
        [-0.0132, -0.0048, -0.0014,  ...,  0.0031,  0.0034, -0.0062]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-02 23:34:24 root INFO     h_layer_name='transformer.h.5' z_layer_name='transformer.h.27'
2024-07-02 23:34:24 root INFO     [order_1_approx] starting weight calculation for The plural form of memory is memories
The plural form of activity is activities
The plural form of theory is theories
The plural form of history is histories
The plural form of ability is abilities
The plural form of family is families
The plural form of library is libraries
The plural form of country is
2024-07-02 23:34:24 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5
2024-07-02 23:38:19 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0302, -0.0065,  0.0116,  ..., -0.0056, -0.0271, -0.0212],
        [-0.0082, -0.0155, -0.0018,  ...,  0.0210, -0.0048,  0.0074],
        [ 0.0048,  0.0147, -0.0090,  ..., -0.0055,  0.0174, -0.0005],
        ...,
        [-0.0061, -0.0384,  0.0036,  ..., -0.0268,  0.0149, -0.0160],
        [ 0.0020, -0.0182,  0.0282,  ...,  0.0027, -0.0657,  0.0224],
        [-0.0146,  0.0165,  0.0057,  ..., -0.0019,  0.0191, -0.0540]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-02 23:38:20 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of memory is memories
The plural form of activity is activities
The plural form of theory is theories
The plural form of history is histories
The plural form of ability is abilities
The plural form of family is families
The plural form of library is libraries
The plural form of country is
2024-07-02 23:38:20 root INFO     h_layer_name='transformer.h.5.ln_1' z_layer_name='transformer.h.27'
2024-07-02 23:38:20 root INFO     [order_1_approx] starting weight calculation for The plural form of ability is abilities
The plural form of country is countries
The plural form of activity is activities
The plural form of library is libraries
The plural form of history is histories
The plural form of memory is memories
The plural form of family is families
The plural form of theory is
2024-07-02 23:38:20 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5.ln_1
2024-07-02 23:42:21 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 0.0069,  0.0048, -0.0102,  ..., -0.0017,  0.0124,  0.0048],
        [ 0.0036,  0.0047,  0.0018,  ..., -0.0147,  0.0118,  0.0056],
        [ 0.0035,  0.0082, -0.0042,  ..., -0.0160,  0.0139, -0.0079],
        ...,
        [-0.0041,  0.0058,  0.0070,  ...,  0.0100,  0.0008,  0.0030],
        [ 0.0006,  0.0148, -0.0191,  ...,  0.0017,  0.0026,  0.0073],
        [ 0.0044,  0.0020, -0.0098,  ..., -0.0059, -0.0051, -0.0107]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-02 23:42:22 root INFO     h_layer_name='transformer.h.5' z_layer_name='transformer.h.27'
2024-07-02 23:42:22 root INFO     [order_1_approx] starting weight calculation for The plural form of ability is abilities
The plural form of country is countries
The plural form of activity is activities
The plural form of library is libraries
The plural form of history is histories
The plural form of memory is memories
The plural form of family is families
The plural form of theory is
2024-07-02 23:42:22 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5
2024-07-02 23:46:17 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0322,  0.0015,  0.0276,  ..., -0.0065, -0.0097, -0.0377],
        [-0.0124,  0.0095,  0.0118,  ...,  0.0068,  0.0090,  0.0136],
        [-0.0065,  0.0291, -0.0192,  ..., -0.0035,  0.0044,  0.0011],
        ...,
        [-0.0027, -0.0091, -0.0141,  ..., -0.0522,  0.0043, -0.0075],
        [-0.0237, -0.0117,  0.0093,  ..., -0.0078, -0.0515,  0.0023],
        [-0.0125,  0.0291,  0.0319,  ..., -0.0118,  0.0229, -0.0172]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-02 23:46:18 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of ability is abilities
The plural form of country is countries
The plural form of activity is activities
The plural form of library is libraries
The plural form of history is histories
The plural form of memory is memories
The plural form of family is families
The plural form of theory is
2024-07-02 23:46:18 root INFO     h_layer_name='transformer.h.5.ln_1' z_layer_name='transformer.h.27'
2024-07-02 23:46:18 root INFO     [order_1_approx] starting weight calculation for The plural form of theory is theories
The plural form of history is histories
The plural form of activity is activities
The plural form of country is countries
The plural form of ability is abilities
The plural form of family is families
The plural form of library is libraries
The plural form of memory is
2024-07-02 23:46:18 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5.ln_1
2024-07-02 23:50:21 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 0.0085, -0.0019, -0.0099,  ..., -0.0163,  0.0069,  0.0152],
        [-0.0037,  0.0007,  0.0181,  ...,  0.0027, -0.0095, -0.0082],
        [-0.0038,  0.0029, -0.0055,  ...,  0.0017,  0.0084, -0.0037],
        ...,
        [ 0.0154,  0.0016,  0.0047,  ...,  0.0158,  0.0006,  0.0005],
        [ 0.0060,  0.0072, -0.0198,  ..., -0.0035,  0.0044, -0.0015],
        [-0.0011,  0.0066, -0.0111,  ..., -0.0014,  0.0075,  0.0012]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-02 23:50:22 root INFO     h_layer_name='transformer.h.5' z_layer_name='transformer.h.27'
2024-07-02 23:50:22 root INFO     [order_1_approx] starting weight calculation for The plural form of theory is theories
The plural form of history is histories
The plural form of activity is activities
The plural form of country is countries
The plural form of ability is abilities
The plural form of family is families
The plural form of library is libraries
The plural form of memory is
2024-07-02 23:50:22 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5
2024-07-02 23:54:16 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-1.6129e-02, -1.8860e-02,  2.6657e-02,  ...,  5.4245e-03,
         -1.7166e-04, -2.7405e-02],
        [ 1.7014e-03,  5.5656e-03,  9.5367e-05,  ...,  2.7008e-03,
         -2.0218e-03,  2.6886e-02],
        [-1.3130e-02,  9.9030e-03,  1.1940e-02,  ..., -3.5858e-04,
          1.9806e-02, -4.8828e-03],
        ...,
        [-1.0300e-02, -1.4648e-02,  2.1042e-02,  ..., -2.5314e-02,
         -8.0719e-03, -2.1667e-03],
        [ 1.3077e-02, -2.0233e-02,  6.9504e-03,  ..., -6.1035e-05,
         -3.6499e-02,  9.0332e-03],
        [-1.9562e-02,  1.6174e-02,  2.5043e-03,  ...,  1.0567e-03,
          5.1689e-04, -8.8501e-04]], device='cuda:0', dtype=torch.float16) 

                    
2024-07-02 23:54:17 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of theory is theories
The plural form of history is histories
The plural form of activity is activities
The plural form of country is countries
The plural form of ability is abilities
The plural form of family is families
The plural form of library is libraries
The plural form of memory is
2024-07-02 23:54:17 root INFO     h_layer_name='transformer.h.5.ln_1' z_layer_name='transformer.h.27'
2024-07-02 23:54:17 root INFO     [order_1_approx] starting weight calculation for The plural form of theory is theories
The plural form of activity is activities
The plural form of family is families
The plural form of history is histories
The plural form of country is countries
The plural form of memory is memories
The plural form of library is libraries
The plural form of ability is
2024-07-02 23:54:17 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5.ln_1
2024-07-02 23:58:21 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 1.0071e-03,  1.4771e-02,  1.4324e-03,  ..., -2.1038e-03,
         -1.1187e-03, -1.7395e-03],
        [ 2.6035e-03,  1.5640e-04,  5.7945e-03,  ...,  1.4450e-02,
          4.5433e-03,  2.2078e-04],
        [ 5.7831e-03,  4.4403e-03,  4.3831e-03,  ...,  6.3171e-03,
          9.9411e-03,  7.2670e-04],
        ...,
        [-8.7280e-03, -1.6632e-02, -9.7275e-05,  ...,  6.0959e-03,
          1.9913e-03, -1.7195e-03],
        [-1.7672e-03, -8.6594e-03, -1.7838e-02,  ..., -1.1093e-02,
         -1.0002e-02,  6.2561e-03],
        [-1.0010e-02, -5.7716e-03, -9.4414e-04,  ...,  6.5002e-03,
          3.9291e-03, -3.9711e-03]], device='cuda:0', dtype=torch.float16) 

                    
2024-07-02 23:58:22 root INFO     h_layer_name='transformer.h.5' z_layer_name='transformer.h.27'
2024-07-02 23:58:22 root INFO     [order_1_approx] starting weight calculation for The plural form of theory is theories
The plural form of activity is activities
The plural form of family is families
The plural form of history is histories
The plural form of country is countries
The plural form of memory is memories
The plural form of library is libraries
The plural form of ability is
2024-07-02 23:58:22 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5
2024-07-03 00:02:16 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0371, -0.0110,  0.0201,  ...,  0.0230, -0.0374, -0.0388],
        [ 0.0062,  0.0161, -0.0134,  ...,  0.0124,  0.0167,  0.0331],
        [ 0.0092,  0.0108, -0.0195,  ..., -0.0094,  0.0110, -0.0156],
        ...,
        [-0.0111, -0.0143, -0.0135,  ..., -0.0400,  0.0091,  0.0214],
        [-0.0193, -0.0055,  0.0103,  ..., -0.0068, -0.0570,  0.0017],
        [ 0.0069,  0.0249,  0.0188,  ..., -0.0017,  0.0113, -0.0303]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-03 00:02:17 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of theory is theories
The plural form of activity is activities
The plural form of family is families
The plural form of history is histories
The plural form of country is countries
The plural form of memory is memories
The plural form of library is libraries
The plural form of ability is
2024-07-03 00:02:17 root INFO     total operator prediction time: 3835.2420995235443 seconds
2024-07-03 00:02:17 __main__ INFO     starting test: <class 'lre.operators.JacobianIclMeanEstimator'> on synonyms - intensity
2024-07-03 00:02:20 root INFO     building operator synonyms - intensity
2024-07-03 00:02:20 root INFO     h_layer_name='transformer.h.5.ln_1' z_layer_name='transformer.h.27'
2024-07-03 00:02:20 root INFO     [order_1_approx] starting weight calculation for A more intense word for necessary is  essential
A more intense word for sniffles is  pneumonia
A more intense word for snack is  meal
A more intense word for sad is  desparate
A more intense word for interesting is  exciting
A more intense word for pony is  horse
A more intense word for cry is  scream
A more intense word for cat is 
2024-07-03 00:02:20 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5.ln_1
2024-07-03 00:06:25 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0143, -0.0048, -0.0067,  ...,  0.0040, -0.0137,  0.0016],
        [ 0.0051, -0.0036, -0.0054,  ...,  0.0008,  0.0008, -0.0047],
        [ 0.0084,  0.0114, -0.0016,  ...,  0.0095,  0.0023, -0.0052],
        ...,
        [-0.0111, -0.0008, -0.0010,  ..., -0.0089, -0.0023, -0.0025],
        [-0.0124,  0.0136,  0.0078,  ...,  0.0018,  0.0049, -0.0011],
        [ 0.0010, -0.0111,  0.0094,  ..., -0.0093, -0.0064,  0.0003]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-03 00:06:26 root INFO     h_layer_name='transformer.h.5' z_layer_name='transformer.h.27'
2024-07-03 00:06:26 root INFO     [order_1_approx] starting weight calculation for A more intense word for necessary is  essential
A more intense word for sniffles is  pneumonia
A more intense word for snack is  meal
A more intense word for sad is  desparate
A more intense word for interesting is  exciting
A more intense word for pony is  horse
A more intense word for cry is  scream
A more intense word for cat is 
2024-07-03 00:06:26 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5
2024-07-03 00:10:22 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0353, -0.0075,  0.0116,  ...,  0.0498, -0.0008,  0.0207],
        [ 0.0013, -0.0181, -0.0058,  ...,  0.0273,  0.0043, -0.0001],
        [ 0.0089,  0.0114, -0.0200,  ..., -0.0086,  0.0200,  0.0284],
        ...,
        [ 0.0027, -0.0255, -0.0033,  ...,  0.0089, -0.0199,  0.0083],
        [ 0.0002,  0.0001,  0.0002,  ..., -0.0148, -0.0209, -0.0013],
        [-0.0342,  0.0031, -0.0090,  ..., -0.0042,  0.0149, -0.0081]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-03 00:10:23 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more intense word for necessary is  essential
A more intense word for sniffles is  pneumonia
A more intense word for snack is  meal
A more intense word for sad is  desparate
A more intense word for interesting is  exciting
A more intense word for pony is  horse
A more intense word for cry is  scream
A more intense word for cat is 
2024-07-03 00:10:23 root INFO     h_layer_name='transformer.h.5.ln_1' z_layer_name='transformer.h.27'
2024-07-03 00:10:23 root INFO     [order_1_approx] starting weight calculation for A more intense word for snack is  meal
A more intense word for cry is  scream
A more intense word for cat is  lion
A more intense word for interesting is  exciting
A more intense word for pony is  horse
A more intense word for sniffles is  pneumonia
A more intense word for sad is  desparate
A more intense word for necessary is 
2024-07-03 00:10:23 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5.ln_1
2024-07-03 00:14:28 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 0.0023, -0.0083,  0.0067,  ..., -0.0016, -0.0072,  0.0042],
        [ 0.0102, -0.0036,  0.0018,  ..., -0.0008,  0.0017, -0.0115],
        [-0.0044,  0.0009,  0.0013,  ..., -0.0078, -0.0037,  0.0061],
        ...,
        [ 0.0014, -0.0026, -0.0044,  ...,  0.0038,  0.0022,  0.0030],
        [-0.0241, -0.0018,  0.0027,  ...,  0.0010,  0.0025, -0.0073],
        [-0.0074,  0.0080, -0.0035,  ...,  0.0042, -0.0086,  0.0092]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-03 00:14:29 root INFO     h_layer_name='transformer.h.5' z_layer_name='transformer.h.27'
2024-07-03 00:14:29 root INFO     [order_1_approx] starting weight calculation for A more intense word for snack is  meal
A more intense word for cry is  scream
A more intense word for cat is  lion
A more intense word for interesting is  exciting
A more intense word for pony is  horse
A more intense word for sniffles is  pneumonia
A more intense word for sad is  desparate
A more intense word for necessary is 
2024-07-03 00:14:30 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5
2024-07-03 00:18:26 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0163, -0.0048,  0.0150,  ...,  0.0022,  0.0006, -0.0117],
        [-0.0231,  0.0108, -0.0239,  ..., -0.0027, -0.0158, -0.0077],
        [-0.0049, -0.0073,  0.0128,  ..., -0.0014, -0.0206,  0.0283],
        ...,
        [-0.0040, -0.0073,  0.0088,  ..., -0.0114, -0.0044,  0.0179],
        [-0.0005,  0.0074,  0.0130,  ..., -0.0014,  0.0213,  0.0082],
        [-0.0062, -0.0297, -0.0014,  ..., -0.0115,  0.0231,  0.0151]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-03 00:18:27 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more intense word for snack is  meal
A more intense word for cry is  scream
A more intense word for cat is  lion
A more intense word for interesting is  exciting
A more intense word for pony is  horse
A more intense word for sniffles is  pneumonia
A more intense word for sad is  desparate
A more intense word for necessary is 
2024-07-03 00:18:27 root INFO     h_layer_name='transformer.h.5.ln_1' z_layer_name='transformer.h.27'
2024-07-03 00:18:27 root INFO     [order_1_approx] starting weight calculation for A more intense word for interesting is  exciting
A more intense word for pony is  horse
A more intense word for cat is  lion
A more intense word for necessary is  essential
A more intense word for snack is  meal
A more intense word for sniffles is  pneumonia
A more intense word for sad is  desparate
A more intense word for cry is 
2024-07-03 00:18:27 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5.ln_1
2024-07-03 00:22:31 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0010, -0.0046, -0.0116,  ...,  0.0016,  0.0034,  0.0007],
        [-0.0023, -0.0008,  0.0037,  ..., -0.0073, -0.0080, -0.0041],
        [-0.0145,  0.0052, -0.0034,  ...,  0.0082, -0.0096, -0.0050],
        ...,
        [-0.0042, -0.0103, -0.0052,  ..., -0.0137, -0.0180, -0.0082],
        [-0.0114,  0.0024,  0.0005,  ..., -0.0033,  0.0026, -0.0120],
        [ 0.0093, -0.0114,  0.0023,  ..., -0.0070, -0.0039, -0.0038]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-03 00:22:32 root INFO     h_layer_name='transformer.h.5' z_layer_name='transformer.h.27'
2024-07-03 00:22:32 root INFO     [order_1_approx] starting weight calculation for A more intense word for interesting is  exciting
A more intense word for pony is  horse
A more intense word for cat is  lion
A more intense word for necessary is  essential
A more intense word for snack is  meal
A more intense word for sniffles is  pneumonia
A more intense word for sad is  desparate
A more intense word for cry is 
2024-07-03 00:22:32 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5
2024-07-03 00:26:27 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 6.1569e-03, -8.3389e-03, -6.6681e-03,  ..., -5.5885e-03,
         -2.5208e-02, -1.0590e-02],
        [ 2.2888e-05,  4.4708e-03, -9.3079e-04,  ...,  2.5421e-02,
         -1.1398e-02,  6.5117e-03],
        [ 7.6408e-03,  2.0233e-02,  1.5457e-02,  ...,  1.0475e-02,
          1.9470e-02,  1.7365e-02],
        ...,
        [-1.6098e-03, -1.5030e-02, -3.1710e-04,  ...,  1.4372e-03,
         -1.0040e-02,  2.0370e-02],
        [-1.9226e-02, -2.1881e-02,  1.6537e-03,  ..., -1.0239e-02,
          4.2839e-03,  4.9515e-03],
        [-2.6550e-03, -4.4098e-03, -9.0408e-03,  ..., -7.7248e-03,
         -7.5150e-03,  1.3451e-02]], device='cuda:0', dtype=torch.float16) 

                    
2024-07-03 00:26:27 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more intense word for interesting is  exciting
A more intense word for pony is  horse
A more intense word for cat is  lion
A more intense word for necessary is  essential
A more intense word for snack is  meal
A more intense word for sniffles is  pneumonia
A more intense word for sad is  desparate
A more intense word for cry is 
2024-07-03 00:26:28 root INFO     h_layer_name='transformer.h.5.ln_1' z_layer_name='transformer.h.27'
2024-07-03 00:26:28 root INFO     [order_1_approx] starting weight calculation for A more intense word for pony is  horse
A more intense word for interesting is  exciting
A more intense word for sad is  desparate
A more intense word for cry is  scream
A more intense word for snack is  meal
A more intense word for cat is  lion
A more intense word for necessary is  essential
A more intense word for sniffles is 
2024-07-03 00:26:28 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5.ln_1
2024-07-03 00:30:34 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 0.0060, -0.0118,  0.0144,  ...,  0.0138, -0.0049,  0.0032],
        [ 0.0310, -0.0552, -0.0044,  ...,  0.0478, -0.0252, -0.0151],
        [ 0.0125, -0.0057,  0.0055,  ..., -0.0026,  0.0117,  0.0068],
        ...,
        [-0.0084, -0.0381, -0.0149,  ...,  0.0127,  0.0230,  0.0071],
        [-0.0046,  0.0067, -0.0021,  ..., -0.0171,  0.0224,  0.0089],
        [ 0.0029,  0.0097, -0.0067,  ..., -0.0063,  0.0060, -0.0024]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-03 00:30:35 root INFO     h_layer_name='transformer.h.5' z_layer_name='transformer.h.27'
2024-07-03 00:30:35 root INFO     [order_1_approx] starting weight calculation for A more intense word for pony is  horse
A more intense word for interesting is  exciting
A more intense word for sad is  desparate
A more intense word for cry is  scream
A more intense word for snack is  meal
A more intense word for cat is  lion
A more intense word for necessary is  essential
A more intense word for sniffles is 
2024-07-03 00:30:35 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5
2024-07-03 00:34:32 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 8.4686e-03, -2.7924e-03,  3.4752e-03,  ...,  4.7073e-03,
         -2.7557e-02,  5.6496e-03],
        [ 4.5357e-03, -2.2850e-03,  2.6340e-03,  ...,  4.4525e-02,
          2.4872e-03, -3.6346e-02],
        [-1.4481e-02,  8.7280e-03, -5.5771e-03,  ..., -1.7334e-02,
         -1.2886e-02, -1.9180e-02],
        ...,
        [-3.2410e-02, -2.0447e-02, -2.7618e-02,  ...,  1.6190e-02,
         -2.5116e-02,  1.5087e-03],
        [-2.2568e-02, -1.0155e-02,  2.2186e-02,  ..., -2.4979e-02,
          2.9663e-02,  1.0078e-02],
        [ 6.1035e-05,  3.4790e-03, -8.6060e-03,  ..., -2.9053e-02,
          3.2440e-02, -1.4877e-03]], device='cuda:0', dtype=torch.float16) 

                    
2024-07-03 00:34:32 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more intense word for pony is  horse
A more intense word for interesting is  exciting
A more intense word for sad is  desparate
A more intense word for cry is  scream
A more intense word for snack is  meal
A more intense word for cat is  lion
A more intense word for necessary is  essential
A more intense word for sniffles is 
2024-07-03 00:34:33 root INFO     h_layer_name='transformer.h.5.ln_1' z_layer_name='transformer.h.27'
2024-07-03 00:34:33 root INFO     [order_1_approx] starting weight calculation for A more intense word for snack is  meal
A more intense word for pony is  horse
A more intense word for cry is  scream
A more intense word for cat is  lion
A more intense word for sniffles is  pneumonia
A more intense word for interesting is  exciting
A more intense word for necessary is  essential
A more intense word for sad is 
2024-07-03 00:34:33 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5.ln_1
2024-07-03 00:38:38 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0103, -0.0027, -0.0011,  ..., -0.0075,  0.0013,  0.0091],
        [-0.0058, -0.0011, -0.0064,  ..., -0.0027, -0.0002,  0.0003],
        [-0.0005,  0.0066, -0.0036,  ...,  0.0023, -0.0034, -0.0035],
        ...,
        [ 0.0035, -0.0109,  0.0039,  ..., -0.0084,  0.0008, -0.0003],
        [-0.0157, -0.0016,  0.0013,  ...,  0.0005,  0.0018, -0.0084],
        [ 0.0072,  0.0026,  0.0117,  ..., -0.0034, -0.0013, -0.0057]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-03 00:38:39 root INFO     h_layer_name='transformer.h.5' z_layer_name='transformer.h.27'
2024-07-03 00:38:39 root INFO     [order_1_approx] starting weight calculation for A more intense word for snack is  meal
A more intense word for pony is  horse
A more intense word for cry is  scream
A more intense word for cat is  lion
A more intense word for sniffles is  pneumonia
A more intense word for interesting is  exciting
A more intense word for necessary is  essential
A more intense word for sad is 
2024-07-03 00:38:39 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5
2024-07-03 00:42:35 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 0.0142, -0.0273, -0.0025,  ..., -0.0043, -0.0282,  0.0020],
        [ 0.0210, -0.0063, -0.0045,  ...,  0.0262, -0.0166, -0.0070],
        [-0.0042, -0.0203, -0.0029,  ..., -0.0150,  0.0010,  0.0082],
        ...,
        [-0.0210, -0.0043,  0.0104,  ...,  0.0040, -0.0087,  0.0190],
        [-0.0275, -0.0177,  0.0215,  ..., -0.0055,  0.0194,  0.0032],
        [-0.0113, -0.0062, -0.0077,  ..., -0.0034,  0.0153,  0.0144]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-03 00:42:35 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more intense word for snack is  meal
A more intense word for pony is  horse
A more intense word for cry is  scream
A more intense word for cat is  lion
A more intense word for sniffles is  pneumonia
A more intense word for interesting is  exciting
A more intense word for necessary is  essential
A more intense word for sad is 
2024-07-03 00:42:36 root INFO     h_layer_name='transformer.h.5.ln_1' z_layer_name='transformer.h.27'
2024-07-03 00:42:36 root INFO     [order_1_approx] starting weight calculation for A more intense word for cry is  scream
A more intense word for interesting is  exciting
A more intense word for sad is  desparate
A more intense word for cat is  lion
A more intense word for snack is  meal
A more intense word for necessary is  essential
A more intense word for sniffles is  pneumonia
A more intense word for pony is 
2024-07-03 00:42:36 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5.ln_1
2024-07-03 00:46:40 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 0.0054,  0.0013, -0.0026,  ...,  0.0029,  0.0091, -0.0100],
        [ 0.0153, -0.0078, -0.0043,  ..., -0.0046, -0.0116,  0.0071],
        [ 0.0068,  0.0023, -0.0120,  ...,  0.0104,  0.0036,  0.0007],
        ...,
        [ 0.0125, -0.0045, -0.0154,  ..., -0.0167, -0.0009, -0.0025],
        [-0.0088, -0.0004,  0.0004,  ..., -0.0029,  0.0051,  0.0055],
        [-0.0053,  0.0013, -0.0077,  ..., -0.0072, -0.0111, -0.0068]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-03 00:46:41 root INFO     h_layer_name='transformer.h.5' z_layer_name='transformer.h.27'
2024-07-03 00:46:41 root INFO     [order_1_approx] starting weight calculation for A more intense word for cry is  scream
A more intense word for interesting is  exciting
A more intense word for sad is  desparate
A more intense word for cat is  lion
A more intense word for snack is  meal
A more intense word for necessary is  essential
A more intense word for sniffles is  pneumonia
A more intense word for pony is 
2024-07-03 00:46:41 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5
2024-07-03 00:50:37 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 0.0309, -0.0502,  0.0054,  ...,  0.0451, -0.0152,  0.0073],
        [-0.0258,  0.0046,  0.0053,  ...,  0.0038,  0.0009,  0.0119],
        [-0.0179,  0.0088, -0.0126,  ..., -0.0271,  0.0022, -0.0008],
        ...,
        [-0.0065,  0.0069, -0.0178,  ...,  0.0017,  0.0083,  0.0174],
        [ 0.0245, -0.0196, -0.0114,  ..., -0.0017,  0.0012,  0.0115],
        [ 0.0125, -0.0299, -0.0242,  ...,  0.0131,  0.0070,  0.0022]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-03 00:50:38 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more intense word for cry is  scream
A more intense word for interesting is  exciting
A more intense word for sad is  desparate
A more intense word for cat is  lion
A more intense word for snack is  meal
A more intense word for necessary is  essential
A more intense word for sniffles is  pneumonia
A more intense word for pony is 
2024-07-03 00:50:38 root INFO     h_layer_name='transformer.h.5.ln_1' z_layer_name='transformer.h.27'
2024-07-03 00:50:38 root INFO     [order_1_approx] starting weight calculation for A more intense word for sniffles is  pneumonia
A more intense word for interesting is  exciting
A more intense word for necessary is  essential
A more intense word for cry is  scream
A more intense word for pony is  horse
A more intense word for sad is  desparate
A more intense word for cat is  lion
A more intense word for snack is 
2024-07-03 00:50:38 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5.ln_1
2024-07-03 00:54:44 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0043,  0.0008,  0.0090,  ...,  0.0063, -0.0096,  0.0008],
        [ 0.0132,  0.0099, -0.0077,  ..., -0.0013, -0.0045, -0.0088],
        [ 0.0095, -0.0008,  0.0036,  ...,  0.0087,  0.0055,  0.0012],
        ...,
        [ 0.0077, -0.0068, -0.0094,  ..., -0.0059, -0.0031,  0.0007],
        [-0.0066, -0.0069,  0.0076,  ...,  0.0072, -0.0081, -0.0049],
        [ 0.0011,  0.0028, -0.0051,  ...,  0.0123,  0.0124,  0.0103]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-03 00:54:45 root INFO     h_layer_name='transformer.h.5' z_layer_name='transformer.h.27'
2024-07-03 00:54:45 root INFO     [order_1_approx] starting weight calculation for A more intense word for sniffles is  pneumonia
A more intense word for interesting is  exciting
A more intense word for necessary is  essential
A more intense word for cry is  scream
A more intense word for pony is  horse
A more intense word for sad is  desparate
A more intense word for cat is  lion
A more intense word for snack is 
2024-07-03 00:54:45 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5
2024-07-03 00:58:41 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 0.0181, -0.0154,  0.0131,  ..., -0.0053, -0.0054,  0.0115],
        [-0.0160, -0.0032, -0.0138,  ...,  0.0196, -0.0100,  0.0161],
        [-0.0142,  0.0048, -0.0035,  ..., -0.0026,  0.0099, -0.0077],
        ...,
        [ 0.0067, -0.0013, -0.0036,  ...,  0.0301, -0.0079,  0.0156],
        [-0.0295,  0.0080, -0.0003,  ..., -0.0033,  0.0106,  0.0103],
        [-0.0016, -0.0016,  0.0079,  ..., -0.0074,  0.0030, -0.0082]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-03 00:58:42 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more intense word for sniffles is  pneumonia
A more intense word for interesting is  exciting
A more intense word for necessary is  essential
A more intense word for cry is  scream
A more intense word for pony is  horse
A more intense word for sad is  desparate
A more intense word for cat is  lion
A more intense word for snack is 
2024-07-03 00:58:42 root INFO     h_layer_name='transformer.h.5.ln_1' z_layer_name='transformer.h.27'
2024-07-03 00:58:43 root INFO     [order_1_approx] starting weight calculation for A more intense word for cry is  scream
A more intense word for cat is  lion
A more intense word for pony is  horse
A more intense word for snack is  meal
A more intense word for sad is  desparate
A more intense word for necessary is  essential
A more intense word for sniffles is  pneumonia
A more intense word for interesting is 
2024-07-03 00:58:43 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5.ln_1
2024-07-03 01:02:48 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0013,  0.0062, -0.0091,  ..., -0.0092, -0.0004,  0.0076],
        [-0.0036,  0.0128, -0.0113,  ...,  0.0035,  0.0019,  0.0022],
        [-0.0004, -0.0030, -0.0001,  ...,  0.0065, -0.0019, -0.0086],
        ...,
        [ 0.0111, -0.0039,  0.0008,  ..., -0.0019,  0.0013,  0.0057],
        [-0.0099,  0.0061,  0.0017,  ..., -0.0065, -0.0009,  0.0064],
        [-0.0017, -0.0103,  0.0004,  ..., -0.0024, -0.0048, -0.0052]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-03 01:02:49 root INFO     h_layer_name='transformer.h.5' z_layer_name='transformer.h.27'
2024-07-03 01:02:49 root INFO     [order_1_approx] starting weight calculation for A more intense word for cry is  scream
A more intense word for cat is  lion
A more intense word for pony is  horse
A more intense word for snack is  meal
A more intense word for sad is  desparate
A more intense word for necessary is  essential
A more intense word for sniffles is  pneumonia
A more intense word for interesting is 
2024-07-03 01:02:49 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5
2024-07-03 01:06:43 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 0.0247,  0.0029, -0.0039,  ...,  0.0275, -0.0074, -0.0294],
        [ 0.0159, -0.0024, -0.0109,  ...,  0.0021, -0.0136,  0.0061],
        [-0.0185, -0.0018,  0.0321,  ..., -0.0121,  0.0064, -0.0066],
        ...,
        [-0.0084,  0.0034,  0.0002,  ...,  0.0030, -0.0150,  0.0055],
        [-0.0140, -0.0058,  0.0109,  ..., -0.0092,  0.0107,  0.0061],
        [-0.0089, -0.0266,  0.0240,  ..., -0.0269,  0.0041,  0.0194]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-03 01:06:44 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more intense word for cry is  scream
A more intense word for cat is  lion
A more intense word for pony is  horse
A more intense word for snack is  meal
A more intense word for sad is  desparate
A more intense word for necessary is  essential
A more intense word for sniffles is  pneumonia
A more intense word for interesting is 
2024-07-03 01:06:44 root INFO     total operator prediction time: 3864.6604211330414 seconds
2024-07-03 01:06:44 __main__ INFO     starting test: <class 'lre.operators.JacobianIclMeanEstimator'> on meronyms - substance
2024-07-03 01:06:46 root INFO     building operator meronyms - substance
2024-07-03 01:06:46 root INFO     h_layer_name='transformer.h.5.ln_1' z_layer_name='transformer.h.27'
2024-07-03 01:06:47 root INFO     [order_1_approx] starting weight calculation for A house is made up of bricks
A candy is made up of sugar
A icicle is made up of ice
A water is made up of oxygen
A money is made up of paper
A wall is made up of cement
A chocolate is made up of cocoa
A concrete is made up of
2024-07-03 01:06:47 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5.ln_1
2024-07-03 01:10:53 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-1.8188e-02,  4.9496e-04, -5.3101e-03,  ...,  6.2141e-03,
         -6.8436e-03,  1.8387e-03],
        [-4.4823e-03,  8.9798e-03, -4.3144e-03,  ..., -2.4090e-03,
         -9.9716e-03, -9.2850e-03],
        [-3.7594e-03,  8.0776e-04, -3.5591e-03,  ...,  6.8359e-03,
          7.7972e-03,  5.0583e-03],
        ...,
        [-7.2517e-03,  4.9744e-03, -3.0994e-03,  ...,  2.5406e-03,
         -4.5776e-04, -8.3303e-04],
        [-2.2774e-03,  1.2978e-02, -1.1320e-03,  ..., -8.3237e-03,
          5.3673e-03, -1.1147e-02],
        [-7.4348e-03,  4.9667e-03, -8.8215e-05,  ..., -4.1389e-03,
         -4.2725e-03, -4.7073e-03]], device='cuda:0', dtype=torch.float16) 

                    
2024-07-03 01:10:54 root INFO     h_layer_name='transformer.h.5' z_layer_name='transformer.h.27'
2024-07-03 01:10:54 root INFO     [order_1_approx] starting weight calculation for A house is made up of bricks
A candy is made up of sugar
A icicle is made up of ice
A water is made up of oxygen
A money is made up of paper
A wall is made up of cement
A chocolate is made up of cocoa
A concrete is made up of
2024-07-03 01:10:54 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5
2024-07-03 01:14:50 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 0.0125, -0.0310, -0.0057,  ...,  0.0044, -0.0046, -0.0305],
        [ 0.0013, -0.0186, -0.0130,  ..., -0.0088, -0.0134,  0.0128],
        [-0.0005, -0.0012, -0.0050,  ...,  0.0170,  0.0060,  0.0064],
        ...,
        [ 0.0250,  0.0162, -0.0251,  ..., -0.0306,  0.0279,  0.0244],
        [ 0.0002, -0.0103, -0.0231,  ...,  0.0006, -0.0301,  0.0405],
        [-0.0104, -0.0052,  0.0036,  ..., -0.0242,  0.0096, -0.0045]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-03 01:14:51 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A house is made up of bricks
A candy is made up of sugar
A icicle is made up of ice
A water is made up of oxygen
A money is made up of paper
A wall is made up of cement
A chocolate is made up of cocoa
A concrete is made up of
2024-07-03 01:14:51 root INFO     h_layer_name='transformer.h.5.ln_1' z_layer_name='transformer.h.27'
2024-07-03 01:14:51 root INFO     [order_1_approx] starting weight calculation for A house is made up of bricks
A candy is made up of sugar
A water is made up of oxygen
A wall is made up of cement
A icicle is made up of ice
A concrete is made up of silicon
A chocolate is made up of cocoa
A money is made up of
2024-07-03 01:14:51 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5.ln_1
2024-07-03 01:18:58 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-5.9652e-04,  5.2376e-03,  1.7538e-03,  ..., -4.1580e-03,
          4.2458e-03, -4.7684e-05],
        [ 2.5024e-03, -4.4937e-03, -5.2032e-03,  ...,  1.3306e-02,
          3.1128e-03, -1.1467e-02],
        [-2.7084e-04, -6.4316e-03, -3.7689e-03,  ...,  6.7062e-03,
          4.7150e-03, -9.9487e-03],
        ...,
        [ 5.6190e-03, -3.6278e-03, -5.0974e-04,  ...,  6.4516e-04,
          8.2016e-05,  8.5602e-03],
        [-2.1839e-03,  2.3441e-03, -7.3090e-03,  ...,  1.4603e-02,
          8.0566e-03, -9.9487e-03],
        [-4.0131e-03,  1.3649e-02,  1.1375e-02,  ..., -1.5518e-02,
          9.4910e-03,  1.6800e-02]], device='cuda:0', dtype=torch.float16) 

                    
2024-07-03 01:18:59 root INFO     h_layer_name='transformer.h.5' z_layer_name='transformer.h.27'
2024-07-03 01:18:59 root INFO     [order_1_approx] starting weight calculation for A house is made up of bricks
A candy is made up of sugar
A water is made up of oxygen
A wall is made up of cement
A icicle is made up of ice
A concrete is made up of silicon
A chocolate is made up of cocoa
A money is made up of
2024-07-03 01:18:59 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5
2024-07-03 01:22:55 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0191, -0.0151, -0.0075,  ..., -0.0062, -0.0046, -0.0060],
        [ 0.0040, -0.0083, -0.0058,  ..., -0.0064, -0.0079, -0.0086],
        [-0.0060, -0.0028,  0.0124,  ..., -0.0002,  0.0143, -0.0031],
        ...,
        [ 0.0035, -0.0279, -0.0030,  ...,  0.0005, -0.0041,  0.0058],
        [ 0.0026,  0.0245, -0.0104,  ..., -0.0209, -0.0137, -0.0100],
        [-0.0334,  0.0153,  0.0273,  ..., -0.0033,  0.0184, -0.0071]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-03 01:22:56 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A house is made up of bricks
A candy is made up of sugar
A water is made up of oxygen
A wall is made up of cement
A icicle is made up of ice
A concrete is made up of silicon
A chocolate is made up of cocoa
A money is made up of
2024-07-03 01:22:56 root INFO     h_layer_name='transformer.h.5.ln_1' z_layer_name='transformer.h.27'
2024-07-03 01:22:56 root INFO     [order_1_approx] starting weight calculation for A money is made up of paper
A concrete is made up of silicon
A wall is made up of cement
A house is made up of bricks
A water is made up of oxygen
A chocolate is made up of cocoa
A candy is made up of sugar
A icicle is made up of
2024-07-03 01:22:56 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5.ln_1
2024-07-03 01:27:01 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 0.0043, -0.0109,  0.0067,  ..., -0.0126, -0.0022, -0.0065],
        [ 0.0040,  0.0124,  0.0022,  ..., -0.0042, -0.0055,  0.0084],
        [ 0.0011, -0.0189,  0.0170,  ..., -0.0095,  0.0062, -0.0054],
        ...,
        [ 0.0006, -0.0024, -0.0009,  ...,  0.0083, -0.0264,  0.0089],
        [ 0.0013, -0.0067,  0.0012,  ..., -0.0072,  0.0197,  0.0006],
        [-0.0109,  0.0023,  0.0046,  ..., -0.0129, -0.0141, -0.0008]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-03 01:27:02 root INFO     h_layer_name='transformer.h.5' z_layer_name='transformer.h.27'
2024-07-03 01:27:02 root INFO     [order_1_approx] starting weight calculation for A money is made up of paper
A concrete is made up of silicon
A wall is made up of cement
A house is made up of bricks
A water is made up of oxygen
A chocolate is made up of cocoa
A candy is made up of sugar
A icicle is made up of
2024-07-03 01:27:02 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5
2024-07-03 01:30:58 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 0.0103,  0.0054, -0.0347,  ..., -0.0020,  0.0021, -0.0204],
        [-0.0193,  0.0004,  0.0030,  ..., -0.0037,  0.0206,  0.0018],
        [ 0.0213, -0.0151,  0.0021,  ...,  0.0147, -0.0175, -0.0031],
        ...,
        [-0.0038, -0.0111,  0.0123,  ...,  0.0114, -0.0497,  0.0238],
        [-0.0081, -0.0090,  0.0058,  ...,  0.0184,  0.0051,  0.0064],
        [-0.0253,  0.0064,  0.0037,  ..., -0.0063,  0.0238, -0.0068]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-03 01:30:59 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A money is made up of paper
A concrete is made up of silicon
A wall is made up of cement
A house is made up of bricks
A water is made up of oxygen
A chocolate is made up of cocoa
A candy is made up of sugar
A icicle is made up of
2024-07-03 01:30:59 root INFO     h_layer_name='transformer.h.5.ln_1' z_layer_name='transformer.h.27'
2024-07-03 01:30:59 root INFO     [order_1_approx] starting weight calculation for A water is made up of oxygen
A icicle is made up of ice
A house is made up of bricks
A chocolate is made up of cocoa
A candy is made up of sugar
A concrete is made up of silicon
A money is made up of paper
A wall is made up of
2024-07-03 01:30:59 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5.ln_1
2024-07-03 01:35:05 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-1.3458e-02,  1.5774e-03, -8.0681e-04,  ..., -3.9673e-04,
         -8.4381e-03, -1.6479e-03],
        [ 1.6088e-03,  1.0590e-02,  4.9651e-05,  ...,  2.5463e-03,
         -2.1601e-04, -1.0078e-02],
        [-6.1264e-03, -7.0877e-03,  2.1286e-03,  ..., -9.9106e-03,
          2.0313e-03, -6.3705e-04],
        ...,
        [ 7.7553e-03, -1.3130e-02, -6.0806e-03,  ..., -4.0932e-03,
         -2.6073e-03, -6.4964e-03],
        [-6.5231e-03, -6.5346e-03, -8.1558e-03,  ...,  1.0271e-03,
         -4.0054e-04, -1.2875e-03],
        [-7.3776e-03, -1.1337e-02,  2.8629e-03,  ..., -1.3512e-02,
         -5.1308e-03,  1.4412e-02]], device='cuda:0', dtype=torch.float16) 

                    
2024-07-03 01:35:06 root INFO     h_layer_name='transformer.h.5' z_layer_name='transformer.h.27'
2024-07-03 01:35:06 root INFO     [order_1_approx] starting weight calculation for A water is made up of oxygen
A icicle is made up of ice
A house is made up of bricks
A chocolate is made up of cocoa
A candy is made up of sugar
A concrete is made up of silicon
A money is made up of paper
A wall is made up of
2024-07-03 01:35:06 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5
2024-07-03 01:39:02 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-8.7585e-03, -1.9592e-02,  4.7731e-04,  ..., -6.2866e-03,
         -1.8951e-02, -7.0496e-03],
        [ 1.4832e-02,  6.6833e-03, -3.8071e-03,  ...,  2.2095e-02,
          3.4485e-03, -7.1259e-03],
        [-9.3765e-03,  5.9166e-03,  4.9820e-03,  ...,  2.7771e-03,
          1.7595e-03, -8.5220e-03],
        ...,
        [ 2.4776e-03,  5.1079e-03, -1.2123e-02,  ...,  4.8599e-03,
         -5.4245e-03,  1.4389e-02],
        [ 1.0941e-02,  6.1035e-05, -1.5274e-02,  ...,  3.7003e-04,
          3.8757e-03,  1.7395e-02],
        [-8.2245e-03,  4.7684e-03,  2.5139e-03,  ..., -8.7738e-03,
          2.7039e-02, -2.9716e-03]], device='cuda:0', dtype=torch.float16) 

                    
2024-07-03 01:39:03 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A water is made up of oxygen
A icicle is made up of ice
A house is made up of bricks
A chocolate is made up of cocoa
A candy is made up of sugar
A concrete is made up of silicon
A money is made up of paper
A wall is made up of
2024-07-03 01:39:03 root INFO     h_layer_name='transformer.h.5.ln_1' z_layer_name='transformer.h.27'
2024-07-03 01:39:04 root INFO     [order_1_approx] starting weight calculation for A chocolate is made up of cocoa
A water is made up of oxygen
A concrete is made up of silicon
A icicle is made up of ice
A wall is made up of cement
A candy is made up of sugar
A money is made up of paper
A house is made up of
2024-07-03 01:39:04 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5.ln_1
2024-07-03 01:43:10 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0015,  0.0047, -0.0023,  ..., -0.0014, -0.0057,  0.0033],
        [ 0.0032,  0.0008,  0.0072,  ..., -0.0019, -0.0051,  0.0046],
        [-0.0003,  0.0047, -0.0010,  ..., -0.0078,  0.0026, -0.0109],
        ...,
        [ 0.0068, -0.0026, -0.0043,  ..., -0.0051, -0.0006,  0.0023],
        [-0.0020, -0.0025, -0.0029,  ..., -0.0050, -0.0030, -0.0023],
        [-0.0022, -0.0060, -0.0049,  ..., -0.0002,  0.0052, -0.0035]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-03 01:43:11 root INFO     h_layer_name='transformer.h.5' z_layer_name='transformer.h.27'
2024-07-03 01:43:11 root INFO     [order_1_approx] starting weight calculation for A chocolate is made up of cocoa
A water is made up of oxygen
A concrete is made up of silicon
A icicle is made up of ice
A wall is made up of cement
A candy is made up of sugar
A money is made up of paper
A house is made up of
2024-07-03 01:43:11 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5
2024-07-03 01:47:08 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 0.0057, -0.0274,  0.0014,  ...,  0.0032, -0.0070, -0.0025],
        [-0.0063, -0.0068, -0.0025,  ...,  0.0008, -0.0026, -0.0185],
        [-0.0040,  0.0077,  0.0081,  ...,  0.0021,  0.0083,  0.0039],
        ...,
        [-0.0048, -0.0155, -0.0092,  ..., -0.0030,  0.0053,  0.0111],
        [-0.0049, -0.0006, -0.0070,  ...,  0.0070,  0.0155,  0.0077],
        [-0.0188,  0.0022,  0.0081,  ...,  0.0057,  0.0246,  0.0178]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-03 01:47:08 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A chocolate is made up of cocoa
A water is made up of oxygen
A concrete is made up of silicon
A icicle is made up of ice
A wall is made up of cement
A candy is made up of sugar
A money is made up of paper
A house is made up of
2024-07-03 01:47:09 root INFO     h_layer_name='transformer.h.5.ln_1' z_layer_name='transformer.h.27'
2024-07-03 01:47:09 root INFO     [order_1_approx] starting weight calculation for A concrete is made up of silicon
A icicle is made up of ice
A money is made up of paper
A chocolate is made up of cocoa
A water is made up of oxygen
A wall is made up of cement
A house is made up of bricks
A candy is made up of
2024-07-03 01:47:09 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5.ln_1
2024-07-03 01:51:14 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0037,  0.0063,  0.0022,  ..., -0.0027, -0.0006,  0.0056],
        [ 0.0025,  0.0044,  0.0056,  ..., -0.0013,  0.0024,  0.0054],
        [-0.0003,  0.0082, -0.0058,  ..., -0.0029,  0.0018, -0.0083],
        ...,
        [ 0.0069, -0.0087, -0.0024,  ..., -0.0035,  0.0032,  0.0042],
        [ 0.0023, -0.0029,  0.0043,  ..., -0.0098,  0.0001,  0.0033],
        [-0.0155,  0.0073, -0.0037,  ...,  0.0009,  0.0048,  0.0070]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-03 01:51:15 root INFO     h_layer_name='transformer.h.5' z_layer_name='transformer.h.27'
2024-07-03 01:51:15 root INFO     [order_1_approx] starting weight calculation for A concrete is made up of silicon
A icicle is made up of ice
A money is made up of paper
A chocolate is made up of cocoa
A water is made up of oxygen
A wall is made up of cement
A house is made up of bricks
A candy is made up of
2024-07-03 01:51:15 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5
2024-07-03 01:55:11 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 0.0010, -0.0165, -0.0122,  ...,  0.0090,  0.0011, -0.0276],
        [ 0.0102, -0.0050, -0.0125,  ..., -0.0091,  0.0129,  0.0130],
        [-0.0042,  0.0029, -0.0038,  ...,  0.0049,  0.0117,  0.0146],
        ...,
        [ 0.0245, -0.0323,  0.0057,  ..., -0.0116, -0.0077, -0.0237],
        [ 0.0027,  0.0023, -0.0117,  ...,  0.0154,  0.0024,  0.0025],
        [-0.0150,  0.0152,  0.0145,  ..., -0.0120,  0.0195, -0.0004]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-03 01:55:12 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A concrete is made up of silicon
A icicle is made up of ice
A money is made up of paper
A chocolate is made up of cocoa
A water is made up of oxygen
A wall is made up of cement
A house is made up of bricks
A candy is made up of
2024-07-03 01:55:13 root INFO     h_layer_name='transformer.h.5.ln_1' z_layer_name='transformer.h.27'
2024-07-03 01:55:13 root INFO     [order_1_approx] starting weight calculation for A concrete is made up of silicon
A icicle is made up of ice
A money is made up of paper
A wall is made up of cement
A water is made up of oxygen
A candy is made up of sugar
A house is made up of bricks
A chocolate is made up of
2024-07-03 01:55:13 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5.ln_1
2024-07-03 01:59:17 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 1.7147e-03,  2.7504e-03, -4.6463e-03,  ...,  3.8700e-03,
          4.5395e-03,  1.5396e-02],
        [ 1.9760e-03,  7.6981e-03,  4.0627e-03,  ...,  5.5428e-03,
          3.6030e-03, -9.3842e-03],
        [-1.2138e-02, -4.3411e-03,  4.6825e-04,  ...,  7.6294e-06,
          4.1580e-03, -1.0956e-02],
        ...,
        [ 5.0583e-03, -4.1199e-03, -2.6226e-03,  ..., -1.7223e-03,
         -1.1963e-02,  6.1188e-03],
        [-7.8964e-04, -8.3008e-03,  4.6005e-03,  ..., -3.2310e-03,
          2.7905e-03,  1.1345e-02],
        [-1.6586e-02, -1.2379e-03,  2.6760e-03,  ...,  3.0594e-03,
          1.3256e-03,  9.5139e-03]], device='cuda:0', dtype=torch.float16) 

                    
2024-07-03 01:59:18 root INFO     h_layer_name='transformer.h.5' z_layer_name='transformer.h.27'
2024-07-03 01:59:18 root INFO     [order_1_approx] starting weight calculation for A concrete is made up of silicon
A icicle is made up of ice
A money is made up of paper
A wall is made up of cement
A water is made up of oxygen
A candy is made up of sugar
A house is made up of bricks
A chocolate is made up of
2024-07-03 01:59:18 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5
2024-07-03 02:03:14 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-2.1362e-04, -1.4183e-02, -2.4811e-02,  ...,  1.9226e-02,
         -4.1618e-03, -3.7964e-02],
        [ 6.1493e-03,  1.0780e-02, -9.3460e-03,  ..., -1.9512e-03,
          2.5894e-02,  2.4033e-03],
        [-1.6800e-02,  1.1795e-02, -3.5583e-02,  ..., -1.3313e-02,
          1.3268e-02,  3.4576e-02],
        ...,
        [ 8.0795e-03, -2.8244e-02,  1.8005e-02,  ..., -1.3199e-03,
          3.5477e-03,  6.8092e-03],
        [ 1.0513e-02, -2.7023e-02, -4.6768e-03,  ...,  1.2604e-02,
         -9.4147e-03,  3.8696e-02],
        [ 9.3460e-05,  2.1782e-03,  1.5808e-02,  ..., -1.8921e-02,
          4.6120e-03, -4.9515e-03]], device='cuda:0', dtype=torch.float16) 

                    
2024-07-03 02:03:15 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A concrete is made up of silicon
A icicle is made up of ice
A money is made up of paper
A wall is made up of cement
A water is made up of oxygen
A candy is made up of sugar
A house is made up of bricks
A chocolate is made up of
2024-07-03 02:03:15 root INFO     h_layer_name='transformer.h.5.ln_1' z_layer_name='transformer.h.27'
2024-07-03 02:03:15 root INFO     [order_1_approx] starting weight calculation for A chocolate is made up of cocoa
A money is made up of paper
A concrete is made up of silicon
A wall is made up of cement
A house is made up of bricks
A icicle is made up of ice
A candy is made up of sugar
A water is made up of
2024-07-03 02:03:15 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5.ln_1
2024-07-03 02:07:22 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 0.0005,  0.0066,  0.0006,  ..., -0.0037, -0.0030, -0.0033],
        [ 0.0020, -0.0085, -0.0025,  ..., -0.0083, -0.0050,  0.0097],
        [-0.0048, -0.0006,  0.0022,  ..., -0.0073, -0.0056,  0.0033],
        ...,
        [ 0.0065, -0.0015, -0.0176,  ..., -0.0030, -0.0011,  0.0015],
        [ 0.0114,  0.0111,  0.0042,  ..., -0.0002, -0.0069, -0.0045],
        [-0.0034, -0.0028, -0.0002,  ...,  0.0019,  0.0031,  0.0010]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-03 02:07:23 root INFO     h_layer_name='transformer.h.5' z_layer_name='transformer.h.27'
2024-07-03 02:07:23 root INFO     [order_1_approx] starting weight calculation for A chocolate is made up of cocoa
A money is made up of paper
A concrete is made up of silicon
A wall is made up of cement
A house is made up of bricks
A icicle is made up of ice
A candy is made up of sugar
A water is made up of
2024-07-03 02:07:23 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5
2024-07-03 02:11:20 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0211, -0.0090, -0.0204,  ...,  0.0193,  0.0112, -0.0009],
        [-0.0144, -0.0014,  0.0023,  ..., -0.0044,  0.0013, -0.0332],
        [-0.0045, -0.0088, -0.0283,  ...,  0.0113, -0.0048,  0.0109],
        ...,
        [-0.0061,  0.0130,  0.0056,  ..., -0.0233,  0.0065,  0.0101],
        [ 0.0098, -0.0092,  0.0211,  ..., -0.0015, -0.0321,  0.0017],
        [-0.0156,  0.0097, -0.0030,  ..., -0.0046,  0.0106, -0.0125]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-03 02:11:21 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A chocolate is made up of cocoa
A money is made up of paper
A concrete is made up of silicon
A wall is made up of cement
A house is made up of bricks
A icicle is made up of ice
A candy is made up of sugar
A water is made up of
2024-07-03 02:11:21 root INFO     total operator prediction time: 3874.165834903717 seconds
2024-07-03 02:11:21 __main__ INFO     starting test: <class 'lre.operators.JacobianIclMeanEstimator'> on hypernyms - animals
2024-07-03 02:11:23 root INFO     building operator hypernyms - animals
2024-07-03 02:11:23 root INFO     h_layer_name='transformer.h.5.ln_1' z_layer_name='transformer.h.27'
2024-07-03 02:11:23 root INFO     [order_1_approx] starting weight calculation for The rattlesnake falls into the category of snake
The squirrel falls into the category of rodent
The fox falls into the category of canine
The butterfly falls into the category of insect
The orangutan falls into the category of primate
The mouse falls into the category of rodent
The gorilla falls into the category of primate
The chicken falls into the category of
2024-07-03 02:11:23 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5.ln_1
2024-07-03 02:15:28 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-8.1062e-06, -4.6730e-03, -6.9427e-03,  ..., -2.3804e-03,
         -1.0818e-02,  1.6815e-02],
        [-2.1839e-04,  1.0880e-02,  1.0738e-03,  ...,  4.3411e-03,
         -1.1730e-03,  3.5343e-03],
        [ 1.1627e-02, -1.8501e-03,  5.5962e-03,  ..., -7.3242e-03,
         -8.9035e-03, -8.7814e-03],
        ...,
        [ 3.5954e-04, -3.4676e-03,  1.1559e-02,  ..., -6.7902e-03,
          5.4073e-04, -1.3519e-02],
        [ 1.4549e-02,  1.4717e-02,  4.5848e-04,  ..., -4.6844e-03,
          9.4452e-03,  7.1049e-04],
        [-2.9144e-03, -6.6566e-04,  1.1093e-02,  ..., -5.5084e-03,
         -7.1449e-03, -4.5700e-03]], device='cuda:0', dtype=torch.float16) 

                    
2024-07-03 02:15:29 root INFO     h_layer_name='transformer.h.5' z_layer_name='transformer.h.27'
2024-07-03 02:15:29 root INFO     [order_1_approx] starting weight calculation for The rattlesnake falls into the category of snake
The squirrel falls into the category of rodent
The fox falls into the category of canine
The butterfly falls into the category of insect
The orangutan falls into the category of primate
The mouse falls into the category of rodent
The gorilla falls into the category of primate
The chicken falls into the category of
2024-07-03 02:15:29 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5
2024-07-03 02:19:24 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-2.4033e-03, -1.1940e-02,  3.4847e-03,  ...,  1.8875e-02,
         -2.4445e-02,  3.7003e-04],
        [-1.0078e-02, -1.0281e-03,  1.0071e-02,  ...,  7.3357e-03,
         -3.0193e-03, -5.9891e-04],
        [-1.2863e-02,  8.9874e-03, -1.8906e-02,  ...,  6.3667e-03,
         -3.9215e-03,  1.2718e-02],
        ...,
        [-6.7291e-03,  1.3489e-02, -1.6403e-02,  ...,  4.9171e-03,
         -8.1329e-03,  1.1963e-02],
        [-1.9775e-02, -5.7220e-05,  6.0844e-04,  ..., -1.4267e-02,
          6.8092e-03,  1.1749e-02],
        [ 6.3896e-03,  1.4496e-03, -4.5547e-03,  ...,  6.4659e-03,
          3.7231e-03,  1.8494e-02]], device='cuda:0', dtype=torch.float16) 

                    
2024-07-03 02:19:25 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The rattlesnake falls into the category of snake
The squirrel falls into the category of rodent
The fox falls into the category of canine
The butterfly falls into the category of insect
The orangutan falls into the category of primate
The mouse falls into the category of rodent
The gorilla falls into the category of primate
The chicken falls into the category of
2024-07-03 02:19:25 root INFO     h_layer_name='transformer.h.5.ln_1' z_layer_name='transformer.h.27'
2024-07-03 02:19:25 root INFO     [order_1_approx] starting weight calculation for The mouse falls into the category of rodent
The gorilla falls into the category of primate
The chicken falls into the category of fowl
The squirrel falls into the category of rodent
The orangutan falls into the category of primate
The rattlesnake falls into the category of snake
The fox falls into the category of canine
The butterfly falls into the category of
2024-07-03 02:19:26 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5.ln_1
2024-07-03 02:23:31 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0041, -0.0062, -0.0012,  ..., -0.0018, -0.0019,  0.0018],
        [ 0.0044,  0.0175, -0.0081,  ...,  0.0032,  0.0002, -0.0036],
        [ 0.0038, -0.0094, -0.0022,  ..., -0.0063,  0.0020, -0.0066],
        ...,
        [ 0.0084,  0.0147, -0.0135,  ...,  0.0081,  0.0187, -0.0073],
        [-0.0054, -0.0006,  0.0034,  ...,  0.0011, -0.0105, -0.0034],
        [-0.0041,  0.0037,  0.0038,  ..., -0.0031, -0.0054, -0.0015]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-03 02:23:31 root INFO     h_layer_name='transformer.h.5' z_layer_name='transformer.h.27'
2024-07-03 02:23:32 root INFO     [order_1_approx] starting weight calculation for The mouse falls into the category of rodent
The gorilla falls into the category of primate
The chicken falls into the category of fowl
The squirrel falls into the category of rodent
The orangutan falls into the category of primate
The rattlesnake falls into the category of snake
The fox falls into the category of canine
The butterfly falls into the category of
2024-07-03 02:23:32 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5
2024-07-03 02:27:28 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 0.0175,  0.0078, -0.0154,  ...,  0.0226, -0.0040,  0.0101],
        [ 0.0012, -0.0014,  0.0003,  ...,  0.0219, -0.0060, -0.0058],
        [-0.0167,  0.0014, -0.0037,  ...,  0.0018,  0.0035,  0.0111],
        ...,
        [ 0.0122, -0.0244, -0.0092,  ...,  0.0052, -0.0097,  0.0130],
        [-0.0102, -0.0095, -0.0017,  ..., -0.0082, -0.0011, -0.0008],
        [-0.0043,  0.0112,  0.0168,  ..., -0.0197,  0.0014,  0.0308]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-03 02:27:29 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The mouse falls into the category of rodent
The gorilla falls into the category of primate
The chicken falls into the category of fowl
The squirrel falls into the category of rodent
The orangutan falls into the category of primate
The rattlesnake falls into the category of snake
The fox falls into the category of canine
The butterfly falls into the category of
2024-07-03 02:27:29 root INFO     h_layer_name='transformer.h.5.ln_1' z_layer_name='transformer.h.27'
2024-07-03 02:27:29 root INFO     [order_1_approx] starting weight calculation for The chicken falls into the category of fowl
The orangutan falls into the category of primate
The squirrel falls into the category of rodent
The mouse falls into the category of rodent
The gorilla falls into the category of primate
The butterfly falls into the category of insect
The fox falls into the category of canine
The rattlesnake falls into the category of
2024-07-03 02:27:29 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5.ln_1
2024-07-03 02:31:36 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 0.0035, -0.0005,  0.0046,  ..., -0.0046, -0.0019,  0.0062],
        [-0.0034, -0.0065,  0.0028,  ...,  0.0151, -0.0073, -0.0078],
        [-0.0040, -0.0144, -0.0027,  ...,  0.0031,  0.0029,  0.0048],
        ...,
        [ 0.0042,  0.0047,  0.0006,  ..., -0.0032, -0.0066, -0.0065],
        [ 0.0029,  0.0083,  0.0038,  ...,  0.0001,  0.0065, -0.0146],
        [-0.0044, -0.0099, -0.0111,  ...,  0.0140,  0.0072,  0.0037]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-03 02:31:37 root INFO     h_layer_name='transformer.h.5' z_layer_name='transformer.h.27'
2024-07-03 02:31:37 root INFO     [order_1_approx] starting weight calculation for The chicken falls into the category of fowl
The orangutan falls into the category of primate
The squirrel falls into the category of rodent
The mouse falls into the category of rodent
The gorilla falls into the category of primate
The butterfly falls into the category of insect
The fox falls into the category of canine
The rattlesnake falls into the category of
2024-07-03 02:31:37 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5
2024-07-03 02:35:30 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 0.0052, -0.0064, -0.0088,  ...,  0.0251, -0.0079,  0.0076],
        [-0.0137,  0.0071,  0.0130,  ...,  0.0098, -0.0167,  0.0092],
        [-0.0094, -0.0218,  0.0042,  ...,  0.0028, -0.0071,  0.0068],
        ...,
        [ 0.0156,  0.0042, -0.0032,  ...,  0.0096, -0.0038,  0.0132],
        [ 0.0026, -0.0130, -0.0023,  ..., -0.0109,  0.0034,  0.0113],
        [-0.0220, -0.0043, -0.0059,  ...,  0.0022, -0.0124,  0.0243]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-03 02:35:30 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The chicken falls into the category of fowl
The orangutan falls into the category of primate
The squirrel falls into the category of rodent
The mouse falls into the category of rodent
The gorilla falls into the category of primate
The butterfly falls into the category of insect
The fox falls into the category of canine
The rattlesnake falls into the category of
2024-07-03 02:35:31 root INFO     h_layer_name='transformer.h.5.ln_1' z_layer_name='transformer.h.27'
2024-07-03 02:35:31 root INFO     [order_1_approx] starting weight calculation for The mouse falls into the category of rodent
The butterfly falls into the category of insect
The squirrel falls into the category of rodent
The chicken falls into the category of fowl
The orangutan falls into the category of primate
The rattlesnake falls into the category of snake
The fox falls into the category of canine
The gorilla falls into the category of
2024-07-03 02:35:31 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5.ln_1
2024-07-03 02:39:37 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0051, -0.0008, -0.0068,  ..., -0.0033, -0.0093, -0.0068],
        [-0.0016, -0.0021,  0.0082,  ...,  0.0084, -0.0082, -0.0025],
        [ 0.0106, -0.0065, -0.0124,  ..., -0.0007, -0.0059, -0.0038],
        ...,
        [ 0.0070, -0.0047, -0.0065,  ..., -0.0021,  0.0008, -0.0045],
        [-0.0016,  0.0132,  0.0112,  ...,  0.0088,  0.0036, -0.0033],
        [-0.0125, -0.0087,  0.0003,  ..., -0.0001, -0.0112,  0.0057]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-03 02:39:38 root INFO     h_layer_name='transformer.h.5' z_layer_name='transformer.h.27'
2024-07-03 02:39:38 root INFO     [order_1_approx] starting weight calculation for The mouse falls into the category of rodent
The butterfly falls into the category of insect
The squirrel falls into the category of rodent
The chicken falls into the category of fowl
The orangutan falls into the category of primate
The rattlesnake falls into the category of snake
The fox falls into the category of canine
The gorilla falls into the category of
2024-07-03 02:39:38 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5
2024-07-03 02:43:34 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0040, -0.0194, -0.0009,  ...,  0.0058, -0.0063,  0.0215],
        [ 0.0004, -0.0084, -0.0011,  ...,  0.0053,  0.0037,  0.0131],
        [-0.0073,  0.0027,  0.0015,  ..., -0.0051, -0.0032,  0.0121],
        ...,
        [-0.0070, -0.0034,  0.0018,  ..., -0.0026, -0.0174,  0.0155],
        [-0.0009, -0.0046,  0.0007,  ...,  0.0053,  0.0208, -0.0064],
        [ 0.0035,  0.0199, -0.0037,  ..., -0.0088, -0.0057,  0.0042]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-03 02:43:35 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The mouse falls into the category of rodent
The butterfly falls into the category of insect
The squirrel falls into the category of rodent
The chicken falls into the category of fowl
The orangutan falls into the category of primate
The rattlesnake falls into the category of snake
The fox falls into the category of canine
The gorilla falls into the category of
2024-07-03 02:43:35 root INFO     h_layer_name='transformer.h.5.ln_1' z_layer_name='transformer.h.27'
2024-07-03 02:43:35 root INFO     [order_1_approx] starting weight calculation for The rattlesnake falls into the category of snake
The squirrel falls into the category of rodent
The butterfly falls into the category of insect
The gorilla falls into the category of primate
The mouse falls into the category of rodent
The fox falls into the category of canine
The chicken falls into the category of fowl
The orangutan falls into the category of
2024-07-03 02:43:35 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5.ln_1
2024-07-03 02:47:39 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0083,  0.0019, -0.0051,  ...,  0.0007, -0.0118, -0.0043],
        [ 0.0078, -0.0141,  0.0040,  ..., -0.0022, -0.0075, -0.0001],
        [ 0.0170, -0.0128, -0.0018,  ..., -0.0013,  0.0007, -0.0002],
        ...,
        [-0.0054, -0.0011, -0.0015,  ...,  0.0036,  0.0007, -0.0040],
        [ 0.0100,  0.0166,  0.0060,  ...,  0.0114,  0.0045,  0.0056],
        [-0.0100, -0.0051, -0.0008,  ..., -0.0042,  0.0005,  0.0013]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-03 02:47:40 root INFO     h_layer_name='transformer.h.5' z_layer_name='transformer.h.27'
2024-07-03 02:47:40 root INFO     [order_1_approx] starting weight calculation for The rattlesnake falls into the category of snake
The squirrel falls into the category of rodent
The butterfly falls into the category of insect
The gorilla falls into the category of primate
The mouse falls into the category of rodent
The fox falls into the category of canine
The chicken falls into the category of fowl
The orangutan falls into the category of
2024-07-03 02:47:40 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5
2024-07-03 02:51:37 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-3.4714e-04, -4.1962e-03, -9.6436e-03,  ...,  4.6310e-03,
         -6.1150e-03,  1.6785e-02],
        [ 3.8147e-05,  1.1082e-03,  3.9749e-03,  ...,  1.3641e-02,
          1.0371e-04, -1.6613e-03],
        [-4.8981e-03, -8.9417e-03, -3.4142e-03,  ...,  2.5177e-03,
          1.5976e-02,  6.0577e-03],
        ...,
        [-3.2730e-03, -1.1772e-02, -1.5167e-02,  ..., -1.1978e-02,
         -8.2626e-03,  5.9090e-03],
        [-2.0390e-03,  4.5319e-03, -6.9580e-03,  ...,  1.0843e-03,
         -4.1389e-04,  2.8191e-03],
        [-1.4633e-02, -1.9836e-03,  7.9193e-03,  ..., -3.6354e-03,
          5.7983e-04,  1.7731e-02]], device='cuda:0', dtype=torch.float16) 

                    
2024-07-03 02:51:38 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The rattlesnake falls into the category of snake
The squirrel falls into the category of rodent
The butterfly falls into the category of insect
The gorilla falls into the category of primate
The mouse falls into the category of rodent
The fox falls into the category of canine
The chicken falls into the category of fowl
The orangutan falls into the category of
2024-07-03 02:51:39 root INFO     h_layer_name='transformer.h.5.ln_1' z_layer_name='transformer.h.27'
2024-07-03 02:51:39 root INFO     [order_1_approx] starting weight calculation for The orangutan falls into the category of primate
The mouse falls into the category of rodent
The gorilla falls into the category of primate
The rattlesnake falls into the category of snake
The fox falls into the category of canine
The chicken falls into the category of fowl
The butterfly falls into the category of insect
The squirrel falls into the category of
2024-07-03 02:51:39 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5.ln_1
2024-07-03 02:55:44 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 0.0013,  0.0024, -0.0058,  ...,  0.0051, -0.0233,  0.0014],
        [ 0.0101, -0.0029, -0.0012,  ...,  0.0046, -0.0018, -0.0074],
        [-0.0106, -0.0061, -0.0015,  ...,  0.0068, -0.0009, -0.0037],
        ...,
        [ 0.0067, -0.0033,  0.0016,  ...,  0.0036,  0.0022, -0.0031],
        [ 0.0117,  0.0031,  0.0006,  ...,  0.0004, -0.0036, -0.0004],
        [-0.0094, -0.0022, -0.0005,  ..., -0.0081,  0.0124,  0.0031]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-03 02:55:45 root INFO     h_layer_name='transformer.h.5' z_layer_name='transformer.h.27'
2024-07-03 02:55:45 root INFO     [order_1_approx] starting weight calculation for The orangutan falls into the category of primate
The mouse falls into the category of rodent
The gorilla falls into the category of primate
The rattlesnake falls into the category of snake
The fox falls into the category of canine
The chicken falls into the category of fowl
The butterfly falls into the category of insect
The squirrel falls into the category of
2024-07-03 02:55:45 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5
2024-07-03 02:59:40 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0038,  0.0032, -0.0002,  ...,  0.0023, -0.0176,  0.0014],
        [-0.0101,  0.0105,  0.0015,  ...,  0.0019, -0.0064,  0.0154],
        [ 0.0175, -0.0170,  0.0046,  ..., -0.0147, -0.0006, -0.0036],
        ...,
        [-0.0037, -0.0148, -0.0145,  ...,  0.0111, -0.0227,  0.0185],
        [-0.0142,  0.0014,  0.0036,  ..., -0.0154,  0.0206, -0.0071],
        [ 0.0068, -0.0183,  0.0089,  ..., -0.0041,  0.0018,  0.0214]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-03 02:59:40 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The orangutan falls into the category of primate
The mouse falls into the category of rodent
The gorilla falls into the category of primate
The rattlesnake falls into the category of snake
The fox falls into the category of canine
The chicken falls into the category of fowl
The butterfly falls into the category of insect
The squirrel falls into the category of
2024-07-03 02:59:41 root INFO     h_layer_name='transformer.h.5.ln_1' z_layer_name='transformer.h.27'
2024-07-03 02:59:41 root INFO     [order_1_approx] starting weight calculation for The gorilla falls into the category of primate
The rattlesnake falls into the category of snake
The butterfly falls into the category of insect
The orangutan falls into the category of primate
The squirrel falls into the category of rodent
The chicken falls into the category of fowl
The mouse falls into the category of rodent
The fox falls into the category of
2024-07-03 02:59:41 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5.ln_1
2024-07-03 03:03:46 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0014,  0.0008,  0.0073,  ..., -0.0001,  0.0069,  0.0041],
        [ 0.0016,  0.0060,  0.0093,  ...,  0.0051,  0.0054,  0.0042],
        [-0.0072, -0.0063, -0.0049,  ...,  0.0059,  0.0037,  0.0034],
        ...,
        [ 0.0010, -0.0049,  0.0020,  ..., -0.0114, -0.0057, -0.0034],
        [ 0.0034,  0.0006,  0.0034,  ...,  0.0014, -0.0023, -0.0049],
        [ 0.0011,  0.0068, -0.0073,  ...,  0.0073,  0.0063,  0.0046]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-03 03:03:47 root INFO     h_layer_name='transformer.h.5' z_layer_name='transformer.h.27'
2024-07-03 03:03:47 root INFO     [order_1_approx] starting weight calculation for The gorilla falls into the category of primate
The rattlesnake falls into the category of snake
The butterfly falls into the category of insect
The orangutan falls into the category of primate
The squirrel falls into the category of rodent
The chicken falls into the category of fowl
The mouse falls into the category of rodent
The fox falls into the category of
2024-07-03 03:03:47 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5
2024-07-03 03:07:43 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0029, -0.0178, -0.0033,  ..., -0.0009, -0.0115,  0.0027],
        [-0.0081,  0.0097,  0.0012,  ...,  0.0030,  0.0095,  0.0208],
        [ 0.0107, -0.0058,  0.0035,  ..., -0.0063,  0.0194, -0.0002],
        ...,
        [ 0.0013, -0.0029,  0.0070,  ...,  0.0138, -0.0334,  0.0099],
        [-0.0078,  0.0007, -0.0017,  ..., -0.0083,  0.0174,  0.0242],
        [ 0.0162,  0.0013, -0.0033,  ..., -0.0071, -0.0056,  0.0306]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-03 03:07:44 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The gorilla falls into the category of primate
The rattlesnake falls into the category of snake
The butterfly falls into the category of insect
The orangutan falls into the category of primate
The squirrel falls into the category of rodent
The chicken falls into the category of fowl
The mouse falls into the category of rodent
The fox falls into the category of
2024-07-03 03:07:44 root INFO     h_layer_name='transformer.h.5.ln_1' z_layer_name='transformer.h.27'
2024-07-03 03:07:45 root INFO     [order_1_approx] starting weight calculation for The butterfly falls into the category of insect
The chicken falls into the category of fowl
The gorilla falls into the category of primate
The squirrel falls into the category of rodent
The orangutan falls into the category of primate
The fox falls into the category of canine
The rattlesnake falls into the category of snake
The mouse falls into the category of
2024-07-03 03:07:45 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5.ln_1
2024-07-03 03:11:49 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 0.0051, -0.0041,  0.0005,  ...,  0.0022, -0.0126,  0.0041],
        [ 0.0086, -0.0021, -0.0055,  ...,  0.0097,  0.0053,  0.0070],
        [ 0.0069, -0.0145, -0.0050,  ...,  0.0050, -0.0067, -0.0078],
        ...,
        [ 0.0027, -0.0017,  0.0034,  ..., -0.0045, -0.0030, -0.0063],
        [ 0.0031,  0.0005, -0.0020,  ..., -0.0068,  0.0133, -0.0014],
        [-0.0051,  0.0051, -0.0033,  ...,  0.0007,  0.0013,  0.0069]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-03 03:11:50 root INFO     h_layer_name='transformer.h.5' z_layer_name='transformer.h.27'
2024-07-03 03:11:50 root INFO     [order_1_approx] starting weight calculation for The butterfly falls into the category of insect
The chicken falls into the category of fowl
The gorilla falls into the category of primate
The squirrel falls into the category of rodent
The orangutan falls into the category of primate
The fox falls into the category of canine
The rattlesnake falls into the category of snake
The mouse falls into the category of
2024-07-03 03:11:50 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5
2024-07-03 03:15:47 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 6.9733e-03, -1.4923e-02, -1.4633e-02,  ...,  8.9340e-03,
         -1.6037e-02,  1.6708e-02],
        [-5.8365e-04,  1.6356e-04, -1.8826e-03,  ...,  5.4359e-04,
         -1.3260e-02, -4.7340e-03],
        [-1.7166e-03, -4.5853e-03, -2.7008e-02,  ..., -7.2479e-05,
          2.1622e-02,  7.9193e-03],
        ...,
        [-4.9591e-05,  3.8528e-03, -4.0321e-03,  ...,  1.1658e-02,
         -1.9318e-02,  1.7166e-02],
        [-1.3519e-02, -5.0125e-03,  1.0834e-03,  ...,  5.4169e-04,
         -3.9215e-03,  2.2926e-03],
        [ 1.1072e-03, -7.5035e-03, -8.2016e-05,  ..., -7.9117e-03,
         -6.1646e-03,  5.5122e-03]], device='cuda:0', dtype=torch.float16) 

                    
2024-07-03 03:15:47 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The butterfly falls into the category of insect
The chicken falls into the category of fowl
The gorilla falls into the category of primate
The squirrel falls into the category of rodent
The orangutan falls into the category of primate
The fox falls into the category of canine
The rattlesnake falls into the category of snake
The mouse falls into the category of
2024-07-03 03:15:47 root INFO     total operator prediction time: 3864.725485563278 seconds
2024-07-03 03:15:47 __main__ INFO     starting test: <class 'lre.operators.JacobianIclMeanEstimator'> on verb_Ving - 3pSg
2024-07-03 03:15:50 root INFO     building operator verb_Ving - 3pSg
2024-07-03 03:15:50 root INFO     h_layer_name='transformer.h.5.ln_1' z_layer_name='transformer.h.27'
2024-07-03 03:15:50 root INFO     [order_1_approx] starting weight calculation for When something is sitting, it sits
When something is considering, it considers
When something is continuing, it continues
When something is receiving, it receives
When something is adding, it adds
When something is referring, it refers
When something is creating, it creates
When something is discovering, it
2024-07-03 03:15:50 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5.ln_1
2024-07-03 03:19:52 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 0.0010, -0.0034,  0.0051,  ...,  0.0112, -0.0083, -0.0070],
        [ 0.0046,  0.0038, -0.0044,  ..., -0.0019,  0.0041, -0.0065],
        [-0.0016,  0.0159, -0.0189,  ...,  0.0129,  0.0189,  0.0010],
        ...,
        [ 0.0028, -0.0029,  0.0075,  ..., -0.0006, -0.0005,  0.0024],
        [-0.0113,  0.0095, -0.0037,  ...,  0.0052, -0.0082, -0.0117],
        [ 0.0108,  0.0026,  0.0032,  ..., -0.0091,  0.0027, -0.0050]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-03 03:19:52 root INFO     h_layer_name='transformer.h.5' z_layer_name='transformer.h.27'
2024-07-03 03:19:52 root INFO     [order_1_approx] starting weight calculation for When something is sitting, it sits
When something is considering, it considers
When something is continuing, it continues
When something is receiving, it receives
When something is adding, it adds
When something is referring, it refers
When something is creating, it creates
When something is discovering, it
2024-07-03 03:19:53 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5
2024-07-03 03:23:45 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0362, -0.0136,  0.0106,  ..., -0.0176, -0.0130, -0.0243],
        [ 0.0049, -0.0121,  0.0012,  ...,  0.0112,  0.0238,  0.0166],
        [ 0.0370,  0.0061, -0.0464,  ..., -0.0068,  0.0058,  0.0056],
        ...,
        [-0.0117,  0.0018, -0.0186,  ..., -0.0198,  0.0249, -0.0175],
        [ 0.0207,  0.0074,  0.0143,  ...,  0.0180, -0.0694,  0.0041],
        [-0.0083,  0.0269,  0.0107,  ..., -0.0285,  0.0024, -0.0436]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-03 03:23:46 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When something is sitting, it sits
When something is considering, it considers
When something is continuing, it continues
When something is receiving, it receives
When something is adding, it adds
When something is referring, it refers
When something is creating, it creates
When something is discovering, it
2024-07-03 03:23:46 root INFO     h_layer_name='transformer.h.5.ln_1' z_layer_name='transformer.h.27'
2024-07-03 03:23:46 root INFO     [order_1_approx] starting weight calculation for When something is continuing, it continues
When something is creating, it creates
When something is sitting, it sits
When something is considering, it considers
When something is discovering, it discovers
When something is adding, it adds
When something is receiving, it receives
When something is referring, it
2024-07-03 03:23:46 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5.ln_1
2024-07-03 03:27:50 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-6.1378e-03,  7.3547e-03,  1.0757e-02,  ...,  6.5842e-03,
          1.3321e-02, -1.8799e-02],
        [-3.0174e-03,  1.1848e-02, -7.5417e-03,  ..., -9.1324e-03,
         -9.4223e-04,  5.2414e-03],
        [ 3.8471e-03, -1.1642e-02, -2.5673e-03,  ..., -4.9019e-03,
          2.6703e-04,  5.4817e-03],
        ...,
        [-6.4850e-05, -1.8692e-04, -1.0681e-02,  ...,  3.1719e-03,
          1.0658e-02,  7.8735e-03],
        [-1.3077e-02,  7.2823e-03, -1.0880e-02,  ..., -1.5793e-02,
          1.3189e-03, -6.4087e-03],
        [-3.8605e-03, -2.5902e-03,  2.2141e-02,  ...,  5.0354e-04,
          1.2825e-02, -5.4131e-03]], device='cuda:0', dtype=torch.float16) 

                    
2024-07-03 03:27:51 root INFO     h_layer_name='transformer.h.5' z_layer_name='transformer.h.27'
2024-07-03 03:27:51 root INFO     [order_1_approx] starting weight calculation for When something is continuing, it continues
When something is creating, it creates
When something is sitting, it sits
When something is considering, it considers
When something is discovering, it discovers
When something is adding, it adds
When something is receiving, it receives
When something is referring, it
2024-07-03 03:27:51 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5
2024-07-03 03:31:46 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-4.4647e-02, -3.9612e-02,  1.7120e-02,  ...,  3.9673e-03,
         -2.7313e-02,  1.0353e-02],
        [-8.2703e-03, -4.0558e-02, -1.9730e-02,  ...,  1.1696e-02,
          1.4709e-02, -2.5894e-02],
        [-2.2888e-05,  3.6011e-03, -1.7822e-02,  ...,  1.7197e-02,
          2.9221e-03,  4.6692e-03],
        ...,
        [ 3.4676e-03, -7.1297e-03, -8.3160e-04,  ..., -2.9816e-02,
          1.3268e-02, -3.2410e-02],
        [ 5.1498e-03, -1.4496e-03,  3.0838e-02,  ..., -3.6469e-02,
         -5.4291e-02,  9.0790e-03],
        [-1.5358e-02,  2.3499e-02,  2.6993e-02,  ...,  1.5152e-02,
          6.2294e-03, -3.5217e-02]], device='cuda:0', dtype=torch.float16) 

                    
2024-07-03 03:31:47 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When something is continuing, it continues
When something is creating, it creates
When something is sitting, it sits
When something is considering, it considers
When something is discovering, it discovers
When something is adding, it adds
When something is receiving, it receives
When something is referring, it
2024-07-03 03:31:47 root INFO     h_layer_name='transformer.h.5.ln_1' z_layer_name='transformer.h.27'
2024-07-03 03:31:47 root INFO     [order_1_approx] starting weight calculation for When something is adding, it adds
When something is sitting, it sits
When something is continuing, it continues
When something is creating, it creates
When something is discovering, it discovers
When something is receiving, it receives
When something is referring, it refers
When something is considering, it
2024-07-03 03:31:47 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5.ln_1
2024-07-03 03:35:51 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 0.0132, -0.0049,  0.0031,  ...,  0.0198, -0.0097, -0.0078],
        [-0.0026,  0.0106, -0.0028,  ..., -0.0032, -0.0020, -0.0047],
        [ 0.0017, -0.0040, -0.0054,  ...,  0.0224,  0.0151, -0.0051],
        ...,
        [ 0.0089,  0.0061,  0.0015,  ..., -0.0052,  0.0018,  0.0078],
        [-0.0017, -0.0011, -0.0048,  ...,  0.0035, -0.0082, -0.0071],
        [-0.0065,  0.0063,  0.0047,  ...,  0.0055, -0.0034, -0.0223]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-03 03:35:52 root INFO     h_layer_name='transformer.h.5' z_layer_name='transformer.h.27'
2024-07-03 03:35:52 root INFO     [order_1_approx] starting weight calculation for When something is adding, it adds
When something is sitting, it sits
When something is continuing, it continues
When something is creating, it creates
When something is discovering, it discovers
When something is receiving, it receives
When something is referring, it refers
When something is considering, it
2024-07-03 03:35:52 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5
2024-07-03 03:39:49 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0436,  0.0077,  0.0280,  ..., -0.0111, -0.0360, -0.0178],
        [-0.0159, -0.0307, -0.0076,  ..., -0.0109,  0.0172, -0.0244],
        [-0.0053,  0.0032, -0.0159,  ...,  0.0138,  0.0023,  0.0067],
        ...,
        [ 0.0004, -0.0264, -0.0279,  ..., -0.0282,  0.0202, -0.0188],
        [ 0.0024,  0.0210, -0.0030,  ..., -0.0429, -0.0512,  0.0187],
        [-0.0036,  0.0278,  0.0139,  ..., -0.0090,  0.0047, -0.0699]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-03 03:39:50 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When something is adding, it adds
When something is sitting, it sits
When something is continuing, it continues
When something is creating, it creates
When something is discovering, it discovers
When something is receiving, it receives
When something is referring, it refers
When something is considering, it
2024-07-03 03:39:50 root INFO     h_layer_name='transformer.h.5.ln_1' z_layer_name='transformer.h.27'
2024-07-03 03:39:50 root INFO     [order_1_approx] starting weight calculation for When something is referring, it refers
When something is adding, it adds
When something is sitting, it sits
When something is creating, it creates
When something is discovering, it discovers
When something is receiving, it receives
When something is considering, it considers
When something is continuing, it
2024-07-03 03:39:50 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5.ln_1
2024-07-03 03:43:53 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0120, -0.0024,  0.0034,  ...,  0.0057, -0.0104,  0.0092],
        [-0.0111,  0.0023, -0.0095,  ...,  0.0046,  0.0003,  0.0054],
        [-0.0045,  0.0017,  0.0059,  ...,  0.0002,  0.0132,  0.0018],
        ...,
        [ 0.0153, -0.0050, -0.0037,  ...,  0.0088,  0.0041,  0.0133],
        [ 0.0002,  0.0151, -0.0112,  ..., -0.0065, -0.0083, -0.0057],
        [ 0.0066, -0.0139,  0.0193,  ...,  0.0144,  0.0101, -0.0170]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-03 03:43:53 root INFO     h_layer_name='transformer.h.5' z_layer_name='transformer.h.27'
2024-07-03 03:43:54 root INFO     [order_1_approx] starting weight calculation for When something is referring, it refers
When something is adding, it adds
When something is sitting, it sits
When something is creating, it creates
When something is discovering, it discovers
When something is receiving, it receives
When something is considering, it considers
When something is continuing, it
2024-07-03 03:43:54 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5
2024-07-03 03:47:50 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0523, -0.0379,  0.0186,  ..., -0.0037, -0.0041, -0.0224],
        [-0.0010, -0.0301, -0.0094,  ..., -0.0084,  0.0022, -0.0114],
        [ 0.0068, -0.0092, -0.0419,  ...,  0.0022,  0.0122,  0.0186],
        ...,
        [-0.0255,  0.0044, -0.0162,  ..., -0.0524, -0.0082, -0.0009],
        [ 0.0040,  0.0120,  0.0110,  ..., -0.0217, -0.0414,  0.0227],
        [-0.0114,  0.0353,  0.0210,  ..., -0.0401,  0.0134, -0.0580]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-03 03:47:51 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When something is referring, it refers
When something is adding, it adds
When something is sitting, it sits
When something is creating, it creates
When something is discovering, it discovers
When something is receiving, it receives
When something is considering, it considers
When something is continuing, it
2024-07-03 03:47:51 root INFO     h_layer_name='transformer.h.5.ln_1' z_layer_name='transformer.h.27'
2024-07-03 03:47:51 root INFO     [order_1_approx] starting weight calculation for When something is continuing, it continues
When something is creating, it creates
When something is discovering, it discovers
When something is referring, it refers
When something is adding, it adds
When something is sitting, it sits
When something is considering, it considers
When something is receiving, it
2024-07-03 03:47:51 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5.ln_1
2024-07-03 03:51:56 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0087, -0.0022,  0.0181,  ..., -0.0061, -0.0124,  0.0012],
        [-0.0101,  0.0066, -0.0026,  ..., -0.0021, -0.0025,  0.0033],
        [-0.0105,  0.0019, -0.0099,  ...,  0.0149,  0.0025, -0.0068],
        ...,
        [-0.0013, -0.0050, -0.0004,  ..., -0.0072, -0.0118,  0.0114],
        [ 0.0006,  0.0124,  0.0107,  ..., -0.0063,  0.0020, -0.0010],
        [-0.0007, -0.0102,  0.0019,  ..., -0.0043,  0.0066, -0.0070]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-03 03:51:57 root INFO     h_layer_name='transformer.h.5' z_layer_name='transformer.h.27'
2024-07-03 03:51:57 root INFO     [order_1_approx] starting weight calculation for When something is continuing, it continues
When something is creating, it creates
When something is discovering, it discovers
When something is referring, it refers
When something is adding, it adds
When something is sitting, it sits
When something is considering, it considers
When something is receiving, it
2024-07-03 03:51:57 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5
2024-07-03 03:55:53 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0380, -0.0245,  0.0033,  ..., -0.0131, -0.0116, -0.0293],
        [ 0.0120, -0.0176,  0.0113,  ..., -0.0010,  0.0050, -0.0044],
        [ 0.0064, -0.0083,  0.0009,  ..., -0.0042, -0.0045,  0.0165],
        ...,
        [-0.0024, -0.0099, -0.0353,  ..., -0.0186,  0.0072, -0.0212],
        [ 0.0069,  0.0062, -0.0050,  ..., -0.0061, -0.0307,  0.0135],
        [-0.0102,  0.0059,  0.0164,  ..., -0.0051, -0.0003, -0.0283]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-03 03:55:53 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When something is continuing, it continues
When something is creating, it creates
When something is discovering, it discovers
When something is referring, it refers
When something is adding, it adds
When something is sitting, it sits
When something is considering, it considers
When something is receiving, it
2024-07-03 03:55:54 root INFO     h_layer_name='transformer.h.5.ln_1' z_layer_name='transformer.h.27'
2024-07-03 03:55:54 root INFO     [order_1_approx] starting weight calculation for When something is adding, it adds
When something is referring, it refers
When something is receiving, it receives
When something is sitting, it sits
When something is discovering, it discovers
When something is considering, it considers
When something is continuing, it continues
When something is creating, it
2024-07-03 03:55:54 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5.ln_1
2024-07-03 03:59:58 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 0.0058,  0.0063,  0.0004,  ..., -0.0047, -0.0077, -0.0043],
        [-0.0041, -0.0017, -0.0075,  ...,  0.0068, -0.0086, -0.0012],
        [-0.0091,  0.0092,  0.0006,  ...,  0.0131,  0.0056,  0.0072],
        ...,
        [ 0.0105,  0.0069, -0.0106,  ..., -0.0120,  0.0024,  0.0110],
        [-0.0069, -0.0031, -0.0004,  ..., -0.0027, -0.0082, -0.0131],
        [ 0.0095, -0.0080,  0.0055,  ...,  0.0045,  0.0020, -0.0027]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-03 03:59:59 root INFO     h_layer_name='transformer.h.5' z_layer_name='transformer.h.27'
2024-07-03 03:59:59 root INFO     [order_1_approx] starting weight calculation for When something is adding, it adds
When something is referring, it refers
When something is receiving, it receives
When something is sitting, it sits
When something is discovering, it discovers
When something is considering, it considers
When something is continuing, it continues
When something is creating, it
2024-07-03 04:00:00 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5
2024-07-03 04:03:55 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0335, -0.0213,  0.0198,  ...,  0.0209,  0.0009, -0.0267],
        [-0.0145, -0.0102,  0.0073,  ..., -0.0094, -0.0103, -0.0216],
        [-0.0025, -0.0116, -0.0166,  ...,  0.0054,  0.0023,  0.0016],
        ...,
        [-0.0108,  0.0003, -0.0150,  ..., -0.0190, -0.0060, -0.0142],
        [ 0.0047,  0.0231, -0.0014,  ..., -0.0116, -0.0561, -0.0001],
        [-0.0171,  0.0011,  0.0182,  ..., -0.0042,  0.0014, -0.0443]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-03 04:03:56 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When something is adding, it adds
When something is referring, it refers
When something is receiving, it receives
When something is sitting, it sits
When something is discovering, it discovers
When something is considering, it considers
When something is continuing, it continues
When something is creating, it
2024-07-03 04:03:56 root INFO     h_layer_name='transformer.h.5.ln_1' z_layer_name='transformer.h.27'
2024-07-03 04:03:56 root INFO     [order_1_approx] starting weight calculation for When something is receiving, it receives
When something is creating, it creates
When something is considering, it considers
When something is referring, it refers
When something is continuing, it continues
When something is discovering, it discovers
When something is sitting, it sits
When something is adding, it
2024-07-03 04:03:56 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5.ln_1
2024-07-03 04:08:02 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-3.3035e-03, -3.5000e-03,  1.0132e-02,  ...,  2.8000e-03,
         -4.1676e-04, -1.0666e-02],
        [-1.9245e-03,  7.1983e-03, -1.8120e-04,  ...,  1.0738e-03,
         -2.1744e-03,  3.5667e-03],
        [ 2.1000e-03,  5.5771e-03,  1.0376e-02,  ...,  4.5471e-03,
         -9.5463e-04,  8.1177e-03],
        ...,
        [ 6.3992e-04,  9.1095e-03, -3.6736e-03,  ...,  1.4982e-03,
          8.5592e-04,  2.3499e-03],
        [ 1.9979e-04,  6.5231e-03, -2.0142e-03,  ..., -7.2594e-03,
         -3.3989e-03,  9.0313e-04],
        [-7.5035e-03,  4.6082e-03,  6.8665e-05,  ...,  1.4477e-03,
          8.7128e-03, -9.8114e-03]], device='cuda:0', dtype=torch.float16) 

                    
2024-07-03 04:08:03 root INFO     h_layer_name='transformer.h.5' z_layer_name='transformer.h.27'
2024-07-03 04:08:03 root INFO     [order_1_approx] starting weight calculation for When something is receiving, it receives
When something is creating, it creates
When something is considering, it considers
When something is referring, it refers
When something is continuing, it continues
When something is discovering, it discovers
When something is sitting, it sits
When something is adding, it
2024-07-03 04:08:03 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5
2024-07-03 04:11:59 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0251, -0.0078,  0.0147,  ...,  0.0096, -0.0185, -0.0176],
        [-0.0005, -0.0377,  0.0082,  ...,  0.0044,  0.0036, -0.0048],
        [-0.0049, -0.0003, -0.0208,  ...,  0.0072,  0.0023,  0.0013],
        ...,
        [-0.0120, -0.0110, -0.0065,  ..., -0.0199,  0.0109,  0.0083],
        [ 0.0030, -0.0104,  0.0064,  ..., -0.0070, -0.0479, -0.0147],
        [-0.0028,  0.0054, -0.0179,  ..., -0.0112, -0.0157, -0.0310]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-03 04:12:00 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When something is receiving, it receives
When something is creating, it creates
When something is considering, it considers
When something is referring, it refers
When something is continuing, it continues
When something is discovering, it discovers
When something is sitting, it sits
When something is adding, it
2024-07-03 04:12:00 root INFO     h_layer_name='transformer.h.5.ln_1' z_layer_name='transformer.h.27'
2024-07-03 04:12:00 root INFO     [order_1_approx] starting weight calculation for When something is discovering, it discovers
When something is considering, it considers
When something is continuing, it continues
When something is adding, it adds
When something is referring, it refers
When something is creating, it creates
When something is receiving, it receives
When something is sitting, it
2024-07-03 04:12:00 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5.ln_1
2024-07-03 04:16:03 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0025,  0.0048,  0.0086,  ..., -0.0044,  0.0049, -0.0003],
        [-0.0008,  0.0004,  0.0005,  ...,  0.0043,  0.0079,  0.0029],
        [ 0.0057, -0.0034, -0.0102,  ...,  0.0024,  0.0154,  0.0020],
        ...,
        [ 0.0067, -0.0012,  0.0108,  ...,  0.0068, -0.0004, -0.0062],
        [-0.0031,  0.0026, -0.0017,  ...,  0.0028, -0.0121,  0.0022],
        [-0.0010, -0.0075,  0.0054,  ..., -0.0115, -0.0098, -0.0163]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-03 04:16:04 root INFO     h_layer_name='transformer.h.5' z_layer_name='transformer.h.27'
2024-07-03 04:16:04 root INFO     [order_1_approx] starting weight calculation for When something is discovering, it discovers
When something is considering, it considers
When something is continuing, it continues
When something is adding, it adds
When something is referring, it refers
When something is creating, it creates
When something is receiving, it receives
When something is sitting, it
2024-07-03 04:16:04 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5
2024-07-03 04:20:01 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0411, -0.0401,  0.0126,  ...,  0.0232, -0.0277, -0.0127],
        [ 0.0007, -0.0218, -0.0220,  ...,  0.0016, -0.0020, -0.0087],
        [-0.0222, -0.0026, -0.0158,  ...,  0.0170, -0.0222,  0.0090],
        ...,
        [-0.0105, -0.0011, -0.0193,  ..., -0.0680,  0.0147,  0.0097],
        [-0.0169,  0.0043,  0.0152,  ..., -0.0013, -0.0502, -0.0271],
        [-0.0094,  0.0155,  0.0103,  ..., -0.0179, -0.0071, -0.0472]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-03 04:20:02 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When something is discovering, it discovers
When something is considering, it considers
When something is continuing, it continues
When something is adding, it adds
When something is referring, it refers
When something is creating, it creates
When something is receiving, it receives
When something is sitting, it
2024-07-03 04:20:02 root INFO     total operator prediction time: 3851.994194507599 seconds
2024-07-03 04:20:02 __main__ INFO     starting test: <class 'lre.operators.JacobianIclMeanEstimator'> on adj+ness_reg
2024-07-03 04:20:04 root INFO     building operator adj+ness_reg
2024-07-03 04:20:04 root INFO     h_layer_name='transformer.h.5.ln_1' z_layer_name='transformer.h.27'
2024-07-03 04:20:04 root INFO     [order_1_approx] starting weight calculation for The state of being unique is uniqueness
The state of being strange is strangeness
The state of being obvious is obviousness
The state of being attractive is attractiveness
The state of being happy is happiness
The state of being creative is creativeness
The state of being prepared is preparedness
The state of being random is
2024-07-03 04:20:04 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5.ln_1
2024-07-03 04:24:08 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 1.2238e-02,  1.6678e-02, -5.6267e-04,  ...,  2.2144e-03,
          6.5041e-03, -3.9749e-03],
        [ 1.9775e-02,  6.3629e-03,  3.7556e-03,  ...,  4.9667e-03,
         -6.1798e-03,  1.1353e-02],
        [ 3.0651e-03,  5.7507e-04,  4.4136e-03,  ...,  8.0109e-03,
         -1.7910e-03,  2.5234e-03],
        ...,
        [-1.0887e-02,  1.4496e-03, -1.1978e-02,  ...,  7.6294e-06,
          1.0612e-02,  1.3763e-02],
        [ 1.2909e-02, -3.9029e-04, -9.8877e-03,  ..., -1.0216e-02,
         -2.2621e-03,  6.6185e-03],
        [ 1.1787e-02,  1.0910e-03,  2.0638e-03,  ..., -1.5930e-02,
         -6.5422e-03,  5.0507e-03]], device='cuda:0', dtype=torch.float16) 

                    
2024-07-03 04:24:09 root INFO     h_layer_name='transformer.h.5' z_layer_name='transformer.h.27'
2024-07-03 04:24:09 root INFO     [order_1_approx] starting weight calculation for The state of being unique is uniqueness
The state of being strange is strangeness
The state of being obvious is obviousness
The state of being attractive is attractiveness
The state of being happy is happiness
The state of being creative is creativeness
The state of being prepared is preparedness
The state of being random is
2024-07-03 04:24:09 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5
2024-07-03 04:28:04 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0123, -0.0254, -0.0032,  ..., -0.0162, -0.0140, -0.0458],
        [-0.0202, -0.0156,  0.0073,  ...,  0.0207, -0.0207, -0.0219],
        [ 0.0108, -0.0374, -0.0117,  ...,  0.0201, -0.0037,  0.0157],
        ...,
        [-0.0217,  0.0057,  0.0017,  ..., -0.0368,  0.0209,  0.0024],
        [ 0.0095, -0.0298,  0.0161,  ..., -0.0087, -0.0238,  0.0352],
        [ 0.0057,  0.0194,  0.0103,  ...,  0.0090,  0.0035, -0.0401]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-03 04:28:05 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The state of being unique is uniqueness
The state of being strange is strangeness
The state of being obvious is obviousness
The state of being attractive is attractiveness
The state of being happy is happiness
The state of being creative is creativeness
The state of being prepared is preparedness
The state of being random is
2024-07-03 04:28:05 root INFO     h_layer_name='transformer.h.5.ln_1' z_layer_name='transformer.h.27'
2024-07-03 04:28:05 root INFO     [order_1_approx] starting weight calculation for The state of being attractive is attractiveness
The state of being obvious is obviousness
The state of being random is randomness
The state of being prepared is preparedness
The state of being strange is strangeness
The state of being unique is uniqueness
The state of being happy is happiness
The state of being creative is
2024-07-03 04:28:05 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5.ln_1
2024-07-03 04:32:09 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-5.3215e-03,  1.0277e-02,  1.5198e-02,  ...,  2.3127e-04,
         -1.5732e-02,  3.1328e-04],
        [-1.0147e-02, -8.2541e-04,  1.0128e-03,  ...,  1.3208e-03,
         -1.3456e-03, -1.7500e-03],
        [-3.9864e-04,  1.2337e-02,  7.6828e-03,  ...,  9.0942e-03,
          9.3079e-03,  1.4753e-03],
        ...,
        [ 6.5269e-03, -1.0437e-02,  7.1297e-03,  ...,  2.6379e-03,
         -8.9645e-05,  2.2297e-03],
        [-3.5419e-03, -5.3024e-04, -5.3062e-03,  ..., -8.3313e-03,
          4.6768e-03, -5.2299e-03],
        [-4.0398e-03, -5.8861e-03, -8.7509e-03,  ..., -1.2604e-02,
         -2.2888e-04, -1.1969e-03]], device='cuda:0', dtype=torch.float16) 

                    
2024-07-03 04:32:10 root INFO     h_layer_name='transformer.h.5' z_layer_name='transformer.h.27'
2024-07-03 04:32:10 root INFO     [order_1_approx] starting weight calculation for The state of being attractive is attractiveness
The state of being obvious is obviousness
The state of being random is randomness
The state of being prepared is preparedness
The state of being strange is strangeness
The state of being unique is uniqueness
The state of being happy is happiness
The state of being creative is
2024-07-03 04:32:10 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5
2024-07-03 04:36:06 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0131, -0.0370,  0.0017,  ...,  0.0016,  0.0132, -0.0190],
        [-0.0055, -0.0137,  0.0096,  ...,  0.0050,  0.0065,  0.0037],
        [ 0.0019, -0.0151, -0.0342,  ...,  0.0001, -0.0006,  0.0106],
        ...,
        [-0.0133, -0.0078,  0.0014,  ..., -0.0188,  0.0031, -0.0087],
        [-0.0115, -0.0143,  0.0024,  ..., -0.0064, -0.0289,  0.0072],
        [-0.0042,  0.0080, -0.0099,  ...,  0.0013,  0.0073, -0.0481]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-03 04:36:07 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The state of being attractive is attractiveness
The state of being obvious is obviousness
The state of being random is randomness
The state of being prepared is preparedness
The state of being strange is strangeness
The state of being unique is uniqueness
The state of being happy is happiness
The state of being creative is
2024-07-03 04:36:07 root INFO     h_layer_name='transformer.h.5.ln_1' z_layer_name='transformer.h.27'
2024-07-03 04:36:07 root INFO     [order_1_approx] starting weight calculation for The state of being happy is happiness
The state of being attractive is attractiveness
The state of being obvious is obviousness
The state of being strange is strangeness
The state of being random is randomness
The state of being creative is creativeness
The state of being prepared is preparedness
The state of being unique is
2024-07-03 04:36:07 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5.ln_1
2024-07-03 04:40:11 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0050,  0.0034, -0.0043,  ..., -0.0070, -0.0108, -0.0029],
        [-0.0031, -0.0036, -0.0039,  ...,  0.0101,  0.0001,  0.0013],
        [ 0.0157,  0.0069,  0.0097,  ..., -0.0019,  0.0020,  0.0002],
        ...,
        [ 0.0027,  0.0012,  0.0068,  ..., -0.0024, -0.0018,  0.0007],
        [-0.0013,  0.0122, -0.0166,  ..., -0.0138,  0.0031, -0.0007],
        [ 0.0077, -0.0153,  0.0071,  ..., -0.0173, -0.0103, -0.0011]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-03 04:40:12 root INFO     h_layer_name='transformer.h.5' z_layer_name='transformer.h.27'
2024-07-03 04:40:12 root INFO     [order_1_approx] starting weight calculation for The state of being happy is happiness
The state of being attractive is attractiveness
The state of being obvious is obviousness
The state of being strange is strangeness
The state of being random is randomness
The state of being creative is creativeness
The state of being prepared is preparedness
The state of being unique is
2024-07-03 04:40:12 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5
2024-07-03 04:44:08 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0060, -0.0376,  0.0101,  ..., -0.0144, -0.0060, -0.0303],
        [-0.0032, -0.0007, -0.0104,  ...,  0.0267,  0.0119, -0.0072],
        [ 0.0003,  0.0098, -0.0269,  ...,  0.0123, -0.0048,  0.0164],
        ...,
        [ 0.0067, -0.0133,  0.0025,  ..., -0.0241,  0.0010, -0.0237],
        [-0.0094,  0.0016,  0.0032,  ..., -0.0120, -0.0305,  0.0199],
        [ 0.0120,  0.0282, -0.0130,  ..., -0.0392,  0.0184, -0.0488]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-03 04:44:09 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The state of being happy is happiness
The state of being attractive is attractiveness
The state of being obvious is obviousness
The state of being strange is strangeness
The state of being random is randomness
The state of being creative is creativeness
The state of being prepared is preparedness
The state of being unique is
2024-07-03 04:44:09 root INFO     h_layer_name='transformer.h.5.ln_1' z_layer_name='transformer.h.27'
2024-07-03 04:44:09 root INFO     [order_1_approx] starting weight calculation for The state of being happy is happiness
The state of being obvious is obviousness
The state of being strange is strangeness
The state of being unique is uniqueness
The state of being attractive is attractiveness
The state of being creative is creativeness
The state of being random is randomness
The state of being prepared is
2024-07-03 04:44:09 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5.ln_1
2024-07-03 04:48:15 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 0.0138,  0.0111, -0.0068,  ..., -0.0040,  0.0040,  0.0084],
        [-0.0052,  0.0014, -0.0107,  ...,  0.0089,  0.0029,  0.0043],
        [ 0.0075,  0.0056, -0.0008,  ...,  0.0113,  0.0057, -0.0018],
        ...,
        [ 0.0043, -0.0096,  0.0111,  ...,  0.0095,  0.0003, -0.0059],
        [-0.0066, -0.0010, -0.0030,  ..., -0.0148,  0.0084, -0.0103],
        [ 0.0012, -0.0097, -0.0021,  ...,  0.0058,  0.0056, -0.0053]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-03 04:48:16 root INFO     h_layer_name='transformer.h.5' z_layer_name='transformer.h.27'
2024-07-03 04:48:16 root INFO     [order_1_approx] starting weight calculation for The state of being happy is happiness
The state of being obvious is obviousness
The state of being strange is strangeness
The state of being unique is uniqueness
The state of being attractive is attractiveness
The state of being creative is creativeness
The state of being random is randomness
The state of being prepared is
2024-07-03 04:48:16 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5
2024-07-03 04:52:12 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 0.0090, -0.0382,  0.0153,  ...,  0.0086, -0.0134, -0.0075],
        [-0.0141,  0.0108, -0.0020,  ..., -0.0028, -0.0100, -0.0097],
        [ 0.0180,  0.0005,  0.0150,  ...,  0.0179, -0.0099,  0.0038],
        ...,
        [-0.0197, -0.0165,  0.0024,  ..., -0.0222, -0.0171, -0.0011],
        [-0.0011,  0.0018,  0.0253,  ..., -0.0009, -0.0159,  0.0027],
        [-0.0115,  0.0178,  0.0062,  ..., -0.0098,  0.0206, -0.0332]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-03 04:52:12 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The state of being happy is happiness
The state of being obvious is obviousness
The state of being strange is strangeness
The state of being unique is uniqueness
The state of being attractive is attractiveness
The state of being creative is creativeness
The state of being random is randomness
The state of being prepared is
2024-07-03 04:52:13 root INFO     h_layer_name='transformer.h.5.ln_1' z_layer_name='transformer.h.27'
2024-07-03 04:52:13 root INFO     [order_1_approx] starting weight calculation for The state of being strange is strangeness
The state of being happy is happiness
The state of being creative is creativeness
The state of being obvious is obviousness
The state of being prepared is preparedness
The state of being unique is uniqueness
The state of being random is randomness
The state of being attractive is
2024-07-03 04:52:13 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5.ln_1
2024-07-03 04:56:17 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-1.2493e-03, -6.2408e-03, -1.1253e-02,  ...,  2.4357e-03,
         -1.7242e-02, -8.1253e-03],
        [-4.4594e-03,  1.1047e-02,  5.9853e-03,  ..., -1.9283e-03,
          7.6294e-05,  4.6120e-03],
        [ 3.2005e-03, -1.2264e-03,  3.9940e-03,  ...,  3.9024e-03,
          4.1122e-03, -1.1765e-02],
        ...,
        [ 2.9793e-03,  8.7585e-03,  3.0899e-03,  ...,  7.2365e-03,
         -2.7714e-03,  1.4725e-02],
        [-7.0190e-03, -6.6376e-03, -1.1040e-02,  ..., -8.8501e-03,
          5.0850e-03, -2.7027e-03],
        [ 1.1673e-02, -2.5986e-02,  7.6675e-04,  ..., -1.7624e-02,
         -4.2953e-03, -3.5934e-03]], device='cuda:0', dtype=torch.float16) 

                    
2024-07-03 04:56:18 root INFO     h_layer_name='transformer.h.5' z_layer_name='transformer.h.27'
2024-07-03 04:56:18 root INFO     [order_1_approx] starting weight calculation for The state of being strange is strangeness
The state of being happy is happiness
The state of being creative is creativeness
The state of being obvious is obviousness
The state of being prepared is preparedness
The state of being unique is uniqueness
The state of being random is randomness
The state of being attractive is
2024-07-03 04:56:18 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5
2024-07-03 05:00:13 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0171, -0.0042,  0.0050,  ..., -0.0031, -0.0159, -0.0302],
        [ 0.0017, -0.0082,  0.0053,  ..., -0.0100,  0.0094, -0.0061],
        [-0.0206,  0.0128, -0.0335,  ...,  0.0250, -0.0173,  0.0032],
        ...,
        [-0.0239, -0.0357,  0.0012,  ..., -0.0375, -0.0115, -0.0264],
        [-0.0092, -0.0100,  0.0214,  ..., -0.0225, -0.0619,  0.0013],
        [-0.0132,  0.0263, -0.0084,  ..., -0.0091, -0.0275, -0.0641]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-03 05:00:14 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The state of being strange is strangeness
The state of being happy is happiness
The state of being creative is creativeness
The state of being obvious is obviousness
The state of being prepared is preparedness
The state of being unique is uniqueness
The state of being random is randomness
The state of being attractive is
2024-07-03 05:00:14 root INFO     h_layer_name='transformer.h.5.ln_1' z_layer_name='transformer.h.27'
2024-07-03 05:00:14 root INFO     [order_1_approx] starting weight calculation for The state of being random is randomness
The state of being prepared is preparedness
The state of being unique is uniqueness
The state of being happy is happiness
The state of being attractive is attractiveness
The state of being creative is creativeness
The state of being obvious is obviousness
The state of being strange is
2024-07-03 05:00:14 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5.ln_1
2024-07-03 05:04:19 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0107,  0.0052, -0.0018,  ..., -0.0053,  0.0011, -0.0081],
        [-0.0010,  0.0009,  0.0066,  ...,  0.0034,  0.0105,  0.0075],
        [ 0.0058,  0.0015,  0.0062,  ...,  0.0059,  0.0189, -0.0115],
        ...,
        [ 0.0038, -0.0144,  0.0048,  ...,  0.0069,  0.0053, -0.0039],
        [-0.0042,  0.0059, -0.0142,  ..., -0.0120, -0.0113,  0.0178],
        [ 0.0046, -0.0179,  0.0168,  ..., -0.0203, -0.0068, -0.0049]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-03 05:04:20 root INFO     h_layer_name='transformer.h.5' z_layer_name='transformer.h.27'
2024-07-03 05:04:20 root INFO     [order_1_approx] starting weight calculation for The state of being random is randomness
The state of being prepared is preparedness
The state of being unique is uniqueness
The state of being happy is happiness
The state of being attractive is attractiveness
The state of being creative is creativeness
The state of being obvious is obviousness
The state of being strange is
2024-07-03 05:04:20 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5
2024-07-03 05:08:16 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0009, -0.0359,  0.0122,  ..., -0.0084, -0.0069, -0.0270],
        [-0.0104, -0.0296, -0.0054,  ...,  0.0075, -0.0129, -0.0021],
        [-0.0073, -0.0204, -0.0309,  ...,  0.0377, -0.0162,  0.0268],
        ...,
        [ 0.0105, -0.0216,  0.0055,  ..., -0.0347, -0.0018, -0.0067],
        [-0.0032,  0.0111,  0.0289,  ..., -0.0291, -0.0353,  0.0111],
        [-0.0227,  0.0336, -0.0049,  ..., -0.0332, -0.0371, -0.0579]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-03 05:08:17 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The state of being random is randomness
The state of being prepared is preparedness
The state of being unique is uniqueness
The state of being happy is happiness
The state of being attractive is attractiveness
The state of being creative is creativeness
The state of being obvious is obviousness
The state of being strange is
2024-07-03 05:08:17 root INFO     h_layer_name='transformer.h.5.ln_1' z_layer_name='transformer.h.27'
2024-07-03 05:08:17 root INFO     [order_1_approx] starting weight calculation for The state of being prepared is preparedness
The state of being creative is creativeness
The state of being unique is uniqueness
The state of being random is randomness
The state of being strange is strangeness
The state of being happy is happiness
The state of being attractive is attractiveness
The state of being obvious is
2024-07-03 05:08:17 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5.ln_1
2024-07-03 05:12:20 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-5.0201e-03,  1.4397e-02,  5.7259e-03,  ...,  2.5578e-03,
         -1.2810e-02, -5.6610e-03],
        [-5.2719e-03, -2.8839e-03,  1.4786e-02,  ..., -1.3252e-02,
         -1.2436e-02,  8.0729e-04],
        [-6.3133e-04, -2.0180e-03, -1.4832e-02,  ...,  2.3041e-03,
          4.0207e-03, -1.4679e-02],
        ...,
        [ 3.0537e-03,  1.7746e-02, -1.5930e-02,  ...,  6.8626e-03,
          1.4458e-02, -7.4883e-03],
        [ 5.9013e-03, -8.4152e-03, -2.4872e-02,  ..., -2.2888e-02,
          5.9357e-03,  9.0103e-03],
        [ 2.1362e-02,  2.1343e-03, -1.0338e-02,  ...,  5.9128e-05,
          1.0307e-02, -3.3894e-03]], device='cuda:0', dtype=torch.float16) 

                    
2024-07-03 05:12:21 root INFO     h_layer_name='transformer.h.5' z_layer_name='transformer.h.27'
2024-07-03 05:12:21 root INFO     [order_1_approx] starting weight calculation for The state of being prepared is preparedness
The state of being creative is creativeness
The state of being unique is uniqueness
The state of being random is randomness
The state of being strange is strangeness
The state of being happy is happiness
The state of being attractive is attractiveness
The state of being obvious is
2024-07-03 05:12:21 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5
2024-07-03 05:16:16 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0053, -0.0226, -0.0020,  ..., -0.0056,  0.0022, -0.0268],
        [ 0.0025,  0.0056, -0.0163,  ...,  0.0139, -0.0223, -0.0167],
        [-0.0063, -0.0011, -0.0216,  ...,  0.0275,  0.0136,  0.0037],
        ...,
        [-0.0002, -0.0201, -0.0052,  ..., -0.0347, -0.0003, -0.0233],
        [-0.0062, -0.0078,  0.0047,  ..., -0.0059, -0.0232,  0.0234],
        [-0.0110,  0.0431, -0.0011,  ..., -0.0141,  0.0032, -0.0317]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-03 05:16:17 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The state of being prepared is preparedness
The state of being creative is creativeness
The state of being unique is uniqueness
The state of being random is randomness
The state of being strange is strangeness
The state of being happy is happiness
The state of being attractive is attractiveness
The state of being obvious is
2024-07-03 05:16:17 root INFO     h_layer_name='transformer.h.5.ln_1' z_layer_name='transformer.h.27'
2024-07-03 05:16:17 root INFO     [order_1_approx] starting weight calculation for The state of being attractive is attractiveness
The state of being random is randomness
The state of being prepared is preparedness
The state of being strange is strangeness
The state of being obvious is obviousness
The state of being creative is creativeness
The state of being unique is uniqueness
The state of being happy is
2024-07-03 05:16:17 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5.ln_1
2024-07-03 05:20:21 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0080,  0.0002, -0.0020,  ..., -0.0045, -0.0054, -0.0012],
        [-0.0084,  0.0026,  0.0031,  ..., -0.0001,  0.0021, -0.0027],
        [-0.0018,  0.0095, -0.0015,  ..., -0.0023,  0.0079,  0.0034],
        ...,
        [ 0.0020,  0.0021,  0.0073,  ..., -0.0004, -0.0001,  0.0028],
        [ 0.0027,  0.0091, -0.0002,  ..., -0.0033,  0.0190,  0.0078],
        [-0.0010,  0.0007, -0.0036,  ..., -0.0017, -0.0036,  0.0036]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-03 05:20:22 root INFO     h_layer_name='transformer.h.5' z_layer_name='transformer.h.27'
2024-07-03 05:20:22 root INFO     [order_1_approx] starting weight calculation for The state of being attractive is attractiveness
The state of being random is randomness
The state of being prepared is preparedness
The state of being strange is strangeness
The state of being obvious is obviousness
The state of being creative is creativeness
The state of being unique is uniqueness
The state of being happy is
2024-07-03 05:20:22 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5
2024-07-03 05:24:18 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0137, -0.0185,  0.0021,  ...,  0.0043, -0.0083, -0.0288],
        [ 0.0069, -0.0160,  0.0105,  ...,  0.0050,  0.0038, -0.0038],
        [-0.0021, -0.0084, -0.0201,  ..., -0.0118,  0.0053,  0.0060],
        ...,
        [-0.0122, -0.0260, -0.0133,  ..., -0.0238, -0.0090, -0.0061],
        [-0.0076, -0.0146,  0.0007,  ..., -0.0168, -0.0460,  0.0185],
        [-0.0106,  0.0141,  0.0075,  ..., -0.0150,  0.0045, -0.0533]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-03 05:24:19 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The state of being attractive is attractiveness
The state of being random is randomness
The state of being prepared is preparedness
The state of being strange is strangeness
The state of being obvious is obviousness
The state of being creative is creativeness
The state of being unique is uniqueness
The state of being happy is
2024-07-03 05:24:19 root INFO     total operator prediction time: 3855.048237800598 seconds
2024-07-03 05:24:19 __main__ INFO     starting test: <class 'lre.operators.JacobianIclMeanEstimator'> on name - nationality
2024-07-03 05:24:21 root INFO     building operator name - nationality
2024-07-03 05:24:21 root INFO     h_layer_name='transformer.h.5.ln_1' z_layer_name='transformer.h.27'
2024-07-03 05:24:21 root INFO     [order_1_approx] starting weight calculation for jolie was american
dickens was english
lennon was english
machiavelli was italian
newton was english
descartes was french
hawking was english
euclid was
2024-07-03 05:24:21 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5.ln_1
2024-07-03 05:28:25 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0154, -0.0005,  0.0147,  ..., -0.0140, -0.0158,  0.0039],
        [ 0.0024,  0.0008,  0.0102,  ..., -0.0056, -0.0077, -0.0036],
        [ 0.0101,  0.0069,  0.0254,  ..., -0.0058,  0.0118,  0.0099],
        ...,
        [ 0.0060, -0.0097,  0.0033,  ...,  0.0170,  0.0060,  0.0162],
        [ 0.0063,  0.0010, -0.0129,  ...,  0.0006,  0.0020,  0.0054],
        [-0.0021,  0.0159,  0.0066,  ..., -0.0089, -0.0006,  0.0032]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-03 05:28:26 root INFO     h_layer_name='transformer.h.5' z_layer_name='transformer.h.27'
2024-07-03 05:28:26 root INFO     [order_1_approx] starting weight calculation for jolie was american
dickens was english
lennon was english
machiavelli was italian
newton was english
descartes was french
hawking was english
euclid was
2024-07-03 05:28:26 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5
2024-07-03 05:32:21 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 0.0144, -0.0076, -0.0043,  ..., -0.0151,  0.0295, -0.0142],
        [ 0.0157,  0.0021,  0.0123,  ...,  0.0156, -0.0183, -0.0004],
        [-0.0068, -0.0035,  0.0036,  ..., -0.0204,  0.0020,  0.0086],
        ...,
        [-0.0019, -0.0079,  0.0048,  ...,  0.0153, -0.0257,  0.0090],
        [-0.0051,  0.0076, -0.0129,  ..., -0.0068, -0.0114,  0.0154],
        [ 0.0020,  0.0148, -0.0016,  ..., -0.0140,  0.0029, -0.0316]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-03 05:32:22 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for jolie was american
dickens was english
lennon was english
machiavelli was italian
newton was english
descartes was french
hawking was english
euclid was
2024-07-03 05:32:22 root INFO     h_layer_name='transformer.h.5.ln_1' z_layer_name='transformer.h.27'
2024-07-03 05:32:22 root INFO     [order_1_approx] starting weight calculation for hawking was english
dickens was english
lennon was english
descartes was french
euclid was greek
jolie was american
machiavelli was italian
newton was
2024-07-03 05:32:23 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5.ln_1
2024-07-03 05:36:26 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 0.0138, -0.0095, -0.0081,  ..., -0.0041,  0.0035, -0.0044],
        [ 0.0077,  0.0088,  0.0005,  ...,  0.0059, -0.0116, -0.0047],
        [ 0.0125, -0.0115,  0.0039,  ...,  0.0132,  0.0046, -0.0008],
        ...,
        [-0.0091, -0.0049,  0.0049,  ...,  0.0133, -0.0121, -0.0114],
        [ 0.0047, -0.0029,  0.0030,  ..., -0.0018,  0.0069,  0.0058],
        [-0.0019,  0.0079, -0.0159,  ..., -0.0085,  0.0017, -0.0046]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-03 05:36:27 root INFO     h_layer_name='transformer.h.5' z_layer_name='transformer.h.27'
2024-07-03 05:36:27 root INFO     [order_1_approx] starting weight calculation for hawking was english
dickens was english
lennon was english
descartes was french
euclid was greek
jolie was american
machiavelli was italian
newton was
2024-07-03 05:36:27 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5
2024-07-03 05:40:22 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-1.8707e-02, -1.5335e-02,  4.8447e-03,  ..., -2.2755e-03,
         -1.4725e-02, -1.0056e-02],
        [-1.4448e-04,  2.3743e-02,  1.7258e-02,  ...,  6.8054e-03,
         -4.9210e-03, -7.4806e-03],
        [ 5.5847e-03,  1.1795e-02,  4.5929e-03,  ..., -2.2621e-03,
          6.9199e-03, -8.1940e-03],
        ...,
        [-1.2192e-02,  1.4755e-02,  1.3420e-02,  ...,  2.7542e-03,
         -1.8501e-03,  2.6688e-02],
        [ 7.9918e-04, -6.3553e-03, -1.6388e-02,  ..., -1.1520e-02,
         -2.3468e-02,  1.5045e-02],
        [-6.1035e-03,  1.5259e-05, -7.7209e-03,  ..., -1.7319e-02,
          3.0518e-05, -8.8196e-03]], device='cuda:0', dtype=torch.float16) 

                    
2024-07-03 05:40:23 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for hawking was english
dickens was english
lennon was english
descartes was french
euclid was greek
jolie was american
machiavelli was italian
newton was
2024-07-03 05:40:24 root INFO     h_layer_name='transformer.h.5.ln_1' z_layer_name='transformer.h.27'
2024-07-03 05:40:24 root INFO     [order_1_approx] starting weight calculation for dickens was english
euclid was greek
newton was english
descartes was french
jolie was american
hawking was english
lennon was english
machiavelli was
2024-07-03 05:40:24 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5.ln_1
2024-07-03 05:44:28 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 1.8555e-02,  2.6291e-02, -5.4131e-03,  ..., -1.3237e-02,
          2.2278e-02,  4.9896e-03],
        [-7.8430e-03,  4.8599e-03, -1.9388e-03,  ..., -6.3553e-03,
          3.4332e-05, -1.3399e-03],
        [-4.3602e-03, -7.0648e-03,  2.1992e-03,  ...,  7.1411e-03,
         -1.8139e-03,  4.7874e-03],
        ...,
        [ 5.1880e-03, -9.4795e-04, -2.8038e-03,  ...,  5.7564e-03,
          1.0109e-02, -1.5974e-04],
        [-4.8943e-03,  8.2321e-03, -6.5899e-04,  ...,  6.6414e-03,
         -1.9665e-03,  3.7289e-04],
        [ 1.8219e-02,  9.6512e-03, -1.9547e-02,  ...,  1.5160e-02,
         -2.2869e-03, -5.1575e-03]], device='cuda:0', dtype=torch.float16) 

                    
2024-07-03 05:44:29 root INFO     h_layer_name='transformer.h.5' z_layer_name='transformer.h.27'
2024-07-03 05:44:29 root INFO     [order_1_approx] starting weight calculation for dickens was english
euclid was greek
newton was english
descartes was french
jolie was american
hawking was english
lennon was english
machiavelli was
2024-07-03 05:44:29 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5
2024-07-03 05:48:24 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0382, -0.0155, -0.0005,  ..., -0.0058,  0.0007,  0.0048],
        [ 0.0016,  0.0093,  0.0172,  ...,  0.0138, -0.0100, -0.0019],
        [ 0.0145, -0.0034,  0.0135,  ...,  0.0063,  0.0005,  0.0083],
        ...,
        [-0.0027,  0.0142, -0.0025,  ...,  0.0286, -0.0047,  0.0098],
        [-0.0044, -0.0010, -0.0076,  ..., -0.0116,  0.0013,  0.0004],
        [ 0.0064,  0.0191,  0.0180,  ...,  0.0033,  0.0186, -0.0051]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-03 05:48:25 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for dickens was english
euclid was greek
newton was english
descartes was french
jolie was american
hawking was english
lennon was english
machiavelli was
2024-07-03 05:48:25 root INFO     h_layer_name='transformer.h.5.ln_1' z_layer_name='transformer.h.27'
2024-07-03 05:48:25 root INFO     [order_1_approx] starting weight calculation for machiavelli was italian
hawking was english
jolie was american
newton was english
lennon was english
euclid was greek
dickens was english
descartes was
2024-07-03 05:48:25 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5.ln_1
2024-07-03 05:52:30 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0159,  0.0191,  0.0070,  ...,  0.0057, -0.0074, -0.0105],
        [-0.0126, -0.0070, -0.0100,  ..., -0.0193, -0.0067, -0.0034],
        [-0.0042, -0.0188,  0.0069,  ...,  0.0014, -0.0007, -0.0056],
        ...,
        [-0.0097,  0.0077, -0.0011,  ...,  0.0146, -0.0005, -0.0196],
        [ 0.0050,  0.0123,  0.0121,  ...,  0.0006, -0.0023,  0.0109],
        [ 0.0072,  0.0095,  0.0030,  ..., -0.0017, -0.0058, -0.0189]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-03 05:52:31 root INFO     h_layer_name='transformer.h.5' z_layer_name='transformer.h.27'
2024-07-03 05:52:31 root INFO     [order_1_approx] starting weight calculation for machiavelli was italian
hawking was english
jolie was american
newton was english
lennon was english
euclid was greek
dickens was english
descartes was
2024-07-03 05:52:31 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5
2024-07-03 05:56:26 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-4.9782e-03, -3.5492e-02, -1.2718e-02,  ..., -2.1301e-02,
          1.7899e-02, -1.2207e-02],
        [ 1.6083e-02,  1.2321e-02,  1.6266e-02,  ...,  3.7659e-02,
          3.3455e-03,  5.0125e-03],
        [-1.2749e-02,  1.6693e-02,  8.3923e-05,  ...,  1.0208e-02,
          5.6610e-03,  4.7760e-03],
        ...,
        [-4.0100e-02, -1.0513e-02,  9.2621e-03,  ...,  4.0527e-02,
         -8.0719e-03,  1.8829e-02],
        [ 4.7150e-03, -5.9090e-03, -1.8295e-02,  ..., -1.7456e-02,
         -4.9438e-03, -4.9324e-03],
        [-1.3336e-02,  1.7319e-02,  3.2425e-04,  ..., -1.2436e-03,
         -8.2092e-03, -6.9923e-03]], device='cuda:0', dtype=torch.float16) 

                    
2024-07-03 05:56:27 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for machiavelli was italian
hawking was english
jolie was american
newton was english
lennon was english
euclid was greek
dickens was english
descartes was
2024-07-03 05:56:27 root INFO     h_layer_name='transformer.h.5.ln_1' z_layer_name='transformer.h.27'
2024-07-03 05:56:27 root INFO     [order_1_approx] starting weight calculation for euclid was greek
machiavelli was italian
jolie was american
descartes was french
newton was english
lennon was english
hawking was english
dickens was
2024-07-03 05:56:27 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5.ln_1
2024-07-03 06:00:31 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 0.0079, -0.0016, -0.0081,  ...,  0.0003,  0.0034, -0.0003],
        [-0.0081,  0.0206,  0.0197,  ..., -0.0116,  0.0082,  0.0066],
        [ 0.0004, -0.0133,  0.0058,  ..., -0.0128,  0.0039,  0.0045],
        ...,
        [-0.0165, -0.0046, -0.0054,  ...,  0.0080,  0.0006, -0.0009],
        [-0.0089, -0.0169,  0.0120,  ..., -0.0235, -0.0051, -0.0099],
        [-0.0098, -0.0034, -0.0135,  ...,  0.0002, -0.0025,  0.0008]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-03 06:00:31 root INFO     h_layer_name='transformer.h.5' z_layer_name='transformer.h.27'
2024-07-03 06:00:32 root INFO     [order_1_approx] starting weight calculation for euclid was greek
machiavelli was italian
jolie was american
descartes was french
newton was english
lennon was english
hawking was english
dickens was
2024-07-03 06:00:32 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5
2024-07-03 06:04:27 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0312, -0.0008, -0.0125,  ..., -0.0244, -0.0114,  0.0065],
        [ 0.0218, -0.0064,  0.0136,  ...,  0.0027,  0.0004,  0.0043],
        [-0.0159,  0.0076,  0.0209,  ..., -0.0060,  0.0129, -0.0115],
        ...,
        [-0.0112, -0.0071, -0.0228,  ...,  0.0051, -0.0424,  0.0228],
        [ 0.0014, -0.0357, -0.0134,  ..., -0.0298, -0.0414, -0.0509],
        [-0.0190, -0.0374, -0.0229,  ..., -0.0192, -0.0029, -0.0576]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-03 06:04:28 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for euclid was greek
machiavelli was italian
jolie was american
descartes was french
newton was english
lennon was english
hawking was english
dickens was
2024-07-03 06:04:28 root INFO     h_layer_name='transformer.h.5.ln_1' z_layer_name='transformer.h.27'
2024-07-03 06:04:28 root INFO     [order_1_approx] starting weight calculation for euclid was greek
descartes was french
jolie was american
machiavelli was italian
lennon was english
dickens was english
newton was english
hawking was
2024-07-03 06:04:28 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5.ln_1
2024-07-03 06:08:31 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0287, -0.0077,  0.0133,  ..., -0.0085, -0.0067, -0.0009],
        [-0.0081,  0.0069,  0.0025,  ..., -0.0064, -0.0051,  0.0104],
        [ 0.0051, -0.0389, -0.0163,  ..., -0.0053, -0.0118,  0.0148],
        ...,
        [-0.0315, -0.0084,  0.0012,  ..., -0.0195,  0.0184, -0.0014],
        [-0.0061,  0.0037,  0.0175,  ..., -0.0099, -0.0096, -0.0019],
        [-0.0153, -0.0060, -0.0083,  ..., -0.0255,  0.0185, -0.0075]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-03 06:08:31 root INFO     h_layer_name='transformer.h.5' z_layer_name='transformer.h.27'
2024-07-03 06:08:32 root INFO     [order_1_approx] starting weight calculation for euclid was greek
descartes was french
jolie was american
machiavelli was italian
lennon was english
dickens was english
newton was english
hawking was
2024-07-03 06:08:32 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5
2024-07-03 06:12:26 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 0.0232, -0.0303,  0.0138,  ..., -0.0210,  0.0193, -0.0036],
        [-0.0077,  0.0438,  0.0190,  ...,  0.0385, -0.0143,  0.0057],
        [-0.0094, -0.0159,  0.0049,  ..., -0.0018, -0.0096, -0.0186],
        ...,
        [-0.0008,  0.0169,  0.0274,  ...,  0.0383, -0.0621,  0.0657],
        [ 0.0174, -0.0388,  0.0005,  ..., -0.0204,  0.0420,  0.0288],
        [ 0.0125,  0.0549, -0.0077,  ..., -0.0226,  0.0080,  0.0068]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-03 06:12:27 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for euclid was greek
descartes was french
jolie was american
machiavelli was italian
lennon was english
dickens was english
newton was english
hawking was
2024-07-03 06:12:27 root INFO     h_layer_name='transformer.h.5.ln_1' z_layer_name='transformer.h.27'
2024-07-03 06:12:27 root INFO     [order_1_approx] starting weight calculation for dickens was english
newton was english
hawking was english
lennon was english
descartes was french
euclid was greek
machiavelli was italian
jolie was
2024-07-03 06:12:27 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5.ln_1
2024-07-03 06:16:32 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0002,  0.0010, -0.0107,  ..., -0.0025,  0.0051,  0.0135],
        [ 0.0006,  0.0110, -0.0109,  ...,  0.0002,  0.0102,  0.0011],
        [ 0.0124, -0.0088, -0.0113,  ...,  0.0030,  0.0042, -0.0072],
        ...,
        [-0.0047, -0.0086, -0.0132,  ..., -0.0022,  0.0134, -0.0030],
        [ 0.0082,  0.0019, -0.0047,  ...,  0.0455, -0.0104, -0.0228],
        [-0.0056, -0.0232, -0.0074,  ..., -0.0043, -0.0003, -0.0112]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-03 06:16:33 root INFO     h_layer_name='transformer.h.5' z_layer_name='transformer.h.27'
2024-07-03 06:16:33 root INFO     [order_1_approx] starting weight calculation for dickens was english
newton was english
hawking was english
lennon was english
descartes was french
euclid was greek
machiavelli was italian
jolie was
2024-07-03 06:16:33 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5
2024-07-03 06:20:29 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 0.0233,  0.0071,  0.0189,  ...,  0.0174,  0.0443, -0.0166],
        [-0.0017,  0.0019, -0.0023,  ...,  0.0182,  0.0071, -0.0012],
        [-0.0070, -0.0052,  0.0045,  ..., -0.0124, -0.0246,  0.0026],
        ...,
        [ 0.0251, -0.0286,  0.0222,  ...,  0.0261, -0.0372,  0.0020],
        [ 0.0136, -0.0011, -0.0333,  ..., -0.0238, -0.0182,  0.0030],
        [-0.0154, -0.0139,  0.0099,  ..., -0.0032,  0.0076,  0.0045]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-03 06:20:30 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for dickens was english
newton was english
hawking was english
lennon was english
descartes was french
euclid was greek
machiavelli was italian
jolie was
2024-07-03 06:20:30 root INFO     h_layer_name='transformer.h.5.ln_1' z_layer_name='transformer.h.27'
2024-07-03 06:20:30 root INFO     [order_1_approx] starting weight calculation for euclid was greek
jolie was american
hawking was english
dickens was english
machiavelli was italian
descartes was french
newton was english
lennon was
2024-07-03 06:20:30 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5.ln_1
2024-07-03 06:24:36 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 1.0040e-02, -2.0630e-02,  1.6270e-03,  ..., -6.9618e-04,
         -3.5324e-03,  1.9180e-02],
        [ 3.0518e-05, -1.6647e-02, -1.2772e-02,  ...,  7.5684e-03,
         -2.4281e-03,  5.5351e-03],
        [ 1.1826e-02,  7.4234e-03,  2.2491e-02,  ...,  2.2926e-03,
          6.7425e-04, -5.8441e-03],
        ...,
        [-2.1088e-02, -4.2305e-03,  3.1605e-03,  ...,  1.8829e-02,
          5.0926e-04, -2.8961e-02],
        [-2.6398e-03, -1.9806e-02,  1.8635e-03,  ...,  2.7637e-03,
         -2.5101e-03, -4.9057e-03],
        [ 7.0801e-03, -4.4937e-03, -1.1246e-02,  ..., -7.0305e-03,
         -5.8794e-04,  8.7500e-04]], device='cuda:0', dtype=torch.float16) 

                    
2024-07-03 06:24:37 root INFO     h_layer_name='transformer.h.5' z_layer_name='transformer.h.27'
2024-07-03 06:24:37 root INFO     [order_1_approx] starting weight calculation for euclid was greek
jolie was american
hawking was english
dickens was english
machiavelli was italian
descartes was french
newton was english
lennon was
2024-07-03 06:24:37 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5
2024-07-03 06:28:30 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 2.7275e-04, -5.7564e-03,  3.3436e-03,  ..., -6.2523e-03,
          7.3853e-03,  7.3624e-03],
        [-7.2060e-03,  1.9241e-02, -2.1667e-03,  ...,  1.4763e-02,
         -6.7101e-03, -4.2038e-03],
        [-1.1642e-02,  1.9440e-02, -2.5311e-03,  ...,  2.3670e-03,
          6.0730e-03, -4.9591e-05],
        ...,
        [-3.2990e-02,  8.1825e-04, -4.4327e-03,  ..., -4.3945e-03,
         -2.3621e-02,  1.6022e-02],
        [ 1.4191e-03, -4.5135e-02, -7.7438e-03,  ..., -1.6632e-02,
         -1.7433e-03,  1.2955e-02],
        [-3.0727e-03, -9.7275e-03, -2.3376e-02,  ..., -9.6893e-03,
          9.1019e-03,  4.7798e-03]], device='cuda:0', dtype=torch.float16) 

                    
2024-07-03 06:28:32 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for euclid was greek
jolie was american
hawking was english
dickens was english
machiavelli was italian
descartes was french
newton was english
lennon was
2024-07-03 06:28:32 root INFO     total operator prediction time: 3850.875403404236 seconds
2024-07-03 06:28:32 __main__ INFO     starting test: <class 'lre.operators.JacobianIclMeanEstimator'> on country - language
2024-07-03 06:28:34 root INFO     building operator country - language
2024-07-03 06:28:34 root INFO     h_layer_name='transformer.h.5.ln_1' z_layer_name='transformer.h.27'
2024-07-03 06:28:34 root INFO     [order_1_approx] starting weight calculation for The country of moldova primarily speaks the language of moldovan
The country of kosovo primarily speaks the language of albanian
The country of andorra primarily speaks the language of catalan
The country of belize primarily speaks the language of english
The country of venezuela primarily speaks the language of spanish
The country of guatemala primarily speaks the language of spanish
The country of fiji primarily speaks the language of english
The country of iran primarily speaks the language of
2024-07-03 06:28:34 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5.ln_1
2024-07-03 06:32:37 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-4.5052e-03,  2.2964e-03, -9.6607e-04,  ...,  1.2093e-03,
         -3.9291e-03, -8.9264e-03],
        [-4.6844e-03, -7.7438e-04,  4.4250e-04,  ..., -6.8130e-03,
          2.7542e-03,  1.1501e-03],
        [-5.7173e-04, -7.2212e-03,  3.3379e-03,  ...,  1.2674e-03,
          6.3629e-03, -6.5899e-04],
        ...,
        [-3.9101e-03, -3.0937e-03,  1.0986e-03,  ..., -2.4643e-03,
          1.1513e-02,  4.8180e-03],
        [ 2.7466e-03,  3.0117e-03,  5.0430e-03,  ..., -6.7902e-03,
          1.8330e-03,  4.2191e-03],
        [ 7.3166e-03, -7.4387e-05,  1.7023e-03,  ...,  3.3045e-04,
         -5.4741e-03, -1.2903e-03]], device='cuda:0', dtype=torch.float16) 

                    
2024-07-03 06:32:38 root INFO     h_layer_name='transformer.h.5' z_layer_name='transformer.h.27'
2024-07-03 06:32:38 root INFO     [order_1_approx] starting weight calculation for The country of moldova primarily speaks the language of moldovan
The country of kosovo primarily speaks the language of albanian
The country of andorra primarily speaks the language of catalan
The country of belize primarily speaks the language of english
The country of venezuela primarily speaks the language of spanish
The country of guatemala primarily speaks the language of spanish
The country of fiji primarily speaks the language of english
The country of iran primarily speaks the language of
2024-07-03 06:32:38 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5
2024-07-03 06:36:33 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0235, -0.0104, -0.0098,  ...,  0.0031,  0.0105,  0.0112],
        [ 0.0013,  0.0012, -0.0059,  ...,  0.0014,  0.0061, -0.0036],
        [ 0.0027,  0.0155, -0.0117,  ..., -0.0081, -0.0015, -0.0071],
        ...,
        [ 0.0040,  0.0078, -0.0047,  ...,  0.0074, -0.0029, -0.0197],
        [-0.0107, -0.0012,  0.0038,  ..., -0.0091, -0.0135, -0.0022],
        [-0.0032,  0.0070,  0.0141,  ...,  0.0047,  0.0040, -0.0114]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-03 06:36:34 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country of moldova primarily speaks the language of moldovan
The country of kosovo primarily speaks the language of albanian
The country of andorra primarily speaks the language of catalan
The country of belize primarily speaks the language of english
The country of venezuela primarily speaks the language of spanish
The country of guatemala primarily speaks the language of spanish
The country of fiji primarily speaks the language of english
The country of iran primarily speaks the language of
2024-07-03 06:36:35 root INFO     h_layer_name='transformer.h.5.ln_1' z_layer_name='transformer.h.27'
2024-07-03 06:36:35 root INFO     [order_1_approx] starting weight calculation for The country of guatemala primarily speaks the language of spanish
The country of moldova primarily speaks the language of moldovan
The country of kosovo primarily speaks the language of albanian
The country of fiji primarily speaks the language of english
The country of andorra primarily speaks the language of catalan
The country of venezuela primarily speaks the language of spanish
The country of iran primarily speaks the language of persian
The country of belize primarily speaks the language of
2024-07-03 06:36:35 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5.ln_1
2024-07-03 06:40:41 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 3.8490e-03, -2.1515e-02,  1.1969e-03,  ..., -1.2352e-02,
          1.8021e-02,  6.3896e-05],
        [-3.3379e-03,  2.0493e-02,  2.3460e-03,  ...,  3.3150e-03,
          1.8326e-02,  9.9716e-03],
        [ 4.1046e-03,  5.4207e-03,  4.5547e-03,  ..., -1.6308e-03,
          1.2260e-02,  2.1729e-02],
        ...,
        [ 5.5847e-03, -6.3629e-03, -3.9787e-03,  ...,  1.1261e-02,
         -2.1576e-02, -1.7792e-02],
        [-2.7199e-03, -8.1024e-03,  2.0782e-02,  ..., -3.6945e-03,
          1.7357e-04,  1.3359e-02],
        [-7.6771e-04,  6.4316e-03, -1.9211e-02,  ...,  3.2257e-02,
         -1.1856e-02, -1.5030e-02]], device='cuda:0', dtype=torch.float16) 

                    
2024-07-03 06:40:42 root INFO     h_layer_name='transformer.h.5' z_layer_name='transformer.h.27'
2024-07-03 06:40:42 root INFO     [order_1_approx] starting weight calculation for The country of guatemala primarily speaks the language of spanish
The country of moldova primarily speaks the language of moldovan
The country of kosovo primarily speaks the language of albanian
The country of fiji primarily speaks the language of english
The country of andorra primarily speaks the language of catalan
The country of venezuela primarily speaks the language of spanish
The country of iran primarily speaks the language of persian
The country of belize primarily speaks the language of
2024-07-03 06:40:42 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5
2024-07-03 06:44:38 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0006, -0.0240,  0.0050,  ...,  0.0163,  0.0102,  0.0196],
        [ 0.0205,  0.0386,  0.0107,  ..., -0.0250,  0.0054,  0.0049],
        [-0.0188,  0.0237, -0.0153,  ..., -0.0265,  0.0429, -0.0169],
        ...,
        [-0.0251,  0.0065,  0.0241,  ...,  0.0166,  0.0006, -0.0210],
        [-0.0014, -0.0137,  0.0093,  ..., -0.0254, -0.0177, -0.0148],
        [-0.0143,  0.0012, -0.0379,  ..., -0.0134, -0.0274, -0.0224]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-03 06:44:39 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country of guatemala primarily speaks the language of spanish
The country of moldova primarily speaks the language of moldovan
The country of kosovo primarily speaks the language of albanian
The country of fiji primarily speaks the language of english
The country of andorra primarily speaks the language of catalan
The country of venezuela primarily speaks the language of spanish
The country of iran primarily speaks the language of persian
The country of belize primarily speaks the language of
2024-07-03 06:44:39 root INFO     h_layer_name='transformer.h.5.ln_1' z_layer_name='transformer.h.27'
2024-07-03 06:44:39 root INFO     [order_1_approx] starting weight calculation for The country of belize primarily speaks the language of english
The country of kosovo primarily speaks the language of albanian
The country of iran primarily speaks the language of persian
The country of andorra primarily speaks the language of catalan
The country of guatemala primarily speaks the language of spanish
The country of moldova primarily speaks the language of moldovan
The country of fiji primarily speaks the language of english
The country of venezuela primarily speaks the language of
2024-07-03 06:44:39 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5.ln_1
2024-07-03 06:48:45 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 1.8654e-03, -1.3676e-03,  3.6144e-03,  ...,  1.7166e-05,
         -5.0449e-04, -5.3596e-03],
        [-8.1825e-04,  2.1887e-04,  2.2984e-04,  ...,  1.6937e-03,
         -1.1134e-04, -2.7084e-04],
        [-1.0738e-03, -3.1509e-03,  1.7786e-03,  ...,  1.4477e-03,
         -4.4894e-04,  1.3733e-04],
        ...,
        [-5.7983e-04,  1.8978e-04, -1.2398e-05,  ...,  2.3117e-03,
          8.2612e-05, -4.8280e-04],
        [-6.2847e-04,  1.4515e-03, -6.7902e-04,  ..., -1.9369e-03,
          2.9545e-03, -7.2908e-04],
        [-1.9312e-03, -3.7718e-04, -1.5411e-03,  ...,  1.1463e-03,
          4.1819e-04,  9.3937e-04]], device='cuda:0', dtype=torch.float16) 

                    
2024-07-03 06:48:46 root INFO     h_layer_name='transformer.h.5' z_layer_name='transformer.h.27'
2024-07-03 06:48:46 root INFO     [order_1_approx] starting weight calculation for The country of belize primarily speaks the language of english
The country of kosovo primarily speaks the language of albanian
The country of iran primarily speaks the language of persian
The country of andorra primarily speaks the language of catalan
The country of guatemala primarily speaks the language of spanish
The country of moldova primarily speaks the language of moldovan
The country of fiji primarily speaks the language of english
The country of venezuela primarily speaks the language of
2024-07-03 06:48:46 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5
2024-07-03 06:52:41 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0049, -0.0055,  0.0014,  ...,  0.0011, -0.0002,  0.0025],
        [ 0.0027, -0.0025,  0.0032,  ..., -0.0023,  0.0005, -0.0044],
        [-0.0002,  0.0003, -0.0010,  ...,  0.0037,  0.0047, -0.0033],
        ...,
        [-0.0006,  0.0028, -0.0068,  ..., -0.0089,  0.0035, -0.0006],
        [ 0.0004, -0.0019, -0.0044,  ...,  0.0017, -0.0041, -0.0002],
        [ 0.0038, -0.0017, -0.0007,  ..., -0.0036, -0.0025, -0.0043]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-03 06:52:42 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country of belize primarily speaks the language of english
The country of kosovo primarily speaks the language of albanian
The country of iran primarily speaks the language of persian
The country of andorra primarily speaks the language of catalan
The country of guatemala primarily speaks the language of spanish
The country of moldova primarily speaks the language of moldovan
The country of fiji primarily speaks the language of english
The country of venezuela primarily speaks the language of
2024-07-03 06:52:42 root INFO     h_layer_name='transformer.h.5.ln_1' z_layer_name='transformer.h.27'
2024-07-03 06:52:42 root INFO     [order_1_approx] starting weight calculation for The country of kosovo primarily speaks the language of albanian
The country of moldova primarily speaks the language of moldovan
The country of iran primarily speaks the language of persian
The country of guatemala primarily speaks the language of spanish
The country of belize primarily speaks the language of english
The country of fiji primarily speaks the language of english
The country of venezuela primarily speaks the language of spanish
The country of andorra primarily speaks the language of
2024-07-03 06:52:42 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5.ln_1
2024-07-03 06:56:46 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 0.0109, -0.0215, -0.0054,  ...,  0.0151,  0.0232, -0.0125],
        [-0.0046, -0.0185,  0.0165,  ..., -0.0013, -0.0011, -0.0099],
        [-0.0213, -0.0144, -0.0166,  ...,  0.0037,  0.0299, -0.0231],
        ...,
        [-0.0116, -0.0116,  0.0064,  ..., -0.0038, -0.0201, -0.0049],
        [ 0.0092,  0.0030,  0.0149,  ...,  0.0046, -0.0003, -0.0070],
        [ 0.0082,  0.0196, -0.0177,  ...,  0.0064, -0.0023, -0.0175]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-03 06:56:47 root INFO     h_layer_name='transformer.h.5' z_layer_name='transformer.h.27'
2024-07-03 06:56:47 root INFO     [order_1_approx] starting weight calculation for The country of kosovo primarily speaks the language of albanian
The country of moldova primarily speaks the language of moldovan
The country of iran primarily speaks the language of persian
The country of guatemala primarily speaks the language of spanish
The country of belize primarily speaks the language of english
The country of fiji primarily speaks the language of english
The country of venezuela primarily speaks the language of spanish
The country of andorra primarily speaks the language of
2024-07-03 06:56:47 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5
2024-07-03 07:00:44 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0340, -0.0019, -0.0056,  ..., -0.0361,  0.0070,  0.0018],
        [ 0.0026,  0.0067, -0.0217,  ..., -0.0036, -0.0117,  0.0054],
        [-0.0108,  0.0014, -0.0499,  ...,  0.0626, -0.0441, -0.0083],
        ...,
        [-0.0306,  0.0006,  0.0009,  ...,  0.0062,  0.0061, -0.0042],
        [-0.0042,  0.0004,  0.0007,  ..., -0.0085,  0.0195,  0.0020],
        [ 0.0156,  0.0076,  0.0072,  ...,  0.0402,  0.0148, -0.0079]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-03 07:00:45 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country of kosovo primarily speaks the language of albanian
The country of moldova primarily speaks the language of moldovan
The country of iran primarily speaks the language of persian
The country of guatemala primarily speaks the language of spanish
The country of belize primarily speaks the language of english
The country of fiji primarily speaks the language of english
The country of venezuela primarily speaks the language of spanish
The country of andorra primarily speaks the language of
2024-07-03 07:00:45 root INFO     h_layer_name='transformer.h.5.ln_1' z_layer_name='transformer.h.27'
2024-07-03 07:00:45 root INFO     [order_1_approx] starting weight calculation for The country of andorra primarily speaks the language of catalan
The country of guatemala primarily speaks the language of spanish
The country of kosovo primarily speaks the language of albanian
The country of belize primarily speaks the language of english
The country of iran primarily speaks the language of persian
The country of moldova primarily speaks the language of moldovan
The country of venezuela primarily speaks the language of spanish
The country of fiji primarily speaks the language of
2024-07-03 07:00:45 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5.ln_1
2024-07-03 07:04:50 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 3.5954e-03, -1.6136e-03, -1.0109e-03,  ...,  1.0712e-02,
         -1.3351e-04, -3.9520e-03],
        [-1.7303e-02, -1.0468e-02, -8.7738e-05,  ...,  7.6637e-03,
         -7.6981e-03, -5.7030e-03],
        [-2.4033e-03, -3.5458e-03,  6.4888e-03,  ..., -4.7722e-03,
         -1.4290e-02,  6.5422e-04],
        ...,
        [ 8.7967e-03, -8.0643e-03, -1.5457e-02,  ...,  1.8692e-02,
         -6.2943e-03, -5.3787e-03],
        [-1.3123e-02, -3.6602e-03,  1.6342e-02,  ..., -2.8801e-03,
          5.7487e-03, -2.8458e-03],
        [ 7.3891e-03,  8.1062e-05,  5.6171e-04,  ..., -7.2479e-04,
         -3.3691e-02,  2.8992e-03]], device='cuda:0', dtype=torch.float16) 

                    
2024-07-03 07:04:51 root INFO     h_layer_name='transformer.h.5' z_layer_name='transformer.h.27'
2024-07-03 07:04:51 root INFO     [order_1_approx] starting weight calculation for The country of andorra primarily speaks the language of catalan
The country of guatemala primarily speaks the language of spanish
The country of kosovo primarily speaks the language of albanian
The country of belize primarily speaks the language of english
The country of iran primarily speaks the language of persian
The country of moldova primarily speaks the language of moldovan
The country of venezuela primarily speaks the language of spanish
The country of fiji primarily speaks the language of
2024-07-03 07:04:51 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5
2024-07-03 07:08:49 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0213, -0.0176,  0.0194,  ...,  0.0038, -0.0125, -0.0014],
        [ 0.0175, -0.0190, -0.0005,  ..., -0.0180, -0.0121, -0.0035],
        [-0.0081,  0.0086, -0.0382,  ..., -0.0192, -0.0042,  0.0040],
        ...,
        [-0.0056,  0.0080, -0.0157,  ..., -0.0069, -0.0292,  0.0085],
        [-0.0067, -0.0024,  0.0050,  ..., -0.0009, -0.0190, -0.0135],
        [-0.0119,  0.0198, -0.0232,  ..., -0.0132, -0.0198, -0.0103]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-03 07:08:49 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country of andorra primarily speaks the language of catalan
The country of guatemala primarily speaks the language of spanish
The country of kosovo primarily speaks the language of albanian
The country of belize primarily speaks the language of english
The country of iran primarily speaks the language of persian
The country of moldova primarily speaks the language of moldovan
The country of venezuela primarily speaks the language of spanish
The country of fiji primarily speaks the language of
2024-07-03 07:08:50 root INFO     h_layer_name='transformer.h.5.ln_1' z_layer_name='transformer.h.27'
2024-07-03 07:08:50 root INFO     [order_1_approx] starting weight calculation for The country of guatemala primarily speaks the language of spanish
The country of belize primarily speaks the language of english
The country of kosovo primarily speaks the language of albanian
The country of andorra primarily speaks the language of catalan
The country of fiji primarily speaks the language of english
The country of venezuela primarily speaks the language of spanish
The country of iran primarily speaks the language of persian
The country of moldova primarily speaks the language of
2024-07-03 07:08:50 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5.ln_1
2024-07-03 07:12:56 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 8.6212e-03, -1.4679e-02, -1.5541e-02,  ...,  1.3878e-02,
          4.6806e-03,  1.9806e-02],
        [-1.6251e-02,  6.9618e-03,  2.1942e-02,  ..., -2.0798e-02,
          1.9703e-03, -1.7395e-02],
        [ 9.4604e-03, -1.2589e-02,  1.2527e-02,  ...,  1.2497e-02,
         -8.6060e-03,  7.2556e-03],
        ...,
        [-3.0766e-03, -6.6452e-03, -5.4359e-05,  ...,  5.7602e-03,
          4.4060e-04, -1.5526e-02],
        [-3.3722e-02,  1.6052e-02, -1.3504e-02,  ..., -1.5038e-02,
          6.8245e-03,  2.1393e-02],
        [ 7.2746e-03, -6.0768e-03,  4.8599e-03,  ...,  1.1200e-02,
          1.1772e-02,  9.0485e-03]], device='cuda:0', dtype=torch.float16) 

                    
2024-07-03 07:12:57 root INFO     h_layer_name='transformer.h.5' z_layer_name='transformer.h.27'
2024-07-03 07:12:57 root INFO     [order_1_approx] starting weight calculation for The country of guatemala primarily speaks the language of spanish
The country of belize primarily speaks the language of english
The country of kosovo primarily speaks the language of albanian
The country of andorra primarily speaks the language of catalan
The country of fiji primarily speaks the language of english
The country of venezuela primarily speaks the language of spanish
The country of iran primarily speaks the language of persian
The country of moldova primarily speaks the language of
2024-07-03 07:12:57 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5
2024-07-03 07:16:52 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 0.0010, -0.0237, -0.0037,  ...,  0.0173,  0.0054, -0.0238],
        [-0.0139,  0.0059,  0.0004,  ..., -0.0001,  0.0043, -0.0108],
        [-0.0219,  0.0183, -0.0275,  ...,  0.0054, -0.0082,  0.0064],
        ...,
        [-0.0078,  0.0143, -0.0197,  ...,  0.0066, -0.0129,  0.0011],
        [-0.0180, -0.0218, -0.0206,  ...,  0.0022, -0.0180, -0.0221],
        [-0.0148,  0.0052,  0.0110,  ..., -0.0077, -0.0048, -0.0191]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-03 07:16:53 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country of guatemala primarily speaks the language of spanish
The country of belize primarily speaks the language of english
The country of kosovo primarily speaks the language of albanian
The country of andorra primarily speaks the language of catalan
The country of fiji primarily speaks the language of english
The country of venezuela primarily speaks the language of spanish
The country of iran primarily speaks the language of persian
The country of moldova primarily speaks the language of
2024-07-03 07:16:53 root INFO     h_layer_name='transformer.h.5.ln_1' z_layer_name='transformer.h.27'
2024-07-03 07:16:53 root INFO     [order_1_approx] starting weight calculation for The country of belize primarily speaks the language of english
The country of kosovo primarily speaks the language of albanian
The country of venezuela primarily speaks the language of spanish
The country of andorra primarily speaks the language of catalan
The country of iran primarily speaks the language of persian
The country of moldova primarily speaks the language of moldovan
The country of fiji primarily speaks the language of english
The country of guatemala primarily speaks the language of
2024-07-03 07:16:54 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5.ln_1
2024-07-03 07:20:59 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 0.0017, -0.0055, -0.0037,  ..., -0.0040,  0.0060, -0.0029],
        [-0.0038,  0.0052,  0.0003,  ...,  0.0061,  0.0009,  0.0004],
        [-0.0039,  0.0028,  0.0010,  ...,  0.0004,  0.0011,  0.0006],
        ...,
        [-0.0044, -0.0025,  0.0043,  ..., -0.0004, -0.0064, -0.0033],
        [ 0.0102, -0.0024, -0.0053,  ..., -0.0021,  0.0087,  0.0016],
        [-0.0030,  0.0063, -0.0039,  ..., -0.0032,  0.0010,  0.0027]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-03 07:21:00 root INFO     h_layer_name='transformer.h.5' z_layer_name='transformer.h.27'
2024-07-03 07:21:00 root INFO     [order_1_approx] starting weight calculation for The country of belize primarily speaks the language of english
The country of kosovo primarily speaks the language of albanian
The country of venezuela primarily speaks the language of spanish
The country of andorra primarily speaks the language of catalan
The country of iran primarily speaks the language of persian
The country of moldova primarily speaks the language of moldovan
The country of fiji primarily speaks the language of english
The country of guatemala primarily speaks the language of
2024-07-03 07:21:00 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5
2024-07-03 07:24:54 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-4.1809e-03, -1.9867e-02,  7.3290e-04,  ..., -7.3547e-03,
         -4.2839e-03,  4.6768e-03],
        [-1.9159e-03, -2.7962e-03,  3.4027e-03,  ...,  1.0468e-02,
          1.3664e-02,  3.3531e-03],
        [-2.8305e-03,  2.8210e-03, -1.7731e-02,  ..., -1.4938e-02,
          4.9667e-03, -3.4924e-03],
        ...,
        [-1.1726e-02,  2.1820e-03, -3.4332e-04,  ..., -6.8283e-03,
          4.7569e-03, -1.0376e-03],
        [ 9.4986e-04, -4.1962e-05, -2.3785e-03,  ..., -3.0975e-03,
         -8.5754e-03, -4.0741e-03],
        [ 2.3842e-04,  9.0599e-04, -4.6310e-03,  ..., -6.0120e-03,
         -1.0567e-02, -6.9504e-03]], device='cuda:0', dtype=torch.float16) 

                    
2024-07-03 07:24:55 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country of belize primarily speaks the language of english
The country of kosovo primarily speaks the language of albanian
The country of venezuela primarily speaks the language of spanish
The country of andorra primarily speaks the language of catalan
The country of iran primarily speaks the language of persian
The country of moldova primarily speaks the language of moldovan
The country of fiji primarily speaks the language of english
The country of guatemala primarily speaks the language of
2024-07-03 07:24:55 root INFO     h_layer_name='transformer.h.5.ln_1' z_layer_name='transformer.h.27'
2024-07-03 07:24:55 root INFO     [order_1_approx] starting weight calculation for The country of iran primarily speaks the language of persian
The country of venezuela primarily speaks the language of spanish
The country of fiji primarily speaks the language of english
The country of guatemala primarily speaks the language of spanish
The country of andorra primarily speaks the language of catalan
The country of moldova primarily speaks the language of moldovan
The country of belize primarily speaks the language of english
The country of kosovo primarily speaks the language of
2024-07-03 07:24:55 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5.ln_1
2024-07-03 07:29:01 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0069, -0.0070,  0.0084,  ..., -0.0073,  0.0116, -0.0002],
        [ 0.0024, -0.0057,  0.0168,  ...,  0.0009, -0.0011, -0.0097],
        [-0.0133,  0.0024,  0.0059,  ...,  0.0042, -0.0010, -0.0073],
        ...,
        [-0.0169, -0.0031,  0.0020,  ...,  0.0047, -0.0041, -0.0008],
        [ 0.0063,  0.0048,  0.0027,  ..., -0.0162,  0.0083,  0.0007],
        [ 0.0025, -0.0069, -0.0046,  ..., -0.0065,  0.0103,  0.0010]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-03 07:29:02 root INFO     h_layer_name='transformer.h.5' z_layer_name='transformer.h.27'
2024-07-03 07:29:02 root INFO     [order_1_approx] starting weight calculation for The country of iran primarily speaks the language of persian
The country of venezuela primarily speaks the language of spanish
The country of fiji primarily speaks the language of english
The country of guatemala primarily speaks the language of spanish
The country of andorra primarily speaks the language of catalan
The country of moldova primarily speaks the language of moldovan
The country of belize primarily speaks the language of english
The country of kosovo primarily speaks the language of
2024-07-03 07:29:02 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5
2024-07-03 07:33:01 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0357, -0.0008,  0.0294,  ...,  0.0028, -0.0129,  0.0043],
        [ 0.0144, -0.0121,  0.0097,  ...,  0.0185,  0.0085,  0.0183],
        [-0.0047, -0.0140, -0.0469,  ...,  0.0064, -0.0119, -0.0062],
        ...,
        [-0.0066, -0.0052,  0.0005,  ...,  0.0108, -0.0067, -0.0298],
        [ 0.0008,  0.0072,  0.0042,  ...,  0.0035, -0.0285, -0.0014],
        [-0.0264,  0.0242, -0.0069,  ...,  0.0074,  0.0190, -0.0180]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-03 07:33:02 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country of iran primarily speaks the language of persian
The country of venezuela primarily speaks the language of spanish
The country of fiji primarily speaks the language of english
The country of guatemala primarily speaks the language of spanish
The country of andorra primarily speaks the language of catalan
The country of moldova primarily speaks the language of moldovan
The country of belize primarily speaks the language of english
The country of kosovo primarily speaks the language of
2024-07-03 07:33:02 root INFO     total operator prediction time: 3867.5032255649567 seconds
2024-07-03 07:33:02 __main__ INFO     starting test: <class 'lre.operators.JacobianIclMeanEstimator'> on synonyms - exact
2024-07-03 07:33:04 root INFO     building operator synonyms - exact
2024-07-03 07:33:04 root INFO     h_layer_name='transformer.h.5.ln_1' z_layer_name='transformer.h.27'
2024-07-03 07:33:04 root INFO     [order_1_approx] starting weight calculation for Another word for airplane is  aeroplane
Another word for murder is  slaying
Another word for harbor is  seaport
Another word for auto is  car
Another word for lady is  madam
Another word for list is  listing
Another word for jewel is  gem
Another word for hieroglyph is 
2024-07-03 07:33:04 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5.ln_1
2024-07-03 07:37:08 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0027,  0.0287, -0.0146,  ..., -0.0157, -0.0095, -0.0037],
        [-0.0034,  0.0037, -0.0048,  ..., -0.0033,  0.0009, -0.0029],
        [ 0.0039, -0.0098, -0.0178,  ...,  0.0063, -0.0110,  0.0024],
        ...,
        [-0.0034,  0.0073, -0.0075,  ..., -0.0074,  0.0051, -0.0011],
        [-0.0092,  0.0227, -0.0128,  ..., -0.0217,  0.0029, -0.0084],
        [-0.0028, -0.0159,  0.0116,  ...,  0.0023,  0.0088, -0.0076]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-03 07:37:08 root INFO     h_layer_name='transformer.h.5' z_layer_name='transformer.h.27'
2024-07-03 07:37:09 root INFO     [order_1_approx] starting weight calculation for Another word for airplane is  aeroplane
Another word for murder is  slaying
Another word for harbor is  seaport
Another word for auto is  car
Another word for lady is  madam
Another word for list is  listing
Another word for jewel is  gem
Another word for hieroglyph is 
2024-07-03 07:37:09 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5
2024-07-03 07:41:02 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0087, -0.0247,  0.0134,  ...,  0.0198, -0.0032, -0.0316],
        [ 0.0060, -0.0305,  0.0073,  ...,  0.0286, -0.0202,  0.0136],
        [-0.0018,  0.0069, -0.0064,  ...,  0.0131,  0.0130,  0.0103],
        ...,
        [-0.0096, -0.0096,  0.0059,  ...,  0.0092, -0.0026, -0.0059],
        [ 0.0268, -0.0338, -0.0016,  ...,  0.0025, -0.0317,  0.0247],
        [ 0.0003,  0.0093,  0.0177,  ..., -0.0332,  0.0047, -0.0070]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-03 07:41:03 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Another word for airplane is  aeroplane
Another word for murder is  slaying
Another word for harbor is  seaport
Another word for auto is  car
Another word for lady is  madam
Another word for list is  listing
Another word for jewel is  gem
Another word for hieroglyph is 
2024-07-03 07:41:03 root INFO     h_layer_name='transformer.h.5.ln_1' z_layer_name='transformer.h.27'
2024-07-03 07:41:03 root INFO     [order_1_approx] starting weight calculation for Another word for lady is  madam
Another word for harbor is  seaport
Another word for jewel is  gem
Another word for auto is  car
Another word for hieroglyph is  hieroglyphic
Another word for list is  listing
Another word for airplane is  aeroplane
Another word for murder is 
2024-07-03 07:41:03 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5.ln_1
2024-07-03 07:45:09 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0147, -0.0143,  0.0003,  ..., -0.0006, -0.0051,  0.0026],
        [-0.0035, -0.0067,  0.0143,  ..., -0.0086, -0.0095,  0.0123],
        [ 0.0079, -0.0051,  0.0047,  ...,  0.0074, -0.0047, -0.0042],
        ...,
        [ 0.0028, -0.0053, -0.0191,  ..., -0.0042,  0.0071, -0.0146],
        [ 0.0117,  0.0154, -0.0032,  ...,  0.0014,  0.0105,  0.0038],
        [-0.0048,  0.0041,  0.0036,  ..., -0.0036, -0.0133, -0.0091]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-03 07:45:10 root INFO     h_layer_name='transformer.h.5' z_layer_name='transformer.h.27'
2024-07-03 07:45:10 root INFO     [order_1_approx] starting weight calculation for Another word for lady is  madam
Another word for harbor is  seaport
Another word for jewel is  gem
Another word for auto is  car
Another word for hieroglyph is  hieroglyphic
Another word for list is  listing
Another word for airplane is  aeroplane
Another word for murder is 
2024-07-03 07:45:10 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5
2024-07-03 07:49:06 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 0.0208, -0.0178, -0.0079,  ...,  0.0052, -0.0141, -0.0158],
        [ 0.0090, -0.0184,  0.0049,  ...,  0.0189, -0.0149, -0.0111],
        [-0.0259,  0.0130, -0.0064,  ..., -0.0272,  0.0198,  0.0107],
        ...,
        [-0.0206,  0.0036,  0.0169,  ...,  0.0243, -0.0113,  0.0058],
        [-0.0111, -0.0109, -0.0057,  ..., -0.0346, -0.0101, -0.0221],
        [-0.0080,  0.0289,  0.0137,  ...,  0.0033,  0.0168,  0.0202]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-03 07:49:07 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Another word for lady is  madam
Another word for harbor is  seaport
Another word for jewel is  gem
Another word for auto is  car
Another word for hieroglyph is  hieroglyphic
Another word for list is  listing
Another word for airplane is  aeroplane
Another word for murder is 
2024-07-03 07:49:07 root INFO     h_layer_name='transformer.h.5.ln_1' z_layer_name='transformer.h.27'
2024-07-03 07:49:07 root INFO     [order_1_approx] starting weight calculation for Another word for harbor is  seaport
Another word for murder is  slaying
Another word for lady is  madam
Another word for jewel is  gem
Another word for hieroglyph is  hieroglyphic
Another word for list is  listing
Another word for auto is  car
Another word for airplane is 
2024-07-03 07:49:07 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5.ln_1
2024-07-03 07:53:12 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 5.3310e-04,  4.6272e-03,  6.8741e-03,  ..., -3.4199e-03,
         -3.4752e-03,  1.7796e-03],
        [ 2.4033e-03,  3.9291e-03,  5.3177e-03,  ..., -4.2000e-03,
          1.1616e-03,  1.2417e-03],
        [-1.5427e-02, -5.9357e-03, -1.2569e-03,  ...,  1.2741e-02,
         -2.5520e-03,  2.5654e-03],
        ...,
        [-1.2398e-05, -2.3708e-03, -5.1594e-04,  ...,  6.2256e-03,
         -1.8425e-03,  5.8212e-03],
        [-7.6866e-03,  4.4136e-03,  1.6088e-03,  ...,  1.0653e-03,
          6.0349e-03, -2.0676e-03],
        [-1.7395e-03, -8.6975e-03, -9.4223e-04,  ..., -1.1444e-02,
         -1.0468e-02,  1.6403e-04]], device='cuda:0', dtype=torch.float16) 

                    
2024-07-03 07:53:13 root INFO     h_layer_name='transformer.h.5' z_layer_name='transformer.h.27'
2024-07-03 07:53:13 root INFO     [order_1_approx] starting weight calculation for Another word for harbor is  seaport
Another word for murder is  slaying
Another word for lady is  madam
Another word for jewel is  gem
Another word for hieroglyph is  hieroglyphic
Another word for list is  listing
Another word for auto is  car
Another word for airplane is 
2024-07-03 07:53:13 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5
2024-07-03 07:57:11 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 0.0064, -0.0212, -0.0081,  ...,  0.0259, -0.0175, -0.0022],
        [-0.0070, -0.0253, -0.0140,  ...,  0.0177,  0.0058, -0.0193],
        [-0.0171, -0.0061, -0.0063,  ..., -0.0017,  0.0106,  0.0085],
        ...,
        [ 0.0064, -0.0197, -0.0115,  ..., -0.0263, -0.0115, -0.0092],
        [-0.0005, -0.0085, -0.0098,  ...,  0.0185, -0.0082,  0.0189],
        [ 0.0043,  0.0008,  0.0067,  ..., -0.0002, -0.0002, -0.0144]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-03 07:57:11 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Another word for harbor is  seaport
Another word for murder is  slaying
Another word for lady is  madam
Another word for jewel is  gem
Another word for hieroglyph is  hieroglyphic
Another word for list is  listing
Another word for auto is  car
Another word for airplane is 
2024-07-03 07:57:12 root INFO     h_layer_name='transformer.h.5.ln_1' z_layer_name='transformer.h.27'
2024-07-03 07:57:12 root INFO     [order_1_approx] starting weight calculation for Another word for airplane is  aeroplane
Another word for hieroglyph is  hieroglyphic
Another word for harbor is  seaport
Another word for auto is  car
Another word for murder is  slaying
Another word for lady is  madam
Another word for list is  listing
Another word for jewel is 
2024-07-03 07:57:12 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5.ln_1
2024-07-03 08:01:17 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 0.0071,  0.0024,  0.0044,  ..., -0.0110,  0.0074,  0.0141],
        [ 0.0003, -0.0048,  0.0066,  ...,  0.0003, -0.0059,  0.0088],
        [ 0.0046, -0.0022, -0.0099,  ..., -0.0055, -0.0071,  0.0085],
        ...,
        [ 0.0040, -0.0003, -0.0010,  ...,  0.0028, -0.0018,  0.0032],
        [-0.0112,  0.0015, -0.0025,  ...,  0.0105, -0.0029,  0.0012],
        [ 0.0013, -0.0025,  0.0009,  ..., -0.0188,  0.0237, -0.0065]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-03 08:01:18 root INFO     h_layer_name='transformer.h.5' z_layer_name='transformer.h.27'
2024-07-03 08:01:18 root INFO     [order_1_approx] starting weight calculation for Another word for airplane is  aeroplane
Another word for hieroglyph is  hieroglyphic
Another word for harbor is  seaport
Another word for auto is  car
Another word for murder is  slaying
Another word for lady is  madam
Another word for list is  listing
Another word for jewel is 
2024-07-03 08:01:18 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5
2024-07-03 08:05:14 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 0.0053, -0.0183, -0.0015,  ..., -0.0242,  0.0167,  0.0036],
        [-0.0119, -0.0104, -0.0060,  ..., -0.0019,  0.0027,  0.0024],
        [ 0.0060,  0.0226, -0.0054,  ...,  0.0101,  0.0074, -0.0172],
        ...,
        [ 0.0069,  0.0222, -0.0094,  ..., -0.0198, -0.0062, -0.0114],
        [-0.0235,  0.0013,  0.0015,  ...,  0.0126, -0.0185, -0.0252],
        [-0.0149, -0.0270,  0.0046,  ..., -0.0149,  0.0073,  0.0160]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-03 08:05:15 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Another word for airplane is  aeroplane
Another word for hieroglyph is  hieroglyphic
Another word for harbor is  seaport
Another word for auto is  car
Another word for murder is  slaying
Another word for lady is  madam
Another word for list is  listing
Another word for jewel is 
2024-07-03 08:05:16 root INFO     h_layer_name='transformer.h.5.ln_1' z_layer_name='transformer.h.27'
2024-07-03 08:05:16 root INFO     [order_1_approx] starting weight calculation for Another word for murder is  slaying
Another word for lady is  madam
Another word for harbor is  seaport
Another word for jewel is  gem
Another word for list is  listing
Another word for hieroglyph is  hieroglyphic
Another word for airplane is  aeroplane
Another word for auto is 
2024-07-03 08:05:16 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5.ln_1
2024-07-03 08:09:23 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0043, -0.0012,  0.0018,  ..., -0.0121,  0.0082,  0.0047],
        [ 0.0004, -0.0017, -0.0043,  ..., -0.0030, -0.0091, -0.0009],
        [ 0.0103, -0.0039, -0.0064,  ..., -0.0054, -0.0107,  0.0114],
        ...,
        [-0.0060,  0.0017,  0.0021,  ...,  0.0012, -0.0048,  0.0030],
        [ 0.0058, -0.0069, -0.0078,  ...,  0.0102,  0.0124,  0.0001],
        [-0.0026,  0.0045,  0.0105,  ...,  0.0043,  0.0023, -0.0079]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-03 08:09:23 root INFO     h_layer_name='transformer.h.5' z_layer_name='transformer.h.27'
2024-07-03 08:09:24 root INFO     [order_1_approx] starting weight calculation for Another word for murder is  slaying
Another word for lady is  madam
Another word for harbor is  seaport
Another word for jewel is  gem
Another word for list is  listing
Another word for hieroglyph is  hieroglyphic
Another word for airplane is  aeroplane
Another word for auto is 
2024-07-03 08:09:24 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5
2024-07-03 08:13:20 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 0.0187, -0.0126,  0.0157,  ...,  0.0244, -0.0065,  0.0099],
        [ 0.0029, -0.0251, -0.0038,  ..., -0.0063,  0.0027,  0.0087],
        [-0.0413, -0.0090, -0.0176,  ..., -0.0167, -0.0044, -0.0103],
        ...,
        [-0.0078,  0.0262, -0.0240,  ..., -0.0230, -0.0038,  0.0097],
        [ 0.0096, -0.0036,  0.0074,  ...,  0.0084, -0.0197, -0.0039],
        [-0.0064,  0.0110,  0.0048,  ..., -0.0286, -0.0057, -0.0300]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-03 08:13:21 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Another word for murder is  slaying
Another word for lady is  madam
Another word for harbor is  seaport
Another word for jewel is  gem
Another word for list is  listing
Another word for hieroglyph is  hieroglyphic
Another word for airplane is  aeroplane
Another word for auto is 
2024-07-03 08:13:21 root INFO     h_layer_name='transformer.h.5.ln_1' z_layer_name='transformer.h.27'
2024-07-03 08:13:21 root INFO     [order_1_approx] starting weight calculation for Another word for airplane is  aeroplane
Another word for list is  listing
Another word for jewel is  gem
Another word for lady is  madam
Another word for murder is  slaying
Another word for auto is  car
Another word for hieroglyph is  hieroglyphic
Another word for harbor is 
2024-07-03 08:13:21 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5.ln_1
2024-07-03 08:17:28 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 0.0013, -0.0084,  0.0111,  ...,  0.0091, -0.0068,  0.0101],
        [ 0.0037,  0.0080,  0.0066,  ...,  0.0004, -0.0080,  0.0059],
        [ 0.0011,  0.0044, -0.0061,  ...,  0.0089,  0.0024,  0.0122],
        ...,
        [ 0.0074, -0.0042,  0.0006,  ..., -0.0075,  0.0066, -0.0060],
        [-0.0101,  0.0108,  0.0104,  ..., -0.0094,  0.0131,  0.0120],
        [ 0.0014, -0.0022, -0.0132,  ...,  0.0187, -0.0058, -0.0022]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-03 08:17:29 root INFO     h_layer_name='transformer.h.5' z_layer_name='transformer.h.27'
2024-07-03 08:17:29 root INFO     [order_1_approx] starting weight calculation for Another word for airplane is  aeroplane
Another word for list is  listing
Another word for jewel is  gem
Another word for lady is  madam
Another word for murder is  slaying
Another word for auto is  car
Another word for hieroglyph is  hieroglyphic
Another word for harbor is 
2024-07-03 08:17:29 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5
2024-07-03 08:21:25 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0022, -0.0161,  0.0119,  ..., -0.0077, -0.0154,  0.0025],
        [-0.0128, -0.0170,  0.0033,  ..., -0.0069, -0.0046, -0.0147],
        [-0.0009, -0.0220, -0.0162,  ..., -0.0124, -0.0079, -0.0139],
        ...,
        [ 0.0071, -0.0040, -0.0004,  ...,  0.0011, -0.0061,  0.0161],
        [ 0.0044,  0.0085, -0.0053,  ..., -0.0061, -0.0206, -0.0267],
        [-0.0100, -0.0070,  0.0169,  ..., -0.0114, -0.0103, -0.0334]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-03 08:21:25 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Another word for airplane is  aeroplane
Another word for list is  listing
Another word for jewel is  gem
Another word for lady is  madam
Another word for murder is  slaying
Another word for auto is  car
Another word for hieroglyph is  hieroglyphic
Another word for harbor is 
2024-07-03 08:21:26 root INFO     h_layer_name='transformer.h.5.ln_1' z_layer_name='transformer.h.27'
2024-07-03 08:21:26 root INFO     [order_1_approx] starting weight calculation for Another word for airplane is  aeroplane
Another word for auto is  car
Another word for murder is  slaying
Another word for harbor is  seaport
Another word for lady is  madam
Another word for hieroglyph is  hieroglyphic
Another word for jewel is  gem
Another word for list is 
2024-07-03 08:21:26 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5.ln_1
2024-07-03 08:25:31 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 2.3918e-03, -6.1874e-03, -4.6616e-03,  ..., -1.9016e-03,
          1.4076e-02, -5.3177e-03],
        [ 8.8348e-03,  1.3977e-02, -2.1973e-03,  ...,  1.1644e-03,
         -6.8521e-04, -1.2207e-02],
        [-4.0665e-03,  8.1329e-03, -3.7813e-04,  ..., -8.5831e-05,
         -6.3248e-03,  8.2703e-03],
        ...,
        [-1.8902e-03, -1.4908e-02, -6.3705e-03,  ...,  4.3297e-03,
         -6.8283e-03, -1.3016e-02],
        [ 1.9121e-04,  1.3971e-03,  4.9019e-03,  ..., -1.1597e-02,
          1.5373e-02,  6.9962e-03],
        [-3.7422e-03,  7.2670e-03,  5.3978e-03,  ..., -5.4665e-03,
         -1.6357e-02, -1.2367e-02]], device='cuda:0', dtype=torch.float16) 

                    
2024-07-03 08:25:32 root INFO     h_layer_name='transformer.h.5' z_layer_name='transformer.h.27'
2024-07-03 08:25:32 root INFO     [order_1_approx] starting weight calculation for Another word for airplane is  aeroplane
Another word for auto is  car
Another word for murder is  slaying
Another word for harbor is  seaport
Another word for lady is  madam
Another word for hieroglyph is  hieroglyphic
Another word for jewel is  gem
Another word for list is 
2024-07-03 08:25:32 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5
2024-07-03 08:29:29 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-5.2910e-03, -1.2619e-02,  5.9242e-03,  ...,  1.0086e-02,
          1.2314e-02,  8.2092e-03],
        [-9.9792e-03, -1.4381e-02,  5.8823e-03,  ...,  9.0485e-03,
         -7.9803e-03,  5.3215e-03],
        [-6.9275e-03, -1.5121e-02,  1.1063e-03,  ..., -9.3079e-04,
          1.1909e-02, -1.1742e-02],
        ...,
        [-8.6975e-03,  2.3376e-02,  1.1749e-02,  ..., -2.5223e-02,
         -4.8180e-03, -2.9526e-03],
        [ 1.0895e-02, -2.4109e-03,  5.9204e-03,  ...,  5.5618e-03,
          1.5305e-02, -3.5610e-03],
        [ 1.6661e-03,  2.6413e-02,  1.9547e-02,  ...,  5.7220e-05,
          8.4229e-03,  5.6000e-03]], device='cuda:0', dtype=torch.float16) 

                    
2024-07-03 08:29:30 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Another word for airplane is  aeroplane
Another word for auto is  car
Another word for murder is  slaying
Another word for harbor is  seaport
Another word for lady is  madam
Another word for hieroglyph is  hieroglyphic
Another word for jewel is  gem
Another word for list is 
2024-07-03 08:29:30 root INFO     h_layer_name='transformer.h.5.ln_1' z_layer_name='transformer.h.27'
2024-07-03 08:29:30 root INFO     [order_1_approx] starting weight calculation for Another word for auto is  car
Another word for list is  listing
Another word for airplane is  aeroplane
Another word for murder is  slaying
Another word for harbor is  seaport
Another word for jewel is  gem
Another word for hieroglyph is  hieroglyphic
Another word for lady is 
2024-07-03 08:29:30 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5.ln_1
2024-07-03 08:33:36 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-6.6986e-03, -8.2245e-03, -3.1490e-03,  ..., -7.7477e-03,
         -4.5776e-03,  1.9083e-03],
        [-5.4932e-03,  1.4515e-03,  5.0430e-03,  ...,  6.9695e-03,
         -3.9406e-03,  5.5389e-03],
        [ 5.9319e-03,  2.5425e-03, -3.3875e-03,  ...,  1.0674e-02,
          1.2331e-03,  6.6681e-03],
        ...,
        [-1.0368e-02,  5.7526e-03, -1.0967e-04,  ..., -1.5879e-03,
          7.5760e-03,  7.8917e-05],
        [-9.8114e-03,  4.0627e-03, -1.9836e-03,  ...,  3.5553e-03,
         -3.6449e-03,  3.6983e-03],
        [-1.0376e-02, -6.1646e-03,  7.7438e-03,  ..., -6.4659e-03,
         -1.0635e-02,  1.0700e-03]], device='cuda:0', dtype=torch.float16) 

                    
2024-07-03 08:33:37 root INFO     h_layer_name='transformer.h.5' z_layer_name='transformer.h.27'
2024-07-03 08:33:37 root INFO     [order_1_approx] starting weight calculation for Another word for auto is  car
Another word for list is  listing
Another word for airplane is  aeroplane
Another word for murder is  slaying
Another word for harbor is  seaport
Another word for jewel is  gem
Another word for hieroglyph is  hieroglyphic
Another word for lady is 
2024-07-03 08:33:37 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5
2024-07-03 08:37:34 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0229, -0.0161,  0.0056,  ...,  0.0084, -0.0151,  0.0040],
        [ 0.0021, -0.0238,  0.0006,  ...,  0.0105,  0.0003, -0.0035],
        [ 0.0044, -0.0424,  0.0237,  ..., -0.0045,  0.0065, -0.0223],
        ...,
        [-0.0191, -0.0252,  0.0168,  ..., -0.0080, -0.0090,  0.0078],
        [-0.0121,  0.0227, -0.0150,  ..., -0.0170,  0.0068,  0.0131],
        [ 0.0008, -0.0007,  0.0120,  ..., -0.0029, -0.0173,  0.0169]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-03 08:37:35 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Another word for auto is  car
Another word for list is  listing
Another word for airplane is  aeroplane
Another word for murder is  slaying
Another word for harbor is  seaport
Another word for jewel is  gem
Another word for hieroglyph is  hieroglyphic
Another word for lady is 
2024-07-03 08:37:35 root INFO     total operator prediction time: 3870.95272064209 seconds
2024-07-03 08:37:35 __main__ INFO     starting test: <class 'lre.operators.JacobianIclMeanEstimator'> on verb+er_irreg
2024-07-03 08:37:37 root INFO     building operator verb+er_irreg
2024-07-03 08:37:37 root INFO     h_layer_name='transformer.h.5.ln_1' z_layer_name='transformer.h.27'
2024-07-03 08:37:37 root INFO     [order_1_approx] starting weight calculation for If you provide something, you are a provider
If you send something, you are a sender
If you observe something, you are a observer
If you compose something, you are a composer
If you contend something, you are a contender
If you consume something, you are a consumer
If you manage something, you are a manager
If you mourn something, you are a
2024-07-03 08:37:37 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5.ln_1
2024-07-03 08:41:43 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 0.0151,  0.0001, -0.0042,  ..., -0.0057,  0.0084,  0.0014],
        [ 0.0043, -0.0061, -0.0049,  ..., -0.0017, -0.0008, -0.0066],
        [ 0.0072,  0.0012, -0.0079,  ..., -0.0058,  0.0086, -0.0096],
        ...,
        [ 0.0024,  0.0041,  0.0070,  ..., -0.0043, -0.0124,  0.0098],
        [ 0.0022,  0.0011, -0.0018,  ..., -0.0074, -0.0022,  0.0060],
        [ 0.0037, -0.0058, -0.0116,  ..., -0.0244,  0.0073, -0.0024]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-03 08:41:44 root INFO     h_layer_name='transformer.h.5' z_layer_name='transformer.h.27'
2024-07-03 08:41:44 root INFO     [order_1_approx] starting weight calculation for If you provide something, you are a provider
If you send something, you are a sender
If you observe something, you are a observer
If you compose something, you are a composer
If you contend something, you are a contender
If you consume something, you are a consumer
If you manage something, you are a manager
If you mourn something, you are a
2024-07-03 08:41:44 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5
2024-07-03 08:45:41 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0091, -0.0002,  0.0230,  ...,  0.0111, -0.0160, -0.0223],
        [-0.0225, -0.0183, -0.0033,  ...,  0.0249, -0.0011,  0.0280],
        [-0.0103,  0.0202, -0.0154,  ...,  0.0221,  0.0255,  0.0208],
        ...,
        [-0.0101, -0.0260, -0.0165,  ..., -0.0293,  0.0079, -0.0282],
        [ 0.0116, -0.0150, -0.0228,  ..., -0.0015, -0.0442,  0.0109],
        [-0.0120,  0.0318,  0.0205,  ..., -0.0147, -0.0091, -0.0267]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-03 08:45:42 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you provide something, you are a provider
If you send something, you are a sender
If you observe something, you are a observer
If you compose something, you are a composer
If you contend something, you are a contender
If you consume something, you are a consumer
If you manage something, you are a manager
If you mourn something, you are a
2024-07-03 08:45:42 root INFO     h_layer_name='transformer.h.5.ln_1' z_layer_name='transformer.h.27'
2024-07-03 08:45:42 root INFO     [order_1_approx] starting weight calculation for If you observe something, you are a observer
If you mourn something, you are a mourner
If you manage something, you are a manager
If you contend something, you are a contender
If you provide something, you are a provider
If you compose something, you are a composer
If you consume something, you are a consumer
If you send something, you are a
2024-07-03 08:45:42 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5.ln_1
2024-07-03 08:49:47 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0026, -0.0019, -0.0097,  ...,  0.0002,  0.0001,  0.0060],
        [ 0.0033, -0.0023, -0.0016,  ..., -0.0029, -0.0020,  0.0007],
        [-0.0013, -0.0027, -0.0089,  ...,  0.0023, -0.0005, -0.0038],
        ...,
        [ 0.0037, -0.0005,  0.0004,  ...,  0.0012, -0.0019, -0.0070],
        [-0.0012, -0.0054, -0.0026,  ...,  0.0029,  0.0056,  0.0070],
        [ 0.0009, -0.0080, -0.0017,  ..., -0.0061, -0.0002,  0.0013]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-03 08:49:47 root INFO     h_layer_name='transformer.h.5' z_layer_name='transformer.h.27'
2024-07-03 08:49:48 root INFO     [order_1_approx] starting weight calculation for If you observe something, you are a observer
If you mourn something, you are a mourner
If you manage something, you are a manager
If you contend something, you are a contender
If you provide something, you are a provider
If you compose something, you are a composer
If you consume something, you are a consumer
If you send something, you are a
2024-07-03 08:49:48 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5
2024-07-03 08:53:44 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0217, -0.0180,  0.0011,  ..., -0.0123, -0.0119, -0.0220],
        [-0.0005, -0.0022,  0.0064,  ...,  0.0041, -0.0120, -0.0011],
        [-0.0075, -0.0059,  0.0041,  ...,  0.0133, -0.0194,  0.0243],
        ...,
        [-0.0061, -0.0035, -0.0030,  ..., -0.0153,  0.0068,  0.0052],
        [-0.0022, -0.0019,  0.0040,  ..., -0.0211, -0.0373,  0.0049],
        [ 0.0098,  0.0093, -0.0019,  ..., -0.0131,  0.0063, -0.0178]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-03 08:53:45 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you observe something, you are a observer
If you mourn something, you are a mourner
If you manage something, you are a manager
If you contend something, you are a contender
If you provide something, you are a provider
If you compose something, you are a composer
If you consume something, you are a consumer
If you send something, you are a
2024-07-03 08:53:45 root INFO     h_layer_name='transformer.h.5.ln_1' z_layer_name='transformer.h.27'
2024-07-03 08:53:45 root INFO     [order_1_approx] starting weight calculation for If you contend something, you are a contender
If you consume something, you are a consumer
If you provide something, you are a provider
If you compose something, you are a composer
If you mourn something, you are a mourner
If you send something, you are a sender
If you manage something, you are a manager
If you observe something, you are a
2024-07-03 08:53:45 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5.ln_1
2024-07-03 08:57:51 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-3.2635e-03,  5.2929e-05, -6.4964e-03,  ..., -8.0204e-04,
          5.5466e-03,  2.3975e-03],
        [ 3.0746e-03,  5.0507e-03, -4.6310e-03,  ..., -8.8978e-04,
          6.8855e-03, -4.7455e-03],
        [ 2.9068e-03,  5.0659e-03,  3.1624e-03,  ...,  3.8872e-03,
          7.5073e-03,  6.1226e-03],
        ...,
        [-5.4836e-04,  7.1793e-03,  1.2188e-03,  ...,  2.8133e-03,
         -5.2986e-03, -1.8415e-03],
        [-2.1439e-03,  7.4234e-03, -1.1566e-02,  ...,  5.3940e-03,
          2.6817e-03,  1.5802e-03],
        [ 3.9406e-03, -9.7656e-03,  5.1651e-03,  ..., -1.7731e-02,
          1.5327e-02, -6.2790e-03]], device='cuda:0', dtype=torch.float16) 

                    
2024-07-03 08:57:52 root INFO     h_layer_name='transformer.h.5' z_layer_name='transformer.h.27'
2024-07-03 08:57:52 root INFO     [order_1_approx] starting weight calculation for If you contend something, you are a contender
If you consume something, you are a consumer
If you provide something, you are a provider
If you compose something, you are a composer
If you mourn something, you are a mourner
If you send something, you are a sender
If you manage something, you are a manager
If you observe something, you are a
2024-07-03 08:57:52 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5
2024-07-03 09:01:47 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0033, -0.0047,  0.0184,  ..., -0.0088, -0.0125, -0.0201],
        [ 0.0017,  0.0079,  0.0007,  ...,  0.0094, -0.0110,  0.0068],
        [-0.0089,  0.0125, -0.0154,  ...,  0.0151, -0.0022, -0.0035],
        ...,
        [-0.0121, -0.0177, -0.0033,  ..., -0.0158, -0.0034, -0.0109],
        [-0.0121, -0.0097,  0.0197,  ..., -0.0098, -0.0273,  0.0121],
        [-0.0064,  0.0003,  0.0125,  ..., -0.0009, -0.0170, -0.0194]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-03 09:01:47 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you contend something, you are a contender
If you consume something, you are a consumer
If you provide something, you are a provider
If you compose something, you are a composer
If you mourn something, you are a mourner
If you send something, you are a sender
If you manage something, you are a manager
If you observe something, you are a
2024-07-03 09:01:48 root INFO     h_layer_name='transformer.h.5.ln_1' z_layer_name='transformer.h.27'
2024-07-03 09:01:48 root INFO     [order_1_approx] starting weight calculation for If you manage something, you are a manager
If you send something, you are a sender
If you contend something, you are a contender
If you observe something, you are a observer
If you consume something, you are a consumer
If you mourn something, you are a mourner
If you compose something, you are a composer
If you provide something, you are a
2024-07-03 09:01:48 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5.ln_1
2024-07-03 09:05:52 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 0.0034, -0.0011, -0.0026,  ..., -0.0031,  0.0078,  0.0101],
        [ 0.0010, -0.0046, -0.0047,  ...,  0.0009,  0.0022, -0.0032],
        [-0.0040,  0.0067,  0.0093,  ...,  0.0134,  0.0070, -0.0074],
        ...,
        [-0.0036, -0.0002, -0.0054,  ...,  0.0064, -0.0122,  0.0045],
        [ 0.0027, -0.0050, -0.0113,  ..., -0.0043,  0.0051, -0.0053],
        [-0.0012, -0.0037,  0.0051,  ..., -0.0075,  0.0032, -0.0080]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-03 09:05:54 root INFO     h_layer_name='transformer.h.5' z_layer_name='transformer.h.27'
2024-07-03 09:05:54 root INFO     [order_1_approx] starting weight calculation for If you manage something, you are a manager
If you send something, you are a sender
If you contend something, you are a contender
If you observe something, you are a observer
If you consume something, you are a consumer
If you mourn something, you are a mourner
If you compose something, you are a composer
If you provide something, you are a
2024-07-03 09:05:54 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5
2024-07-03 09:09:52 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-7.4005e-03, -3.5797e-02,  1.5533e-02,  ..., -3.2959e-03,
         -3.7598e-02, -2.1759e-02],
        [-4.9706e-03,  3.0670e-03,  7.4005e-04,  ...,  5.1155e-03,
         -4.7760e-03,  1.0345e-02],
        [-7.3509e-03,  6.6566e-03, -2.0561e-03,  ...,  1.0193e-02,
          9.7275e-05, -1.3695e-03],
        ...,
        [ 6.0120e-03, -6.6452e-03, -2.2217e-02,  ..., -1.4420e-02,
         -1.2493e-03, -3.9444e-03],
        [ 4.8752e-03,  1.0880e-02,  1.4969e-02,  ..., -2.1759e-02,
         -2.7710e-02,  9.9487e-03],
        [-6.7368e-03,  1.8616e-02,  7.6294e-05,  ..., -9.6359e-03,
          4.8180e-03, -1.6510e-02]], device='cuda:0', dtype=torch.float16) 

                    
2024-07-03 09:09:53 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you manage something, you are a manager
If you send something, you are a sender
If you contend something, you are a contender
If you observe something, you are a observer
If you consume something, you are a consumer
If you mourn something, you are a mourner
If you compose something, you are a composer
If you provide something, you are a
2024-07-03 09:09:53 root INFO     h_layer_name='transformer.h.5.ln_1' z_layer_name='transformer.h.27'
2024-07-03 09:09:53 root INFO     [order_1_approx] starting weight calculation for If you provide something, you are a provider
If you send something, you are a sender
If you observe something, you are a observer
If you mourn something, you are a mourner
If you manage something, you are a manager
If you compose something, you are a composer
If you consume something, you are a consumer
If you contend something, you are a
2024-07-03 09:09:53 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5.ln_1
2024-07-03 09:14:00 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 8.4877e-05, -3.1967e-03,  6.5002e-03,  ..., -2.5940e-03,
         -5.7220e-03,  4.5319e-03],
        [ 1.1665e-02,  1.3161e-02,  4.6463e-03,  ...,  5.0163e-04,
         -2.2125e-03, -3.9368e-03],
        [-5.7602e-03, -1.7166e-05, -7.0381e-03,  ..., -6.9504e-03,
          6.9580e-03, -2.5238e-02],
        ...,
        [-1.1511e-03,  1.2909e-02,  1.2764e-02,  ..., -7.7248e-04,
         -4.9133e-03,  6.8855e-03],
        [ 8.5020e-04, -1.0757e-03, -3.4866e-03,  ..., -1.1169e-02,
          2.0508e-02, -1.7281e-03],
        [-7.4692e-03, -2.3788e-02,  4.3716e-03,  ..., -7.3700e-03,
         -2.3460e-03, -1.2650e-02]], device='cuda:0', dtype=torch.float16) 

                    
2024-07-03 09:14:01 root INFO     h_layer_name='transformer.h.5' z_layer_name='transformer.h.27'
2024-07-03 09:14:01 root INFO     [order_1_approx] starting weight calculation for If you provide something, you are a provider
If you send something, you are a sender
If you observe something, you are a observer
If you mourn something, you are a mourner
If you manage something, you are a manager
If you compose something, you are a composer
If you consume something, you are a consumer
If you contend something, you are a
2024-07-03 09:14:01 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5
2024-07-03 09:17:58 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0066,  0.0089,  0.0136,  ..., -0.0135, -0.0096, -0.0273],
        [-0.0243, -0.0137, -0.0097,  ..., -0.0043,  0.0153,  0.0172],
        [ 0.0185,  0.0206, -0.0352,  ...,  0.0122, -0.0081,  0.0284],
        ...,
        [-0.0176, -0.0180,  0.0010,  ..., -0.0272, -0.0002, -0.0067],
        [-0.0333, -0.0177,  0.0149,  ..., -0.0084, -0.0145, -0.0055],
        [-0.0093,  0.0381,  0.0309,  ..., -0.0190,  0.0191, -0.0502]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-03 09:17:58 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you provide something, you are a provider
If you send something, you are a sender
If you observe something, you are a observer
If you mourn something, you are a mourner
If you manage something, you are a manager
If you compose something, you are a composer
If you consume something, you are a consumer
If you contend something, you are a
2024-07-03 09:17:59 root INFO     h_layer_name='transformer.h.5.ln_1' z_layer_name='transformer.h.27'
2024-07-03 09:17:59 root INFO     [order_1_approx] starting weight calculation for If you manage something, you are a manager
If you compose something, you are a composer
If you mourn something, you are a mourner
If you observe something, you are a observer
If you send something, you are a sender
If you contend something, you are a contender
If you provide something, you are a provider
If you consume something, you are a
2024-07-03 09:17:59 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5.ln_1
2024-07-03 09:22:05 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0043, -0.0054, -0.0106,  ..., -0.0030, -0.0182, -0.0074],
        [ 0.0014,  0.0008, -0.0009,  ..., -0.0018, -0.0029, -0.0009],
        [ 0.0027,  0.0075, -0.0036,  ..., -0.0020,  0.0045, -0.0065],
        ...,
        [-0.0051, -0.0022,  0.0094,  ..., -0.0053, -0.0018, -0.0098],
        [-0.0041,  0.0008, -0.0036,  ...,  0.0055,  0.0130,  0.0055],
        [-0.0141, -0.0008, -0.0104,  ..., -0.0003, -0.0009, -0.0088]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-03 09:22:05 root INFO     h_layer_name='transformer.h.5' z_layer_name='transformer.h.27'
2024-07-03 09:22:06 root INFO     [order_1_approx] starting weight calculation for If you manage something, you are a manager
If you compose something, you are a composer
If you mourn something, you are a mourner
If you observe something, you are a observer
If you send something, you are a sender
If you contend something, you are a contender
If you provide something, you are a provider
If you consume something, you are a
2024-07-03 09:22:06 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.5
