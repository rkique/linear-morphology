2024-07-31 14:23:00 root INFO     loading model + tokenizer
2024-07-31 14:23:04 root INFO     model + tokenizer loaded
2024-07-31 14:23:04 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on meronyms - part
2024-07-31 14:23:04 root INFO     building operator meronyms - part
2024-07-31 14:23:05 root INFO     [order_1_approx] starting weight calculation for A part of a shilling is a pence
A part of a bus is a seats
A part of a gramm is a milligram
A part of a byte is a bit
A part of a harbor is a dock
A part of a teapot is a spout
A part of a piano is a keyboard
A part of a gigabit is a
2024-07-31 14:23:05 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-07-31 14:25:55 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0286, -0.2729, -0.1085,  ..., -0.2485, -0.2969,  0.0293],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.2891, -3.0469,  1.1445,  ...,  1.6045, -2.3242, -2.3027],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0097,  0.0383,  0.0196,  ..., -0.0268, -0.0007, -0.0574],
        [-0.0266, -0.0041,  0.0116,  ..., -0.0095,  0.0100,  0.0344],
        [-0.0053,  0.0247,  0.0130,  ..., -0.0339, -0.0142,  0.0273],
        ...,
        [-0.0275,  0.0137,  0.0129,  ...,  0.0481,  0.0085, -0.0004],
        [-0.0154, -0.0151, -0.0034,  ...,  0.0081,  0.0183, -0.0006],
        [-0.0215, -0.0083, -0.0204,  ...,  0.0284, -0.0042,  0.0292]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.9102, -2.6660,  0.8574,  ...,  1.5117, -2.3984, -2.1816]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 14:25:56 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A part of a shilling is a pence
A part of a bus is a seats
A part of a gramm is a milligram
A part of a byte is a bit
A part of a harbor is a dock
A part of a teapot is a spout
A part of a piano is a keyboard
A part of a gigabit is a
2024-07-31 14:25:57 root INFO     [order_1_approx] starting weight calculation for A part of a gramm is a milligram
A part of a gigabit is a megabit
A part of a piano is a keyboard
A part of a harbor is a dock
A part of a byte is a bit
A part of a teapot is a spout
A part of a shilling is a pence
A part of a bus is a
2024-07-31 14:25:57 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-07-31 14:28:46 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0926,  0.0601,  0.2455,  ...,  0.0098, -0.2812,  0.1357],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.8560, -3.9863, -1.9902,  ...,  5.0391, -1.8203, -0.9990],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0411, -0.0146, -0.0025,  ..., -0.0137,  0.0052, -0.0367],
        [ 0.0318,  0.0413, -0.0005,  ...,  0.0271,  0.0013, -0.0016],
        [ 0.0386, -0.0340,  0.0280,  ..., -0.0406, -0.0643,  0.0215],
        ...,
        [ 0.0315,  0.0240, -0.0013,  ...,  0.0448,  0.0466, -0.0302],
        [-0.0287,  0.0258,  0.0179,  ...,  0.0151, -0.0073,  0.0187],
        [ 0.0138,  0.0034,  0.0182,  ...,  0.0137,  0.0167,  0.0260]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.0537, -3.9414, -1.9404,  ...,  4.9414, -1.8896, -1.0791]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 14:28:47 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A part of a gramm is a milligram
A part of a gigabit is a megabit
A part of a piano is a keyboard
A part of a harbor is a dock
A part of a byte is a bit
A part of a teapot is a spout
A part of a shilling is a pence
A part of a bus is a
2024-07-31 14:28:47 root INFO     [order_1_approx] starting weight calculation for A part of a teapot is a spout
A part of a harbor is a dock
A part of a gigabit is a megabit
A part of a byte is a bit
A part of a piano is a keyboard
A part of a bus is a seats
A part of a shilling is a pence
A part of a gramm is a
2024-07-31 14:28:48 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-07-31 14:31:39 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3501, -0.1204,  0.1274,  ..., -0.0656,  0.0470, -0.2886],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.2148, -0.5508,  3.7246,  ..., -0.5288, -1.7930, -0.8364],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0760, -0.0518, -0.0183,  ..., -0.0882,  0.0176,  0.0300],
        [-0.0188,  0.0308, -0.0027,  ..., -0.0384, -0.0490, -0.0341],
        [-0.0175, -0.0055,  0.0547,  ..., -0.0265, -0.0435,  0.0161],
        ...,
        [-0.0099,  0.1176, -0.0037,  ...,  0.1115, -0.0167, -0.0110],
        [ 0.0512,  0.0023,  0.0009,  ...,  0.0591,  0.0053, -0.0111],
        [-0.0801,  0.0074, -0.0233,  ..., -0.0240,  0.0072,  0.0570]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.5430, -0.6089,  3.9688,  ...,  0.1875, -1.5879, -1.0859]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 14:31:40 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A part of a teapot is a spout
A part of a harbor is a dock
A part of a gigabit is a megabit
A part of a byte is a bit
A part of a piano is a keyboard
A part of a bus is a seats
A part of a shilling is a pence
A part of a gramm is a
2024-07-31 14:31:40 root INFO     [order_1_approx] starting weight calculation for A part of a gigabit is a megabit
A part of a gramm is a milligram
A part of a harbor is a dock
A part of a shilling is a pence
A part of a byte is a bit
A part of a piano is a keyboard
A part of a bus is a seats
A part of a teapot is a
2024-07-31 14:31:40 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-07-31 14:34:28 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2615, -0.1897, -0.0951,  ..., -0.0943, -0.0437, -0.0817],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.3848,  0.3125,  0.1943,  ..., -0.8105, -1.7715, -0.4531],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0078, -0.0444,  0.0445,  ...,  0.0104, -0.0115,  0.0127],
        [ 0.0135,  0.0726, -0.0284,  ...,  0.0213,  0.0049,  0.0292],
        [ 0.0195, -0.0004,  0.0062,  ...,  0.0429, -0.0047,  0.0129],
        ...,
        [-0.0204,  0.0359, -0.0056,  ...,  0.0786, -0.0281, -0.0259],
        [-0.0492, -0.0289,  0.0026,  ..., -0.0006,  0.0329,  0.0017],
        [ 0.0065, -0.0154,  0.0047,  ..., -0.0056,  0.0077,  0.0345]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.6270,  0.6519, -0.0935,  ..., -1.3164, -2.0742, -0.4839]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 14:34:29 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A part of a gigabit is a megabit
A part of a gramm is a milligram
A part of a harbor is a dock
A part of a shilling is a pence
A part of a byte is a bit
A part of a piano is a keyboard
A part of a bus is a seats
A part of a teapot is a
2024-07-31 14:34:30 root INFO     [order_1_approx] starting weight calculation for A part of a bus is a seats
A part of a harbor is a dock
A part of a gigabit is a megabit
A part of a shilling is a pence
A part of a teapot is a spout
A part of a gramm is a milligram
A part of a piano is a keyboard
A part of a byte is a
2024-07-31 14:34:30 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-07-31 14:37:19 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3154,  0.0271, -0.0538,  ..., -0.0442, -0.3008,  0.1238],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.5742, -4.6367,  0.3677,  ...,  0.2700, -2.2090, -0.5830],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.1091,  0.0434,  0.0400,  ..., -0.0197,  0.0117, -0.2061],
        [ 0.0679, -0.0361,  0.0010,  ..., -0.0449, -0.0095,  0.1539],
        [-0.0106,  0.0044,  0.0441,  ..., -0.0158,  0.0057, -0.0026],
        ...,
        [ 0.0531,  0.0055, -0.0417,  ...,  0.0931,  0.0381,  0.0315],
        [-0.0377, -0.0224,  0.0378,  ...,  0.0181,  0.0210, -0.0544],
        [ 0.0551, -0.0245, -0.0275,  ..., -0.0319, -0.0138,  0.0957]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-2.7930, -2.9023,  0.2212,  ...,  1.3652, -2.8008, -0.0483]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 14:37:20 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A part of a bus is a seats
A part of a harbor is a dock
A part of a gigabit is a megabit
A part of a shilling is a pence
A part of a teapot is a spout
A part of a gramm is a milligram
A part of a piano is a keyboard
A part of a byte is a
2024-07-31 14:37:20 root INFO     [order_1_approx] starting weight calculation for A part of a shilling is a pence
A part of a gigabit is a megabit
A part of a gramm is a milligram
A part of a piano is a keyboard
A part of a teapot is a spout
A part of a byte is a bit
A part of a bus is a seats
A part of a harbor is a
2024-07-31 14:37:20 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-07-31 14:40:07 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0284,  0.0947, -0.0855,  ..., -0.1654, -0.2332,  0.0028],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.6611, -8.2344,  1.5576,  ...,  1.1582, -1.1602,  0.8135],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0477, -0.0352, -0.0287,  ..., -0.0385,  0.0210, -0.0333],
        [ 0.0102,  0.0354, -0.0092,  ...,  0.0108, -0.0113,  0.0159],
        [-0.0305,  0.0347,  0.0274,  ...,  0.0115,  0.0308,  0.0163],
        ...,
        [-0.0136, -0.0135, -0.0556,  ...,  0.0240,  0.0265, -0.0141],
        [-0.0359,  0.0302,  0.0444,  ..., -0.0008,  0.0253, -0.0109],
        [ 0.0101, -0.0157, -0.0174,  ...,  0.0033, -0.0351,  0.0534]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.4883, -7.8516,  1.6406,  ...,  1.5508, -1.0859,  1.0469]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 14:40:08 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A part of a shilling is a pence
A part of a gigabit is a megabit
A part of a gramm is a milligram
A part of a piano is a keyboard
A part of a teapot is a spout
A part of a byte is a bit
A part of a bus is a seats
A part of a harbor is a
2024-07-31 14:40:09 root INFO     [order_1_approx] starting weight calculation for A part of a bus is a seats
A part of a byte is a bit
A part of a harbor is a dock
A part of a gramm is a milligram
A part of a gigabit is a megabit
A part of a piano is a keyboard
A part of a teapot is a spout
A part of a shilling is a
2024-07-31 14:40:09 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-07-31 14:42:55 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2260,  0.1132, -0.3618,  ...,  0.1209,  0.1516, -0.1785],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.0283,  1.1963, -1.9160,  ...,  0.4885, -1.0615, -0.3008],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.1046, -0.0167, -0.0081,  ..., -0.0263, -0.0368, -0.0202],
        [-0.0314, -0.0277,  0.0098,  ...,  0.0213,  0.0047, -0.0267],
        [ 0.0517, -0.0184,  0.0302,  ...,  0.0450,  0.0113,  0.0171],
        ...,
        [-0.0246,  0.0294, -0.0131,  ...,  0.1445, -0.0040, -0.0345],
        [-0.0115,  0.0235, -0.0144,  ..., -0.0059, -0.0089,  0.0208],
        [-0.0139, -0.0089, -0.0389,  ..., -0.0067,  0.0382,  0.0522]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.0604,  1.0029, -1.9941,  ...,  1.2949, -1.5312, -0.1958]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 14:42:56 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A part of a bus is a seats
A part of a byte is a bit
A part of a harbor is a dock
A part of a gramm is a milligram
A part of a gigabit is a megabit
A part of a piano is a keyboard
A part of a teapot is a spout
A part of a shilling is a
2024-07-31 14:42:57 root INFO     [order_1_approx] starting weight calculation for A part of a byte is a bit
A part of a teapot is a spout
A part of a gramm is a milligram
A part of a bus is a seats
A part of a harbor is a dock
A part of a gigabit is a megabit
A part of a shilling is a pence
A part of a piano is a
2024-07-31 14:42:57 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-07-31 14:45:43 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0320,  0.0783, -0.1564,  ..., -0.1819, -0.3059,  0.1266],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.6538, -2.9297,  1.0000,  ..., -2.1172, -0.3477, -1.8418],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0626, -0.0612, -0.0134,  ...,  0.0269,  0.0016, -0.0226],
        [-0.0047,  0.0300, -0.0245,  ...,  0.0450,  0.0130,  0.0109],
        [-0.0006,  0.0188,  0.0618,  ..., -0.0079, -0.0309,  0.0298],
        ...,
        [ 0.0192,  0.0130, -0.0669,  ...,  0.1049,  0.0255, -0.0180],
        [-0.0149,  0.0651, -0.0724,  ...,  0.0154,  0.0232, -0.0066],
        [-0.0303, -0.0660,  0.0053,  ...,  0.0118, -0.0244,  0.0059]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.3396, -2.6992,  1.0586,  ..., -2.5078, -1.1582, -1.6807]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 14:45:45 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A part of a byte is a bit
A part of a teapot is a spout
A part of a gramm is a milligram
A part of a bus is a seats
A part of a harbor is a dock
A part of a gigabit is a megabit
A part of a shilling is a pence
A part of a piano is a
2024-07-31 14:45:45 root INFO     total operator prediction time: 1361.1718413829803 seconds
2024-07-31 14:45:45 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on synonyms - exact
2024-07-31 14:45:45 root INFO     building operator synonyms - exact
2024-07-31 14:45:45 root INFO     [order_1_approx] starting weight calculation for Another word for airplane is aeroplane
Another word for identical is same
Another word for emphasis is accent
Another word for sweets is confectionery
Another word for package is parcel
Another word for shore is coast
Another word for homogeneous is uniform
Another word for harbor is
2024-07-31 14:45:45 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-07-31 14:48:37 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0606,  0.0657, -0.1382,  ..., -0.0008, -0.2122,  0.0079],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.9370, -6.1016,  0.2729,  ...,  2.0820, -3.4824,  2.5098],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0601, -0.0162,  0.0191,  ..., -0.0111, -0.0200,  0.0033],
        [ 0.0061,  0.0415,  0.0013,  ...,  0.0378,  0.0072,  0.0038],
        [ 0.0122, -0.0515,  0.0615,  ..., -0.0225, -0.0183,  0.0229],
        ...,
        [-0.0334,  0.0309, -0.0296,  ...,  0.0109,  0.0265, -0.0594],
        [-0.0205,  0.0163, -0.0267,  ...,  0.0036,  0.0355, -0.0170],
        [-0.0346,  0.0237, -0.0123,  ..., -0.0102,  0.0121,  0.0143]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.5508, -5.0938,  0.3569,  ...,  2.0645, -3.0723,  2.1641]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 14:48:38 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Another word for airplane is aeroplane
Another word for identical is same
Another word for emphasis is accent
Another word for sweets is confectionery
Another word for package is parcel
Another word for shore is coast
Another word for homogeneous is uniform
Another word for harbor is
2024-07-31 14:48:38 root INFO     [order_1_approx] starting weight calculation for Another word for emphasis is accent
Another word for identical is same
Another word for sweets is confectionery
Another word for shore is coast
Another word for homogeneous is uniform
Another word for harbor is seaport
Another word for airplane is aeroplane
Another word for package is
2024-07-31 14:48:38 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-07-31 14:51:30 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1160, -0.1416, -0.0237,  ..., -0.1288, -0.2010,  0.1559],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.5469, -2.0820, -1.2363,  ..., -1.7324, -0.6040, -0.5200],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0715,  0.0204,  0.0067,  ..., -0.0303, -0.0249,  0.0108],
        [-0.0326,  0.0081,  0.0379,  ...,  0.0378, -0.0022, -0.0124],
        [-0.0030, -0.0345,  0.0410,  ...,  0.0017, -0.0155, -0.0261],
        ...,
        [-0.0186,  0.0185,  0.0182,  ..., -0.0059,  0.0376, -0.0132],
        [ 0.0277, -0.0159, -0.0186,  ...,  0.0333,  0.0267, -0.0160],
        [-0.0021, -0.0370, -0.0043,  ..., -0.0037, -0.0135,  0.0669]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.1641, -2.4473, -0.6797,  ..., -1.3262, -0.6729, -0.2476]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 14:51:31 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Another word for emphasis is accent
Another word for identical is same
Another word for sweets is confectionery
Another word for shore is coast
Another word for homogeneous is uniform
Another word for harbor is seaport
Another word for airplane is aeroplane
Another word for package is
2024-07-31 14:51:31 root INFO     [order_1_approx] starting weight calculation for Another word for identical is same
Another word for sweets is confectionery
Another word for package is parcel
Another word for emphasis is accent
Another word for airplane is aeroplane
Another word for shore is coast
Another word for harbor is seaport
Another word for homogeneous is
2024-07-31 14:51:31 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-07-31 14:54:23 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0706,  0.2012, -0.0338,  ..., -0.1694, -0.1759,  0.4014],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.1816,  1.2676,  1.8359,  ..., -1.1836, -6.9062, -1.2207],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.1255, -0.0010,  0.0291,  ..., -0.0144, -0.0078,  0.0350],
        [ 0.0300,  0.0409,  0.0237,  ..., -0.0147, -0.0049, -0.0674],
        [-0.0216, -0.0380,  0.0156,  ..., -0.0066, -0.0407, -0.0164],
        ...,
        [-0.0002,  0.0749,  0.0025,  ...,  0.0594, -0.0424, -0.0209],
        [-0.0061, -0.0210, -0.0182,  ...,  0.0195, -0.0126,  0.0363],
        [ 0.0041, -0.0008,  0.0122,  ...,  0.0015, -0.0282,  0.0052]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.9609,  0.7578,  1.5967,  ..., -0.8613, -7.0078, -0.5938]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 14:54:24 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Another word for identical is same
Another word for sweets is confectionery
Another word for package is parcel
Another word for emphasis is accent
Another word for airplane is aeroplane
Another word for shore is coast
Another word for harbor is seaport
Another word for homogeneous is
2024-07-31 14:54:24 root INFO     [order_1_approx] starting weight calculation for Another word for airplane is aeroplane
Another word for homogeneous is uniform
Another word for identical is same
Another word for harbor is seaport
Another word for emphasis is accent
Another word for package is parcel
Another word for shore is coast
Another word for sweets is
2024-07-31 14:54:24 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-07-31 14:57:15 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1071, -0.0160,  0.3684,  ..., -0.0077, -0.2444, -0.0615],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.9258, -6.9688,  1.2441,  ..., -1.6602, -2.0078,  2.6211],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0531, -0.0259,  0.0052,  ..., -0.0428,  0.0079,  0.0328],
        [-0.0249,  0.0213,  0.0271,  ..., -0.0208, -0.0285, -0.0011],
        [-0.0135, -0.0079,  0.0206,  ...,  0.0117, -0.0296,  0.0016],
        ...,
        [ 0.0086,  0.0382, -0.0239,  ...,  0.0154, -0.0070, -0.0204],
        [-0.0040, -0.0023, -0.0368,  ...,  0.0197,  0.0312, -0.0021],
        [-0.0197,  0.0271, -0.0026,  ...,  0.0189,  0.0041,  0.0293]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.4766, -7.2852,  0.8965,  ..., -1.4404, -2.1328,  2.1250]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 14:57:17 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Another word for airplane is aeroplane
Another word for homogeneous is uniform
Another word for identical is same
Another word for harbor is seaport
Another word for emphasis is accent
Another word for package is parcel
Another word for shore is coast
Another word for sweets is
2024-07-31 14:57:17 root INFO     [order_1_approx] starting weight calculation for Another word for package is parcel
Another word for identical is same
Another word for sweets is confectionery
Another word for harbor is seaport
Another word for emphasis is accent
Another word for homogeneous is uniform
Another word for shore is coast
Another word for airplane is
2024-07-31 14:57:17 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-07-31 15:00:09 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0477,  0.0747, -0.2905,  ...,  0.1165, -0.1750,  0.1350],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.1128, -3.0156,  3.2344,  ..., -0.6650, -2.5879,  1.4219],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0320, -0.0027, -0.0138,  ...,  0.0200,  0.0267,  0.0130],
        [ 0.0038,  0.0703, -0.0125,  ...,  0.0325,  0.0250,  0.0089],
        [ 0.0054, -0.0137,  0.0490,  ..., -0.0090, -0.0160,  0.0165],
        ...,
        [-0.0028,  0.0270, -0.0025,  ...,  0.0396,  0.0104, -0.0154],
        [-0.0172,  0.0073,  0.0064,  ..., -0.0097,  0.0383,  0.0157],
        [ 0.0084,  0.0077,  0.0100,  ...,  0.0016,  0.0009,  0.0103]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.1467, -3.0840,  2.9668,  ..., -0.6562, -2.4766,  1.3945]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 15:00:10 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Another word for package is parcel
Another word for identical is same
Another word for sweets is confectionery
Another word for harbor is seaport
Another word for emphasis is accent
Another word for homogeneous is uniform
Another word for shore is coast
Another word for airplane is
2024-07-31 15:00:11 root INFO     [order_1_approx] starting weight calculation for Another word for sweets is confectionery
Another word for identical is same
Another word for homogeneous is uniform
Another word for harbor is seaport
Another word for airplane is aeroplane
Another word for package is parcel
Another word for shore is coast
Another word for emphasis is
2024-07-31 15:00:11 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-07-31 15:03:00 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2573,  0.0414, -0.2451,  ...,  0.1229, -0.1401,  0.4185],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.7891, -2.8848,  0.3662,  ...,  1.3701, -1.8535, -3.3789],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 4.2969e-02, -3.6285e-02, -1.2531e-03,  ...,  1.4549e-02,
          2.6154e-02,  3.7659e-02],
        [-2.3132e-02,  5.1025e-02, -1.4328e-02,  ..., -2.2400e-02,
          1.0323e-02,  9.6321e-05],
        [ 2.3376e-02, -9.8267e-03,  7.9880e-03,  ...,  1.9318e-02,
          2.2369e-02, -1.2543e-02],
        ...,
        [-1.3283e-02,  8.3847e-03,  4.6234e-03,  ...,  2.3560e-02,
         -2.7893e-02, -3.6316e-02],
        [-3.3455e-03,  1.7052e-03, -1.7471e-02,  ...,  6.7902e-03,
          3.5801e-03,  5.3673e-03],
        [-6.5994e-03, -1.0323e-02, -3.4142e-03,  ..., -1.4015e-02,
         -1.6068e-02,  3.7598e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.2803, -3.4023,  0.7690,  ...,  1.2363, -2.0293, -3.5781]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 15:03:02 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Another word for sweets is confectionery
Another word for identical is same
Another word for homogeneous is uniform
Another word for harbor is seaport
Another word for airplane is aeroplane
Another word for package is parcel
Another word for shore is coast
Another word for emphasis is
2024-07-31 15:03:02 root INFO     [order_1_approx] starting weight calculation for Another word for sweets is confectionery
Another word for homogeneous is uniform
Another word for airplane is aeroplane
Another word for package is parcel
Another word for harbor is seaport
Another word for emphasis is accent
Another word for identical is same
Another word for shore is
2024-07-31 15:03:02 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-07-31 15:05:54 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0253,  0.0972, -0.0463,  ..., -0.2063, -0.1198,  0.1489],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.7148, -3.1309,  0.8115,  ...,  4.0625, -0.9639, -2.2227],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0571, -0.0703, -0.0036,  ...,  0.0387,  0.0125,  0.0156],
        [ 0.0137, -0.0172,  0.0286,  ...,  0.0320, -0.0352,  0.0054],
        [-0.0169,  0.0143,  0.1101,  ..., -0.0088, -0.0235,  0.0264],
        ...,
        [-0.0267, -0.0070,  0.0006,  ...,  0.0427, -0.0044, -0.0257],
        [-0.0119,  0.0399,  0.0232,  ..., -0.0004,  0.0471, -0.0224],
        [-0.0437,  0.0131, -0.0388,  ..., -0.0288,  0.0150,  0.0368]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.3242, -3.0664,  0.7627,  ...,  3.5508, -1.7637, -1.9404]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 15:05:55 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Another word for sweets is confectionery
Another word for homogeneous is uniform
Another word for airplane is aeroplane
Another word for package is parcel
Another word for harbor is seaport
Another word for emphasis is accent
Another word for identical is same
Another word for shore is
2024-07-31 15:05:56 root INFO     [order_1_approx] starting weight calculation for Another word for homogeneous is uniform
Another word for airplane is aeroplane
Another word for sweets is confectionery
Another word for harbor is seaport
Another word for shore is coast
Another word for package is parcel
Another word for emphasis is accent
Another word for identical is
2024-07-31 15:05:56 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-07-31 15:08:47 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0977, -0.1063, -0.1804,  ..., -0.1299, -0.1191,  0.3601],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.3669,  0.0649,  2.0840,  ...,  0.0621, -3.0996, -0.6631],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0590,  0.0156, -0.0038,  ..., -0.0105,  0.0714,  0.0378],
        [-0.0051,  0.0165,  0.0060,  ..., -0.0024, -0.0093, -0.0063],
        [ 0.0295,  0.0015,  0.0096,  ...,  0.0162, -0.0192, -0.0106],
        ...,
        [-0.0007,  0.0236, -0.0295,  ...,  0.0332, -0.0299, -0.0362],
        [ 0.0435, -0.0350, -0.0113,  ...,  0.0319, -0.0303, -0.0278],
        [-0.0023, -0.0195, -0.0004,  ...,  0.0107, -0.0321,  0.0031]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.0115, -0.1917,  1.8438,  ...,  0.6016, -4.0781, -0.7324]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 15:08:48 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Another word for homogeneous is uniform
Another word for airplane is aeroplane
Another word for sweets is confectionery
Another word for harbor is seaport
Another word for shore is coast
Another word for package is parcel
Another word for emphasis is accent
Another word for identical is
2024-07-31 15:08:48 root INFO     total operator prediction time: 1383.4478642940521 seconds
2024-07-31 15:08:48 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on hypernyms - misc
2024-07-31 15:08:48 root INFO     building operator hypernyms - misc
2024-07-31 15:08:49 root INFO     [order_1_approx] starting weight calculation for The tub falls into the category of container
The dress falls into the category of clothes
The perfume falls into the category of toiletry
The brooch falls into the category of jewelry
The notebook falls into the category of book
The pie falls into the category of pastry
The stapler falls into the category of device
The skirt falls into the category of
2024-07-31 15:08:49 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-07-31 15:11:35 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1814, -0.2236, -0.1926,  ...,  0.3379, -0.1635,  0.1010],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.3652, -5.5859,  0.6821,  ..., -0.4604, -3.1758,  0.0693],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0252, -0.0416, -0.0306,  ..., -0.0129,  0.0246,  0.0137],
        [-0.0096,  0.0201,  0.0147,  ...,  0.0241,  0.0116,  0.0242],
        [ 0.0051,  0.0001,  0.0276,  ...,  0.0089, -0.0164, -0.0230],
        ...,
        [ 0.0251, -0.0050,  0.0200,  ...,  0.0477,  0.0181, -0.0258],
        [-0.0017, -0.0088, -0.0153,  ...,  0.0472,  0.0373,  0.0052],
        [ 0.0059, -0.0315,  0.0225,  ..., -0.0104, -0.0083,  0.0632]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.0449, -5.7539,  1.3467,  ..., -0.7192, -3.4785, -0.1583]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 15:11:36 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The tub falls into the category of container
The dress falls into the category of clothes
The perfume falls into the category of toiletry
The brooch falls into the category of jewelry
The notebook falls into the category of book
The pie falls into the category of pastry
The stapler falls into the category of device
The skirt falls into the category of
2024-07-31 15:11:37 root INFO     [order_1_approx] starting weight calculation for The brooch falls into the category of jewelry
The perfume falls into the category of toiletry
The dress falls into the category of clothes
The tub falls into the category of container
The pie falls into the category of pastry
The notebook falls into the category of book
The skirt falls into the category of clothes
The stapler falls into the category of
2024-07-31 15:11:37 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-07-31 15:14:25 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2025, -0.1724, -0.2283,  ...,  0.0387, -0.3647, -0.2261],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.5117, -4.6328,  1.1230,  ..., -1.9844, -3.6055,  0.0420],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0587, -0.0117, -0.0238,  ..., -0.0025, -0.0033,  0.0133],
        [-0.0127,  0.0375,  0.0127,  ..., -0.0034, -0.0168, -0.0101],
        [ 0.0234, -0.0103,  0.0133,  ..., -0.0075, -0.0208,  0.0072],
        ...,
        [ 0.0006,  0.0088,  0.0235,  ...,  0.0303, -0.0020,  0.0039],
        [ 0.0010, -0.0089,  0.0070,  ..., -0.0034,  0.0259, -0.0039],
        [-0.0012,  0.0250,  0.0129,  ..., -0.0160, -0.0108,  0.0264]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.9492, -4.7617,  1.5137,  ..., -1.5771, -3.9727,  0.4390]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 15:14:26 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The brooch falls into the category of jewelry
The perfume falls into the category of toiletry
The dress falls into the category of clothes
The tub falls into the category of container
The pie falls into the category of pastry
The notebook falls into the category of book
The skirt falls into the category of clothes
The stapler falls into the category of
2024-07-31 15:14:27 root INFO     [order_1_approx] starting weight calculation for The pie falls into the category of pastry
The perfume falls into the category of toiletry
The stapler falls into the category of device
The tub falls into the category of container
The skirt falls into the category of clothes
The brooch falls into the category of jewelry
The dress falls into the category of clothes
The notebook falls into the category of
2024-07-31 15:14:27 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-07-31 15:17:16 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2617,  0.0197, -0.3096,  ...,  0.2106, -0.2715, -0.0990],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.5381, -2.9473,  1.2734,  ..., -1.9248, -2.6914, -0.1807],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0377, -0.0287, -0.0167,  ..., -0.0243,  0.0163,  0.0025],
        [-0.0139,  0.0373,  0.0243,  ...,  0.0153, -0.0262, -0.0025],
        [-0.0093, -0.0308,  0.0194,  ..., -0.0033, -0.0556,  0.0166],
        ...,
        [ 0.0020, -0.0109, -0.0115,  ...,  0.0388, -0.0083, -0.0252],
        [-0.0270,  0.0094,  0.0279,  ...,  0.0369,  0.0167,  0.0210],
        [ 0.0117,  0.0007,  0.0328,  ..., -0.0209,  0.0180,  0.0202]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.4043, -3.4258,  1.4082,  ..., -1.9219, -2.1484, -0.7217]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 15:17:17 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The pie falls into the category of pastry
The perfume falls into the category of toiletry
The stapler falls into the category of device
The tub falls into the category of container
The skirt falls into the category of clothes
The brooch falls into the category of jewelry
The dress falls into the category of clothes
The notebook falls into the category of
2024-07-31 15:17:17 root INFO     [order_1_approx] starting weight calculation for The stapler falls into the category of device
The notebook falls into the category of book
The dress falls into the category of clothes
The skirt falls into the category of clothes
The perfume falls into the category of toiletry
The tub falls into the category of container
The pie falls into the category of pastry
The brooch falls into the category of
2024-07-31 15:17:17 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-07-31 15:20:08 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0562, -0.0345, -0.0534,  ...,  0.2852,  0.0323,  0.1477],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.4473, -8.5312, -3.2754,  ..., -0.8799, -4.8203,  2.8633],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0685, -0.0458,  0.0268,  ..., -0.0390,  0.0179,  0.0146],
        [ 0.0452, -0.0082,  0.0050,  ..., -0.0712,  0.0881, -0.0231],
        [ 0.0182,  0.0050, -0.0142,  ...,  0.0485, -0.0745,  0.0309],
        ...,
        [ 0.0324, -0.0524, -0.0105,  ...,  0.0420,  0.0190, -0.0374],
        [-0.0290, -0.0091,  0.0011,  ...,  0.0394,  0.0498, -0.0105],
        [ 0.0050, -0.0234, -0.0007,  ..., -0.0460,  0.0220,  0.0330]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.4004, -7.7344, -2.9023,  ..., -0.4734, -4.6562,  3.2520]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 15:20:09 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The stapler falls into the category of device
The notebook falls into the category of book
The dress falls into the category of clothes
The skirt falls into the category of clothes
The perfume falls into the category of toiletry
The tub falls into the category of container
The pie falls into the category of pastry
The brooch falls into the category of
2024-07-31 15:20:09 root INFO     [order_1_approx] starting weight calculation for The brooch falls into the category of jewelry
The tub falls into the category of container
The dress falls into the category of clothes
The skirt falls into the category of clothes
The stapler falls into the category of device
The perfume falls into the category of toiletry
The notebook falls into the category of book
The pie falls into the category of
2024-07-31 15:20:10 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-07-31 15:23:01 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0177, -0.3315, -0.1122,  ..., -0.2172, -0.2373,  0.0540],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.2656, -5.9844, -0.0229,  ..., -3.5430, -3.6406, -0.5068],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0472,  0.0275,  0.0051,  ..., -0.0229, -0.0203,  0.0103],
        [ 0.0497, -0.1323, -0.0359,  ..., -0.0155, -0.0614, -0.0486],
        [-0.0437,  0.0117,  0.0547,  ..., -0.0291,  0.0130,  0.0150],
        ...,
        [ 0.0376, -0.0897, -0.0079,  ...,  0.0325, -0.0474, -0.0424],
        [-0.0035, -0.0575, -0.0185,  ..., -0.0076,  0.0614, -0.0117],
        [ 0.0058, -0.1326, -0.0246,  ..., -0.0222, -0.0364, -0.0210]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.6660, -5.3672, -0.3235,  ..., -3.1641, -3.2910,  0.1304]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 15:23:02 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The brooch falls into the category of jewelry
The tub falls into the category of container
The dress falls into the category of clothes
The skirt falls into the category of clothes
The stapler falls into the category of device
The perfume falls into the category of toiletry
The notebook falls into the category of book
The pie falls into the category of
2024-07-31 15:23:02 root INFO     [order_1_approx] starting weight calculation for The dress falls into the category of clothes
The perfume falls into the category of toiletry
The pie falls into the category of pastry
The notebook falls into the category of book
The stapler falls into the category of device
The brooch falls into the category of jewelry
The skirt falls into the category of clothes
The tub falls into the category of
2024-07-31 15:23:02 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-07-31 15:25:50 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1326, -0.2429,  0.0274,  ..., -0.1976, -0.2230, -0.0360],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.4199, -2.2559,  3.1504,  ..., -1.8965, -2.1445,  1.4023],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0420,  0.0084, -0.0042,  ...,  0.0047,  0.0096, -0.0137],
        [ 0.0131,  0.0645,  0.0367,  ..., -0.0532, -0.0278, -0.0180],
        [-0.0181,  0.0747, -0.0322,  ...,  0.0075,  0.0380,  0.0399],
        ...,
        [ 0.0421, -0.0621,  0.0770,  ...,  0.0320, -0.0204,  0.0254],
        [ 0.0098, -0.0503,  0.0496,  ..., -0.0309,  0.0025, -0.0170],
        [ 0.0104,  0.0203,  0.0055,  ...,  0.0023, -0.0116,  0.0406]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.5132, -2.0918,  2.9492,  ..., -1.6143, -2.0781,  1.2930]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 15:25:51 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The dress falls into the category of clothes
The perfume falls into the category of toiletry
The pie falls into the category of pastry
The notebook falls into the category of book
The stapler falls into the category of device
The brooch falls into the category of jewelry
The skirt falls into the category of clothes
The tub falls into the category of
2024-07-31 15:25:51 root INFO     [order_1_approx] starting weight calculation for The perfume falls into the category of toiletry
The pie falls into the category of pastry
The brooch falls into the category of jewelry
The notebook falls into the category of book
The skirt falls into the category of clothes
The tub falls into the category of container
The stapler falls into the category of device
The dress falls into the category of
2024-07-31 15:25:51 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-07-31 15:28:41 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0317, -0.1917, -0.2140,  ...,  0.1697, -0.2368, -0.0186],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.7051, -5.3516,  0.2128,  ..., -0.2446, -3.8301, -0.4409],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0043, -0.0250, -0.0266,  ..., -0.0075,  0.0186, -0.0112],
        [-0.0202,  0.0382,  0.0054,  ...,  0.0077,  0.0004, -0.0343],
        [ 0.0298, -0.0097,  0.0374,  ..., -0.0299, -0.0248, -0.0013],
        ...,
        [ 0.0072, -0.0146,  0.0274,  ...,  0.0258,  0.0077, -0.0095],
        [-0.0101,  0.0127,  0.0101,  ..., -0.0078,  0.0023, -0.0095],
        [-0.0139, -0.0474, -0.0159,  ...,  0.0540,  0.0095,  0.0059]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.5918, -4.8516,  0.7188,  ..., -0.5791, -3.8770, -0.4478]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 15:28:42 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The perfume falls into the category of toiletry
The pie falls into the category of pastry
The brooch falls into the category of jewelry
The notebook falls into the category of book
The skirt falls into the category of clothes
The tub falls into the category of container
The stapler falls into the category of device
The dress falls into the category of
2024-07-31 15:28:42 root INFO     [order_1_approx] starting weight calculation for The tub falls into the category of container
The dress falls into the category of clothes
The brooch falls into the category of jewelry
The stapler falls into the category of device
The pie falls into the category of pastry
The notebook falls into the category of book
The skirt falls into the category of clothes
The perfume falls into the category of
2024-07-31 15:28:42 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-07-31 15:31:33 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0029, -0.0917, -0.1636,  ..., -0.4194,  0.0446, -0.1604],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.4980, -3.5195,  0.4741,  ..., -4.4492, -3.0078,  2.6367],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0086,  0.0051,  0.0050,  ..., -0.0082, -0.0104,  0.0070],
        [-0.0010,  0.0107,  0.0059,  ..., -0.0034,  0.0164,  0.0003],
        [-0.0057,  0.0012,  0.0189,  ..., -0.0042, -0.0026, -0.0110],
        ...,
        [ 0.0355, -0.0292,  0.0129,  ...,  0.0389,  0.0392,  0.0058],
        [-0.0143,  0.0047, -0.0106,  ...,  0.0115,  0.0309, -0.0059],
        [ 0.0121,  0.0136, -0.0047,  ..., -0.0081,  0.0037,  0.0259]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.7930, -3.6191,  0.5225,  ..., -4.3242, -3.0898,  2.5000]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 15:31:34 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The tub falls into the category of container
The dress falls into the category of clothes
The brooch falls into the category of jewelry
The stapler falls into the category of device
The pie falls into the category of pastry
The notebook falls into the category of book
The skirt falls into the category of clothes
The perfume falls into the category of
2024-07-31 15:31:34 root INFO     total operator prediction time: 1365.6322495937347 seconds
2024-07-31 15:31:34 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on meronyms - substance
2024-07-31 15:31:34 root INFO     building operator meronyms - substance
2024-07-31 15:31:34 root INFO     [order_1_approx] starting weight calculation for A jam is made up of fruit
A table is made up of wood
A clothing is made up of fabric
A concrete is made up of silicon
A roof is made up of shingles
A body is made up of flesh
A ocean is made up of water
A wig is made up of
2024-07-31 15:31:34 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-07-31 15:34:25 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1549,  0.1384, -0.1453,  ...,  0.1065,  0.0469, -0.0637],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.9189, -6.1211, -1.9863,  ..., -1.4150, -0.9443,  0.3965],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0538, -0.0257, -0.0133,  ...,  0.0301, -0.0252,  0.0235],
        [-0.0448,  0.0596, -0.0195,  ..., -0.0036, -0.0206, -0.0174],
        [-0.0067, -0.0071,  0.0419,  ...,  0.0106, -0.0063, -0.0224],
        ...,
        [ 0.0406, -0.0067,  0.0254,  ..., -0.0026, -0.0081, -0.0218],
        [ 0.0162,  0.0044, -0.0166,  ...,  0.0254,  0.0282, -0.0117],
        [ 0.0217, -0.0486,  0.0270,  ...,  0.0043,  0.0517,  0.0682]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.3867, -6.0273, -1.6445,  ..., -1.6309, -0.8340, -0.0747]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 15:34:26 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A jam is made up of fruit
A table is made up of wood
A clothing is made up of fabric
A concrete is made up of silicon
A roof is made up of shingles
A body is made up of flesh
A ocean is made up of water
A wig is made up of
2024-07-31 15:34:27 root INFO     [order_1_approx] starting weight calculation for A table is made up of wood
A jam is made up of fruit
A concrete is made up of silicon
A ocean is made up of water
A wig is made up of hair
A roof is made up of shingles
A body is made up of flesh
A clothing is made up of
2024-07-31 15:34:27 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-07-31 15:37:16 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0919, -0.0312, -0.3311,  ...,  0.1075,  0.0239, -0.1484],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.5938, -8.1562,  1.4277,  ..., -1.4785, -0.6807,  1.7344],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 1.5320e-02, -1.2596e-02,  2.8534e-02,  ...,  1.5366e-02,
         -3.6072e-02,  2.3987e-02],
        [ 2.3270e-04,  8.7891e-03, -5.6458e-04,  ...,  1.1101e-02,
          4.3030e-03,  2.4834e-03],
        [ 1.9928e-02, -1.3519e-02,  3.0548e-02,  ...,  3.0029e-02,
         -3.8788e-02, -6.6223e-03],
        ...,
        [ 2.4170e-02, -2.2614e-02,  1.7990e-02,  ...,  2.7435e-02,
         -6.1302e-03, -1.0071e-02],
        [-5.3406e-03,  2.0554e-02,  1.1734e-02,  ...,  2.2430e-02,
         -6.6605e-03,  5.5695e-04],
        [-6.2180e-04,  3.8147e-05, -1.0735e-02,  ..., -2.0355e-02,
          1.4542e-02,  1.9104e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.7969, -7.7109,  0.9253,  ..., -1.3232, -1.5742,  1.7939]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 15:37:17 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A table is made up of wood
A jam is made up of fruit
A concrete is made up of silicon
A ocean is made up of water
A wig is made up of hair
A roof is made up of shingles
A body is made up of flesh
A clothing is made up of
2024-07-31 15:37:18 root INFO     [order_1_approx] starting weight calculation for A concrete is made up of silicon
A ocean is made up of water
A jam is made up of fruit
A clothing is made up of fabric
A table is made up of wood
A wig is made up of hair
A roof is made up of shingles
A body is made up of
2024-07-31 15:37:18 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-07-31 15:40:08 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0801,  0.0718, -0.0347,  ..., -0.0530, -0.0079, -0.2234],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.5352, -7.6406,  1.9482,  ..., -3.7812, -3.6367, -0.4268],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0129,  0.0026,  0.0059,  ..., -0.0042,  0.0040,  0.0035],
        [-0.0211,  0.0163,  0.0195,  ...,  0.0047,  0.0004, -0.0080],
        [-0.0068,  0.0002, -0.0151,  ...,  0.0078, -0.0195,  0.0192],
        ...,
        [-0.0176,  0.0247, -0.0130,  ...,  0.0303, -0.0029, -0.0136],
        [ 0.0054, -0.0158,  0.0337,  ..., -0.0333,  0.0153,  0.0043],
        [ 0.0185, -0.0175,  0.0208,  ..., -0.0108,  0.0048,  0.0205]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.0645, -7.2930,  1.7480,  ..., -3.7910, -3.5410,  0.2188]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 15:40:10 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A concrete is made up of silicon
A ocean is made up of water
A jam is made up of fruit
A clothing is made up of fabric
A table is made up of wood
A wig is made up of hair
A roof is made up of shingles
A body is made up of
2024-07-31 15:40:10 root INFO     [order_1_approx] starting weight calculation for A ocean is made up of water
A roof is made up of shingles
A concrete is made up of silicon
A body is made up of flesh
A clothing is made up of fabric
A table is made up of wood
A wig is made up of hair
A jam is made up of
2024-07-31 15:40:10 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-07-31 15:42:59 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1650,  0.1282, -0.0592,  ...,  0.0538, -0.3752,  0.0903],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.9121, -7.9648, -0.4766,  ..., -2.3047, -3.9707,  2.1016],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0283, -0.0428,  0.0200,  ..., -0.0190, -0.0027,  0.0148],
        [-0.0280, -0.0011, -0.0018,  ..., -0.0248,  0.0446, -0.0250],
        [-0.0203, -0.0107,  0.0230,  ..., -0.0269, -0.0118, -0.0006],
        ...,
        [-0.0002, -0.0088,  0.0279,  ...,  0.0850, -0.0139, -0.0454],
        [ 0.0302, -0.0029, -0.0945,  ...,  0.0699,  0.0442, -0.0474],
        [-0.0249, -0.0400,  0.0120,  ..., -0.0275,  0.0054,  0.0768]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.5117, -8.3047, -0.2539,  ..., -2.7168, -3.7305,  2.6250]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 15:43:00 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A ocean is made up of water
A roof is made up of shingles
A concrete is made up of silicon
A body is made up of flesh
A clothing is made up of fabric
A table is made up of wood
A wig is made up of hair
A jam is made up of
2024-07-31 15:43:00 root INFO     [order_1_approx] starting weight calculation for A jam is made up of fruit
A wig is made up of hair
A concrete is made up of silicon
A clothing is made up of fabric
A body is made up of flesh
A ocean is made up of water
A table is made up of wood
A roof is made up of
2024-07-31 15:43:00 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-07-31 15:45:50 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0318,  0.0959,  0.0581,  ..., -0.0992, -0.1810, -0.2087],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.9766, -6.4805,  1.6836,  ..., -2.4434, -0.4629, -1.8955],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0475, -0.0455,  0.0288,  ..., -0.0366,  0.0078, -0.0036],
        [-0.0250,  0.0199, -0.0200,  ..., -0.0189, -0.0016,  0.0245],
        [-0.0076,  0.0356, -0.0244,  ...,  0.0388, -0.0246, -0.0118],
        ...,
        [ 0.0211,  0.0249, -0.0100,  ...,  0.0670, -0.0074, -0.0107],
        [ 0.0036,  0.0492, -0.0245,  ...,  0.0160,  0.0030,  0.0364],
        [ 0.0134, -0.0325,  0.0038,  ..., -0.0038,  0.0150,  0.0217]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 5.4414, -5.9297,  1.3916,  ..., -2.5488, -0.9170, -1.6543]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 15:45:51 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A jam is made up of fruit
A wig is made up of hair
A concrete is made up of silicon
A clothing is made up of fabric
A body is made up of flesh
A ocean is made up of water
A table is made up of wood
A roof is made up of
2024-07-31 15:45:52 root INFO     [order_1_approx] starting weight calculation for A table is made up of wood
A wig is made up of hair
A ocean is made up of water
A body is made up of flesh
A clothing is made up of fabric
A jam is made up of fruit
A roof is made up of shingles
A concrete is made up of
2024-07-31 15:45:52 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-07-31 15:48:43 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0652,  0.0391, -0.1555,  ...,  0.1857, -0.2245,  0.1803],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.1719, -7.0234, -0.6729,  ..., -1.4658, -0.4502,  0.2695],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0464, -0.0043,  0.0145,  ..., -0.0160, -0.0201, -0.0130],
        [-0.0142,  0.0158,  0.0146,  ..., -0.0075, -0.0193,  0.0038],
        [-0.0060,  0.0143,  0.0281,  ...,  0.0291, -0.0044,  0.0075],
        ...,
        [ 0.0308, -0.0007,  0.0406,  ...,  0.0462, -0.0089, -0.0052],
        [-0.0127,  0.0118,  0.0072,  ..., -0.0334, -0.0332,  0.0082],
        [-0.0026, -0.0239, -0.0133,  ..., -0.0330,  0.0339,  0.0076]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.0879, -6.9688, -0.4062,  ..., -1.2510, -1.3340,  0.3936]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 15:48:44 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A table is made up of wood
A wig is made up of hair
A ocean is made up of water
A body is made up of flesh
A clothing is made up of fabric
A jam is made up of fruit
A roof is made up of shingles
A concrete is made up of
2024-07-31 15:48:44 root INFO     [order_1_approx] starting weight calculation for A clothing is made up of fabric
A concrete is made up of silicon
A wig is made up of hair
A body is made up of flesh
A jam is made up of fruit
A roof is made up of shingles
A table is made up of wood
A ocean is made up of
2024-07-31 15:48:44 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-07-31 15:51:35 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0113,  0.3623, -0.0254,  ..., -0.0482, -0.0547, -0.2285],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.0781, -4.0898,  1.8379,  ..., -5.0938,  2.5996, -1.0732],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.1086,  0.1553, -0.1049,  ..., -0.0098,  0.0509,  0.0707],
        [ 0.0740, -0.0654,  0.0369,  ..., -0.0132, -0.0278, -0.0540],
        [-0.0140,  0.0424,  0.0078,  ...,  0.0452,  0.0364,  0.0379],
        ...,
        [ 0.0936, -0.0548,  0.0417,  ...,  0.0166, -0.0422, -0.0139],
        [-0.0646,  0.0698, -0.0295,  ..., -0.0015,  0.0292,  0.0368],
        [ 0.0235, -0.0751,  0.0483,  ..., -0.0107, -0.0094, -0.0084]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.2246, -3.8945,  1.3984,  ..., -4.8867,  2.0781, -0.1689]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 15:51:36 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A clothing is made up of fabric
A concrete is made up of silicon
A wig is made up of hair
A body is made up of flesh
A jam is made up of fruit
A roof is made up of shingles
A table is made up of wood
A ocean is made up of
2024-07-31 15:51:37 root INFO     [order_1_approx] starting weight calculation for A jam is made up of fruit
A concrete is made up of silicon
A body is made up of flesh
A ocean is made up of water
A wig is made up of hair
A roof is made up of shingles
A clothing is made up of fabric
A table is made up of
2024-07-31 15:51:37 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-07-31 15:54:28 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1464,  0.0129, -0.2490,  ..., -0.0583, -0.1624, -0.2275],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.2305e+00, -4.3125e+00,  3.1973e+00,  ..., -4.6914e+00,
         1.0986e-03, -4.5850e-01], device='cuda:1', dtype=torch.float16,
       grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0021, -0.0225,  0.0297,  ..., -0.0139, -0.0247, -0.0104],
        [-0.0005,  0.0461, -0.0080,  ...,  0.0276, -0.0162,  0.0084],
        [-0.0139,  0.0767,  0.0297,  ...,  0.0132, -0.0276,  0.0051],
        ...,
        [ 0.0586, -0.0216, -0.0029,  ...,  0.0712, -0.0191,  0.0046],
        [ 0.0011,  0.0281,  0.0120,  ..., -0.0038,  0.0165, -0.0124],
        [-0.0155,  0.0131,  0.0223,  ..., -0.0012, -0.0104, -0.0043]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.3125, -4.6328,  2.9980,  ..., -5.0664, -0.3882, -0.2056]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 15:54:29 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A jam is made up of fruit
A concrete is made up of silicon
A body is made up of flesh
A ocean is made up of water
A wig is made up of hair
A roof is made up of shingles
A clothing is made up of fabric
A table is made up of
2024-07-31 15:54:29 root INFO     total operator prediction time: 1375.067198753357 seconds
2024-07-31 15:54:29 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on synonyms - intensity
2024-07-31 15:54:29 root INFO     building operator synonyms - intensity
2024-07-31 15:54:29 root INFO     [order_1_approx] starting weight calculation for A more intense word for boring is tedious
A more intense word for hungry is starving
A more intense word for strong is powerful
A more intense word for dislike is hate
A more intense word for unhappy is miserable
A more intense word for necessary is essential
A more intense word for like is love
A more intense word for well is
2024-07-31 15:54:29 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-07-31 15:57:20 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0135, -0.1130,  0.0276,  ..., -0.1324, -0.4028,  0.0091],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.3828, -0.0068,  1.5986,  ..., -2.2148, -5.3633, -2.1133],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0425,  0.0023,  0.0426,  ..., -0.0311, -0.0066,  0.0034],
        [-0.0376,  0.0085,  0.0704,  ...,  0.0808,  0.0135, -0.0222],
        [ 0.0099, -0.0529,  0.0055,  ...,  0.0322, -0.0233,  0.0462],
        ...,
        [-0.0228,  0.0132,  0.0211,  ...,  0.0828,  0.0251,  0.0273],
        [ 0.0724, -0.0671, -0.0580,  ..., -0.0313,  0.0930,  0.0956],
        [-0.0043, -0.0218,  0.0248,  ...,  0.0833, -0.0108,  0.0564]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.6934, -0.2844,  1.8994,  ..., -2.3320, -5.2539, -2.2422]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 15:57:21 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more intense word for boring is tedious
A more intense word for hungry is starving
A more intense word for strong is powerful
A more intense word for dislike is hate
A more intense word for unhappy is miserable
A more intense word for necessary is essential
A more intense word for like is love
A more intense word for well is
2024-07-31 15:57:21 root INFO     [order_1_approx] starting weight calculation for A more intense word for dislike is hate
A more intense word for unhappy is miserable
A more intense word for boring is tedious
A more intense word for like is love
A more intense word for strong is powerful
A more intense word for necessary is essential
A more intense word for well is flourishing
A more intense word for hungry is
2024-07-31 15:57:21 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-07-31 16:00:12 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0233, -0.2815, -0.1945,  ..., -0.0743, -0.2297,  0.1229],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.8086, -3.2266,  2.3340,  ..., -0.6934, -2.0508, -0.3828],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0058, -0.0231,  0.0134,  ..., -0.0017,  0.0155,  0.0098],
        [ 0.0114,  0.0603,  0.0013,  ...,  0.0055,  0.0128,  0.0026],
        [-0.0014, -0.0252,  0.0131,  ..., -0.0011, -0.0256,  0.0009],
        ...,
        [ 0.0159,  0.0196, -0.0197,  ...,  0.0316, -0.0096, -0.0079],
        [-0.0336, -0.0184,  0.0016,  ..., -0.0231,  0.0199, -0.0169],
        [-0.0071,  0.0002, -0.0070,  ..., -0.0027, -0.0296,  0.0039]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.9473, -3.1855,  2.1953,  ..., -0.6860, -2.1484, -0.2335]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 16:00:13 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more intense word for dislike is hate
A more intense word for unhappy is miserable
A more intense word for boring is tedious
A more intense word for like is love
A more intense word for strong is powerful
A more intense word for necessary is essential
A more intense word for well is flourishing
A more intense word for hungry is
2024-07-31 16:00:13 root INFO     [order_1_approx] starting weight calculation for A more intense word for boring is tedious
A more intense word for hungry is starving
A more intense word for strong is powerful
A more intense word for well is flourishing
A more intense word for necessary is essential
A more intense word for unhappy is miserable
A more intense word for like is love
A more intense word for dislike is
2024-07-31 16:00:13 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-07-31 16:03:04 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0563,  0.2288,  0.0648,  ...,  0.0963,  0.1285,  0.1246],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.2969, -5.1445,  0.0107,  ..., -1.3086, -3.1699, -2.1055],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-1.4275e-02,  9.0027e-03, -5.2109e-03,  ..., -8.5983e-03,
          3.0327e-03,  3.3508e-02],
        [ 1.3321e-02, -1.2627e-02,  3.7445e-02,  ..., -3.6102e-02,
         -3.1433e-03,  2.4395e-03],
        [-1.9333e-02,  1.1307e-02, -1.0437e-02,  ...,  1.9257e-02,
         -1.6937e-02, -6.3972e-03],
        ...,
        [ 3.6804e-02,  1.2611e-02,  1.1124e-02,  ...,  3.6926e-03,
         -7.7438e-03, -2.6566e-02],
        [ 9.6436e-03, -7.8888e-03, -2.2507e-02,  ...,  1.3069e-02,
          3.0518e-05, -1.0818e-02],
        [ 5.8517e-03,  1.5869e-02, -1.3573e-02,  ...,  2.1172e-03,
          2.3651e-03,  3.1891e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.5859, -5.0547, -0.4189,  ..., -1.1426, -3.2012, -1.9805]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 16:03:05 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more intense word for boring is tedious
A more intense word for hungry is starving
A more intense word for strong is powerful
A more intense word for well is flourishing
A more intense word for necessary is essential
A more intense word for unhappy is miserable
A more intense word for like is love
A more intense word for dislike is
2024-07-31 16:03:05 root INFO     [order_1_approx] starting weight calculation for A more intense word for necessary is essential
A more intense word for dislike is hate
A more intense word for like is love
A more intense word for unhappy is miserable
A more intense word for well is flourishing
A more intense word for boring is tedious
A more intense word for hungry is starving
A more intense word for strong is
2024-07-31 16:03:05 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-07-31 16:05:54 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0634, -0.4365,  0.1421,  ..., -0.2063, -0.1479,  0.2112],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.5000, -3.6836,  0.7949,  ..., -0.6406, -7.4414, -3.4922],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0030, -0.0118, -0.0026,  ...,  0.0068, -0.0016,  0.0280],
        [ 0.0072,  0.0145,  0.0274,  ..., -0.0101,  0.0157, -0.0122],
        [ 0.0141, -0.0216,  0.0288,  ..., -0.0181, -0.0047,  0.0305],
        ...,
        [ 0.0081,  0.0067, -0.0124,  ...,  0.0219, -0.0019, -0.0081],
        [ 0.0168, -0.0276,  0.0157,  ..., -0.0336, -0.0123,  0.0220],
        [ 0.0107,  0.0140, -0.0110,  ...,  0.0380, -0.0081, -0.0102]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.0889, -3.7656,  0.6729,  ..., -0.4785, -8.1250, -2.9922]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 16:05:55 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more intense word for necessary is essential
A more intense word for dislike is hate
A more intense word for like is love
A more intense word for unhappy is miserable
A more intense word for well is flourishing
A more intense word for boring is tedious
A more intense word for hungry is starving
A more intense word for strong is
2024-07-31 16:05:55 root INFO     [order_1_approx] starting weight calculation for A more intense word for boring is tedious
A more intense word for well is flourishing
A more intense word for like is love
A more intense word for dislike is hate
A more intense word for strong is powerful
A more intense word for hungry is starving
A more intense word for necessary is essential
A more intense word for unhappy is
2024-07-31 16:05:55 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-07-31 16:08:46 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1276,  0.0042, -0.0969,  ..., -0.2362, -0.1802,  0.1246],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.8047, -3.5781,  2.1621,  ..., -2.2578, -0.7754, -1.4404],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0067,  0.0377, -0.0053,  ..., -0.0124, -0.0158,  0.0382],
        [-0.0245,  0.0052, -0.0022,  ..., -0.0275,  0.0061, -0.0376],
        [-0.0331,  0.0164,  0.0317,  ...,  0.0145, -0.0282,  0.0225],
        ...,
        [ 0.0148, -0.0198, -0.0135,  ..., -0.0050, -0.0223, -0.0439],
        [-0.0013,  0.0127, -0.0187,  ...,  0.0110, -0.0032, -0.0193],
        [ 0.0163, -0.0180, -0.0170,  ..., -0.0039, -0.0172, -0.0073]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.9238, -3.6816,  1.7754,  ..., -2.1641, -1.3125, -1.8555]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 16:08:47 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more intense word for boring is tedious
A more intense word for well is flourishing
A more intense word for like is love
A more intense word for dislike is hate
A more intense word for strong is powerful
A more intense word for hungry is starving
A more intense word for necessary is essential
A more intense word for unhappy is
2024-07-31 16:08:47 root INFO     [order_1_approx] starting weight calculation for A more intense word for strong is powerful
A more intense word for dislike is hate
A more intense word for necessary is essential
A more intense word for hungry is starving
A more intense word for well is flourishing
A more intense word for unhappy is miserable
A more intense word for boring is tedious
A more intense word for like is
2024-07-31 16:08:47 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-07-31 16:11:37 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1707, -0.1273,  0.0079,  ...,  0.0025, -0.1210,  0.0692],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.8320, -2.9062, -0.4248,  ...,  1.5469, -6.5781, -0.8223],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0223, -0.0097, -0.0152,  ...,  0.0256,  0.0168,  0.0238],
        [-0.0124,  0.0139,  0.0415,  ..., -0.0095, -0.0206,  0.0087],
        [ 0.0265, -0.0338, -0.0018,  ...,  0.0120, -0.0112,  0.0140],
        ...,
        [ 0.0003, -0.0028,  0.0445,  ...,  0.0014,  0.0011, -0.0190],
        [ 0.0032, -0.0144, -0.0341,  ...,  0.0123,  0.0209, -0.0117],
        [ 0.0088, -0.0119, -0.0263,  ...,  0.0111,  0.0112,  0.0263]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.8828, -2.4844, -0.3196,  ...,  1.1924, -6.4609, -0.8872]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 16:11:37 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more intense word for strong is powerful
A more intense word for dislike is hate
A more intense word for necessary is essential
A more intense word for hungry is starving
A more intense word for well is flourishing
A more intense word for unhappy is miserable
A more intense word for boring is tedious
A more intense word for like is
2024-07-31 16:11:38 root INFO     [order_1_approx] starting weight calculation for A more intense word for necessary is essential
A more intense word for well is flourishing
A more intense word for like is love
A more intense word for unhappy is miserable
A more intense word for hungry is starving
A more intense word for strong is powerful
A more intense word for dislike is hate
A more intense word for boring is
2024-07-31 16:11:38 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-07-31 16:14:27 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0330,  0.1262,  0.2024,  ..., -0.0060, -0.2322,  0.0332],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.8027, -1.8389,  4.7305,  ..., -2.9238, -4.3672, -1.5713],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0595, -0.0112, -0.0343,  ...,  0.0004, -0.0022,  0.0073],
        [ 0.0172,  0.0538,  0.0104,  ..., -0.0354,  0.0014, -0.0209],
        [-0.0102,  0.0213,  0.0131,  ...,  0.0345, -0.0117,  0.0058],
        ...,
        [ 0.0525,  0.0039,  0.0216,  ..., -0.0073, -0.0205, -0.0374],
        [-0.0031,  0.0058,  0.0449,  ...,  0.0227, -0.0375,  0.0030],
        [ 0.0621,  0.0098,  0.0023,  ...,  0.0113, -0.0159,  0.0063]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.6699, -2.0391,  4.2812,  ..., -2.9023, -4.1758, -2.0781]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 16:14:28 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more intense word for necessary is essential
A more intense word for well is flourishing
A more intense word for like is love
A more intense word for unhappy is miserable
A more intense word for hungry is starving
A more intense word for strong is powerful
A more intense word for dislike is hate
A more intense word for boring is
2024-07-31 16:14:29 root INFO     [order_1_approx] starting weight calculation for A more intense word for like is love
A more intense word for unhappy is miserable
A more intense word for hungry is starving
A more intense word for well is flourishing
A more intense word for boring is tedious
A more intense word for strong is powerful
A more intense word for dislike is hate
A more intense word for necessary is
2024-07-31 16:14:29 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-07-31 16:17:19 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0176,  0.1372, -0.1791,  ..., -0.0761, -0.3699,  0.1259],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.6367, -0.2732, -0.6113,  ...,  0.0918, -5.9062, -1.0996],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0051, -0.0121,  0.0100,  ...,  0.0014,  0.0115, -0.0113],
        [-0.0124,  0.0061, -0.0141,  ...,  0.0108,  0.0283,  0.0173],
        [ 0.0283, -0.0106,  0.0398,  ...,  0.0014, -0.0331,  0.0319],
        ...,
        [ 0.0159,  0.0326, -0.0008,  ...,  0.0209, -0.0067, -0.0012],
        [ 0.0062, -0.0418,  0.0221,  ..., -0.0206,  0.0460, -0.0249],
        [ 0.0027, -0.0031, -0.0229,  ..., -0.0159, -0.0388,  0.0254]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.3398,  0.2468, -0.7905,  ...,  0.1072, -6.0234, -1.4668]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 16:17:20 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more intense word for like is love
A more intense word for unhappy is miserable
A more intense word for hungry is starving
A more intense word for well is flourishing
A more intense word for boring is tedious
A more intense word for strong is powerful
A more intense word for dislike is hate
A more intense word for necessary is
2024-07-31 16:17:20 root INFO     total operator prediction time: 1370.599217414856 seconds
2024-07-31 16:17:20 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on hypernyms - animals
2024-07-31 16:17:20 root INFO     building operator hypernyms - animals
2024-07-31 16:17:20 root INFO     [order_1_approx] starting weight calculation for The vulture falls into the category of raptor
The cobra falls into the category of snake
The mouse falls into the category of rodent
The orangutan falls into the category of primate
The velociraptor falls into the category of dinosaur
The beaver falls into the category of rodent
The wolf falls into the category of canine
The rattlesnake falls into the category of
2024-07-31 16:17:20 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-07-31 16:20:10 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0093,  0.0839, -0.5439,  ...,  0.0406,  0.0585, -0.3562],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.4053, -4.1094,  0.7905,  ..., -2.4863, -1.0703, -0.5391],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0404, -0.0009, -0.0078,  ...,  0.0044, -0.0056,  0.0009],
        [ 0.0097, -0.0127,  0.0102,  ...,  0.0093, -0.0071, -0.0093],
        [-0.0003,  0.0153,  0.0248,  ..., -0.0328, -0.0095,  0.0070],
        ...,
        [ 0.0200,  0.0015, -0.0012,  ...,  0.0228, -0.0003,  0.0038],
        [-0.0041,  0.0048,  0.0193,  ...,  0.0100,  0.0123,  0.0123],
        [ 0.0071, -0.0016,  0.0046,  ..., -0.0136,  0.0167, -0.0011]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.1895, -4.0547,  0.4934,  ..., -2.3477, -1.0264, -0.1382]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 16:20:11 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The vulture falls into the category of raptor
The cobra falls into the category of snake
The mouse falls into the category of rodent
The orangutan falls into the category of primate
The velociraptor falls into the category of dinosaur
The beaver falls into the category of rodent
The wolf falls into the category of canine
The rattlesnake falls into the category of
2024-07-31 16:20:11 root INFO     [order_1_approx] starting weight calculation for The cobra falls into the category of snake
The orangutan falls into the category of primate
The wolf falls into the category of canine
The beaver falls into the category of rodent
The rattlesnake falls into the category of snake
The mouse falls into the category of rodent
The vulture falls into the category of raptor
The velociraptor falls into the category of
2024-07-31 16:20:11 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-07-31 16:23:00 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1569, -0.1692, -0.2583,  ..., -0.1792, -0.2177, -0.0210],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.8418, -5.1406,  2.7246,  ..., -0.9917, -8.4531,  0.2168],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0242, -0.0031, -0.0002,  ...,  0.0177, -0.0033,  0.0052],
        [ 0.0028, -0.0114,  0.0064,  ..., -0.0132,  0.0267, -0.0060],
        [ 0.0041,  0.0129, -0.0106,  ...,  0.0193, -0.0541,  0.0127],
        ...,
        [ 0.0148,  0.0144,  0.0049,  ...,  0.0200, -0.0386,  0.0171],
        [ 0.0068,  0.0014, -0.0021,  ...,  0.0140,  0.0119,  0.0086],
        [-0.0140, -0.0165,  0.0101,  ..., -0.0129,  0.0369,  0.0204]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.8760, -5.0820,  2.6445,  ..., -1.0293, -9.0938,  0.5791]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 16:23:01 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The cobra falls into the category of snake
The orangutan falls into the category of primate
The wolf falls into the category of canine
The beaver falls into the category of rodent
The rattlesnake falls into the category of snake
The mouse falls into the category of rodent
The vulture falls into the category of raptor
The velociraptor falls into the category of
2024-07-31 16:23:01 root INFO     [order_1_approx] starting weight calculation for The rattlesnake falls into the category of snake
The velociraptor falls into the category of dinosaur
The orangutan falls into the category of primate
The cobra falls into the category of snake
The beaver falls into the category of rodent
The wolf falls into the category of canine
The mouse falls into the category of rodent
The vulture falls into the category of
2024-07-31 16:23:02 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-07-31 16:25:51 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3901, -0.0953, -0.3997,  ..., -0.0853, -0.3396,  0.0536],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.8203, -2.0938,  3.9082,  ..., -1.6084, -5.6172,  2.0352],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0775,  0.0080, -0.0396,  ..., -0.0262,  0.0376, -0.0168],
        [-0.0345,  0.0374,  0.0142,  ...,  0.0079,  0.0092,  0.0285],
        [-0.0065, -0.0105,  0.0394,  ...,  0.0008,  0.0117, -0.0019],
        ...,
        [ 0.0193,  0.0349,  0.0337,  ...,  0.0564, -0.0474,  0.0095],
        [ 0.0255,  0.0079, -0.0229,  ...,  0.0891,  0.0403,  0.0492],
        [ 0.0391, -0.0188,  0.0046,  ..., -0.0281,  0.0054,  0.0579]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.8438, -2.4961,  3.6992,  ..., -1.3613, -6.1797,  2.4453]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 16:25:52 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The rattlesnake falls into the category of snake
The velociraptor falls into the category of dinosaur
The orangutan falls into the category of primate
The cobra falls into the category of snake
The beaver falls into the category of rodent
The wolf falls into the category of canine
The mouse falls into the category of rodent
The vulture falls into the category of
2024-07-31 16:25:52 root INFO     [order_1_approx] starting weight calculation for The mouse falls into the category of rodent
The rattlesnake falls into the category of snake
The velociraptor falls into the category of dinosaur
The wolf falls into the category of canine
The orangutan falls into the category of primate
The vulture falls into the category of raptor
The beaver falls into the category of rodent
The cobra falls into the category of
2024-07-31 16:25:53 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-07-31 16:28:42 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0148, -0.0190, -0.2285,  ..., -0.0084, -0.0959, -0.0699],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.2119, -3.3945,  1.4785,  ..., -1.9355, -3.1094,  0.6504],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0748, -0.0120,  0.0179,  ..., -0.0210,  0.0273,  0.0464],
        [-0.0105,  0.0164, -0.0327,  ..., -0.0084,  0.0140,  0.0096],
        [ 0.0045,  0.0069,  0.0836,  ..., -0.0452, -0.0161, -0.0042],
        ...,
        [-0.0067,  0.0292,  0.0024,  ...,  0.0775,  0.0177, -0.0103],
        [-0.0287,  0.0432, -0.0039,  ...,  0.0125,  0.0083, -0.0473],
        [ 0.0331, -0.0082,  0.0029,  ..., -0.0313,  0.0413,  0.0513]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.4121, -3.0156,  0.9990,  ..., -1.8398, -3.8340,  1.1357]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 16:28:43 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The mouse falls into the category of rodent
The rattlesnake falls into the category of snake
The velociraptor falls into the category of dinosaur
The wolf falls into the category of canine
The orangutan falls into the category of primate
The vulture falls into the category of raptor
The beaver falls into the category of rodent
The cobra falls into the category of
2024-07-31 16:28:43 root INFO     [order_1_approx] starting weight calculation for The cobra falls into the category of snake
The vulture falls into the category of raptor
The beaver falls into the category of rodent
The orangutan falls into the category of primate
The rattlesnake falls into the category of snake
The velociraptor falls into the category of dinosaur
The wolf falls into the category of canine
The mouse falls into the category of
2024-07-31 16:28:44 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-07-31 16:31:33 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2146,  0.0242, -0.1130,  ..., -0.0172, -0.0720, -0.1525],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.2036, -3.8047,  1.7441,  ..., -3.4766, -6.6953, -0.4082],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0178, -0.0400, -0.0138,  ..., -0.0181, -0.0357,  0.0231],
        [ 0.0216,  0.0477,  0.0198,  ..., -0.0153,  0.0120, -0.0283],
        [ 0.0247,  0.0165,  0.0257,  ..., -0.0059, -0.0232, -0.0115],
        ...,
        [-0.0083,  0.0294,  0.0046,  ...,  0.0305,  0.0219, -0.0207],
        [-0.0075,  0.0067, -0.0194,  ..., -0.0117,  0.0319, -0.0155],
        [-0.0054, -0.0114, -0.0065,  ..., -0.0179,  0.0129,  0.0481]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.2764, -3.7793,  1.5420,  ..., -3.4375, -6.7070, -0.5586]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 16:31:34 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The cobra falls into the category of snake
The vulture falls into the category of raptor
The beaver falls into the category of rodent
The orangutan falls into the category of primate
The rattlesnake falls into the category of snake
The velociraptor falls into the category of dinosaur
The wolf falls into the category of canine
The mouse falls into the category of
2024-07-31 16:31:34 root INFO     [order_1_approx] starting weight calculation for The cobra falls into the category of snake
The beaver falls into the category of rodent
The mouse falls into the category of rodent
The rattlesnake falls into the category of snake
The velociraptor falls into the category of dinosaur
The vulture falls into the category of raptor
The orangutan falls into the category of primate
The wolf falls into the category of
2024-07-31 16:31:34 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-07-31 16:34:23 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2422, -0.0255, -0.1545,  ...,  0.0332, -0.0310, -0.1520],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.1099, -6.1172, -0.0420,  ..., -3.1152, -6.3906,  0.6934],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0529, -0.0549,  0.0173,  ...,  0.0296, -0.0276, -0.0003],
        [ 0.0512, -0.0423,  0.0473,  ...,  0.0286, -0.0122, -0.0055],
        [-0.0291,  0.0520,  0.0096,  ..., -0.0469, -0.0030, -0.0049],
        ...,
        [ 0.0269, -0.0213,  0.0356,  ..., -0.0086, -0.0309,  0.0012],
        [-0.0093,  0.0551, -0.0159,  ..., -0.0135,  0.0533,  0.0123],
        [ 0.0210, -0.0333,  0.0091,  ...,  0.0349, -0.0048, -0.0037]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.6338, -6.5625,  0.1027,  ..., -3.1309, -6.5742,  0.4182]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 16:34:24 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The cobra falls into the category of snake
The beaver falls into the category of rodent
The mouse falls into the category of rodent
The rattlesnake falls into the category of snake
The velociraptor falls into the category of dinosaur
The vulture falls into the category of raptor
The orangutan falls into the category of primate
The wolf falls into the category of
2024-07-31 16:34:24 root INFO     [order_1_approx] starting weight calculation for The velociraptor falls into the category of dinosaur
The mouse falls into the category of rodent
The rattlesnake falls into the category of snake
The wolf falls into the category of canine
The vulture falls into the category of raptor
The cobra falls into the category of snake
The beaver falls into the category of rodent
The orangutan falls into the category of
2024-07-31 16:34:24 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-07-31 16:37:14 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2651, -0.1007, -0.2063,  ..., -0.0499, -0.3274,  0.1131],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.6001, -3.7539, -0.4639,  ..., -3.7773, -6.3984,  1.7979],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0073, -0.0153, -0.0005,  ...,  0.0087, -0.0009,  0.0149],
        [-0.0007,  0.0009,  0.0093,  ..., -0.0033,  0.0056, -0.0098],
        [-0.0020, -0.0066,  0.0016,  ..., -0.0038, -0.0049, -0.0005],
        ...,
        [-0.0044, -0.0043,  0.0034,  ..., -0.0054, -0.0097,  0.0066],
        [-0.0024,  0.0088, -0.0013,  ...,  0.0100,  0.0156, -0.0002],
        [-0.0057, -0.0157, -0.0001,  ..., -0.0042,  0.0022,  0.0067]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.5249, -3.5859, -0.4612,  ..., -3.9961, -6.5156,  2.1309]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 16:37:15 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The velociraptor falls into the category of dinosaur
The mouse falls into the category of rodent
The rattlesnake falls into the category of snake
The wolf falls into the category of canine
The vulture falls into the category of raptor
The cobra falls into the category of snake
The beaver falls into the category of rodent
The orangutan falls into the category of
2024-07-31 16:37:16 root INFO     [order_1_approx] starting weight calculation for The mouse falls into the category of rodent
The cobra falls into the category of snake
The velociraptor falls into the category of dinosaur
The rattlesnake falls into the category of snake
The vulture falls into the category of raptor
The orangutan falls into the category of primate
The wolf falls into the category of canine
The beaver falls into the category of
2024-07-31 16:37:16 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-07-31 16:40:06 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0925,  0.1465, -0.1418,  ..., -0.0843, -0.1202,  0.0709],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.1846, -4.5703,  1.9023,  ..., -0.8252, -7.1953, -1.9463],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0575, -0.0064,  0.0049,  ..., -0.0007, -0.0163,  0.0032],
        [ 0.0629, -0.0282,  0.0236,  ..., -0.0067,  0.0159, -0.0583],
        [-0.0681,  0.0253,  0.0297,  ..., -0.0063, -0.0384,  0.0779],
        ...,
        [ 0.0050,  0.0378,  0.0111,  ...,  0.0490, -0.0308,  0.0071],
        [ 0.0075,  0.0214, -0.0029,  ..., -0.0031,  0.0503, -0.0163],
        [ 0.0310, -0.0591,  0.0358,  ..., -0.0120,  0.0123, -0.0289]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.2773, -3.9297,  0.6943,  ..., -0.7188, -7.3984, -1.0488]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 16:40:06 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The mouse falls into the category of rodent
The cobra falls into the category of snake
The velociraptor falls into the category of dinosaur
The rattlesnake falls into the category of snake
The vulture falls into the category of raptor
The orangutan falls into the category of primate
The wolf falls into the category of canine
The beaver falls into the category of
2024-07-31 16:40:06 root INFO     total operator prediction time: 1366.853605747223 seconds
2024-07-31 16:40:06 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on hyponyms - misc
2024-07-31 16:40:06 root INFO     building operator hyponyms - misc
2024-07-31 16:40:07 root INFO     [order_1_approx] starting weight calculation for A more specific term for a cookware is pot
A more specific term for a drum is tambourine
A more specific term for a tool is rake
A more specific term for a cutlery is knife
A more specific term for a flask is thermos
A more specific term for a dress is gown
A more specific term for a mixer is blender
A more specific term for a burger is
2024-07-31 16:40:07 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-07-31 16:42:57 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0911,  0.4055, -0.1060,  ..., -0.0084, -0.1165, -0.0613],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.1719, -5.3477,  0.6440,  ..., -1.2598, -3.6680, -0.6055],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0334, -0.0059, -0.0008,  ...,  0.0058, -0.0194,  0.0170],
        [ 0.0206,  0.0245, -0.0116,  ..., -0.0233,  0.0096,  0.0035],
        [ 0.0093, -0.0297,  0.0578,  ..., -0.0130, -0.0112, -0.0299],
        ...,
        [ 0.0315,  0.0268,  0.0094,  ...,  0.0101, -0.0059, -0.0401],
        [ 0.0147, -0.0094, -0.0011,  ...,  0.0328,  0.0469, -0.0095],
        [ 0.0178,  0.0264, -0.0283,  ...,  0.0211, -0.0066,  0.0641]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.5391, -5.1875,  0.6489,  ..., -1.4561, -3.3828, -0.4478]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 16:42:58 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more specific term for a cookware is pot
A more specific term for a drum is tambourine
A more specific term for a tool is rake
A more specific term for a cutlery is knife
A more specific term for a flask is thermos
A more specific term for a dress is gown
A more specific term for a mixer is blender
A more specific term for a burger is
2024-07-31 16:42:58 root INFO     [order_1_approx] starting weight calculation for A more specific term for a tool is rake
A more specific term for a flask is thermos
A more specific term for a drum is tambourine
A more specific term for a cutlery is knife
A more specific term for a dress is gown
A more specific term for a mixer is blender
A more specific term for a burger is hamburger
A more specific term for a cookware is
2024-07-31 16:42:58 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-07-31 16:45:48 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0642, -0.1946, -0.1129,  ..., -0.1945, -0.0972, -0.1980],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.9336, -2.8418,  3.4727,  ..., -2.4570, -4.0625,  0.3516],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0011,  0.0006,  0.0012,  ..., -0.0118,  0.0070,  0.0228],
        [ 0.0184,  0.0207, -0.0103,  ..., -0.0024, -0.0022, -0.0039],
        [-0.0036, -0.0120,  0.0123,  ...,  0.0125, -0.0443, -0.0338],
        ...,
        [ 0.0086, -0.0054, -0.0053,  ...,  0.0304, -0.0045, -0.0042],
        [-0.0005, -0.0515,  0.0151,  ...,  0.0203,  0.0333, -0.0142],
        [ 0.0174, -0.0109, -0.0033,  ..., -0.0172, -0.0395,  0.0200]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.9961, -2.7168,  3.3203,  ..., -2.0898, -3.6328,  0.3113]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 16:45:49 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more specific term for a tool is rake
A more specific term for a flask is thermos
A more specific term for a drum is tambourine
A more specific term for a cutlery is knife
A more specific term for a dress is gown
A more specific term for a mixer is blender
A more specific term for a burger is hamburger
A more specific term for a cookware is
2024-07-31 16:45:49 root INFO     [order_1_approx] starting weight calculation for A more specific term for a flask is thermos
A more specific term for a tool is rake
A more specific term for a cookware is pot
A more specific term for a cutlery is knife
A more specific term for a burger is hamburger
A more specific term for a drum is tambourine
A more specific term for a dress is gown
A more specific term for a mixer is
2024-07-31 16:45:50 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-07-31 16:48:40 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1831, -0.1613, -0.1587,  ...,  0.3008, -0.3459, -0.1722],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.8691, -4.6211, -1.5342,  ...,  1.0645, -3.1289,  0.0664],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0224, -0.0178, -0.0118,  ...,  0.0305,  0.0012, -0.0234],
        [ 0.0162,  0.0249,  0.0045,  ..., -0.0081,  0.0015,  0.0043],
        [ 0.0023, -0.0129,  0.0412,  ...,  0.0055,  0.0007,  0.0220],
        ...,
        [ 0.0422,  0.0437,  0.0171,  ...,  0.0349, -0.0490,  0.0007],
        [-0.0361, -0.0224, -0.0327,  ...,  0.0058,  0.0728, -0.0185],
        [ 0.0090,  0.0531,  0.0307,  ..., -0.0215, -0.0298,  0.0384]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.8096, -4.6758, -1.6953,  ...,  1.9033, -2.8594,  0.4102]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 16:48:41 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more specific term for a flask is thermos
A more specific term for a tool is rake
A more specific term for a cookware is pot
A more specific term for a cutlery is knife
A more specific term for a burger is hamburger
A more specific term for a drum is tambourine
A more specific term for a dress is gown
A more specific term for a mixer is
2024-07-31 16:48:41 root INFO     [order_1_approx] starting weight calculation for A more specific term for a dress is gown
A more specific term for a cutlery is knife
A more specific term for a burger is hamburger
A more specific term for a tool is rake
A more specific term for a cookware is pot
A more specific term for a flask is thermos
A more specific term for a mixer is blender
A more specific term for a drum is
2024-07-31 16:48:41 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-07-31 16:51:31 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2402,  0.2542, -0.0549,  ..., -0.2086, -0.1614,  0.1212],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.3691, -5.0312,  1.8057,  ..., -0.8564, -0.2314, -0.4238],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0986,  0.0670, -0.0098,  ..., -0.0192,  0.0450,  0.0542],
        [-0.0077,  0.0454, -0.0652,  ...,  0.0304, -0.0007, -0.0119],
        [ 0.0469,  0.0333,  0.0717,  ..., -0.0003,  0.0297,  0.0383],
        ...,
        [-0.0199, -0.0082,  0.0069,  ...,  0.0437, -0.0230, -0.0296],
        [-0.0149, -0.0116,  0.0154,  ...,  0.0042,  0.0470, -0.0457],
        [-0.0243, -0.0316,  0.0226,  ..., -0.0543, -0.0122,  0.0299]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.6367, -4.5977,  1.4424,  ..., -0.5117, -0.1014, -0.2257]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 16:51:32 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more specific term for a dress is gown
A more specific term for a cutlery is knife
A more specific term for a burger is hamburger
A more specific term for a tool is rake
A more specific term for a cookware is pot
A more specific term for a flask is thermos
A more specific term for a mixer is blender
A more specific term for a drum is
2024-07-31 16:51:32 root INFO     [order_1_approx] starting weight calculation for A more specific term for a mixer is blender
A more specific term for a cutlery is knife
A more specific term for a flask is thermos
A more specific term for a cookware is pot
A more specific term for a tool is rake
A more specific term for a burger is hamburger
A more specific term for a drum is tambourine
A more specific term for a dress is
2024-07-31 16:51:32 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-07-31 16:54:20 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1154, -0.1364, -0.1917,  ...,  0.1694, -0.0780,  0.0107],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.0815, -5.8203, -0.6719,  ...,  0.7456, -4.0547,  1.5576],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0226,  0.0050,  0.0046,  ..., -0.0490,  0.0623,  0.0233],
        [ 0.0107,  0.0011,  0.0401,  ...,  0.0075, -0.0068, -0.0104],
        [ 0.0065, -0.0330,  0.0760,  ...,  0.0033, -0.0284, -0.0138],
        ...,
        [ 0.0064,  0.0103, -0.0296,  ...,  0.0132,  0.0535, -0.0046],
        [ 0.0171,  0.0079, -0.0085,  ...,  0.0436,  0.0532, -0.0199],
        [-0.0108,  0.0027,  0.0091,  ..., -0.0080, -0.0178,  0.0219]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.3376, -5.4609, -0.4600,  ...,  0.5972, -4.0078,  1.7275]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 16:54:21 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more specific term for a mixer is blender
A more specific term for a cutlery is knife
A more specific term for a flask is thermos
A more specific term for a cookware is pot
A more specific term for a tool is rake
A more specific term for a burger is hamburger
A more specific term for a drum is tambourine
A more specific term for a dress is
2024-07-31 16:54:22 root INFO     [order_1_approx] starting weight calculation for A more specific term for a drum is tambourine
A more specific term for a cutlery is knife
A more specific term for a tool is rake
A more specific term for a dress is gown
A more specific term for a cookware is pot
A more specific term for a burger is hamburger
A more specific term for a mixer is blender
A more specific term for a flask is
2024-07-31 16:54:22 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-07-31 16:57:11 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1418, -0.2554, -0.3105,  ..., -0.1798,  0.2137,  0.0051],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.5684, -3.4219,  0.0845,  ..., -0.1064,  1.5371, -0.6719],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.1066,  0.0296, -0.0214,  ...,  0.0546, -0.0442,  0.0642],
        [-0.0353,  0.0491,  0.0324,  ..., -0.0349,  0.0457, -0.0170],
        [ 0.0345,  0.0051,  0.1337,  ...,  0.0150, -0.0203,  0.0620],
        ...,
        [ 0.0081,  0.0486,  0.0103,  ...,  0.0680, -0.0088, -0.0036],
        [-0.0777,  0.0087, -0.0660,  ..., -0.0038,  0.0986, -0.0941],
        [-0.0005,  0.0467, -0.0019,  ...,  0.0342,  0.0255,  0.1089]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.3340, -2.6777,  0.1028,  ..., -0.7041,  1.3965, -0.9062]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 16:57:12 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more specific term for a drum is tambourine
A more specific term for a cutlery is knife
A more specific term for a tool is rake
A more specific term for a dress is gown
A more specific term for a cookware is pot
A more specific term for a burger is hamburger
A more specific term for a mixer is blender
A more specific term for a flask is
2024-07-31 16:57:13 root INFO     [order_1_approx] starting weight calculation for A more specific term for a drum is tambourine
A more specific term for a tool is rake
A more specific term for a flask is thermos
A more specific term for a cookware is pot
A more specific term for a burger is hamburger
A more specific term for a dress is gown
A more specific term for a mixer is blender
A more specific term for a cutlery is
2024-07-31 16:57:13 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-07-31 17:00:02 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0957, -0.0842, -0.4185,  ..., -0.2152, -0.0780, -0.1616],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.3452, -3.9727, -3.0430,  ..., -1.5752, -2.3184, -0.0620],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0305, -0.0145, -0.0062,  ...,  0.0154, -0.0071,  0.0028],
        [-0.0124,  0.0119,  0.0281,  ..., -0.0423,  0.0493, -0.0238],
        [-0.0122,  0.0009,  0.0341,  ...,  0.0214, -0.0160,  0.0020],
        ...,
        [ 0.0289, -0.0459, -0.0306,  ...,  0.0076, -0.0006,  0.0129],
        [ 0.0130, -0.0124, -0.0505,  ..., -0.0097,  0.0553, -0.0345],
        [-0.0308,  0.0102, -0.0407,  ..., -0.0011,  0.0222,  0.0266]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.5508, -3.2695, -3.3301,  ..., -1.4141, -2.0586,  0.2971]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 17:00:03 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more specific term for a drum is tambourine
A more specific term for a tool is rake
A more specific term for a flask is thermos
A more specific term for a cookware is pot
A more specific term for a burger is hamburger
A more specific term for a dress is gown
A more specific term for a mixer is blender
A more specific term for a cutlery is
2024-07-31 17:00:03 root INFO     [order_1_approx] starting weight calculation for A more specific term for a flask is thermos
A more specific term for a cookware is pot
A more specific term for a mixer is blender
A more specific term for a dress is gown
A more specific term for a drum is tambourine
A more specific term for a burger is hamburger
A more specific term for a cutlery is knife
A more specific term for a tool is
2024-07-31 17:00:03 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-07-31 17:02:52 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0887, -0.2976, -0.0322,  ..., -0.0217,  0.0269, -0.0636],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.3755, -3.3730,  0.0420,  ...,  1.4844, -4.9414,  0.7314],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0423, -0.0007, -0.0052,  ...,  0.0278, -0.0161,  0.0188],
        [ 0.0051,  0.0077,  0.0229,  ...,  0.0146, -0.0013, -0.0355],
        [-0.0056,  0.0309,  0.0012,  ..., -0.0034, -0.0078,  0.0004],
        ...,
        [ 0.0141, -0.0051,  0.0157,  ..., -0.0041,  0.0137, -0.0112],
        [-0.0035, -0.0201, -0.0074,  ..., -0.0016,  0.0238,  0.0046],
        [ 0.0117, -0.0039,  0.0011,  ..., -0.0282,  0.0128,  0.0171]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.4194, -3.2734, -0.1725,  ...,  1.2461, -4.9062,  0.8594]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 17:02:53 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more specific term for a flask is thermos
A more specific term for a cookware is pot
A more specific term for a mixer is blender
A more specific term for a dress is gown
A more specific term for a drum is tambourine
A more specific term for a burger is hamburger
A more specific term for a cutlery is knife
A more specific term for a tool is
2024-07-31 17:02:53 root INFO     total operator prediction time: 1366.8902924060822 seconds
2024-07-31 17:02:53 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on antonyms - binary
2024-07-31 17:02:53 root INFO     building operator antonyms - binary
2024-07-31 17:02:54 root INFO     [order_1_approx] starting weight calculation for The opposite of outward is upward
The opposite of down is up
The opposite of front is back
The opposite of climb is descend
The opposite of dynamic is static
The opposite of decrement is increment
The opposite of in is out
The opposite of inhale is
2024-07-31 17:02:54 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-07-31 17:05:44 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0057,  0.1503, -0.1053,  ..., -0.2108, -0.2490, -0.2036],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.0234, -1.8350,  2.2266,  ..., -1.9414, -0.5566,  0.8359],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0287, -0.0144, -0.0137,  ..., -0.0008,  0.0540,  0.0446],
        [ 0.0134,  0.0148, -0.0140,  ..., -0.0137,  0.0216, -0.0019],
        [ 0.0136, -0.0235, -0.0279,  ..., -0.0143, -0.0199, -0.0279],
        ...,
        [-0.0086,  0.0189,  0.0115,  ..., -0.0325, -0.0001,  0.0078],
        [ 0.0201, -0.0014,  0.0098,  ..., -0.0352, -0.0125, -0.0002],
        [ 0.0362, -0.0276,  0.0071,  ..., -0.0087,  0.0030, -0.0066]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.1920, -1.5859,  1.8623,  ..., -1.4707, -1.0938,  1.0215]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 17:05:45 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of outward is upward
The opposite of down is up
The opposite of front is back
The opposite of climb is descend
The opposite of dynamic is static
The opposite of decrement is increment
The opposite of in is out
The opposite of inhale is
2024-07-31 17:05:45 root INFO     [order_1_approx] starting weight calculation for The opposite of decrement is increment
The opposite of front is back
The opposite of dynamic is static
The opposite of climb is descend
The opposite of inhale is exhale
The opposite of in is out
The opposite of down is up
The opposite of outward is
2024-07-31 17:05:45 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-07-31 17:08:22 root INFO     loading model + tokenizer
2024-07-31 17:08:36 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0681,  0.0442, -0.0701,  ..., -0.0284, -0.2360, -0.0735],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.8223, -1.0273,  1.0039,  ..., -1.6641,  1.2617, -4.3789],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0158, -0.0235,  0.0106,  ..., -0.0173,  0.0415, -0.0167],
        [-0.0369,  0.0387, -0.0089,  ..., -0.0079, -0.0105,  0.0612],
        [ 0.0438, -0.0120,  0.0753,  ...,  0.0226, -0.0398, -0.0144],
        ...,
        [-0.0100,  0.0461, -0.0753,  ...,  0.0615,  0.0303, -0.0296],
        [ 0.0299,  0.0004, -0.0026,  ...,  0.0677,  0.0505, -0.0469],
        [-0.0213, -0.0090, -0.0080,  ...,  0.0359,  0.0171,  0.0653]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.2520, -1.0088,  1.0039,  ..., -1.4766,  0.9692, -4.0195]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 17:08:37 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of decrement is increment
The opposite of front is back
The opposite of dynamic is static
The opposite of climb is descend
The opposite of inhale is exhale
The opposite of in is out
The opposite of down is up
The opposite of outward is
2024-07-31 17:08:37 root INFO     [order_1_approx] starting weight calculation for The opposite of front is back
The opposite of in is out
The opposite of outward is upward
The opposite of dynamic is static
The opposite of decrement is increment
The opposite of climb is descend
The opposite of inhale is exhale
The opposite of down is
2024-07-31 17:08:37 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-07-31 17:11:26 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0436, -0.1278, -0.2769,  ..., -0.1896, -0.3184, -0.1768],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.5469, -5.1406,  0.6133,  ...,  0.0649, -0.2666, -3.0488],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0120, -0.0388, -0.0068,  ...,  0.0256,  0.0175,  0.0510],
        [-0.0099, -0.0116,  0.0045,  ...,  0.0180, -0.0020,  0.0114],
        [-0.0110, -0.0264, -0.0062,  ...,  0.0168, -0.0088,  0.0427],
        ...,
        [ 0.0560, -0.0110, -0.0508,  ..., -0.0131,  0.0028, -0.0027],
        [ 0.0753,  0.0429,  0.0102,  ...,  0.0012,  0.0358, -0.0139],
        [-0.0311, -0.0367,  0.0022,  ...,  0.0295,  0.0117,  0.0627]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.6782, -4.5547,  0.9497,  ...,  0.1045, -0.5713, -2.3125]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 17:11:27 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of front is back
The opposite of in is out
The opposite of outward is upward
The opposite of dynamic is static
The opposite of decrement is increment
The opposite of climb is descend
The opposite of inhale is exhale
The opposite of down is
2024-07-31 17:11:27 root INFO     [order_1_approx] starting weight calculation for The opposite of decrement is increment
The opposite of climb is descend
The opposite of outward is upward
The opposite of in is out
The opposite of down is up
The opposite of dynamic is static
The opposite of inhale is exhale
The opposite of front is
2024-07-31 17:11:27 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-07-31 17:14:15 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0449, -0.0280, -0.1533,  ..., -0.1227, -0.1643,  0.1864],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.2627, -2.5742,  1.6162,  ..., -1.1006, -1.1416, -1.8516],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0403, -0.0563,  0.0262,  ...,  0.0686, -0.0016, -0.0047],
        [ 0.0183,  0.0165,  0.0353,  ...,  0.0103,  0.0522,  0.0123],
        [ 0.0271, -0.0210,  0.0116,  ...,  0.0354, -0.0291, -0.0184],
        ...,
        [ 0.0110,  0.0124, -0.0237,  ...,  0.0193,  0.0467,  0.0296],
        [ 0.0005,  0.0069,  0.0205,  ..., -0.0319,  0.0361,  0.0216],
        [-0.0089,  0.0050, -0.0079,  ...,  0.0468,  0.0206,  0.0535]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.1914, -2.0820,  1.3516,  ..., -1.0215, -0.8535, -1.6914]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 17:14:16 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of decrement is increment
The opposite of climb is descend
The opposite of outward is upward
The opposite of in is out
The opposite of down is up
The opposite of dynamic is static
The opposite of inhale is exhale
The opposite of front is
2024-07-31 17:14:16 root INFO     [order_1_approx] starting weight calculation for The opposite of dynamic is static
The opposite of outward is upward
The opposite of climb is descend
The opposite of decrement is increment
The opposite of down is up
The opposite of front is back
The opposite of inhale is exhale
The opposite of in is
2024-07-31 17:14:16 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-07-31 17:17:01 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0270, -0.1935, -0.1279,  ...,  0.0399, -0.0811,  0.1154],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.5762, -4.7109,  2.5098,  ..., -3.7734, -0.0161, -3.9219],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0247, -0.0026, -0.0423,  ...,  0.0352,  0.0070,  0.0528],
        [ 0.0050,  0.0417, -0.0059,  ...,  0.0178,  0.0043,  0.0710],
        [ 0.0107, -0.0311, -0.0084,  ..., -0.0065,  0.0006, -0.0352],
        ...,
        [-0.0274,  0.0274, -0.0267,  ..., -0.0069,  0.0033, -0.0048],
        [-0.0040, -0.0335,  0.0362,  ..., -0.0189,  0.0475, -0.0601],
        [ 0.0280,  0.0152, -0.0349,  ...,  0.0403, -0.0104,  0.0365]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.2227, -5.0781,  2.5039,  ..., -4.2852,  0.0733, -3.7715]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 17:17:02 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of dynamic is static
The opposite of outward is upward
The opposite of climb is descend
The opposite of decrement is increment
The opposite of down is up
The opposite of front is back
The opposite of inhale is exhale
The opposite of in is
2024-07-31 17:17:02 root INFO     [order_1_approx] starting weight calculation for The opposite of decrement is increment
The opposite of front is back
The opposite of in is out
The opposite of dynamic is static
The opposite of down is up
The opposite of inhale is exhale
The opposite of outward is upward
The opposite of climb is
2024-07-31 17:17:03 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-07-31 17:19:52 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0272,  0.0415, -0.0290,  ..., -0.2783, -0.4585,  0.2603],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.3125, -1.5703,  2.8320,  ..., -0.7085, -4.4609, -0.9497],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0390, -0.0044,  0.0053,  ..., -0.0049,  0.0289,  0.0300],
        [ 0.0037,  0.0339,  0.0063,  ...,  0.0311, -0.0238, -0.0010],
        [ 0.0018, -0.0158, -0.0304,  ..., -0.0263,  0.0216, -0.0231],
        ...,
        [ 0.0074,  0.0135,  0.0072,  ...,  0.0169, -0.0030, -0.0227],
        [-0.0197,  0.0278,  0.0082,  ...,  0.0079, -0.0129,  0.0441],
        [ 0.0276,  0.0081, -0.0013,  ...,  0.0221, -0.0231,  0.0196]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.6602, -1.3311,  2.9258,  ..., -0.5767, -5.1602, -1.1777]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 17:19:53 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of decrement is increment
The opposite of front is back
The opposite of in is out
The opposite of dynamic is static
The opposite of down is up
The opposite of inhale is exhale
The opposite of outward is upward
The opposite of climb is
2024-07-31 17:19:53 root INFO     [order_1_approx] starting weight calculation for The opposite of front is back
The opposite of in is out
The opposite of outward is upward
The opposite of down is up
The opposite of inhale is exhale
The opposite of dynamic is static
The opposite of climb is descend
The opposite of decrement is
2024-07-31 17:19:53 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-07-31 17:22:41 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2319,  0.2295, -0.2544,  ...,  0.0394, -0.2815, -0.0057],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.3765, -0.8716, -0.8623,  ...,  0.7251, -2.6562, -0.9219],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0115, -0.0011,  0.0192,  ...,  0.0241,  0.0111, -0.0099],
        [-0.0135,  0.0286,  0.0330,  ...,  0.0345,  0.0210,  0.0081],
        [ 0.0269, -0.0368, -0.0142,  ...,  0.0008, -0.0408,  0.0022],
        ...,
        [ 0.0139,  0.0106,  0.0141,  ..., -0.0082, -0.0228, -0.0154],
        [ 0.0091, -0.0308, -0.0143,  ..., -0.0265, -0.0030,  0.0296],
        [ 0.0346, -0.0019, -0.0004,  ..., -0.0277, -0.0417,  0.0132]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.5723, -0.4138, -1.3594,  ...,  0.0337, -3.0957, -0.5850]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 17:22:42 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of front is back
The opposite of in is out
The opposite of outward is upward
The opposite of down is up
The opposite of inhale is exhale
The opposite of dynamic is static
The opposite of climb is descend
The opposite of decrement is
2024-07-31 17:22:42 root INFO     [order_1_approx] starting weight calculation for The opposite of inhale is exhale
The opposite of front is back
The opposite of outward is upward
The opposite of in is out
The opposite of climb is descend
The opposite of decrement is increment
The opposite of down is up
The opposite of dynamic is
2024-07-31 17:22:42 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-07-31 17:25:31 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1544,  0.2213, -0.0084,  ..., -0.0233, -0.1097,  0.0678],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.4800,  0.8457,  1.7588,  ...,  0.1006, -4.2422, -2.6250],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0655,  0.0444,  0.0436,  ...,  0.0158,  0.0185,  0.0199],
        [-0.0532, -0.0053,  0.0009,  ...,  0.0245,  0.0174,  0.0097],
        [ 0.0102,  0.0224,  0.0087,  ...,  0.0086, -0.0421, -0.0124],
        ...,
        [ 0.0083,  0.0160, -0.0151,  ...,  0.0113, -0.0108, -0.0212],
        [-0.0286, -0.0434, -0.0465,  ..., -0.0011,  0.0151, -0.0048],
        [ 0.0060,  0.0358, -0.0130,  ...,  0.0228,  0.0894,  0.1242]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.3667,  0.8296,  1.2666,  ..., -0.4370, -5.1836, -1.8770]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 17:25:32 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of inhale is exhale
The opposite of front is back
The opposite of outward is upward
The opposite of in is out
The opposite of climb is descend
The opposite of decrement is increment
The opposite of down is up
The opposite of dynamic is
2024-07-31 17:25:32 root INFO     total operator prediction time: 1358.8386070728302 seconds
2024-07-31 17:25:32 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on meronyms - member
2024-07-31 17:25:32 root INFO     building operator meronyms - member
2024-07-31 17:25:32 root INFO     [order_1_approx] starting weight calculation for A calf is a member of a cattle
A antelope is a member of a herd
A letter is a member of a alphabet
A page is a member of a book
A shrub is a member of a shrubbery
A parishioner is a member of a parish
A song is a member of a album
A nomad is a member of a
2024-07-31 17:25:33 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-07-31 17:28:24 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1448, -0.0378, -0.1353,  ..., -0.0768, -0.1035,  0.0588],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.4531, -3.0859,  1.5840,  ..., -2.1699, -1.9238, -0.7344],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0612, -0.0083,  0.0050,  ...,  0.0132,  0.0051, -0.0016],
        [ 0.0072,  0.0233,  0.0184,  ...,  0.0041, -0.0518, -0.0022],
        [-0.0121, -0.0085,  0.0318,  ...,  0.0062,  0.0114,  0.0173],
        ...,
        [ 0.0121, -0.0010, -0.0129,  ...,  0.0349, -0.0186,  0.0036],
        [ 0.0025, -0.0019, -0.0109,  ..., -0.0128,  0.0285,  0.0044],
        [ 0.0268,  0.0068,  0.0071,  ...,  0.0126, -0.0070,  0.0463]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.2559, -2.8066,  1.6260,  ..., -2.0957, -1.8955, -0.4673]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 17:28:25 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A calf is a member of a cattle
A antelope is a member of a herd
A letter is a member of a alphabet
A page is a member of a book
A shrub is a member of a shrubbery
A parishioner is a member of a parish
A song is a member of a album
A nomad is a member of a
2024-07-31 17:28:25 root INFO     [order_1_approx] starting weight calculation for A letter is a member of a alphabet
A song is a member of a album
A calf is a member of a cattle
A shrub is a member of a shrubbery
A antelope is a member of a herd
A page is a member of a book
A nomad is a member of a horde
A parishioner is a member of a
2024-07-31 17:28:25 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-07-31 17:31:15 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1737,  0.0374, -0.2942,  ...,  0.1010, -0.0819, -0.0568],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.3359, -6.6406,  4.7852,  ..., -1.9727, -0.1201,  0.5596],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0003, -0.0063, -0.0096,  ..., -0.0053,  0.0055, -0.0181],
        [ 0.0071, -0.0023,  0.0178,  ...,  0.0291, -0.0072,  0.0302],
        [ 0.0022, -0.0027,  0.0023,  ..., -0.0075, -0.0087, -0.0176],
        ...,
        [ 0.0073,  0.0034,  0.0160,  ...,  0.0202, -0.0134,  0.0147],
        [-0.0062, -0.0037, -0.0275,  ..., -0.0161,  0.0072, -0.0149],
        [ 0.0124, -0.0131,  0.0214,  ...,  0.0186, -0.0239,  0.0372]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.0566, -5.3867,  4.5312,  ..., -1.6797, -0.5889,  1.0977]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 17:31:15 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A letter is a member of a alphabet
A song is a member of a album
A calf is a member of a cattle
A shrub is a member of a shrubbery
A antelope is a member of a herd
A page is a member of a book
A nomad is a member of a horde
A parishioner is a member of a
2024-07-31 17:31:16 root INFO     [order_1_approx] starting weight calculation for A page is a member of a book
A nomad is a member of a horde
A song is a member of a album
A parishioner is a member of a parish
A antelope is a member of a herd
A shrub is a member of a shrubbery
A letter is a member of a alphabet
A calf is a member of a
2024-07-31 17:31:16 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-07-31 17:34:02 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2786,  0.0284,  0.1041,  ..., -0.3523, -0.2098, -0.0214],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 5.0625, -1.9756,  1.3701,  ..., -1.5166,  0.7588, -1.7021],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0062,  0.0376,  0.0012,  ...,  0.0331, -0.0340, -0.0207],
        [-0.0069,  0.0557, -0.0110,  ...,  0.0201, -0.0059,  0.0114],
        [-0.0113, -0.0304,  0.0286,  ..., -0.0169, -0.0248, -0.0056],
        ...,
        [ 0.0264,  0.0080, -0.0016,  ...,  0.0278,  0.0021, -0.0064],
        [ 0.0009,  0.0590, -0.0352,  ...,  0.0421,  0.0828,  0.0037],
        [ 0.0132, -0.0609,  0.0224,  ..., -0.0331, -0.0199,  0.0249]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.8047, -2.1621,  1.7666,  ..., -1.3809, -0.0391, -1.2812]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 17:34:03 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A page is a member of a book
A nomad is a member of a horde
A song is a member of a album
A parishioner is a member of a parish
A antelope is a member of a herd
A shrub is a member of a shrubbery
A letter is a member of a alphabet
A calf is a member of a
2024-07-31 17:34:04 root INFO     [order_1_approx] starting weight calculation for A calf is a member of a cattle
A letter is a member of a alphabet
A antelope is a member of a herd
A nomad is a member of a horde
A song is a member of a album
A parishioner is a member of a parish
A shrub is a member of a shrubbery
A page is a member of a
2024-07-31 17:34:04 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-07-31 17:36:53 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1680,  0.3291, -0.3184,  ..., -0.2379, -0.3906,  0.1198],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.2344, -1.6143,  0.5703,  ..., -0.5273, -1.6982, -0.8262],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0125,  0.0151,  0.0238,  ...,  0.0084, -0.0086,  0.0185],
        [-0.0481,  0.0928,  0.0158,  ..., -0.0171, -0.0282, -0.0247],
        [ 0.0515, -0.0797,  0.0740,  ...,  0.0404, -0.0269, -0.0226],
        ...,
        [ 0.0165,  0.0525,  0.0215,  ...,  0.0742,  0.0076, -0.0352],
        [ 0.0398,  0.0483, -0.0059,  ..., -0.0143,  0.0650,  0.0049],
        [-0.0378, -0.0079,  0.0002,  ..., -0.0085, -0.0126,  0.0540]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.2676, -1.8789,  1.0215,  ..., -0.5864, -1.7842, -0.6816]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 17:36:53 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A calf is a member of a cattle
A letter is a member of a alphabet
A antelope is a member of a herd
A nomad is a member of a horde
A song is a member of a album
A parishioner is a member of a parish
A shrub is a member of a shrubbery
A page is a member of a
2024-07-31 17:36:54 root INFO     [order_1_approx] starting weight calculation for A letter is a member of a alphabet
A parishioner is a member of a parish
A antelope is a member of a herd
A shrub is a member of a shrubbery
A nomad is a member of a horde
A calf is a member of a cattle
A page is a member of a book
A song is a member of a
2024-07-31 17:36:54 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-07-31 17:39:37 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1149,  0.2061, -0.1124,  ...,  0.0061, -0.2273, -0.0583],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.0806, -5.5195,  3.3398,  ..., -0.1123, -1.3906, -1.0420],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0379, -0.0535, -0.0081,  ...,  0.0328, -0.0154,  0.0165],
        [ 0.0043,  0.0217,  0.0130,  ..., -0.0125, -0.0076, -0.0284],
        [ 0.0125,  0.0014,  0.0631,  ..., -0.0177,  0.0068,  0.0109],
        ...,
        [ 0.0161, -0.0004,  0.0068,  ...,  0.0569,  0.0197, -0.0037],
        [-0.0115,  0.0370, -0.0345,  ..., -0.0130,  0.0165,  0.0037],
        [ 0.0178, -0.0437,  0.0011,  ..., -0.0166,  0.0017,  0.0278]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-2.6855e-03, -5.2227e+00,  3.3789e+00,  ..., -2.3425e-01,
         -1.4023e+00, -1.0771e+00]], device='cuda:1', dtype=torch.float16,
       grad_fn=<SubBackward0>) 

                    
2024-07-31 17:39:38 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A letter is a member of a alphabet
A parishioner is a member of a parish
A antelope is a member of a herd
A shrub is a member of a shrubbery
A nomad is a member of a horde
A calf is a member of a cattle
A page is a member of a book
A song is a member of a
2024-07-31 17:39:38 root INFO     [order_1_approx] starting weight calculation for A antelope is a member of a herd
A parishioner is a member of a parish
A letter is a member of a alphabet
A calf is a member of a cattle
A song is a member of a album
A nomad is a member of a horde
A page is a member of a book
A shrub is a member of a
2024-07-31 17:39:38 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-07-31 17:42:28 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2703,  0.0609, -0.0251,  ...,  0.0502, -0.1083, -0.2744],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.1934, -4.3281,  0.6172,  ..., -3.4004, -1.7930, -2.3965],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0233, -0.0132, -0.0247,  ...,  0.0377, -0.0244,  0.0027],
        [ 0.0063,  0.0461,  0.0067,  ...,  0.0209, -0.0201, -0.0057],
        [-0.0213,  0.0179,  0.0477,  ...,  0.0131, -0.0109,  0.0059],
        ...,
        [ 0.0170,  0.0128, -0.0064,  ...,  0.0487, -0.0060, -0.0087],
        [ 0.0013,  0.0061,  0.0007,  ...,  0.0161,  0.0244,  0.0040],
        [-0.0053, -0.0071,  0.0202,  ..., -0.0051, -0.0321,  0.0509]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.9580, -3.7656,  0.2483,  ..., -3.1680, -2.2520, -2.1230]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 17:42:29 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A antelope is a member of a herd
A parishioner is a member of a parish
A letter is a member of a alphabet
A calf is a member of a cattle
A song is a member of a album
A nomad is a member of a horde
A page is a member of a book
A shrub is a member of a
2024-07-31 17:42:29 root INFO     [order_1_approx] starting weight calculation for A calf is a member of a cattle
A nomad is a member of a horde
A page is a member of a book
A antelope is a member of a herd
A shrub is a member of a shrubbery
A song is a member of a album
A parishioner is a member of a parish
A letter is a member of a
2024-07-31 17:42:30 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-07-31 17:45:16 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1230,  0.1350, -0.3577,  ..., -0.1895, -0.0956, -0.0157],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.7280, -3.4844, -0.8740,  ...,  0.9092, -3.1289, -1.2598],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0319,  0.0345,  0.0118,  ...,  0.0244, -0.0218,  0.0009],
        [ 0.0051,  0.0485, -0.0052,  ..., -0.0257,  0.0028, -0.0018],
        [ 0.0657, -0.1456,  0.0182,  ...,  0.0328,  0.0168,  0.0396],
        ...,
        [-0.0061,  0.1079,  0.0417,  ...,  0.0161, -0.0103, -0.0624],
        [ 0.0385, -0.0066, -0.0269,  ..., -0.0025,  0.0145,  0.0297],
        [ 0.0098, -0.0551,  0.0320,  ..., -0.0233,  0.0126,  0.0244]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.7993, -3.5488, -0.5742,  ...,  0.2700, -3.0879, -1.4180]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 17:45:17 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A calf is a member of a cattle
A nomad is a member of a horde
A page is a member of a book
A antelope is a member of a herd
A shrub is a member of a shrubbery
A song is a member of a album
A parishioner is a member of a parish
A letter is a member of a
2024-07-31 17:45:17 root INFO     [order_1_approx] starting weight calculation for A song is a member of a album
A page is a member of a book
A letter is a member of a alphabet
A parishioner is a member of a parish
A shrub is a member of a shrubbery
A nomad is a member of a horde
A calf is a member of a cattle
A antelope is a member of a
2024-07-31 17:45:17 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-07-31 17:48:06 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1963,  0.0197, -0.3477,  ...,  0.1032, -0.2073, -0.0760],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.9941, -3.2773,  1.1846,  ..., -0.6670, -7.3438, -0.1729],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 1.8478e-02,  1.5259e-02, -6.2752e-03,  ...,  3.1921e-02,
         -2.4147e-03, -1.1436e-02],
        [-9.8190e-03,  3.0746e-02,  2.2049e-02,  ..., -6.6528e-03,
         -4.9866e-02, -3.9062e-03],
        [ 1.1200e-02,  1.1414e-02,  1.0910e-02,  ..., -1.3527e-02,
          2.3560e-02,  9.6588e-03],
        ...,
        [-1.1444e-05,  1.1856e-02,  8.8272e-03,  ..., -1.0162e-02,
         -9.0408e-03, -2.0065e-03],
        [ 2.9572e-02, -4.3213e-02, -4.6631e-02,  ..., -1.9684e-02,
          8.8257e-02,  2.8973e-03],
        [ 1.9913e-03,  9.4452e-03,  8.7357e-03,  ...,  4.4670e-03,
         -3.2043e-04, -2.0554e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.3320, -3.2754,  1.1416,  ..., -0.2593, -7.6406, -0.0668]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 17:48:07 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A song is a member of a album
A page is a member of a book
A letter is a member of a alphabet
A parishioner is a member of a parish
A shrub is a member of a shrubbery
A nomad is a member of a horde
A calf is a member of a cattle
A antelope is a member of a
2024-07-31 17:48:07 root INFO     total operator prediction time: 1354.7331411838531 seconds
2024-07-31 17:48:07 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on noun - plural_irreg
2024-07-31 17:48:07 root INFO     building operator noun - plural_irreg
2024-07-31 17:48:07 root INFO     [order_1_approx] starting weight calculation for The plural form of category is categories
The plural form of energy is energies
The plural form of university is universities
The plural form of agency is agencies
The plural form of datum is data
The plural form of series is series
The plural form of ability is abilities
The plural form of secretary is
2024-07-31 17:48:07 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-07-31 17:50:49 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0188, -0.1309, -0.3125,  ..., -0.1570, -0.3394,  0.1215],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.2754, -1.7246,  2.8086,  ..., -1.4424, -0.8940, -3.7109],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0858, -0.0379, -0.0557,  ..., -0.0486,  0.0475, -0.0871],
        [-0.0123,  0.0275,  0.0053,  ..., -0.0051,  0.0019,  0.0129],
        [ 0.0330,  0.0231,  0.0214,  ...,  0.0232, -0.0319,  0.0239],
        ...,
        [-0.0059,  0.0585,  0.0329,  ...,  0.0007, -0.0221,  0.0187],
        [ 0.0073,  0.0224,  0.0014,  ...,  0.0381, -0.0087, -0.0051],
        [ 0.0241, -0.0030, -0.0184,  ...,  0.0397, -0.0055,  0.0284]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.2285, -2.1602,  2.4844,  ..., -1.5566, -0.9702, -3.6387]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 17:50:50 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of category is categories
The plural form of energy is energies
The plural form of university is universities
The plural form of agency is agencies
The plural form of datum is data
The plural form of series is series
The plural form of ability is abilities
The plural form of secretary is
2024-07-31 17:50:50 root INFO     [order_1_approx] starting weight calculation for The plural form of agency is agencies
The plural form of energy is energies
The plural form of series is series
The plural form of datum is data
The plural form of ability is abilities
The plural form of university is universities
The plural form of secretary is secretaries
The plural form of category is
2024-07-31 17:50:50 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-07-31 17:53:38 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1744, -0.0172, -0.0779,  ..., -0.0469, -0.3918,  0.0649],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.8477, -2.5078,  1.8438,  ..., -1.1367,  0.1670, -2.2383],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0211, -0.0123, -0.0246,  ...,  0.0070,  0.0108, -0.0215],
        [-0.0043,  0.0382,  0.0216,  ..., -0.0087, -0.0048,  0.0161],
        [-0.0147, -0.0102, -0.0012,  ..., -0.0006,  0.0005,  0.0092],
        ...,
        [-0.0258, -0.0091,  0.0191,  ...,  0.0137, -0.0069, -0.0034],
        [-0.0081, -0.0040, -0.0090,  ..., -0.0245,  0.0029,  0.0277],
        [ 0.0244,  0.0057, -0.0171,  ...,  0.0075, -0.0131,  0.0332]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.6372, -2.9082,  1.8574,  ..., -1.7510,  0.1982, -2.4512]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 17:53:39 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of agency is agencies
The plural form of energy is energies
The plural form of series is series
The plural form of datum is data
The plural form of ability is abilities
The plural form of university is universities
The plural form of secretary is secretaries
The plural form of category is
2024-07-31 17:53:39 root INFO     [order_1_approx] starting weight calculation for The plural form of energy is energies
The plural form of series is series
The plural form of ability is abilities
The plural form of secretary is secretaries
The plural form of agency is agencies
The plural form of university is universities
The plural form of category is categories
The plural form of datum is
2024-07-31 17:53:39 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-07-31 17:56:29 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0605,  0.1033, -0.2681,  ..., -0.1210, -0.3350, -0.0756],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.5918, -2.0566,  2.2656,  ..., -1.0713, -4.3164, -2.1016],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0512,  0.0122,  0.0332,  ..., -0.0007,  0.0222, -0.0099],
        [ 0.0011,  0.0528,  0.0076,  ..., -0.0058, -0.0368,  0.0290],
        [-0.0075,  0.0244, -0.0135,  ..., -0.0087,  0.0200, -0.0177],
        ...,
        [ 0.0174, -0.0122, -0.0055,  ...,  0.0267, -0.0199,  0.0211],
        [-0.0014,  0.0062, -0.0206,  ..., -0.0260,  0.0500, -0.0093],
        [-0.0089,  0.0064, -0.0228,  ...,  0.0060, -0.0450,  0.0285]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.3281, -2.2656,  2.1387,  ..., -1.0986, -4.1797, -1.7979]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 17:56:30 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of energy is energies
The plural form of series is series
The plural form of ability is abilities
The plural form of secretary is secretaries
The plural form of agency is agencies
The plural form of university is universities
The plural form of category is categories
The plural form of datum is
2024-07-31 17:56:30 root INFO     [order_1_approx] starting weight calculation for The plural form of series is series
The plural form of ability is abilities
The plural form of datum is data
The plural form of category is categories
The plural form of secretary is secretaries
The plural form of energy is energies
The plural form of university is universities
The plural form of agency is
2024-07-31 17:56:30 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-07-31 17:59:20 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0475,  0.2229, -0.0690,  ..., -0.2175, -0.0820, -0.2664],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.1696, -0.1426,  2.5527,  ..., -1.4170,  0.0734, -3.5195],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0168, -0.0121, -0.0041,  ..., -0.0013,  0.0066, -0.0520],
        [-0.0045,  0.0336, -0.0107,  ...,  0.0075,  0.0170,  0.0069],
        [-0.0012,  0.0264,  0.0038,  ...,  0.0478,  0.0185,  0.0072],
        ...,
        [ 0.0338,  0.0678, -0.0122,  ...,  0.0309,  0.0078,  0.0236],
        [-0.0305,  0.0088,  0.0186,  ...,  0.0180,  0.0269, -0.0071],
        [ 0.0458,  0.0010, -0.0248,  ..., -0.0156, -0.0074,  0.0305]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.0931, -0.0546,  1.8672,  ..., -1.9521, -0.2910, -3.5820]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 17:59:21 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of series is series
The plural form of ability is abilities
The plural form of datum is data
The plural form of category is categories
The plural form of secretary is secretaries
The plural form of energy is energies
The plural form of university is universities
The plural form of agency is
2024-07-31 17:59:22 root INFO     [order_1_approx] starting weight calculation for The plural form of agency is agencies
The plural form of series is series
The plural form of datum is data
The plural form of energy is energies
The plural form of category is categories
The plural form of ability is abilities
The plural form of secretary is secretaries
The plural form of university is
2024-07-31 17:59:22 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-07-31 18:02:09 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2676, -0.0396, -0.1489,  ...,  0.0384, -0.2810,  0.1289],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 6.0425e-02, -2.4355e+00,  1.6104e+00,  ..., -7.6807e-01,
        -1.3428e-03, -1.2529e+00], device='cuda:1', dtype=torch.float16,
       grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0185, -0.0145, -0.0224,  ...,  0.0177, -0.0111, -0.0546],
        [-0.0113,  0.0304,  0.0122,  ..., -0.0274,  0.0101,  0.0016],
        [ 0.0132, -0.0164,  0.0329,  ...,  0.0129, -0.0479,  0.0291],
        ...,
        [-0.0392,  0.0207,  0.0082,  ...,  0.0011, -0.0102,  0.0282],
        [ 0.0035, -0.0138,  0.0249,  ..., -0.0070,  0.0039,  0.0425],
        [-0.0082,  0.0025, -0.0092,  ...,  0.0246, -0.0187, -0.0144]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.6582, -1.9814,  2.1289,  ..., -1.8320, -0.4487, -0.8516]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 18:02:10 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of agency is agencies
The plural form of series is series
The plural form of datum is data
The plural form of energy is energies
The plural form of category is categories
The plural form of ability is abilities
The plural form of secretary is secretaries
The plural form of university is
2024-07-31 18:02:10 root INFO     [order_1_approx] starting weight calculation for The plural form of secretary is secretaries
The plural form of category is categories
The plural form of university is universities
The plural form of agency is agencies
The plural form of series is series
The plural form of datum is data
The plural form of ability is abilities
The plural form of energy is
2024-07-31 18:02:10 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-07-31 18:04:56 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1304, -0.0759, -0.0819,  ..., -0.0227, -0.0931, -0.0113],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.6411,  0.6064,  1.6465,  ..., -2.7715, -2.8418, -3.0215],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 3.6926e-02, -8.8806e-03, -1.5991e-02,  ...,  2.1301e-02,
          5.2452e-04, -3.1082e-02],
        [-2.8168e-02,  2.3438e-02,  1.1826e-04,  ..., -1.1612e-02,
         -1.3664e-02,  3.1403e-02],
        [-1.3123e-03, -1.7166e-04,  5.7869e-03,  ..., -1.0490e-03,
         -2.4384e-02,  3.2593e-02],
        ...,
        [ 1.6815e-02,  1.1772e-02, -1.5808e-02,  ...,  2.6703e-05,
          7.1983e-03, -3.3539e-02],
        [ 9.8419e-03,  6.0844e-03,  5.2643e-03,  ...,  2.9106e-03,
         -1.2779e-03, -5.8670e-03],
        [ 1.5808e-02, -1.1192e-02,  1.5160e-02,  ...,  4.0466e-02,
          1.0437e-02,  3.2501e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.8066,  0.1323,  1.5547,  ..., -2.3359, -3.4297, -2.8691]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 18:04:57 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of secretary is secretaries
The plural form of category is categories
The plural form of university is universities
The plural form of agency is agencies
The plural form of series is series
The plural form of datum is data
The plural form of ability is abilities
The plural form of energy is
2024-07-31 18:04:57 root INFO     [order_1_approx] starting weight calculation for The plural form of category is categories
The plural form of university is universities
The plural form of agency is agencies
The plural form of secretary is secretaries
The plural form of datum is data
The plural form of energy is energies
The plural form of series is series
The plural form of ability is
2024-07-31 18:04:57 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-07-31 18:07:46 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0034, -0.0618,  0.0150,  ..., -0.1858, -0.3289,  0.1312],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.1602, -1.5391,  0.8965,  ..., -0.4160, -3.0273, -1.7598],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0062, -0.0142,  0.0077,  ..., -0.0034,  0.0195,  0.0154],
        [ 0.0289,  0.0260,  0.0025,  ...,  0.0298,  0.0022, -0.0047],
        [ 0.0065,  0.0060,  0.0127,  ..., -0.0221,  0.0060,  0.0443],
        ...,
        [ 0.0005,  0.0125,  0.0023,  ...,  0.0017, -0.0277,  0.0003],
        [ 0.0301, -0.0047, -0.0183,  ...,  0.0217, -0.0227, -0.0281],
        [ 0.0284,  0.0042, -0.0025,  ...,  0.0396,  0.0190,  0.0002]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.8125, -1.7285,  0.5732,  ..., -0.4919, -3.7637, -2.3145]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 18:07:47 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of category is categories
The plural form of university is universities
The plural form of agency is agencies
The plural form of secretary is secretaries
The plural form of datum is data
The plural form of energy is energies
The plural form of series is series
The plural form of ability is
2024-07-31 18:07:47 root INFO     [order_1_approx] starting weight calculation for The plural form of category is categories
The plural form of agency is agencies
The plural form of ability is abilities
The plural form of university is universities
The plural form of datum is data
The plural form of energy is energies
The plural form of secretary is secretaries
The plural form of series is
2024-07-31 18:07:47 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-07-31 18:10:37 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1716, -0.0835, -0.0607,  ..., -0.0557, -0.1931,  0.0850],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.3660, -1.5566, -0.0288,  ..., -2.0820, -0.4282, -2.9141],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0627, -0.0117, -0.0288,  ..., -0.0111,  0.0141, -0.0122],
        [ 0.0152,  0.0179,  0.0041,  ...,  0.0023, -0.0022,  0.0268],
        [-0.0188,  0.0317,  0.0096,  ...,  0.0007,  0.0129,  0.0416],
        ...,
        [-0.0041,  0.0169,  0.0247,  ...,  0.0094,  0.0038,  0.0050],
        [ 0.0142,  0.0008, -0.0227,  ...,  0.0218,  0.0007,  0.0338],
        [ 0.0525,  0.0121, -0.0164,  ...,  0.0278,  0.0357,  0.0553]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.1760, -1.8682,  0.2053,  ..., -2.0234, -0.0452, -2.7793]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 18:10:38 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of category is categories
The plural form of agency is agencies
The plural form of ability is abilities
The plural form of university is universities
The plural form of datum is data
The plural form of energy is energies
The plural form of secretary is secretaries
The plural form of series is
2024-07-31 18:10:38 root INFO     total operator prediction time: 1351.3943936824799 seconds
2024-07-31 18:10:38 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on Ving - verb_inf
2024-07-31 18:10:38 root INFO     building operator Ving - verb_inf
2024-07-31 18:10:39 root INFO     [order_1_approx] starting weight calculation for creating is the active form of create
achieving is the active form of achieve
performing is the active form of perform
managing is the active form of manage
believing is the active form of believe
losing is the active form of lose
attending is the active form of attend
reducing is the active form of
2024-07-31 18:10:39 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-07-31 18:13:27 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0046, -0.0561, -0.0488,  ..., -0.0241, -0.1504, -0.1674],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.9209, -3.0762, -1.1211,  ..., -0.8340, -1.5879, -4.8711],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 2.1988e-02, -1.3718e-02,  1.2550e-03,  ..., -1.4896e-03,
          1.2024e-02,  2.7828e-03],
        [ 1.1053e-03,  6.1035e-03,  4.1275e-03,  ...,  1.5045e-02,
         -1.1543e-02, -4.9591e-05],
        [ 1.6556e-03,  1.5976e-02,  6.5536e-03,  ..., -8.7051e-03,
         -3.0994e-03, -1.8921e-02],
        ...,
        [ 1.4786e-02,  3.0624e-02, -1.5152e-02,  ...,  1.2131e-02,
         -1.3023e-02,  7.5035e-03],
        [-7.7286e-03, -8.6403e-04, -3.3531e-03,  ...,  1.3748e-02,
          3.0304e-02, -4.7722e-03],
        [-4.0321e-03,  2.1286e-02, -5.0583e-03,  ..., -1.6510e-02,
          1.9791e-02,  2.0996e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.6860, -3.4805, -1.1914,  ..., -0.9116, -1.6934, -4.7266]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 18:13:28 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for creating is the active form of create
achieving is the active form of achieve
performing is the active form of perform
managing is the active form of manage
believing is the active form of believe
losing is the active form of lose
attending is the active form of attend
reducing is the active form of
2024-07-31 18:13:29 root INFO     [order_1_approx] starting weight calculation for achieving is the active form of achieve
managing is the active form of manage
reducing is the active form of reduce
performing is the active form of perform
believing is the active form of believe
creating is the active form of create
attending is the active form of attend
losing is the active form of
2024-07-31 18:13:29 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-07-31 18:16:18 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0133,  0.1570,  0.0285,  ..., -0.0807, -0.0136,  0.0952],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.1514, -2.8242, -0.8994,  ...,  0.8604,  0.6387, -2.1309],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 2.3636e-02, -3.3386e-02, -8.7738e-04,  ...,  2.6978e-02,
         -5.7983e-03,  1.8158e-03],
        [-7.3547e-03,  2.4231e-02,  1.1917e-02,  ..., -2.7390e-03,
          4.3182e-03, -2.9945e-03],
        [ 1.4343e-02, -1.9592e-02, -4.8485e-03,  ..., -1.8492e-03,
         -2.6207e-03, -1.2505e-02],
        ...,
        [ 1.2999e-03,  1.4061e-02, -2.7985e-02,  ...,  1.8677e-02,
         -9.0485e-03, -4.5776e-05],
        [-2.1347e-02,  1.8372e-02,  1.4191e-02,  ..., -4.5090e-03,
          6.8436e-03, -6.0272e-04],
        [-2.7199e-03,  2.8503e-02,  1.1978e-02,  ..., -3.0899e-04,
          2.7771e-03,  1.6975e-03]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.3926, -2.9805, -0.7432,  ...,  0.9829,  0.1423, -2.1211]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 18:16:19 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for achieving is the active form of achieve
managing is the active form of manage
reducing is the active form of reduce
performing is the active form of perform
believing is the active form of believe
creating is the active form of create
attending is the active form of attend
losing is the active form of
2024-07-31 18:16:19 root INFO     [order_1_approx] starting weight calculation for believing is the active form of believe
performing is the active form of perform
achieving is the active form of achieve
reducing is the active form of reduce
managing is the active form of manage
losing is the active form of lose
creating is the active form of create
attending is the active form of
2024-07-31 18:16:19 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-07-31 18:19:10 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1708,  0.2612, -0.2783,  ..., -0.0636, -0.2622, -0.0733],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.6680, -2.8438, -2.0195,  ...,  2.0215, -3.5293, -4.0820],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0416,  0.0018, -0.0123,  ..., -0.0077, -0.0017, -0.0224],
        [-0.0055,  0.0328, -0.0013,  ..., -0.0044, -0.0142,  0.0059],
        [ 0.0163, -0.0183,  0.0057,  ...,  0.0114,  0.0188,  0.0062],
        ...,
        [ 0.0057,  0.0069, -0.0065,  ...,  0.0180, -0.0106,  0.0043],
        [ 0.0037, -0.0214,  0.0114,  ...,  0.0188,  0.0175, -0.0049],
        [ 0.0041, -0.0034, -0.0244,  ..., -0.0101,  0.0044,  0.0203]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.9629, -3.1602, -2.1484,  ...,  1.8438, -3.7227, -4.3008]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 18:19:11 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for believing is the active form of believe
performing is the active form of perform
achieving is the active form of achieve
reducing is the active form of reduce
managing is the active form of manage
losing is the active form of lose
creating is the active form of create
attending is the active form of
2024-07-31 18:19:11 root INFO     [order_1_approx] starting weight calculation for performing is the active form of perform
attending is the active form of attend
reducing is the active form of reduce
creating is the active form of create
losing is the active form of lose
managing is the active form of manage
achieving is the active form of achieve
believing is the active form of
2024-07-31 18:19:11 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-07-31 18:22:01 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1168,  0.1659,  0.0936,  ..., -0.1382, -0.2300,  0.1631],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.5508, -5.1289,  0.8140,  ...,  1.4863, -1.6973, -3.0625],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 1.9333e-02, -1.3397e-02,  3.8624e-03,  ..., -1.9028e-02,
         -1.2474e-02, -1.1158e-03],
        [ 1.4557e-02,  2.4170e-02, -6.0272e-04,  ...,  1.4252e-02,
          2.0050e-02,  8.8654e-03],
        [-1.7899e-02,  2.5482e-03,  2.2308e-02,  ...,  6.5994e-04,
         -3.9764e-02, -1.1063e-02],
        ...,
        [ 1.9714e-02,  2.2446e-02, -8.0566e-03,  ...,  3.8452e-02,
          1.0986e-02,  8.2321e-03],
        [-1.6876e-02,  5.8174e-05, -1.2283e-02,  ...,  1.6144e-02,
         -3.1281e-03, -8.7738e-03],
        [ 4.7989e-03, -8.4229e-03, -1.6815e-02,  ..., -1.3733e-02,
          1.9745e-02, -8.2092e-03]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.8242, -5.0000,  0.3984,  ...,  1.2998, -1.6660, -3.2793]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 18:22:01 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for performing is the active form of perform
attending is the active form of attend
reducing is the active form of reduce
creating is the active form of create
losing is the active form of lose
managing is the active form of manage
achieving is the active form of achieve
believing is the active form of
2024-07-31 18:22:02 root INFO     [order_1_approx] starting weight calculation for losing is the active form of lose
attending is the active form of attend
achieving is the active form of achieve
believing is the active form of believe
reducing is the active form of reduce
managing is the active form of manage
performing is the active form of perform
creating is the active form of
2024-07-31 18:22:02 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-07-31 18:24:51 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1661,  0.1536,  0.1267,  ...,  0.0477, -0.1971,  0.0388],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.6113, -3.5508,  0.9805,  ...,  2.8379, -3.0039, -1.1807],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0414, -0.0032, -0.0352,  ...,  0.0048,  0.0341,  0.0264],
        [ 0.0266,  0.0491, -0.0231,  ...,  0.0225,  0.0609,  0.0214],
        [-0.0077, -0.0137,  0.0186,  ...,  0.0087, -0.0081, -0.0243],
        ...,
        [ 0.0130, -0.0074,  0.0082,  ...,  0.0019, -0.0290,  0.0004],
        [-0.0164,  0.0222, -0.0263,  ..., -0.0054,  0.0271, -0.0023],
        [ 0.0023,  0.0087, -0.0323,  ...,  0.0043,  0.0276,  0.0359]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.1270, -3.2969,  0.9292,  ...,  2.3379, -2.8672, -1.2188]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 18:24:52 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for losing is the active form of lose
attending is the active form of attend
achieving is the active form of achieve
believing is the active form of believe
reducing is the active form of reduce
managing is the active form of manage
performing is the active form of perform
creating is the active form of
2024-07-31 18:24:52 root INFO     [order_1_approx] starting weight calculation for reducing is the active form of reduce
attending is the active form of attend
believing is the active form of believe
creating is the active form of create
performing is the active form of perform
achieving is the active form of achieve
losing is the active form of lose
managing is the active form of
2024-07-31 18:24:52 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-07-31 18:27:42 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1196,  0.3870, -0.0476,  ..., -0.1068, -0.3049, -0.1107],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.4102, -3.7266,  0.5957,  ...,  1.7617, -1.6699, -3.1289],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0422,  0.0137, -0.0061,  ..., -0.0076, -0.0099, -0.0005],
        [ 0.0028,  0.0189, -0.0073,  ..., -0.0102,  0.0033,  0.0188],
        [-0.0152,  0.0043,  0.0148,  ..., -0.0150, -0.0145, -0.0283],
        ...,
        [ 0.0081,  0.0109,  0.0029,  ...,  0.0317, -0.0249, -0.0024],
        [-0.0031,  0.0076, -0.0069,  ...,  0.0190,  0.0276,  0.0048],
        [-0.0014, -0.0017, -0.0117,  ...,  0.0145,  0.0327,  0.0344]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.5947, -3.6055,  0.6797,  ...,  1.6162, -1.9219, -3.2539]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 18:27:43 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for reducing is the active form of reduce
attending is the active form of attend
believing is the active form of believe
creating is the active form of create
performing is the active form of perform
achieving is the active form of achieve
losing is the active form of lose
managing is the active form of
2024-07-31 18:27:43 root INFO     [order_1_approx] starting weight calculation for achieving is the active form of achieve
managing is the active form of manage
reducing is the active form of reduce
losing is the active form of lose
creating is the active form of create
attending is the active form of attend
believing is the active form of believe
performing is the active form of
2024-07-31 18:27:43 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-07-31 18:30:33 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1322,  0.0909, -0.0961,  ..., -0.1709, -0.2754,  0.0387],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.0273, -3.7734,  2.4297,  ...,  0.6689, -1.3184, -3.8438],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0280, -0.0189, -0.0031,  ...,  0.0065,  0.0062,  0.0235],
        [ 0.0067,  0.0309, -0.0133,  ..., -0.0051, -0.0058, -0.0013],
        [ 0.0149,  0.0107, -0.0068,  ...,  0.0026, -0.0016, -0.0226],
        ...,
        [ 0.0071,  0.0243, -0.0027,  ...,  0.0255, -0.0028, -0.0228],
        [-0.0127, -0.0022,  0.0057,  ..., -0.0004,  0.0094,  0.0122],
        [-0.0015, -0.0034, -0.0009,  ..., -0.0038, -0.0026,  0.0070]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.2812, -3.8691,  2.4707,  ...,  0.5298, -1.4346, -4.0156]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 18:30:34 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for achieving is the active form of achieve
managing is the active form of manage
reducing is the active form of reduce
losing is the active form of lose
creating is the active form of create
attending is the active form of attend
believing is the active form of believe
performing is the active form of
2024-07-31 18:30:34 root INFO     [order_1_approx] starting weight calculation for reducing is the active form of reduce
performing is the active form of perform
managing is the active form of manage
attending is the active form of attend
creating is the active form of create
losing is the active form of lose
believing is the active form of believe
achieving is the active form of
2024-07-31 18:30:34 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-07-31 18:33:25 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1125,  0.2411,  0.0019,  ..., -0.1737, -0.2405,  0.0170],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.2266, -2.3438, -0.7910,  ...,  0.8320, -2.3652, -2.6758],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 1.0468e-02, -1.3931e-02, -2.0657e-03,  ..., -3.6240e-03,
          2.3956e-03, -6.0844e-03],
        [-5.1117e-03,  1.8631e-02, -1.6346e-03,  ..., -1.7643e-03,
         -1.2444e-02,  2.2144e-03],
        [ 7.5874e-03,  6.8626e-03,  1.5602e-03,  ...,  1.3626e-02,
         -7.8964e-03,  1.3542e-03],
        ...,
        [ 1.7563e-02,  4.8637e-04,  1.2398e-05,  ...,  2.8839e-02,
         -1.2802e-02,  8.2855e-03],
        [-1.9989e-02, -6.7940e-03,  2.1801e-03,  ...,  1.2344e-02,
          2.6428e-02, -2.0203e-02],
        [ 2.1267e-04,  4.5013e-03, -1.3611e-02,  ...,  3.8605e-03,
         -2.8610e-05,  2.7962e-03]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.2471, -2.5332, -0.7358,  ...,  0.6689, -2.1484, -2.8242]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 18:33:26 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for reducing is the active form of reduce
performing is the active form of perform
managing is the active form of manage
attending is the active form of attend
creating is the active form of create
losing is the active form of lose
believing is the active form of believe
achieving is the active form of
2024-07-31 18:33:26 root INFO     total operator prediction time: 1367.2134184837341 seconds
2024-07-31 18:33:26 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on verb_Ving - Ved
2024-07-31 18:33:26 root INFO     building operator verb_Ving - Ved
2024-07-31 18:33:26 root INFO     [order_1_approx] starting weight calculation for After something is managing, it has managed
After something is teaching, it has taught
After something is asking, it has asked
After something is announcing, it has announced
After something is allowing, it has allowed
After something is telling, it has told
After something is adding, it has added
After something is spending, it has
2024-07-31 18:33:26 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-07-31 18:36:17 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1503,  0.1567,  0.0684,  ..., -0.0685, -0.1121,  0.0314],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.0781, -0.9775, -3.2227,  ..., -3.0781, -2.6641,  0.2246],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0252,  0.0005,  0.0254,  ..., -0.0527,  0.0206, -0.0399],
        [-0.0360,  0.0445,  0.0083,  ...,  0.0136,  0.0138,  0.0285],
        [-0.0052,  0.0042, -0.0105,  ..., -0.0249, -0.0022, -0.0365],
        ...,
        [ 0.0213, -0.0139,  0.0051,  ...,  0.0048,  0.0168,  0.0157],
        [ 0.0167, -0.0050, -0.0164,  ..., -0.0168,  0.0209,  0.0099],
        [-0.0217,  0.0012,  0.0008,  ...,  0.0052,  0.0094,  0.0288]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.4453, -1.1816, -2.7793,  ..., -3.0137, -2.8926,  0.2057]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 18:36:18 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for After something is managing, it has managed
After something is teaching, it has taught
After something is asking, it has asked
After something is announcing, it has announced
After something is allowing, it has allowed
After something is telling, it has told
After something is adding, it has added
After something is spending, it has
2024-07-31 18:36:18 root INFO     [order_1_approx] starting weight calculation for After something is asking, it has asked
After something is announcing, it has announced
After something is allowing, it has allowed
After something is telling, it has told
After something is spending, it has spent
After something is teaching, it has taught
After something is adding, it has added
After something is managing, it has
2024-07-31 18:36:18 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-07-31 18:39:11 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0453,  0.4766,  0.0343,  ..., -0.1133, -0.2891, -0.0592],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.4629, -1.5615,  1.6357,  ..., -2.1836, -1.8340, -1.7686],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0171, -0.0073,  0.0254,  ..., -0.0458,  0.0338, -0.0558],
        [-0.0125,  0.0380, -0.0133,  ...,  0.0054, -0.0007,  0.0235],
        [-0.0326, -0.0240,  0.0440,  ..., -0.0209, -0.0226, -0.0873],
        ...,
        [-0.0136, -0.0138,  0.0417,  ..., -0.0058,  0.0257, -0.0521],
        [ 0.0091,  0.0184, -0.0059,  ...,  0.0081, -0.0138,  0.0054],
        [ 0.0151,  0.0240, -0.0216,  ...,  0.0326, -0.0360,  0.0295]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.6641, -2.0449,  3.0625,  ..., -1.1260, -1.8701, -2.6133]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 18:39:12 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for After something is asking, it has asked
After something is announcing, it has announced
After something is allowing, it has allowed
After something is telling, it has told
After something is spending, it has spent
After something is teaching, it has taught
After something is adding, it has added
After something is managing, it has
2024-07-31 18:39:12 root INFO     [order_1_approx] starting weight calculation for After something is teaching, it has taught
After something is managing, it has managed
After something is spending, it has spent
After something is allowing, it has allowed
After something is telling, it has told
After something is adding, it has added
After something is asking, it has asked
After something is announcing, it has
2024-07-31 18:39:12 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-07-31 18:42:03 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0580,  0.3521,  0.0632,  ..., -0.0659, -0.1691, -0.1306],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.2930, -1.5986,  2.4355,  ..., -0.1455, -2.5586,  0.8105],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0265,  0.0110, -0.0288,  ...,  0.0201, -0.0102,  0.0129],
        [-0.0191,  0.0078,  0.0085,  ..., -0.0164, -0.0002, -0.0003],
        [ 0.0158, -0.0001, -0.0188,  ...,  0.0021, -0.0071, -0.0082],
        ...,
        [ 0.0117,  0.0129, -0.0185,  ...,  0.0019,  0.0182,  0.0193],
        [ 0.0036, -0.0019, -0.0136,  ..., -0.0182,  0.0039,  0.0128],
        [-0.0158, -0.0158,  0.0326,  ..., -0.0227, -0.0027, -0.0034]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.3418, -1.4336,  2.4941,  ..., -0.3340, -2.6504,  0.8027]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 18:42:04 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for After something is teaching, it has taught
After something is managing, it has managed
After something is spending, it has spent
After something is allowing, it has allowed
After something is telling, it has told
After something is adding, it has added
After something is asking, it has asked
After something is announcing, it has
2024-07-31 18:42:04 root INFO     [order_1_approx] starting weight calculation for After something is adding, it has added
After something is managing, it has managed
After something is asking, it has asked
After something is telling, it has told
After something is announcing, it has announced
After something is spending, it has spent
After something is teaching, it has taught
After something is allowing, it has
2024-07-31 18:42:04 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-07-31 18:44:56 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0354,  0.1613,  0.3486,  ..., -0.2944, -0.2749, -0.0551],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.7949, -2.5703, -0.0566,  ..., -1.9014, -1.5820,  1.4102],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0263,  0.0153, -0.0410,  ...,  0.0141, -0.0003, -0.0461],
        [-0.0241,  0.0471, -0.0200,  ...,  0.0127,  0.0156, -0.0182],
        [-0.0288, -0.0114,  0.0198,  ..., -0.0112, -0.0203, -0.0135],
        ...,
        [-0.0075, -0.0237, -0.0185,  ..., -0.0154,  0.0048,  0.0244],
        [ 0.0348,  0.0360,  0.0085,  ..., -0.0339,  0.0511, -0.0036],
        [-0.0086,  0.0397,  0.0067,  ...,  0.0096, -0.0052, -0.0079]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.1875, -2.8477,  0.2068,  ..., -1.5850, -1.3125,  1.1094]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 18:44:57 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for After something is adding, it has added
After something is managing, it has managed
After something is asking, it has asked
After something is telling, it has told
After something is announcing, it has announced
After something is spending, it has spent
After something is teaching, it has taught
After something is allowing, it has
2024-07-31 18:44:57 root INFO     [order_1_approx] starting weight calculation for After something is teaching, it has taught
After something is spending, it has spent
After something is adding, it has added
After something is allowing, it has allowed
After something is telling, it has told
After something is managing, it has managed
After something is announcing, it has announced
After something is asking, it has
2024-07-31 18:44:57 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-07-31 18:47:49 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0179,  0.2354, -0.0856,  ...,  0.0348, -0.1873, -0.2612],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.7178, -1.3770, -0.3955,  ..., -0.1978, -2.9844,  0.1074],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0234,  0.0020,  0.0244,  ...,  0.0002,  0.0072, -0.0085],
        [-0.0396,  0.0519, -0.0034,  ...,  0.0146, -0.0145,  0.0074],
        [ 0.0026, -0.0031,  0.0212,  ..., -0.0124,  0.0271, -0.0399],
        ...,
        [ 0.0147, -0.0069,  0.0037,  ...,  0.0222,  0.0082,  0.0169],
        [ 0.0186,  0.0095,  0.0003,  ..., -0.0389,  0.0277,  0.0038],
        [-0.0210, -0.0052,  0.0220,  ...,  0.0214, -0.0049,  0.0053]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.2812, -1.5908,  0.0293,  ..., -0.2886, -2.7305, -0.1425]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 18:47:50 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for After something is teaching, it has taught
After something is spending, it has spent
After something is adding, it has added
After something is allowing, it has allowed
After something is telling, it has told
After something is managing, it has managed
After something is announcing, it has announced
After something is asking, it has
2024-07-31 18:47:50 root INFO     [order_1_approx] starting weight calculation for After something is managing, it has managed
After something is spending, it has spent
After something is teaching, it has taught
After something is allowing, it has allowed
After something is asking, it has asked
After something is announcing, it has announced
After something is telling, it has told
After something is adding, it has
2024-07-31 18:47:51 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-07-31 18:50:42 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0466, -0.0803,  0.2937,  ...,  0.1027, -0.3635,  0.0057],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.7715,  0.9756, -0.7607,  ..., -0.6772, -3.3555, -0.8340],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 3.2745e-02, -1.5610e-02, -3.9749e-03,  ...,  8.2016e-05,
          1.9638e-02, -7.8506e-03],
        [-4.5044e-02,  6.1737e-02,  3.1281e-02,  ...,  1.3939e-02,
          1.1070e-02, -3.1189e-02],
        [-3.3398e-03, -5.3062e-03, -5.6572e-03,  ...,  5.5046e-03,
         -2.5238e-02,  2.2980e-02],
        ...,
        [-7.6523e-03,  1.5249e-03, -7.9536e-04,  ...,  2.6398e-02,
          2.4414e-04,  4.0100e-02],
        [ 9.9335e-03, -9.7733e-03, -3.3569e-02,  ..., -2.9404e-02,
          5.6152e-02,  1.4862e-02],
        [-1.0864e-02, -1.6647e-02,  2.1667e-02,  ..., -2.8931e-02,
         -2.3956e-02,  2.3621e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.1504,  0.4893, -0.2295,  ..., -0.7617, -2.8496, -1.2207]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 18:50:43 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for After something is managing, it has managed
After something is spending, it has spent
After something is teaching, it has taught
After something is allowing, it has allowed
After something is asking, it has asked
After something is announcing, it has announced
After something is telling, it has told
After something is adding, it has
2024-07-31 18:50:43 root INFO     [order_1_approx] starting weight calculation for After something is allowing, it has allowed
After something is asking, it has asked
After something is spending, it has spent
After something is managing, it has managed
After something is adding, it has added
After something is teaching, it has taught
After something is announcing, it has announced
After something is telling, it has
2024-07-31 18:50:43 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-07-31 18:53:29 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2229,  0.0263,  0.1537,  ..., -0.2549, -0.1028,  0.0193],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.6641,  0.9678,  3.2559,  ...,  0.1807, -3.4961, -0.8496],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0023,  0.0116, -0.0242,  ..., -0.0103,  0.0164,  0.0080],
        [-0.0229,  0.0439,  0.0200,  ..., -0.0144, -0.0613, -0.0101],
        [-0.0033, -0.0198,  0.0280,  ..., -0.0029, -0.0166, -0.0020],
        ...,
        [-0.0039, -0.0155, -0.0384,  ..., -0.0055,  0.0315,  0.0114],
        [-0.0185,  0.0086, -0.0163,  ..., -0.0084,  0.0337,  0.0183],
        [ 0.0133,  0.0214,  0.0263,  ...,  0.0150, -0.0066,  0.0041]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.5410,  0.9268,  3.6426,  ...,  0.0769, -3.5020, -1.1152]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 18:53:30 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for After something is allowing, it has allowed
After something is asking, it has asked
After something is spending, it has spent
After something is managing, it has managed
After something is adding, it has added
After something is teaching, it has taught
After something is announcing, it has announced
After something is telling, it has
2024-07-31 18:53:31 root INFO     [order_1_approx] starting weight calculation for After something is announcing, it has announced
After something is managing, it has managed
After something is adding, it has added
After something is asking, it has asked
After something is allowing, it has allowed
After something is telling, it has told
After something is spending, it has spent
After something is teaching, it has
2024-07-31 18:53:31 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-07-31 18:56:22 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2366,  0.3210,  0.0842,  ..., -0.4060, -0.2622,  0.0728],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.0391,  0.5410,  2.9258,  ..., -0.8809, -3.0137, -4.1133],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0018,  0.0015, -0.0069,  ..., -0.0078,  0.0282, -0.0075],
        [-0.0479,  0.0259, -0.0215,  ..., -0.0094, -0.0331,  0.0050],
        [ 0.0252,  0.0223,  0.0447,  ...,  0.0039,  0.0086, -0.0293],
        ...,
        [ 0.0148,  0.0056,  0.0068,  ..., -0.0007,  0.0335, -0.0272],
        [ 0.0037,  0.0150,  0.0014,  ..., -0.0088,  0.0193, -0.0140],
        [ 0.0070,  0.0179,  0.0185,  ...,  0.0201, -0.0170,  0.0035]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.1406,  0.5303,  3.4238,  ..., -0.6836, -2.7539, -4.2812]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 18:56:22 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for After something is announcing, it has announced
After something is managing, it has managed
After something is adding, it has added
After something is asking, it has asked
After something is allowing, it has allowed
After something is telling, it has told
After something is spending, it has spent
After something is teaching, it has
2024-07-31 18:56:22 root INFO     total operator prediction time: 1376.8505775928497 seconds
2024-07-31 18:56:22 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on verb_inf - Ved
2024-07-31 18:56:22 root INFO     building operator verb_inf - Ved
2024-07-31 18:56:23 root INFO     [order_1_approx] starting weight calculation for If the present form is expect, the past form is expected
If the present form is tell, the past form is told
If the present form is ensure, the past form is ensured
If the present form is involve, the past form is involved
If the present form is become, the past form is became
If the present form is develop, the past form is developed
If the present form is appear, the past form is appeared
If the present form is manage, the past form is
2024-07-31 18:56:23 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-07-31 18:59:10 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0974,  0.2080, -0.0720,  ..., -0.0844, -0.2617, -0.0835],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.3105, -0.9858,  1.4727,  ..., -1.7305, -1.1680, -1.6836],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0182,  0.0023, -0.0023,  ..., -0.0316,  0.0120, -0.0177],
        [ 0.0090,  0.0664,  0.0155,  ...,  0.0558, -0.0343, -0.0008],
        [-0.0058, -0.0036,  0.0035,  ..., -0.0108, -0.0308, -0.0054],
        ...,
        [ 0.0126, -0.0075, -0.0016,  ...,  0.0268,  0.0076, -0.0136],
        [ 0.0276, -0.0122, -0.0126,  ..., -0.0001, -0.0246, -0.0042],
        [ 0.0302,  0.0045,  0.0227,  ...,  0.0496, -0.0385,  0.0086]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.4688, -1.3174,  1.4248,  ..., -1.5098, -1.0742, -1.7363]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 18:59:11 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If the present form is expect, the past form is expected
If the present form is tell, the past form is told
If the present form is ensure, the past form is ensured
If the present form is involve, the past form is involved
If the present form is become, the past form is became
If the present form is develop, the past form is developed
If the present form is appear, the past form is appeared
If the present form is manage, the past form is
2024-07-31 18:59:11 root INFO     [order_1_approx] starting weight calculation for If the present form is manage, the past form is managed
If the present form is ensure, the past form is ensured
If the present form is involve, the past form is involved
If the present form is tell, the past form is told
If the present form is appear, the past form is appeared
If the present form is develop, the past form is developed
If the present form is become, the past form is became
If the present form is expect, the past form is
2024-07-31 18:59:11 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-07-31 19:01:56 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1891, -0.0348, -0.0707,  ..., -0.4194, -0.3164, -0.0223],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.8770,  0.7324, -0.9980,  ..., -1.0664, -2.4141, -1.9062],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0115, -0.0019,  0.0012,  ..., -0.0174, -0.0183,  0.0217],
        [-0.0252,  0.0167, -0.0066,  ..., -0.0062,  0.0172,  0.0059],
        [ 0.0185, -0.0013,  0.0056,  ..., -0.0148, -0.0163,  0.0060],
        ...,
        [-0.0005,  0.0044,  0.0042,  ...,  0.0089,  0.0292, -0.0107],
        [ 0.0173,  0.0002, -0.0137,  ..., -0.0003,  0.0364, -0.0081],
        [ 0.0051,  0.0145,  0.0081,  ...,  0.0068,  0.0265,  0.0007]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.8066,  0.7490, -1.2646,  ..., -0.8721, -1.9961, -1.7988]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 19:01:57 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If the present form is manage, the past form is managed
If the present form is ensure, the past form is ensured
If the present form is involve, the past form is involved
If the present form is tell, the past form is told
If the present form is appear, the past form is appeared
If the present form is develop, the past form is developed
If the present form is become, the past form is became
If the present form is expect, the past form is
2024-07-31 19:01:57 root INFO     [order_1_approx] starting weight calculation for If the present form is ensure, the past form is ensured
If the present form is become, the past form is became
If the present form is manage, the past form is managed
If the present form is involve, the past form is involved
If the present form is appear, the past form is appeared
If the present form is tell, the past form is told
If the present form is expect, the past form is expected
If the present form is develop, the past form is
2024-07-31 19:01:57 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-07-31 19:04:43 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2081, -0.0081,  0.0710,  ..., -0.2053, -0.2017,  0.0806],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.7432, -1.2354,  3.1875,  ..., -1.7109, -1.4453, -1.6250],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0006, -0.0099,  0.0025,  ..., -0.0305,  0.0033, -0.0044],
        [-0.0274,  0.0333, -0.0133,  ...,  0.0405, -0.0031, -0.0204],
        [ 0.0085,  0.0170, -0.0173,  ..., -0.0092, -0.0730, -0.0169],
        ...,
        [ 0.0268, -0.0053, -0.0009,  ...,  0.0034,  0.0095,  0.0040],
        [ 0.0223, -0.0015, -0.0063,  ..., -0.0211,  0.0113,  0.0087],
        [-0.0019, -0.0098,  0.0034,  ...,  0.0331, -0.0273,  0.0186]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.6807, -1.0986,  2.8008,  ..., -2.2188, -0.8652, -1.4961]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 19:04:43 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If the present form is ensure, the past form is ensured
If the present form is become, the past form is became
If the present form is manage, the past form is managed
If the present form is involve, the past form is involved
If the present form is appear, the past form is appeared
If the present form is tell, the past form is told
If the present form is expect, the past form is expected
If the present form is develop, the past form is
2024-07-31 19:04:44 root INFO     [order_1_approx] starting weight calculation for If the present form is manage, the past form is managed
If the present form is develop, the past form is developed
If the present form is become, the past form is became
If the present form is appear, the past form is appeared
If the present form is ensure, the past form is ensured
If the present form is involve, the past form is involved
If the present form is expect, the past form is expected
If the present form is tell, the past form is
2024-07-31 19:04:44 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-07-31 19:07:28 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1097,  0.0149,  0.0386,  ..., -0.1521, -0.3049,  0.1700],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.1660,  0.1277,  1.8232,  ...,  3.1523, -5.1641, -2.8203],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0135, -0.0142, -0.0172,  ..., -0.0092,  0.0295, -0.0183],
        [ 0.0089,  0.0339, -0.0055,  ...,  0.0174, -0.0378, -0.0213],
        [-0.0190, -0.0142,  0.0143,  ..., -0.0182, -0.0110, -0.0109],
        ...,
        [ 0.0078,  0.0016,  0.0228,  ...,  0.0311, -0.0285, -0.0120],
        [-0.0086,  0.0044, -0.0232,  ..., -0.0464,  0.0508,  0.0208],
        [ 0.0164,  0.0391,  0.0168,  ...,  0.0165,  0.0011,  0.0269]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.5117,  0.2979,  2.2734,  ...,  3.2422, -4.7852, -3.3672]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 19:07:29 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If the present form is manage, the past form is managed
If the present form is develop, the past form is developed
If the present form is become, the past form is became
If the present form is appear, the past form is appeared
If the present form is ensure, the past form is ensured
If the present form is involve, the past form is involved
If the present form is expect, the past form is expected
If the present form is tell, the past form is
2024-07-31 19:07:29 root INFO     [order_1_approx] starting weight calculation for If the present form is tell, the past form is told
If the present form is expect, the past form is expected
If the present form is ensure, the past form is ensured
If the present form is develop, the past form is developed
If the present form is manage, the past form is managed
If the present form is appear, the past form is appeared
If the present form is involve, the past form is involved
If the present form is become, the past form is
2024-07-31 19:07:29 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-07-31 19:10:15 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0169,  0.1654,  0.2598,  ..., -0.0916, -0.3521,  0.0784],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.9678,  0.3584,  1.5088,  ...,  0.1450,  0.6172, -1.2979],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0240, -0.0076,  0.0338,  ...,  0.0202,  0.0320, -0.0112],
        [-0.0155,  0.0026,  0.0388,  ..., -0.0035, -0.0472, -0.0306],
        [ 0.0119, -0.0080,  0.0157,  ..., -0.0255, -0.0094, -0.0247],
        ...,
        [ 0.0051,  0.0011, -0.0236,  ...,  0.0314,  0.0089, -0.0160],
        [ 0.0183,  0.0407, -0.0363,  ..., -0.0267,  0.0443, -0.0007],
        [ 0.0070,  0.0082,  0.0269,  ..., -0.0048, -0.0179,  0.0037]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.9307,  0.0728,  0.9160,  ...,  0.2891,  0.4695, -1.5791]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 19:10:16 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If the present form is tell, the past form is told
If the present form is expect, the past form is expected
If the present form is ensure, the past form is ensured
If the present form is develop, the past form is developed
If the present form is manage, the past form is managed
If the present form is appear, the past form is appeared
If the present form is involve, the past form is involved
If the present form is become, the past form is
2024-07-31 19:10:16 root INFO     [order_1_approx] starting weight calculation for If the present form is expect, the past form is expected
If the present form is tell, the past form is told
If the present form is develop, the past form is developed
If the present form is appear, the past form is appeared
If the present form is become, the past form is became
If the present form is ensure, the past form is ensured
If the present form is manage, the past form is managed
If the present form is involve, the past form is
2024-07-31 19:10:16 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-07-31 19:12:57 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0092,  0.0646, -0.0469,  ...,  0.0385, -0.3564,  0.0728],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.0176,  0.7544,  2.0156,  ..., -0.7544,  0.0320, -2.7383],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0106,  0.0032, -0.0057,  ..., -0.0162,  0.0004, -0.0309],
        [-0.0333,  0.0568,  0.0131,  ...,  0.0313, -0.0054, -0.0315],
        [ 0.0034,  0.0049,  0.0018,  ..., -0.0140, -0.0372, -0.0203],
        ...,
        [-0.0085,  0.0018, -0.0099,  ...,  0.0446,  0.0135,  0.0132],
        [ 0.0175,  0.0142, -0.0199,  ..., -0.0211,  0.0317,  0.0190],
        [ 0.0342,  0.0148,  0.0239,  ...,  0.0167, -0.0440,  0.0133]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.4836,  0.8569,  1.5693,  ..., -0.7383,  0.0172, -2.6152]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 19:12:58 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If the present form is expect, the past form is expected
If the present form is tell, the past form is told
If the present form is develop, the past form is developed
If the present form is appear, the past form is appeared
If the present form is become, the past form is became
If the present form is ensure, the past form is ensured
If the present form is manage, the past form is managed
If the present form is involve, the past form is
2024-07-31 19:12:58 root INFO     [order_1_approx] starting weight calculation for If the present form is appear, the past form is appeared
If the present form is involve, the past form is involved
If the present form is develop, the past form is developed
If the present form is tell, the past form is told
If the present form is expect, the past form is expected
If the present form is manage, the past form is managed
If the present form is become, the past form is became
If the present form is ensure, the past form is
2024-07-31 19:12:58 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-07-31 19:15:45 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1802,  0.0275, -0.1902,  ..., -0.0099, -0.1857, -0.0271],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.2021,  0.2061,  0.8311,  ...,  0.1787, -1.9912, -2.3652],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0260,  0.0117,  0.0076,  ..., -0.0266, -0.0024, -0.0056],
        [-0.0154,  0.0378, -0.0153,  ..., -0.0006,  0.0202, -0.0077],
        [-0.0031, -0.0033,  0.0225,  ..., -0.0248, -0.0453, -0.0094],
        ...,
        [-0.0153, -0.0257,  0.0098,  ...,  0.0104, -0.0035, -0.0131],
        [ 0.0327, -0.0056, -0.0147,  ..., -0.0089,  0.0108,  0.0079],
        [ 0.0394,  0.0424,  0.0193,  ...,  0.0055, -0.0188,  0.0306]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.3906,  0.5049,  0.9121,  ...,  0.2454, -1.4785, -1.6465]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 19:15:46 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If the present form is appear, the past form is appeared
If the present form is involve, the past form is involved
If the present form is develop, the past form is developed
If the present form is tell, the past form is told
If the present form is expect, the past form is expected
If the present form is manage, the past form is managed
If the present form is become, the past form is became
If the present form is ensure, the past form is
2024-07-31 19:15:46 root INFO     [order_1_approx] starting weight calculation for If the present form is expect, the past form is expected
If the present form is tell, the past form is told
If the present form is develop, the past form is developed
If the present form is become, the past form is became
If the present form is involve, the past form is involved
If the present form is manage, the past form is managed
If the present form is ensure, the past form is ensured
If the present form is appear, the past form is
2024-07-31 19:15:47 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-07-31 19:18:33 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0457, -0.0198, -0.0286,  ..., -0.0239, -0.2742,  0.0281],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.1484,  0.6475,  0.7002,  ...,  1.3496, -3.2461,  0.3652],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0092, -0.0515, -0.0094,  ..., -0.0229,  0.0366, -0.0024],
        [-0.0302,  0.0573, -0.0042,  ...,  0.0408, -0.0267, -0.0258],
        [ 0.0173,  0.0338,  0.0399,  ..., -0.0387, -0.0198, -0.0110],
        ...,
        [-0.0097, -0.0010,  0.0072,  ...,  0.0406, -0.0331,  0.0147],
        [ 0.0381, -0.0067,  0.0100,  ..., -0.0218,  0.0325, -0.0286],
        [ 0.0099,  0.0547,  0.0146,  ...,  0.0035, -0.0213,  0.0093]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.1187,  0.5942,  0.7046,  ...,  1.2285, -3.1895,  0.2627]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 19:18:34 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If the present form is expect, the past form is expected
If the present form is tell, the past form is told
If the present form is develop, the past form is developed
If the present form is become, the past form is became
If the present form is involve, the past form is involved
If the present form is manage, the past form is managed
If the present form is ensure, the past form is ensured
If the present form is appear, the past form is
2024-07-31 19:18:34 root INFO     total operator prediction time: 1331.5013496875763 seconds
2024-07-31 19:18:34 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on verb_inf - 3pSg
2024-07-31 19:18:34 root INFO     building operator verb_inf - 3pSg
2024-07-31 19:18:34 root INFO     [order_1_approx] starting weight calculation for I allow, he allows
I improve, he improves
I identify, he identifies
I involve, he involves
I become, he becomes
I exist, he exists
I require, he requires
I protect, he
2024-07-31 19:18:34 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-07-31 19:21:21 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0476, -0.0331, -0.1353,  ..., -0.0208, -0.1100, -0.0423],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.6729, -5.4609, -1.6641,  ..., -1.2725, -6.1602,  0.9678],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0144,  0.0101,  0.0039,  ...,  0.0008, -0.0326,  0.0044],
        [-0.0177, -0.0059,  0.0001,  ..., -0.0102,  0.0186,  0.0060],
        [ 0.0254,  0.0077,  0.0021,  ...,  0.0054, -0.0053, -0.0229],
        ...,
        [ 0.0068, -0.0102,  0.0055,  ..., -0.0003,  0.0177,  0.0119],
        [ 0.0198, -0.0360,  0.0008,  ..., -0.0288,  0.0260,  0.0012],
        [ 0.0154, -0.0105,  0.0026,  ..., -0.0178,  0.0080, -0.0054]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.5039, -5.2852, -1.5439,  ..., -0.7852, -6.5352,  0.9761]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 19:21:22 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for I allow, he allows
I improve, he improves
I identify, he identifies
I involve, he involves
I become, he becomes
I exist, he exists
I require, he requires
I protect, he
2024-07-31 19:21:22 root INFO     [order_1_approx] starting weight calculation for I identify, he identifies
I become, he becomes
I allow, he allows
I involve, he involves
I improve, he improves
I protect, he protects
I require, he requires
I exist, he
2024-07-31 19:21:23 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-07-31 19:24:13 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1405,  0.1046, -0.2896,  ..., -0.1970, -0.1731, -0.2812],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.4297, -3.2559, -1.4648,  ..., -2.0625, -5.5898,  0.7734],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0127, -0.0217,  0.0144,  ..., -0.0085, -0.0223, -0.0116],
        [-0.0132,  0.0030, -0.0064,  ..., -0.0196,  0.0117, -0.0113],
        [ 0.0053,  0.0134, -0.0010,  ...,  0.0036,  0.0080,  0.0165],
        ...,
        [ 0.0080, -0.0128,  0.0011,  ...,  0.0145, -0.0091, -0.0008],
        [-0.0236, -0.0235,  0.0002,  ..., -0.0398,  0.0343, -0.0075],
        [ 0.0022,  0.0042,  0.0021,  ..., -0.0018,  0.0039, -0.0070]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.6211, -3.0664, -1.6318,  ..., -1.6172, -6.0352,  0.6021]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 19:24:15 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for I identify, he identifies
I become, he becomes
I allow, he allows
I involve, he involves
I improve, he improves
I protect, he protects
I require, he requires
I exist, he
2024-07-31 19:24:15 root INFO     [order_1_approx] starting weight calculation for I exist, he exists
I allow, he allows
I protect, he protects
I require, he requires
I identify, he identifies
I involve, he involves
I improve, he improves
I become, he
2024-07-31 19:24:15 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-07-31 19:27:05 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0385,  0.2781, -0.0503,  ..., -0.1003, -0.2410,  0.1158],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.0703, -2.7305, -1.8623,  ..., -0.3828, -3.4258, -0.3203],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0090, -0.0039,  0.0249,  ...,  0.0258,  0.0144, -0.0077],
        [-0.0169, -0.0178, -0.0060,  ..., -0.0050, -0.0131,  0.0156],
        [-0.0133, -0.0032, -0.0187,  ...,  0.0209, -0.0050, -0.0193],
        ...,
        [ 0.0038, -0.0094,  0.0018,  ...,  0.0087, -0.0035, -0.0048],
        [ 0.0063,  0.0230,  0.0024,  ..., -0.0169, -0.0080, -0.0168],
        [ 0.0015,  0.0003,  0.0101,  ...,  0.0054, -0.0037,  0.0179]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.9941, -2.8398, -1.7617,  ..., -0.1437, -3.9082, -0.5078]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 19:27:06 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for I exist, he exists
I allow, he allows
I protect, he protects
I require, he requires
I identify, he identifies
I involve, he involves
I improve, he improves
I become, he
2024-07-31 19:27:06 root INFO     [order_1_approx] starting weight calculation for I identify, he identifies
I protect, he protects
I improve, he improves
I become, he becomes
I allow, he allows
I exist, he exists
I require, he requires
I involve, he
2024-07-31 19:27:06 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-07-31 19:29:52 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1191,  0.1804, -0.0827,  ...,  0.0920, -0.4473, -0.0905],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.3086, -1.2520,  2.3203,  ..., -0.3320, -4.7500, -1.5703],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0125, -0.0140,  0.0328,  ...,  0.0258, -0.0190,  0.0080],
        [-0.0309,  0.0322, -0.0070,  ..., -0.0112,  0.0206, -0.0053],
        [ 0.0050,  0.0183,  0.0195,  ...,  0.0091, -0.0065,  0.0042],
        ...,
        [ 0.0221, -0.0083, -0.0118,  ..., -0.0248, -0.0004,  0.0101],
        [ 0.0033,  0.0113,  0.0024,  ..., -0.0133,  0.0065,  0.0420],
        [ 0.0258,  0.0231,  0.0287,  ...,  0.0017, -0.0075, -0.0295]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.8994, -1.0254,  1.5996,  ..., -0.3135, -5.7461, -1.2041]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 19:29:53 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for I identify, he identifies
I protect, he protects
I improve, he improves
I become, he becomes
I allow, he allows
I exist, he exists
I require, he requires
I involve, he
2024-07-31 19:29:53 root INFO     [order_1_approx] starting weight calculation for I identify, he identifies
I protect, he protects
I require, he requires
I involve, he involves
I exist, he exists
I become, he becomes
I allow, he allows
I improve, he
2024-07-31 19:29:53 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-07-31 19:32:44 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1600,  0.1758, -0.0159,  ..., -0.1183, -0.1589,  0.0608],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 6.2500, -3.4863, -2.6133,  ..., -0.8120, -7.2578,  2.3438],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0301,  0.0080,  0.0238,  ...,  0.0546, -0.0144,  0.0140],
        [ 0.0031,  0.0127, -0.0058,  ..., -0.0153,  0.0066, -0.0164],
        [ 0.0050,  0.0240, -0.0031,  ..., -0.0043,  0.0081, -0.0164],
        ...,
        [ 0.0135, -0.0209, -0.0051,  ...,  0.0315, -0.0027, -0.0136],
        [-0.0054, -0.0156, -0.0113,  ..., -0.0463, -0.0131,  0.0363],
        [ 0.0043, -0.0043,  0.0111,  ...,  0.0241,  0.0002,  0.0271]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 5.8945, -3.2480, -2.4434,  ..., -0.5615, -7.3750,  2.3457]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 19:32:44 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for I identify, he identifies
I protect, he protects
I require, he requires
I involve, he involves
I exist, he exists
I become, he becomes
I allow, he allows
I improve, he
2024-07-31 19:32:45 root INFO     [order_1_approx] starting weight calculation for I require, he requires
I become, he becomes
I protect, he protects
I exist, he exists
I improve, he improves
I allow, he allows
I involve, he involves
I identify, he
2024-07-31 19:32:45 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-07-31 19:35:35 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1807,  0.0394, -0.1959,  ...,  0.3274, -0.3071, -0.0592],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.2148, -1.9453,  2.6797,  ..., -1.9932, -6.3438,  0.9727],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0137, -0.0082,  0.0140,  ...,  0.0273, -0.0224,  0.0082],
        [-0.0292, -0.0017, -0.0151,  ..., -0.0143, -0.0012, -0.0205],
        [ 0.0189, -0.0185,  0.0455,  ..., -0.0120, -0.0296,  0.0238],
        ...,
        [-0.0010, -0.0055, -0.0131,  ..., -0.0116,  0.0162, -0.0170],
        [ 0.0205, -0.0060, -0.0435,  ..., -0.0532,  0.0489, -0.0282],
        [ 0.0045, -0.0050,  0.0174,  ...,  0.0098,  0.0057, -0.0224]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.0664, -1.3809,  1.8750,  ..., -1.2871, -6.5703,  0.9189]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 19:35:36 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for I require, he requires
I become, he becomes
I protect, he protects
I exist, he exists
I improve, he improves
I allow, he allows
I involve, he involves
I identify, he
2024-07-31 19:35:36 root INFO     [order_1_approx] starting weight calculation for I protect, he protects
I exist, he exists
I require, he requires
I improve, he improves
I identify, he identifies
I become, he becomes
I involve, he involves
I allow, he
2024-07-31 19:35:36 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-07-31 19:38:27 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0391,  0.2739,  0.1877,  ..., -0.2183, -0.3513, -0.1124],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.2891, -3.8027, -1.4238,  ..., -1.7285, -7.7930,  1.5137],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0145,  0.0071, -0.0140,  ...,  0.0356, -0.0332,  0.0051],
        [-0.0273, -0.0118, -0.0368,  ...,  0.0014,  0.0468, -0.0314],
        [-0.0163,  0.0220,  0.0077,  ...,  0.0283, -0.0186,  0.0143],
        ...,
        [-0.0287, -0.0210,  0.0018,  ...,  0.0023,  0.0296, -0.0003],
        [ 0.0126, -0.0447, -0.0199,  ..., -0.0625,  0.0637, -0.0343],
        [ 0.0011,  0.0071,  0.0097,  ..., -0.0008,  0.0047, -0.0056]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.1816, -2.7305, -1.9824,  ..., -1.0293, -8.1953,  1.4395]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 19:38:28 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for I protect, he protects
I exist, he exists
I require, he requires
I improve, he improves
I identify, he identifies
I become, he becomes
I involve, he involves
I allow, he
2024-07-31 19:38:28 root INFO     [order_1_approx] starting weight calculation for I allow, he allows
I improve, he improves
I protect, he protects
I exist, he exists
I identify, he identifies
I become, he becomes
I involve, he involves
I require, he
2024-07-31 19:38:28 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-07-31 19:41:17 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1654,  0.1851, -0.1393,  ..., -0.1089, -0.2079, -0.2317],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.3203, -2.6152,  0.6816,  ..., -1.4502, -6.6172,  0.0723],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0025,  0.0091,  0.0257,  ...,  0.0068, -0.0230,  0.0013],
        [-0.0441, -0.0052, -0.0184,  ...,  0.0122,  0.0052, -0.0092],
        [ 0.0139,  0.0177,  0.0142,  ..., -0.0194,  0.0233, -0.0090],
        ...,
        [-0.0310, -0.0229,  0.0010,  ..., -0.0006, -0.0205,  0.0060],
        [-0.0176,  0.0090,  0.0099,  ..., -0.0128,  0.0874, -0.0048],
        [ 0.0034,  0.0056,  0.0118,  ...,  0.0022,  0.0153, -0.0118]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.4512, -2.0742,  0.5840,  ..., -0.8838, -7.1094,  0.3184]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 19:41:18 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for I allow, he allows
I improve, he improves
I protect, he protects
I exist, he exists
I identify, he identifies
I become, he becomes
I involve, he involves
I require, he
2024-07-31 19:41:18 root INFO     total operator prediction time: 1364.3884868621826 seconds
2024-07-31 19:41:18 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on verb_Ving - 3pSg
2024-07-31 19:41:18 root INFO     building operator verb_Ving - 3pSg
2024-07-31 19:41:19 root INFO     [order_1_approx] starting weight calculation for When something is occurring, it occurs
When something is providing, it provides
When something is applying, it applies
When something is performing, it performs
When something is representing, it represents
When something is creating, it creates
When something is remaining, it remains
When something is depending, it
2024-07-31 19:41:19 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-07-31 19:44:06 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0872,  0.2957, -0.0939,  ..., -0.0744, -0.1450,  0.0006],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.4688, -0.3511,  1.4727,  ..., -1.5391, -5.5664,  0.3496],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0138,  0.0145, -0.0240,  ..., -0.0072,  0.0058, -0.0271],
        [-0.0243,  0.0870, -0.0403,  ...,  0.0834,  0.0238,  0.0100],
        [-0.0279,  0.0461,  0.0152,  ...,  0.0191, -0.0319, -0.0211],
        ...,
        [ 0.0248,  0.0033,  0.0246,  ...,  0.0196,  0.0019,  0.0123],
        [ 0.0343, -0.0217,  0.0433,  ..., -0.0788,  0.0046,  0.0182],
        [ 0.0343, -0.0158,  0.0097,  ..., -0.0198, -0.0205,  0.0506]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.5859, -0.7393,  1.5430,  ..., -1.3008, -5.8867, -0.0081]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 19:44:07 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When something is occurring, it occurs
When something is providing, it provides
When something is applying, it applies
When something is performing, it performs
When something is representing, it represents
When something is creating, it creates
When something is remaining, it remains
When something is depending, it
2024-07-31 19:44:07 root INFO     [order_1_approx] starting weight calculation for When something is depending, it depends
When something is remaining, it remains
When something is representing, it represents
When something is providing, it provides
When something is occurring, it occurs
When something is applying, it applies
When something is creating, it creates
When something is performing, it
2024-07-31 19:44:07 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-07-31 19:46:56 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0147,  0.2639,  0.0309,  ..., -0.0740, -0.1989, -0.0612],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.1680, -4.3945,  1.1777,  ..., -1.0898, -6.1406, -2.4785],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0299,  0.0508, -0.0553,  ...,  0.0554,  0.0018, -0.1299],
        [-0.0636,  0.1064, -0.0651,  ...,  0.0521,  0.0853, -0.1075],
        [-0.0429,  0.0560, -0.0447,  ...,  0.0689, -0.0312, -0.0473],
        ...,
        [-0.0099,  0.0197,  0.0108,  ...,  0.0213,  0.0224, -0.0019],
        [ 0.0604, -0.0804,  0.0653,  ..., -0.0862, -0.0357,  0.0975],
        [-0.0112,  0.0446, -0.0095,  ...,  0.0202,  0.0674, -0.0388]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.5410, -2.9961,  0.6187,  ..., -1.2324, -6.5312, -2.1758]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 19:46:57 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When something is depending, it depends
When something is remaining, it remains
When something is representing, it represents
When something is providing, it provides
When something is occurring, it occurs
When something is applying, it applies
When something is creating, it creates
When something is performing, it
2024-07-31 19:46:57 root INFO     [order_1_approx] starting weight calculation for When something is creating, it creates
When something is remaining, it remains
When something is occurring, it occurs
When something is depending, it depends
When something is performing, it performs
When something is providing, it provides
When something is applying, it applies
When something is representing, it
2024-07-31 19:46:57 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-07-31 19:49:46 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0179,  0.3372, -0.2397,  ..., -0.0421, -0.0508, -0.1626],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.5654, -2.9688,  1.9297,  ...,  1.2021, -8.1953,  0.0859],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0346, -0.0130, -0.0026,  ..., -0.0012,  0.0268,  0.0228],
        [-0.0125,  0.0374,  0.0104,  ...,  0.0001,  0.0242,  0.0192],
        [ 0.0003, -0.0064,  0.0153,  ..., -0.0048, -0.0481, -0.0484],
        ...,
        [ 0.0194,  0.0288, -0.0200,  ...,  0.0339,  0.0037,  0.0164],
        [-0.0099, -0.0075,  0.0121,  ..., -0.0093, -0.0094, -0.0532],
        [-0.0045, -0.0216,  0.0141,  ..., -0.0024, -0.0202, -0.0164]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.4292, -3.0527,  1.8877,  ...,  1.3496, -7.9922, -0.3735]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 19:49:47 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When something is creating, it creates
When something is remaining, it remains
When something is occurring, it occurs
When something is depending, it depends
When something is performing, it performs
When something is providing, it provides
When something is applying, it applies
When something is representing, it
2024-07-31 19:49:47 root INFO     [order_1_approx] starting weight calculation for When something is remaining, it remains
When something is representing, it represents
When something is occurring, it occurs
When something is depending, it depends
When something is applying, it applies
When something is creating, it creates
When something is performing, it performs
When something is providing, it
2024-07-31 19:49:47 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-07-31 19:52:36 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0688,  0.0276, -0.0891,  ..., -0.0223, -0.0925, -0.2256],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.0703, -5.8594,  0.7832,  ..., -1.1895, -6.7969, -0.6133],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0158, -0.0271,  0.0481,  ..., -0.0167, -0.0451,  0.0022],
        [ 0.0006,  0.0323, -0.0333,  ...,  0.0130,  0.0574,  0.0378],
        [-0.0123,  0.0022,  0.0598,  ...,  0.0192, -0.0633, -0.0285],
        ...,
        [-0.0035,  0.0177,  0.0127,  ...,  0.0411, -0.0009,  0.0164],
        [ 0.0174, -0.0005, -0.0029,  ..., -0.0188,  0.0051, -0.0044],
        [ 0.0144, -0.0164,  0.0232,  ..., -0.0291, -0.0105,  0.0155]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.9951, -4.7812,  0.5586,  ..., -1.4023, -6.9961, -0.8887]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 19:52:37 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When something is remaining, it remains
When something is representing, it represents
When something is occurring, it occurs
When something is depending, it depends
When something is applying, it applies
When something is creating, it creates
When something is performing, it performs
When something is providing, it
2024-07-31 19:52:38 root INFO     [order_1_approx] starting weight calculation for When something is depending, it depends
When something is remaining, it remains
When something is providing, it provides
When something is occurring, it occurs
When something is creating, it creates
When something is performing, it performs
When something is representing, it represents
When something is applying, it
2024-07-31 19:52:38 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-07-31 19:55:27 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2384,  0.1693,  0.1921,  ...,  0.1694, -0.2393, -0.0959],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.3223, -2.5176, -0.3730,  ..., -0.8877, -6.1133, -1.0908],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0402, -0.0150,  0.0107,  ..., -0.0297, -0.0254,  0.0040],
        [-0.0291,  0.0444, -0.0300,  ...,  0.0144,  0.0082,  0.0178],
        [ 0.0041,  0.0145,  0.0145,  ...,  0.0007, -0.0258, -0.0248],
        ...,
        [ 0.0194,  0.0198, -0.0058,  ...,  0.0401,  0.0152,  0.0025],
        [ 0.0139,  0.0334, -0.0108,  ..., -0.0739,  0.0262, -0.0530],
        [-0.0142, -0.0219,  0.0268,  ...,  0.0091, -0.0356,  0.0183]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 8.8525e-01, -2.5859e+00,  4.3945e-03,  ..., -1.0273e+00,
         -6.2734e+00, -8.9355e-01]], device='cuda:1', dtype=torch.float16,
       grad_fn=<SubBackward0>) 

                    
2024-07-31 19:55:28 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When something is depending, it depends
When something is remaining, it remains
When something is providing, it provides
When something is occurring, it occurs
When something is creating, it creates
When something is performing, it performs
When something is representing, it represents
When something is applying, it
2024-07-31 19:55:28 root INFO     [order_1_approx] starting weight calculation for When something is providing, it provides
When something is performing, it performs
When something is applying, it applies
When something is representing, it represents
When something is depending, it depends
When something is creating, it creates
When something is occurring, it occurs
When something is remaining, it
2024-07-31 19:55:28 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-07-31 19:58:18 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0365,  0.4519,  0.0234,  ..., -0.0302, -0.0801,  0.0517],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.4023, -2.7129, -0.2617,  ..., -1.8184, -1.9609, -1.5820],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0229, -0.0479, -0.0414,  ...,  0.0075,  0.0051,  0.0164],
        [ 0.0157,  0.0923,  0.0003,  ...,  0.0249,  0.0210,  0.0343],
        [ 0.0019, -0.0144,  0.0227,  ..., -0.0163, -0.0012, -0.0050],
        ...,
        [ 0.0300, -0.0024, -0.0090,  ...,  0.0446, -0.0108,  0.0004],
        [-0.0484, -0.0119, -0.0112,  ..., -0.0434,  0.0259,  0.0055],
        [ 0.0109,  0.0470,  0.0105,  ..., -0.0049,  0.0030, -0.0031]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.3398, -3.6973, -0.1012,  ..., -1.6182, -1.7441, -2.6992]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 19:58:19 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When something is providing, it provides
When something is performing, it performs
When something is applying, it applies
When something is representing, it represents
When something is depending, it depends
When something is creating, it creates
When something is occurring, it occurs
When something is remaining, it
2024-07-31 19:58:19 root INFO     [order_1_approx] starting weight calculation for When something is creating, it creates
When something is remaining, it remains
When something is providing, it provides
When something is depending, it depends
When something is performing, it performs
When something is representing, it represents
When something is applying, it applies
When something is occurring, it
2024-07-31 19:58:19 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-07-31 20:01:08 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1475,  0.1487,  0.0698,  ..., -0.0248, -0.1039, -0.4036],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.8311, -3.6797, -0.8604,  ..., -1.1230, -3.6094,  0.6816],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0064,  0.0127, -0.0002,  ...,  0.0019,  0.0316, -0.0024],
        [ 0.0082,  0.0414, -0.0052,  ...,  0.0118,  0.0013,  0.0076],
        [ 0.0190, -0.0031, -0.0212,  ..., -0.0042, -0.0266, -0.0388],
        ...,
        [-0.0214,  0.0161,  0.0124,  ..., -0.0005, -0.0030,  0.0177],
        [ 0.0336,  0.0124,  0.0009,  ..., -0.0495, -0.0460, -0.0124],
        [ 0.0002, -0.0066,  0.0056,  ...,  0.0223, -0.0156, -0.0045]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.4548, -3.1914, -1.3604,  ..., -0.8828, -4.0195,  0.2573]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 20:01:09 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When something is creating, it creates
When something is remaining, it remains
When something is providing, it provides
When something is depending, it depends
When something is performing, it performs
When something is representing, it represents
When something is applying, it applies
When something is occurring, it
2024-07-31 20:01:09 root INFO     [order_1_approx] starting weight calculation for When something is providing, it provides
When something is applying, it applies
When something is occurring, it occurs
When something is depending, it depends
When something is remaining, it remains
When something is representing, it represents
When something is performing, it performs
When something is creating, it
2024-07-31 20:01:09 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-07-31 20:03:58 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1345,  0.2874, -0.0358,  ...,  0.2073, -0.1499, -0.1499],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.2178, -3.9219,  1.9355,  ...,  0.8525, -6.3750,  0.5879],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0320, -0.0106, -0.0199,  ...,  0.0036, -0.0094,  0.0258],
        [ 0.0148,  0.0797, -0.0504,  ...,  0.0046,  0.0421, -0.0060],
        [ 0.0037, -0.0245,  0.0380,  ...,  0.0215, -0.0350, -0.0106],
        ...,
        [ 0.0137,  0.0231, -0.0022,  ...,  0.0381,  0.0104,  0.0070],
        [-0.0049,  0.0149,  0.0059,  ..., -0.0567, -0.0041, -0.0198],
        [ 0.0155, -0.0219,  0.0326,  ..., -0.0111, -0.0211, -0.0008]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.3535, -3.6484,  1.7764,  ...,  0.7729, -7.3242,  0.4448]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 20:04:00 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When something is providing, it provides
When something is applying, it applies
When something is occurring, it occurs
When something is depending, it depends
When something is remaining, it remains
When something is representing, it represents
When something is performing, it performs
When something is creating, it
2024-07-31 20:04:00 root INFO     total operator prediction time: 1361.2023565769196 seconds
2024-07-31 20:04:00 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on noun - plural_reg
2024-07-31 20:04:00 root INFO     building operator noun - plural_reg
2024-07-31 20:04:00 root INFO     [order_1_approx] starting weight calculation for The plural form of hour is hours
The plural form of album is albums
The plural form of town is towns
The plural form of difference is differences
The plural form of development is developments
The plural form of population is populations
The plural form of player is players
The plural form of council is
2024-07-31 20:04:00 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-07-31 20:06:51 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0720,  0.1531, -0.1606,  ...,  0.0026, -0.2335,  0.1196],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.4727, -4.4609,  4.2930,  ..., -1.9365,  1.3184, -0.2754],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0367,  0.0019, -0.0145,  ...,  0.0023,  0.0039, -0.0083],
        [ 0.0149,  0.0072, -0.0113,  ...,  0.0283, -0.0125, -0.0104],
        [-0.0118, -0.0059,  0.0481,  ...,  0.0239, -0.0656,  0.0057],
        ...,
        [-0.0009,  0.0054,  0.0148,  ...,  0.0207, -0.0183, -0.0282],
        [-0.0155, -0.0057, -0.0198,  ..., -0.0197,  0.0031,  0.0080],
        [-0.0077,  0.0033,  0.0092,  ...,  0.0079,  0.0233,  0.0510]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.5059, -5.0156,  3.8906,  ..., -1.8652,  1.2764,  0.1350]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 20:06:52 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of hour is hours
The plural form of album is albums
The plural form of town is towns
The plural form of difference is differences
The plural form of development is developments
The plural form of population is populations
The plural form of player is players
The plural form of council is
2024-07-31 20:06:52 root INFO     [order_1_approx] starting weight calculation for The plural form of town is towns
The plural form of council is councils
The plural form of development is developments
The plural form of difference is differences
The plural form of population is populations
The plural form of hour is hours
The plural form of album is albums
The plural form of player is
2024-07-31 20:06:52 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-07-31 20:09:42 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1021, -0.1653,  0.0874,  ..., -0.0723, -0.2122,  0.0986],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.0918, -5.5547,  0.3682,  ..., -0.7178, -1.6221, -2.0020],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0668, -0.0330, -0.0063,  ...,  0.0032,  0.0117,  0.0172],
        [ 0.0086,  0.0690, -0.0351,  ...,  0.0519, -0.0130,  0.0054],
        [ 0.0228,  0.0310,  0.0382,  ..., -0.0113, -0.0271, -0.0032],
        ...,
        [ 0.0059,  0.0328,  0.0339,  ...,  0.0123,  0.0260, -0.0128],
        [ 0.0425,  0.0468, -0.0096,  ..., -0.0079,  0.0069,  0.0230],
        [ 0.0495,  0.0380, -0.0212,  ...,  0.0615,  0.0447, -0.0131]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.2976, -5.7227,  0.1222,  ..., -0.6494, -2.2227, -1.7324]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 20:09:43 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of town is towns
The plural form of council is councils
The plural form of development is developments
The plural form of difference is differences
The plural form of population is populations
The plural form of hour is hours
The plural form of album is albums
The plural form of player is
2024-07-31 20:09:43 root INFO     [order_1_approx] starting weight calculation for The plural form of hour is hours
The plural form of album is albums
The plural form of development is developments
The plural form of town is towns
The plural form of player is players
The plural form of council is councils
The plural form of population is populations
The plural form of difference is
2024-07-31 20:09:43 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-07-31 20:12:34 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0578, -0.2494,  0.0695,  ..., -0.0748, -0.0789,  0.2795],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.0332, -0.5352,  3.1660,  ..., -3.4766, -2.6797, -1.8438],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0276, -0.0654,  0.0066,  ..., -0.0138, -0.0317, -0.0181],
        [ 0.0147,  0.0423,  0.0075,  ...,  0.0249,  0.0223, -0.0098],
        [-0.0033, -0.0027,  0.0446,  ..., -0.0056, -0.0326,  0.0371],
        ...,
        [-0.0085,  0.0244,  0.0177,  ..., -0.0079, -0.0110, -0.0065],
        [ 0.0090,  0.0201, -0.0192,  ..., -0.0212,  0.0146, -0.0029],
        [ 0.0216,  0.0077,  0.0067,  ...,  0.0344,  0.0068,  0.0398]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.1035, -0.7725,  2.8672,  ..., -3.7031, -2.6738, -1.8193]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 20:12:35 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of hour is hours
The plural form of album is albums
The plural form of development is developments
The plural form of town is towns
The plural form of player is players
The plural form of council is councils
The plural form of population is populations
The plural form of difference is
2024-07-31 20:12:35 root INFO     [order_1_approx] starting weight calculation for The plural form of council is councils
The plural form of difference is differences
The plural form of hour is hours
The plural form of album is albums
The plural form of development is developments
The plural form of player is players
The plural form of town is towns
The plural form of population is
2024-07-31 20:12:35 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-07-31 20:15:27 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0747, -0.1719,  0.1068,  ..., -0.2141,  0.0466,  0.0134],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.2598, -3.4219,  0.9878,  ..., -1.6807, -3.2148, -2.2598],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0134, -0.0474,  0.0003,  ...,  0.0141, -0.0630, -0.0312],
        [ 0.0108,  0.0102,  0.0152,  ...,  0.0001,  0.0155,  0.0074],
        [ 0.0088,  0.0045,  0.0117,  ..., -0.0319, -0.0258,  0.0174],
        ...,
        [ 0.0024, -0.0059, -0.0022,  ..., -0.0164,  0.0117,  0.0020],
        [-0.0111,  0.0118, -0.0294,  ..., -0.0231,  0.0053, -0.0161],
        [ 0.0433, -0.0294,  0.0208,  ...,  0.0278,  0.0151,  0.0392]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.1445, -3.4023,  1.3789,  ..., -1.3809, -3.0859, -1.7715]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 20:15:28 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of council is councils
The plural form of difference is differences
The plural form of hour is hours
The plural form of album is albums
The plural form of development is developments
The plural form of player is players
The plural form of town is towns
The plural form of population is
2024-07-31 20:15:28 root INFO     [order_1_approx] starting weight calculation for The plural form of difference is differences
The plural form of player is players
The plural form of council is councils
The plural form of population is populations
The plural form of development is developments
The plural form of album is albums
The plural form of town is towns
The plural form of hour is
2024-07-31 20:15:28 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-07-31 20:18:20 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1948, -0.1573,  0.1069,  ...,  0.0184, -0.0582,  0.0785],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.0083, -2.6523,  1.0293,  ..., -2.1230,  0.7588, -2.3359],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0048, -0.0024, -0.0301,  ..., -0.0207, -0.0101, -0.0065],
        [ 0.0141,  0.0261, -0.0273,  ...,  0.0127, -0.0484, -0.0321],
        [ 0.0300, -0.0010,  0.0287,  ...,  0.0370,  0.0089,  0.0710],
        ...,
        [-0.0117,  0.0179, -0.0026,  ...,  0.0284,  0.0045,  0.0034],
        [ 0.0240, -0.0080, -0.0043,  ...,  0.0446,  0.0054, -0.0185],
        [ 0.0186, -0.0116,  0.0159,  ..., -0.0038, -0.0302,  0.0303]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.0364, -2.2422,  0.7437,  ..., -2.1426, -0.0820, -2.0898]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 20:18:21 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of difference is differences
The plural form of player is players
The plural form of council is councils
The plural form of population is populations
The plural form of development is developments
The plural form of album is albums
The plural form of town is towns
The plural form of hour is
2024-07-31 20:18:21 root INFO     [order_1_approx] starting weight calculation for The plural form of album is albums
The plural form of difference is differences
The plural form of development is developments
The plural form of player is players
The plural form of population is populations
The plural form of hour is hours
The plural form of council is councils
The plural form of town is
2024-07-31 20:18:21 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-07-31 20:21:13 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0851,  0.0891, -0.1340,  ..., -0.1090, -0.1209,  0.1423],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.2402, -3.9141,  0.1389,  ..., -0.1628,  0.3726, -1.3916],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0186, -0.0529, -0.0165,  ..., -0.0086, -0.0092,  0.0009],
        [ 0.0037,  0.0804, -0.0300,  ...,  0.0226,  0.0171, -0.0316],
        [ 0.0033, -0.0243,  0.0187,  ...,  0.0095, -0.0304,  0.0620],
        ...,
        [-0.0021,  0.0514,  0.0109,  ...,  0.0317, -0.0006, -0.0385],
        [ 0.0057, -0.0811,  0.0138,  ...,  0.0072, -0.0033,  0.0269],
        [-0.0147, -0.0337,  0.0195,  ...,  0.0076, -0.0034,  0.0266]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.8682, -4.1680,  0.3281,  ..., -0.4448,  0.7715, -1.3008]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 20:21:14 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of album is albums
The plural form of difference is differences
The plural form of development is developments
The plural form of player is players
The plural form of population is populations
The plural form of hour is hours
The plural form of council is councils
The plural form of town is
2024-07-31 20:21:15 root INFO     [order_1_approx] starting weight calculation for The plural form of development is developments
The plural form of hour is hours
The plural form of council is councils
The plural form of town is towns
The plural form of difference is differences
The plural form of population is populations
The plural form of player is players
The plural form of album is
2024-07-31 20:21:15 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-07-31 20:24:06 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0232,  0.0175, -0.1354,  ..., -0.0094, -0.2063,  0.1229],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.1382, -3.8398,  1.5820,  ...,  0.0197, -1.0293, -0.4736],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0452, -0.0214, -0.0347,  ..., -0.0343, -0.0152, -0.0120],
        [-0.0193,  0.0586, -0.0164,  ...,  0.0283,  0.0167,  0.0059],
        [-0.0254, -0.0038, -0.0085,  ..., -0.0196, -0.0489, -0.0158],
        ...,
        [-0.0291, -0.0082,  0.0266,  ..., -0.0129, -0.0061, -0.0080],
        [-0.0243, -0.0204, -0.0206,  ...,  0.0129,  0.0046, -0.0047],
        [ 0.0034,  0.0053,  0.0132,  ..., -0.0099,  0.0152,  0.0133]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.6680, -4.2383,  1.8945,  ..., -0.2510, -1.1348, -0.4526]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 20:24:07 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of development is developments
The plural form of hour is hours
The plural form of council is councils
The plural form of town is towns
The plural form of difference is differences
The plural form of population is populations
The plural form of player is players
The plural form of album is
2024-07-31 20:24:07 root INFO     [order_1_approx] starting weight calculation for The plural form of hour is hours
The plural form of player is players
The plural form of town is towns
The plural form of population is populations
The plural form of difference is differences
The plural form of album is albums
The plural form of council is councils
The plural form of development is
2024-07-31 20:24:07 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-07-31 20:26:59 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0171,  0.0042, -0.0750,  ..., -0.0764, -0.1580,  0.1267],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.6211, -2.1074,  0.6035,  ..., -2.3535, -2.8438, -2.4043],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0496, -0.0246,  0.0011,  ...,  0.0193, -0.0206, -0.0263],
        [-0.0145,  0.0401,  0.0018,  ..., -0.0028, -0.0218, -0.0360],
        [-0.0048, -0.0141, -0.0163,  ...,  0.0093, -0.0144,  0.0497],
        ...,
        [-0.0171, -0.0194, -0.0021,  ...,  0.0057, -0.0434, -0.0126],
        [ 0.0096,  0.0371, -0.0013,  ...,  0.0096,  0.0484,  0.0251],
        [ 0.0304,  0.0025, -0.0085,  ...,  0.0453,  0.0331,  0.0493]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.5371, -2.3750,  0.5391,  ..., -2.3516, -3.2324, -2.2520]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 20:26:59 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of hour is hours
The plural form of player is players
The plural form of town is towns
The plural form of population is populations
The plural form of difference is differences
The plural form of album is albums
The plural form of council is councils
The plural form of development is
2024-07-31 20:26:59 root INFO     total operator prediction time: 1379.808413028717 seconds
2024-07-31 20:26:59 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on verb_3pSg - Ved
2024-07-31 20:26:59 root INFO     building operator verb_3pSg - Ved
2024-07-31 20:27:00 root INFO     [order_1_approx] starting weight calculation for When he publishes something, something has been published
When he happens something, something has been happened
When he performs something, something has been performed
When he locates something, something has been located
When he intends something, something has been intended
When he continues something, something has been continued
When he applies something, something has been applied
When he requires something, something has been
2024-07-31 20:27:00 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-07-31 20:29:51 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1216,  0.1736, -0.1638,  ...,  0.0770, -0.2208, -0.1371],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.9922,  0.9697,  1.4102,  ..., -1.3555, -2.2070, -1.3330],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0034, -0.0320, -0.0074,  ...,  0.0039,  0.0070,  0.0274],
        [-0.0388,  0.0183,  0.0015,  ..., -0.0149, -0.0011, -0.0137],
        [ 0.0041,  0.0002, -0.0217,  ..., -0.0225, -0.0066, -0.0121],
        ...,
        [ 0.0164,  0.0087, -0.0151,  ...,  0.0395,  0.0151,  0.0265],
        [ 0.0155,  0.0119,  0.0074,  ..., -0.0445,  0.0210, -0.0253],
        [-0.0303,  0.0181,  0.0155,  ..., -0.0164,  0.0170, -0.0011]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.2939,  0.6904,  1.2441,  ..., -1.0752, -1.8340, -1.0293]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 20:29:52 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When he publishes something, something has been published
When he happens something, something has been happened
When he performs something, something has been performed
When he locates something, something has been located
When he intends something, something has been intended
When he continues something, something has been continued
When he applies something, something has been applied
When he requires something, something has been
2024-07-31 20:29:52 root INFO     [order_1_approx] starting weight calculation for When he locates something, something has been located
When he intends something, something has been intended
When he happens something, something has been happened
When he publishes something, something has been published
When he performs something, something has been performed
When he applies something, something has been applied
When he requires something, something has been required
When he continues something, something has been
2024-07-31 20:29:52 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-07-31 20:32:44 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0046, -0.0538, -0.1967,  ..., -0.0015, -0.3501,  0.1033],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.4004, -0.8135,  2.2656,  ...,  0.2615,  0.9976, -1.5234],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0006, -0.0130, -0.0112,  ..., -0.0103,  0.0110,  0.0229],
        [-0.0195,  0.0544,  0.0166,  ..., -0.0009, -0.0059, -0.0107],
        [ 0.0115, -0.0053, -0.0203,  ..., -0.0115, -0.0168, -0.0171],
        ...,
        [ 0.0013,  0.0233,  0.0298,  ...,  0.0048, -0.0124, -0.0025],
        [-0.0067,  0.0177, -0.0273,  ..., -0.0112, -0.0330, -0.0148],
        [-0.0118,  0.0092,  0.0108,  ..., -0.0145, -0.0148,  0.0021]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.1055, -0.0190,  1.7559,  ...,  0.6748,  0.9707, -1.8203]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 20:32:45 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When he locates something, something has been located
When he intends something, something has been intended
When he happens something, something has been happened
When he publishes something, something has been published
When he performs something, something has been performed
When he applies something, something has been applied
When he requires something, something has been required
When he continues something, something has been
2024-07-31 20:32:45 root INFO     [order_1_approx] starting weight calculation for When he performs something, something has been performed
When he intends something, something has been intended
When he requires something, something has been required
When he happens something, something has been happened
When he continues something, something has been continued
When he locates something, something has been located
When he publishes something, something has been published
When he applies something, something has been
2024-07-31 20:32:45 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-07-31 20:35:36 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0183,  0.1512, -0.0317,  ...,  0.2346, -0.3069,  0.0299],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.3936,  0.9243,  1.0586,  ..., -0.2278, -1.1445,  0.2363],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 1.5930e-02, -9.2621e-03,  2.1744e-02,  ..., -1.3618e-02,
          1.9501e-02,  3.3325e-02],
        [-1.1978e-02,  1.6632e-02,  3.0594e-03,  ..., -2.2888e-05,
         -2.0103e-03,  1.0361e-02],
        [ 4.0207e-03,  1.8875e-02, -6.8436e-03,  ..., -1.8234e-03,
         -1.7166e-02, -1.7233e-03],
        ...,
        [ 1.1692e-03,  2.9022e-02, -2.3994e-03,  ...,  2.2324e-02,
          7.9575e-03,  8.7662e-03],
        [ 3.0632e-03,  9.3842e-04, -6.1760e-03,  ..., -1.4015e-02,
          5.5885e-03, -1.0796e-02],
        [ 6.8130e-03,  6.1798e-04, -3.3169e-03,  ...,  9.3460e-03,
         -2.3788e-02, -1.1032e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.4172,  0.8457,  1.3613,  ..., -0.3232, -0.9409,  0.3550]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 20:35:37 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When he performs something, something has been performed
When he intends something, something has been intended
When he requires something, something has been required
When he happens something, something has been happened
When he continues something, something has been continued
When he locates something, something has been located
When he publishes something, something has been published
When he applies something, something has been
2024-07-31 20:35:37 root INFO     [order_1_approx] starting weight calculation for When he applies something, something has been applied
When he intends something, something has been intended
When he requires something, something has been required
When he continues something, something has been continued
When he performs something, something has been performed
When he happens something, something has been happened
When he publishes something, something has been published
When he locates something, something has been
2024-07-31 20:35:37 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-07-31 20:38:28 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0616,  0.3359, -0.3743,  ...,  0.1287, -0.2233, -0.0555],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.3857, -0.9678, -0.5498,  ..., -0.8291, -2.8242, -3.4492],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0219, -0.0278, -0.0032,  ..., -0.0052,  0.0109,  0.0218],
        [ 0.0122,  0.0196, -0.0105,  ...,  0.0149, -0.0050,  0.0041],
        [ 0.0257,  0.0051, -0.0172,  ...,  0.0108,  0.0221, -0.0263],
        ...,
        [ 0.0130,  0.0184,  0.0004,  ...,  0.0061,  0.0143,  0.0235],
        [ 0.0166,  0.0011, -0.0140,  ...,  0.0145,  0.0033, -0.0008],
        [-0.0101,  0.0417,  0.0065,  ...,  0.0377, -0.0011,  0.0206]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.3760, -1.0195, -0.5327,  ..., -0.3608, -2.8223, -3.2051]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 20:38:28 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When he applies something, something has been applied
When he intends something, something has been intended
When he requires something, something has been required
When he continues something, something has been continued
When he performs something, something has been performed
When he happens something, something has been happened
When he publishes something, something has been published
When he locates something, something has been
2024-07-31 20:38:29 root INFO     [order_1_approx] starting weight calculation for When he locates something, something has been located
When he continues something, something has been continued
When he performs something, something has been performed
When he happens something, something has been happened
When he intends something, something has been intended
When he requires something, something has been required
When he applies something, something has been applied
When he publishes something, something has been
2024-07-31 20:38:29 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-07-31 20:41:19 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1592,  0.2998, -0.1128,  ...,  0.1387, -0.1652,  0.1035],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.6836, -2.1406,  2.3477,  ..., -1.5615, -2.0312,  0.3262],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 7.5531e-04, -1.7395e-03,  1.5930e-02,  ..., -1.1475e-02,
          8.3923e-03, -1.7426e-02],
        [-2.1729e-02, -5.4932e-03,  9.9182e-05,  ..., -1.5778e-02,
          1.3145e-02, -1.9211e-02],
        [ 2.6169e-02,  2.4796e-03, -2.2644e-02,  ..., -1.6479e-02,
          4.9210e-03, -4.5242e-03],
        ...,
        [ 2.3880e-03,  2.7267e-02, -3.6736e-03,  ..., -2.0103e-03,
          1.7883e-02,  5.9204e-03],
        [ 1.0925e-02,  1.9360e-03, -1.6342e-02,  ..., -3.1616e-02,
          1.8738e-02,  1.8940e-03],
        [-3.8147e-05,  2.5742e-02,  7.7744e-03,  ...,  6.3400e-03,
          5.2643e-03, -1.5961e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.8594, -1.8457,  2.4219,  ..., -1.5840, -1.9678, -0.0166]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 20:41:20 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When he locates something, something has been located
When he continues something, something has been continued
When he performs something, something has been performed
When he happens something, something has been happened
When he intends something, something has been intended
When he requires something, something has been required
When he applies something, something has been applied
When he publishes something, something has been
2024-07-31 20:41:21 root INFO     [order_1_approx] starting weight calculation for When he applies something, something has been applied
When he happens something, something has been happened
When he locates something, something has been located
When he continues something, something has been continued
When he publishes something, something has been published
When he requires something, something has been required
When he performs something, something has been performed
When he intends something, something has been
2024-07-31 20:41:21 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-07-31 20:44:12 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0813,  0.3342, -0.3467,  ..., -0.0536, -0.1110,  0.0453],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.4238,  2.2930,  0.6792,  ..., -0.8760, -2.0000, -2.0430],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0032, -0.0449, -0.0034,  ..., -0.0200,  0.0028,  0.0229],
        [-0.0320,  0.0317, -0.0128,  ..., -0.0148,  0.0024, -0.0290],
        [ 0.0208, -0.0043,  0.0098,  ...,  0.0006,  0.0009, -0.0135],
        ...,
        [-0.0122,  0.0113,  0.0024,  ..., -0.0052,  0.0167,  0.0005],
        [ 0.0132,  0.0289, -0.0044,  ...,  0.0048, -0.0026, -0.0100],
        [-0.0199,  0.0326,  0.0228,  ...,  0.0053,  0.0097, -0.0178]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.2979,  2.2871,  0.7480,  ..., -0.4966, -1.7305, -2.1660]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 20:44:13 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When he applies something, something has been applied
When he happens something, something has been happened
When he locates something, something has been located
When he continues something, something has been continued
When he publishes something, something has been published
When he requires something, something has been required
When he performs something, something has been performed
When he intends something, something has been
2024-07-31 20:44:13 root INFO     [order_1_approx] starting weight calculation for When he continues something, something has been continued
When he happens something, something has been happened
When he requires something, something has been required
When he applies something, something has been applied
When he intends something, something has been intended
When he publishes something, something has been published
When he locates something, something has been located
When he performs something, something has been
2024-07-31 20:44:13 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-07-31 20:47:03 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1085,  0.3218, -0.0945,  ..., -0.0913, -0.2489, -0.0607],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.7051, -0.2412,  4.6484,  ..., -1.2988, -2.6914, -0.8037],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-3.2349e-03,  2.8610e-02,  4.9774e-02,  ..., -4.2603e-02,
          1.3062e-01, -4.6448e-02],
        [-3.0884e-02,  2.7679e-02, -6.3705e-04,  ..., -3.7308e-03,
          6.1890e-02, -4.2633e-02],
        [ 9.8038e-03, -4.5776e-05, -5.2460e-02,  ..., -1.0712e-02,
         -8.6517e-03,  4.8431e-02],
        ...,
        [-5.4016e-03,  4.1260e-02,  2.3880e-02,  ..., -9.9564e-03,
          1.0309e-01, -6.7017e-02],
        [ 2.9144e-03, -9.4299e-03, -3.4485e-02,  ..., -4.9561e-02,
         -4.5166e-02,  5.0171e-02],
        [-1.0689e-02,  2.3819e-02, -3.0899e-03,  ...,  3.0289e-02,
         -4.7058e-02,  2.3834e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.3867,  0.3564,  4.2891,  ..., -0.6128, -2.5938, -1.0273]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 20:47:04 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When he continues something, something has been continued
When he happens something, something has been happened
When he requires something, something has been required
When he applies something, something has been applied
When he intends something, something has been intended
When he publishes something, something has been published
When he locates something, something has been located
When he performs something, something has been
2024-07-31 20:47:04 root INFO     [order_1_approx] starting weight calculation for When he publishes something, something has been published
When he locates something, something has been located
When he intends something, something has been intended
When he performs something, something has been performed
When he requires something, something has been required
When he continues something, something has been continued
When he applies something, something has been applied
When he happens something, something has been
2024-07-31 20:47:05 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-07-31 20:49:53 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.3579, -0.0916, -0.1770,  ..., -0.0923, -0.2058, -0.2849],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.2871,  2.0762,  3.2539,  ...,  0.0649, -3.9609,  1.3584],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0021, -0.0284, -0.0024,  ..., -0.0337,  0.0003,  0.0106],
        [-0.0205,  0.0028, -0.0132,  ...,  0.0042, -0.0005, -0.0052],
        [ 0.0099,  0.0128,  0.0072,  ...,  0.0130,  0.0128, -0.0089],
        ...,
        [-0.0154, -0.0071, -0.0407,  ..., -0.0226,  0.0013,  0.0289],
        [ 0.0032,  0.0218, -0.0140,  ...,  0.0004,  0.0164, -0.0139],
        [-0.0226,  0.0406,  0.0310,  ...,  0.0035,  0.0402, -0.0029]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.1055,  1.8184,  3.4434,  ..., -0.1479, -3.7266,  1.1816]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 20:49:54 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When he publishes something, something has been published
When he locates something, something has been located
When he intends something, something has been intended
When he performs something, something has been performed
When he requires something, something has been required
When he continues something, something has been continued
When he applies something, something has been applied
When he happens something, something has been
2024-07-31 20:49:54 root INFO     total operator prediction time: 1374.5634980201721 seconds
2024-07-31 20:49:54 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on adj - superlative
2024-07-31 20:49:54 root INFO     building operator adj - superlative
2024-07-31 20:49:54 root INFO     [order_1_approx] starting weight calculation for If something is the most cruel, it is cruelest
If something is the most lucky, it is luckiest
If something is the most ugly, it is ugliest
If something is the most hardy, it is hardiest
If something is the most noisy, it is noisiest
If something is the most healthy, it is healthiest
If something is the most happy, it is happiest
If something is the most rude, it is
2024-07-31 20:49:54 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-07-31 20:52:39 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1379,  0.0983,  0.0419,  ..., -0.1654, -0.1545, -0.0502],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.9297, -4.7500,  0.5166,  ..., -2.6367, -1.5488, -1.5273],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0233, -0.0253,  0.0302,  ..., -0.0302, -0.0109, -0.0064],
        [ 0.0110, -0.0018,  0.0296,  ..., -0.0355,  0.0143,  0.0535],
        [-0.0206, -0.0020,  0.0430,  ...,  0.0406, -0.0292, -0.0051],
        ...,
        [ 0.0083, -0.0110,  0.0217,  ...,  0.0058, -0.0086,  0.0168],
        [-0.0288, -0.0101,  0.0172,  ..., -0.0274,  0.0059, -0.0510],
        [-0.0069, -0.0203,  0.0174,  ..., -0.0250,  0.0192, -0.0346]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.4805, -4.7930,  0.1338,  ..., -2.5234, -1.3311, -1.2432]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 20:52:40 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is the most cruel, it is cruelest
If something is the most lucky, it is luckiest
If something is the most ugly, it is ugliest
If something is the most hardy, it is hardiest
If something is the most noisy, it is noisiest
If something is the most healthy, it is healthiest
If something is the most happy, it is happiest
If something is the most rude, it is
2024-07-31 20:52:40 root INFO     [order_1_approx] starting weight calculation for If something is the most happy, it is happiest
If something is the most ugly, it is ugliest
If something is the most lucky, it is luckiest
If something is the most noisy, it is noisiest
If something is the most healthy, it is healthiest
If something is the most rude, it is rudest
If something is the most cruel, it is cruelest
If something is the most hardy, it is
2024-07-31 20:52:41 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-07-31 20:55:29 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0659, -0.0301, -0.2126,  ..., -0.2233,  0.1063,  0.0377],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.1416, -7.4297, -0.6782,  ..., -2.9570, -3.2715, -2.4062],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0164, -0.0209,  0.0455,  ..., -0.0095,  0.0013,  0.0089],
        [-0.0302,  0.0020, -0.0050,  ..., -0.0201,  0.0418, -0.0013],
        [-0.0125, -0.0260,  0.0480,  ...,  0.0084, -0.0147, -0.0083],
        ...,
        [ 0.0023, -0.0095, -0.0294,  ...,  0.0022,  0.0034, -0.0162],
        [ 0.0062,  0.0070,  0.0028,  ...,  0.0051,  0.0314, -0.0432],
        [-0.0043,  0.0098, -0.0056,  ...,  0.0012,  0.0146,  0.0139]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.9146, -6.8711, -0.4858,  ..., -2.7168, -2.8066, -1.9141]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 20:55:30 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is the most happy, it is happiest
If something is the most ugly, it is ugliest
If something is the most lucky, it is luckiest
If something is the most noisy, it is noisiest
If something is the most healthy, it is healthiest
If something is the most rude, it is rudest
If something is the most cruel, it is cruelest
If something is the most hardy, it is
2024-07-31 20:55:30 root INFO     [order_1_approx] starting weight calculation for If something is the most ugly, it is ugliest
If something is the most happy, it is happiest
If something is the most lucky, it is luckiest
If something is the most hardy, it is hardiest
If something is the most healthy, it is healthiest
If something is the most noisy, it is noisiest
If something is the most rude, it is rudest
If something is the most cruel, it is
2024-07-31 20:55:30 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-07-31 20:58:15 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3110,  0.1511,  0.1971,  ..., -0.1720, -0.2148,  0.0658],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.1377, -3.6094, -1.8252,  ..., -1.3096,  0.2402,  0.2158],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0034, -0.0042,  0.0205,  ..., -0.0058,  0.0128,  0.0460],
        [ 0.0187, -0.0089,  0.0073,  ..., -0.0093,  0.0025,  0.0179],
        [-0.0060,  0.0015,  0.0323,  ...,  0.0059, -0.0122, -0.0094],
        ...,
        [ 0.0102, -0.0197,  0.0147,  ...,  0.0196,  0.0009,  0.0066],
        [ 0.0124, -0.0091,  0.0145,  ..., -0.0265,  0.0053, -0.0313],
        [ 0.0077,  0.0105, -0.0044,  ...,  0.0191, -0.0009, -0.0129]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.4653, -3.1094, -1.9082,  ..., -0.8755,  0.0413,  0.3625]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 20:58:16 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is the most ugly, it is ugliest
If something is the most happy, it is happiest
If something is the most lucky, it is luckiest
If something is the most hardy, it is hardiest
If something is the most healthy, it is healthiest
If something is the most noisy, it is noisiest
If something is the most rude, it is rudest
If something is the most cruel, it is
2024-07-31 20:58:16 root INFO     [order_1_approx] starting weight calculation for If something is the most healthy, it is healthiest
If something is the most ugly, it is ugliest
If something is the most rude, it is rudest
If something is the most lucky, it is luckiest
If something is the most hardy, it is hardiest
If something is the most noisy, it is noisiest
If something is the most cruel, it is cruelest
If something is the most happy, it is
2024-07-31 20:58:17 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-07-31 21:01:03 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1252,  0.1478, -0.1169,  ..., -0.2944, -0.2529, -0.0230],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.8320, -3.7930,  0.0439,  ..., -0.0898, -2.0176, -0.9482],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0021, -0.0161,  0.0195,  ..., -0.0096,  0.0222,  0.0242],
        [-0.0020,  0.0208,  0.0068,  ...,  0.0022,  0.0318, -0.0046],
        [ 0.0021, -0.0165,  0.0157,  ...,  0.0251, -0.0187,  0.0045],
        ...,
        [ 0.0110, -0.0261,  0.0050,  ...,  0.0007,  0.0100,  0.0009],
        [ 0.0066,  0.0078,  0.0085,  ..., -0.0003,  0.0196, -0.0246],
        [ 0.0032, -0.0080,  0.0211,  ...,  0.0043,  0.0122, -0.0029]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.3801, -3.7168, -0.1299,  ..., -0.0400, -1.8750, -0.8618]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 21:01:04 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is the most healthy, it is healthiest
If something is the most ugly, it is ugliest
If something is the most rude, it is rudest
If something is the most lucky, it is luckiest
If something is the most hardy, it is hardiest
If something is the most noisy, it is noisiest
If something is the most cruel, it is cruelest
If something is the most happy, it is
2024-07-31 21:01:04 root INFO     [order_1_approx] starting weight calculation for If something is the most lucky, it is luckiest
If something is the most hardy, it is hardiest
If something is the most rude, it is rudest
If something is the most noisy, it is noisiest
If something is the most cruel, it is cruelest
If something is the most healthy, it is healthiest
If something is the most happy, it is happiest
If something is the most ugly, it is
2024-07-31 21:01:04 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-07-31 21:03:49 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0015,  0.2681,  0.0774,  ..., -0.0989,  0.1699, -0.0782],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.3438, -4.2383, -1.3936,  ..., -1.5732, -1.7002,  0.3887],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0103, -0.0189,  0.0309,  ..., -0.0395, -0.0355,  0.0256],
        [-0.0121, -0.0240,  0.0080,  ..., -0.0113,  0.0266, -0.0039],
        [ 0.0108, -0.0003,  0.0148,  ...,  0.0206, -0.0281, -0.0144],
        ...,
        [ 0.0235, -0.0170,  0.0103,  ...,  0.0262,  0.0132,  0.0018],
        [-0.0247, -0.0124, -0.0220,  ...,  0.0185,  0.0135, -0.0373],
        [-0.0148,  0.0217, -0.0074,  ..., -0.0043, -0.0052, -0.0204]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.1865, -4.2305, -1.3398,  ..., -1.9248, -1.5010,  0.6562]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 21:03:50 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is the most lucky, it is luckiest
If something is the most hardy, it is hardiest
If something is the most rude, it is rudest
If something is the most noisy, it is noisiest
If something is the most cruel, it is cruelest
If something is the most healthy, it is healthiest
If something is the most happy, it is happiest
If something is the most ugly, it is
2024-07-31 21:03:50 root INFO     [order_1_approx] starting weight calculation for If something is the most happy, it is happiest
If something is the most noisy, it is noisiest
If something is the most hardy, it is hardiest
If something is the most lucky, it is luckiest
If something is the most rude, it is rudest
If something is the most cruel, it is cruelest
If something is the most ugly, it is ugliest
If something is the most healthy, it is
2024-07-31 21:03:50 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-07-31 21:06:35 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0006,  0.0715, -0.0735,  ..., -0.3223, -0.1733, -0.2035],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.6582, -7.0000, -0.3796,  ..., -0.7695, -1.9277, -1.8848],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0056, -0.0044,  0.0175,  ..., -0.0111, -0.0083,  0.0045],
        [-0.0253,  0.0044,  0.0065,  ..., -0.0205,  0.0191, -0.0090],
        [ 0.0018, -0.0090,  0.0113,  ...,  0.0277,  0.0008,  0.0108],
        ...,
        [ 0.0200, -0.0150,  0.0121,  ...,  0.0139, -0.0078,  0.0149],
        [ 0.0003,  0.0062, -0.0035,  ...,  0.0190,  0.0135, -0.0188],
        [-0.0116, -0.0081, -0.0031,  ...,  0.0034, -0.0008, -0.0071]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.5352, -6.7578, -0.2441,  ..., -1.0127, -1.7979, -1.7383]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 21:06:36 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is the most happy, it is happiest
If something is the most noisy, it is noisiest
If something is the most hardy, it is hardiest
If something is the most lucky, it is luckiest
If something is the most rude, it is rudest
If something is the most cruel, it is cruelest
If something is the most ugly, it is ugliest
If something is the most healthy, it is
2024-07-31 21:06:36 root INFO     [order_1_approx] starting weight calculation for If something is the most cruel, it is cruelest
If something is the most lucky, it is luckiest
If something is the most hardy, it is hardiest
If something is the most rude, it is rudest
If something is the most healthy, it is healthiest
If something is the most happy, it is happiest
If something is the most ugly, it is ugliest
If something is the most noisy, it is
2024-07-31 21:06:36 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-07-31 21:09:22 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0920,  0.0625, -0.0247,  ...,  0.1216, -0.3091,  0.0150],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-4.1523, -4.2422, -0.7627,  ..., -1.7031, -1.6250,  0.3589],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0014, -0.0174,  0.0372,  ..., -0.0018, -0.0018,  0.0164],
        [-0.0029,  0.0197,  0.0135,  ..., -0.0155, -0.0044,  0.0202],
        [-0.0097, -0.0075,  0.0162,  ...,  0.0042, -0.0126, -0.0026],
        ...,
        [ 0.0158, -0.0182,  0.0283,  ...,  0.0213, -0.0115,  0.0244],
        [ 0.0154,  0.0008, -0.0051,  ..., -0.0008,  0.0130, -0.0271],
        [-0.0074,  0.0216, -0.0037,  ...,  0.0041, -0.0011, -0.0176]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-3.9121, -4.2148, -0.9424,  ..., -1.7139, -1.4482,  0.3474]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 21:09:23 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is the most cruel, it is cruelest
If something is the most lucky, it is luckiest
If something is the most hardy, it is hardiest
If something is the most rude, it is rudest
If something is the most healthy, it is healthiest
If something is the most happy, it is happiest
If something is the most ugly, it is ugliest
If something is the most noisy, it is
2024-07-31 21:09:23 root INFO     [order_1_approx] starting weight calculation for If something is the most noisy, it is noisiest
If something is the most hardy, it is hardiest
If something is the most ugly, it is ugliest
If something is the most healthy, it is healthiest
If something is the most cruel, it is cruelest
If something is the most happy, it is happiest
If something is the most rude, it is rudest
If something is the most lucky, it is
2024-07-31 21:09:23 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-07-31 21:12:08 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1240,  0.1638, -0.0693,  ..., -0.2183, -0.1658, -0.1047],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.9072, -3.2148, -3.0469,  ..., -0.6445, -0.5576, -2.0137],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0103, -0.0021,  0.0227,  ..., -0.0104, -0.0128,  0.0019],
        [-0.0030,  0.0083,  0.0097,  ..., -0.0140,  0.0015, -0.0025],
        [ 0.0114, -0.0024,  0.0075,  ...,  0.0224, -0.0194,  0.0036],
        ...,
        [ 0.0126, -0.0177,  0.0199,  ...,  0.0041, -0.0059,  0.0181],
        [ 0.0014,  0.0179,  0.0070,  ...,  0.0220,  0.0092,  0.0008],
        [-0.0034,  0.0049,  0.0138,  ..., -0.0105,  0.0049, -0.0075]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.8975, -3.1328, -2.8828,  ..., -0.7671, -0.7344, -2.0527]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 21:12:09 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is the most noisy, it is noisiest
If something is the most hardy, it is hardiest
If something is the most ugly, it is ugliest
If something is the most healthy, it is healthiest
If something is the most cruel, it is cruelest
If something is the most happy, it is happiest
If something is the most rude, it is rudest
If something is the most lucky, it is
2024-07-31 21:12:09 root INFO     total operator prediction time: 1335.0132009983063 seconds
2024-07-31 21:12:09 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on verb+er_irreg
2024-07-31 21:12:09 root INFO     building operator verb+er_irreg
2024-07-31 21:12:09 root INFO     [order_1_approx] starting weight calculation for If you borrow something, you are a borrower
If you examine something, you are a examiner
If you organize something, you are a organizer
If you subscribe something, you are a subscriber
If you discover something, you are a discoverer
If you eat something, you are a eater
If you defend something, you are a defender
If you choreograph something, you are a
2024-07-31 21:12:09 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-07-31 21:14:49 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0894,  0.2273, -0.1489,  ..., -0.0311, -0.4502, -0.0500],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.6938, -3.7578,  2.3086,  ..., -1.7559, -3.5391, -1.8008],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0209, -0.0133, -0.0006,  ...,  0.0157,  0.0228, -0.0027],
        [-0.0209,  0.0222, -0.0183,  ...,  0.0233,  0.0147, -0.0017],
        [-0.0246, -0.0097, -0.0097,  ..., -0.0147,  0.0150, -0.0012],
        ...,
        [ 0.0347,  0.0094, -0.0022,  ..., -0.0093, -0.0004, -0.0247],
        [-0.0120,  0.0045, -0.0165,  ..., -0.0303,  0.0017,  0.0019],
        [-0.0046,  0.0083,  0.0164,  ...,  0.0133, -0.0106, -0.0011]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.6670, -3.2793,  2.5234,  ..., -1.9160, -3.0840, -1.2578]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 21:14:50 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you borrow something, you are a borrower
If you examine something, you are a examiner
If you organize something, you are a organizer
If you subscribe something, you are a subscriber
If you discover something, you are a discoverer
If you eat something, you are a eater
If you defend something, you are a defender
If you choreograph something, you are a
2024-07-31 21:14:50 root INFO     [order_1_approx] starting weight calculation for If you discover something, you are a discoverer
If you organize something, you are a organizer
If you choreograph something, you are a choreographer
If you subscribe something, you are a subscriber
If you defend something, you are a defender
If you examine something, you are a examiner
If you borrow something, you are a borrower
If you eat something, you are a
2024-07-31 21:14:50 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-07-31 21:17:36 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1997,  0.0337, -0.1986,  ...,  0.0261, -0.2240,  0.0227],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.5215, -0.3594, -0.0158,  ...,  0.4062, -6.6523, -3.7852],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0146, -0.0038,  0.0055,  ..., -0.0019,  0.0152,  0.0097],
        [-0.0160,  0.0212,  0.0016,  ..., -0.0008,  0.0096, -0.0323],
        [ 0.0230,  0.0070,  0.0213,  ...,  0.0095,  0.0016,  0.0210],
        ...,
        [ 0.0271, -0.0149, -0.0071,  ...,  0.0200,  0.0190,  0.0009],
        [-0.0011, -0.0069, -0.0035,  ..., -0.0281, -0.0133, -0.0097],
        [ 0.0019,  0.0066,  0.0228,  ...,  0.0028, -0.0117,  0.0112]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.8164, -0.5005,  0.0961,  ...,  0.4719, -6.5508, -3.7988]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 21:17:37 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you discover something, you are a discoverer
If you organize something, you are a organizer
If you choreograph something, you are a choreographer
If you subscribe something, you are a subscriber
If you defend something, you are a defender
If you examine something, you are a examiner
If you borrow something, you are a borrower
If you eat something, you are a
2024-07-31 21:17:38 root INFO     [order_1_approx] starting weight calculation for If you borrow something, you are a borrower
If you organize something, you are a organizer
If you subscribe something, you are a subscriber
If you eat something, you are a eater
If you discover something, you are a discoverer
If you defend something, you are a defender
If you choreograph something, you are a choreographer
If you examine something, you are a
2024-07-31 21:17:38 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-07-31 21:20:23 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1049,  0.0767, -0.1080,  ..., -0.1425, -0.0419, -0.1812],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.5430, -1.3516,  0.7930,  ..., -2.4102, -3.3750, -5.1484],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0297, -0.0181, -0.0088,  ...,  0.0152,  0.0049, -0.0331],
        [-0.0410,  0.0176,  0.0247,  ..., -0.0289,  0.0103, -0.0035],
        [-0.0012, -0.0062, -0.0001,  ...,  0.0181,  0.0503, -0.0100],
        ...,
        [-0.0016,  0.0292,  0.0127,  ...,  0.0201,  0.0156,  0.0192],
        [-0.0001,  0.0010, -0.0174,  ..., -0.0248, -0.0344,  0.0212],
        [ 0.0085,  0.0063,  0.0025,  ...,  0.0210, -0.0318, -0.0139]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.7324, -0.9336,  0.4004,  ..., -2.4082, -3.5840, -4.8281]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 21:20:24 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you borrow something, you are a borrower
If you organize something, you are a organizer
If you subscribe something, you are a subscriber
If you eat something, you are a eater
If you discover something, you are a discoverer
If you defend something, you are a defender
If you choreograph something, you are a choreographer
If you examine something, you are a
2024-07-31 21:20:24 root INFO     [order_1_approx] starting weight calculation for If you organize something, you are a organizer
If you defend something, you are a defender
If you discover something, you are a discoverer
If you eat something, you are a eater
If you choreograph something, you are a choreographer
If you subscribe something, you are a subscriber
If you examine something, you are a examiner
If you borrow something, you are a
2024-07-31 21:20:24 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-07-31 21:23:07 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0003,  0.1130,  0.0104,  ..., -0.1382, -0.1024, -0.1299],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.6006, -1.1406, -0.1562,  ..., -0.7627, -1.2852, -4.5234],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0010, -0.0077,  0.0021,  ...,  0.0149,  0.0100,  0.0001],
        [-0.0540,  0.0406,  0.0086,  ...,  0.0004,  0.0050,  0.0079],
        [ 0.0077, -0.0112,  0.0293,  ..., -0.0125, -0.0099,  0.0203],
        ...,
        [ 0.0351, -0.0098, -0.0029,  ...,  0.0247,  0.0437, -0.0043],
        [ 0.0200, -0.0296, -0.0025,  ..., -0.0195, -0.0189, -0.0094],
        [-0.0190,  0.0080,  0.0312,  ..., -0.0350,  0.0240, -0.0279]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.2686, -1.0869, -0.7324,  ..., -1.0615, -1.2217, -4.7070]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 21:23:08 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you organize something, you are a organizer
If you defend something, you are a defender
If you discover something, you are a discoverer
If you eat something, you are a eater
If you choreograph something, you are a choreographer
If you subscribe something, you are a subscriber
If you examine something, you are a examiner
If you borrow something, you are a
2024-07-31 21:23:08 root INFO     [order_1_approx] starting weight calculation for If you examine something, you are a examiner
If you defend something, you are a defender
If you choreograph something, you are a choreographer
If you subscribe something, you are a subscriber
If you eat something, you are a eater
If you organize something, you are a organizer
If you borrow something, you are a borrower
If you discover something, you are a
2024-07-31 21:23:08 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-07-31 21:25:53 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0659,  0.1820, -0.1575,  ..., -0.2235, -0.3591, -0.1416],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.3184, -3.5898,  2.3594,  ..., -0.1045, -4.2812, -1.2520],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0054, -0.0145,  0.0018,  ..., -0.0099,  0.0186, -0.0002],
        [-0.0493,  0.0363, -0.0070,  ...,  0.0045,  0.0095,  0.0232],
        [ 0.0092,  0.0028, -0.0105,  ...,  0.0160,  0.0016, -0.0512],
        ...,
        [ 0.0412, -0.0225,  0.0504,  ..., -0.0017, -0.0159,  0.0037],
        [ 0.0178,  0.0164, -0.0241,  ..., -0.0044,  0.0294, -0.0083],
        [ 0.0298,  0.0352,  0.0063,  ...,  0.0241, -0.0345,  0.0048]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.0957, -3.7656,  2.2695,  ..., -0.0570, -4.2188, -1.3906]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 21:25:54 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you examine something, you are a examiner
If you defend something, you are a defender
If you choreograph something, you are a choreographer
If you subscribe something, you are a subscriber
If you eat something, you are a eater
If you organize something, you are a organizer
If you borrow something, you are a borrower
If you discover something, you are a
2024-07-31 21:25:55 root INFO     [order_1_approx] starting weight calculation for If you subscribe something, you are a subscriber
If you choreograph something, you are a choreographer
If you examine something, you are a examiner
If you eat something, you are a eater
If you defend something, you are a defender
If you borrow something, you are a borrower
If you discover something, you are a discoverer
If you organize something, you are a
2024-07-31 21:25:55 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-07-31 21:28:41 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1141,  0.1808, -0.1559,  ..., -0.1281, -0.1638, -0.0309],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.5527, -2.4648,  1.2422,  ...,  0.5459, -3.0430, -6.0469],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 2.5803e-02,  3.5400e-03,  1.3641e-02,  ..., -1.5686e-02,
         -3.3722e-03,  7.9250e-04],
        [-2.8687e-02,  1.1383e-02, -1.5610e-02,  ...,  1.8021e-02,
         -1.0063e-02,  1.6052e-02],
        [ 1.3199e-02,  5.3406e-04,  5.5885e-03,  ...,  5.6953e-03,
         -3.1242e-03, -1.3535e-02],
        ...,
        [ 3.7720e-02,  1.2772e-02,  4.4327e-03,  ...,  7.9575e-03,
         -1.8127e-02,  2.9602e-03],
        [-1.6724e-02,  6.4774e-03, -6.0806e-03,  ...,  3.5286e-05,
          1.7273e-02, -9.1858e-03],
        [ 4.9858e-03,  1.3145e-02, -3.1433e-03,  ...,  1.3336e-02,
         -1.6556e-03,  2.0111e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.5688, -2.1387,  1.1230,  ...,  0.4038, -2.8867, -5.8828]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 21:28:42 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you subscribe something, you are a subscriber
If you choreograph something, you are a choreographer
If you examine something, you are a examiner
If you eat something, you are a eater
If you defend something, you are a defender
If you borrow something, you are a borrower
If you discover something, you are a discoverer
If you organize something, you are a
2024-07-31 21:28:42 root INFO     [order_1_approx] starting weight calculation for If you choreograph something, you are a choreographer
If you examine something, you are a examiner
If you discover something, you are a discoverer
If you borrow something, you are a borrower
If you subscribe something, you are a subscriber
If you eat something, you are a eater
If you organize something, you are a organizer
If you defend something, you are a
2024-07-31 21:28:42 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-07-31 21:31:29 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1224,  0.0729, -0.1366,  ..., -0.0165, -0.0733,  0.0496],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.2832, -5.1719,  3.1035,  ..., -3.2812, -2.6289, -3.5332],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0281,  0.0073,  0.0203,  ..., -0.0029, -0.0152, -0.0463],
        [-0.0307, -0.0026, -0.0208,  ..., -0.0150,  0.0169,  0.0121],
        [ 0.0137, -0.0091, -0.0006,  ...,  0.0203, -0.0205, -0.0128],
        ...,
        [ 0.0353, -0.0046,  0.0076,  ..., -0.0034,  0.0371, -0.0017],
        [-0.0085, -0.0131, -0.0025,  ...,  0.0151, -0.0020,  0.0125],
        [ 0.0126,  0.0207, -0.0052,  ..., -0.0172, -0.0267, -0.0006]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.3965, -5.2734,  2.9082,  ..., -3.0859, -2.7852, -3.8281]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 21:31:30 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you choreograph something, you are a choreographer
If you examine something, you are a examiner
If you discover something, you are a discoverer
If you borrow something, you are a borrower
If you subscribe something, you are a subscriber
If you eat something, you are a eater
If you organize something, you are a organizer
If you defend something, you are a
2024-07-31 21:31:30 root INFO     [order_1_approx] starting weight calculation for If you defend something, you are a defender
If you discover something, you are a discoverer
If you eat something, you are a eater
If you choreograph something, you are a choreographer
If you examine something, you are a examiner
If you organize something, you are a organizer
If you borrow something, you are a borrower
If you subscribe something, you are a
2024-07-31 21:31:30 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-07-31 21:34:17 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0113,  0.0641, -0.1482,  ...,  0.0751, -0.1271,  0.0513],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.3457, -1.8594,  1.1602,  ...,  0.7842, -1.3506, -4.9023],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0370,  0.0129,  0.0177,  ...,  0.0093,  0.0098, -0.0105],
        [-0.0494,  0.0215,  0.0077,  ..., -0.0057, -0.0243,  0.0009],
        [ 0.0063,  0.0051,  0.0006,  ..., -0.0156, -0.0358, -0.0255],
        ...,
        [ 0.0262,  0.0348,  0.0040,  ...,  0.0104,  0.0054, -0.0164],
        [ 0.0150, -0.0389,  0.0236,  ..., -0.0209, -0.0259, -0.0110],
        [ 0.0034,  0.0006,  0.0149,  ..., -0.0238, -0.0284,  0.0341]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.7031, -1.9854,  1.8086,  ...,  0.9922, -1.4297, -4.9570]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 21:34:18 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you defend something, you are a defender
If you discover something, you are a discoverer
If you eat something, you are a eater
If you choreograph something, you are a choreographer
If you examine something, you are a examiner
If you organize something, you are a organizer
If you borrow something, you are a borrower
If you subscribe something, you are a
2024-07-31 21:34:18 root INFO     total operator prediction time: 1328.7344913482666 seconds
2024-07-31 21:34:18 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on over+adj_reg
2024-07-31 21:34:18 root INFO     building operator over+adj_reg
2024-07-31 21:34:18 root INFO     [order_1_approx] starting weight calculation for If something is too ambitious, it is overambitious
If something is too written, it is overwritten
If something is too loaded, it is overloaded
If something is too laid, it is overlaid
If something is too powered, it is overpowered
If something is too grown, it is overgrown
If something is too zealous, it is overzealous
If something is too inflated, it is
2024-07-31 21:34:18 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-07-31 21:37:07 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1071, -0.3057, -0.1152,  ...,  0.2128, -0.3533,  0.1547],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.8652, -2.8320,  1.1719,  ..., -0.3384, -0.3291, -2.6387],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0700, -0.0019,  0.0164,  ..., -0.0138, -0.0249, -0.0127],
        [-0.0209,  0.0166, -0.0109,  ...,  0.0025,  0.0255,  0.0155],
        [ 0.0067,  0.0164,  0.0230,  ...,  0.0020, -0.0096, -0.0381],
        ...,
        [ 0.0139,  0.0432, -0.0204,  ...,  0.0408, -0.0127,  0.0159],
        [ 0.0035,  0.0147, -0.0097,  ..., -0.0063,  0.0229, -0.0191],
        [-0.0517,  0.0188,  0.0323,  ..., -0.0040,  0.0232,  0.0130]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.0723, -3.0234,  0.6846,  ..., -0.4028, -0.3594, -3.0684]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 21:37:08 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is too ambitious, it is overambitious
If something is too written, it is overwritten
If something is too loaded, it is overloaded
If something is too laid, it is overlaid
If something is too powered, it is overpowered
If something is too grown, it is overgrown
If something is too zealous, it is overzealous
If something is too inflated, it is
2024-07-31 21:37:08 root INFO     [order_1_approx] starting weight calculation for If something is too loaded, it is overloaded
If something is too ambitious, it is overambitious
If something is too powered, it is overpowered
If something is too inflated, it is overinflated
If something is too zealous, it is overzealous
If something is too written, it is overwritten
If something is too grown, it is overgrown
If something is too laid, it is
2024-07-31 21:37:08 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-07-31 21:39:55 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0544,  0.2639, -0.1261,  ..., -0.1340, -0.3638,  0.0864],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.2246, -3.0215, -0.1846,  ...,  1.4551, -1.7832, -2.8086],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0661,  0.0016, -0.0150,  ...,  0.0005, -0.0427, -0.0025],
        [-0.0089,  0.0649,  0.0136,  ...,  0.0233, -0.0056,  0.0166],
        [ 0.0090, -0.0186,  0.0580,  ..., -0.0101, -0.0405,  0.0144],
        ...,
        [ 0.0204,  0.0583,  0.0193,  ...,  0.0458, -0.0169, -0.0144],
        [ 0.0002, -0.0152,  0.0104,  ..., -0.0469,  0.0491, -0.0134],
        [-0.0234,  0.0145, -0.0074,  ...,  0.0299,  0.0287,  0.0039]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.2510, -3.0996, -0.2078,  ...,  1.8086, -1.5498, -3.2832]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 21:39:56 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is too loaded, it is overloaded
If something is too ambitious, it is overambitious
If something is too powered, it is overpowered
If something is too inflated, it is overinflated
If something is too zealous, it is overzealous
If something is too written, it is overwritten
If something is too grown, it is overgrown
If something is too laid, it is
2024-07-31 21:39:56 root INFO     [order_1_approx] starting weight calculation for If something is too inflated, it is overinflated
If something is too ambitious, it is overambitious
If something is too zealous, it is overzealous
If something is too laid, it is overlaid
If something is too loaded, it is overloaded
If something is too grown, it is overgrown
If something is too powered, it is overpowered
If something is too written, it is
2024-07-31 21:39:56 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-07-31 21:42:45 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1541,  0.0812, -0.1088,  ..., -0.2510, -0.2351, -0.0616],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.7539, -3.9277,  1.6182,  ..., -0.2886, -1.7305, -3.3672],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 3.6377e-02, -4.9591e-05,  1.0361e-02,  ..., -5.7411e-04,
         -1.3596e-02,  3.4668e-02],
        [-1.7059e-02,  3.9642e-02,  2.7161e-03,  ..., -1.1261e-02,
          1.3199e-02,  1.1261e-02],
        [-1.8265e-02, -1.8570e-02,  2.2247e-02,  ...,  4.9194e-02,
          4.7699e-02,  8.3771e-03],
        ...,
        [ 4.4518e-03,  9.4528e-03,  5.4932e-04,  ...,  2.2079e-02,
         -6.4774e-03, -1.1253e-02],
        [-7.4310e-03,  3.3447e-02,  2.0332e-03,  ..., -2.4933e-02,
          2.4490e-03, -1.4908e-02],
        [ 1.3397e-02, -1.8372e-02,  1.4038e-02,  ...,  3.5645e-02,
          2.1362e-02,  1.9928e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.4785, -3.9941,  1.7266,  ..., -0.1589, -1.6807, -3.6211]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 21:42:46 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is too inflated, it is overinflated
If something is too ambitious, it is overambitious
If something is too zealous, it is overzealous
If something is too laid, it is overlaid
If something is too loaded, it is overloaded
If something is too grown, it is overgrown
If something is too powered, it is overpowered
If something is too written, it is
2024-07-31 21:42:46 root INFO     [order_1_approx] starting weight calculation for If something is too laid, it is overlaid
If something is too written, it is overwritten
If something is too inflated, it is overinflated
If something is too zealous, it is overzealous
If something is too grown, it is overgrown
If something is too loaded, it is overloaded
If something is too ambitious, it is overambitious
If something is too powered, it is
2024-07-31 21:42:46 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-07-31 21:45:24 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0131, -0.0657, -0.2778,  ..., -0.0557, -0.0786,  0.0136],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.0186, -4.0469,  1.3115,  ...,  0.4666, -2.9219, -2.5703],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0317, -0.0050, -0.0029,  ...,  0.0067,  0.0003, -0.0094],
        [-0.0135,  0.0111,  0.0056,  ...,  0.0103, -0.0052,  0.0301],
        [ 0.0223,  0.0060,  0.0235,  ...,  0.0155, -0.0017,  0.0126],
        ...,
        [ 0.0127,  0.0162, -0.0236,  ...,  0.0263, -0.0053, -0.0163],
        [-0.0041,  0.0112, -0.0099,  ...,  0.0011, -0.0006, -0.0081],
        [-0.0249, -0.0182,  0.0203,  ..., -0.0050,  0.0064,  0.0350]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.9077, -4.1133,  1.1816,  ...,  0.5918, -2.8750, -2.5273]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 21:45:25 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is too laid, it is overlaid
If something is too written, it is overwritten
If something is too inflated, it is overinflated
If something is too zealous, it is overzealous
If something is too grown, it is overgrown
If something is too loaded, it is overloaded
If something is too ambitious, it is overambitious
If something is too powered, it is
2024-07-31 21:45:25 root INFO     [order_1_approx] starting weight calculation for If something is too zealous, it is overzealous
If something is too powered, it is overpowered
If something is too inflated, it is overinflated
If something is too grown, it is overgrown
If something is too written, it is overwritten
If something is too loaded, it is overloaded
If something is too laid, it is overlaid
If something is too ambitious, it is
2024-07-31 21:45:25 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-07-31 21:48:13 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0482,  0.0357, -0.2859,  ...,  0.1814, -0.1317, -0.0705],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.2051, -4.2344,  0.5410,  ...,  0.6040, -1.8789, -2.5488],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0189,  0.0005,  0.0280,  ..., -0.0074, -0.0062,  0.0061],
        [-0.0064,  0.0165, -0.0037,  ..., -0.0034,  0.0065, -0.0019],
        [ 0.0075,  0.0152,  0.0220,  ..., -0.0007,  0.0187,  0.0081],
        ...,
        [-0.0041,  0.0298,  0.0101,  ...,  0.0017, -0.0009,  0.0005],
        [-0.0021,  0.0016,  0.0191,  ...,  0.0065,  0.0113, -0.0102],
        [-0.0030,  0.0011, -0.0126,  ..., -0.0036,  0.0013, -0.0093]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.1309, -3.9902,  0.3464,  ...,  0.5112, -1.6885, -2.5703]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 21:48:14 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is too zealous, it is overzealous
If something is too powered, it is overpowered
If something is too inflated, it is overinflated
If something is too grown, it is overgrown
If something is too written, it is overwritten
If something is too loaded, it is overloaded
If something is too laid, it is overlaid
If something is too ambitious, it is
2024-07-31 21:48:14 root INFO     [order_1_approx] starting weight calculation for If something is too laid, it is overlaid
If something is too inflated, it is overinflated
If something is too powered, it is overpowered
If something is too ambitious, it is overambitious
If something is too zealous, it is overzealous
If something is too written, it is overwritten
If something is too loaded, it is overloaded
If something is too grown, it is
2024-07-31 21:48:14 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-07-31 21:50:59 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0786,  0.0282, -0.2344,  ..., -0.3037, -0.2915, -0.1194],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.8149, -4.4297,  1.0244,  ..., -0.0278, -1.2715, -2.8789],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0227,  0.0015, -0.0022,  ...,  0.0022,  0.0158,  0.0189],
        [ 0.0044,  0.0386, -0.0096,  ...,  0.0266,  0.0172, -0.0135],
        [-0.0104, -0.0091,  0.0475,  ...,  0.0068, -0.0005,  0.0297],
        ...,
        [ 0.0243,  0.0263, -0.0115,  ...,  0.0699,  0.0194,  0.0079],
        [-0.0062,  0.0103, -0.0018,  ..., -0.0157,  0.0041, -0.0440],
        [-0.0217, -0.0377, -0.0117,  ...,  0.0254, -0.0100,  0.0164]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.0898, -4.1445,  1.2529,  ...,  0.0165, -1.3408, -2.8262]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 21:51:00 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is too laid, it is overlaid
If something is too inflated, it is overinflated
If something is too powered, it is overpowered
If something is too ambitious, it is overambitious
If something is too zealous, it is overzealous
If something is too written, it is overwritten
If something is too loaded, it is overloaded
If something is too grown, it is
2024-07-31 21:51:00 root INFO     [order_1_approx] starting weight calculation for If something is too written, it is overwritten
If something is too inflated, it is overinflated
If something is too loaded, it is overloaded
If something is too powered, it is overpowered
If something is too grown, it is overgrown
If something is too laid, it is overlaid
If something is too ambitious, it is overambitious
If something is too zealous, it is
2024-07-31 21:51:00 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-07-31 21:53:47 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3831, -0.0882, -0.1335,  ...,  0.1051, -0.3848, -0.0923],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.8291, -5.5156,  0.4087,  ...,  0.1265, -1.3652, -2.8789],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0295,  0.0019,  0.0167,  ..., -0.0034,  0.0237,  0.0110],
        [-0.0126,  0.0315, -0.0021,  ...,  0.0056,  0.0103,  0.0235],
        [ 0.0391,  0.0130,  0.0392,  ..., -0.0121, -0.0096,  0.0042],
        ...,
        [ 0.0095,  0.0362, -0.0144,  ...,  0.0191,  0.0092, -0.0089],
        [ 0.0161,  0.0098,  0.0147,  ..., -0.0054,  0.0032, -0.0139],
        [-0.0200,  0.0219,  0.0114,  ...,  0.0060, -0.0297,  0.0159]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.9180, -5.2852,  0.5459,  ...,  0.1141, -1.5078, -2.8496]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 21:53:48 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is too written, it is overwritten
If something is too inflated, it is overinflated
If something is too loaded, it is overloaded
If something is too powered, it is overpowered
If something is too grown, it is overgrown
If something is too laid, it is overlaid
If something is too ambitious, it is overambitious
If something is too zealous, it is
2024-07-31 21:53:48 root INFO     [order_1_approx] starting weight calculation for If something is too zealous, it is overzealous
If something is too grown, it is overgrown
If something is too laid, it is overlaid
If something is too ambitious, it is overambitious
If something is too powered, it is overpowered
If something is too written, it is overwritten
If something is too inflated, it is overinflated
If something is too loaded, it is
2024-07-31 21:53:48 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-07-31 21:56:31 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0234, -0.2590, -0.2625,  ..., -0.0928, -0.3899,  0.1995],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.3857, -3.5312,  0.4707,  ...,  1.5098, -2.2871, -2.0625],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0623, -0.0130,  0.0031,  ...,  0.0016,  0.0222,  0.0213],
        [ 0.0065,  0.0001,  0.0008,  ...,  0.0021,  0.0282,  0.0087],
        [ 0.0102,  0.0184,  0.0374,  ...,  0.0105, -0.0033,  0.0099],
        ...,
        [-0.0079,  0.0223, -0.0155,  ...,  0.0279, -0.0054, -0.0010],
        [ 0.0074,  0.0167, -0.0134,  ...,  0.0181,  0.0599, -0.0359],
        [ 0.0191, -0.0069, -0.0044,  ...,  0.0186,  0.0090,  0.0466]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.5752, -3.5898,  0.5181,  ...,  1.8398, -2.4355, -2.1719]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 21:56:32 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is too zealous, it is overzealous
If something is too grown, it is overgrown
If something is too laid, it is overlaid
If something is too ambitious, it is overambitious
If something is too powered, it is overpowered
If something is too written, it is overwritten
If something is too inflated, it is overinflated
If something is too loaded, it is
2024-07-31 21:56:32 root INFO     total operator prediction time: 1333.8490793704987 seconds
2024-07-31 21:56:32 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on adj+ly_reg
2024-07-31 21:56:32 root INFO     building operator adj+ly_reg
2024-07-31 21:56:32 root INFO     [order_1_approx] starting weight calculation for The adjective form of according is accordingly
The adjective form of previous is previously
The adjective form of cultural is culturally
The adjective form of beautiful is beautifully
The adjective form of sexual is sexually
The adjective form of successful is successfully
The adjective form of serious is seriously
The adjective form of rare is
2024-07-31 21:56:32 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-07-31 21:59:15 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1041, -0.1024, -0.1185,  ..., -0.2267, -0.1056,  0.0918],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.8799, -3.7383, -0.7339,  ..., -4.3242, -3.4707, -4.4023],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0080,  0.0268,  0.0188,  ..., -0.0032,  0.0080,  0.0218],
        [-0.0447,  0.0290,  0.0276,  ...,  0.0177,  0.0518, -0.0271],
        [ 0.0450, -0.0299,  0.0335,  ..., -0.0438, -0.0182,  0.0212],
        ...,
        [-0.0273,  0.0310, -0.0008,  ...,  0.0859,  0.0411, -0.0284],
        [ 0.0184, -0.0054,  0.0148,  ...,  0.0148,  0.0154, -0.0128],
        [-0.0482,  0.0168, -0.0323,  ...,  0.0487, -0.0344, -0.0209]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-2.5840, -3.6953, -0.9731,  ..., -3.7891, -3.9219, -4.0586]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 21:59:16 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The adjective form of according is accordingly
The adjective form of previous is previously
The adjective form of cultural is culturally
The adjective form of beautiful is beautifully
The adjective form of sexual is sexually
The adjective form of successful is successfully
The adjective form of serious is seriously
The adjective form of rare is
2024-07-31 21:59:17 root INFO     [order_1_approx] starting weight calculation for The adjective form of sexual is sexually
The adjective form of according is accordingly
The adjective form of serious is seriously
The adjective form of successful is successfully
The adjective form of rare is rarely
The adjective form of cultural is culturally
The adjective form of previous is previously
The adjective form of beautiful is
2024-07-31 21:59:17 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-07-31 22:02:08 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2935,  0.0963,  0.1412,  ...,  0.0213, -0.2891,  0.2014],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.8340, -1.6094, -0.8799,  ...,  0.7373, -3.7148, -2.6719],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 2.7039e-02, -1.0895e-02,  3.1982e-02,  ...,  1.3527e-02,
          1.6159e-02,  3.2562e-02],
        [-1.5564e-02,  1.7639e-02, -6.4240e-03,  ...,  1.8677e-02,
          9.8724e-03, -3.2104e-02],
        [ 9.5367e-05,  2.9953e-02,  3.2623e-02,  ...,  1.2505e-02,
          9.4910e-03,  1.5068e-02],
        ...,
        [ 1.3702e-02, -3.0853e-02, -1.0788e-02,  ...,  5.3101e-02,
         -1.9913e-03, -2.3010e-02],
        [ 6.9946e-02,  1.8600e-02,  5.2567e-03,  ...,  5.2521e-02,
          1.6113e-02,  5.3162e-02],
        [-1.6800e-02, -7.9498e-03, -1.6068e-02,  ...,  3.2135e-02,
         -2.3743e-02, -2.4979e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.3682, -1.6172, -1.1133,  ...,  0.9395, -4.3828, -2.8535]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 22:02:09 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The adjective form of sexual is sexually
The adjective form of according is accordingly
The adjective form of serious is seriously
The adjective form of successful is successfully
The adjective form of rare is rarely
The adjective form of cultural is culturally
The adjective form of previous is previously
The adjective form of beautiful is
2024-07-31 22:02:09 root INFO     [order_1_approx] starting weight calculation for The adjective form of beautiful is beautifully
The adjective form of sexual is sexually
The adjective form of cultural is culturally
The adjective form of serious is seriously
The adjective form of according is accordingly
The adjective form of rare is rarely
The adjective form of successful is successfully
The adjective form of previous is
2024-07-31 22:02:09 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-07-31 22:04:57 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0188, -0.1597, -0.0092,  ..., -0.0289, -0.4114,  0.1526],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.2773, -1.7139, -0.2393,  ..., -0.9966, -1.5488, -2.7578],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0221, -0.0417,  0.0405,  ...,  0.0188,  0.0384,  0.0529],
        [-0.0078,  0.0287, -0.0324,  ...,  0.0138,  0.0285,  0.0208],
        [ 0.0616, -0.0304,  0.0020,  ..., -0.0425, -0.0575, -0.0081],
        ...,
        [ 0.0042, -0.0158, -0.0058,  ...,  0.0429, -0.0229,  0.0011],
        [ 0.0394,  0.0070,  0.0142,  ...,  0.0379, -0.0128, -0.0386],
        [ 0.0428, -0.0053,  0.0231,  ..., -0.0381, -0.0707,  0.0040]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.5137, -2.0742, -0.0591,  ..., -0.5537, -2.2344, -2.8516]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 22:04:58 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The adjective form of beautiful is beautifully
The adjective form of sexual is sexually
The adjective form of cultural is culturally
The adjective form of serious is seriously
The adjective form of according is accordingly
The adjective form of rare is rarely
The adjective form of successful is successfully
The adjective form of previous is
2024-07-31 22:04:58 root INFO     [order_1_approx] starting weight calculation for The adjective form of previous is previously
The adjective form of beautiful is beautifully
The adjective form of sexual is sexually
The adjective form of rare is rarely
The adjective form of serious is seriously
The adjective form of according is accordingly
The adjective form of cultural is culturally
The adjective form of successful is
2024-07-31 22:04:58 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-07-31 22:07:47 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0847, -0.0208, -0.0564,  ...,  0.0532, -0.4028,  0.2192],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.4844, -0.6265,  0.4980,  ...,  0.1274, -1.3057, -2.7656],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0081, -0.0186,  0.0547,  ..., -0.0751,  0.0289, -0.0109],
        [ 0.0052, -0.0090,  0.0003,  ...,  0.0070,  0.0279, -0.0108],
        [ 0.0466, -0.0006, -0.0224,  ..., -0.0179, -0.0076,  0.0068],
        ...,
        [-0.0043, -0.0063,  0.0179,  ...,  0.0726,  0.0020, -0.0161],
        [ 0.0271,  0.0438,  0.0053,  ...,  0.0366,  0.0258, -0.0227],
        [ 0.0045, -0.0298,  0.0124,  ...,  0.0399,  0.0490, -0.0125]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.4512, -0.8765,  0.7363,  ...,  0.1652, -1.3799, -3.3418]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 22:07:47 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The adjective form of previous is previously
The adjective form of beautiful is beautifully
The adjective form of sexual is sexually
The adjective form of rare is rarely
The adjective form of serious is seriously
The adjective form of according is accordingly
The adjective form of cultural is culturally
The adjective form of successful is
2024-07-31 22:07:48 root INFO     [order_1_approx] starting weight calculation for The adjective form of serious is seriously
The adjective form of according is accordingly
The adjective form of cultural is culturally
The adjective form of previous is previously
The adjective form of successful is successfully
The adjective form of beautiful is beautifully
The adjective form of rare is rarely
The adjective form of sexual is
2024-07-31 22:07:48 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-07-31 22:10:37 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0235, -0.0787, -0.1528,  ..., -0.0902, -0.1182,  0.2305],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.5664, -1.0176, -0.0763,  ..., -2.4883, -1.2100, -2.8496],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0109, -0.0359,  0.0138,  ..., -0.0152,  0.0243,  0.0239],
        [ 0.0116,  0.0357, -0.0329,  ...,  0.0113,  0.0225, -0.0032],
        [ 0.0331, -0.0343,  0.0012,  ..., -0.0086, -0.0287, -0.0110],
        ...,
        [-0.0018,  0.0339, -0.0135,  ...,  0.0819,  0.0035, -0.0099],
        [ 0.0030,  0.0369, -0.0100,  ...,  0.0479,  0.0236,  0.0009],
        [ 0.0278, -0.0392, -0.0186,  ...,  0.0112, -0.0601, -0.0054]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.6338, -1.3301, -0.1888,  ..., -2.9785, -1.8164, -2.9082]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 22:10:38 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The adjective form of serious is seriously
The adjective form of according is accordingly
The adjective form of cultural is culturally
The adjective form of previous is previously
The adjective form of successful is successfully
The adjective form of beautiful is beautifully
The adjective form of rare is rarely
The adjective form of sexual is
2024-07-31 22:10:38 root INFO     [order_1_approx] starting weight calculation for The adjective form of rare is rarely
The adjective form of sexual is sexually
The adjective form of according is accordingly
The adjective form of serious is seriously
The adjective form of successful is successfully
The adjective form of previous is previously
The adjective form of beautiful is beautifully
The adjective form of cultural is
2024-07-31 22:10:39 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-07-31 22:13:30 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1301,  0.0223, -0.1151,  ..., -0.1720, -0.2568,  0.1735],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.1289, -0.4089,  3.0078,  ..., -0.8428,  0.0300,  0.6318],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0515, -0.0644, -0.0144,  ..., -0.0206, -0.0027, -0.0328],
        [-0.0069,  0.0507,  0.0194,  ...,  0.0289,  0.0250, -0.0053],
        [ 0.0371, -0.0120,  0.0268,  ...,  0.0120, -0.0204, -0.0024],
        ...,
        [ 0.0280,  0.0149, -0.0153,  ...,  0.1279, -0.0170,  0.0137],
        [ 0.0115,  0.0143,  0.0054,  ..., -0.0043,  0.0660, -0.0043],
        [ 0.0044, -0.0526, -0.0202,  ...,  0.0339, -0.0505,  0.0076]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.3574, -0.0535,  3.0293,  ..., -0.9414, -0.3369,  0.7773]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 22:13:31 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The adjective form of rare is rarely
The adjective form of sexual is sexually
The adjective form of according is accordingly
The adjective form of serious is seriously
The adjective form of successful is successfully
The adjective form of previous is previously
The adjective form of beautiful is beautifully
The adjective form of cultural is
2024-07-31 22:13:32 root INFO     [order_1_approx] starting weight calculation for The adjective form of according is accordingly
The adjective form of previous is previously
The adjective form of successful is successfully
The adjective form of rare is rarely
The adjective form of sexual is sexually
The adjective form of beautiful is beautifully
The adjective form of cultural is culturally
The adjective form of serious is
2024-07-31 22:13:32 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-07-31 22:16:23 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0590, -0.1032, -0.3140,  ..., -0.0486, -0.4297,  0.2737],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.1211, -2.0352, -0.9390,  ..., -1.9062,  0.0986, -4.2617],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0072,  0.0178, -0.0101,  ...,  0.0158,  0.0130, -0.0036],
        [-0.0041,  0.0005,  0.0379,  ...,  0.0237,  0.0361,  0.0057],
        [ 0.0007, -0.0014,  0.0076,  ..., -0.0237, -0.0130,  0.0085],
        ...,
        [ 0.0296, -0.0175,  0.0271,  ...,  0.0925,  0.0048,  0.0144],
        [ 0.0036, -0.0169,  0.0009,  ...,  0.0197,  0.0331, -0.0215],
        [ 0.0367,  0.0001, -0.0186,  ...,  0.0732,  0.0032,  0.0240]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.0664, -2.1465, -0.7725,  ..., -2.1797, -0.1470, -3.9453]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 22:16:24 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The adjective form of according is accordingly
The adjective form of previous is previously
The adjective form of successful is successfully
The adjective form of rare is rarely
The adjective form of sexual is sexually
The adjective form of beautiful is beautifully
The adjective form of cultural is culturally
The adjective form of serious is
2024-07-31 22:16:25 root INFO     [order_1_approx] starting weight calculation for The adjective form of previous is previously
The adjective form of sexual is sexually
The adjective form of serious is seriously
The adjective form of successful is successfully
The adjective form of rare is rarely
The adjective form of beautiful is beautifully
The adjective form of cultural is culturally
The adjective form of according is
2024-07-31 22:16:25 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-07-31 22:19:16 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2119, -0.2854, -0.1902,  ..., -0.0555, -0.4370,  0.1184],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.1006, -3.5449,  1.1484,  ...,  2.8613, -1.9141, -1.2090],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0440, -0.0486, -0.0249,  ...,  0.0560, -0.0366,  0.0718],
        [-0.0242,  0.0613, -0.0019,  ..., -0.0095,  0.0564, -0.0282],
        [ 0.0081, -0.0045,  0.0283,  ..., -0.0880, -0.0257,  0.0010],
        ...,
        [ 0.0660,  0.0535,  0.0465,  ...,  0.0607,  0.0153, -0.0162],
        [ 0.0712,  0.0006, -0.0032,  ..., -0.0232,  0.0272, -0.0321],
        [ 0.0043,  0.0267,  0.0544,  ...,  0.0358, -0.0225,  0.0006]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.3076, -3.0332,  1.2949,  ...,  3.1836, -2.1074, -1.4316]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 22:19:17 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The adjective form of previous is previously
The adjective form of sexual is sexually
The adjective form of serious is seriously
The adjective form of successful is successfully
The adjective form of rare is rarely
The adjective form of beautiful is beautifully
The adjective form of cultural is culturally
The adjective form of according is
2024-07-31 22:19:17 root INFO     total operator prediction time: 1365.6698019504547 seconds
2024-07-31 22:19:17 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on verb+tion_irreg
2024-07-31 22:19:17 root INFO     building operator verb+tion_irreg
2024-07-31 22:19:17 root INFO     [order_1_approx] starting weight calculation for To perspire results in perspiration
To visualize results in visualization
To expire results in expiration
To improvize results in improvization
To compute results in computation
To occupy results in occupation
To determine results in determination
To privatize results in
2024-07-31 22:19:18 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-07-31 22:22:07 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2576, -0.0123, -0.3965,  ..., -0.0552, -0.0706, -0.0049],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.6592, -5.0469,  2.2012,  ..., -1.5469, -0.4634, -1.1211],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0080,  0.0183, -0.0073,  ...,  0.0029,  0.0029,  0.0016],
        [ 0.0202,  0.0016,  0.0056,  ...,  0.0324,  0.0136,  0.0390],
        [-0.0142,  0.0017, -0.0037,  ..., -0.0056, -0.0140, -0.0262],
        ...,
        [ 0.0302, -0.0184,  0.0156,  ...,  0.0463,  0.0195,  0.0211],
        [-0.0001, -0.0159, -0.0022,  ...,  0.0195,  0.0495,  0.0155],
        [ 0.0163, -0.0163,  0.0239,  ..., -0.0058, -0.0025,  0.0313]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.9570, -4.3320,  2.0391,  ..., -1.1426, -0.6572, -0.7583]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 22:22:08 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To perspire results in perspiration
To visualize results in visualization
To expire results in expiration
To improvize results in improvization
To compute results in computation
To occupy results in occupation
To determine results in determination
To privatize results in
2024-07-31 22:22:08 root INFO     [order_1_approx] starting weight calculation for To improvize results in improvization
To privatize results in privatization
To visualize results in visualization
To occupy results in occupation
To perspire results in perspiration
To expire results in expiration
To compute results in computation
To determine results in
2024-07-31 22:22:08 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-07-31 22:24:58 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0928,  0.2861, -0.0356,  ...,  0.0976, -0.2627, -0.1903],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.3672, -4.2344,  0.7681,  ..., -0.6675, -3.7793, -1.7383],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0110, -0.0053, -0.0074,  ..., -0.0234,  0.0004,  0.0070],
        [ 0.0255,  0.0276, -0.0364,  ...,  0.0403, -0.0071,  0.0344],
        [ 0.0073, -0.0084,  0.0208,  ..., -0.0004, -0.0216, -0.0135],
        ...,
        [ 0.0079,  0.0205,  0.0187,  ...,  0.0311,  0.0112,  0.0074],
        [-0.0269, -0.0276,  0.0117,  ..., -0.0127,  0.0084, -0.0145],
        [ 0.0392, -0.0184, -0.0105,  ...,  0.0742, -0.0496,  0.0410]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.2617, -3.7871,  0.6978,  ..., -0.6831, -4.3438, -1.7070]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 22:24:59 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To improvize results in improvization
To privatize results in privatization
To visualize results in visualization
To occupy results in occupation
To perspire results in perspiration
To expire results in expiration
To compute results in computation
To determine results in
2024-07-31 22:24:59 root INFO     [order_1_approx] starting weight calculation for To improvize results in improvization
To occupy results in occupation
To compute results in computation
To expire results in expiration
To perspire results in perspiration
To determine results in determination
To privatize results in privatization
To visualize results in
2024-07-31 22:24:59 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-07-31 22:27:50 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1081,  0.1699,  0.1243,  ..., -0.0199, -0.1661, -0.0903],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.4219, -4.4375,  4.2383,  ...,  0.8511, -1.1230, -0.5376],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0040, -0.0091,  0.0082,  ...,  0.0003, -0.0030,  0.0078],
        [ 0.0055,  0.0021,  0.0007,  ..., -0.0131,  0.0091,  0.0089],
        [-0.0023,  0.0014,  0.0498,  ...,  0.0039, -0.0176, -0.0077],
        ...,
        [ 0.0176,  0.0166, -0.0083,  ...,  0.0104, -0.0001,  0.0030],
        [-0.0092, -0.0063,  0.0027,  ...,  0.0100,  0.0164, -0.0169],
        [-0.0065, -0.0350,  0.0294,  ..., -0.0052, -0.0144,  0.0196]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.2325, -4.1680,  4.1367,  ...,  0.9478, -1.2988, -0.3691]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 22:27:50 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To improvize results in improvization
To occupy results in occupation
To compute results in computation
To expire results in expiration
To perspire results in perspiration
To determine results in determination
To privatize results in privatization
To visualize results in
2024-07-31 22:27:51 root INFO     [order_1_approx] starting weight calculation for To privatize results in privatization
To compute results in computation
To expire results in expiration
To perspire results in perspiration
To visualize results in visualization
To occupy results in occupation
To determine results in determination
To improvize results in
2024-07-31 22:27:51 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-07-31 22:30:41 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0161,  0.1835, -0.1489,  ..., -0.1432, -0.1320, -0.0213],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.0117, -3.1367,  2.1074,  ...,  3.1348, -1.0254, -2.1895],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0121,  0.0301,  0.0036,  ..., -0.0067, -0.0455, -0.0369],
        [-0.0226, -0.0131, -0.0092,  ...,  0.0036,  0.0472,  0.0250],
        [-0.0173,  0.0114,  0.0148,  ...,  0.0214, -0.0169, -0.0210],
        ...,
        [-0.0026, -0.0219,  0.0068,  ...,  0.0233,  0.0278,  0.0350],
        [-0.0105, -0.0193, -0.0101,  ...,  0.0091,  0.0807,  0.0145],
        [ 0.0099, -0.0219, -0.0020,  ..., -0.0087,  0.0381,  0.0418]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.8701, -1.8525,  1.8965,  ...,  3.5547, -0.0635, -1.5498]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 22:30:42 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To privatize results in privatization
To compute results in computation
To expire results in expiration
To perspire results in perspiration
To visualize results in visualization
To occupy results in occupation
To determine results in determination
To improvize results in
2024-07-31 22:30:42 root INFO     [order_1_approx] starting weight calculation for To expire results in expiration
To compute results in computation
To perspire results in perspiration
To visualize results in visualization
To improvize results in improvization
To determine results in determination
To privatize results in privatization
To occupy results in
2024-07-31 22:30:43 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-07-31 22:33:32 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0302,  0.1639, -0.0207,  ..., -0.1060, -0.2122,  0.0262],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.7422, -4.2578,  2.6523,  ...,  0.7188, -2.0547, -0.6699],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0214, -0.0301,  0.0112,  ..., -0.0160,  0.0186,  0.0265],
        [-0.0035,  0.0086,  0.0054,  ...,  0.0059, -0.0146,  0.0231],
        [-0.0027, -0.0131,  0.0091,  ...,  0.0147,  0.0102,  0.0158],
        ...,
        [ 0.0123, -0.0113,  0.0188,  ...,  0.0059, -0.0555, -0.0109],
        [-0.0092, -0.0052, -0.0095,  ...,  0.0189,  0.0438,  0.0281],
        [ 0.0106, -0.0232, -0.0056,  ...,  0.0179, -0.0106,  0.0305]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.7056, -4.1289,  2.5391,  ...,  0.8838, -2.3027, -0.7749]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 22:33:33 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To expire results in expiration
To compute results in computation
To perspire results in perspiration
To visualize results in visualization
To improvize results in improvization
To determine results in determination
To privatize results in privatization
To occupy results in
2024-07-31 22:33:33 root INFO     [order_1_approx] starting weight calculation for To determine results in determination
To privatize results in privatization
To visualize results in visualization
To occupy results in occupation
To expire results in expiration
To compute results in computation
To improvize results in improvization
To perspire results in
2024-07-31 22:33:33 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-07-31 22:36:23 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0864,  0.1696, -0.5229,  ..., -0.1443, -0.1196, -0.1219],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.1523, -4.6484,  0.6133,  ..., -2.0078, -0.9863, -0.3613],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0140, -0.0095, -0.0209,  ..., -0.0241,  0.0251, -0.0117],
        [ 0.0001,  0.0296,  0.0219,  ...,  0.0454, -0.0415,  0.0386],
        [-0.0272,  0.0078,  0.0420,  ...,  0.0103, -0.0338, -0.0138],
        ...,
        [ 0.0160, -0.0091,  0.0008,  ...,  0.0569,  0.0264,  0.0235],
        [-0.0128,  0.0119, -0.0144,  ...,  0.0139,  0.0091, -0.0363],
        [-0.0368, -0.0364, -0.0015,  ...,  0.0269,  0.0116,  0.0921]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.1660, -4.3633,  0.4729,  ..., -2.0664, -1.0186,  0.0769]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 22:36:24 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To determine results in determination
To privatize results in privatization
To visualize results in visualization
To occupy results in occupation
To expire results in expiration
To compute results in computation
To improvize results in improvization
To perspire results in
2024-07-31 22:36:24 root INFO     [order_1_approx] starting weight calculation for To compute results in computation
To privatize results in privatization
To perspire results in perspiration
To improvize results in improvization
To determine results in determination
To visualize results in visualization
To occupy results in occupation
To expire results in
2024-07-31 22:36:24 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-07-31 22:39:14 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0180,  0.1602, -0.4497,  ..., -0.1847, -0.0933, -0.1495],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.7188, -3.3359,  1.5117,  ..., -0.7070, -1.3262, -1.8721],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0095, -0.0217, -0.0263,  ..., -0.0074, -0.0070,  0.0090],
        [-0.0312, -0.0203,  0.0208,  ..., -0.0013,  0.0213,  0.0468],
        [ 0.0182,  0.0162,  0.0033,  ...,  0.0035, -0.0218, -0.0347],
        ...,
        [ 0.0279,  0.0231,  0.0395,  ...,  0.0214,  0.0078,  0.0028],
        [-0.0075, -0.0618,  0.0009,  ...,  0.0146,  0.0492,  0.0567],
        [-0.0124, -0.0364,  0.0206,  ..., -0.0064, -0.0159,  0.0914]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.3215, -1.6025,  0.8301,  ..., -0.4094, -0.2178, -0.5107]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 22:39:15 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To compute results in computation
To privatize results in privatization
To perspire results in perspiration
To improvize results in improvization
To determine results in determination
To visualize results in visualization
To occupy results in occupation
To expire results in
2024-07-31 22:39:16 root INFO     [order_1_approx] starting weight calculation for To improvize results in improvization
To determine results in determination
To privatize results in privatization
To visualize results in visualization
To perspire results in perspiration
To expire results in expiration
To occupy results in occupation
To compute results in
2024-07-31 22:39:16 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-07-31 22:42:03 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1328,  0.1825,  0.3926,  ...,  0.0400, -0.2830, -0.0628],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.7070, -1.9775,  1.1816,  ..., -0.4639, -0.2144, -0.2861],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0032, -0.0525,  0.0539,  ..., -0.0078, -0.0002,  0.0335],
        [ 0.0025,  0.0403, -0.0413,  ..., -0.0015,  0.0080,  0.0158],
        [ 0.0095, -0.0021, -0.0024,  ...,  0.0090,  0.0252,  0.0014],
        ...,
        [-0.0050, -0.0061,  0.0352,  ...,  0.0067,  0.0147, -0.0461],
        [-0.0182, -0.0120,  0.0014,  ...,  0.0233,  0.0033,  0.0041],
        [ 0.0201, -0.0099,  0.0246,  ...,  0.0417, -0.0097,  0.0453]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.8027, -1.7988,  1.1436,  ..., -0.6289, -0.0088,  0.1387]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 22:42:04 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To improvize results in improvization
To determine results in determination
To privatize results in privatization
To visualize results in visualization
To perspire results in perspiration
To expire results in expiration
To occupy results in occupation
To compute results in
2024-07-31 22:42:04 root INFO     total operator prediction time: 1366.4480395317078 seconds
2024-07-31 22:42:04 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on verb+able_reg
2024-07-31 22:42:04 root INFO     building operator verb+able_reg
2024-07-31 22:42:04 root INFO     [order_1_approx] starting weight calculation for If you can download something, that thing is downloadable
If you can publish something, that thing is publishable
If you can protect something, that thing is protectable
If you can improve something, that thing is improvable
If you can achieve something, that thing is achieveable
If you can believe something, that thing is believeable
If you can rely something, that thing is reliable
If you can accept something, that thing is
2024-07-31 22:42:04 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-07-31 22:44:51 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0853,  0.3997,  0.1138,  ...,  0.1531, -0.3018,  0.1313],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.3311,  0.9336, -3.8477,  ..., -0.9409, -9.3359, -0.7617],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0121,  0.0045, -0.0448,  ...,  0.0163,  0.0590,  0.0213],
        [ 0.0169, -0.0150, -0.0064,  ...,  0.0308, -0.0728,  0.0082],
        [ 0.0146, -0.0122,  0.0132,  ..., -0.0140,  0.0034,  0.0053],
        ...,
        [ 0.0529, -0.0260,  0.0312,  ...,  0.0174, -0.0614, -0.0048],
        [-0.0277,  0.0164, -0.0058,  ..., -0.0202,  0.0125,  0.0115],
        [-0.0051, -0.0161, -0.0087,  ..., -0.0045, -0.0111,  0.0007]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.7495,  0.7134, -3.8984,  ..., -0.9849, -8.9609, -0.4812]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 22:44:52 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you can download something, that thing is downloadable
If you can publish something, that thing is publishable
If you can protect something, that thing is protectable
If you can improve something, that thing is improvable
If you can achieve something, that thing is achieveable
If you can believe something, that thing is believeable
If you can rely something, that thing is reliable
If you can accept something, that thing is
2024-07-31 22:44:52 root INFO     [order_1_approx] starting weight calculation for If you can believe something, that thing is believeable
If you can achieve something, that thing is achieveable
If you can accept something, that thing is acceptable
If you can protect something, that thing is protectable
If you can improve something, that thing is improvable
If you can rely something, that thing is reliable
If you can publish something, that thing is publishable
If you can download something, that thing is
2024-07-31 22:44:52 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-07-31 22:47:42 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0576,  0.0658,  0.1013,  ...,  0.0667, -0.2727,  0.0203],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.3965, -2.4062, -0.0186,  ..., -3.4102, -8.0625, -1.7539],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0042, -0.0616,  0.0429,  ..., -0.0166,  0.0194,  0.0030],
        [-0.0212,  0.0073,  0.0084,  ..., -0.0158, -0.0097,  0.0075],
        [ 0.0223,  0.0113, -0.0159,  ...,  0.0064, -0.0436, -0.0230],
        ...,
        [ 0.0321,  0.0229,  0.0269,  ...,  0.0347,  0.0250,  0.0159],
        [ 0.0197,  0.0163, -0.0203,  ..., -0.0164,  0.0356,  0.0074],
        [-0.0178,  0.0086, -0.0114,  ..., -0.0131, -0.0135,  0.0328]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.4756, -2.2324, -0.2101,  ..., -3.8379, -7.8047, -2.3711]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 22:47:43 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you can believe something, that thing is believeable
If you can achieve something, that thing is achieveable
If you can accept something, that thing is acceptable
If you can protect something, that thing is protectable
If you can improve something, that thing is improvable
If you can rely something, that thing is reliable
If you can publish something, that thing is publishable
If you can download something, that thing is
2024-07-31 22:47:43 root INFO     [order_1_approx] starting weight calculation for If you can believe something, that thing is believeable
If you can protect something, that thing is protectable
If you can download something, that thing is downloadable
If you can publish something, that thing is publishable
If you can achieve something, that thing is achieveable
If you can rely something, that thing is reliable
If you can accept something, that thing is acceptable
If you can improve something, that thing is
2024-07-31 22:47:44 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-07-31 22:50:32 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1277,  0.1189,  0.1785,  ...,  0.0136, -0.1528,  0.0712],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.6621, -1.2441, -0.4888,  ..., -2.8691, -7.9688, -3.5723],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0180, -0.0049,  0.0321,  ..., -0.0139, -0.0026,  0.0019],
        [ 0.0086,  0.0263, -0.0141,  ..., -0.0051, -0.0141, -0.0082],
        [ 0.0205,  0.0041,  0.0085,  ...,  0.0036,  0.0200, -0.0154],
        ...,
        [ 0.0089, -0.0041,  0.0054,  ...,  0.0100, -0.0059, -0.0119],
        [ 0.0039, -0.0096, -0.0038,  ..., -0.0078, -0.0197, -0.0052],
        [-0.0251, -0.0198,  0.0107,  ..., -0.0109, -0.0346,  0.0009]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.3398, -0.9863, -0.7065,  ..., -2.8691, -7.5703, -3.3809]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 22:50:33 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you can believe something, that thing is believeable
If you can protect something, that thing is protectable
If you can download something, that thing is downloadable
If you can publish something, that thing is publishable
If you can achieve something, that thing is achieveable
If you can rely something, that thing is reliable
If you can accept something, that thing is acceptable
If you can improve something, that thing is
2024-07-31 22:50:33 root INFO     [order_1_approx] starting weight calculation for If you can accept something, that thing is acceptable
If you can publish something, that thing is publishable
If you can believe something, that thing is believeable
If you can improve something, that thing is improvable
If you can download something, that thing is downloadable
If you can protect something, that thing is protectable
If you can rely something, that thing is reliable
If you can achieve something, that thing is
2024-07-31 22:50:33 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-07-31 22:53:19 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0377,  0.3159,  0.0613,  ...,  0.0662, -0.4358,  0.0193],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.8164,  0.8828, -2.0742,  ..., -3.6172, -8.9531, -3.9199],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0138,  0.0216,  0.0255,  ...,  0.0142,  0.0427,  0.0153],
        [-0.0097, -0.0110, -0.0582,  ...,  0.0145, -0.0396, -0.0228],
        [ 0.0309, -0.0336,  0.0239,  ...,  0.0140, -0.0152,  0.0315],
        ...,
        [ 0.0196, -0.0031,  0.0075,  ..., -0.0075, -0.0041, -0.0274],
        [ 0.0146,  0.0311, -0.0018,  ..., -0.0222,  0.0077,  0.0189],
        [ 0.0125,  0.0021, -0.0043,  ..., -0.0090, -0.0080, -0.0068]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.7954,  0.8901, -2.0742,  ..., -3.6621, -8.8906, -3.8398]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 22:53:20 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you can accept something, that thing is acceptable
If you can publish something, that thing is publishable
If you can believe something, that thing is believeable
If you can improve something, that thing is improvable
If you can download something, that thing is downloadable
If you can protect something, that thing is protectable
If you can rely something, that thing is reliable
If you can achieve something, that thing is
2024-07-31 22:53:20 root INFO     [order_1_approx] starting weight calculation for If you can achieve something, that thing is achieveable
If you can publish something, that thing is publishable
If you can download something, that thing is downloadable
If you can improve something, that thing is improvable
If you can protect something, that thing is protectable
If you can accept something, that thing is acceptable
If you can believe something, that thing is believeable
If you can rely something, that thing is
2024-07-31 22:53:20 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-07-31 22:56:06 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0156, -0.0402,  0.2390,  ..., -0.0453, -0.3171,  0.2268],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.1777, -0.5527, -2.1328,  ..., -1.6406, -6.2656, -2.7539],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 2.1271e-02, -4.1565e-02,  9.8343e-03,  ..., -6.6376e-03,
          7.7515e-02, -1.2474e-02],
        [-5.2460e-02,  4.2816e-02, -3.0243e-02,  ...,  4.8401e-02,
         -3.2928e-02, -2.3346e-02],
        [ 2.2385e-02, -7.6332e-03,  4.4373e-02,  ..., -2.9926e-03,
         -2.9251e-02, -2.1378e-02],
        ...,
        [ 5.3284e-02, -5.8365e-03,  7.5836e-03,  ...,  1.4603e-02,
         -6.4331e-02, -7.4921e-03],
        [ 5.7861e-02,  2.7344e-02, -2.5482e-02,  ..., -1.3672e-02,
          3.2440e-02, -1.1940e-02],
        [-1.1978e-02,  4.8462e-02, -1.1856e-02,  ..., -2.2888e-05,
          4.5776e-03, -1.6174e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.7324, -0.5020, -2.1504,  ..., -2.1660, -5.7383, -2.9043]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 22:56:07 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you can achieve something, that thing is achieveable
If you can publish something, that thing is publishable
If you can download something, that thing is downloadable
If you can improve something, that thing is improvable
If you can protect something, that thing is protectable
If you can accept something, that thing is acceptable
If you can believe something, that thing is believeable
If you can rely something, that thing is
2024-07-31 22:56:07 root INFO     [order_1_approx] starting weight calculation for If you can rely something, that thing is reliable
If you can improve something, that thing is improvable
If you can download something, that thing is downloadable
If you can protect something, that thing is protectable
If you can achieve something, that thing is achieveable
If you can publish something, that thing is publishable
If you can accept something, that thing is acceptable
If you can believe something, that thing is
2024-07-31 22:56:07 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-07-31 22:58:54 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0974,  0.3438,  0.1910,  ..., -0.0690, -0.3696,  0.0826],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.1426, -1.6816, -0.3799,  ..., -3.1602, -5.8828, -2.8457],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0164, -0.0105, -0.0028,  ...,  0.0156,  0.0021,  0.0134],
        [-0.0361,  0.0126, -0.0048,  ..., -0.0099,  0.0061, -0.0047],
        [-0.0016,  0.0204,  0.0096,  ...,  0.0110, -0.0063,  0.0019],
        ...,
        [ 0.0092, -0.0056, -0.0128,  ..., -0.0096, -0.0228, -0.0138],
        [-0.0071, -0.0094, -0.0031,  ...,  0.0026, -0.0118, -0.0136],
        [ 0.0149, -0.0194, -0.0155,  ..., -0.0152, -0.0075,  0.0083]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.1582, -1.6992,  0.2007,  ..., -2.9160, -5.8828, -3.1250]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 22:58:55 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you can rely something, that thing is reliable
If you can improve something, that thing is improvable
If you can download something, that thing is downloadable
If you can protect something, that thing is protectable
If you can achieve something, that thing is achieveable
If you can publish something, that thing is publishable
If you can accept something, that thing is acceptable
If you can believe something, that thing is
2024-07-31 22:58:55 root INFO     [order_1_approx] starting weight calculation for If you can accept something, that thing is acceptable
If you can publish something, that thing is publishable
If you can achieve something, that thing is achieveable
If you can improve something, that thing is improvable
If you can rely something, that thing is reliable
If you can believe something, that thing is believeable
If you can download something, that thing is downloadable
If you can protect something, that thing is
2024-07-31 22:58:55 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-07-31 23:01:45 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0140, -0.1071,  0.0119,  ...,  0.0384, -0.2214,  0.0507],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.5420, -3.0117, -1.8213,  ..., -1.6211, -6.8281, -1.9551],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0012, -0.0130, -0.0115,  ..., -0.0274,  0.0203,  0.0088],
        [-0.0085,  0.0295, -0.0069,  ...,  0.0105, -0.0098,  0.0206],
        [ 0.0288, -0.0400,  0.0139,  ...,  0.0009, -0.0001, -0.0074],
        ...,
        [ 0.0415,  0.0297, -0.0210,  ...,  0.0166, -0.0012, -0.0254],
        [ 0.0228, -0.0012,  0.0171,  ..., -0.0048, -0.0575, -0.0173],
        [ 0.0051,  0.0081,  0.0168,  ...,  0.0143,  0.0057,  0.0022]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.1433, -2.5703, -1.7500,  ..., -1.2295, -6.7266, -2.7773]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 23:01:46 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you can accept something, that thing is acceptable
If you can publish something, that thing is publishable
If you can achieve something, that thing is achieveable
If you can improve something, that thing is improvable
If you can rely something, that thing is reliable
If you can believe something, that thing is believeable
If you can download something, that thing is downloadable
If you can protect something, that thing is
2024-07-31 23:01:46 root INFO     [order_1_approx] starting weight calculation for If you can believe something, that thing is believeable
If you can download something, that thing is downloadable
If you can achieve something, that thing is achieveable
If you can rely something, that thing is reliable
If you can improve something, that thing is improvable
If you can accept something, that thing is acceptable
If you can protect something, that thing is protectable
If you can publish something, that thing is
2024-07-31 23:01:46 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-07-31 23:04:36 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0341,  0.1296,  0.1108,  ...,  0.0812, -0.1516,  0.0880],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.5449, -3.0645, -0.8335,  ..., -2.4062, -8.0547, -0.2617],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0005, -0.0201,  0.0152,  ..., -0.0408,  0.0349,  0.0248],
        [-0.0109,  0.0216, -0.0113,  ..., -0.0101, -0.0163, -0.0134],
        [ 0.0333,  0.0151, -0.0003,  ...,  0.0211, -0.0715, -0.0059],
        ...,
        [-0.0107,  0.0401, -0.0102,  ...,  0.0517,  0.0043, -0.0104],
        [ 0.0007, -0.0070, -0.0296,  ..., -0.0257, -0.0165, -0.0074],
        [-0.0039,  0.0235,  0.0041,  ..., -0.0130, -0.0167, -0.0084]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.0935, -2.9531, -0.6865,  ..., -2.6504, -7.8203, -0.7314]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 23:04:37 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you can believe something, that thing is believeable
If you can download something, that thing is downloadable
If you can achieve something, that thing is achieveable
If you can rely something, that thing is reliable
If you can improve something, that thing is improvable
If you can accept something, that thing is acceptable
If you can protect something, that thing is protectable
If you can publish something, that thing is
2024-07-31 23:04:37 root INFO     total operator prediction time: 1352.799189567566 seconds
2024-07-31 23:04:37 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on un+adj_reg
2024-07-31 23:04:37 root INFO     building operator un+adj_reg
2024-07-31 23:04:37 root INFO     [order_1_approx] starting weight calculation for The opposite of predictable is unpredictable
The opposite of comfortable is uncomfortable
The opposite of specified is unspecified
The opposite of restricted is unrestricted
The opposite of published is unpublished
The opposite of controlled is uncontrolled
The opposite of realistic is unrealistic
The opposite of authorized is
2024-07-31 23:04:37 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-07-31 23:07:28 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0059,  0.1324, -0.0637,  ..., -0.2307, -0.1919, -0.0522],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.4229, -1.3945,  1.6885,  ...,  1.0479, -0.4194, -0.7915],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0382,  0.0010,  0.0065,  ...,  0.0310, -0.0203,  0.0088],
        [-0.0025,  0.0320, -0.0083,  ..., -0.0015, -0.0128, -0.0146],
        [ 0.0341, -0.0219,  0.0030,  ...,  0.0898, -0.0306, -0.0180],
        ...,
        [ 0.0252,  0.0159,  0.0108,  ..., -0.0326, -0.0090, -0.0097],
        [-0.0095,  0.0219,  0.0152,  ..., -0.0418,  0.0680, -0.0112],
        [ 0.0052, -0.0138, -0.0135,  ..., -0.0037, -0.0382,  0.0001]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.5444, -1.7998,  1.5303,  ...,  1.2607, -0.4526, -0.5977]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 23:07:29 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of predictable is unpredictable
The opposite of comfortable is uncomfortable
The opposite of specified is unspecified
The opposite of restricted is unrestricted
The opposite of published is unpublished
The opposite of controlled is uncontrolled
The opposite of realistic is unrealistic
The opposite of authorized is
2024-07-31 23:07:29 root INFO     [order_1_approx] starting weight calculation for The opposite of realistic is unrealistic
The opposite of specified is unspecified
The opposite of restricted is unrestricted
The opposite of comfortable is uncomfortable
The opposite of authorized is unauthorized
The opposite of published is unpublished
The opposite of controlled is uncontrolled
The opposite of predictable is
2024-07-31 23:07:29 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-07-31 23:10:19 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0525,  0.0554, -0.0020,  ..., -0.0504, -0.2236,  0.0027],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.8262,  0.9609, -0.9971,  ...,  0.9248, -0.4307, -1.7969],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0261,  0.0174,  0.0053,  ...,  0.0291, -0.0027,  0.0529],
        [-0.0104, -0.0088, -0.0047,  ..., -0.0099, -0.0067, -0.0035],
        [-0.0007, -0.0086, -0.0010,  ...,  0.0287, -0.0197,  0.0086],
        ...,
        [-0.0028, -0.0013, -0.0098,  ..., -0.0031, -0.0195, -0.0076],
        [-0.0201,  0.0142, -0.0239,  ..., -0.0082,  0.0297, -0.0326],
        [-0.0405,  0.0035, -0.0156,  ...,  0.0096, -0.0339,  0.0010]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.2031,  1.1826, -1.4150,  ...,  1.4473, -0.8555, -2.4297]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 23:10:20 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of realistic is unrealistic
The opposite of specified is unspecified
The opposite of restricted is unrestricted
The opposite of comfortable is uncomfortable
The opposite of authorized is unauthorized
The opposite of published is unpublished
The opposite of controlled is uncontrolled
The opposite of predictable is
2024-07-31 23:10:20 root INFO     [order_1_approx] starting weight calculation for The opposite of comfortable is uncomfortable
The opposite of realistic is unrealistic
The opposite of specified is unspecified
The opposite of predictable is unpredictable
The opposite of authorized is unauthorized
The opposite of restricted is unrestricted
The opposite of published is unpublished
The opposite of controlled is
2024-07-31 23:10:20 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-07-31 23:13:08 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0910, -0.0214, -0.0615,  ..., -0.1044, -0.1874,  0.0436],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.4028,  0.0859,  1.7295,  ...,  1.0625,  1.3184, -1.4326],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0081, -0.0149, -0.0354,  ..., -0.0070, -0.0520,  0.0054],
        [-0.0170,  0.0254,  0.0223,  ...,  0.0548, -0.0460, -0.0129],
        [ 0.0157,  0.0134,  0.0096,  ...,  0.0619, -0.0483,  0.0135],
        ...,
        [ 0.0333, -0.0124, -0.0247,  ..., -0.0424, -0.0216, -0.0081],
        [-0.0080, -0.0039,  0.0192,  ..., -0.0657,  0.0698, -0.0653],
        [-0.0016, -0.0303, -0.0118,  ...,  0.0396,  0.0218, -0.0076]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.6880, -0.3376,  1.2676,  ...,  1.4434,  1.9375, -1.9648]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 23:13:08 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of comfortable is uncomfortable
The opposite of realistic is unrealistic
The opposite of specified is unspecified
The opposite of predictable is unpredictable
The opposite of authorized is unauthorized
The opposite of restricted is unrestricted
The opposite of published is unpublished
The opposite of controlled is
2024-07-31 23:13:09 root INFO     [order_1_approx] starting weight calculation for The opposite of authorized is unauthorized
The opposite of predictable is unpredictable
The opposite of realistic is unrealistic
The opposite of restricted is unrestricted
The opposite of controlled is uncontrolled
The opposite of comfortable is uncomfortable
The opposite of specified is unspecified
The opposite of published is
2024-07-31 23:13:09 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-07-31 23:16:00 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0337,  0.1075, -0.0496,  ..., -0.1843, -0.1777,  0.0687],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.4365, -1.2578,  0.6787,  ..., -0.8286, -1.6914,  1.7070],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0584, -0.0374,  0.0346,  ...,  0.0386, -0.0051,  0.0029],
        [-0.0003,  0.0355,  0.0328,  ...,  0.0107,  0.0172,  0.0176],
        [-0.0179, -0.0410,  0.0312,  ...,  0.0506, -0.0189, -0.0077],
        ...,
        [ 0.0525,  0.0073, -0.0185,  ..., -0.0325, -0.0110,  0.0319],
        [-0.0377,  0.0428,  0.0010,  ..., -0.0077,  0.0504,  0.0131],
        [-0.0211,  0.0367, -0.0754,  ..., -0.0097, -0.0340, -0.0533]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.9551, -1.3301,  1.0420,  ..., -0.8735, -1.5439,  0.9214]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 23:16:01 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of authorized is unauthorized
The opposite of predictable is unpredictable
The opposite of realistic is unrealistic
The opposite of restricted is unrestricted
The opposite of controlled is uncontrolled
The opposite of comfortable is uncomfortable
The opposite of specified is unspecified
The opposite of published is
2024-07-31 23:16:01 root INFO     [order_1_approx] starting weight calculation for The opposite of authorized is unauthorized
The opposite of controlled is uncontrolled
The opposite of restricted is unrestricted
The opposite of realistic is unrealistic
The opposite of specified is unspecified
The opposite of predictable is unpredictable
The opposite of published is unpublished
The opposite of comfortable is
2024-07-31 23:16:01 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-07-31 23:18:51 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2383, -0.0917, -0.0635,  ..., -0.2690, -0.5273,  0.2568],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.1973, -0.1750,  1.9395,  ..., -0.9639, -0.0635,  1.0918],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0463,  0.0050,  0.0199,  ...,  0.0414, -0.0198,  0.0471],
        [-0.0031,  0.0544, -0.0250,  ...,  0.0067, -0.0024,  0.0023],
        [ 0.0080, -0.0016,  0.0088,  ...,  0.0312, -0.0288,  0.0101],
        ...,
        [ 0.0352,  0.0001, -0.0130,  ...,  0.0151, -0.0083, -0.0375],
        [-0.0160,  0.0327,  0.0412,  ..., -0.0519,  0.0341,  0.0063],
        [ 0.0144, -0.0110, -0.0528,  ...,  0.0271, -0.0243,  0.0013]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.1016,  0.1797,  1.2412,  ..., -0.9395, -0.6519,  1.1553]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 23:18:52 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of authorized is unauthorized
The opposite of controlled is uncontrolled
The opposite of restricted is unrestricted
The opposite of realistic is unrealistic
The opposite of specified is unspecified
The opposite of predictable is unpredictable
The opposite of published is unpublished
The opposite of comfortable is
2024-07-31 23:18:52 root INFO     [order_1_approx] starting weight calculation for The opposite of authorized is unauthorized
The opposite of realistic is unrealistic
The opposite of comfortable is uncomfortable
The opposite of published is unpublished
The opposite of controlled is uncontrolled
The opposite of predictable is unpredictable
The opposite of specified is unspecified
The opposite of restricted is
2024-07-31 23:18:52 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-07-31 23:21:39 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0325, -0.0110, -0.3765,  ..., -0.1710, -0.0028, -0.0011],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.4619,  0.7617,  2.0645,  ...,  0.9478, -0.8955, -1.2520],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0320, -0.0307, -0.0236,  ..., -0.0032, -0.0374,  0.0147],
        [ 0.0234,  0.0131,  0.0090,  ..., -0.0016, -0.0687,  0.0132],
        [ 0.0080, -0.0320, -0.0007,  ...,  0.0218, -0.0136, -0.0416],
        ...,
        [ 0.0358,  0.0262, -0.0104,  ...,  0.0019,  0.0021,  0.0099],
        [-0.0110, -0.0253,  0.0024,  ...,  0.0273,  0.0359, -0.0084],
        [-0.0461,  0.0006, -0.0210,  ...,  0.0075,  0.0187,  0.0366]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.6445, -0.4492,  1.7842,  ...,  0.3677, -0.6060, -1.4805]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 23:21:40 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of authorized is unauthorized
The opposite of realistic is unrealistic
The opposite of comfortable is uncomfortable
The opposite of published is unpublished
The opposite of controlled is uncontrolled
The opposite of predictable is unpredictable
The opposite of specified is unspecified
The opposite of restricted is
2024-07-31 23:21:40 root INFO     [order_1_approx] starting weight calculation for The opposite of restricted is unrestricted
The opposite of controlled is uncontrolled
The opposite of authorized is unauthorized
The opposite of comfortable is uncomfortable
The opposite of realistic is unrealistic
The opposite of published is unpublished
The opposite of predictable is unpredictable
The opposite of specified is
2024-07-31 23:21:40 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-07-31 23:24:29 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0157,  0.0782, -0.2910,  ..., -0.1849, -0.3503, -0.2537],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.4238,  1.5449,  0.0889,  ...,  2.3223,  0.3223, -0.2178],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0169,  0.0416,  0.0091,  ..., -0.0109,  0.0002, -0.0026],
        [ 0.0409,  0.0042,  0.0334,  ..., -0.0390, -0.0773,  0.0148],
        [-0.0127,  0.0037, -0.0189,  ...,  0.0150,  0.0181,  0.0428],
        ...,
        [ 0.0401, -0.0020, -0.0256,  ..., -0.0623, -0.0274, -0.0443],
        [-0.0069, -0.0066,  0.0552,  ...,  0.0166,  0.0460,  0.0068],
        [-0.0134,  0.0018,  0.0304,  ..., -0.0441, -0.0163,  0.0030]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[1.6973, 1.3438, 0.5908,  ..., 2.4531, 0.0552, 0.2993]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 23:24:30 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of restricted is unrestricted
The opposite of controlled is uncontrolled
The opposite of authorized is unauthorized
The opposite of comfortable is uncomfortable
The opposite of realistic is unrealistic
The opposite of published is unpublished
The opposite of predictable is unpredictable
The opposite of specified is
2024-07-31 23:24:30 root INFO     [order_1_approx] starting weight calculation for The opposite of controlled is uncontrolled
The opposite of authorized is unauthorized
The opposite of restricted is unrestricted
The opposite of predictable is unpredictable
The opposite of comfortable is uncomfortable
The opposite of published is unpublished
The opposite of specified is unspecified
The opposite of realistic is
2024-07-31 23:24:30 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-07-31 23:27:20 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1111,  0.2035, -0.0689,  ..., -0.2404, -0.1511,  0.1392],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.8496, -0.2812, -0.1748,  ..., -2.5742, -1.5205, -1.3848],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 2.8137e-02, -6.6452e-03,  7.0953e-04,  ..., -1.1688e-02,
          8.6899e-03, -2.2507e-03],
        [ 2.3651e-03,  4.8866e-03, -1.9684e-03,  ...,  2.0721e-02,
         -2.5635e-03,  3.6221e-03],
        [ 1.5450e-02, -2.6535e-02,  6.8909e-02,  ...,  1.4687e-02,
         -4.9774e-02,  6.5460e-03],
        ...,
        [ 3.6652e-02,  6.7101e-03,  2.6302e-03,  ..., -2.5574e-02,
          1.5228e-02, -1.6556e-02],
        [-3.4599e-03,  5.7161e-05, -1.4328e-02,  ...,  2.8324e-03,
          1.7822e-02, -2.1942e-02],
        [ 1.1864e-02, -2.4475e-02,  3.4576e-02,  ...,  9.6970e-03,
         -2.1423e-02,  2.0203e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.3730, -0.4800,  0.1179,  ..., -2.2617, -1.8584, -1.2607]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 23:27:21 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of controlled is uncontrolled
The opposite of authorized is unauthorized
The opposite of restricted is unrestricted
The opposite of predictable is unpredictable
The opposite of comfortable is uncomfortable
The opposite of published is unpublished
The opposite of specified is unspecified
The opposite of realistic is
2024-07-31 23:27:21 root INFO     total operator prediction time: 1364.2910397052765 seconds
2024-07-31 23:27:21 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on re+verb_reg
2024-07-31 23:27:21 root INFO     building operator re+verb_reg
2024-07-31 23:27:21 root INFO     [order_1_approx] starting weight calculation for To install again is to reinstall
To create again is to recreate
To cognize again is to recognize
To configure again is to reconfigure
To occur again is to reoccur
To interpret again is to reinterpret
To negotiate again is to renegotiate
To organize again is to
2024-07-31 23:27:21 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-07-31 23:30:12 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1353,  0.4414, -0.0379,  ..., -0.1235, -0.0914,  0.0042],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-2.0859, -3.5664,  1.8584,  ...,  1.5244, -1.5508, -4.2500],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0261, -0.0082,  0.0255,  ..., -0.0063, -0.0036,  0.0023],
        [-0.0130,  0.0205, -0.0065,  ..., -0.0046, -0.0090,  0.0066],
        [ 0.0197,  0.0242,  0.0134,  ..., -0.0015,  0.0098, -0.0108],
        ...,
        [ 0.0057, -0.0019,  0.0023,  ...,  0.0083,  0.0033,  0.0064],
        [-0.0109,  0.0102, -0.0242,  ..., -0.0082,  0.0050, -0.0046],
        [ 0.0085,  0.0007,  0.0037,  ..., -0.0085,  0.0038,  0.0128]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-2.0332, -3.3652,  1.8867,  ...,  1.7451, -1.2734, -4.3633]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 23:30:13 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To install again is to reinstall
To create again is to recreate
To cognize again is to recognize
To configure again is to reconfigure
To occur again is to reoccur
To interpret again is to reinterpret
To negotiate again is to renegotiate
To organize again is to
2024-07-31 23:30:13 root INFO     [order_1_approx] starting weight calculation for To cognize again is to recognize
To negotiate again is to renegotiate
To occur again is to reoccur
To organize again is to reorganize
To install again is to reinstall
To create again is to recreate
To configure again is to reconfigure
To interpret again is to
2024-07-31 23:30:13 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-07-31 23:33:02 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0048,  0.2417,  0.0643,  ...,  0.1477, -0.2136,  0.1660],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.2944, -1.2998,  1.9199,  ...,  0.1694, -2.5391, -4.3750],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 5.7793e-04, -3.5400e-02, -1.8539e-03,  ..., -8.2092e-03,
          2.1088e-02,  1.6739e-02],
        [ 2.0905e-02,  2.9877e-02, -2.2202e-03,  ...,  1.4954e-03,
          8.9188e-03,  5.1575e-03],
        [ 3.5339e-02,  2.5024e-02,  8.7128e-03,  ...,  6.8726e-02,
         -3.0365e-02, -1.1703e-02],
        ...,
        [ 8.9417e-03, -9.0485e-03,  1.3000e-02,  ...,  2.3865e-02,
          2.1027e-02, -4.5776e-05],
        [ 1.0834e-03,  5.5618e-03, -1.0002e-02,  ..., -6.5536e-03,
         -1.1108e-02, -1.6998e-02],
        [-2.3544e-02, -1.2489e-02,  7.1983e-03,  ..., -1.3039e-02,
         -2.3071e-02,  5.3062e-03]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.0093, -1.5840,  1.9766,  ..., -0.4326, -2.2930, -4.3164]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 23:33:03 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To cognize again is to recognize
To negotiate again is to renegotiate
To occur again is to reoccur
To organize again is to reorganize
To install again is to reinstall
To create again is to recreate
To configure again is to reconfigure
To interpret again is to
2024-07-31 23:33:03 root INFO     [order_1_approx] starting weight calculation for To create again is to recreate
To cognize again is to recognize
To install again is to reinstall
To interpret again is to reinterpret
To occur again is to reoccur
To configure again is to reconfigure
To organize again is to reorganize
To negotiate again is to
2024-07-31 23:33:03 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-07-31 23:35:53 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2142,  0.4287, -0.1499,  ..., -0.1868, -0.3022, -0.0172],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.6768, -0.9512,  1.9102,  ..., -0.9492, -4.0000, -3.3789],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0136, -0.0279,  0.0312,  ...,  0.0010, -0.0101,  0.0080],
        [-0.0006,  0.0250,  0.0141,  ...,  0.0033,  0.0139,  0.0031],
        [ 0.0055,  0.0030,  0.0114,  ..., -0.0027, -0.0150, -0.0157],
        ...,
        [-0.0153,  0.0028, -0.0176,  ...,  0.0119,  0.0111,  0.0186],
        [-0.0017, -0.0006, -0.0132,  ...,  0.0070, -0.0070, -0.0046],
        [ 0.0226, -0.0038,  0.0142,  ...,  0.0032, -0.0159, -0.0129]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.9761, -0.6602,  2.2969,  ..., -0.9185, -3.9590, -3.4004]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 23:35:54 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To create again is to recreate
To cognize again is to recognize
To install again is to reinstall
To interpret again is to reinterpret
To occur again is to reoccur
To configure again is to reconfigure
To organize again is to reorganize
To negotiate again is to
2024-07-31 23:35:54 root INFO     [order_1_approx] starting weight calculation for To negotiate again is to renegotiate
To interpret again is to reinterpret
To configure again is to reconfigure
To create again is to recreate
To install again is to reinstall
To organize again is to reorganize
To occur again is to reoccur
To cognize again is to
2024-07-31 23:35:54 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-07-31 23:38:43 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1823,  0.5791, -0.4309,  ..., -0.0588, -0.0567, -0.0247],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-2.1699, -1.0830,  2.6094,  ...,  1.4883, -2.4902, -1.7656],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0527, -0.0124,  0.0151,  ...,  0.0166,  0.0047,  0.0108],
        [ 0.0074, -0.0003, -0.0111,  ..., -0.0072, -0.0003,  0.0074],
        [-0.0158, -0.0184,  0.0303,  ..., -0.0272,  0.0238, -0.0143],
        ...,
        [ 0.0383,  0.0096, -0.0108,  ...,  0.0228, -0.0048,  0.0482],
        [-0.0046,  0.0098, -0.0100,  ..., -0.0142,  0.0018, -0.0148],
        [ 0.0062,  0.0110,  0.0073,  ...,  0.0075, -0.0146, -0.0038]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.7998, -0.8477,  2.3516,  ...,  2.3477, -2.6016, -2.2871]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 23:38:44 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To negotiate again is to renegotiate
To interpret again is to reinterpret
To configure again is to reconfigure
To create again is to recreate
To install again is to reinstall
To organize again is to reorganize
To occur again is to reoccur
To cognize again is to
2024-07-31 23:38:44 root INFO     [order_1_approx] starting weight calculation for To negotiate again is to renegotiate
To cognize again is to recognize
To occur again is to reoccur
To organize again is to reorganize
To install again is to reinstall
To configure again is to reconfigure
To interpret again is to reinterpret
To create again is to
2024-07-31 23:38:44 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-07-31 23:41:32 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0413,  0.1885,  0.0704,  ..., -0.0698, -0.2793, -0.0492],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.7715, -2.8027,  1.4297,  ...,  3.2500, -4.1445, -0.7051],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0313, -0.0293,  0.0046,  ...,  0.0098, -0.0120,  0.0259],
        [-0.0137,  0.0279, -0.0114,  ...,  0.0089,  0.0349,  0.0062],
        [ 0.0042, -0.0002,  0.0259,  ...,  0.0274,  0.0035, -0.0052],
        ...,
        [ 0.0131,  0.0143,  0.0144,  ...,  0.0317,  0.0085, -0.0073],
        [-0.0141,  0.0107,  0.0035,  ..., -0.0479, -0.0013, -0.0131],
        [ 0.0061, -0.0294,  0.0157,  ..., -0.0027, -0.0190,  0.0244]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.7510, -2.5273,  1.8311,  ...,  3.1484, -4.1055, -0.6255]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 23:41:33 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To negotiate again is to renegotiate
To cognize again is to recognize
To occur again is to reoccur
To organize again is to reorganize
To install again is to reinstall
To configure again is to reconfigure
To interpret again is to reinterpret
To create again is to
2024-07-31 23:41:34 root INFO     [order_1_approx] starting weight calculation for To occur again is to reoccur
To create again is to recreate
To negotiate again is to renegotiate
To cognize again is to recognize
To interpret again is to reinterpret
To configure again is to reconfigure
To organize again is to reorganize
To install again is to
2024-07-31 23:41:34 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-07-31 23:44:24 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0113,  0.0589,  0.0351,  ...,  0.0353, -0.1667,  0.1027],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.2406, -3.5527,  1.4932,  ...,  2.2734, -4.8359, -3.7969],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0133, -0.0341,  0.0131,  ...,  0.0075, -0.0022,  0.0316],
        [-0.0051,  0.0450,  0.0065,  ...,  0.0095,  0.0010, -0.0092],
        [ 0.0365,  0.0180,  0.0228,  ...,  0.0048, -0.0451, -0.0343],
        ...,
        [ 0.0141,  0.0167, -0.0101,  ...,  0.0152, -0.0032, -0.0145],
        [-0.0244, -0.0214, -0.0235,  ..., -0.0009,  0.0238,  0.0078],
        [-0.0175, -0.0131, -0.0172,  ...,  0.0055, -0.0280,  0.0083]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.0104, -3.5918,  1.6865,  ...,  2.1797, -4.6133, -4.2656]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 23:44:25 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To occur again is to reoccur
To create again is to recreate
To negotiate again is to renegotiate
To cognize again is to recognize
To interpret again is to reinterpret
To configure again is to reconfigure
To organize again is to reorganize
To install again is to
2024-07-31 23:44:25 root INFO     [order_1_approx] starting weight calculation for To create again is to recreate
To interpret again is to reinterpret
To organize again is to reorganize
To negotiate again is to renegotiate
To install again is to reinstall
To cognize again is to recognize
To configure again is to reconfigure
To occur again is to
2024-07-31 23:44:25 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-07-31 23:47:14 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1788,  0.2280, -0.0673,  ..., -0.3328, -0.2273, -0.2827],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.6484, -2.4336,  2.4160,  ...,  0.8452, -5.0508, -1.2734],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0213, -0.0426,  0.0192,  ..., -0.0221,  0.0091, -0.0017],
        [ 0.0045,  0.0288, -0.0246,  ...,  0.0320, -0.0088, -0.0050],
        [ 0.0413,  0.0104, -0.0009,  ...,  0.0147, -0.0031, -0.0346],
        ...,
        [-0.0061, -0.0309,  0.0085,  ...,  0.0269,  0.0133,  0.0388],
        [ 0.0037,  0.0173, -0.0210,  ..., -0.0662, -0.0092, -0.0343],
        [ 0.0276,  0.0218, -0.0025,  ...,  0.0099, -0.0111,  0.0239]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.3403, -2.4980,  2.4824,  ...,  0.8564, -5.3320, -1.0137]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 23:47:15 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To create again is to recreate
To interpret again is to reinterpret
To organize again is to reorganize
To negotiate again is to renegotiate
To install again is to reinstall
To cognize again is to recognize
To configure again is to reconfigure
To occur again is to
2024-07-31 23:47:15 root INFO     [order_1_approx] starting weight calculation for To occur again is to reoccur
To install again is to reinstall
To organize again is to reorganize
To interpret again is to reinterpret
To create again is to recreate
To cognize again is to recognize
To negotiate again is to renegotiate
To configure again is to
2024-07-31 23:47:15 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-07-31 23:50:06 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1532,  0.1465, -0.1345,  ...,  0.0162, -0.0501, -0.0938],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.4473, -2.7832,  2.4902,  ...,  3.7500, -2.9531, -2.6738],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0233, -0.0180,  0.0120,  ...,  0.0060,  0.0392,  0.0284],
        [-0.0171,  0.0231,  0.0114,  ...,  0.0064,  0.0245,  0.0179],
        [ 0.0142,  0.0318,  0.0172,  ...,  0.0033, -0.0008, -0.0463],
        ...,
        [ 0.0068,  0.0211, -0.0079,  ...,  0.0120, -0.0197, -0.0065],
        [-0.0040,  0.0260,  0.0023,  ..., -0.0223, -0.0399, -0.0219],
        [-0.0312, -0.0004, -0.0163,  ...,  0.0186, -0.0413,  0.0093]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.1309, -2.6719,  2.5137,  ...,  3.7207, -3.1328, -2.8086]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 23:50:07 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To occur again is to reoccur
To install again is to reinstall
To organize again is to reorganize
To interpret again is to reinterpret
To create again is to recreate
To cognize again is to recognize
To negotiate again is to renegotiate
To configure again is to
2024-07-31 23:50:07 root INFO     total operator prediction time: 1366.2471387386322 seconds
2024-07-31 23:50:07 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on adj+ness_reg
2024-07-31 23:50:07 root INFO     building operator adj+ness_reg
2024-07-31 23:50:07 root INFO     [order_1_approx] starting weight calculation for The state of being related is relatedness
The state of being distinctive is distinctiveness
The state of being directed is directedness
The state of being helpful is helpfulness
The state of being attractive is attractiveness
The state of being huge is hugeness
The state of being strange is strangeness
The state of being weak is
2024-07-31 23:50:07 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-07-31 23:52:59 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2034,  0.0278, -0.0574,  ..., -0.1760, -0.0458,  0.0927],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.2051, -4.1562, -1.9199,  ..., -6.0703, -1.8232, -4.7422],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0038,  0.0006,  0.0058,  ..., -0.0300,  0.0066,  0.0140],
        [-0.0114, -0.0193,  0.0063,  ...,  0.0150,  0.0071, -0.0029],
        [-0.0053, -0.0079,  0.0256,  ...,  0.0028, -0.0030,  0.0056],
        ...,
        [ 0.0209,  0.0017,  0.0233,  ..., -0.0017, -0.0275,  0.0237],
        [-0.0054,  0.0247,  0.0058,  ..., -0.0198,  0.0120, -0.0300],
        [ 0.0024, -0.0076,  0.0058,  ...,  0.0362, -0.0207,  0.0106]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.2402, -4.4062, -1.4336,  ..., -6.4375, -2.1758, -4.7148]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 23:53:00 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The state of being related is relatedness
The state of being distinctive is distinctiveness
The state of being directed is directedness
The state of being helpful is helpfulness
The state of being attractive is attractiveness
The state of being huge is hugeness
The state of being strange is strangeness
The state of being weak is
2024-07-31 23:53:00 root INFO     [order_1_approx] starting weight calculation for The state of being directed is directedness
The state of being related is relatedness
The state of being weak is weakness
The state of being strange is strangeness
The state of being huge is hugeness
The state of being attractive is attractiveness
The state of being distinctive is distinctiveness
The state of being helpful is
2024-07-31 23:53:01 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-07-31 23:55:50 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0308, -0.0118,  0.1323,  ...,  0.1097, -0.3281,  0.0139],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.9248, -1.2422, -2.1973,  ...,  1.0508, -5.3672, -2.3516],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0131,  0.0126,  0.0085,  ..., -0.0338,  0.0019, -0.0104],
        [ 0.0009, -0.0005, -0.0067,  ...,  0.0190,  0.0205, -0.0040],
        [-0.0210,  0.0018,  0.0106,  ...,  0.0217, -0.0195, -0.0323],
        ...,
        [ 0.0189,  0.0151, -0.0047,  ...,  0.0034,  0.0070,  0.0178],
        [ 0.0053, -0.0022, -0.0168,  ..., -0.0259,  0.0267,  0.0180],
        [ 0.0043,  0.0057, -0.0043,  ...,  0.0108,  0.0148,  0.0372]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.8516, -0.9336, -2.7812,  ...,  1.2871, -5.6758, -2.4004]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 23:55:51 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The state of being directed is directedness
The state of being related is relatedness
The state of being weak is weakness
The state of being strange is strangeness
The state of being huge is hugeness
The state of being attractive is attractiveness
The state of being distinctive is distinctiveness
The state of being helpful is
2024-07-31 23:55:51 root INFO     [order_1_approx] starting weight calculation for The state of being helpful is helpfulness
The state of being strange is strangeness
The state of being weak is weakness
The state of being attractive is attractiveness
The state of being directed is directedness
The state of being huge is hugeness
The state of being related is relatedness
The state of being distinctive is
2024-07-31 23:55:51 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-07-31 23:58:41 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.3196, -0.0020, -0.0641,  ...,  0.0868,  0.0645,  0.1168],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.2764, -1.4648, -1.0117,  ..., -2.3398, -4.7969, -1.2676],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0128, -0.0042,  0.0146,  ..., -0.0090, -0.0011,  0.0221],
        [-0.0081,  0.0086,  0.0091,  ..., -0.0067,  0.0238, -0.0193],
        [ 0.0150, -0.0106, -0.0047,  ...,  0.0022, -0.0033,  0.0047],
        ...,
        [-0.0064,  0.0099,  0.0032,  ...,  0.0080, -0.0072, -0.0152],
        [-0.0019,  0.0113, -0.0183,  ...,  0.0080, -0.0033,  0.0098],
        [-0.0050,  0.0025,  0.0057,  ...,  0.0122, -0.0077,  0.0076]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.1421, -1.3311, -0.7026,  ..., -2.2520, -4.5859, -1.4336]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 23:58:42 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The state of being helpful is helpfulness
The state of being strange is strangeness
The state of being weak is weakness
The state of being attractive is attractiveness
The state of being directed is directedness
The state of being huge is hugeness
The state of being related is relatedness
The state of being distinctive is
2024-07-31 23:58:42 root INFO     [order_1_approx] starting weight calculation for The state of being distinctive is distinctiveness
The state of being helpful is helpfulness
The state of being attractive is attractiveness
The state of being huge is hugeness
The state of being related is relatedness
The state of being strange is strangeness
The state of being weak is weakness
The state of being directed is
2024-07-31 23:58:42 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-08-01 00:01:35 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2209,  0.1838, -0.1718,  ..., -0.0107, -0.3196,  0.1453],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.2832, -3.5469, -1.6445,  ...,  1.7783, -4.1953, -5.5273],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0053, -0.0154,  0.0130,  ...,  0.0036,  0.0242,  0.0156],
        [-0.0168,  0.0191, -0.0055,  ..., -0.0135,  0.0230,  0.0135],
        [-0.0005,  0.0100,  0.0021,  ..., -0.0084, -0.0297,  0.0240],
        ...,
        [ 0.0158,  0.0189,  0.0159,  ..., -0.0263, -0.0124, -0.0309],
        [-0.0140,  0.0281,  0.0143,  ..., -0.0361,  0.0675, -0.0173],
        [-0.0355, -0.0159, -0.0209,  ...,  0.0006, -0.0283,  0.0890]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.4863, -3.6406, -1.0547,  ...,  1.9561, -3.7090, -5.5312]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 00:01:35 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The state of being distinctive is distinctiveness
The state of being helpful is helpfulness
The state of being attractive is attractiveness
The state of being huge is hugeness
The state of being related is relatedness
The state of being strange is strangeness
The state of being weak is weakness
The state of being directed is
2024-08-01 00:01:36 root INFO     [order_1_approx] starting weight calculation for The state of being related is relatedness
The state of being weak is weakness
The state of being helpful is helpfulness
The state of being distinctive is distinctiveness
The state of being directed is directedness
The state of being strange is strangeness
The state of being attractive is attractiveness
The state of being huge is
2024-08-01 00:01:36 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-08-01 00:04:25 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0596,  0.1719,  0.1138,  ...,  0.1349, -0.2812, -0.1159],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.3320, -3.0176, -1.9258,  ..., -3.4766, -7.9297, -2.4180],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0477, -0.0121,  0.0150,  ..., -0.0184, -0.0114,  0.0287],
        [-0.0562,  0.0019, -0.0152,  ..., -0.0332,  0.0090, -0.0034],
        [-0.0059,  0.0024, -0.0020,  ...,  0.0120, -0.0193,  0.0552],
        ...,
        [-0.0068,  0.0059,  0.0222,  ...,  0.0139,  0.0203,  0.0016],
        [ 0.0473, -0.0028,  0.0139,  ...,  0.0023,  0.0358,  0.0248],
        [-0.0289,  0.0217, -0.0192,  ...,  0.0278, -0.0046,  0.0036]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.0137, -3.2090, -2.1680,  ..., -3.4609, -7.4297, -2.7227]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 00:04:26 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The state of being related is relatedness
The state of being weak is weakness
The state of being helpful is helpfulness
The state of being distinctive is distinctiveness
The state of being directed is directedness
The state of being strange is strangeness
The state of being attractive is attractiveness
The state of being huge is
2024-08-01 00:04:26 root INFO     [order_1_approx] starting weight calculation for The state of being huge is hugeness
The state of being attractive is attractiveness
The state of being strange is strangeness
The state of being weak is weakness
The state of being helpful is helpfulness
The state of being distinctive is distinctiveness
The state of being directed is directedness
The state of being related is
2024-08-01 00:04:26 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-08-01 00:07:17 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2063,  0.1935, -0.2593,  ...,  0.0406, -0.3000,  0.0054],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.7168, -2.1289, -2.1914,  ...,  1.1787, -3.7227, -2.4961],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0158, -0.0084,  0.0044,  ..., -0.0060,  0.0337,  0.0032],
        [-0.0021,  0.0245, -0.0121,  ...,  0.0530,  0.0287,  0.0091],
        [-0.0116,  0.0394,  0.0058,  ...,  0.0060, -0.0209, -0.0039],
        ...,
        [ 0.0109, -0.0008,  0.0085,  ...,  0.0011,  0.0094, -0.0073],
        [ 0.0136,  0.0107,  0.0112,  ..., -0.0670, -0.0080, -0.0175],
        [-0.0097,  0.0009, -0.0219,  ...,  0.0522, -0.0055,  0.0234]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.6919, -1.7197, -1.8066,  ...,  0.8125, -3.8066, -2.6582]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 00:07:18 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The state of being huge is hugeness
The state of being attractive is attractiveness
The state of being strange is strangeness
The state of being weak is weakness
The state of being helpful is helpfulness
The state of being distinctive is distinctiveness
The state of being directed is directedness
The state of being related is
2024-08-01 00:07:18 root INFO     [order_1_approx] starting weight calculation for The state of being directed is directedness
The state of being distinctive is distinctiveness
The state of being attractive is attractiveness
The state of being huge is hugeness
The state of being weak is weakness
The state of being helpful is helpfulness
The state of being related is relatedness
The state of being strange is
2024-08-01 00:07:18 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-08-01 00:10:06 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2186,  0.2075, -0.0533,  ..., -0.1143,  0.0612,  0.0391],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.7300, -2.0781, -2.5723,  ..., -2.7227, -4.6875, -2.0840],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 1.3123e-02, -3.7365e-03, -9.1553e-04,  ..., -3.0457e-02,
         -5.4893e-03,  1.4977e-02],
        [ 6.7711e-03,  9.2773e-03, -2.3918e-03,  ...,  1.6403e-02,
          9.3536e-03, -1.2520e-02],
        [-1.9211e-02, -3.6224e-02,  1.7075e-02,  ..., -2.1400e-03,
         -1.7914e-02,  2.1477e-03],
        ...,
        [-4.2191e-03,  2.4780e-02,  2.2842e-02,  ...,  2.5978e-03,
          9.1553e-05,  6.1569e-03],
        [-1.7715e-02,  4.7089e-02, -1.0834e-02,  ..., -2.2263e-02,
         -4.0894e-03, -2.4658e-02],
        [-2.1286e-03,  8.1635e-04,  5.6038e-03,  ...,  1.7517e-02,
         -2.7634e-02, -2.0691e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.8516, -1.7070, -2.6426,  ..., -2.6211, -5.1445, -2.0098]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 00:10:06 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The state of being directed is directedness
The state of being distinctive is distinctiveness
The state of being attractive is attractiveness
The state of being huge is hugeness
The state of being weak is weakness
The state of being helpful is helpfulness
The state of being related is relatedness
The state of being strange is
2024-08-01 00:10:07 root INFO     [order_1_approx] starting weight calculation for The state of being huge is hugeness
The state of being helpful is helpfulness
The state of being directed is directedness
The state of being weak is weakness
The state of being related is relatedness
The state of being distinctive is distinctiveness
The state of being strange is strangeness
The state of being attractive is
2024-08-01 00:10:07 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-08-01 00:12:54 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0845,  0.1921, -0.1063,  ...,  0.1013,  0.0699, -0.0211],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.2520, -0.6919, -3.4180,  ...,  0.0991, -4.5703, -2.7344],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0103, -0.0052,  0.0006,  ..., -0.0130,  0.0029,  0.0024],
        [ 0.0093,  0.0110, -0.0063,  ...,  0.0002,  0.0059, -0.0088],
        [-0.0072,  0.0061, -0.0040,  ..., -0.0137,  0.0162, -0.0102],
        ...,
        [ 0.0409,  0.0111,  0.0118,  ...,  0.0139, -0.0157, -0.0015],
        [ 0.0005,  0.0027,  0.0023,  ..., -0.0218, -0.0023,  0.0055],
        [-0.0060,  0.0113,  0.0034,  ...,  0.0082,  0.0034,  0.0049]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.2266, -0.6948, -3.2988,  ..., -0.2048, -4.6484, -2.7734]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 00:12:55 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The state of being huge is hugeness
The state of being helpful is helpfulness
The state of being directed is directedness
The state of being weak is weakness
The state of being related is relatedness
The state of being distinctive is distinctiveness
The state of being strange is strangeness
The state of being attractive is
2024-08-01 00:12:55 root INFO     total operator prediction time: 1368.2699043750763 seconds
2024-08-01 00:12:55 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on noun+less_reg
2024-08-01 00:12:55 root INFO     building operator noun+less_reg
2024-08-01 00:12:56 root INFO     [order_1_approx] starting weight calculation for Something without goal is goalless
Something without remorse is remorseless
Something without bone is boneless
Something without hair is hairless
Something without law is lawless
Something without life is lifeless
Something without talent is talentless
Something without meat is
2024-08-01 00:12:56 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-08-01 00:15:40 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0033, -0.2627,  0.2620,  ..., -0.1788, -0.3389,  0.1444],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.6836, -3.6172, -1.4297,  ..., -3.4902, -6.2891, -2.8848],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0215, -0.0253,  0.0066,  ..., -0.0289, -0.0252,  0.0106],
        [ 0.0404,  0.0168,  0.0160,  ..., -0.0068,  0.0174, -0.0023],
        [-0.0027, -0.0150,  0.0165,  ..., -0.0062, -0.0063, -0.0058],
        ...,
        [ 0.0400,  0.0152,  0.0247,  ...,  0.0002,  0.0046, -0.0313],
        [-0.0260, -0.0054, -0.0211,  ...,  0.0015,  0.0424, -0.0102],
        [ 0.0193,  0.0174, -0.0037,  ...,  0.0104,  0.0229, -0.0055]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.3730, -2.9629, -1.5000,  ..., -3.2188, -6.1953, -2.7969]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 00:15:41 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Something without goal is goalless
Something without remorse is remorseless
Something without bone is boneless
Something without hair is hairless
Something without law is lawless
Something without life is lifeless
Something without talent is talentless
Something without meat is
2024-08-01 00:15:41 root INFO     [order_1_approx] starting weight calculation for Something without remorse is remorseless
Something without life is lifeless
Something without talent is talentless
Something without meat is meatless
Something without bone is boneless
Something without law is lawless
Something without goal is goalless
Something without hair is
2024-08-01 00:15:41 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-08-01 00:18:25 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2710, -0.1401, -0.1281,  ...,  0.0382, -0.0056,  0.0999],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.6631, -3.4043, -2.2852,  ..., -2.4961, -3.9258, -1.6406],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0475, -0.0048, -0.0067,  ..., -0.0027, -0.0124, -0.0172],
        [ 0.0024,  0.0028,  0.0053,  ..., -0.0042,  0.0175,  0.0284],
        [-0.0145, -0.0188,  0.0098,  ..., -0.0106,  0.0066, -0.0055],
        ...,
        [-0.0101,  0.0291,  0.0143,  ..., -0.0281,  0.0193, -0.0357],
        [ 0.0035,  0.0101,  0.0008,  ...,  0.0040,  0.0366,  0.0030],
        [ 0.0167, -0.0005, -0.0174,  ..., -0.0057, -0.0107,  0.0098]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.9102, -3.8672, -1.6709,  ..., -2.8828, -4.1484, -1.6289]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 00:18:26 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Something without remorse is remorseless
Something without life is lifeless
Something without talent is talentless
Something without meat is meatless
Something without bone is boneless
Something without law is lawless
Something without goal is goalless
Something without hair is
2024-08-01 00:18:26 root INFO     [order_1_approx] starting weight calculation for Something without goal is goalless
Something without talent is talentless
Something without life is lifeless
Something without bone is boneless
Something without meat is meatless
Something without remorse is remorseless
Something without hair is hairless
Something without law is
2024-08-01 00:18:26 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-08-01 00:21:09 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1173,  0.0142,  0.0330,  ..., -0.2610, -0.1530, -0.1925],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.2756, -3.9258, -0.1973,  ..., -0.5693, -0.7344, -0.5439],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0258, -0.0295,  0.0069,  ..., -0.0160,  0.0073, -0.0030],
        [ 0.0446, -0.0128, -0.0264,  ..., -0.0134,  0.0110, -0.0015],
        [-0.0145, -0.0203,  0.0203,  ..., -0.0207,  0.0112, -0.0138],
        ...,
        [-0.0108,  0.0101,  0.0023,  ..., -0.0309,  0.0166,  0.0034],
        [-0.0231,  0.0289,  0.0115,  ..., -0.0673,  0.0172, -0.0140],
        [-0.0143, -0.0124, -0.0125,  ..., -0.0059, -0.0050, -0.0074]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.3657, -3.2656,  0.1147,  ..., -0.5791, -1.9570, -0.5210]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 00:21:10 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Something without goal is goalless
Something without talent is talentless
Something without life is lifeless
Something without bone is boneless
Something without meat is meatless
Something without remorse is remorseless
Something without hair is hairless
Something without law is
2024-08-01 00:21:10 root INFO     [order_1_approx] starting weight calculation for Something without hair is hairless
Something without goal is goalless
Something without life is lifeless
Something without remorse is remorseless
Something without bone is boneless
Something without law is lawless
Something without meat is meatless
Something without talent is
2024-08-01 00:21:11 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-08-01 00:24:01 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0064, -0.0330,  0.0101,  ..., -0.1663,  0.2778,  0.0216],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.4414, -1.7344,  0.1450,  ..., -3.5254, -4.6484, -2.1895],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0002, -0.0068,  0.0046,  ...,  0.0312, -0.0200,  0.0440],
        [ 0.0586,  0.0309, -0.0193,  ..., -0.0119, -0.0148, -0.0128],
        [-0.0048, -0.0325,  0.0141,  ..., -0.0247,  0.0185, -0.0294],
        ...,
        [ 0.0204,  0.0054,  0.0028,  ..., -0.0627,  0.0093,  0.0039],
        [-0.0505,  0.0272,  0.0194,  ..., -0.0580,  0.0192, -0.0162],
        [ 0.0287, -0.0229, -0.0176,  ..., -0.0896,  0.0274,  0.0051]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.4414, -0.8076, -0.1526,  ..., -2.8145, -4.9805, -1.5078]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 00:24:02 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Something without hair is hairless
Something without goal is goalless
Something without life is lifeless
Something without remorse is remorseless
Something without bone is boneless
Something without law is lawless
Something without meat is meatless
Something without talent is
2024-08-01 00:24:02 root INFO     [order_1_approx] starting weight calculation for Something without talent is talentless
Something without bone is boneless
Something without law is lawless
Something without meat is meatless
Something without hair is hairless
Something without remorse is remorseless
Something without goal is goalless
Something without life is
2024-08-01 00:24:02 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-08-01 00:26:50 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0662, -0.0711, -0.0564,  ..., -0.2878, -0.1108, -0.1926],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.3589, -3.6641, -0.2271,  ..., -3.0840, -2.4531, -0.4111],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0347, -0.0153,  0.0151,  ..., -0.0240,  0.0091,  0.0134],
        [ 0.0257,  0.0144,  0.0013,  ...,  0.0055,  0.0222, -0.0060],
        [ 0.0096, -0.0363,  0.0104,  ..., -0.0364, -0.0163, -0.0065],
        ...,
        [ 0.0341, -0.0042,  0.0007,  ..., -0.0497,  0.0192, -0.0292],
        [ 0.0012,  0.0129,  0.0066,  ..., -0.0284,  0.0140, -0.0317],
        [ 0.0059,  0.0029, -0.0024,  ..., -0.0030,  0.0040, -0.0009]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.6509, -3.6621, -0.0168,  ..., -3.9180, -2.5938, -0.8677]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 00:26:51 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Something without talent is talentless
Something without bone is boneless
Something without law is lawless
Something without meat is meatless
Something without hair is hairless
Something without remorse is remorseless
Something without goal is goalless
Something without life is
2024-08-01 00:26:51 root INFO     [order_1_approx] starting weight calculation for Something without remorse is remorseless
Something without talent is talentless
Something without hair is hairless
Something without life is lifeless
Something without goal is goalless
Something without law is lawless
Something without meat is meatless
Something without bone is
2024-08-01 00:26:51 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-08-01 00:29:39 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3115,  0.0053,  0.0501,  ..., -0.2336, -0.1943,  0.1677],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.0293, -1.8887, -1.3008,  ..., -1.7744, -1.6562, -1.9561],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0411, -0.0316,  0.0250,  ..., -0.0221,  0.0411,  0.0395],
        [-0.0132,  0.0017,  0.0122,  ..., -0.0223,  0.0304, -0.0026],
        [-0.0232, -0.0313,  0.0113,  ..., -0.0034, -0.0005, -0.0195],
        ...,
        [ 0.0367,  0.0309,  0.0021,  ..., -0.0049,  0.0224, -0.0332],
        [-0.0120,  0.0585, -0.0326,  ...,  0.0246, -0.0336, -0.0234],
        [ 0.0005,  0.0277, -0.0076,  ...,  0.0161, -0.0297, -0.0308]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.2450, -1.6924, -0.8555,  ..., -1.8535, -1.5781, -2.0527]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 00:29:40 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Something without remorse is remorseless
Something without talent is talentless
Something without hair is hairless
Something without life is lifeless
Something without goal is goalless
Something without law is lawless
Something without meat is meatless
Something without bone is
2024-08-01 00:29:40 root INFO     [order_1_approx] starting weight calculation for Something without hair is hairless
Something without bone is boneless
Something without goal is goalless
Something without meat is meatless
Something without law is lawless
Something without life is lifeless
Something without talent is talentless
Something without remorse is
2024-08-01 00:29:40 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-08-01 00:32:26 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1392,  0.1646, -0.1344,  ...,  0.1313, -0.2174,  0.1256],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.6914, -3.8164, -1.3242,  ..., -3.6602, -1.7617, -1.6426],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0072,  0.0074,  0.0031,  ..., -0.0093, -0.0060,  0.0053],
        [ 0.0232,  0.0085,  0.0148,  ..., -0.0097,  0.0191, -0.0054],
        [-0.0113,  0.0225,  0.0266,  ..., -0.0215, -0.0141, -0.0226],
        ...,
        [ 0.0110,  0.0143, -0.0077,  ..., -0.0634,  0.0154, -0.0029],
        [-0.0059,  0.0258,  0.0225,  ..., -0.0359, -0.0014, -0.0157],
        [ 0.0167,  0.0058, -0.0057,  ..., -0.0029, -0.0077,  0.0036]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.8086, -3.7422, -1.4639,  ..., -3.8184, -2.1465, -1.9561]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 00:32:27 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Something without hair is hairless
Something without bone is boneless
Something without goal is goalless
Something without meat is meatless
Something without law is lawless
Something without life is lifeless
Something without talent is talentless
Something without remorse is
2024-08-01 00:32:27 root INFO     [order_1_approx] starting weight calculation for Something without life is lifeless
Something without talent is talentless
Something without law is lawless
Something without meat is meatless
Something without bone is boneless
Something without hair is hairless
Something without remorse is remorseless
Something without goal is
2024-08-01 00:32:27 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-08-01 00:35:11 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0155, -0.0417,  0.0098,  ..., -0.1080, -0.1533, -0.0218],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.6035, -2.7461, -2.0020,  ..., -2.4531, -2.0684, -1.7207],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0101,  0.0145,  0.0175,  ..., -0.0164, -0.0039, -0.0091],
        [ 0.0252,  0.0104, -0.0092,  ..., -0.0149,  0.0124, -0.0020],
        [ 0.0045, -0.0018,  0.0159,  ...,  0.0058,  0.0068, -0.0327],
        ...,
        [ 0.0242,  0.0005, -0.0124,  ..., -0.0315,  0.0118,  0.0048],
        [-0.0307,  0.0184,  0.0087,  ..., -0.0153, -0.0067, -0.0291],
        [ 0.0338, -0.0180, -0.0075,  ...,  0.0158,  0.0029,  0.0004]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.7812, -2.0039, -1.8750,  ..., -2.0762, -2.4629, -1.4736]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 00:35:12 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Something without life is lifeless
Something without talent is talentless
Something without law is lawless
Something without meat is meatless
Something without bone is boneless
Something without hair is hairless
Something without remorse is remorseless
Something without goal is
2024-08-01 00:35:12 root INFO     total operator prediction time: 1336.7342216968536 seconds
2024-08-01 00:35:12 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on verb+ment_irreg
2024-08-01 00:35:12 root INFO     building operator verb+ment_irreg
2024-08-01 00:35:12 root INFO     [order_1_approx] starting weight calculation for To advertise results in a advertisement
To establish results in a establishment
To fulfil results in a fulfilment
To enroll results in a enrollment
To reimburse results in a reimbursement
To infringe results in a infringement
To amuse results in a amusement
To disappoint results in a
2024-08-01 00:35:12 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-08-01 00:38:00 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0991,  0.5942, -0.1863,  ...,  0.0012, -0.1786, -0.0642],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.6270, -4.7734,  2.0566,  ...,  1.2988,  2.0352, -1.2656],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0013, -0.0287, -0.0051,  ...,  0.0227,  0.0103,  0.0012],
        [-0.0331,  0.0436,  0.0056,  ...,  0.0167,  0.0434,  0.0451],
        [ 0.0193, -0.0583, -0.0469,  ...,  0.0261, -0.0009, -0.0260],
        ...,
        [ 0.0366, -0.0095,  0.0018,  ..., -0.0029,  0.0128,  0.0183],
        [-0.0062, -0.0179,  0.0247,  ..., -0.0114,  0.0126, -0.0533],
        [ 0.0257,  0.0027,  0.0045,  ..., -0.0085, -0.0677, -0.0141]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.0469, -4.7539,  1.9854,  ...,  1.3389,  1.6631, -1.3750]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 00:38:01 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To advertise results in a advertisement
To establish results in a establishment
To fulfil results in a fulfilment
To enroll results in a enrollment
To reimburse results in a reimbursement
To infringe results in a infringement
To amuse results in a amusement
To disappoint results in a
2024-08-01 00:38:01 root INFO     [order_1_approx] starting weight calculation for To infringe results in a infringement
To enroll results in a enrollment
To fulfil results in a fulfilment
To reimburse results in a reimbursement
To disappoint results in a disappointment
To advertise results in a advertisement
To establish results in a establishment
To amuse results in a
2024-08-01 00:38:01 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-08-01 00:40:51 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1152,  0.3511, -0.1274,  ...,  0.0696, -0.1898,  0.0387],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.9609, -1.8828,  0.2456,  ...,  1.9980, -0.6738, -0.9819],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0042, -0.0316,  0.0373,  ..., -0.0049,  0.0638,  0.0316],
        [-0.0066, -0.0040,  0.0158,  ..., -0.0238, -0.0677,  0.0175],
        [ 0.0017, -0.0387, -0.0115,  ...,  0.0494,  0.0327,  0.0041],
        ...,
        [ 0.0292, -0.0210, -0.0092,  ..., -0.0130, -0.0029, -0.0060],
        [ 0.0360,  0.0427,  0.0596,  ..., -0.0349, -0.0461,  0.0118],
        [ 0.0299,  0.0295,  0.0158,  ...,  0.0132, -0.0570, -0.0031]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.6953, -1.3232, -0.7109,  ...,  3.1602, -0.5928, -0.7822]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 00:40:52 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To infringe results in a infringement
To enroll results in a enrollment
To fulfil results in a fulfilment
To reimburse results in a reimbursement
To disappoint results in a disappointment
To advertise results in a advertisement
To establish results in a establishment
To amuse results in a
2024-08-01 00:40:52 root INFO     [order_1_approx] starting weight calculation for To reimburse results in a reimbursement
To disappoint results in a disappointment
To amuse results in a amusement
To fulfil results in a fulfilment
To infringe results in a infringement
To advertise results in a advertisement
To enroll results in a enrollment
To establish results in a
2024-08-01 00:40:52 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-08-01 00:43:42 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1694,  0.2837, -0.1855,  ...,  0.0313, -0.2343,  0.0367],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.7109, -5.1250, -0.1924,  ...,  3.5137, -3.3965,  0.2354],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0132, -0.0251,  0.0184,  ..., -0.0009, -0.0448,  0.0098],
        [ 0.0077,  0.0472,  0.0181,  ..., -0.0247,  0.0023,  0.0158],
        [ 0.0285, -0.0382,  0.0272,  ...,  0.0042,  0.0104,  0.0019],
        ...,
        [ 0.0035, -0.0223, -0.0437,  ...,  0.0082,  0.0363,  0.0372],
        [ 0.0161,  0.0200,  0.0545,  ...,  0.0074,  0.0063,  0.0364],
        [ 0.0162,  0.0063, -0.0110,  ...,  0.0068, -0.0191, -0.0016]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.5513, -5.5078, -0.0876,  ...,  3.4395, -4.5234, -0.1765]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 00:43:43 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To reimburse results in a reimbursement
To disappoint results in a disappointment
To amuse results in a amusement
To fulfil results in a fulfilment
To infringe results in a infringement
To advertise results in a advertisement
To enroll results in a enrollment
To establish results in a
2024-08-01 00:43:43 root INFO     [order_1_approx] starting weight calculation for To enroll results in a enrollment
To disappoint results in a disappointment
To establish results in a establishment
To fulfil results in a fulfilment
To reimburse results in a reimbursement
To amuse results in a amusement
To advertise results in a advertisement
To infringe results in a
2024-08-01 00:43:43 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-08-01 00:46:34 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1764,  0.3457, -0.2307,  ...,  0.1486, -0.1990,  0.0707],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.2246, -7.2578,  0.9600,  ...,  1.9502, -1.8242,  0.2217],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0004, -0.0059,  0.0103,  ..., -0.0353,  0.0192,  0.0220],
        [-0.0276,  0.0239, -0.0180,  ...,  0.0043,  0.0645,  0.0476],
        [-0.0046, -0.0295, -0.0130,  ...,  0.0130,  0.0172, -0.0170],
        ...,
        [ 0.0065,  0.0068, -0.0141,  ...,  0.0216,  0.0074,  0.0089],
        [ 0.0177,  0.0222,  0.0339,  ...,  0.0006,  0.0211, -0.0269],
        [ 0.0022, -0.0063, -0.0060,  ...,  0.0155, -0.0642, -0.0115]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.6738, -7.3477,  1.0723,  ...,  1.7402, -1.9902, -0.1023]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 00:46:35 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To enroll results in a enrollment
To disappoint results in a disappointment
To establish results in a establishment
To fulfil results in a fulfilment
To reimburse results in a reimbursement
To amuse results in a amusement
To advertise results in a advertisement
To infringe results in a
2024-08-01 00:46:35 root INFO     [order_1_approx] starting weight calculation for To enroll results in a enrollment
To disappoint results in a disappointment
To amuse results in a amusement
To fulfil results in a fulfilment
To establish results in a establishment
To reimburse results in a reimbursement
To infringe results in a infringement
To advertise results in a
2024-08-01 00:46:35 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-08-01 00:49:25 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2063,  0.2705, -0.0618,  ...,  0.0048, -0.1240, -0.0576],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.4258, -2.8027,  0.5625,  ...,  3.4551, -3.2051, -1.0693],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0198, -0.0160,  0.0179,  ..., -0.0208, -0.0408,  0.0290],
        [ 0.0143, -0.0061,  0.0110,  ...,  0.0040,  0.0608, -0.0145],
        [ 0.0175, -0.0264, -0.0170,  ...,  0.0150,  0.0031, -0.0138],
        ...,
        [ 0.0065,  0.0403,  0.0206,  ...,  0.0166, -0.0612,  0.0221],
        [ 0.0105,  0.0096, -0.0048,  ...,  0.0014,  0.0068, -0.0042],
        [-0.0087, -0.0133,  0.0388,  ..., -0.0044, -0.0164,  0.0431]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.1191, -3.1797,  0.0083,  ...,  3.7051, -3.0254, -1.4043]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 00:49:26 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To enroll results in a enrollment
To disappoint results in a disappointment
To amuse results in a amusement
To fulfil results in a fulfilment
To establish results in a establishment
To reimburse results in a reimbursement
To infringe results in a infringement
To advertise results in a
2024-08-01 00:49:26 root INFO     [order_1_approx] starting weight calculation for To amuse results in a amusement
To establish results in a establishment
To enroll results in a enrollment
To fulfil results in a fulfilment
To disappoint results in a disappointment
To advertise results in a advertisement
To infringe results in a infringement
To reimburse results in a
2024-08-01 00:49:26 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-08-01 00:52:16 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3228,  0.2433, -0.3420,  ...,  0.1304, -0.1027, -0.1946],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.7988, -4.0352, -0.7607,  ..., -0.7617, -2.4219, -1.6689],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0200, -0.0346,  0.0179,  ..., -0.0155, -0.0088,  0.0105],
        [-0.0153,  0.0363,  0.0245,  ...,  0.0084,  0.0488,  0.0224],
        [-0.0027, -0.0235,  0.0195,  ..., -0.0176,  0.0329, -0.0133],
        ...,
        [ 0.0548,  0.0355,  0.0133,  ...,  0.0274,  0.0221,  0.0235],
        [ 0.0038,  0.0028,  0.0070,  ..., -0.0255,  0.0343,  0.0154],
        [ 0.0280, -0.0039, -0.0113,  ...,  0.0144, -0.0422,  0.0393]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.8115, -4.5664, -1.0430,  ..., -0.6479, -2.7520, -1.7842]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 00:52:17 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To amuse results in a amusement
To establish results in a establishment
To enroll results in a enrollment
To fulfil results in a fulfilment
To disappoint results in a disappointment
To advertise results in a advertisement
To infringe results in a infringement
To reimburse results in a
2024-08-01 00:52:17 root INFO     [order_1_approx] starting weight calculation for To fulfil results in a fulfilment
To reimburse results in a reimbursement
To advertise results in a advertisement
To establish results in a establishment
To amuse results in a amusement
To disappoint results in a disappointment
To infringe results in a infringement
To enroll results in a
2024-08-01 00:52:17 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-08-01 00:55:02 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1067,  0.2288, -0.1530,  ...,  0.0630,  0.0091, -0.3220],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.5278, -3.3223, -0.4121,  ...,  2.3672, -0.2964, -4.3711],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0339, -0.0431,  0.0365,  ..., -0.0083,  0.0239,  0.0291],
        [-0.0162,  0.0314,  0.0246,  ...,  0.0220,  0.0175,  0.0036],
        [-0.0102, -0.0667,  0.0180,  ..., -0.0250,  0.0085, -0.0293],
        ...,
        [ 0.0347,  0.0312,  0.0139,  ...,  0.0266, -0.0079,  0.0085],
        [-0.0106,  0.0334,  0.0162,  ..., -0.0067,  0.0171,  0.0058],
        [-0.0135, -0.0444,  0.0272,  ...,  0.0378, -0.0176,  0.0498]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.0229, -3.4316, -0.4473,  ...,  2.1582, -0.1295, -4.4883]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 00:55:03 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To fulfil results in a fulfilment
To reimburse results in a reimbursement
To advertise results in a advertisement
To establish results in a establishment
To amuse results in a amusement
To disappoint results in a disappointment
To infringe results in a infringement
To enroll results in a
2024-08-01 00:55:03 root INFO     [order_1_approx] starting weight calculation for To establish results in a establishment
To disappoint results in a disappointment
To enroll results in a enrollment
To reimburse results in a reimbursement
To amuse results in a amusement
To advertise results in a advertisement
To infringe results in a infringement
To fulfil results in a
2024-08-01 00:55:03 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-08-01 00:57:48 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0350,  0.4561, -0.1807,  ..., -0.0262, -0.4204,  0.2915],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.8984, -4.0820,  3.1406,  ...,  1.4609, -4.4141, -1.2822],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0217, -0.0306, -0.0068,  ..., -0.0101, -0.0053,  0.0010],
        [-0.0454,  0.0114,  0.0125,  ..., -0.0156,  0.0375,  0.0198],
        [ 0.0076, -0.0191, -0.0170,  ..., -0.0013, -0.0113, -0.0174],
        ...,
        [ 0.0326, -0.0144,  0.0320,  ...,  0.0334,  0.0136,  0.0255],
        [-0.0107,  0.0396,  0.0336,  ..., -0.0206,  0.0144,  0.0070],
        [-0.0115, -0.0169,  0.0028,  ..., -0.0086,  0.0111,  0.0611]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 5.1914, -3.7695,  2.8281,  ...,  1.1016, -4.1758, -1.0273]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 00:57:49 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To establish results in a establishment
To disappoint results in a disappointment
To enroll results in a enrollment
To reimburse results in a reimbursement
To amuse results in a amusement
To advertise results in a advertisement
To infringe results in a infringement
To fulfil results in a
2024-08-01 00:57:49 root INFO     total operator prediction time: 1357.1998052597046 seconds
2024-08-01 00:57:49 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on name - nationality
2024-08-01 00:57:49 root INFO     building operator name - nationality
2024-08-01 00:57:50 root INFO     [order_1_approx] starting weight calculation for strauss was austrian
tolstoi was russian
maxwell was scottish
truman was american
napoleon was french
descartes was french
hegel was german
marx was
2024-08-01 00:57:50 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-08-01 01:00:39 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0505,  0.0946, -0.1266,  ...,  0.0636,  0.1931,  0.0950],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.7188, -5.8867,  0.1104,  ..., -4.3906,  1.6836, -2.0039],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0622, -0.0229,  0.0070,  ..., -0.0597, -0.0223,  0.0047],
        [ 0.0354, -0.0052,  0.0238,  ..., -0.0242, -0.0250,  0.0153],
        [-0.0245,  0.0191,  0.0443,  ...,  0.0015, -0.0006,  0.0002],
        ...,
        [ 0.0451, -0.0439,  0.0714,  ...,  0.0345, -0.0017,  0.0590],
        [-0.0090, -0.0245, -0.0016,  ...,  0.0382,  0.0097,  0.0123],
        [-0.0030,  0.0138,  0.0101,  ...,  0.0274, -0.0186,  0.0369]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.4248, -5.3398,  0.6338,  ..., -4.2773,  1.6406, -1.5713]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 01:00:40 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for strauss was austrian
tolstoi was russian
maxwell was scottish
truman was american
napoleon was french
descartes was french
hegel was german
marx was
2024-08-01 01:00:40 root INFO     [order_1_approx] starting weight calculation for descartes was french
strauss was austrian
hegel was german
tolstoi was russian
maxwell was scottish
truman was american
marx was german
napoleon was
2024-08-01 01:00:40 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-08-01 01:03:29 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1836,  0.0712, -0.1584,  ..., -0.0126,  0.0254,  0.2114],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.1934, -4.8516, -0.1685,  ..., -1.1152, -0.1143, -0.3599],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0392,  0.0048, -0.0203,  ..., -0.0056,  0.0403, -0.0558],
        [-0.0362,  0.0276,  0.0222,  ..., -0.0120, -0.0401,  0.0627],
        [-0.0074, -0.0246,  0.0222,  ...,  0.0156,  0.0385, -0.0392],
        ...,
        [ 0.0085, -0.0039,  0.0304,  ...,  0.0170, -0.0485,  0.0489],
        [-0.0103, -0.0167,  0.0168,  ...,  0.0120,  0.0283,  0.0193],
        [-0.0188, -0.0248,  0.0005,  ..., -0.0043, -0.0314,  0.0519]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.8496, -4.2773, -0.3091,  ..., -1.0029, -0.1720, -0.1782]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 01:03:29 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for descartes was french
strauss was austrian
hegel was german
tolstoi was russian
maxwell was scottish
truman was american
marx was german
napoleon was
2024-08-01 01:03:30 root INFO     [order_1_approx] starting weight calculation for marx was german
hegel was german
strauss was austrian
tolstoi was russian
maxwell was scottish
napoleon was french
descartes was french
truman was
2024-08-01 01:03:30 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-08-01 01:06:14 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1052,  0.1050, -0.4180,  ..., -0.0513, -0.2220,  0.1602],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.1133, -2.2246,  0.3982,  ..., -3.0137,  2.5742,  0.1243],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0027, -0.0003, -0.0068,  ..., -0.0194,  0.0152,  0.0092],
        [-0.0387,  0.0527, -0.0006,  ...,  0.0316, -0.0035,  0.0094],
        [-0.0446, -0.0063,  0.0247,  ..., -0.0089, -0.0235,  0.0208],
        ...,
        [ 0.0188,  0.0310, -0.0032,  ...,  0.0722,  0.0024,  0.0117],
        [-0.0135, -0.0137,  0.0205,  ...,  0.0395,  0.0229,  0.0155],
        [-0.0439,  0.0380, -0.0094,  ...,  0.0317, -0.0249,  0.0453]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.6660, -2.0586,  0.2942,  ..., -3.1504,  2.6484,  0.5693]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 01:06:15 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for marx was german
hegel was german
strauss was austrian
tolstoi was russian
maxwell was scottish
napoleon was french
descartes was french
truman was
2024-08-01 01:06:15 root INFO     [order_1_approx] starting weight calculation for truman was american
tolstoi was russian
hegel was german
maxwell was scottish
marx was german
napoleon was french
descartes was french
strauss was
2024-08-01 01:06:15 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-08-01 01:09:04 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1608, -0.0373, -0.0318,  ...,  0.0599, -0.1481,  0.0746],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.4680, -5.6484, -0.3262,  ..., -3.4668, -0.6143, -1.4717],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0747,  0.0146, -0.0080,  ..., -0.0138,  0.0128, -0.0104],
        [-0.0017,  0.0421,  0.0126,  ...,  0.0098, -0.0439, -0.0060],
        [ 0.0014,  0.0086,  0.0298,  ...,  0.0020, -0.0165,  0.0085],
        ...,
        [ 0.0043,  0.0228,  0.0170,  ...,  0.0641,  0.0250, -0.0142],
        [ 0.0435, -0.0249, -0.0014,  ...,  0.0382,  0.0452, -0.0135],
        [-0.0128,  0.0061, -0.0215,  ..., -0.0034, -0.0745,  0.0502]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.3943, -5.1250, -0.5264,  ..., -2.9219, -0.9746, -0.5225]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 01:09:05 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for truman was american
tolstoi was russian
hegel was german
maxwell was scottish
marx was german
napoleon was french
descartes was french
strauss was
2024-08-01 01:09:05 root INFO     [order_1_approx] starting weight calculation for truman was american
hegel was german
napoleon was french
maxwell was scottish
marx was german
descartes was french
strauss was austrian
tolstoi was
2024-08-01 01:09:05 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-08-01 01:11:56 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2661,  0.3030, -0.5107,  ..., -0.3171, -0.1294, -0.0097],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.9307, -4.1641,  0.5376,  ..., -6.5820, -0.4697, -1.7666],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0173,  0.0063,  0.0141,  ..., -0.0099, -0.0235,  0.0019],
        [ 0.0242, -0.0116,  0.0167,  ...,  0.0192,  0.0152,  0.0251],
        [-0.0074,  0.0518,  0.0292,  ...,  0.0089, -0.0300, -0.0009],
        ...,
        [ 0.0356, -0.0388,  0.0143,  ...,  0.0539,  0.0128,  0.0493],
        [ 0.0021, -0.0356,  0.0023,  ...,  0.0136,  0.0314,  0.0082],
        [ 0.0049,  0.0162, -0.0012,  ...,  0.0015, -0.0100,  0.0245]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.3340, -3.9316,  0.4734,  ..., -6.4492, -0.8730, -1.6553]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 01:11:57 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for truman was american
hegel was german
napoleon was french
maxwell was scottish
marx was german
descartes was french
strauss was austrian
tolstoi was
2024-08-01 01:11:57 root INFO     [order_1_approx] starting weight calculation for tolstoi was russian
hegel was german
marx was german
napoleon was french
maxwell was scottish
truman was american
strauss was austrian
descartes was
2024-08-01 01:11:57 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-08-01 01:14:48 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0344,  0.1155, -0.2583,  ..., -0.1653, -0.0645,  0.0851],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 5.2617, -4.0859,  1.8535,  ..., -5.0352, -1.3564,  0.5381],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0536,  0.0017, -0.0320,  ..., -0.0073,  0.0117, -0.0096],
        [ 0.0084,  0.0352,  0.0259,  ...,  0.0019,  0.0018, -0.0110],
        [-0.0276, -0.0090,  0.0350,  ..., -0.0077,  0.0175, -0.0053],
        ...,
        [ 0.0407,  0.0190, -0.0221,  ...,  0.0648, -0.0175,  0.0631],
        [-0.0096, -0.0139,  0.0132,  ...,  0.0162,  0.0168, -0.0195],
        [-0.0155, -0.0039,  0.0034,  ...,  0.0058, -0.0025, -0.0070]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 5.7500, -3.6289,  1.2188,  ..., -4.0430, -1.2441,  0.0073]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 01:14:49 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for tolstoi was russian
hegel was german
marx was german
napoleon was french
maxwell was scottish
truman was american
strauss was austrian
descartes was
2024-08-01 01:14:49 root INFO     [order_1_approx] starting weight calculation for tolstoi was russian
descartes was french
marx was german
truman was american
napoleon was french
strauss was austrian
maxwell was scottish
hegel was
2024-08-01 01:14:49 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-08-01 01:17:40 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1858,  0.2639, -0.0796,  ..., -0.0509,  0.1816,  0.2382],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.9229, -5.1836,  1.2764,  ..., -2.2207, -1.4453, -0.0588],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0040, -0.0042,  0.0163,  ...,  0.0056, -0.0161,  0.0044],
        [ 0.0122, -0.0030,  0.0034,  ..., -0.0216,  0.0176, -0.0020],
        [-0.0155, -0.0081,  0.0305,  ..., -0.0129, -0.0161,  0.0026],
        ...,
        [ 0.0166, -0.0030,  0.0238,  ...,  0.0393, -0.0313,  0.0094],
        [ 0.0345,  0.0036,  0.0059,  ...,  0.0263, -0.0157, -0.0178],
        [-0.0187, -0.0016, -0.0222,  ...,  0.0202,  0.0051,  0.0240]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.2031, -5.2383,  1.6357,  ..., -1.8320, -1.2197, -0.1793]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 01:17:41 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for tolstoi was russian
descartes was french
marx was german
truman was american
napoleon was french
strauss was austrian
maxwell was scottish
hegel was
2024-08-01 01:17:41 root INFO     [order_1_approx] starting weight calculation for descartes was french
truman was american
hegel was german
strauss was austrian
napoleon was french
marx was german
tolstoi was russian
maxwell was
2024-08-01 01:17:41 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-08-01 01:20:27 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0193, -0.0277, -0.0018,  ...,  0.0097, -0.0881,  0.0118],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.4121, -3.1562, -0.4695,  ..., -3.4160, -0.5234, -2.3906],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 4.7638e-02, -7.8003e-02,  2.8473e-02,  ..., -1.1902e-01,
         -2.8229e-03, -1.7487e-02],
        [-1.7029e-02,  9.7107e-02,  3.8147e-05,  ...,  1.6479e-02,
         -2.2064e-02,  4.4647e-02],
        [ 2.0798e-02,  1.3435e-02,  2.3087e-02,  ..., -2.2736e-02,
         -1.7380e-02,  1.4687e-02],
        ...,
        [ 3.1952e-02, -1.1734e-02, -1.9226e-02,  ...,  3.0045e-02,
          9.3460e-03,  1.0704e-02],
        [-2.1637e-02, -2.0638e-03,  7.3051e-03,  ...,  3.9795e-02,
         -3.6926e-03, -5.4588e-03],
        [-1.9516e-02,  5.7404e-02, -3.7537e-02,  ...,  3.6377e-02,
         -3.8300e-02,  6.9946e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.1445, -2.5391, -0.3953,  ..., -2.4258, -0.4878, -1.6768]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 01:20:28 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for descartes was french
truman was american
hegel was german
strauss was austrian
napoleon was french
marx was german
tolstoi was russian
maxwell was
2024-08-01 01:20:28 root INFO     total operator prediction time: 1358.7684528827667 seconds
2024-08-01 01:20:28 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on country - language
2024-08-01 01:20:28 root INFO     building operator country - language
2024-08-01 01:20:28 root INFO     [order_1_approx] starting weight calculation for The country of bahamas primarily speaks the language of english
The country of guyana primarily speaks the language of english
The country of jordan primarily speaks the language of arabic
The country of cuba primarily speaks the language of spanish
The country of philippines primarily speaks the language of tagalog
The country of kuwait primarily speaks the language of arabic
The country of kosovo primarily speaks the language of albanian
The country of moldova primarily speaks the language of
2024-08-01 01:20:28 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-08-01 01:23:15 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3279, -0.3057, -0.2505,  ...,  0.0201, -0.3594, -0.0643],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-2.4785, -4.8242, -0.2424,  ..., -4.2852, -0.8779, -1.3369],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0068,  0.0035,  0.0179,  ..., -0.0030,  0.0127, -0.0179],
        [ 0.0113,  0.0178,  0.0248,  ..., -0.0022,  0.0082, -0.0082],
        [-0.0027, -0.0123,  0.0063,  ...,  0.0009, -0.0131, -0.0145],
        ...,
        [ 0.0168,  0.0042, -0.0210,  ...,  0.0156,  0.0200, -0.0086],
        [-0.0203,  0.0117,  0.0255,  ..., -0.0128,  0.0089,  0.0049],
        [ 0.0016, -0.0233, -0.0018,  ..., -0.0004, -0.0121, -0.0057]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-2.5293, -4.7539, -0.4697,  ..., -4.5391, -0.4956, -1.1826]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 01:23:15 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country of bahamas primarily speaks the language of english
The country of guyana primarily speaks the language of english
The country of jordan primarily speaks the language of arabic
The country of cuba primarily speaks the language of spanish
The country of philippines primarily speaks the language of tagalog
The country of kuwait primarily speaks the language of arabic
The country of kosovo primarily speaks the language of albanian
The country of moldova primarily speaks the language of
2024-08-01 01:23:16 root INFO     [order_1_approx] starting weight calculation for The country of cuba primarily speaks the language of spanish
The country of philippines primarily speaks the language of tagalog
The country of kosovo primarily speaks the language of albanian
The country of bahamas primarily speaks the language of english
The country of jordan primarily speaks the language of arabic
The country of moldova primarily speaks the language of moldovan
The country of guyana primarily speaks the language of english
The country of kuwait primarily speaks the language of
2024-08-01 01:23:16 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-08-01 01:26:04 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0645, -0.2023, -0.3914,  ...,  0.2610, -0.2996,  0.2842],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.7197, -2.5898,  0.0854,  ...,  0.3296,  0.2339, -1.1650],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0179, -0.0238,  0.0217,  ...,  0.0021, -0.0163,  0.0134],
        [-0.0013,  0.0007,  0.0103,  ...,  0.0003, -0.0160,  0.0115],
        [-0.0238,  0.0269,  0.0141,  ...,  0.0050,  0.0113, -0.0143],
        ...,
        [-0.0055,  0.0211, -0.0032,  ...,  0.0315,  0.0228, -0.0116],
        [ 0.0055, -0.0246,  0.0157,  ...,  0.0228,  0.0125, -0.0051],
        [ 0.0206, -0.0231,  0.0080,  ..., -0.0034, -0.0016,  0.0092]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.1787e+00, -2.1250e+00, -1.9995e-01,  ...,  1.9531e-03,
          3.2764e-01, -1.0596e+00]], device='cuda:1', dtype=torch.float16,
       grad_fn=<SubBackward0>) 

                    
2024-08-01 01:26:05 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country of cuba primarily speaks the language of spanish
The country of philippines primarily speaks the language of tagalog
The country of kosovo primarily speaks the language of albanian
The country of bahamas primarily speaks the language of english
The country of jordan primarily speaks the language of arabic
The country of moldova primarily speaks the language of moldovan
The country of guyana primarily speaks the language of english
The country of kuwait primarily speaks the language of
2024-08-01 01:26:06 root INFO     [order_1_approx] starting weight calculation for The country of jordan primarily speaks the language of arabic
The country of kosovo primarily speaks the language of albanian
The country of cuba primarily speaks the language of spanish
The country of kuwait primarily speaks the language of arabic
The country of bahamas primarily speaks the language of english
The country of moldova primarily speaks the language of moldovan
The country of philippines primarily speaks the language of tagalog
The country of guyana primarily speaks the language of
2024-08-01 01:26:06 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-08-01 01:28:55 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1663, -0.0158,  0.0230,  ...,  0.0639, -0.3918, -0.0820],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.7510, -0.0840,  1.6797,  ...,  0.9517,  0.3711, -3.1523],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0053,  0.0195,  0.0068,  ...,  0.0124, -0.0013,  0.0079],
        [-0.0129,  0.0230, -0.0138,  ...,  0.0043, -0.0170, -0.0199],
        [-0.0061,  0.0246,  0.0314,  ..., -0.0338, -0.0003, -0.0208],
        ...,
        [ 0.0095, -0.0168, -0.0121,  ...,  0.0483, -0.0242, -0.0406],
        [-0.0076,  0.0321, -0.0132,  ..., -0.0114,  0.0172,  0.0049],
        [ 0.0224, -0.0192, -0.0145,  ..., -0.0061,  0.0191,  0.0300]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.7178e+00, -2.0752e-03,  2.1250e+00,  ...,  5.3662e-01,
          8.6670e-02, -2.9980e+00]], device='cuda:1', dtype=torch.float16,
       grad_fn=<SubBackward0>) 

                    
2024-08-01 01:28:56 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country of jordan primarily speaks the language of arabic
The country of kosovo primarily speaks the language of albanian
The country of cuba primarily speaks the language of spanish
The country of kuwait primarily speaks the language of arabic
The country of bahamas primarily speaks the language of english
The country of moldova primarily speaks the language of moldovan
The country of philippines primarily speaks the language of tagalog
The country of guyana primarily speaks the language of
2024-08-01 01:28:57 root INFO     [order_1_approx] starting weight calculation for The country of bahamas primarily speaks the language of english
The country of jordan primarily speaks the language of arabic
The country of cuba primarily speaks the language of spanish
The country of kuwait primarily speaks the language of arabic
The country of moldova primarily speaks the language of moldovan
The country of kosovo primarily speaks the language of albanian
The country of guyana primarily speaks the language of english
The country of philippines primarily speaks the language of
2024-08-01 01:28:57 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-08-01 01:31:44 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0034,  0.0096, -0.4072,  ...,  0.3267, -0.3608, -0.0168],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.3223, -1.4941,  1.6758,  ..., -0.6274, -2.0586, -1.8730],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0433, -0.0235,  0.0208,  ..., -0.0002, -0.0023,  0.0229],
        [ 0.0172,  0.0058,  0.0179,  ...,  0.0029, -0.0139,  0.0170],
        [-0.0540,  0.0551, -0.0156,  ..., -0.0171,  0.0159, -0.0177],
        ...,
        [-0.0234,  0.0208, -0.0267,  ...,  0.0035,  0.0148, -0.0082],
        [ 0.0201, -0.0346,  0.0286,  ...,  0.0290, -0.0001,  0.0055],
        [ 0.0282, -0.0187,  0.0110,  ...,  0.0092, -0.0043,  0.0240]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.4727, -1.1963,  1.7158,  ..., -0.7676, -2.1465, -1.5605]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 01:31:45 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country of bahamas primarily speaks the language of english
The country of jordan primarily speaks the language of arabic
The country of cuba primarily speaks the language of spanish
The country of kuwait primarily speaks the language of arabic
The country of moldova primarily speaks the language of moldovan
The country of kosovo primarily speaks the language of albanian
The country of guyana primarily speaks the language of english
The country of philippines primarily speaks the language of
2024-08-01 01:31:45 root INFO     [order_1_approx] starting weight calculation for The country of guyana primarily speaks the language of english
The country of jordan primarily speaks the language of arabic
The country of cuba primarily speaks the language of spanish
The country of philippines primarily speaks the language of tagalog
The country of kosovo primarily speaks the language of albanian
The country of kuwait primarily speaks the language of arabic
The country of moldova primarily speaks the language of moldovan
The country of bahamas primarily speaks the language of
2024-08-01 01:31:45 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-08-01 01:34:31 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1523,  0.1066, -0.0545,  ..., -0.1392, -0.3831, -0.1375],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.7227, -0.6499,  2.4277,  ...,  1.2451,  1.1973, -2.5332],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0262, -0.0044,  0.0295,  ..., -0.0309, -0.0153,  0.0154],
        [-0.0026,  0.0011,  0.0039,  ..., -0.0050, -0.0106,  0.0038],
        [-0.0134, -0.0029,  0.0125,  ..., -0.0057,  0.0118,  0.0042],
        ...,
        [-0.0590, -0.0091, -0.0198,  ...,  0.0134,  0.0112,  0.0011],
        [-0.0089,  0.0074,  0.0180,  ...,  0.0150,  0.0071,  0.0113],
        [ 0.0376,  0.0047,  0.0205,  ...,  0.0007, -0.0218,  0.0170]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.9531, -0.4121,  2.3301,  ...,  1.0859,  1.1953, -2.2910]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 01:34:32 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country of guyana primarily speaks the language of english
The country of jordan primarily speaks the language of arabic
The country of cuba primarily speaks the language of spanish
The country of philippines primarily speaks the language of tagalog
The country of kosovo primarily speaks the language of albanian
The country of kuwait primarily speaks the language of arabic
The country of moldova primarily speaks the language of moldovan
The country of bahamas primarily speaks the language of
2024-08-01 01:34:33 root INFO     [order_1_approx] starting weight calculation for The country of bahamas primarily speaks the language of english
The country of moldova primarily speaks the language of moldovan
The country of kosovo primarily speaks the language of albanian
The country of philippines primarily speaks the language of tagalog
The country of kuwait primarily speaks the language of arabic
The country of cuba primarily speaks the language of spanish
The country of guyana primarily speaks the language of english
The country of jordan primarily speaks the language of
2024-08-01 01:34:33 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-08-01 01:37:18 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2639,  0.0414, -0.2227,  ...,  0.1536, -0.3484, -0.0380],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-2.6895, -2.3828,  0.3621,  ..., -0.7827,  0.8574, -1.0898],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0011,  0.0030,  0.0150,  ..., -0.0311, -0.0196, -0.0039],
        [-0.0059,  0.0221,  0.0031,  ...,  0.0021, -0.0066,  0.0017],
        [-0.0061,  0.0063,  0.0220,  ...,  0.0042,  0.0108, -0.0065],
        ...,
        [-0.0167,  0.0314, -0.0173,  ...,  0.0555,  0.0042,  0.0064],
        [-0.0069, -0.0044,  0.0057,  ...,  0.0039, -0.0007, -0.0032],
        [ 0.0130, -0.0136,  0.0024,  ...,  0.0061, -0.0026,  0.0180]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.9922, -2.2617,  0.1389,  ..., -1.2197,  0.9067, -1.0918]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 01:37:19 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country of bahamas primarily speaks the language of english
The country of moldova primarily speaks the language of moldovan
The country of kosovo primarily speaks the language of albanian
The country of philippines primarily speaks the language of tagalog
The country of kuwait primarily speaks the language of arabic
The country of cuba primarily speaks the language of spanish
The country of guyana primarily speaks the language of english
The country of jordan primarily speaks the language of
2024-08-01 01:37:19 root INFO     [order_1_approx] starting weight calculation for The country of bahamas primarily speaks the language of english
The country of philippines primarily speaks the language of tagalog
The country of kuwait primarily speaks the language of arabic
The country of cuba primarily speaks the language of spanish
The country of jordan primarily speaks the language of arabic
The country of moldova primarily speaks the language of moldovan
The country of guyana primarily speaks the language of english
The country of kosovo primarily speaks the language of
2024-08-01 01:37:19 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-08-01 01:40:05 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.5112, -0.0887, -0.1995,  ...,  0.2905, -0.2881, -0.0067],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.1436, -4.6562,  2.1992,  ..., -1.3311, -0.3120, -1.3408],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0282,  0.0034,  0.0096,  ..., -0.0025,  0.0275, -0.0002],
        [-0.0131,  0.0365, -0.0061,  ...,  0.0110, -0.0128, -0.0141],
        [ 0.0059,  0.0015,  0.0263,  ..., -0.0097,  0.0097, -0.0333],
        ...,
        [-0.0132, -0.0016, -0.0264,  ...,  0.0187,  0.0337, -0.0161],
        [ 0.0187, -0.0078,  0.0188,  ..., -0.0043,  0.0254,  0.0153],
        [ 0.0112,  0.0004, -0.0205,  ...,  0.0287, -0.0031,  0.0018]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.3320, -4.4844,  1.9326,  ..., -1.4219,  0.0288, -1.1748]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 01:40:06 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country of bahamas primarily speaks the language of english
The country of philippines primarily speaks the language of tagalog
The country of kuwait primarily speaks the language of arabic
The country of cuba primarily speaks the language of spanish
The country of jordan primarily speaks the language of arabic
The country of moldova primarily speaks the language of moldovan
The country of guyana primarily speaks the language of english
The country of kosovo primarily speaks the language of
2024-08-01 01:40:07 root INFO     [order_1_approx] starting weight calculation for The country of kuwait primarily speaks the language of arabic
The country of guyana primarily speaks the language of english
The country of philippines primarily speaks the language of tagalog
The country of jordan primarily speaks the language of arabic
The country of moldova primarily speaks the language of moldovan
The country of bahamas primarily speaks the language of english
The country of kosovo primarily speaks the language of albanian
The country of cuba primarily speaks the language of
2024-08-01 01:40:07 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-08-01 01:42:56 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1787, -0.2095, -0.0241,  ..., -0.1702, -0.0590, -0.0543],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.8477, -2.6504,  1.9932,  ...,  1.2988, -0.4375, -2.1641],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-1.8158e-02,  1.6922e-02,  1.5480e-02,  ..., -2.1652e-02,
          1.8066e-02,  6.6605e-03],
        [-3.6888e-03,  2.3453e-02,  5.7640e-03,  ...,  9.6130e-03,
         -2.1088e-02, -6.9427e-04],
        [-1.2161e-02,  9.2163e-03,  2.0905e-02,  ...,  4.9324e-03,
          5.1003e-03, -2.1957e-02],
        ...,
        [-1.1017e-02,  1.9455e-04, -1.1330e-02,  ...,  2.0950e-02,
          1.5358e-02, -1.6235e-02],
        [-6.0997e-03, -1.0290e-03, -9.6970e-03,  ..., -2.6703e-03,
          1.8860e-02,  3.1982e-02],
        [ 1.0422e-02, -2.0279e-02, -1.9226e-02,  ..., -1.3351e-05,
          8.5678e-03, -7.0190e-03]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.7393, -2.2852,  2.0879,  ...,  1.0762, -0.4241, -2.0293]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 01:42:57 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country of kuwait primarily speaks the language of arabic
The country of guyana primarily speaks the language of english
The country of philippines primarily speaks the language of tagalog
The country of jordan primarily speaks the language of arabic
The country of moldova primarily speaks the language of moldovan
The country of bahamas primarily speaks the language of english
The country of kosovo primarily speaks the language of albanian
The country of cuba primarily speaks the language of
2024-08-01 01:42:57 root INFO     total operator prediction time: 1349.1600289344788 seconds
2024-08-01 01:42:57 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on animal - shelter
2024-08-01 01:42:57 root INFO     building operator animal - shelter
2024-08-01 01:42:57 root INFO     [order_1_approx] starting weight calculation for The place tiger lives in is called den
The place chimpanzee lives in is called grove
The place lion lives in is called den
The place rat lives in is called nest
The place cricket lives in is called nest
The place beaver lives in is called dam
The place fox lives in is called den
The place baboon lives in is called
2024-08-01 01:42:58 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-08-01 01:45:50 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4204,  0.0362, -0.2056,  ...,  0.0296, -0.4568,  0.0909],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 5.9102, -4.8008, -0.5322,  ..., -0.3364, -2.3340, -0.9507],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0462, -0.0258,  0.0051,  ..., -0.0202, -0.0096, -0.0104],
        [ 0.0013,  0.1063, -0.0151,  ...,  0.0929, -0.0352,  0.0236],
        [-0.0291,  0.0110,  0.0043,  ..., -0.0017, -0.0062, -0.0306],
        ...,
        [-0.0010,  0.0457,  0.0008,  ...,  0.0804,  0.0074,  0.0099],
        [ 0.0021,  0.0044,  0.0236,  ..., -0.0171,  0.0135, -0.0196],
        [-0.0280,  0.0039, -0.0257,  ..., -0.0239, -0.0066,  0.0310]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 5.3242, -4.6445, -0.4314,  ..., -0.1768, -2.4414, -0.2612]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 01:45:51 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The place tiger lives in is called den
The place chimpanzee lives in is called grove
The place lion lives in is called den
The place rat lives in is called nest
The place cricket lives in is called nest
The place beaver lives in is called dam
The place fox lives in is called den
The place baboon lives in is called
2024-08-01 01:45:51 root INFO     [order_1_approx] starting weight calculation for The place cricket lives in is called nest
The place rat lives in is called nest
The place tiger lives in is called den
The place lion lives in is called den
The place baboon lives in is called grove
The place beaver lives in is called dam
The place chimpanzee lives in is called grove
The place fox lives in is called
2024-08-01 01:45:51 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-08-01 01:48:39 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2297,  0.2267, -0.2125,  ..., -0.2302,  0.2605, -0.2250],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.8281, -7.0391, -0.4434,  ..., -1.8428, -1.4492,  2.0625],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 4.1229e-02,  2.1820e-02,  1.2337e-02,  ...,  2.8046e-02,
         -1.0864e-02,  8.2703e-03],
        [-5.5237e-03,  5.5756e-02, -1.0101e-02,  ...,  1.8799e-02,
         -2.4612e-02, -4.4632e-03],
        [ 3.6964e-03, -1.3771e-03,  3.4210e-02,  ..., -1.6586e-02,
          6.6795e-03,  1.3748e-02],
        ...,
        [-6.4964e-03,  1.1650e-02,  2.7557e-02,  ...,  1.0406e-02,
          3.7670e-03, -8.5220e-03],
        [ 2.2522e-02, -1.3214e-02,  1.3298e-02,  ..., -4.4746e-03,
          3.3081e-02,  5.8594e-03],
        [ 1.3794e-02,  9.9182e-05,  8.7433e-03,  ..., -1.4961e-02,
         -1.7586e-03,  4.0558e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.7930, -7.3047, -0.2554,  ..., -2.0645, -1.5410,  1.7979]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 01:48:40 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The place cricket lives in is called nest
The place rat lives in is called nest
The place tiger lives in is called den
The place lion lives in is called den
The place baboon lives in is called grove
The place beaver lives in is called dam
The place chimpanzee lives in is called grove
The place fox lives in is called
2024-08-01 01:48:41 root INFO     [order_1_approx] starting weight calculation for The place chimpanzee lives in is called grove
The place lion lives in is called den
The place baboon lives in is called grove
The place fox lives in is called den
The place tiger lives in is called den
The place beaver lives in is called dam
The place rat lives in is called nest
The place cricket lives in is called
2024-08-01 01:48:41 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-08-01 01:51:29 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0070,  0.1830, -0.0114,  ...,  0.0260,  0.0375, -0.3103],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.9375, -6.2188,  3.1484,  ...,  0.2810, -0.3110, -0.9170],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0290, -0.0334, -0.0184,  ..., -0.0418, -0.0201, -0.0591],
        [ 0.0098, -0.0053, -0.0280,  ..., -0.0276,  0.0094, -0.0013],
        [ 0.0123,  0.0812,  0.0316,  ..., -0.0343, -0.0393,  0.0141],
        ...,
        [ 0.0241, -0.0112, -0.0076,  ...,  0.1300,  0.0469,  0.0615],
        [-0.0037, -0.0072, -0.0144,  ..., -0.0069,  0.0571, -0.0177],
        [-0.0693,  0.0174, -0.0023,  ...,  0.0136,  0.0089,  0.0177]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.2715, -6.5078,  2.6738,  ...,  0.0648, -0.5176, -1.1992]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 01:51:30 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The place chimpanzee lives in is called grove
The place lion lives in is called den
The place baboon lives in is called grove
The place fox lives in is called den
The place tiger lives in is called den
The place beaver lives in is called dam
The place rat lives in is called nest
The place cricket lives in is called
2024-08-01 01:51:30 root INFO     [order_1_approx] starting weight calculation for The place baboon lives in is called grove
The place chimpanzee lives in is called grove
The place beaver lives in is called dam
The place cricket lives in is called nest
The place tiger lives in is called den
The place lion lives in is called den
The place fox lives in is called den
The place rat lives in is called
2024-08-01 01:51:30 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-08-01 01:54:19 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0512, -0.0010, -0.2097,  ..., -0.2290, -0.2021, -0.1184],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.9512, -5.1797,  2.9922,  ..., -0.6348, -0.3667, -0.7085],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 7.3730e-02, -1.0559e-02,  6.2332e-03,  ...,  5.7182e-03,
         -1.6205e-02, -2.3712e-02],
        [-2.4063e-02,  3.7964e-02, -4.5547e-03,  ...,  1.3870e-02,
         -3.6377e-02,  5.9814e-03],
        [ 5.7106e-03,  4.5807e-02,  2.3956e-02,  ..., -4.0375e-02,
         -5.3711e-03,  1.9867e-02],
        ...,
        [-1.2054e-03,  1.1978e-03,  1.2772e-02,  ...,  7.6355e-02,
         -8.7738e-05,  2.0981e-02],
        [ 1.4542e-02,  3.8147e-06, -1.6220e-02,  ...,  3.7354e-02,
          1.3596e-02, -1.3817e-02],
        [-2.6901e-02, -3.1662e-03,  7.8869e-04,  ..., -6.4850e-03,
         -6.9046e-03,  3.5858e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.2285, -5.2031,  2.5977,  ..., -0.8062, -0.3145, -1.0557]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 01:54:20 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The place baboon lives in is called grove
The place chimpanzee lives in is called grove
The place beaver lives in is called dam
The place cricket lives in is called nest
The place tiger lives in is called den
The place lion lives in is called den
The place fox lives in is called den
The place rat lives in is called
2024-08-01 01:54:20 root INFO     [order_1_approx] starting weight calculation for The place rat lives in is called nest
The place fox lives in is called den
The place beaver lives in is called dam
The place baboon lives in is called grove
The place cricket lives in is called nest
The place chimpanzee lives in is called grove
The place tiger lives in is called den
The place lion lives in is called
2024-08-01 01:54:20 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-08-01 01:57:09 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2152,  0.1978, -0.2183,  ..., -0.0995, -0.0386, -0.0391],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([  5.2031, -10.0625,  -0.5996,  ...,  -1.4980,  -1.2090,  -2.4609],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0217,  0.0073,  0.0084,  ...,  0.0118,  0.0055, -0.0154],
        [ 0.0266, -0.0386,  0.0117,  ..., -0.0141, -0.0198,  0.0193],
        [-0.0426,  0.0134,  0.0107,  ..., -0.0036, -0.0196,  0.0020],
        ...,
        [-0.0145,  0.0280, -0.0231,  ...,  0.0252, -0.0106, -0.0032],
        [ 0.0087, -0.0066,  0.0173,  ...,  0.0193,  0.0169, -0.0067],
        [ 0.0165, -0.0546, -0.0022,  ..., -0.0299, -0.0190,  0.0342]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[  4.9297, -10.0391,  -0.4258,  ...,  -1.5225,  -1.6699,  -2.7598]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 01:57:10 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The place rat lives in is called nest
The place fox lives in is called den
The place beaver lives in is called dam
The place baboon lives in is called grove
The place cricket lives in is called nest
The place chimpanzee lives in is called grove
The place tiger lives in is called den
The place lion lives in is called
2024-08-01 01:57:10 root INFO     [order_1_approx] starting weight calculation for The place baboon lives in is called grove
The place rat lives in is called nest
The place tiger lives in is called den
The place lion lives in is called den
The place chimpanzee lives in is called grove
The place cricket lives in is called nest
The place fox lives in is called den
The place beaver lives in is called
2024-08-01 01:57:10 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-08-01 01:59:58 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1048,  0.3154, -0.2236,  ..., -0.2534, -0.0993,  0.0115],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.4414, -6.7109, -2.0586,  ..., -3.1484, -0.0331, -1.1582],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0673, -0.0603, -0.0217,  ...,  0.0144, -0.0025, -0.0515],
        [ 0.0139,  0.0317,  0.0105,  ...,  0.0018, -0.0312, -0.0254],
        [ 0.0029,  0.0201,  0.0311,  ..., -0.0200, -0.0365, -0.0072],
        ...,
        [-0.0468,  0.0352,  0.0017,  ...,  0.0450, -0.0374,  0.0104],
        [ 0.0274,  0.0370,  0.0163,  ...,  0.0177,  0.0126,  0.0085],
        [-0.0336, -0.0142, -0.0190,  ..., -0.0206, -0.0083,  0.0405]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.1719, -6.3945, -1.7988,  ..., -3.5195, -0.4187, -1.4395]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 01:59:59 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The place baboon lives in is called grove
The place rat lives in is called nest
The place tiger lives in is called den
The place lion lives in is called den
The place chimpanzee lives in is called grove
The place cricket lives in is called nest
The place fox lives in is called den
The place beaver lives in is called
2024-08-01 01:59:59 root INFO     [order_1_approx] starting weight calculation for The place beaver lives in is called dam
The place lion lives in is called den
The place baboon lives in is called grove
The place chimpanzee lives in is called grove
The place cricket lives in is called nest
The place fox lives in is called den
The place rat lives in is called nest
The place tiger lives in is called
2024-08-01 01:59:59 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-08-01 02:02:47 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0071,  0.2488, -0.3701,  ..., -0.1097, -0.0507, -0.0782],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.2852, -9.3125, -0.3086,  ..., -0.9707, -1.2080, -3.1953],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0178, -0.0111,  0.0075,  ..., -0.0013, -0.0019, -0.0228],
        [-0.0079, -0.0044, -0.0176,  ...,  0.0095,  0.0015,  0.0079],
        [-0.0099, -0.0110,  0.0214,  ..., -0.0159, -0.0122,  0.0111],
        ...,
        [ 0.0033,  0.0284, -0.0247,  ...,  0.0535, -0.0026, -0.0135],
        [ 0.0150, -0.0118,  0.0162,  ...,  0.0087, -0.0003, -0.0077],
        [-0.0377, -0.0118, -0.0026,  ..., -0.0227, -0.0034,  0.0365]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.3594, -9.2031, -0.2620,  ..., -1.0518, -0.9551, -2.8047]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 02:02:48 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The place beaver lives in is called dam
The place lion lives in is called den
The place baboon lives in is called grove
The place chimpanzee lives in is called grove
The place cricket lives in is called nest
The place fox lives in is called den
The place rat lives in is called nest
The place tiger lives in is called
2024-08-01 02:02:48 root INFO     [order_1_approx] starting weight calculation for The place baboon lives in is called grove
The place rat lives in is called nest
The place tiger lives in is called den
The place beaver lives in is called dam
The place cricket lives in is called nest
The place fox lives in is called den
The place lion lives in is called den
The place chimpanzee lives in is called
2024-08-01 02:02:48 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-08-01 02:05:39 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2321, -0.0808, -0.2467,  ..., -0.2061, -0.4128,  0.0524],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.7305, -6.9062, -0.5117,  ..., -1.1514, -2.0742,  0.4873],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0018, -0.0100, -0.0036,  ..., -0.0032, -0.0070,  0.0019],
        [-0.0072,  0.0101,  0.0056,  ...,  0.0063, -0.0012,  0.0117],
        [-0.0011,  0.0058,  0.0098,  ...,  0.0083, -0.0128, -0.0144],
        ...,
        [ 0.0017,  0.0128,  0.0055,  ...,  0.0140,  0.0139, -0.0043],
        [ 0.0023, -0.0054,  0.0019,  ...,  0.0011,  0.0031,  0.0046],
        [ 0.0041, -0.0114,  0.0112,  ..., -0.0021,  0.0029, -0.0030]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.9062, -7.0391, -0.4097,  ..., -1.1172, -1.9805,  0.4724]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 02:05:40 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The place baboon lives in is called grove
The place rat lives in is called nest
The place tiger lives in is called den
The place beaver lives in is called dam
The place cricket lives in is called nest
The place fox lives in is called den
The place lion lives in is called den
The place chimpanzee lives in is called
2024-08-01 02:05:40 root INFO     total operator prediction time: 1363.1552708148956 seconds
2024-08-01 02:05:40 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on male - female
2024-08-01 02:05:40 root INFO     building operator male - female
2024-08-01 02:05:41 root INFO     [order_1_approx] starting weight calculation for A female policeman is known as a policewoman
A female groom is known as a bride
A female heir is known as a heiress
A female waiter is known as a waitress
A female bull is known as a cow
A female god is known as a goddess
A female sir is known as a madam
A female manager is known as a
2024-08-01 02:05:41 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-08-01 02:08:28 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0253,  0.2466, -0.0160,  ...,  0.1006, -0.2544, -0.2300],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.4141, -4.1055,  1.1836,  ...,  2.7344, -1.9014, -3.7871],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0253, -0.0030, -0.0052,  ...,  0.0142, -0.0007, -0.0002],
        [-0.0240,  0.0377, -0.0192,  ...,  0.0036,  0.0315,  0.0082],
        [-0.0099,  0.0029,  0.0442,  ..., -0.0145, -0.0242, -0.0050],
        ...,
        [-0.0045,  0.0308, -0.0094,  ...,  0.0495, -0.0252, -0.0240],
        [ 0.0161, -0.0067,  0.0310,  ..., -0.0557,  0.0306,  0.0121],
        [ 0.0212, -0.0173, -0.0389,  ...,  0.0015,  0.0178,  0.0161]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.6133, -3.9551,  1.0088,  ...,  2.8379, -2.1738, -3.7793]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 02:08:29 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A female policeman is known as a policewoman
A female groom is known as a bride
A female heir is known as a heiress
A female waiter is known as a waitress
A female bull is known as a cow
A female god is known as a goddess
A female sir is known as a madam
A female manager is known as a
2024-08-01 02:08:29 root INFO     [order_1_approx] starting weight calculation for A female groom is known as a bride
A female bull is known as a cow
A female policeman is known as a policewoman
A female sir is known as a madam
A female manager is known as a manageress
A female heir is known as a heiress
A female waiter is known as a waitress
A female god is known as a
2024-08-01 02:08:29 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-08-01 02:11:19 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0884,  0.3169,  0.0144,  ...,  0.0232, -0.3467, -0.0917],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.8125, -5.8008,  0.6621,  ..., -0.3589, -1.7305, -0.1373],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0193, -0.0051,  0.0288,  ..., -0.0002, -0.0251,  0.0172],
        [-0.0024,  0.0230, -0.0126,  ...,  0.0236,  0.0270, -0.0029],
        [-0.0012, -0.0035,  0.0488,  ...,  0.0422,  0.0052, -0.0016],
        ...,
        [-0.0198, -0.0018,  0.0037,  ...,  0.0349,  0.0123, -0.0139],
        [ 0.0082,  0.0021,  0.0044,  ..., -0.0151, -0.0025,  0.0010],
        [ 0.0172,  0.0183, -0.0063,  ..., -0.0380,  0.0114,  0.0047]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.6445, -5.9180,  0.5547,  ..., -0.3438, -1.9902,  0.3804]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 02:11:20 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A female groom is known as a bride
A female bull is known as a cow
A female policeman is known as a policewoman
A female sir is known as a madam
A female manager is known as a manageress
A female heir is known as a heiress
A female waiter is known as a waitress
A female god is known as a
2024-08-01 02:11:20 root INFO     [order_1_approx] starting weight calculation for A female manager is known as a manageress
A female god is known as a goddess
A female policeman is known as a policewoman
A female groom is known as a bride
A female sir is known as a madam
A female heir is known as a heiress
A female bull is known as a cow
A female waiter is known as a
2024-08-01 02:11:20 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-08-01 02:14:09 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1732, -0.0084, -0.2515,  ..., -0.1123, -0.1691, -0.1296],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.6758, -0.6221,  0.9282,  ...,  2.2891, -2.4688, -0.4263],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 6.0349e-03, -3.0441e-03,  2.5387e-03,  ..., -1.5991e-02,
          1.5259e-05, -2.4963e-02],
        [-2.8381e-03,  4.9500e-02, -6.8207e-03,  ...,  1.9928e-02,
         -9.3842e-03,  2.7084e-03],
        [ 8.6212e-03, -1.1925e-02,  1.0597e-02,  ..., -1.2417e-03,
          1.9417e-03,  1.1063e-02],
        ...,
        [ 4.9248e-03,  2.1820e-02,  1.4816e-02,  ...,  2.8244e-02,
          2.4147e-03, -1.0445e-02],
        [-3.9978e-03,  6.0654e-04, -1.7242e-02,  ..., -1.9928e-02,
          1.7212e-02, -1.2482e-02],
        [ 1.9398e-03,  2.6093e-02,  4.6501e-03,  ...,  9.7961e-03,
         -2.5375e-02,  2.0046e-03]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 5.0352, -0.6636,  0.8696,  ...,  1.9990, -2.4141, -0.3364]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 02:14:10 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A female manager is known as a manageress
A female god is known as a goddess
A female policeman is known as a policewoman
A female groom is known as a bride
A female sir is known as a madam
A female heir is known as a heiress
A female bull is known as a cow
A female waiter is known as a
2024-08-01 02:14:10 root INFO     [order_1_approx] starting weight calculation for A female manager is known as a manageress
A female sir is known as a madam
A female bull is known as a cow
A female waiter is known as a waitress
A female policeman is known as a policewoman
A female god is known as a goddess
A female heir is known as a heiress
A female groom is known as a
2024-08-01 02:14:10 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-08-01 02:16:59 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2607,  0.2302, -0.1602,  ..., -0.2573, -0.1942,  0.2151],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.3008, -4.3281, -0.9736,  ..., -0.9824, -3.2656,  1.7881],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0659, -0.0251,  0.0222,  ..., -0.0066,  0.0045,  0.0037],
        [-0.0361,  0.0812, -0.0039,  ...,  0.0060,  0.0080,  0.0224],
        [ 0.0040, -0.0041,  0.0358,  ...,  0.0032,  0.0014,  0.0191],
        ...,
        [-0.0103, -0.0435, -0.0018,  ..., -0.0218,  0.0507, -0.0210],
        [-0.0100, -0.0171, -0.0027,  ...,  0.0051,  0.0246, -0.0075],
        [-0.0060,  0.0298, -0.0234,  ...,  0.0127, -0.0019,  0.0339]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.3047, -3.6504, -1.2949,  ..., -1.1709, -3.2246,  2.0469]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 02:17:00 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A female manager is known as a manageress
A female sir is known as a madam
A female bull is known as a cow
A female waiter is known as a waitress
A female policeman is known as a policewoman
A female god is known as a goddess
A female heir is known as a heiress
A female groom is known as a
2024-08-01 02:17:00 root INFO     [order_1_approx] starting weight calculation for A female groom is known as a bride
A female waiter is known as a waitress
A female policeman is known as a policewoman
A female god is known as a goddess
A female manager is known as a manageress
A female bull is known as a cow
A female heir is known as a heiress
A female sir is known as a
2024-08-01 02:17:00 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-08-01 02:19:49 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0507,  0.0610, -0.1351,  ...,  0.1313, -0.0944,  0.2791],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.8887, -1.2881, -1.3203,  ...,  0.5703, -4.5820, -3.1699],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 4.7943e-02, -1.7593e-02,  5.7312e-02,  ..., -1.8753e-02,
          1.3409e-03,  1.3123e-03],
        [ 1.6174e-03,  5.3680e-02, -2.0493e-02,  ...,  1.7258e-02,
          7.0007e-02, -2.8625e-02],
        [ 7.6599e-02,  1.7548e-02,  1.3542e-02,  ...,  5.2765e-02,
         -4.4037e-02, -3.1662e-03],
        ...,
        [ 2.2888e-05,  1.6739e-02,  4.2389e-02,  ...,  7.0312e-02,
          3.7193e-03, -5.5145e-02],
        [-2.9663e-02, -6.0608e-02,  2.5726e-02,  ..., -2.7008e-02,
         -1.8112e-02,  2.8641e-02],
        [-3.2959e-02, -2.4490e-02, -2.2644e-02,  ...,  2.3994e-03,
          1.7212e-02, -6.9092e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.2930, -1.1621, -0.7144,  ...,  0.8096, -4.7891, -2.9590]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 02:19:50 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A female groom is known as a bride
A female waiter is known as a waitress
A female policeman is known as a policewoman
A female god is known as a goddess
A female manager is known as a manageress
A female bull is known as a cow
A female heir is known as a heiress
A female sir is known as a
2024-08-01 02:19:50 root INFO     [order_1_approx] starting weight calculation for A female heir is known as a heiress
A female waiter is known as a waitress
A female manager is known as a manageress
A female bull is known as a cow
A female groom is known as a bride
A female god is known as a goddess
A female sir is known as a madam
A female policeman is known as a
2024-08-01 02:19:50 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-08-01 02:22:36 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4170,  0.0641, -0.1436,  ..., -0.0374, -0.1605, -0.0183],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.8652, -5.7344,  3.5586,  ...,  1.3184, -0.3652, -0.4692],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 2.7580e-03,  5.8975e-03,  1.9196e-02,  ...,  1.6571e-02,
          1.4938e-02, -7.2174e-03],
        [ 1.0643e-02,  1.1597e-02, -6.5346e-03,  ...,  2.6894e-03,
         -1.3603e-02,  1.3504e-02],
        [ 5.0659e-03,  1.8082e-02,  4.6082e-03,  ...,  4.3304e-02,
         -1.7639e-02,  2.8763e-03],
        ...,
        [ 2.1553e-04,  7.6294e-05,  1.5343e-02,  ...,  4.0253e-02,
          1.1330e-02, -5.6915e-03],
        [ 1.5083e-02, -1.9894e-03,  8.6212e-03,  ..., -2.9327e-02,
         -6.7253e-03,  7.4310e-03],
        [-7.1640e-03, -5.6686e-03,  3.8013e-03,  ..., -8.3847e-03,
         -5.0621e-03, -1.8341e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.7871, -5.5742,  3.3418,  ...,  1.0732, -0.4766, -0.3940]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 02:22:37 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A female heir is known as a heiress
A female waiter is known as a waitress
A female manager is known as a manageress
A female bull is known as a cow
A female groom is known as a bride
A female god is known as a goddess
A female sir is known as a madam
A female policeman is known as a
2024-08-01 02:22:37 root INFO     [order_1_approx] starting weight calculation for A female sir is known as a madam
A female waiter is known as a waitress
A female manager is known as a manageress
A female groom is known as a bride
A female heir is known as a heiress
A female god is known as a goddess
A female policeman is known as a policewoman
A female bull is known as a
2024-08-01 02:22:37 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-08-01 02:25:19 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1277, -0.0535,  0.1527,  ..., -0.1851, -0.1107,  0.0658],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 5.1992, -4.7109, -1.1426,  ...,  1.4180, -0.0186,  0.7344],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 2.3941e-02, -2.2995e-02,  2.6733e-02,  ...,  1.1635e-02,
         -6.9275e-03,  2.6718e-02],
        [-6.3660e-02,  7.8674e-02, -5.7007e-02,  ...,  7.0618e-02,
          9.9792e-03,  1.4633e-02],
        [ 2.6474e-03,  4.7546e-02,  1.3214e-02,  ..., -3.3970e-03,
         -4.8218e-03, -4.1931e-02],
        ...,
        [ 7.3204e-03, -2.4521e-02,  2.3178e-02,  ...,  1.7838e-02,
         -5.7220e-05, -8.5876e-02],
        [-4.0169e-03,  1.7212e-02,  1.3626e-02,  ...,  5.2765e-02,
          8.5526e-03,  1.1482e-02],
        [ 6.6910e-03,  8.0719e-03, -3.6377e-02,  ..., -1.6022e-03,
          2.1027e-02,  1.9897e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 5.0508, -4.4688, -0.9517,  ...,  2.0039, -0.5322,  1.1182]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 02:25:20 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A female sir is known as a madam
A female waiter is known as a waitress
A female manager is known as a manageress
A female groom is known as a bride
A female heir is known as a heiress
A female god is known as a goddess
A female policeman is known as a policewoman
A female bull is known as a
2024-08-01 02:25:20 root INFO     [order_1_approx] starting weight calculation for A female bull is known as a cow
A female god is known as a goddess
A female manager is known as a manageress
A female policeman is known as a policewoman
A female waiter is known as a waitress
A female groom is known as a bride
A female sir is known as a madam
A female heir is known as a
2024-08-01 02:25:20 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-08-01 02:28:01 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2708,  0.0377, -0.0712,  ..., -0.0154, -0.1476,  0.1854],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.1992, -2.8398,  1.6748,  ..., -3.0996, -4.5938,  1.4287],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0390, -0.0248,  0.0057,  ...,  0.0113, -0.0042,  0.0183],
        [-0.0188,  0.0353,  0.0022,  ...,  0.0278,  0.0456,  0.0032],
        [-0.0170,  0.0102,  0.0500,  ...,  0.0267,  0.0012, -0.0121],
        ...,
        [ 0.0158,  0.0121, -0.0172,  ...,  0.0519,  0.0221,  0.0154],
        [ 0.0294,  0.0127, -0.0022,  ...,  0.0054,  0.0311, -0.0031],
        [-0.0037,  0.0255, -0.0009,  ..., -0.0029,  0.0009,  0.0329]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.2188, -2.4160,  1.2109,  ..., -2.9824, -4.2461,  1.4219]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 02:28:02 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A female bull is known as a cow
A female god is known as a goddess
A female manager is known as a manageress
A female policeman is known as a policewoman
A female waiter is known as a waitress
A female groom is known as a bride
A female sir is known as a madam
A female heir is known as a
2024-08-01 02:28:02 root INFO     total operator prediction time: 1341.369815826416 seconds
2024-08-01 02:28:02 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on name - occupation
2024-08-01 02:28:02 root INFO     building operator name - occupation
2024-08-01 02:28:02 root INFO     [order_1_approx] starting weight calculation for mencius was known for their work as a  philosopher
dante was known for their work as a  poet
depp was known for their work as a  actor
locke was known for their work as a  philosopher
rousseau was known for their work as a  writer
descartes was known for their work as a  mathematician
plato was known for their work as a  philosopher
beethoven was known for their work as a 
2024-08-01 02:28:02 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-08-01 02:30:45 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0941,  0.2350, -0.4399,  ..., -0.0074,  0.0428, -0.1338],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.5312, -6.9883,  1.8291,  ..., -2.2070,  0.8306, -2.0859],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0247,  0.0231, -0.0297,  ..., -0.0043, -0.0050,  0.0008],
        [ 0.0333, -0.0047,  0.0382,  ..., -0.0241,  0.0006, -0.0028],
        [-0.0053,  0.0043,  0.0049,  ..., -0.0013,  0.0022, -0.0061],
        ...,
        [-0.0048,  0.0151, -0.0244,  ...,  0.0320, -0.0071, -0.0039],
        [-0.0072,  0.0083,  0.0027,  ...,  0.0024,  0.0040,  0.0073],
        [ 0.0191, -0.0114,  0.0184,  ..., -0.0056, -0.0094,  0.0142]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.5371, -6.5000,  1.6895,  ..., -2.3867,  0.8076, -1.8672]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 02:30:46 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for mencius was known for their work as a  philosopher
dante was known for their work as a  poet
depp was known for their work as a  actor
locke was known for their work as a  philosopher
rousseau was known for their work as a  writer
descartes was known for their work as a  mathematician
plato was known for their work as a  philosopher
beethoven was known for their work as a 
2024-08-01 02:30:46 root INFO     [order_1_approx] starting weight calculation for beethoven was known for their work as a  composer
dante was known for their work as a  poet
locke was known for their work as a  philosopher
mencius was known for their work as a  philosopher
depp was known for their work as a  actor
descartes was known for their work as a  mathematician
rousseau was known for their work as a  writer
plato was known for their work as a 
2024-08-01 02:30:46 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-08-01 02:33:36 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0034, -0.1453, -0.6450,  ...,  0.0714,  0.0803, -0.1237],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.7217, -5.5430,  2.0586,  ..., -6.2656, -0.3242, -0.3252],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0307, -0.0635,  0.0335,  ..., -0.0003, -0.0080,  0.0117],
        [ 0.0107, -0.0109,  0.0077,  ..., -0.0135, -0.0053,  0.0074],
        [ 0.0150,  0.0032,  0.0290,  ...,  0.0013,  0.0029,  0.0301],
        ...,
        [ 0.0351, -0.0081, -0.0182,  ...,  0.0450,  0.0239, -0.0092],
        [ 0.0024,  0.0175,  0.0259,  ...,  0.0159,  0.0295, -0.0082],
        [-0.0249,  0.0349,  0.0024,  ...,  0.0022, -0.0029,  0.0292]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.7803, -5.0352,  2.1641,  ..., -5.9453, -0.4387, -0.0359]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 02:33:36 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for beethoven was known for their work as a  composer
dante was known for their work as a  poet
locke was known for their work as a  philosopher
mencius was known for their work as a  philosopher
depp was known for their work as a  actor
descartes was known for their work as a  mathematician
rousseau was known for their work as a  writer
plato was known for their work as a 
2024-08-01 02:33:37 root INFO     [order_1_approx] starting weight calculation for depp was known for their work as a  actor
dante was known for their work as a  poet
plato was known for their work as a  philosopher
rousseau was known for their work as a  writer
beethoven was known for their work as a  composer
locke was known for their work as a  philosopher
mencius was known for their work as a  philosopher
descartes was known for their work as a 
2024-08-01 02:33:37 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-08-01 02:36:25 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0421,  0.0668, -0.3193,  ..., -0.0377,  0.0249,  0.1138],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.0879, -4.8672,  1.4785,  ..., -5.2578,  0.5288,  0.0342],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0126, -0.0073, -0.0116,  ..., -0.0031,  0.0045, -0.0187],
        [ 0.0104,  0.0316, -0.0033,  ..., -0.0092,  0.0011,  0.0053],
        [ 0.0005, -0.0027,  0.0211,  ..., -0.0065,  0.0056,  0.0059],
        ...,
        [ 0.0128,  0.0155, -0.0090,  ...,  0.0286,  0.0052,  0.0065],
        [ 0.0071, -0.0093, -0.0092,  ...,  0.0184,  0.0075,  0.0110],
        [-0.0106, -0.0012, -0.0089,  ..., -0.0007,  0.0016,  0.0343]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.1936, -4.9062,  1.4258,  ..., -5.1133,  0.8340,  0.1847]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 02:36:25 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for depp was known for their work as a  actor
dante was known for their work as a  poet
plato was known for their work as a  philosopher
rousseau was known for their work as a  writer
beethoven was known for their work as a  composer
locke was known for their work as a  philosopher
mencius was known for their work as a  philosopher
descartes was known for their work as a 
2024-08-01 02:36:26 root INFO     [order_1_approx] starting weight calculation for beethoven was known for their work as a  composer
depp was known for their work as a  actor
rousseau was known for their work as a  writer
plato was known for their work as a  philosopher
mencius was known for their work as a  philosopher
descartes was known for their work as a  mathematician
locke was known for their work as a  philosopher
dante was known for their work as a 
2024-08-01 02:36:26 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-08-01 02:39:11 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0028,  0.1110, -0.3894,  ...,  0.1821, -0.0194, -0.0932],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.0742, -8.3594,  2.6641,  ..., -4.4570,  0.0441,  0.1016],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0580,  0.0161,  0.0424,  ...,  0.0096,  0.0161,  0.0085],
        [-0.0197,  0.0330, -0.0142,  ..., -0.0190,  0.0139, -0.0121],
        [ 0.0482,  0.0030,  0.0359,  ...,  0.0012, -0.0423,  0.0323],
        ...,
        [ 0.0199,  0.0418, -0.0180,  ...,  0.0730,  0.0062, -0.0463],
        [ 0.0112, -0.0248,  0.0009,  ...,  0.0092,  0.0285, -0.0080],
        [-0.0020,  0.0067,  0.0058,  ...,  0.0164,  0.0174,  0.0631]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.9023, -7.5273,  2.2539,  ..., -4.0781, -0.4758,  0.6519]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 02:39:12 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for beethoven was known for their work as a  composer
depp was known for their work as a  actor
rousseau was known for their work as a  writer
plato was known for their work as a  philosopher
mencius was known for their work as a  philosopher
descartes was known for their work as a  mathematician
locke was known for their work as a  philosopher
dante was known for their work as a 
2024-08-01 02:39:12 root INFO     [order_1_approx] starting weight calculation for beethoven was known for their work as a  composer
dante was known for their work as a  poet
plato was known for their work as a  philosopher
depp was known for their work as a  actor
locke was known for their work as a  philosopher
descartes was known for their work as a  mathematician
mencius was known for their work as a  philosopher
rousseau was known for their work as a 
2024-08-01 02:39:13 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-08-01 02:41:54 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1448, -0.0927, -0.3604,  ..., -0.1934, -0.0007,  0.1442],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.6992, -6.0938,  4.1445,  ..., -5.8516,  0.5068,  0.4121],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0426,  0.0151,  0.0379,  ..., -0.0122,  0.0070,  0.0016],
        [ 0.0004,  0.0189, -0.0025,  ..., -0.0059, -0.0049, -0.0289],
        [ 0.0032,  0.0047,  0.0423,  ..., -0.0216,  0.0276,  0.0306],
        ...,
        [ 0.0072,  0.0097, -0.0282,  ...,  0.0927,  0.0179, -0.0086],
        [ 0.0035,  0.0157,  0.0162,  ...,  0.0029, -0.0011, -0.0086],
        [-0.0022,  0.0165, -0.0070,  ...,  0.0006, -0.0017,  0.0449]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.6855, -5.9336,  3.7441,  ..., -5.8984,  0.3699,  0.4329]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 02:41:55 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for beethoven was known for their work as a  composer
dante was known for their work as a  poet
plato was known for their work as a  philosopher
depp was known for their work as a  actor
locke was known for their work as a  philosopher
descartes was known for their work as a  mathematician
mencius was known for their work as a  philosopher
rousseau was known for their work as a 
2024-08-01 02:41:56 root INFO     [order_1_approx] starting weight calculation for rousseau was known for their work as a  writer
beethoven was known for their work as a  composer
descartes was known for their work as a  mathematician
plato was known for their work as a  philosopher
locke was known for their work as a  philosopher
mencius was known for their work as a  philosopher
dante was known for their work as a  poet
depp was known for their work as a 
2024-08-01 02:41:56 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-08-01 02:44:45 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0786,  0.0028,  0.1525,  ...,  0.2163, -0.2231,  0.0219],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.2285, -3.7422,  2.4688,  ..., -3.3027, -0.6367,  0.7852],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 8.2886e-02, -7.5195e-02,  6.4758e-02,  ...,  8.9340e-03,
         -1.2520e-02, -2.9938e-02],
        [-6.6681e-03,  1.3013e-01, -4.0070e-02,  ...,  1.7090e-02,
         -2.1347e-02,  2.5803e-02],
        [ 2.9297e-03,  1.2802e-02,  6.4087e-02,  ...,  1.0910e-03,
         -3.4424e-02, -7.9346e-03],
        ...,
        [ 3.0823e-02,  8.3618e-02, -2.6276e-02,  ...,  1.0541e-01,
         -7.1594e-02,  2.1057e-02],
        [ 1.6541e-02,  6.1035e-05,  1.1208e-02,  ..., -7.5073e-03,
          4.3396e-02,  1.6937e-02],
        [-8.8043e-03, -1.9897e-02,  1.3018e-03,  ..., -2.7054e-02,
         -7.3509e-03,  6.9031e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.1426, -3.6934,  2.8008,  ..., -2.8867, -1.0938,  0.7734]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 02:44:46 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for rousseau was known for their work as a  writer
beethoven was known for their work as a  composer
descartes was known for their work as a  mathematician
plato was known for their work as a  philosopher
locke was known for their work as a  philosopher
mencius was known for their work as a  philosopher
dante was known for their work as a  poet
depp was known for their work as a 
2024-08-01 02:44:46 root INFO     [order_1_approx] starting weight calculation for depp was known for their work as a  actor
rousseau was known for their work as a  writer
locke was known for their work as a  philosopher
plato was known for their work as a  philosopher
descartes was known for their work as a  mathematician
dante was known for their work as a  poet
beethoven was known for their work as a  composer
mencius was known for their work as a 
2024-08-01 02:44:46 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-08-01 02:47:30 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0880,  0.1975, -0.4778,  ...,  0.0694, -0.1050, -0.0657],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.9756, -5.0391,  4.5312,  ..., -9.4531,  1.9922,  0.9600],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0485,  0.0326,  0.0289,  ...,  0.0029,  0.0040,  0.0125],
        [ 0.0009,  0.0738, -0.0143,  ..., -0.0293,  0.0378, -0.0124],
        [ 0.0162,  0.0177,  0.0394,  ...,  0.0114, -0.0087, -0.0383],
        ...,
        [-0.0014, -0.0369,  0.0039,  ...,  0.0392, -0.0114,  0.0103],
        [-0.0057,  0.0317, -0.0398,  ...,  0.0178,  0.0158, -0.0145],
        [-0.0018,  0.0305, -0.0206,  ...,  0.0288, -0.0446,  0.0856]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.2520, -5.3477,  4.4336,  ..., -8.9922,  2.0273,  1.3447]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 02:47:31 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for depp was known for their work as a  actor
rousseau was known for their work as a  writer
locke was known for their work as a  philosopher
plato was known for their work as a  philosopher
descartes was known for their work as a  mathematician
dante was known for their work as a  poet
beethoven was known for their work as a  composer
mencius was known for their work as a 
2024-08-01 02:47:31 root INFO     [order_1_approx] starting weight calculation for dante was known for their work as a  poet
mencius was known for their work as a  philosopher
plato was known for their work as a  philosopher
depp was known for their work as a  actor
rousseau was known for their work as a  writer
beethoven was known for their work as a  composer
descartes was known for their work as a  mathematician
locke was known for their work as a 
2024-08-01 02:47:31 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-08-01 02:50:16 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0941,  0.0560, -0.3203,  ..., -0.0982,  0.0237, -0.0743],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.1123, -4.4180,  2.9062,  ..., -6.0703,  1.4102, -2.8125],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0268,  0.0003,  0.0133,  ...,  0.0055, -0.0007,  0.0070],
        [ 0.0111,  0.0223,  0.0148,  ..., -0.0394,  0.0003,  0.0012],
        [ 0.0133,  0.0077,  0.0412,  ..., -0.0173,  0.0224,  0.0185],
        ...,
        [ 0.0159,  0.0040, -0.0029,  ...,  0.0569, -0.0087, -0.0097],
        [-0.0140,  0.0106, -0.0019,  ...,  0.0134,  0.0267, -0.0029],
        [ 0.0096, -0.0091,  0.0022,  ...,  0.0032, -0.0060,  0.0388]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.2402, -4.6289,  2.5879,  ..., -5.4727,  1.2998, -2.4414]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 02:50:17 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for dante was known for their work as a  poet
mencius was known for their work as a  philosopher
plato was known for their work as a  philosopher
depp was known for their work as a  actor
rousseau was known for their work as a  writer
beethoven was known for their work as a  composer
descartes was known for their work as a  mathematician
locke was known for their work as a 
2024-08-01 02:50:17 root INFO     total operator prediction time: 1335.10387134552 seconds
2024-08-01 02:50:17 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on country - capital
2024-08-01 02:50:17 root INFO     building operator country - capital
2024-08-01 02:50:17 root INFO     [order_1_approx] starting weight calculation for The country with damascus as its capital is known as syria
The country with cairo as its capital is known as egypt
The country with amman as its capital is known as jordan
The country with lisbon as its capital is known as portugal
The country with dublin as its capital is known as ireland
The country with berlin as its capital is known as germany
The country with conakry as its capital is known as guinea
The country with lima as its capital is known as
2024-08-01 02:50:17 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-08-01 02:53:05 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0462, -0.0190, -0.3408,  ...,  0.0684, -0.0990,  0.0756],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.9336, -3.8555,  1.4971,  ..., -0.7686, -1.6367, -3.0020],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 5.3253e-03, -2.5055e-02,  2.8107e-02,  ..., -2.1706e-03,
          2.0767e-02, -7.6561e-03],
        [ 3.4851e-02,  6.9427e-03, -1.8265e-02,  ..., -4.1229e-02,
          2.7267e-02, -5.5695e-02],
        [ 2.4155e-02,  5.6915e-02,  2.9236e-02,  ...,  2.0081e-02,
          5.3482e-03, -4.8828e-03],
        ...,
        [ 2.4200e-02,  3.2715e-02, -4.4312e-02,  ...,  3.2440e-02,
          8.2550e-03, -1.2444e-02],
        [-6.1035e-05, -5.8258e-02, -7.2632e-03,  ..., -5.8556e-03,
          2.8198e-02, -1.6968e-02],
        [ 6.8054e-03, -9.7198e-03, -2.6054e-03,  ...,  1.4359e-02,
         -9.2621e-03,  5.1346e-03]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.9766, -4.4688,  1.1875,  ..., -1.2402, -1.8330, -2.4980]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 02:53:06 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country with damascus as its capital is known as syria
The country with cairo as its capital is known as egypt
The country with amman as its capital is known as jordan
The country with lisbon as its capital is known as portugal
The country with dublin as its capital is known as ireland
The country with berlin as its capital is known as germany
The country with conakry as its capital is known as guinea
The country with lima as its capital is known as
2024-08-01 02:53:06 root INFO     [order_1_approx] starting weight calculation for The country with berlin as its capital is known as germany
The country with dublin as its capital is known as ireland
The country with amman as its capital is known as jordan
The country with cairo as its capital is known as egypt
The country with lisbon as its capital is known as portugal
The country with damascus as its capital is known as syria
The country with lima as its capital is known as peru
The country with conakry as its capital is known as
2024-08-01 02:53:06 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-08-01 02:55:55 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1406,  0.0015, -0.7686,  ...,  0.2336, -0.2122,  0.2852],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.4023, -5.4766,  2.4277,  ..., -0.8062, -0.0073, -1.0820],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0360,  0.0106, -0.0001,  ...,  0.0206,  0.0149, -0.0251],
        [-0.0053, -0.0057,  0.0153,  ..., -0.0231,  0.0153, -0.0235],
        [ 0.0012, -0.0153, -0.0019,  ..., -0.0186,  0.0107, -0.0282],
        ...,
        [ 0.0286, -0.0045, -0.0003,  ...,  0.0080,  0.0163,  0.0011],
        [ 0.0069,  0.0079, -0.0110,  ...,  0.0200,  0.0145,  0.0010],
        [-0.0021, -0.0214, -0.0193,  ..., -0.0018,  0.0138, -0.0146]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.9180, -4.8984,  2.6680,  ..., -0.9541, -0.3599, -0.7012]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 02:55:56 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country with berlin as its capital is known as germany
The country with dublin as its capital is known as ireland
The country with amman as its capital is known as jordan
The country with cairo as its capital is known as egypt
The country with lisbon as its capital is known as portugal
The country with damascus as its capital is known as syria
The country with lima as its capital is known as peru
The country with conakry as its capital is known as
2024-08-01 02:55:57 root INFO     [order_1_approx] starting weight calculation for The country with berlin as its capital is known as germany
The country with conakry as its capital is known as guinea
The country with amman as its capital is known as jordan
The country with dublin as its capital is known as ireland
The country with damascus as its capital is known as syria
The country with lima as its capital is known as peru
The country with cairo as its capital is known as egypt
The country with lisbon as its capital is known as
2024-08-01 02:55:57 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-08-01 02:58:45 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0521, -0.0041, -0.5312,  ...,  0.2140, -0.0933, -0.0614],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.9922, -5.8516, -2.7773,  ...,  0.0322,  1.5918, -4.0391],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0120, -0.0039,  0.0016,  ...,  0.0077,  0.0114, -0.0095],
        [-0.0031,  0.0058, -0.0010,  ..., -0.0199, -0.0197, -0.0080],
        [ 0.0192,  0.0027,  0.0106,  ..., -0.0119,  0.0219, -0.0165],
        ...,
        [ 0.0090,  0.0103, -0.0013,  ...,  0.0281, -0.0050, -0.0065],
        [-0.0013,  0.0037, -0.0098,  ..., -0.0065,  0.0190, -0.0003],
        [ 0.0091, -0.0122, -0.0141,  ..., -0.0228, -0.0122, -0.0065]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.8730, -5.9766, -2.6270,  ...,  0.0813,  1.7695, -4.0156]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 02:58:46 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country with berlin as its capital is known as germany
The country with conakry as its capital is known as guinea
The country with amman as its capital is known as jordan
The country with dublin as its capital is known as ireland
The country with damascus as its capital is known as syria
The country with lima as its capital is known as peru
The country with cairo as its capital is known as egypt
The country with lisbon as its capital is known as
2024-08-01 02:58:46 root INFO     [order_1_approx] starting weight calculation for The country with damascus as its capital is known as syria
The country with lima as its capital is known as peru
The country with amman as its capital is known as jordan
The country with dublin as its capital is known as ireland
The country with lisbon as its capital is known as portugal
The country with conakry as its capital is known as guinea
The country with cairo as its capital is known as egypt
The country with berlin as its capital is known as
2024-08-01 02:58:47 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-08-01 03:01:31 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2091,  0.0467, -0.4285,  ...,  0.4399, -0.0637, -0.1111],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-6.7383e-02, -5.5078e+00, -7.1289e-01,  ..., -5.3711e-03,
         8.7109e-01, -4.7578e+00], device='cuda:1', dtype=torch.float16,
       grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0156,  0.0046, -0.0090,  ...,  0.0208,  0.0118,  0.0034],
        [ 0.0090,  0.0029,  0.0399,  ...,  0.0047, -0.0139, -0.0379],
        [-0.0060,  0.0455,  0.0426,  ...,  0.0128, -0.0337, -0.0011],
        ...,
        [ 0.0102,  0.0102,  0.0004,  ...,  0.0378, -0.0335, -0.0238],
        [ 0.0015, -0.0036, -0.0095,  ...,  0.0231,  0.0177, -0.0081],
        [-0.0123,  0.0028,  0.0229,  ..., -0.0085, -0.0158,  0.0259]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.2754, -5.3320, -0.6357,  ...,  0.3867,  0.4578, -4.1875]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 03:01:32 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country with damascus as its capital is known as syria
The country with lima as its capital is known as peru
The country with amman as its capital is known as jordan
The country with dublin as its capital is known as ireland
The country with lisbon as its capital is known as portugal
The country with conakry as its capital is known as guinea
The country with cairo as its capital is known as egypt
The country with berlin as its capital is known as
2024-08-01 03:01:32 root INFO     [order_1_approx] starting weight calculation for The country with lisbon as its capital is known as portugal
The country with cairo as its capital is known as egypt
The country with berlin as its capital is known as germany
The country with conakry as its capital is known as guinea
The country with lima as its capital is known as peru
The country with damascus as its capital is known as syria
The country with dublin as its capital is known as ireland
The country with amman as its capital is known as
2024-08-01 03:01:32 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-08-01 03:04:20 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1030,  0.0609, -0.2686,  ...,  0.3303, -0.3760, -0.0662],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.0205, -4.4609,  0.8872,  ..., -0.6191, -0.1699, -2.2422],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 3.7964e-02, -1.3382e-02, -8.7738e-04,  ...,  8.2397e-03,
          1.0271e-03, -1.1719e-02],
        [-7.4387e-03, -6.2790e-03,  3.2440e-02,  ...,  3.2196e-02,
          2.0203e-02,  2.0351e-03],
        [-2.4734e-02,  2.7023e-02,  2.8778e-02,  ..., -2.9114e-02,
         -5.3406e-05, -5.2567e-03],
        ...,
        [-5.7411e-03,  3.9673e-02, -7.0343e-03,  ...,  4.2267e-02,
         -1.0818e-02, -3.3447e-02],
        [ 2.7039e-02,  7.2784e-03,  7.4654e-03,  ..., -2.5879e-02,
         -7.1564e-03, -7.8659e-03],
        [-1.3062e-02,  2.5467e-02,  3.5095e-02,  ...,  4.8248e-02,
         -1.2596e-02,  1.2123e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.5635, -4.4297,  0.6631,  ..., -0.6914,  0.3306, -2.2344]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 03:04:21 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country with lisbon as its capital is known as portugal
The country with cairo as its capital is known as egypt
The country with berlin as its capital is known as germany
The country with conakry as its capital is known as guinea
The country with lima as its capital is known as peru
The country with damascus as its capital is known as syria
The country with dublin as its capital is known as ireland
The country with amman as its capital is known as
2024-08-01 03:04:21 root INFO     [order_1_approx] starting weight calculation for The country with amman as its capital is known as jordan
The country with conakry as its capital is known as guinea
The country with berlin as its capital is known as germany
The country with lisbon as its capital is known as portugal
The country with lima as its capital is known as peru
The country with dublin as its capital is known as ireland
The country with damascus as its capital is known as syria
The country with cairo as its capital is known as
2024-08-01 03:04:21 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-08-01 03:07:09 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1204, -0.0218, -0.4324,  ...,  0.4170, -0.2258,  0.0049],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.7559, -3.2695,  2.0137,  ..., -0.5151,  0.7905, -1.7207],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0474, -0.0244,  0.0010,  ..., -0.0125, -0.0119, -0.0134],
        [ 0.0110,  0.0142,  0.0281,  ...,  0.0162,  0.0251, -0.0147],
        [-0.0094,  0.0494,  0.0820,  ...,  0.0094,  0.0032,  0.0065],
        ...,
        [ 0.0149,  0.0547,  0.0149,  ...,  0.0450, -0.0161, -0.0170],
        [ 0.0104, -0.0327, -0.0092,  ..., -0.0070,  0.0144, -0.0006],
        [ 0.0173,  0.0266,  0.0406,  ...,  0.0332, -0.0077,  0.0122]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.6172, -3.0781,  1.3398,  ..., -0.5464,  0.8149, -1.7080]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 03:07:10 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country with amman as its capital is known as jordan
The country with conakry as its capital is known as guinea
The country with berlin as its capital is known as germany
The country with lisbon as its capital is known as portugal
The country with lima as its capital is known as peru
The country with dublin as its capital is known as ireland
The country with damascus as its capital is known as syria
The country with cairo as its capital is known as
2024-08-01 03:07:10 root INFO     [order_1_approx] starting weight calculation for The country with conakry as its capital is known as guinea
The country with lima as its capital is known as peru
The country with lisbon as its capital is known as portugal
The country with amman as its capital is known as jordan
The country with damascus as its capital is known as syria
The country with cairo as its capital is known as egypt
The country with berlin as its capital is known as germany
The country with dublin as its capital is known as
2024-08-01 03:07:10 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-08-01 03:09:59 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2021,  0.1538, -0.5034,  ...,  0.3398, -0.0120, -0.1014],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.4277, -5.5312, -1.4180,  ...,  1.8555, -1.1162, -6.9297],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0469, -0.0112,  0.0230,  ...,  0.0153, -0.0148, -0.0003],
        [-0.0254,  0.0037, -0.0381,  ..., -0.0341, -0.0068, -0.0193],
        [ 0.0196,  0.0113,  0.0190,  ...,  0.0213,  0.0107, -0.0121],
        ...,
        [ 0.0225,  0.0273, -0.0002,  ...,  0.0253,  0.0182, -0.0318],
        [-0.0200, -0.0160, -0.0245,  ..., -0.0172,  0.0004, -0.0184],
        [-0.0025, -0.0259,  0.0103,  ..., -0.0128, -0.0081,  0.0027]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.4551, -5.6445, -1.4502,  ...,  1.4492, -0.7925, -6.4375]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 03:10:00 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country with conakry as its capital is known as guinea
The country with lima as its capital is known as peru
The country with lisbon as its capital is known as portugal
The country with amman as its capital is known as jordan
The country with damascus as its capital is known as syria
The country with cairo as its capital is known as egypt
The country with berlin as its capital is known as germany
The country with dublin as its capital is known as
2024-08-01 03:10:00 root INFO     [order_1_approx] starting weight calculation for The country with berlin as its capital is known as germany
The country with cairo as its capital is known as egypt
The country with amman as its capital is known as jordan
The country with lima as its capital is known as peru
The country with lisbon as its capital is known as portugal
The country with conakry as its capital is known as guinea
The country with dublin as its capital is known as ireland
The country with damascus as its capital is known as
2024-08-01 03:10:00 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-08-01 03:12:49 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0287, -0.1614, -0.2842,  ...,  0.1076, -0.2239, -0.1201],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.5195, -5.6328, -1.0059,  ..., -0.0200,  1.8809, -4.4531],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0009, -0.0097, -0.0122,  ...,  0.0093,  0.0057, -0.0043],
        [ 0.0107, -0.0148,  0.0121,  ..., -0.0007,  0.0023, -0.0032],
        [-0.0251,  0.0110,  0.0079,  ..., -0.0289, -0.0018, -0.0106],
        ...,
        [ 0.0052,  0.0155, -0.0099,  ...,  0.0036, -0.0072, -0.0051],
        [ 0.0119, -0.0094,  0.0071,  ...,  0.0053,  0.0157,  0.0029],
        [-0.0125, -0.0090, -0.0013,  ..., -0.0019, -0.0052, -0.0042]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.4590, -5.5625, -0.8999,  ...,  0.0456,  1.9912, -4.3711]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 03:12:50 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country with berlin as its capital is known as germany
The country with cairo as its capital is known as egypt
The country with amman as its capital is known as jordan
The country with lima as its capital is known as peru
The country with lisbon as its capital is known as portugal
The country with conakry as its capital is known as guinea
The country with dublin as its capital is known as ireland
The country with damascus as its capital is known as
2024-08-01 03:12:50 root INFO     total operator prediction time: 1353.2453315258026 seconds
2024-08-01 03:12:50 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on things - color
2024-08-01 03:12:50 root INFO     building operator things - color
2024-08-01 03:12:50 root INFO     [order_1_approx] starting weight calculation for The crow is colored black
The cranberry is colored red
The sun is colored yellow
The parsley is colored green
The fridge is colored white
The tomato is colored red
The cabbage is colored green
The grass is colored
2024-08-01 03:12:50 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-08-01 03:15:42 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0345,  0.1611, -0.2603,  ..., -0.1187, -0.0410, -0.1865],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.2744, -7.2930, -2.6172,  ..., -0.9961,  1.4141, -3.0547],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0479,  0.0135,  0.0179,  ...,  0.0020, -0.0373,  0.0210],
        [-0.0119,  0.0098,  0.0020,  ..., -0.0201,  0.0268, -0.0572],
        [ 0.0047, -0.0061,  0.0479,  ...,  0.0235, -0.0041,  0.0100],
        ...,
        [ 0.0122, -0.0458, -0.0019,  ...,  0.0181,  0.0249, -0.0234],
        [-0.0058,  0.0059,  0.0028,  ..., -0.0104,  0.0330,  0.0111],
        [ 0.0192, -0.0165,  0.0214,  ...,  0.0180,  0.0132, -0.0022]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.4619, -7.2852, -2.6055,  ..., -1.0469,  2.2363, -3.4805]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 03:15:43 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The crow is colored black
The cranberry is colored red
The sun is colored yellow
The parsley is colored green
The fridge is colored white
The tomato is colored red
The cabbage is colored green
The grass is colored
2024-08-01 03:15:43 root INFO     [order_1_approx] starting weight calculation for The cranberry is colored red
The sun is colored yellow
The parsley is colored green
The fridge is colored white
The grass is colored green
The tomato is colored red
The crow is colored black
The cabbage is colored
2024-08-01 03:15:43 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-08-01 03:18:34 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0709,  0.3184, -0.2815,  ..., -0.2234, -0.1899,  0.0056],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.4504, -5.6211, -1.8008,  ...,  1.2295,  1.1172, -2.4961],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-1.2360e-02,  2.5238e-02, -6.6605e-03,  ..., -3.3844e-02,
          3.4973e-02,  1.2299e-02],
        [ 2.3376e-02,  5.5618e-03,  1.3878e-02,  ..., -3.5187e-02,
          3.9551e-02, -3.2845e-03],
        [ 5.4474e-03, -3.3569e-02,  2.6550e-02,  ...,  1.7014e-02,
         -2.7710e-02,  1.1093e-02],
        ...,
        [ 1.4267e-02, -6.7200e-02,  2.1423e-02,  ...,  1.0394e-01,
          9.9182e-05,  2.3804e-02],
        [-1.9363e-02,  1.7643e-03, -7.2212e-03,  ...,  4.2877e-02,
          8.6594e-03, -2.2659e-02],
        [-3.5797e-02, -1.2932e-02, -2.7710e-02,  ...,  2.3422e-02,
          7.6294e-05,  4.3915e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.9912, -5.2461, -2.0664,  ...,  0.7969,  1.1514, -2.2461]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 03:18:35 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The cranberry is colored red
The sun is colored yellow
The parsley is colored green
The fridge is colored white
The grass is colored green
The tomato is colored red
The crow is colored black
The cabbage is colored
2024-08-01 03:18:36 root INFO     [order_1_approx] starting weight calculation for The cranberry is colored red
The sun is colored yellow
The grass is colored green
The crow is colored black
The parsley is colored green
The cabbage is colored green
The fridge is colored white
The tomato is colored
2024-08-01 03:18:36 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-08-01 03:21:27 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2646,  0.0372, -0.1837,  ...,  0.0128, -0.1758, -0.2759],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-2.3555, -8.9141, -0.1143,  ..., -1.2881,  1.3809, -1.5859],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0028, -0.0317, -0.0011,  ..., -0.0575,  0.0016, -0.0270],
        [ 0.0008, -0.0198, -0.0030,  ...,  0.0201,  0.0031, -0.0335],
        [ 0.0037,  0.0409,  0.0226,  ...,  0.0627, -0.0055,  0.0366],
        ...,
        [ 0.0076, -0.0415, -0.0281,  ...,  0.0993,  0.0042,  0.0113],
        [-0.0042,  0.0104, -0.0126,  ...,  0.0221,  0.0236,  0.0003],
        [-0.0207, -0.0522,  0.0002,  ...,  0.0312, -0.0075,  0.0264]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.7559, -9.1562, -0.3704,  ..., -1.6523,  1.1582, -1.6230]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 03:21:27 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The cranberry is colored red
The sun is colored yellow
The grass is colored green
The crow is colored black
The parsley is colored green
The cabbage is colored green
The fridge is colored white
The tomato is colored
2024-08-01 03:21:28 root INFO     [order_1_approx] starting weight calculation for The cabbage is colored green
The crow is colored black
The fridge is colored white
The parsley is colored green
The sun is colored yellow
The tomato is colored red
The grass is colored green
The cranberry is colored
2024-08-01 03:21:28 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-08-01 03:24:18 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2295, -0.2384, -0.6714,  ...,  0.1670, -0.2727, -0.1157],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-4.1602, -7.3242, -1.0977,  ..., -1.7959,  1.6660, -0.2993],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0486, -0.0097,  0.0007,  ..., -0.0250,  0.0046,  0.0098],
        [-0.0054,  0.0173,  0.0243,  ..., -0.0168,  0.0524, -0.0202],
        [ 0.0048,  0.0074,  0.0142,  ...,  0.0394, -0.0265,  0.0084],
        ...,
        [ 0.0167, -0.0285, -0.0050,  ...,  0.0825,  0.0014, -0.0172],
        [-0.0036, -0.0076, -0.0080,  ...,  0.0343,  0.0468, -0.0090],
        [ 0.0051, -0.0103, -0.0059,  ..., -0.0100,  0.0049,  0.0099]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-4.2695, -7.1289, -1.3008,  ..., -1.6162,  1.3574, -0.1313]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 03:24:19 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The cabbage is colored green
The crow is colored black
The fridge is colored white
The parsley is colored green
The sun is colored yellow
The tomato is colored red
The grass is colored green
The cranberry is colored
2024-08-01 03:24:19 root INFO     [order_1_approx] starting weight calculation for The cranberry is colored red
The sun is colored yellow
The grass is colored green
The cabbage is colored green
The parsley is colored green
The tomato is colored red
The fridge is colored white
The crow is colored
2024-08-01 03:24:19 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-08-01 03:27:11 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1459,  0.0113, -0.1158,  ..., -0.2524, -0.1597, -0.0148],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.3926, -4.4648,  2.5000,  ..., -0.3950,  1.2988, -0.6333],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0269,  0.0045, -0.0060,  ..., -0.0346, -0.0017,  0.0028],
        [-0.0385,  0.0082,  0.0110,  ...,  0.0017, -0.0042,  0.0505],
        [-0.0450,  0.0069, -0.0061,  ...,  0.0074, -0.0234,  0.0057],
        ...,
        [ 0.0054, -0.0118,  0.0216,  ...,  0.0568,  0.0041,  0.0262],
        [-0.0103,  0.0058, -0.0134,  ...,  0.0055, -0.0032,  0.0065],
        [ 0.0041, -0.0306,  0.0455,  ..., -0.0163, -0.0218,  0.0081]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.7627, -4.7148,  3.2227,  ..., -0.4045,  0.7778, -1.2754]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 03:27:12 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The cranberry is colored red
The sun is colored yellow
The grass is colored green
The cabbage is colored green
The parsley is colored green
The tomato is colored red
The fridge is colored white
The crow is colored
2024-08-01 03:27:12 root INFO     [order_1_approx] starting weight calculation for The grass is colored green
The parsley is colored green
The cranberry is colored red
The cabbage is colored green
The fridge is colored white
The crow is colored black
The tomato is colored red
The sun is colored
2024-08-01 03:27:12 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-08-01 03:30:00 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0846, -0.0217, -0.2930,  ..., -0.2473, -0.1277, -0.2078],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-3.9570, -8.0938, -0.4072,  ..., -2.0508, -1.2207, -0.4346],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0102, -0.0158, -0.0021,  ..., -0.0007, -0.0109,  0.0111],
        [ 0.0186, -0.0125,  0.0188,  ..., -0.0065,  0.0267,  0.0063],
        [-0.0001,  0.0081,  0.0242,  ...,  0.0329,  0.0081,  0.0205],
        ...,
        [ 0.0024, -0.0197,  0.0246,  ...,  0.0505,  0.0050,  0.0038],
        [ 0.0015, -0.0240,  0.0292,  ...,  0.0227,  0.0115,  0.0182],
        [-0.0188, -0.0139,  0.0198,  ...,  0.0113,  0.0026,  0.0123]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-4.0430, -8.0938,  0.1611,  ..., -2.4980, -0.7319, -0.0684]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 03:30:01 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The grass is colored green
The parsley is colored green
The cranberry is colored red
The cabbage is colored green
The fridge is colored white
The crow is colored black
The tomato is colored red
The sun is colored
2024-08-01 03:30:02 root INFO     [order_1_approx] starting weight calculation for The grass is colored green
The tomato is colored red
The cabbage is colored green
The sun is colored yellow
The cranberry is colored red
The parsley is colored green
The crow is colored black
The fridge is colored
2024-08-01 03:30:02 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-08-01 03:32:51 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1132, -0.1008, -0.0486,  ...,  0.0325, -0.1989, -0.0309],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.4399, -8.1953,  0.5601,  ...,  1.0811, -3.3828, -1.0996],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0456,  0.0164,  0.0164,  ..., -0.0105, -0.0246,  0.0303],
        [-0.0202, -0.0105, -0.0037,  ..., -0.0002,  0.0029, -0.0048],
        [ 0.0242,  0.0006,  0.0137,  ...,  0.0375, -0.0268,  0.0075],
        ...,
        [-0.0060, -0.0146, -0.0070,  ...,  0.0224,  0.0140,  0.0069],
        [-0.0135, -0.0440,  0.0194,  ..., -0.0002,  0.0245, -0.0270],
        [-0.0253, -0.0455, -0.0108,  ..., -0.0094,  0.0190, -0.0002]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.6621, -8.1328,  0.8838,  ...,  0.6802, -3.1855, -1.2441]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 03:32:52 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The grass is colored green
The tomato is colored red
The cabbage is colored green
The sun is colored yellow
The cranberry is colored red
The parsley is colored green
The crow is colored black
The fridge is colored
2024-08-01 03:32:52 root INFO     [order_1_approx] starting weight calculation for The cabbage is colored green
The tomato is colored red
The cranberry is colored red
The grass is colored green
The crow is colored black
The fridge is colored white
The sun is colored yellow
The parsley is colored
2024-08-01 03:32:52 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-08-01 03:35:44 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0110,  0.0428, -0.4224,  ..., -0.0686, -0.2421, -0.1321],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.5825, -5.2344, -2.2578,  ..., -0.8179,  0.1978, -2.6348],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0611,  0.0214, -0.0019,  ..., -0.0481,  0.0206,  0.0325],
        [-0.0023,  0.0025,  0.0341,  ..., -0.0363,  0.0444,  0.0148],
        [-0.0384, -0.0211,  0.0168,  ...,  0.0181, -0.0239, -0.0146],
        ...,
        [ 0.0247, -0.0326,  0.0285,  ...,  0.0884, -0.0138, -0.0102],
        [-0.0062, -0.0171, -0.0226,  ...,  0.0170,  0.0375, -0.0007],
        [-0.0022, -0.0154, -0.0088,  ..., -0.0141,  0.0066,  0.0257]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.8428, -5.2109, -2.0605,  ..., -1.0176, -0.2029, -2.3047]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 03:35:45 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The cabbage is colored green
The tomato is colored red
The cranberry is colored red
The grass is colored green
The crow is colored black
The fridge is colored white
The sun is colored yellow
The parsley is colored
2024-08-01 03:35:45 root INFO     total operator prediction time: 1374.8262243270874 seconds
2024-08-01 03:35:45 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on animal - sound
2024-08-01 03:35:45 root INFO     building operator animal - sound
2024-08-01 03:35:45 root INFO     [order_1_approx] starting weight calculation for The sound that a snake makes is called a hiss
The sound that a hornet makes is called a buzz
The sound that a cat makes is called a meow
The sound that a cattle makes is called a moo
The sound that a monkey makes is called a chatter
The sound that a duck makes is called a quack
The sound that a dog makes is called a bark
The sound that a hound makes is called a
2024-08-01 03:35:45 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-08-01 03:38:36 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0262,  0.3262,  0.0506,  ..., -0.0009,  0.0013, -0.0274],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.1309, -5.4453,  0.2197,  ..., -1.0703, -1.0000,  3.3008],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0367,  0.0206,  0.0124,  ..., -0.0506, -0.0039,  0.0028],
        [-0.0372,  0.0177, -0.0108,  ..., -0.0165,  0.0159, -0.0166],
        [ 0.0259,  0.0079,  0.0370,  ...,  0.0076,  0.0342,  0.0070],
        ...,
        [ 0.0214, -0.0420,  0.0453,  ...,  0.0109,  0.0034, -0.0435],
        [-0.0149, -0.0411, -0.0314,  ..., -0.0006,  0.0424,  0.0162],
        [ 0.0083,  0.0100, -0.0053,  ..., -0.0138, -0.0123,  0.0348]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.1602, -5.0039,  0.4377,  ..., -0.3413, -0.9229,  3.3750]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 03:38:37 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The sound that a snake makes is called a hiss
The sound that a hornet makes is called a buzz
The sound that a cat makes is called a meow
The sound that a cattle makes is called a moo
The sound that a monkey makes is called a chatter
The sound that a duck makes is called a quack
The sound that a dog makes is called a bark
The sound that a hound makes is called a
2024-08-01 03:38:37 root INFO     [order_1_approx] starting weight calculation for The sound that a hornet makes is called a buzz
The sound that a hound makes is called a bark
The sound that a cat makes is called a meow
The sound that a cattle makes is called a moo
The sound that a monkey makes is called a chatter
The sound that a snake makes is called a hiss
The sound that a dog makes is called a bark
The sound that a duck makes is called a
2024-08-01 03:38:37 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-08-01 03:41:26 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1037,  0.1863,  0.1404,  ..., -0.0705, -0.1600, -0.1178],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.1064, -4.6562,  3.1914,  ...,  1.1416, -3.6504,  1.7090],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0431, -0.0142, -0.0083,  ...,  0.0052, -0.0160, -0.0280],
        [-0.0018,  0.0421,  0.0027,  ..., -0.0002, -0.0138,  0.0226],
        [ 0.0091, -0.0417,  0.0364,  ..., -0.0245, -0.0124, -0.0243],
        ...,
        [ 0.0180,  0.0699, -0.0483,  ...,  0.0368, -0.0377,  0.0217],
        [-0.0316, -0.0022,  0.0245,  ..., -0.0048,  0.0211, -0.0152],
        [-0.0128, -0.0074,  0.0104,  ..., -0.0429,  0.0085,  0.0074]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.1597e-03, -4.7773e+00,  3.3223e+00,  ...,  1.4863e+00,
         -3.8281e+00,  1.8604e+00]], device='cuda:1', dtype=torch.float16,
       grad_fn=<SubBackward0>) 

                    
2024-08-01 03:41:27 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The sound that a hornet makes is called a buzz
The sound that a hound makes is called a bark
The sound that a cat makes is called a meow
The sound that a cattle makes is called a moo
The sound that a monkey makes is called a chatter
The sound that a snake makes is called a hiss
The sound that a dog makes is called a bark
The sound that a duck makes is called a
2024-08-01 03:41:27 root INFO     [order_1_approx] starting weight calculation for The sound that a snake makes is called a hiss
The sound that a monkey makes is called a chatter
The sound that a duck makes is called a quack
The sound that a hound makes is called a bark
The sound that a hornet makes is called a buzz
The sound that a cat makes is called a meow
The sound that a cattle makes is called a moo
The sound that a dog makes is called a
2024-08-01 03:41:27 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-08-01 03:44:14 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.3176,  0.0637,  0.0979,  ...,  0.0013, -0.2069, -0.0681],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.0645, -6.3125,  0.4609,  ..., -2.0312, -0.9692,  1.9590],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0076, -0.0181,  0.0251,  ..., -0.0210, -0.0199, -0.0139],
        [ 0.0055,  0.0390, -0.0332,  ..., -0.0080,  0.0069,  0.0076],
        [-0.0042, -0.0193,  0.0250,  ..., -0.0050, -0.0138, -0.0246],
        ...,
        [ 0.0145,  0.0039, -0.0167,  ...,  0.0251, -0.0019,  0.0066],
        [-0.0020, -0.0163, -0.0103,  ...,  0.0048,  0.0205,  0.0007],
        [-0.0027, -0.0094, -0.0108,  ..., -0.0152,  0.0047,  0.0024]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.4443, -6.5781,  0.7812,  ..., -2.2578, -0.7930,  2.0156]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 03:44:15 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The sound that a snake makes is called a hiss
The sound that a monkey makes is called a chatter
The sound that a duck makes is called a quack
The sound that a hound makes is called a bark
The sound that a hornet makes is called a buzz
The sound that a cat makes is called a meow
The sound that a cattle makes is called a moo
The sound that a dog makes is called a
2024-08-01 03:44:15 root INFO     [order_1_approx] starting weight calculation for The sound that a monkey makes is called a chatter
The sound that a snake makes is called a hiss
The sound that a cat makes is called a meow
The sound that a duck makes is called a quack
The sound that a hound makes is called a bark
The sound that a cattle makes is called a moo
The sound that a dog makes is called a bark
The sound that a hornet makes is called a
2024-08-01 03:44:15 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-08-01 03:46:58 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1765,  0.1274,  0.1813,  ...,  0.0869, -0.0969,  0.1410],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.4561, -2.0957,  2.2324,  ..., -0.5073, -1.4648,  2.0391],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 4.2603e-02, -6.2790e-03,  6.5956e-03,  ..., -4.2908e-02,
         -2.6276e-02, -2.9297e-02],
        [-4.1168e-02,  1.9073e-02, -1.7288e-02,  ...,  2.6413e-02,
         -2.8473e-02,  4.3869e-03],
        [ 1.6983e-02,  4.5837e-02,  1.6205e-02,  ...,  1.9745e-02,
          1.1921e-05,  5.4817e-03],
        ...,
        [-1.1749e-02,  1.1818e-02,  1.3039e-02,  ...,  5.0964e-02,
         -3.8940e-02, -1.0559e-02],
        [ 1.3542e-02, -3.9215e-03, -3.7193e-03,  ..., -5.5573e-02,
         -9.8267e-03, -3.0869e-02],
        [-2.3102e-02,  1.4320e-02, -4.6959e-03,  ..., -4.4464e-02,
         -1.2535e-02,  1.6357e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.8765, -1.8643,  1.8096,  ..., -0.3921, -1.9746,  2.1777]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 03:46:59 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The sound that a monkey makes is called a chatter
The sound that a snake makes is called a hiss
The sound that a cat makes is called a meow
The sound that a duck makes is called a quack
The sound that a hound makes is called a bark
The sound that a cattle makes is called a moo
The sound that a dog makes is called a bark
The sound that a hornet makes is called a
2024-08-01 03:46:59 root INFO     [order_1_approx] starting weight calculation for The sound that a hound makes is called a bark
The sound that a cat makes is called a meow
The sound that a duck makes is called a quack
The sound that a cattle makes is called a moo
The sound that a dog makes is called a bark
The sound that a snake makes is called a hiss
The sound that a hornet makes is called a buzz
The sound that a monkey makes is called a
2024-08-01 03:47:00 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-08-01 03:49:46 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0208,  0.0479,  0.0823,  ...,  0.0820, -0.4478,  0.0760],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.5684, -2.8047,  2.0977,  ..., -1.0332, -1.9805,  0.2686],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0464,  0.0285,  0.0161,  ..., -0.0226, -0.0249, -0.0141],
        [-0.0110,  0.0246, -0.0085,  ..., -0.0218, -0.0446, -0.0115],
        [-0.0171,  0.0042,  0.0283,  ...,  0.0173,  0.0083, -0.0220],
        ...,
        [-0.0015,  0.0099, -0.0017,  ...,  0.0265, -0.0138,  0.0087],
        [-0.0009, -0.0431,  0.0231,  ..., -0.0092,  0.0047,  0.0098],
        [-0.0238, -0.0038, -0.0160,  ..., -0.0321,  0.0206,  0.0226]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.4395, -2.9004,  2.0625,  ..., -0.8638, -2.0410,  0.1497]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 03:49:47 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The sound that a hound makes is called a bark
The sound that a cat makes is called a meow
The sound that a duck makes is called a quack
The sound that a cattle makes is called a moo
The sound that a dog makes is called a bark
The sound that a snake makes is called a hiss
The sound that a hornet makes is called a buzz
The sound that a monkey makes is called a
2024-08-01 03:49:47 root INFO     [order_1_approx] starting weight calculation for The sound that a snake makes is called a hiss
The sound that a monkey makes is called a chatter
The sound that a duck makes is called a quack
The sound that a cattle makes is called a moo
The sound that a hornet makes is called a buzz
The sound that a hound makes is called a bark
The sound that a dog makes is called a bark
The sound that a cat makes is called a
2024-08-01 03:49:47 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-08-01 03:52:35 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0657,  0.1277,  0.0368,  ...,  0.0036, -0.1144, -0.0819],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.7324, -4.5625, -2.1016,  ..., -2.1016,  0.3652,  2.9590],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 1.7502e-02, -4.6577e-03,  7.7438e-04,  ..., -2.1271e-02,
         -4.2480e-02, -1.3672e-02],
        [-6.6528e-03,  3.2959e-02,  1.7822e-02,  ..., -5.9967e-03,
          1.4191e-02, -2.0847e-03],
        [ 8.7204e-03, -2.4567e-02,  2.4994e-02,  ..., -1.1246e-02,
         -2.2240e-03,  9.5367e-05],
        ...,
        [-1.0803e-02,  1.1063e-02, -5.8441e-03,  ...,  2.2339e-02,
          1.4717e-02, -7.1602e-03],
        [ 9.4910e-03, -9.7198e-03, -2.0462e-02,  ..., -1.4885e-02,
          1.4282e-02,  2.3651e-03],
        [ 3.9330e-03, -1.2465e-03, -2.0874e-02,  ..., -2.0905e-02,
         -2.2125e-03,  1.3969e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.7349, -4.4688, -2.3809,  ..., -1.7949,  0.7754,  3.1055]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 03:52:37 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The sound that a snake makes is called a hiss
The sound that a monkey makes is called a chatter
The sound that a duck makes is called a quack
The sound that a cattle makes is called a moo
The sound that a hornet makes is called a buzz
The sound that a hound makes is called a bark
The sound that a dog makes is called a bark
The sound that a cat makes is called a
2024-08-01 03:52:37 root INFO     [order_1_approx] starting weight calculation for The sound that a hound makes is called a bark
The sound that a hornet makes is called a buzz
The sound that a cat makes is called a meow
The sound that a monkey makes is called a chatter
The sound that a dog makes is called a bark
The sound that a duck makes is called a quack
The sound that a cattle makes is called a moo
The sound that a snake makes is called a
2024-08-01 03:52:37 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-08-01 03:55:25 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1177,  0.2627, -0.0380,  ..., -0.1566, -0.0641,  0.0972],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.9814, -2.2031,  1.5381,  ...,  0.3225, -0.5449,  2.7305],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0009,  0.0155, -0.0142,  ..., -0.0207, -0.0154, -0.0344],
        [-0.0262,  0.0217, -0.0085,  ..., -0.0278, -0.0104,  0.0024],
        [ 0.0099, -0.0025,  0.0428,  ..., -0.0469,  0.0044,  0.0069],
        ...,
        [-0.0122,  0.0382, -0.0203,  ...,  0.0608, -0.0500, -0.0437],
        [-0.0068,  0.0022, -0.0037,  ..., -0.0051,  0.0260, -0.0306],
        [ 0.0322, -0.0110, -0.0252,  ...,  0.0391, -0.0042,  0.0196]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.1768, -2.2676,  1.3184,  ...,  0.3462, -0.6636,  2.7148]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 03:55:26 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The sound that a hound makes is called a bark
The sound that a hornet makes is called a buzz
The sound that a cat makes is called a meow
The sound that a monkey makes is called a chatter
The sound that a dog makes is called a bark
The sound that a duck makes is called a quack
The sound that a cattle makes is called a moo
The sound that a snake makes is called a
2024-08-01 03:55:26 root INFO     [order_1_approx] starting weight calculation for The sound that a dog makes is called a bark
The sound that a monkey makes is called a chatter
The sound that a duck makes is called a quack
The sound that a cat makes is called a meow
The sound that a hornet makes is called a buzz
The sound that a hound makes is called a bark
The sound that a snake makes is called a hiss
The sound that a cattle makes is called a
2024-08-01 03:55:27 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-08-01 03:58:10 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2112,  0.0502, -0.0150,  ..., -0.1951, -0.0178,  0.0428],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.1064, -4.9570,  3.5957,  ..., -0.1250,  3.4258, -0.0488],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0609, -0.0058,  0.0228,  ..., -0.0131, -0.0182, -0.0097],
        [ 0.0041,  0.0239, -0.0272,  ..., -0.0289,  0.0136,  0.0029],
        [-0.0173, -0.0114,  0.0748,  ..., -0.0175,  0.0131, -0.0154],
        ...,
        [-0.0289,  0.0392, -0.0240,  ...,  0.0469, -0.0028, -0.0064],
        [ 0.0255,  0.0057, -0.0272,  ..., -0.0092, -0.0135,  0.0124],
        [ 0.0219, -0.0062,  0.0039,  ..., -0.0252,  0.0256,  0.0325]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.0261, -4.8711,  3.2695,  ..., -0.0274,  3.1992, -0.3586]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 03:58:11 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The sound that a dog makes is called a bark
The sound that a monkey makes is called a chatter
The sound that a duck makes is called a quack
The sound that a cat makes is called a meow
The sound that a hornet makes is called a buzz
The sound that a hound makes is called a bark
The sound that a snake makes is called a hiss
The sound that a cattle makes is called a
2024-08-01 03:58:11 root INFO     total operator prediction time: 1345.8191323280334 seconds
2024-08-01 03:58:11 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on animal - youth
2024-08-01 03:58:11 root INFO     building operator animal - youth
2024-08-01 03:58:11 root INFO     [order_1_approx] starting weight calculation for The offspring of a lion is referred to as a cub
The offspring of a cockroach is referred to as a nymph
The offspring of a sheep is referred to as a lamb
The offspring of a herring is referred to as a fingerling
The offspring of a weasel is referred to as a kit
The offspring of a cricket is referred to as a larva
The offspring of a goat is referred to as a kid
The offspring of a panda is referred to as a
2024-08-01 03:58:11 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-08-01 04:01:02 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0906, -0.0168, -0.3003,  ..., -0.1511, -0.2150,  0.1328],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.4609, -3.9922, -0.9424,  ..., -0.9307, -2.2695,  2.4180],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0302, -0.0177, -0.0192,  ...,  0.0092, -0.0241, -0.0012],
        [-0.0117,  0.0520, -0.0366,  ...,  0.0262, -0.0182, -0.0099],
        [-0.0099,  0.0259,  0.0257,  ...,  0.0088,  0.0281, -0.0352],
        ...,
        [ 0.0414,  0.0381, -0.0478,  ...,  0.0658, -0.0345,  0.0051],
        [-0.0154, -0.0177,  0.0010,  ...,  0.0215,  0.0056, -0.0067],
        [ 0.0110,  0.0010,  0.0185,  ..., -0.0120,  0.0387,  0.0027]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.6035, -3.5898, -0.6748,  ..., -0.5547, -1.8154,  1.9277]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 04:01:03 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The offspring of a lion is referred to as a cub
The offspring of a cockroach is referred to as a nymph
The offspring of a sheep is referred to as a lamb
The offspring of a herring is referred to as a fingerling
The offspring of a weasel is referred to as a kit
The offspring of a cricket is referred to as a larva
The offspring of a goat is referred to as a kid
The offspring of a panda is referred to as a
2024-08-01 04:01:03 root INFO     [order_1_approx] starting weight calculation for The offspring of a weasel is referred to as a kit
The offspring of a panda is referred to as a cub
The offspring of a lion is referred to as a cub
The offspring of a goat is referred to as a kid
The offspring of a cricket is referred to as a larva
The offspring of a cockroach is referred to as a nymph
The offspring of a herring is referred to as a fingerling
The offspring of a sheep is referred to as a
2024-08-01 04:01:03 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-08-01 04:03:50 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0342, -0.0280, -0.1302,  ...,  0.0752, -0.0645,  0.0920],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.5625, -1.9062,  0.1006,  ...,  2.6602, -2.7793, -1.0586],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 1.7227e-02, -4.5052e-03,  2.4658e-02,  ..., -2.7847e-03,
         -5.8594e-02, -2.5070e-02],
        [-4.5738e-03,  1.7197e-02, -1.5366e-02,  ..., -3.2539e-03,
          2.5848e-02,  3.4599e-03],
        [ 2.4994e-02, -3.1860e-02,  6.9214e-02,  ..., -1.0773e-02,
         -2.8885e-02,  1.1803e-02],
        ...,
        [ 1.1795e-02,  4.7363e-02, -1.4832e-02,  ...,  5.9387e-02,
          4.3091e-02,  4.4060e-03],
        [ 2.4166e-03,  1.4648e-02, -1.1681e-02,  ..., -1.2138e-02,
          1.9913e-02,  1.2161e-02],
        [-5.3787e-03,  2.2156e-02, -2.0248e-02,  ..., -1.2924e-02,
         -8.5449e-03,  1.0490e-05]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.0645, -2.4531,  0.3770,  ...,  1.7285, -2.6953, -0.5405]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 04:03:51 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The offspring of a weasel is referred to as a kit
The offspring of a panda is referred to as a cub
The offspring of a lion is referred to as a cub
The offspring of a goat is referred to as a kid
The offspring of a cricket is referred to as a larva
The offspring of a cockroach is referred to as a nymph
The offspring of a herring is referred to as a fingerling
The offspring of a sheep is referred to as a
2024-08-01 04:03:51 root INFO     [order_1_approx] starting weight calculation for The offspring of a herring is referred to as a fingerling
The offspring of a panda is referred to as a cub
The offspring of a sheep is referred to as a lamb
The offspring of a goat is referred to as a kid
The offspring of a cricket is referred to as a larva
The offspring of a weasel is referred to as a kit
The offspring of a cockroach is referred to as a nymph
The offspring of a lion is referred to as a
2024-08-01 04:03:51 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-08-01 04:06:36 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1189,  0.1689, -0.0241,  ..., -0.1747, -0.1062, -0.0927],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.5020, -5.5234, -1.2754,  ...,  1.8301, -1.1465,  0.6436],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 1.6136e-03, -2.3621e-02,  1.2054e-02,  ...,  4.3440e-04,
         -6.5575e-03, -6.1646e-03],
        [-1.1864e-02,  3.7231e-02, -2.4353e-02,  ...,  1.3283e-02,
         -2.0203e-02,  6.2027e-03],
        [-7.2575e-04, -3.0518e-05,  3.3112e-02,  ...,  3.6987e-02,
          3.4393e-02,  4.3579e-02],
        ...,
        [-7.5378e-03,  1.2177e-02,  5.0316e-03,  ...,  1.4633e-02,
          1.8219e-02,  3.5210e-03],
        [ 5.8632e-03,  3.4943e-02,  9.0942e-03,  ...,  4.1504e-02,
          1.3512e-02,  1.3741e-02],
        [ 2.3605e-02, -3.6957e-02,  8.6670e-03,  ..., -2.1133e-02,
         -7.1564e-03, -1.6766e-03]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.4922, -5.1445, -0.9351,  ...,  2.1895, -1.2188,  0.5439]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 04:06:37 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The offspring of a herring is referred to as a fingerling
The offspring of a panda is referred to as a cub
The offspring of a sheep is referred to as a lamb
The offspring of a goat is referred to as a kid
The offspring of a cricket is referred to as a larva
The offspring of a weasel is referred to as a kit
The offspring of a cockroach is referred to as a nymph
The offspring of a lion is referred to as a
2024-08-01 04:06:38 root INFO     [order_1_approx] starting weight calculation for The offspring of a weasel is referred to as a kit
The offspring of a sheep is referred to as a lamb
The offspring of a cricket is referred to as a larva
The offspring of a goat is referred to as a kid
The offspring of a herring is referred to as a fingerling
The offspring of a panda is referred to as a cub
The offspring of a lion is referred to as a cub
The offspring of a cockroach is referred to as a
2024-08-01 04:06:38 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-08-01 04:09:24 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0214, -0.0509, -0.2190,  ..., -0.1199, -0.3638, -0.3413],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.1492, -4.1055, -0.6958,  ..., -0.5938, -3.8438, -0.4570],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0068, -0.0063,  0.0053,  ..., -0.0150,  0.0067, -0.0201],
        [ 0.0268,  0.0093,  0.0062,  ..., -0.0020, -0.0007,  0.0113],
        [-0.0043, -0.0071, -0.0149,  ...,  0.0168,  0.0100, -0.0166],
        ...,
        [ 0.0261, -0.0030, -0.0076,  ...,  0.0148,  0.0033, -0.0048],
        [ 0.0318, -0.0003, -0.0016,  ...,  0.0279, -0.0013,  0.0179],
        [-0.0149,  0.0091,  0.0092,  ..., -0.0170,  0.0035,  0.0063]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.1187, -3.9785, -0.8970,  ..., -0.6074, -3.8867, -0.3765]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 04:09:25 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The offspring of a weasel is referred to as a kit
The offspring of a sheep is referred to as a lamb
The offspring of a cricket is referred to as a larva
The offspring of a goat is referred to as a kid
The offspring of a herring is referred to as a fingerling
The offspring of a panda is referred to as a cub
The offspring of a lion is referred to as a cub
The offspring of a cockroach is referred to as a
2024-08-01 04:09:25 root INFO     [order_1_approx] starting weight calculation for The offspring of a lion is referred to as a cub
The offspring of a panda is referred to as a cub
The offspring of a sheep is referred to as a lamb
The offspring of a cricket is referred to as a larva
The offspring of a goat is referred to as a kid
The offspring of a weasel is referred to as a kit
The offspring of a cockroach is referred to as a nymph
The offspring of a herring is referred to as a
2024-08-01 04:09:25 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-08-01 04:12:15 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2830,  0.1636, -0.2280,  ...,  0.0630, -0.1105, -0.2119],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.3271, -1.1914, -4.3594,  ...,  0.5781, -3.6250, -0.6689],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0222,  0.0173,  0.0179,  ..., -0.0130,  0.0101, -0.0271],
        [ 0.0287,  0.0423, -0.0105,  ..., -0.0058,  0.0127, -0.0040],
        [ 0.0592, -0.0109,  0.0280,  ...,  0.0205, -0.0080, -0.0153],
        ...,
        [-0.0015,  0.0160, -0.0239,  ...,  0.0225, -0.0421,  0.0184],
        [ 0.0043,  0.0291, -0.0019,  ...,  0.0316,  0.0334,  0.0007],
        [-0.0275,  0.0094, -0.0216,  ..., -0.0083,  0.0447,  0.0190]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.5244, -1.2832, -4.6016,  ...,  0.6055, -3.4941, -0.9810]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 04:12:16 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The offspring of a lion is referred to as a cub
The offspring of a panda is referred to as a cub
The offspring of a sheep is referred to as a lamb
The offspring of a cricket is referred to as a larva
The offspring of a goat is referred to as a kid
The offspring of a weasel is referred to as a kit
The offspring of a cockroach is referred to as a nymph
The offspring of a herring is referred to as a
2024-08-01 04:12:16 root INFO     [order_1_approx] starting weight calculation for The offspring of a goat is referred to as a kid
The offspring of a cockroach is referred to as a nymph
The offspring of a lion is referred to as a cub
The offspring of a sheep is referred to as a lamb
The offspring of a herring is referred to as a fingerling
The offspring of a panda is referred to as a cub
The offspring of a cricket is referred to as a larva
The offspring of a weasel is referred to as a
2024-08-01 04:12:16 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-08-01 04:15:05 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0278,  0.1111,  0.0437,  ..., -0.2593, -0.1757, -0.0254],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.7031, -2.7656, -0.8403,  ...,  1.5977, -1.6416,  2.0703],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0032, -0.0043,  0.0115,  ...,  0.0318,  0.0032, -0.0135],
        [-0.0111,  0.0208,  0.0095,  ...,  0.0042,  0.0097,  0.0101],
        [ 0.0009,  0.0020,  0.0033,  ...,  0.0061,  0.0064, -0.0027],
        ...,
        [ 0.0188,  0.0170,  0.0020,  ...,  0.0062,  0.0136, -0.0131],
        [-0.0033,  0.0090,  0.0129,  ...,  0.0176, -0.0117,  0.0149],
        [ 0.0145, -0.0167,  0.0172,  ..., -0.0167, -0.0039, -0.0031]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.1523, -2.6836, -0.8398,  ...,  1.6631, -1.2373,  2.1582]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 04:15:06 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The offspring of a goat is referred to as a kid
The offspring of a cockroach is referred to as a nymph
The offspring of a lion is referred to as a cub
The offspring of a sheep is referred to as a lamb
The offspring of a herring is referred to as a fingerling
The offspring of a panda is referred to as a cub
The offspring of a cricket is referred to as a larva
The offspring of a weasel is referred to as a
2024-08-01 04:15:06 root INFO     [order_1_approx] starting weight calculation for The offspring of a cockroach is referred to as a nymph
The offspring of a herring is referred to as a fingerling
The offspring of a weasel is referred to as a kit
The offspring of a panda is referred to as a cub
The offspring of a sheep is referred to as a lamb
The offspring of a lion is referred to as a cub
The offspring of a cricket is referred to as a larva
The offspring of a goat is referred to as a
2024-08-01 04:15:06 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-08-01 04:17:53 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1080, -0.0962, -0.0533,  ..., -0.1225, -0.1292,  0.0236],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.7656, -3.0000,  0.0068,  ...,  0.9395, -2.6035, -1.4902],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0097,  0.0088,  0.0267,  ...,  0.0243,  0.0040, -0.0232],
        [-0.0184,  0.0292,  0.0121,  ..., -0.0061, -0.0150,  0.0016],
        [-0.0016, -0.0042,  0.0187,  ..., -0.0271, -0.0006, -0.0036],
        ...,
        [ 0.0229,  0.0346,  0.0012,  ...,  0.0576,  0.0076,  0.0082],
        [ 0.0181, -0.0090,  0.0006,  ..., -0.0140, -0.0002,  0.0043],
        [ 0.0208,  0.0357, -0.0151,  ...,  0.0054, -0.0105,  0.0116]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.3477, -2.8066, -0.1117,  ...,  1.2812, -2.3086, -1.4902]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 04:17:54 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The offspring of a cockroach is referred to as a nymph
The offspring of a herring is referred to as a fingerling
The offspring of a weasel is referred to as a kit
The offspring of a panda is referred to as a cub
The offspring of a sheep is referred to as a lamb
The offspring of a lion is referred to as a cub
The offspring of a cricket is referred to as a larva
The offspring of a goat is referred to as a
2024-08-01 04:17:55 root INFO     [order_1_approx] starting weight calculation for The offspring of a cockroach is referred to as a nymph
The offspring of a sheep is referred to as a lamb
The offspring of a herring is referred to as a fingerling
The offspring of a weasel is referred to as a kit
The offspring of a lion is referred to as a cub
The offspring of a goat is referred to as a kid
The offspring of a panda is referred to as a cub
The offspring of a cricket is referred to as a
2024-08-01 04:17:55 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-08-01 04:20:44 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0834,  0.0729, -0.0501,  ...,  0.0515,  0.0115, -0.1956],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.0728, -2.1309,  0.0078,  ..., -0.5913, -1.9248, -0.0469],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0165, -0.0251,  0.0415,  ...,  0.0069, -0.0045, -0.0213],
        [ 0.0204, -0.0016, -0.0269,  ...,  0.0129, -0.0139,  0.0078],
        [ 0.0136, -0.0119,  0.0163,  ..., -0.0171, -0.0308, -0.0030],
        ...,
        [ 0.0061, -0.0413, -0.0425,  ...,  0.0118,  0.0071,  0.0057],
        [ 0.0245,  0.0007, -0.0557,  ...,  0.0641, -0.0077,  0.0107],
        [ 0.0098,  0.0081,  0.0142,  ..., -0.0094,  0.0217, -0.0052]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.4375, -2.1113,  0.1181,  ..., -0.4805, -1.9951,  0.1414]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 04:20:45 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The offspring of a cockroach is referred to as a nymph
The offspring of a sheep is referred to as a lamb
The offspring of a herring is referred to as a fingerling
The offspring of a weasel is referred to as a kit
The offspring of a lion is referred to as a cub
The offspring of a goat is referred to as a kid
The offspring of a panda is referred to as a cub
The offspring of a cricket is referred to as a
2024-08-01 04:20:45 root INFO     total operator prediction time: 1354.4537670612335 seconds
2024-08-01 04:20:45 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on UK_city - county
2024-08-01 04:20:45 root INFO     building operator UK_city - county
2024-08-01 04:20:46 root INFO     [order_1_approx] starting weight calculation for In the United Kingdom, the city of cambridge is in the county of cambridgeshire
In the United Kingdom, the city of belfast is in the county of antrim
In the United Kingdom, the city of hull is in the county of yorkshire
In the United Kingdom, the city of oxford is in the county of oxfordshire
In the United Kingdom, the city of glasgow is in the county of lowlands
In the United Kingdom, the city of coventry is in the county of midlands
In the United Kingdom, the city of wolverhampton is in the county of midlands
In the United Kingdom, the city of leicester is in the county of
2024-08-01 04:20:46 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-08-01 04:23:46 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1232,  0.1218, -0.2180,  ..., -0.0235, -0.0977,  0.1348],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.9062, -6.8516,  1.1914,  ..., -5.1719, -2.7012, -0.9102],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0135, -0.0258, -0.0151,  ...,  0.0050, -0.0080, -0.0106],
        [-0.0032,  0.0038, -0.0007,  ...,  0.0087, -0.0027,  0.0074],
        [ 0.0110,  0.0106,  0.0115,  ...,  0.0187,  0.0019, -0.0154],
        ...,
        [ 0.0021,  0.0066,  0.0007,  ...,  0.0116, -0.0020, -0.0143],
        [-0.0086, -0.0064,  0.0033,  ...,  0.0114,  0.0095, -0.0005],
        [-0.0006, -0.0175, -0.0028,  ...,  0.0003, -0.0100, -0.0034]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.1797, -6.7891,  0.9082,  ..., -5.0156, -2.4980, -0.6660]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 04:23:47 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for In the United Kingdom, the city of cambridge is in the county of cambridgeshire
In the United Kingdom, the city of belfast is in the county of antrim
In the United Kingdom, the city of hull is in the county of yorkshire
In the United Kingdom, the city of oxford is in the county of oxfordshire
In the United Kingdom, the city of glasgow is in the county of lowlands
In the United Kingdom, the city of coventry is in the county of midlands
In the United Kingdom, the city of wolverhampton is in the county of midlands
In the United Kingdom, the city of leicester is in the county of
2024-08-01 04:23:47 root INFO     [order_1_approx] starting weight calculation for In the United Kingdom, the city of oxford is in the county of oxfordshire
In the United Kingdom, the city of cambridge is in the county of cambridgeshire
In the United Kingdom, the city of coventry is in the county of midlands
In the United Kingdom, the city of belfast is in the county of antrim
In the United Kingdom, the city of leicester is in the county of midlands
In the United Kingdom, the city of wolverhampton is in the county of midlands
In the United Kingdom, the city of hull is in the county of yorkshire
In the United Kingdom, the city of glasgow is in the county of
2024-08-01 04:23:48 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-08-01 04:26:48 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0356,  0.2532, -0.2041,  ...,  0.3086, -0.0531,  0.0460],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.1094, -5.9414,  1.2334,  ..., -5.5156,  1.0781, -1.5508],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0020, -0.0068,  0.0145,  ...,  0.0128, -0.0422, -0.0186],
        [ 0.0115,  0.0273,  0.0400,  ...,  0.0395, -0.0064,  0.0173],
        [-0.0027,  0.0237,  0.0527,  ...,  0.0453, -0.0114,  0.0058],
        ...,
        [ 0.0061,  0.0133,  0.0371,  ...,  0.0080, -0.0031,  0.0162],
        [ 0.0092, -0.0215, -0.0049,  ...,  0.0003,  0.0017, -0.0116],
        [-0.0069, -0.0390, -0.0112,  ..., -0.0198, -0.0076,  0.0062]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.9648, -6.1328,  0.9521,  ..., -5.0273,  1.1240, -1.2305]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 04:26:49 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for In the United Kingdom, the city of oxford is in the county of oxfordshire
In the United Kingdom, the city of cambridge is in the county of cambridgeshire
In the United Kingdom, the city of coventry is in the county of midlands
In the United Kingdom, the city of belfast is in the county of antrim
In the United Kingdom, the city of leicester is in the county of midlands
In the United Kingdom, the city of wolverhampton is in the county of midlands
In the United Kingdom, the city of hull is in the county of yorkshire
In the United Kingdom, the city of glasgow is in the county of
2024-08-01 04:26:49 root INFO     [order_1_approx] starting weight calculation for In the United Kingdom, the city of coventry is in the county of midlands
In the United Kingdom, the city of glasgow is in the county of lowlands
In the United Kingdom, the city of cambridge is in the county of cambridgeshire
In the United Kingdom, the city of wolverhampton is in the county of midlands
In the United Kingdom, the city of hull is in the county of yorkshire
In the United Kingdom, the city of leicester is in the county of midlands
In the United Kingdom, the city of oxford is in the county of oxfordshire
In the United Kingdom, the city of belfast is in the county of
2024-08-01 04:26:49 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-08-01 04:29:50 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1282,  0.0601, -0.4795,  ...,  0.3013, -0.2664,  0.1969],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 6.4375, -7.3906,  2.6543,  ..., -2.8496, -1.2559, -1.1270],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-7.0572e-05, -9.7122e-03,  2.0615e-02,  ...,  1.4824e-02,
         -2.6123e-02, -8.4839e-03],
        [-1.3359e-02,  4.6959e-03,  1.6068e-02,  ..., -6.9656e-03,
          4.7722e-03, -2.1103e-02],
        [-9.6970e-03,  1.9989e-02,  9.2773e-03,  ...,  1.4336e-02,
         -1.5411e-03,  9.3460e-04],
        ...,
        [ 6.4087e-04,  1.6739e-02,  2.3766e-03,  ...,  3.2593e-02,
         -1.1414e-02, -9.7122e-03],
        [ 4.9629e-03,  4.8828e-03,  1.1795e-02,  ...,  2.1500e-02,
          7.8888e-03, -5.4016e-03],
        [-3.3665e-03, -2.3544e-02,  5.4207e-03,  ..., -4.0398e-03,
         -3.5553e-03,  2.3727e-03]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 6.6680, -7.4648,  2.5059,  ..., -2.8809, -1.1582, -0.8101]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 04:29:51 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for In the United Kingdom, the city of coventry is in the county of midlands
In the United Kingdom, the city of glasgow is in the county of lowlands
In the United Kingdom, the city of cambridge is in the county of cambridgeshire
In the United Kingdom, the city of wolverhampton is in the county of midlands
In the United Kingdom, the city of hull is in the county of yorkshire
In the United Kingdom, the city of leicester is in the county of midlands
In the United Kingdom, the city of oxford is in the county of oxfordshire
In the United Kingdom, the city of belfast is in the county of
2024-08-01 04:29:51 root INFO     [order_1_approx] starting weight calculation for In the United Kingdom, the city of cambridge is in the county of cambridgeshire
In the United Kingdom, the city of glasgow is in the county of lowlands
In the United Kingdom, the city of coventry is in the county of midlands
In the United Kingdom, the city of belfast is in the county of antrim
In the United Kingdom, the city of oxford is in the county of oxfordshire
In the United Kingdom, the city of wolverhampton is in the county of midlands
In the United Kingdom, the city of leicester is in the county of midlands
In the United Kingdom, the city of hull is in the county of
2024-08-01 04:29:51 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-08-01 04:32:52 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0600,  0.1716, -0.2109,  ...,  0.1367,  0.0059,  0.1094],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.3198, -5.8359, -1.0332,  ..., -5.0039, -0.7773,  1.1084],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0197,  0.0021,  0.0518,  ..., -0.0281,  0.0220, -0.0516],
        [-0.0007,  0.0081,  0.0407,  ...,  0.0157, -0.0202, -0.0724],
        [-0.0413, -0.0063,  0.0110,  ...,  0.0166,  0.0229, -0.0139],
        ...,
        [ 0.0047,  0.0257,  0.0060,  ...,  0.0113, -0.0275,  0.0110],
        [-0.0082, -0.0282,  0.0223,  ..., -0.0017, -0.0180,  0.0010],
        [ 0.0181, -0.0226,  0.0008,  ..., -0.0104, -0.0585, -0.0365]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.3013, -5.4609, -1.6416,  ..., -4.5977, -0.3948,  0.8486]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 04:32:53 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for In the United Kingdom, the city of cambridge is in the county of cambridgeshire
In the United Kingdom, the city of glasgow is in the county of lowlands
In the United Kingdom, the city of coventry is in the county of midlands
In the United Kingdom, the city of belfast is in the county of antrim
In the United Kingdom, the city of oxford is in the county of oxfordshire
In the United Kingdom, the city of wolverhampton is in the county of midlands
In the United Kingdom, the city of leicester is in the county of midlands
In the United Kingdom, the city of hull is in the county of
2024-08-01 04:32:53 root INFO     [order_1_approx] starting weight calculation for In the United Kingdom, the city of coventry is in the county of midlands
In the United Kingdom, the city of belfast is in the county of antrim
In the United Kingdom, the city of oxford is in the county of oxfordshire
In the United Kingdom, the city of cambridge is in the county of cambridgeshire
In the United Kingdom, the city of glasgow is in the county of lowlands
In the United Kingdom, the city of hull is in the county of yorkshire
In the United Kingdom, the city of leicester is in the county of midlands
In the United Kingdom, the city of wolverhampton is in the county of
2024-08-01 04:32:53 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-08-01 04:35:54 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1622, -0.0082, -0.1191,  ...,  0.3440, -0.0718,  0.2234],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 5.2617, -4.3047,  0.5698,  ..., -3.6953,  1.9238, -1.8350],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0037, -0.0130,  0.0189,  ...,  0.0009,  0.0019, -0.0299],
        [-0.0061, -0.0039,  0.0235,  ..., -0.0110, -0.0098, -0.0310],
        [-0.0003, -0.0035,  0.0088,  ..., -0.0059, -0.0102, -0.0171],
        ...,
        [ 0.0061,  0.0022, -0.0173,  ...,  0.0023, -0.0141, -0.0123],
        [-0.0217, -0.0133,  0.0360,  ...,  0.0070,  0.0250, -0.0148],
        [ 0.0214, -0.0127,  0.0085,  ..., -0.0052, -0.0223,  0.0106]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 5.3633, -4.1406,  0.4187,  ..., -3.9668,  2.0078, -1.9346]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 04:35:55 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for In the United Kingdom, the city of coventry is in the county of midlands
In the United Kingdom, the city of belfast is in the county of antrim
In the United Kingdom, the city of oxford is in the county of oxfordshire
In the United Kingdom, the city of cambridge is in the county of cambridgeshire
In the United Kingdom, the city of glasgow is in the county of lowlands
In the United Kingdom, the city of hull is in the county of yorkshire
In the United Kingdom, the city of leicester is in the county of midlands
In the United Kingdom, the city of wolverhampton is in the county of
2024-08-01 04:35:55 root INFO     [order_1_approx] starting weight calculation for In the United Kingdom, the city of hull is in the county of yorkshire
In the United Kingdom, the city of oxford is in the county of oxfordshire
In the United Kingdom, the city of leicester is in the county of midlands
In the United Kingdom, the city of cambridge is in the county of cambridgeshire
In the United Kingdom, the city of glasgow is in the county of lowlands
In the United Kingdom, the city of wolverhampton is in the county of midlands
In the United Kingdom, the city of belfast is in the county of antrim
In the United Kingdom, the city of coventry is in the county of
2024-08-01 04:35:55 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-08-01 04:38:56 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0724,  0.0211, -0.1516,  ...,  0.2090, -0.0673,  0.2255],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.7227, -6.1250,  1.6914,  ..., -4.2344, -0.6348, -2.1973],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0157,  0.0130,  0.0241,  ...,  0.0204, -0.0530, -0.0265],
        [-0.0188,  0.0356,  0.0124,  ...,  0.0150, -0.0005,  0.0100],
        [-0.0378,  0.0141,  0.0149,  ...,  0.0052, -0.0024, -0.0334],
        ...,
        [-0.0001,  0.0164, -0.0007,  ...,  0.0627, -0.0358,  0.0080],
        [-0.0236, -0.0203,  0.0160,  ..., -0.0026, -0.0132, -0.0195],
        [ 0.0067,  0.0036,  0.0004,  ..., -0.0077, -0.0143,  0.0099]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.8555, -6.4297,  1.8955,  ..., -4.1289, -0.3289, -2.2402]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 04:38:56 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for In the United Kingdom, the city of hull is in the county of yorkshire
In the United Kingdom, the city of oxford is in the county of oxfordshire
In the United Kingdom, the city of leicester is in the county of midlands
In the United Kingdom, the city of cambridge is in the county of cambridgeshire
In the United Kingdom, the city of glasgow is in the county of lowlands
In the United Kingdom, the city of wolverhampton is in the county of midlands
In the United Kingdom, the city of belfast is in the county of antrim
In the United Kingdom, the city of coventry is in the county of
2024-08-01 04:38:57 root INFO     [order_1_approx] starting weight calculation for In the United Kingdom, the city of belfast is in the county of antrim
In the United Kingdom, the city of wolverhampton is in the county of midlands
In the United Kingdom, the city of coventry is in the county of midlands
In the United Kingdom, the city of hull is in the county of yorkshire
In the United Kingdom, the city of glasgow is in the county of lowlands
In the United Kingdom, the city of leicester is in the county of midlands
In the United Kingdom, the city of oxford is in the county of oxfordshire
In the United Kingdom, the city of cambridge is in the county of
2024-08-01 04:38:57 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-08-01 04:41:57 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1219,  0.0852, -0.0916,  ..., -0.1680, -0.2354,  0.0426],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.1484, -6.3594,  0.0305,  ..., -6.0781, -1.8945,  0.5146],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0238, -0.0143,  0.0098,  ...,  0.0130, -0.0143, -0.0178],
        [-0.0011,  0.0471,  0.0347,  ..., -0.0102, -0.0264, -0.0162],
        [ 0.0072,  0.0363,  0.0335,  ...,  0.0518, -0.0156, -0.0055],
        ...,
        [ 0.0170, -0.0031,  0.0159,  ...,  0.0284, -0.0017, -0.0081],
        [-0.0216, -0.0251, -0.0175,  ..., -0.0082,  0.0132,  0.0118],
        [ 0.0202, -0.0022,  0.0065,  ..., -0.0020, -0.0134, -0.0034]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.4141, -6.1992, -0.1040,  ..., -5.9766, -1.6934,  0.4995]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 04:41:58 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for In the United Kingdom, the city of belfast is in the county of antrim
In the United Kingdom, the city of wolverhampton is in the county of midlands
In the United Kingdom, the city of coventry is in the county of midlands
In the United Kingdom, the city of hull is in the county of yorkshire
In the United Kingdom, the city of glasgow is in the county of lowlands
In the United Kingdom, the city of leicester is in the county of midlands
In the United Kingdom, the city of oxford is in the county of oxfordshire
In the United Kingdom, the city of cambridge is in the county of
2024-08-01 04:41:58 root INFO     [order_1_approx] starting weight calculation for In the United Kingdom, the city of glasgow is in the county of lowlands
In the United Kingdom, the city of coventry is in the county of midlands
In the United Kingdom, the city of belfast is in the county of antrim
In the United Kingdom, the city of leicester is in the county of midlands
In the United Kingdom, the city of wolverhampton is in the county of midlands
In the United Kingdom, the city of cambridge is in the county of cambridgeshire
In the United Kingdom, the city of hull is in the county of yorkshire
In the United Kingdom, the city of oxford is in the county of
2024-08-01 04:41:58 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-08-01 04:44:59 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1754,  0.2233, -0.1875,  ..., -0.0176, -0.0921, -0.1265],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 5.1328, -6.3516,  1.2520,  ..., -1.8848, -0.3740, -2.2227],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0066,  0.0523,  0.0092,  ..., -0.0006, -0.0158, -0.0006],
        [ 0.0026,  0.1213, -0.0046,  ...,  0.0356, -0.0064,  0.0132],
        [-0.0202,  0.0339, -0.0066,  ..., -0.0039, -0.0226,  0.0169],
        ...,
        [ 0.0358,  0.1145, -0.0232,  ...,  0.0203,  0.0023,  0.0072],
        [-0.0045, -0.1497,  0.0356,  ..., -0.0197,  0.0059, -0.0475],
        [ 0.0047,  0.0594, -0.0225,  ...,  0.0210, -0.0247,  0.0586]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 5.0039, -6.3398,  0.6431,  ..., -1.6836,  0.3291, -2.6699]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 04:45:00 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for In the United Kingdom, the city of glasgow is in the county of lowlands
In the United Kingdom, the city of coventry is in the county of midlands
In the United Kingdom, the city of belfast is in the county of antrim
In the United Kingdom, the city of leicester is in the county of midlands
In the United Kingdom, the city of wolverhampton is in the county of midlands
In the United Kingdom, the city of cambridge is in the county of cambridgeshire
In the United Kingdom, the city of hull is in the county of yorkshire
In the United Kingdom, the city of oxford is in the county of
2024-08-01 04:45:00 root INFO     total operator prediction time: 1454.232055902481 seconds
2024-08-01 04:45:00 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on meronyms - part
2024-08-01 04:45:00 root INFO     building operator meronyms - part
2024-08-01 04:45:00 root INFO     [order_1_approx] starting weight calculation for A part of a brush is a bristle
A part of a staircase is a step
A part of a academia is a college
A part of a seafront is a harbor
A part of a shilling is a pence
A part of a typewriter is a keyboard
A part of a car is a engine
A part of a comb is a
2024-08-01 04:45:00 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-08-01 04:47:51 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2146, -0.2125, -0.1517,  ..., -0.0845, -0.2847, -0.0709],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.9404, -2.0234, -3.3281,  ...,  1.1162,  0.9023, -1.0508],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0261,  0.0239,  0.0228,  ..., -0.0383, -0.0147, -0.0061],
        [-0.0367,  0.0065,  0.0630,  ...,  0.0100, -0.0299,  0.0684],
        [-0.0266, -0.0009,  0.0626,  ...,  0.0108, -0.0228, -0.0222],
        ...,
        [-0.0490,  0.0049, -0.0353,  ...,  0.0635, -0.0063, -0.0029],
        [-0.0149,  0.0244, -0.0203,  ...,  0.0280,  0.0244,  0.0210],
        [-0.0116, -0.0195,  0.0464,  ..., -0.0195, -0.0036,  0.0467]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.2188, -1.6797, -3.0840,  ...,  0.9209,  0.7500, -0.9663]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 04:47:52 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A part of a brush is a bristle
A part of a staircase is a step
A part of a academia is a college
A part of a seafront is a harbor
A part of a shilling is a pence
A part of a typewriter is a keyboard
A part of a car is a engine
A part of a comb is a
2024-08-01 04:47:52 root INFO     [order_1_approx] starting weight calculation for A part of a academia is a college
A part of a staircase is a step
A part of a brush is a bristle
A part of a typewriter is a keyboard
A part of a car is a engine
A part of a seafront is a harbor
A part of a comb is a teeth
A part of a shilling is a
2024-08-01 04:47:52 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-08-01 04:50:43 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1552,  0.0613, -0.3386,  ...,  0.1631,  0.1516, -0.1635],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.0278,  1.3018, -1.9512,  ...,  0.4258, -0.7236,  0.9170],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.1028, -0.0309,  0.0033,  ..., -0.0272, -0.0395, -0.0546],
        [-0.0164, -0.0380,  0.0316,  ..., -0.0089, -0.0374,  0.0018],
        [ 0.0202, -0.0432,  0.0042,  ...,  0.0214, -0.0031, -0.0013],
        ...,
        [ 0.0337, -0.0279,  0.0120,  ...,  0.0896, -0.0184, -0.0233],
        [ 0.0107, -0.0059, -0.0212,  ...,  0.0313,  0.0285, -0.0065],
        [-0.0035,  0.0023, -0.0195,  ..., -0.0201,  0.0140,  0.0406]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.0750,  1.1074, -2.1914,  ...,  1.0781, -0.2361,  0.6367]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 04:50:44 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A part of a academia is a college
A part of a staircase is a step
A part of a brush is a bristle
A part of a typewriter is a keyboard
A part of a car is a engine
A part of a seafront is a harbor
A part of a comb is a teeth
A part of a shilling is a
2024-08-01 04:50:45 root INFO     [order_1_approx] starting weight calculation for A part of a staircase is a step
A part of a academia is a college
A part of a typewriter is a keyboard
A part of a car is a engine
A part of a brush is a bristle
A part of a shilling is a pence
A part of a comb is a teeth
A part of a seafront is a
2024-08-01 04:50:45 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-08-01 04:53:36 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0392,  0.0215, -0.0707,  ...,  0.0957, -0.2289, -0.0328],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.5439, -4.5156, -3.5801,  ...,  5.6875, -0.9927, -1.9697],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0362, -0.0502,  0.0364,  ...,  0.0208,  0.0143, -0.0087],
        [ 0.0075, -0.0013, -0.0098,  ...,  0.0211,  0.0238, -0.0165],
        [-0.0089, -0.0097,  0.0303,  ...,  0.0008, -0.0081,  0.0156],
        ...,
        [ 0.0195,  0.0320,  0.0093,  ...,  0.0289, -0.0520,  0.0091],
        [-0.0188, -0.0072, -0.0150,  ..., -0.0028,  0.0312, -0.0132],
        [-0.0213, -0.0378, -0.0266,  ...,  0.0069, -0.0198,  0.0247]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.1375, -4.1875, -3.4902,  ...,  5.3008, -0.7827, -2.1484]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 04:53:37 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A part of a staircase is a step
A part of a academia is a college
A part of a typewriter is a keyboard
A part of a car is a engine
A part of a brush is a bristle
A part of a shilling is a pence
A part of a comb is a teeth
A part of a seafront is a
2024-08-01 04:53:37 root INFO     [order_1_approx] starting weight calculation for A part of a typewriter is a keyboard
A part of a academia is a college
A part of a shilling is a pence
A part of a brush is a bristle
A part of a car is a engine
A part of a seafront is a harbor
A part of a comb is a teeth
A part of a staircase is a
2024-08-01 04:53:37 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-08-01 04:56:29 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0127, -0.2556, -0.2598,  ..., -0.0899, -0.1565, -0.1162],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.1250, -2.5020,  1.5332,  ...,  2.7891, -3.4258, -2.2969],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0208,  0.0032,  0.0152,  ..., -0.0054,  0.0119, -0.0020],
        [-0.0182,  0.0360,  0.0248,  ..., -0.0028, -0.0123,  0.0082],
        [ 0.0112,  0.0094,  0.0364,  ..., -0.0110, -0.0338, -0.0114],
        ...,
        [ 0.0036,  0.0218,  0.0084,  ...,  0.0260, -0.0155, -0.0010],
        [-0.0053, -0.0085, -0.0119,  ...,  0.0128, -0.0034,  0.0063],
        [ 0.0012, -0.0070,  0.0044,  ...,  0.0024,  0.0194,  0.0059]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.2773, -2.2695,  2.0195,  ...,  2.8359, -3.4824, -2.2988]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 04:56:30 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A part of a typewriter is a keyboard
A part of a academia is a college
A part of a shilling is a pence
A part of a brush is a bristle
A part of a car is a engine
A part of a seafront is a harbor
A part of a comb is a teeth
A part of a staircase is a
2024-08-01 04:56:30 root INFO     [order_1_approx] starting weight calculation for A part of a staircase is a step
A part of a seafront is a harbor
A part of a typewriter is a keyboard
A part of a shilling is a pence
A part of a comb is a teeth
A part of a brush is a bristle
A part of a academia is a college
A part of a car is a
2024-08-01 04:56:30 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-08-01 04:59:15 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1074,  0.0686, -0.2336,  ..., -0.0586, -0.0920,  0.0213],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.0215, -3.3242, -1.2412,  ...,  2.4863, -1.9668, -1.1553],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0150, -0.1689, -0.0211,  ..., -0.0775,  0.0040, -0.0200],
        [-0.0014, -0.0342, -0.0266,  ..., -0.0125,  0.0392, -0.0136],
        [ 0.0113,  0.0097,  0.0321,  ...,  0.0231, -0.0634, -0.0115],
        ...,
        [ 0.0117, -0.0061, -0.0293,  ...,  0.0239, -0.0094,  0.0093],
        [-0.0068,  0.0074, -0.0158,  ..., -0.0199,  0.0170, -0.0098],
        [ 0.0297, -0.1023, -0.0391,  ..., -0.0594,  0.0052, -0.0226]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.6992, -3.3438, -0.9033,  ...,  2.1836, -2.1035, -1.0195]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 04:59:16 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A part of a staircase is a step
A part of a seafront is a harbor
A part of a typewriter is a keyboard
A part of a shilling is a pence
A part of a comb is a teeth
A part of a brush is a bristle
A part of a academia is a college
A part of a car is a
2024-08-01 04:59:16 root INFO     [order_1_approx] starting weight calculation for A part of a car is a engine
A part of a comb is a teeth
A part of a shilling is a pence
A part of a staircase is a step
A part of a seafront is a harbor
A part of a brush is a bristle
A part of a typewriter is a keyboard
A part of a academia is a
2024-08-01 04:59:16 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-08-01 05:01:58 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1320,  0.0542, -0.2363,  ...,  0.2222, -0.1138, -0.0715],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.5664, -3.5664,  4.3594,  ...,  0.8359, -1.0000, -2.8555],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0233,  0.0013, -0.0148,  ..., -0.0166,  0.0114,  0.0093],
        [-0.0074,  0.0238,  0.0042,  ..., -0.0051, -0.0028, -0.0208],
        [-0.0167,  0.0245,  0.0165,  ...,  0.0144, -0.0555,  0.0394],
        ...,
        [ 0.0377, -0.0090,  0.0039,  ...,  0.0182, -0.0095, -0.0181],
        [-0.0304,  0.0056, -0.0330,  ...,  0.0453, -0.0021,  0.0346],
        [ 0.0222, -0.0211,  0.0190,  ..., -0.0104,  0.0240, -0.0029]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.5654, -3.6348,  4.3789,  ...,  0.8730, -1.1670, -2.8867]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 05:01:59 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A part of a car is a engine
A part of a comb is a teeth
A part of a shilling is a pence
A part of a staircase is a step
A part of a seafront is a harbor
A part of a brush is a bristle
A part of a typewriter is a keyboard
A part of a academia is a
2024-08-01 05:01:59 root INFO     [order_1_approx] starting weight calculation for A part of a academia is a college
A part of a staircase is a step
A part of a car is a engine
A part of a brush is a bristle
A part of a comb is a teeth
A part of a seafront is a harbor
A part of a shilling is a pence
A part of a typewriter is a
2024-08-01 05:02:00 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-08-01 05:04:45 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1550, -0.2876, -0.2053,  ..., -0.2666, -0.1738,  0.0963],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.2129, -2.5312, -0.5835,  ..., -0.0742, -1.3828, -1.6436],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0126, -0.0437,  0.0280,  ...,  0.0150,  0.0070,  0.0042],
        [-0.0108,  0.0350, -0.0094,  ...,  0.0310,  0.0033,  0.0455],
        [ 0.0192,  0.0301,  0.0177,  ..., -0.0126, -0.0174, -0.0038],
        ...,
        [ 0.0190,  0.0266, -0.0527,  ...,  0.0582, -0.0179,  0.0025],
        [-0.0317,  0.0228, -0.0382,  ..., -0.0036,  0.0143, -0.0051],
        [ 0.0084, -0.0058,  0.0170,  ...,  0.0027, -0.0024,  0.0457]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.0476, -3.0215, -0.6123,  ..., -0.0227, -2.1680, -1.3994]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 05:04:46 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A part of a academia is a college
A part of a staircase is a step
A part of a car is a engine
A part of a brush is a bristle
A part of a comb is a teeth
A part of a seafront is a harbor
A part of a shilling is a pence
A part of a typewriter is a
2024-08-01 05:04:46 root INFO     [order_1_approx] starting weight calculation for A part of a comb is a teeth
A part of a staircase is a step
A part of a academia is a college
A part of a shilling is a pence
A part of a seafront is a harbor
A part of a car is a engine
A part of a typewriter is a keyboard
A part of a brush is a
2024-08-01 05:04:46 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-08-01 05:07:37 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3840,  0.0202, -0.0199,  ..., -0.0090, -0.0663,  0.0907],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 5.0391, -2.4902, -0.9512,  ...,  1.2100, -1.0234, -1.7109],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0213, -0.0160,  0.0121,  ...,  0.0033, -0.0379, -0.0006],
        [ 0.0139, -0.0455,  0.0396,  ..., -0.0062, -0.0096,  0.0181],
        [-0.0354,  0.0048,  0.0304,  ...,  0.0406, -0.0278,  0.0091],
        ...,
        [-0.0261, -0.0287, -0.0048,  ...,  0.0595, -0.0027, -0.0068],
        [-0.0158,  0.0191, -0.0671,  ...,  0.0121,  0.0494, -0.0533],
        [-0.0182, -0.0169,  0.0162,  ..., -0.0437,  0.0078,  0.0229]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.4258, -2.1895, -0.7451,  ...,  1.4775, -0.6328, -1.4531]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 05:07:38 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A part of a comb is a teeth
A part of a staircase is a step
A part of a academia is a college
A part of a shilling is a pence
A part of a seafront is a harbor
A part of a car is a engine
A part of a typewriter is a keyboard
A part of a brush is a
2024-08-01 05:07:38 root INFO     total operator prediction time: 1358.7242405414581 seconds
2024-08-01 05:07:38 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on synonyms - exact
2024-08-01 05:07:38 root INFO     building operator synonyms - exact
2024-08-01 05:07:39 root INFO     [order_1_approx] starting weight calculation for Another word for loyal is faithful
Another word for emphasis is accent
Another word for market is marketplace
Another word for clothes is clothing
Another word for organized is arranged
Another word for bicycle is bike
Another word for child is kid
Another word for portion is
2024-08-01 05:07:39 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-08-01 05:10:28 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2590, -0.1715,  0.0636,  ..., -0.0628, -0.0177,  0.3379],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.8193, -3.6055, -0.0312,  ..., -2.7188, -0.8579, -2.6504],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0298, -0.0797,  0.0249,  ..., -0.0271,  0.0573,  0.0034],
        [-0.0109,  0.0453,  0.0185,  ..., -0.0247,  0.0125, -0.0385],
        [ 0.0465,  0.0168,  0.0693,  ...,  0.0278, -0.0135,  0.0122],
        ...,
        [-0.0223, -0.0105, -0.0279,  ...,  0.0490,  0.0062, -0.0269],
        [ 0.0429,  0.0033,  0.0103,  ...,  0.0392,  0.0581,  0.0081],
        [ 0.0149, -0.0350,  0.0291,  ..., -0.0426,  0.0149,  0.0290]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.2891, -2.1758,  0.6221,  ..., -1.9941, -0.8521, -2.4492]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 05:10:29 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Another word for loyal is faithful
Another word for emphasis is accent
Another word for market is marketplace
Another word for clothes is clothing
Another word for organized is arranged
Another word for bicycle is bike
Another word for child is kid
Another word for portion is
2024-08-01 05:10:30 root INFO     [order_1_approx] starting weight calculation for Another word for organized is arranged
Another word for child is kid
Another word for market is marketplace
Another word for bicycle is bike
Another word for clothes is clothing
Another word for portion is part
Another word for loyal is faithful
Another word for emphasis is
2024-08-01 05:10:30 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-08-01 05:13:18 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2759,  0.0626, -0.1935,  ...,  0.0891, -0.1650,  0.3730],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.1377, -2.5156, -0.0293,  ...,  0.6748, -1.5977, -3.5977],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0560, -0.0287, -0.0037,  ...,  0.0321,  0.0169,  0.0186],
        [-0.0263,  0.0515, -0.0187,  ..., -0.0191,  0.0199, -0.0092],
        [ 0.0238, -0.0151,  0.0120,  ...,  0.0255,  0.0193, -0.0166],
        ...,
        [-0.0057,  0.0053,  0.0008,  ...,  0.0135, -0.0432, -0.0331],
        [-0.0056, -0.0018, -0.0151,  ...,  0.0089,  0.0075,  0.0128],
        [-0.0103, -0.0059, -0.0013,  ..., -0.0035, -0.0072,  0.0486]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.2842, -2.7148,  0.3245,  ...,  0.5737, -1.8438, -3.8438]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 05:13:19 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Another word for organized is arranged
Another word for child is kid
Another word for market is marketplace
Another word for bicycle is bike
Another word for clothes is clothing
Another word for portion is part
Another word for loyal is faithful
Another word for emphasis is
2024-08-01 05:13:19 root INFO     [order_1_approx] starting weight calculation for Another word for loyal is faithful
Another word for child is kid
Another word for clothes is clothing
Another word for portion is part
Another word for market is marketplace
Another word for bicycle is bike
Another word for emphasis is accent
Another word for organized is
2024-08-01 05:13:20 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-08-01 05:16:11 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0845,  0.2235, -0.1031,  ..., -0.1216, -0.1616,  0.1289],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.6255,  0.1387,  2.3359,  ...,  1.3916, -2.6426, -5.2305],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0024,  0.0266, -0.0176,  ...,  0.0024,  0.0532, -0.0248],
        [-0.0438,  0.0155,  0.0274,  ..., -0.0263, -0.0368,  0.0316],
        [ 0.0191, -0.0328,  0.0705,  ...,  0.0247,  0.0138, -0.0028],
        ...,
        [ 0.0474,  0.0227, -0.0595,  ..., -0.0123, -0.0443,  0.0010],
        [ 0.0435,  0.0127, -0.0267,  ...,  0.0300,  0.0551, -0.0421],
        [ 0.0031,  0.0071, -0.0044,  ..., -0.0121, -0.0310,  0.0333]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.2129,  0.7983,  1.9600,  ...,  1.5312, -2.3984, -5.7930]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 05:16:12 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Another word for loyal is faithful
Another word for child is kid
Another word for clothes is clothing
Another word for portion is part
Another word for market is marketplace
Another word for bicycle is bike
Another word for emphasis is accent
Another word for organized is
2024-08-01 05:16:12 root INFO     [order_1_approx] starting weight calculation for Another word for emphasis is accent
Another word for market is marketplace
Another word for loyal is faithful
Another word for clothes is clothing
Another word for portion is part
Another word for child is kid
Another word for organized is arranged
Another word for bicycle is
2024-08-01 05:16:12 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-08-01 05:19:03 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1205, -0.0405, -0.3108,  ..., -0.2494, -0.0907, -0.0408],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.3340e+00, -4.8867e+00,  1.3857e+00,  ...,  4.5166e-03,
        -6.6260e-01, -2.3906e+00], device='cuda:1', dtype=torch.float16,
       grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 3.3264e-02, -7.5226e-03,  4.2617e-05,  ...,  4.6501e-03,
         -1.4191e-02,  7.7286e-03],
        [ 9.1839e-04,  1.3016e-02,  1.1620e-02,  ...,  1.0834e-02,
          9.3269e-04, -1.1070e-02],
        [ 1.2550e-02, -1.1673e-02,  3.6682e-02,  ..., -3.1052e-03,
          6.4163e-03,  3.6354e-03],
        ...,
        [ 3.0403e-03, -6.3515e-03, -4.6082e-03,  ...,  1.5518e-02,
         -1.4442e-02,  4.5853e-03],
        [-3.0746e-02,  1.2390e-02, -2.6302e-03,  ..., -1.0254e-02,
          2.2079e-02, -1.3016e-02],
        [ 2.6855e-02,  2.3022e-03,  1.2756e-02,  ...,  3.6011e-03,
         -6.4545e-03,  1.4183e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.9238, -4.9062,  1.3154,  ...,  0.1277, -0.8726, -2.2656]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 05:19:04 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Another word for emphasis is accent
Another word for market is marketplace
Another word for loyal is faithful
Another word for clothes is clothing
Another word for portion is part
Another word for child is kid
Another word for organized is arranged
Another word for bicycle is
2024-08-01 05:19:04 root INFO     [order_1_approx] starting weight calculation for Another word for emphasis is accent
Another word for market is marketplace
Another word for loyal is faithful
Another word for bicycle is bike
Another word for child is kid
Another word for organized is arranged
Another word for portion is part
Another word for clothes is
2024-08-01 05:19:04 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-08-01 05:21:54 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0975, -0.1094, -0.2208,  ...,  0.2423, -0.0272,  0.1294],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.6211, -2.8926,  0.7529,  ..., -1.3008, -1.8867, -1.1895],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0400, -0.0267,  0.0226,  ..., -0.0516,  0.0109,  0.0240],
        [ 0.0128,  0.0270, -0.0168,  ..., -0.0357,  0.0228,  0.0107],
        [-0.0015, -0.0528,  0.0615,  ...,  0.0259, -0.0088,  0.0014],
        ...,
        [ 0.0424, -0.0031,  0.0112,  ..., -0.0185,  0.0231, -0.0088],
        [-0.0449,  0.0038,  0.0084,  ..., -0.0247,  0.1176, -0.0047],
        [ 0.0201, -0.0151,  0.0186,  ..., -0.0190,  0.0184, -0.0003]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.9707, -2.1426,  0.4561,  ..., -1.0811, -2.2012, -1.0586]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 05:21:55 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Another word for emphasis is accent
Another word for market is marketplace
Another word for loyal is faithful
Another word for bicycle is bike
Another word for child is kid
Another word for organized is arranged
Another word for portion is part
Another word for clothes is
2024-08-01 05:21:55 root INFO     [order_1_approx] starting weight calculation for Another word for clothes is clothing
Another word for portion is part
Another word for emphasis is accent
Another word for organized is arranged
Another word for bicycle is bike
Another word for child is kid
Another word for loyal is faithful
Another word for market is
2024-08-01 05:21:55 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-08-01 05:24:46 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-1.4990e-01,  1.0352e-01, -2.2241e-01,  ...,  1.8311e-04,
        -4.3915e-02,  5.5969e-02], device='cuda:1', dtype=torch.float16,
       grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.3003, -1.9844,  0.1533,  ...,  0.4658, -2.6602, -1.0186],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0809,  0.0044, -0.0215,  ..., -0.0280,  0.0267, -0.0089],
        [-0.0153,  0.0580,  0.0216,  ...,  0.0004, -0.0187, -0.0411],
        [-0.0121, -0.0117,  0.1001,  ..., -0.0290,  0.0183,  0.0086],
        ...,
        [-0.0087,  0.0220,  0.0135,  ...,  0.0064,  0.0008,  0.0090],
        [ 0.0081, -0.0252, -0.0320,  ..., -0.0377,  0.1167, -0.0100],
        [-0.0149,  0.0316, -0.0059,  ...,  0.0625, -0.0398,  0.0563]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.1211, -2.4219,  0.0171,  ...,  0.1311, -2.1777, -1.1582]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 05:24:47 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Another word for clothes is clothing
Another word for portion is part
Another word for emphasis is accent
Another word for organized is arranged
Another word for bicycle is bike
Another word for child is kid
Another word for loyal is faithful
Another word for market is
2024-08-01 05:24:47 root INFO     [order_1_approx] starting weight calculation for Another word for organized is arranged
Another word for loyal is faithful
Another word for clothes is clothing
Another word for portion is part
Another word for emphasis is accent
Another word for market is marketplace
Another word for bicycle is bike
Another word for child is
2024-08-01 05:24:47 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-08-01 05:27:37 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1121, -0.1757, -0.0589,  ..., -0.1414, -0.4373,  0.0641],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.2578, -3.2344, -2.2520,  ...,  0.2461, -0.6553, -0.3975],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0073, -0.0109,  0.0033,  ...,  0.0215,  0.0450, -0.0206],
        [ 0.0292,  0.0367,  0.0092,  ..., -0.0196,  0.0381,  0.0019],
        [ 0.0224,  0.0014,  0.0304,  ...,  0.0180,  0.0212, -0.0280],
        ...,
        [ 0.0366, -0.0094, -0.0048,  ..., -0.0784,  0.0006,  0.0149],
        [-0.0270,  0.0342,  0.0132,  ...,  0.0234,  0.0589, -0.0366],
        [ 0.0083, -0.0319,  0.0017,  ..., -0.0258,  0.0035,  0.0453]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.1055, -2.7930, -2.3203,  ...,  0.5713, -0.7212, -0.3286]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 05:27:38 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Another word for organized is arranged
Another word for loyal is faithful
Another word for clothes is clothing
Another word for portion is part
Another word for emphasis is accent
Another word for market is marketplace
Another word for bicycle is bike
Another word for child is
2024-08-01 05:27:39 root INFO     [order_1_approx] starting weight calculation for Another word for bicycle is bike
Another word for child is kid
Another word for clothes is clothing
Another word for organized is arranged
Another word for emphasis is accent
Another word for market is marketplace
Another word for portion is part
Another word for loyal is
2024-08-01 05:27:39 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-08-01 05:30:29 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1410,  0.0587, -0.0781,  ..., -0.2231, -0.0113,  0.3037],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.6836, -5.3008, -0.1323,  ..., -1.2637, -6.7266, -1.1240],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0347, -0.0033,  0.0181,  ..., -0.0584,  0.0311, -0.0031],
        [ 0.0296,  0.0494,  0.0022,  ..., -0.0698,  0.0325, -0.0602],
        [ 0.0316, -0.0242,  0.0314,  ..., -0.0028, -0.0058,  0.0064],
        ...,
        [ 0.0056,  0.0179,  0.0237,  ..., -0.0179,  0.0196, -0.0021],
        [ 0.0453, -0.0334,  0.0154,  ..., -0.0936,  0.0535, -0.0388],
        [-0.0204, -0.0158,  0.0046,  ..., -0.0240, -0.0429,  0.0496]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.5391, -4.3477, -0.1340,  ..., -1.3887, -6.0508, -1.1875]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 05:30:30 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Another word for bicycle is bike
Another word for child is kid
Another word for clothes is clothing
Another word for organized is arranged
Another word for emphasis is accent
Another word for market is marketplace
Another word for portion is part
Another word for loyal is
2024-08-01 05:30:30 root INFO     total operator prediction time: 1372.1149871349335 seconds
2024-08-01 05:30:30 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on hypernyms - misc
2024-08-01 05:30:30 root INFO     building operator hypernyms - misc
2024-08-01 05:30:31 root INFO     [order_1_approx] starting weight calculation for The stapler falls into the category of device
The photo falls into the category of picture
The pastry falls into the category of food
The sidewalk falls into the category of walk
The hamburger falls into the category of sandwich
The toaster falls into the category of appliance
The hairpin falls into the category of pin
The fridge falls into the category of
2024-08-01 05:30:31 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-08-01 05:33:22 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2103,  0.0265,  0.0008,  ..., -0.0342, -0.2732, -0.1110],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.1055, -6.2070,  4.5234,  ..., -0.4595, -2.2773, -0.6709],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0717,  0.0154,  0.0165,  ...,  0.0201, -0.0240,  0.0530],
        [-0.0734, -0.0206, -0.0385,  ..., -0.0318,  0.0338, -0.0775],
        [-0.0247, -0.0181,  0.0017,  ...,  0.0076,  0.0038,  0.0324],
        ...,
        [ 0.0061, -0.0330, -0.0211,  ...,  0.0573, -0.0020, -0.0144],
        [ 0.0167,  0.0157,  0.0209,  ...,  0.0093,  0.0457, -0.0153],
        [-0.0344, -0.0244, -0.0610,  ..., -0.0446,  0.0382, -0.0372]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.2920, -6.3359,  4.9219,  ..., -0.2881, -1.8516, -0.5000]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 05:33:24 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The stapler falls into the category of device
The photo falls into the category of picture
The pastry falls into the category of food
The sidewalk falls into the category of walk
The hamburger falls into the category of sandwich
The toaster falls into the category of appliance
The hairpin falls into the category of pin
The fridge falls into the category of
2024-08-01 05:33:24 root INFO     [order_1_approx] starting weight calculation for The sidewalk falls into the category of walk
The toaster falls into the category of appliance
The hamburger falls into the category of sandwich
The stapler falls into the category of device
The fridge falls into the category of appliance
The hairpin falls into the category of pin
The pastry falls into the category of food
The photo falls into the category of
2024-08-01 05:33:24 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-08-01 05:36:11 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1836, -0.1809, -0.1934,  ..., -0.1593, -0.1283, -0.1206],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.0552, -4.4297, -0.3467,  ..., -1.7832, -1.4980,  0.3838],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0369, -0.0793,  0.0224,  ...,  0.0274,  0.0259,  0.0084],
        [-0.0028, -0.0820,  0.0574,  ..., -0.0022, -0.0027,  0.0548],
        [-0.0033,  0.1338, -0.0138,  ...,  0.0340,  0.0097,  0.0106],
        ...,
        [ 0.0304, -0.0402,  0.0185,  ...,  0.0092, -0.0076,  0.0021],
        [-0.0276,  0.0405,  0.0074,  ...,  0.0015,  0.0751,  0.0378],
        [-0.0043, -0.0991,  0.0520,  ..., -0.0131,  0.0074,  0.0562]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.1288, -4.1289, -0.2128,  ..., -1.4258, -1.0449,  0.3633]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 05:36:12 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The sidewalk falls into the category of walk
The toaster falls into the category of appliance
The hamburger falls into the category of sandwich
The stapler falls into the category of device
The fridge falls into the category of appliance
The hairpin falls into the category of pin
The pastry falls into the category of food
The photo falls into the category of
2024-08-01 05:36:12 root INFO     [order_1_approx] starting weight calculation for The hairpin falls into the category of pin
The stapler falls into the category of device
The toaster falls into the category of appliance
The sidewalk falls into the category of walk
The hamburger falls into the category of sandwich
The photo falls into the category of picture
The fridge falls into the category of appliance
The pastry falls into the category of
2024-08-01 05:36:12 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-08-01 05:39:01 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0078,  0.0475, -0.0322,  ...,  0.1304, -0.3765, -0.0130],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.9258, -6.6484,  0.6689,  ..., -1.3359, -2.7500,  0.2402],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0234,  0.0160, -0.0353,  ..., -0.0071, -0.0235,  0.0110],
        [ 0.0607, -0.0067,  0.0342,  ..., -0.0831, -0.0238,  0.0107],
        [-0.0452,  0.0088,  0.0085,  ...,  0.0726, -0.0242, -0.0105],
        ...,
        [ 0.0291,  0.0092,  0.0171,  ...,  0.0333, -0.0299, -0.0173],
        [ 0.0072, -0.0348,  0.0110,  ..., -0.0131,  0.0486,  0.0045],
        [ 0.0782, -0.0157,  0.0423,  ..., -0.0343,  0.0242,  0.0292]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.8301, -6.2812,  0.5557,  ..., -0.7871, -2.3965,  0.2976]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 05:39:02 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The hairpin falls into the category of pin
The stapler falls into the category of device
The toaster falls into the category of appliance
The sidewalk falls into the category of walk
The hamburger falls into the category of sandwich
The photo falls into the category of picture
The fridge falls into the category of appliance
The pastry falls into the category of
2024-08-01 05:39:02 root INFO     [order_1_approx] starting weight calculation for The hairpin falls into the category of pin
The pastry falls into the category of food
The toaster falls into the category of appliance
The photo falls into the category of picture
The hamburger falls into the category of sandwich
The stapler falls into the category of device
The fridge falls into the category of appliance
The sidewalk falls into the category of
2024-08-01 05:39:02 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-08-01 05:41:51 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0008, -0.0179, -0.0969,  ...,  0.1284, -0.0841,  0.0567],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-2.0352, -3.4336,  2.0742,  ..., -0.2590, -3.4258, -0.0117],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0640,  0.0095, -0.0313,  ..., -0.0027, -0.0213,  0.0224],
        [ 0.0169, -0.0698,  0.0193,  ..., -0.0136, -0.0134,  0.0020],
        [-0.0413,  0.0732,  0.0376,  ..., -0.0216,  0.0067, -0.0219],
        ...,
        [ 0.0188, -0.0180,  0.0111,  ...,  0.0303, -0.0168,  0.0097],
        [-0.0081, -0.0414,  0.0229,  ..., -0.0400,  0.0496,  0.0168],
        [-0.0066, -0.0535,  0.0139,  ..., -0.0341,  0.0167,  0.0298]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.9609, -3.5098,  2.4727,  ..., -0.1538, -3.7266,  0.2219]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 05:41:52 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The hairpin falls into the category of pin
The pastry falls into the category of food
The toaster falls into the category of appliance
The photo falls into the category of picture
The hamburger falls into the category of sandwich
The stapler falls into the category of device
The fridge falls into the category of appliance
The sidewalk falls into the category of
2024-08-01 05:41:52 root INFO     [order_1_approx] starting weight calculation for The photo falls into the category of picture
The fridge falls into the category of appliance
The sidewalk falls into the category of walk
The hairpin falls into the category of pin
The pastry falls into the category of food
The toaster falls into the category of appliance
The stapler falls into the category of device
The hamburger falls into the category of
2024-08-01 05:41:52 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-08-01 05:44:41 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0872,  0.2744, -0.1885,  ...,  0.1116, -0.1322, -0.1100],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.7236, -4.3125,  2.8730,  ..., -3.2812, -3.7227, -2.1133],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0291, -0.0121,  0.0180,  ..., -0.0419, -0.0322, -0.0062],
        [-0.0170,  0.0184, -0.0032,  ...,  0.0174, -0.0263, -0.0026],
        [ 0.0038, -0.0189,  0.0110,  ..., -0.0243,  0.0053, -0.0126],
        ...,
        [ 0.0149, -0.0038,  0.0199,  ...,  0.0389, -0.0044, -0.0079],
        [ 0.0151, -0.0173, -0.0109,  ..., -0.0106,  0.0275, -0.0185],
        [-0.0206, -0.0042,  0.0044,  ...,  0.0289, -0.0212,  0.0340]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.0342, -3.9688,  2.7344,  ..., -3.2246, -3.7188, -1.8086]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 05:44:42 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The photo falls into the category of picture
The fridge falls into the category of appliance
The sidewalk falls into the category of walk
The hairpin falls into the category of pin
The pastry falls into the category of food
The toaster falls into the category of appliance
The stapler falls into the category of device
The hamburger falls into the category of
2024-08-01 05:44:42 root INFO     [order_1_approx] starting weight calculation for The hamburger falls into the category of sandwich
The stapler falls into the category of device
The toaster falls into the category of appliance
The photo falls into the category of picture
The fridge falls into the category of appliance
The sidewalk falls into the category of walk
The pastry falls into the category of food
The hairpin falls into the category of
2024-08-01 05:44:42 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-08-01 05:47:26 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0543, -0.3784, -0.1895,  ...,  0.1970,  0.1229, -0.2620],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.5508, -3.7129, -0.3193,  ..., -0.8096, -5.0312,  2.5254],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0657,  0.0053,  0.0042,  ...,  0.0121, -0.0052, -0.0022],
        [ 0.0228, -0.0181,  0.0052,  ..., -0.0569, -0.0542,  0.0046],
        [-0.0116, -0.0268,  0.0092,  ..., -0.0016, -0.0313, -0.0113],
        ...,
        [ 0.0265, -0.0035,  0.0331,  ...,  0.0220, -0.0224, -0.0231],
        [-0.0120, -0.0060,  0.0105,  ...,  0.0234,  0.0427,  0.0219],
        [-0.0136,  0.0237,  0.0216,  ..., -0.0184,  0.0078,  0.0300]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.5059, -3.9219, -0.2281,  ..., -0.6641, -4.7930,  2.5527]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 05:47:27 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The hamburger falls into the category of sandwich
The stapler falls into the category of device
The toaster falls into the category of appliance
The photo falls into the category of picture
The fridge falls into the category of appliance
The sidewalk falls into the category of walk
The pastry falls into the category of food
The hairpin falls into the category of
2024-08-01 05:47:28 root INFO     [order_1_approx] starting weight calculation for The fridge falls into the category of appliance
The hairpin falls into the category of pin
The hamburger falls into the category of sandwich
The pastry falls into the category of food
The sidewalk falls into the category of walk
The photo falls into the category of picture
The stapler falls into the category of device
The toaster falls into the category of
2024-08-01 05:47:28 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-08-01 05:50:17 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.4912, -0.0782, -0.1340,  ..., -0.1958, -0.2871, -0.1268],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.2539, -2.6406,  1.3555,  ...,  0.0918, -4.6328,  2.1680],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0660,  0.0007, -0.0499,  ..., -0.0464, -0.0040,  0.0161],
        [ 0.0063,  0.0576,  0.0369,  ...,  0.0023, -0.0082,  0.0047],
        [ 0.0167, -0.0016,  0.0160,  ..., -0.0052, -0.0280,  0.0145],
        ...,
        [ 0.0130, -0.0033, -0.0035,  ...,  0.0530,  0.0041, -0.0020],
        [-0.0216, -0.0100, -0.0050,  ..., -0.0028,  0.0495, -0.0092],
        [ 0.0167, -0.0025,  0.0257,  ..., -0.0048, -0.0118,  0.0284]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.1191, -3.8457,  2.0820,  ..., -0.2031, -3.8242,  1.6250]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 05:50:18 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The fridge falls into the category of appliance
The hairpin falls into the category of pin
The hamburger falls into the category of sandwich
The pastry falls into the category of food
The sidewalk falls into the category of walk
The photo falls into the category of picture
The stapler falls into the category of device
The toaster falls into the category of
2024-08-01 05:50:18 root INFO     [order_1_approx] starting weight calculation for The hairpin falls into the category of pin
The photo falls into the category of picture
The toaster falls into the category of appliance
The hamburger falls into the category of sandwich
The pastry falls into the category of food
The sidewalk falls into the category of walk
The fridge falls into the category of appliance
The stapler falls into the category of
2024-08-01 05:50:18 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-08-01 05:53:04 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1674, -0.2488, -0.1738,  ...,  0.0448, -0.3174, -0.2235],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.5781, -4.9023,  2.5625,  ..., -2.0059, -4.0977, -1.1016],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0401,  0.0052, -0.0194,  ...,  0.0092,  0.0036,  0.0273],
        [-0.0341,  0.0443, -0.0210,  ..., -0.0258,  0.0140,  0.0329],
        [ 0.0187, -0.0111,  0.0256,  ...,  0.0222, -0.0358, -0.0087],
        ...,
        [ 0.0028,  0.0229,  0.0174,  ...,  0.0239, -0.0063,  0.0150],
        [ 0.0174, -0.0099,  0.0040,  ...,  0.0052,  0.0273, -0.0157],
        [-0.0144,  0.0429, -0.0047,  ...,  0.0039,  0.0073,  0.0376]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.6953, -5.0469,  2.7500,  ..., -1.8584, -4.1523, -1.2500]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 05:53:05 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The hairpin falls into the category of pin
The photo falls into the category of picture
The toaster falls into the category of appliance
The hamburger falls into the category of sandwich
The pastry falls into the category of food
The sidewalk falls into the category of walk
The fridge falls into the category of appliance
The stapler falls into the category of
2024-08-01 05:53:05 root INFO     total operator prediction time: 1354.8927671909332 seconds
2024-08-01 05:53:05 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on meronyms - substance
2024-08-01 05:53:05 root INFO     building operator meronyms - substance
2024-08-01 05:53:05 root INFO     [order_1_approx] starting weight calculation for A plastic is made up of polymer
A mirror is made up of glass
A jam is made up of fruit
A flag is made up of fabric
A body is made up of flesh
A pastry is made up of flour
A pill is made up of medicine
A icicle is made up of
2024-08-01 05:53:06 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-08-01 05:55:55 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0536,  0.2620, -0.3726,  ..., -0.0710, -0.1793,  0.0179],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.5117, -5.4141, -0.5850,  ..., -4.0391,  1.0762, -0.9727],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0570, -0.0248, -0.0248,  ...,  0.0014,  0.0160, -0.0106],
        [-0.0145, -0.0065, -0.0298,  ..., -0.0189, -0.0069, -0.0383],
        [ 0.0082,  0.0007,  0.0149,  ...,  0.0337, -0.0011,  0.0045],
        ...,
        [ 0.0293,  0.0364,  0.0190,  ...,  0.0709,  0.0222, -0.0120],
        [-0.0408,  0.0030,  0.0043,  ...,  0.0546,  0.0210,  0.0197],
        [ 0.0058, -0.0270, -0.0321,  ..., -0.0092,  0.0207, -0.0022]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.6021, -5.5391, -0.1943,  ..., -3.8047,  1.1279, -0.5693]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 05:55:56 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A plastic is made up of polymer
A mirror is made up of glass
A jam is made up of fruit
A flag is made up of fabric
A body is made up of flesh
A pastry is made up of flour
A pill is made up of medicine
A icicle is made up of
2024-08-01 05:55:57 root INFO     [order_1_approx] starting weight calculation for A mirror is made up of glass
A pill is made up of medicine
A body is made up of flesh
A plastic is made up of polymer
A jam is made up of fruit
A flag is made up of fabric
A icicle is made up of ice
A pastry is made up of
2024-08-01 05:55:57 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-08-01 05:58:46 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0022,  0.1135, -0.1516,  ...,  0.0673, -0.3857, -0.0260],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.1777, -3.7793, -0.4810,  ...,  0.3662, -4.2695,  3.3203],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0422,  0.0240,  0.0197,  ...,  0.0020, -0.0291,  0.0133],
        [ 0.0105,  0.0311,  0.0088,  ..., -0.0010, -0.0288,  0.0002],
        [-0.0020, -0.0086,  0.0013,  ...,  0.0402,  0.0084,  0.0199],
        ...,
        [ 0.0495,  0.0281, -0.0061,  ...,  0.0357, -0.0226, -0.0207],
        [ 0.0290,  0.0200, -0.0097,  ...,  0.0322,  0.0109,  0.0134],
        [-0.0158, -0.0011,  0.0367,  ...,  0.0176,  0.0384,  0.0271]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.1465, -3.9355, -0.3101,  ...,  0.0955, -4.4062,  3.3008]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 05:58:47 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A mirror is made up of glass
A pill is made up of medicine
A body is made up of flesh
A plastic is made up of polymer
A jam is made up of fruit
A flag is made up of fabric
A icicle is made up of ice
A pastry is made up of
2024-08-01 05:58:47 root INFO     [order_1_approx] starting weight calculation for A pastry is made up of flour
A body is made up of flesh
A mirror is made up of glass
A jam is made up of fruit
A icicle is made up of ice
A flag is made up of fabric
A plastic is made up of polymer
A pill is made up of
2024-08-01 05:58:47 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-08-01 06:01:36 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1852, -0.0300, -0.2271,  ..., -0.1698, -0.0922, -0.1885],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.4136, -6.9453,  1.1104,  ..., -2.2188,  0.5732,  0.5059],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0020,  0.0010, -0.0057,  ..., -0.0363, -0.0052, -0.0393],
        [ 0.0094, -0.0074, -0.0018,  ...,  0.0142, -0.0154,  0.0263],
        [-0.0170,  0.0614, -0.0014,  ..., -0.0071, -0.0156, -0.0203],
        ...,
        [ 0.0484, -0.0133, -0.0077,  ...,  0.0580, -0.0103,  0.0136],
        [-0.0080,  0.0419, -0.0099,  ...,  0.0300,  0.0349, -0.0133],
        [ 0.0207, -0.0304,  0.0068,  ...,  0.0109,  0.0388,  0.0648]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.4612, -7.3125,  1.3486,  ..., -2.0391,  0.1633,  0.1099]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 06:01:37 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A pastry is made up of flour
A body is made up of flesh
A mirror is made up of glass
A jam is made up of fruit
A icicle is made up of ice
A flag is made up of fabric
A plastic is made up of polymer
A pill is made up of
2024-08-01 06:01:37 root INFO     [order_1_approx] starting weight calculation for A jam is made up of fruit
A pastry is made up of flour
A icicle is made up of ice
A flag is made up of fabric
A pill is made up of medicine
A plastic is made up of polymer
A mirror is made up of glass
A body is made up of
2024-08-01 06:01:37 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-08-01 06:04:25 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2181,  0.0933, -0.0925,  ..., -0.0748, -0.0472, -0.1433],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.9492, -7.0898,  2.2832,  ..., -3.4062, -3.3359, -0.3823],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0116,  0.0200, -0.0129,  ...,  0.0221, -0.0047,  0.0161],
        [-0.0039, -0.0270,  0.0341,  ..., -0.0105, -0.0041, -0.0033],
        [-0.0195,  0.0041,  0.0010,  ...,  0.0316, -0.0234,  0.0276],
        ...,
        [ 0.0008,  0.0119, -0.0068,  ...,  0.0397,  0.0270,  0.0090],
        [-0.0088, -0.0283,  0.0278,  ..., -0.0413, -0.0166,  0.0031],
        [ 0.0116, -0.0161,  0.0261,  ..., -0.0262, -0.0006,  0.0031]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.8193, -6.4023,  1.5391,  ..., -4.0234, -3.0430,  0.6519]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 06:04:26 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A jam is made up of fruit
A pastry is made up of flour
A icicle is made up of ice
A flag is made up of fabric
A pill is made up of medicine
A plastic is made up of polymer
A mirror is made up of glass
A body is made up of
2024-08-01 06:04:26 root INFO     [order_1_approx] starting weight calculation for A pastry is made up of flour
A pill is made up of medicine
A plastic is made up of polymer
A icicle is made up of ice
A body is made up of flesh
A jam is made up of fruit
A flag is made up of fabric
A mirror is made up of
2024-08-01 06:04:26 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-08-01 06:07:14 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0481, -0.0385, -0.3462,  ...,  0.2090,  0.0642, -0.1753],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.6484, -4.3477, -0.2876,  ..., -2.0430, -3.0039,  1.2480],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0299, -0.0185,  0.0052,  ...,  0.0521, -0.0258, -0.0190],
        [-0.0109,  0.0462, -0.0065,  ...,  0.0328, -0.0157,  0.0099],
        [ 0.0004, -0.0132,  0.0449,  ...,  0.0418, -0.0407, -0.0040],
        ...,
        [ 0.0250,  0.0221,  0.0010,  ...,  0.0378, -0.0224, -0.0170],
        [-0.0221, -0.0009, -0.0307,  ...,  0.0001,  0.0395, -0.0316],
        [ 0.0384,  0.0084, -0.0122,  ..., -0.0060,  0.0626,  0.0421]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.3672, -4.5625, -0.3113,  ..., -2.2520, -3.5273,  1.3643]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 06:07:15 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A pastry is made up of flour
A pill is made up of medicine
A plastic is made up of polymer
A icicle is made up of ice
A body is made up of flesh
A jam is made up of fruit
A flag is made up of fabric
A mirror is made up of
2024-08-01 06:07:15 root INFO     [order_1_approx] starting weight calculation for A icicle is made up of ice
A flag is made up of fabric
A jam is made up of fruit
A body is made up of flesh
A mirror is made up of glass
A pastry is made up of flour
A pill is made up of medicine
A plastic is made up of
2024-08-01 06:07:16 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-08-01 06:10:07 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0919,  0.1351, -0.2949,  ..., -0.0525,  0.1588,  0.1675],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.4492, -5.0625, -0.3293,  ..., -3.3828,  1.7715,  2.4844],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0184,  0.0405, -0.0263,  ...,  0.0217, -0.0119, -0.0425],
        [ 0.0026, -0.0164, -0.0106,  ..., -0.0255, -0.0029,  0.0380],
        [-0.0195,  0.0084, -0.0028,  ...,  0.0072,  0.0093, -0.0223],
        ...,
        [ 0.0661, -0.0672,  0.0148,  ...,  0.0117, -0.0305,  0.0120],
        [-0.0314,  0.0569, -0.0253,  ...,  0.0540,  0.0046, -0.0400],
        [ 0.0218, -0.0418,  0.0049,  ..., -0.0393,  0.0111,  0.0221]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.2090, -4.9297, -0.3525,  ..., -3.0254,  1.2656,  2.7441]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 06:10:08 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A icicle is made up of ice
A flag is made up of fabric
A jam is made up of fruit
A body is made up of flesh
A mirror is made up of glass
A pastry is made up of flour
A pill is made up of medicine
A plastic is made up of
2024-08-01 06:10:08 root INFO     [order_1_approx] starting weight calculation for A pill is made up of medicine
A plastic is made up of polymer
A body is made up of flesh
A icicle is made up of ice
A pastry is made up of flour
A flag is made up of fabric
A mirror is made up of glass
A jam is made up of
2024-08-01 06:10:08 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-08-01 06:12:59 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1017,  0.1236, -0.0670,  ...,  0.0154, -0.2898,  0.0704],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.7578, -7.0117, -0.7729,  ..., -2.1758, -3.7266,  1.8008],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0234, -0.0322,  0.0068,  ..., -0.0290, -0.0172,  0.0135],
        [-0.0264,  0.0021,  0.0241,  ..., -0.0517,  0.0361, -0.0185],
        [-0.0181, -0.0030,  0.0112,  ..., -0.0279, -0.0082,  0.0170],
        ...,
        [-0.0154, -0.0052,  0.0176,  ...,  0.0895,  0.0083, -0.0446],
        [ 0.0329,  0.0094, -0.0658,  ...,  0.0249,  0.0208, -0.0321],
        [-0.0200, -0.0399,  0.0172,  ..., -0.0460,  0.0150,  0.0628]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.0449, -7.3867, -0.2427,  ..., -2.6387, -4.1836,  2.3398]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 06:13:00 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A pill is made up of medicine
A plastic is made up of polymer
A body is made up of flesh
A icicle is made up of ice
A pastry is made up of flour
A flag is made up of fabric
A mirror is made up of glass
A jam is made up of
2024-08-01 06:13:00 root INFO     [order_1_approx] starting weight calculation for A mirror is made up of glass
A jam is made up of fruit
A pastry is made up of flour
A icicle is made up of ice
A pill is made up of medicine
A body is made up of flesh
A plastic is made up of polymer
A flag is made up of
2024-08-01 06:13:00 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-08-01 06:15:50 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2151,  0.3994, -0.2817,  ...,  0.1031, -0.1232, -0.0856],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.8438, -6.9062,  2.2461,  ..., -2.5234, -0.9194, -0.5205],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0444, -0.0229,  0.0525,  ...,  0.0177,  0.0101, -0.0170],
        [-0.0119,  0.0679, -0.0037,  ..., -0.0019, -0.0132,  0.0308],
        [-0.0014, -0.0023,  0.0124,  ..., -0.0082, -0.0145, -0.0286],
        ...,
        [ 0.0331,  0.0074,  0.0125,  ...,  0.0573, -0.0082, -0.0350],
        [-0.0176,  0.0105, -0.0068,  ..., -0.0082, -0.0225, -0.0148],
        [ 0.0375, -0.0124, -0.0086,  ..., -0.0144,  0.0524,  0.0742]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.3242, -7.0469,  2.5000,  ..., -2.6562, -1.8203,  0.0479]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 06:15:51 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A mirror is made up of glass
A jam is made up of fruit
A pastry is made up of flour
A icicle is made up of ice
A pill is made up of medicine
A body is made up of flesh
A plastic is made up of polymer
A flag is made up of
2024-08-01 06:15:51 root INFO     total operator prediction time: 1365.3163666725159 seconds
2024-08-01 06:15:51 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on synonyms - intensity
2024-08-01 06:15:51 root INFO     building operator synonyms - intensity
2024-08-01 06:15:51 root INFO     [order_1_approx] starting weight calculation for A more intense word for snack is meal
A more intense word for angry is furious
A more intense word for dislike is hate
A more intense word for pony is horse
A more intense word for sea is ocean
A more intense word for sniffles is pneumonia
A more intense word for lake is sea
A more intense word for chuckle is
2024-08-01 06:15:51 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-08-01 06:18:38 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1831, -0.2178, -0.1226,  ..., -0.0851, -0.6582,  0.1963],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.6602, -3.6836,  5.6719,  ...,  3.0566, -0.4697, -0.4375],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 3.5095e-02,  6.1703e-04, -1.9745e-02,  ...,  1.9012e-02,
          1.1375e-02,  2.7180e-03],
        [ 6.9427e-03,  4.5502e-02,  2.3682e-02,  ..., -1.0422e-02,
          2.1637e-02,  4.8492e-02],
        [-1.3779e-02, -1.8005e-02,  3.9978e-03,  ...,  1.6052e-02,
         -1.9867e-02, -2.6733e-02],
        ...,
        [ 7.2479e-05, -1.8280e-02,  9.5215e-03,  ...,  1.3885e-03,
          4.5280e-03, -3.3325e-02],
        [-1.4633e-02, -3.4332e-04, -1.9135e-02,  ..., -2.0920e-02,
          1.3100e-02,  1.7868e-02],
        [-4.6043e-03,  1.0193e-02, -1.4336e-02,  ..., -1.6953e-02,
          9.5520e-03,  2.3422e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.7021, -3.8789,  5.5312,  ...,  2.4766, -0.4902, -0.5654]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 06:18:39 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more intense word for snack is meal
A more intense word for angry is furious
A more intense word for dislike is hate
A more intense word for pony is horse
A more intense word for sea is ocean
A more intense word for sniffles is pneumonia
A more intense word for lake is sea
A more intense word for chuckle is
2024-08-01 06:18:39 root INFO     [order_1_approx] starting weight calculation for A more intense word for angry is furious
A more intense word for sea is ocean
A more intense word for lake is sea
A more intense word for snack is meal
A more intense word for chuckle is laugh
A more intense word for dislike is hate
A more intense word for sniffles is pneumonia
A more intense word for pony is
2024-08-01 06:18:40 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-08-01 06:21:29 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0526,  0.0410, -0.1089,  ..., -0.2269, -0.0751,  0.1481],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.2959, -4.8281,  0.6787,  ...,  1.5977, -3.6172, -0.9160],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0595, -0.0358,  0.0221,  ...,  0.0013, -0.0473,  0.0381],
        [ 0.0258,  0.0131, -0.0058,  ..., -0.0073,  0.0092, -0.0062],
        [ 0.0286, -0.0421,  0.0772,  ..., -0.0274, -0.0286, -0.0039],
        ...,
        [-0.0041, -0.0026,  0.0066,  ...,  0.0547, -0.0024, -0.0514],
        [-0.0293,  0.0110, -0.0490,  ..., -0.0033,  0.0046,  0.0070],
        [ 0.0073, -0.0579,  0.0199,  ..., -0.0246, -0.0302,  0.0210]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.5664, -3.9160,  0.4536,  ...,  1.4785, -4.1211, -0.6152]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 06:21:30 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more intense word for angry is furious
A more intense word for sea is ocean
A more intense word for lake is sea
A more intense word for snack is meal
A more intense word for chuckle is laugh
A more intense word for dislike is hate
A more intense word for sniffles is pneumonia
A more intense word for pony is
2024-08-01 06:21:30 root INFO     [order_1_approx] starting weight calculation for A more intense word for chuckle is laugh
A more intense word for snack is meal
A more intense word for angry is furious
A more intense word for pony is horse
A more intense word for dislike is hate
A more intense word for sniffles is pneumonia
A more intense word for lake is sea
A more intense word for sea is
2024-08-01 06:21:30 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-08-01 06:24:20 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1534, -0.1215,  0.0639,  ..., -0.1838, -0.1205,  0.2440],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.6162, -7.4766,  1.2832,  ..., -4.3008, -0.8286,  0.5410],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0230, -0.0146, -0.0171,  ..., -0.0009, -0.0175,  0.0137],
        [-0.0165,  0.0160, -0.0014,  ..., -0.0171,  0.0075,  0.0092],
        [ 0.0157, -0.0186,  0.0083,  ..., -0.0171, -0.0071,  0.0233],
        ...,
        [ 0.0213,  0.0017, -0.0031,  ..., -0.0058,  0.0269,  0.0212],
        [-0.0092, -0.0114,  0.0410,  ..., -0.0087,  0.0298, -0.0026],
        [-0.0416,  0.0022, -0.0212,  ...,  0.0303, -0.0380,  0.0138]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.7656, -6.9570,  1.4932,  ..., -4.2773, -0.8486,  0.6240]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 06:24:21 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more intense word for chuckle is laugh
A more intense word for snack is meal
A more intense word for angry is furious
A more intense word for pony is horse
A more intense word for dislike is hate
A more intense word for sniffles is pneumonia
A more intense word for lake is sea
A more intense word for sea is
2024-08-01 06:24:22 root INFO     [order_1_approx] starting weight calculation for A more intense word for sea is ocean
A more intense word for chuckle is laugh
A more intense word for pony is horse
A more intense word for lake is sea
A more intense word for dislike is hate
A more intense word for sniffles is pneumonia
A more intense word for snack is meal
A more intense word for angry is
2024-08-01 06:24:22 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-08-01 06:27:09 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1550,  0.0732, -0.2064,  ..., -0.0516, -0.3687,  0.1200],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.5664, -6.8828, -0.5986,  ..., -1.9434, -2.2754,  0.4043],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0449,  0.0062,  0.0071,  ..., -0.0174,  0.0132, -0.0055],
        [ 0.0362,  0.0090,  0.0054,  ..., -0.0214, -0.0110,  0.0095],
        [-0.0049,  0.0149,  0.0268,  ...,  0.0123, -0.0240,  0.0064],
        ...,
        [ 0.0169,  0.0084,  0.0029,  ...,  0.0533,  0.0010, -0.0202],
        [-0.0310,  0.0041, -0.0007,  ...,  0.0084,  0.0269, -0.0305],
        [-0.0071,  0.0025, -0.0284,  ..., -0.0020, -0.0030,  0.0354]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.6074, -6.6055, -0.2830,  ..., -2.0879, -2.3770, -0.0784]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 06:27:10 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more intense word for sea is ocean
A more intense word for chuckle is laugh
A more intense word for pony is horse
A more intense word for lake is sea
A more intense word for dislike is hate
A more intense word for sniffles is pneumonia
A more intense word for snack is meal
A more intense word for angry is
2024-08-01 06:27:11 root INFO     [order_1_approx] starting weight calculation for A more intense word for sea is ocean
A more intense word for chuckle is laugh
A more intense word for dislike is hate
A more intense word for sniffles is pneumonia
A more intense word for angry is furious
A more intense word for snack is meal
A more intense word for pony is horse
A more intense word for lake is
2024-08-01 06:27:11 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-08-01 06:29:59 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0550,  0.1615,  0.0325,  ..., -0.3979, -0.3003,  0.0357],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.4043, -6.4883,  1.7217,  ..., -3.2754, -0.6226,  0.1875],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0651, -0.0367, -0.0194,  ...,  0.0206, -0.0084,  0.0136],
        [ 0.0357,  0.0357,  0.0172,  ...,  0.0283,  0.0006, -0.0195],
        [ 0.0099,  0.0022,  0.0277,  ...,  0.0075, -0.0042,  0.0315],
        ...,
        [-0.0116,  0.0161,  0.0202,  ...,  0.0579,  0.0169, -0.0091],
        [ 0.0052, -0.0206,  0.0106,  ...,  0.0058,  0.0097,  0.0307],
        [-0.0124, -0.0279,  0.0133,  ..., -0.0135, -0.0096,  0.0357]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.0879, -6.2617,  1.9443,  ..., -3.1855, -0.8164,  0.0150]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 06:30:00 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more intense word for sea is ocean
A more intense word for chuckle is laugh
A more intense word for dislike is hate
A more intense word for sniffles is pneumonia
A more intense word for angry is furious
A more intense word for snack is meal
A more intense word for pony is horse
A more intense word for lake is
2024-08-01 06:30:00 root INFO     [order_1_approx] starting weight calculation for A more intense word for chuckle is laugh
A more intense word for dislike is hate
A more intense word for sea is ocean
A more intense word for pony is horse
A more intense word for lake is sea
A more intense word for snack is meal
A more intense word for angry is furious
A more intense word for sniffles is
2024-08-01 06:30:00 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-08-01 06:32:48 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0625, -0.2296, -0.1483,  ..., -0.2932, -0.3955,  0.1772],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.4922, -1.7178,  4.0352,  ..., -0.1797,  0.1753,  2.5566],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0013,  0.0183,  0.0168,  ..., -0.0222,  0.0084,  0.0419],
        [ 0.0307,  0.0134, -0.0033,  ..., -0.0053, -0.0272, -0.0140],
        [-0.0103, -0.0028,  0.0227,  ...,  0.0399, -0.0386, -0.0187],
        ...,
        [ 0.0130, -0.0151,  0.0155,  ...,  0.0216,  0.0047,  0.0009],
        [-0.0122, -0.0053,  0.0132,  ...,  0.0074,  0.0222, -0.0261],
        [-0.0335,  0.0252, -0.0332,  ..., -0.0065,  0.0328,  0.0379]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.3184, -1.6387,  4.1758,  ..., -0.1211, -0.2014,  2.4492]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 06:32:49 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more intense word for chuckle is laugh
A more intense word for dislike is hate
A more intense word for sea is ocean
A more intense word for pony is horse
A more intense word for lake is sea
A more intense word for snack is meal
A more intense word for angry is furious
A more intense word for sniffles is
2024-08-01 06:32:49 root INFO     [order_1_approx] starting weight calculation for A more intense word for sea is ocean
A more intense word for lake is sea
A more intense word for chuckle is laugh
A more intense word for sniffles is pneumonia
A more intense word for angry is furious
A more intense word for dislike is hate
A more intense word for pony is horse
A more intense word for snack is
2024-08-01 06:32:49 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-08-01 06:35:36 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0697, -0.0722, -0.1114,  ...,  0.1147, -0.4878, -0.1472],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 5.6172, -3.9492,  1.4355,  ...,  0.0237, -5.4883, -1.4092],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0423, -0.0178, -0.0215,  ..., -0.0182, -0.0318,  0.0362],
        [ 0.0103,  0.0278,  0.0181,  ..., -0.0296, -0.0430, -0.0497],
        [-0.0317, -0.0463,  0.0070,  ..., -0.0150, -0.0505,  0.0468],
        ...,
        [ 0.0385, -0.0017,  0.0079,  ...,  0.0290, -0.0467, -0.0076],
        [-0.0159,  0.0059,  0.0141,  ..., -0.0048,  0.0243,  0.0187],
        [-0.0594,  0.0265,  0.0349,  ...,  0.0335,  0.0462,  0.0119]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.7227, -3.4922,  1.5957,  ...,  0.0114, -5.9180, -1.3594]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 06:35:37 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more intense word for sea is ocean
A more intense word for lake is sea
A more intense word for chuckle is laugh
A more intense word for sniffles is pneumonia
A more intense word for angry is furious
A more intense word for dislike is hate
A more intense word for pony is horse
A more intense word for snack is
2024-08-01 06:35:37 root INFO     [order_1_approx] starting weight calculation for A more intense word for angry is furious
A more intense word for sea is ocean
A more intense word for snack is meal
A more intense word for lake is sea
A more intense word for pony is horse
A more intense word for sniffles is pneumonia
A more intense word for chuckle is laugh
A more intense word for dislike is
2024-08-01 06:35:37 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-08-01 06:38:19 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0898, -0.0304, -0.0009,  ...,  0.1289, -0.1403,  0.2498],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.4258, -5.9609,  0.9048,  ..., -0.7817, -3.9980, -2.2695],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0185, -0.0126, -0.0128,  ..., -0.0071, -0.0061,  0.0020],
        [-0.0035,  0.0126,  0.0474,  ..., -0.0060, -0.0363,  0.0160],
        [-0.0023, -0.0109,  0.0038,  ..., -0.0029, -0.0163, -0.0078],
        ...,
        [ 0.0262,  0.0102, -0.0097,  ...,  0.0120, -0.0085, -0.0054],
        [ 0.0479, -0.0317, -0.0326,  ..., -0.0060, -0.0025, -0.0103],
        [-0.0020, -0.0037, -0.0351,  ..., -0.0265,  0.0164,  0.0215]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.7422, -5.8633,  0.7344,  ..., -0.7441, -4.1875, -2.3320]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 06:38:20 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more intense word for angry is furious
A more intense word for sea is ocean
A more intense word for snack is meal
A more intense word for lake is sea
A more intense word for pony is horse
A more intense word for sniffles is pneumonia
A more intense word for chuckle is laugh
A more intense word for dislike is
2024-08-01 06:38:20 root INFO     total operator prediction time: 1349.495989561081 seconds
2024-08-01 06:38:20 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on hypernyms - animals
2024-08-01 06:38:20 root INFO     building operator hypernyms - animals
2024-08-01 06:38:20 root INFO     [order_1_approx] starting weight calculation for The human falls into the category of primate
The velociraptor falls into the category of dinosaur
The coyote falls into the category of canine
The jaguar falls into the category of feline
The tyrannosaurus falls into the category of dinosaur
The goose falls into the category of fowl
The quail falls into the category of fowl
The falcon falls into the category of
2024-08-01 06:38:20 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-08-01 06:41:07 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1157,  0.0956, -0.4829,  ..., -0.0703, -0.0916, -0.0556],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.5781, -3.1992,  2.5781,  ..., -1.2461, -6.3125,  1.6689],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 6.5979e-02,  5.0201e-03, -1.1086e-02,  ...,  1.5182e-02,
         -2.2430e-02,  3.7415e-02],
        [-8.8215e-05, -7.8678e-05,  5.3406e-03,  ...,  1.2756e-02,
          9.8877e-03,  4.1199e-03],
        [ 1.4099e-02, -2.4063e-02,  3.5522e-02,  ..., -4.5128e-03,
          5.0735e-03, -1.9806e-02],
        ...,
        [ 9.9640e-03,  3.1891e-02, -1.3557e-02,  ...,  5.2338e-02,
         -3.2166e-02,  1.4618e-02],
        [-2.8458e-02,  1.3161e-02,  1.7731e-02,  ...,  2.8503e-02,
          5.0140e-02,  2.0309e-02],
        [-1.4282e-02, -5.9471e-03,  3.1525e-02,  ..., -3.8635e-02,
         -5.4932e-04,  8.0872e-03]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.4453, -3.0000,  2.3906,  ..., -1.2871, -6.6016,  2.0859]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 06:41:08 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The human falls into the category of primate
The velociraptor falls into the category of dinosaur
The coyote falls into the category of canine
The jaguar falls into the category of feline
The tyrannosaurus falls into the category of dinosaur
The goose falls into the category of fowl
The quail falls into the category of fowl
The falcon falls into the category of
2024-08-01 06:41:08 root INFO     [order_1_approx] starting weight calculation for The jaguar falls into the category of feline
The tyrannosaurus falls into the category of dinosaur
The quail falls into the category of fowl
The human falls into the category of primate
The falcon falls into the category of raptor
The coyote falls into the category of canine
The velociraptor falls into the category of dinosaur
The goose falls into the category of
2024-08-01 06:41:08 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-08-01 06:43:54 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2023, -0.0856, -0.1777,  ...,  0.1060, -0.1689,  0.0720],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.7090, -2.9805,  3.0566,  ..., -2.2109, -8.7344,  1.4756],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0210,  0.0107, -0.0303,  ..., -0.0117, -0.0396,  0.0073],
        [ 0.0069,  0.0265,  0.0055,  ...,  0.0226, -0.0207,  0.0090],
        [ 0.0045, -0.0028,  0.0668,  ...,  0.0091, -0.0434,  0.0095],
        ...,
        [ 0.0359, -0.0041,  0.0273,  ...,  0.0627, -0.0286,  0.0114],
        [-0.0075,  0.0085,  0.0051,  ...,  0.0100,  0.0707, -0.0075],
        [ 0.0159, -0.0310,  0.0213,  ..., -0.0609,  0.0415, -0.0016]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.9688, -2.9941,  2.9141,  ..., -2.1074, -9.1562,  1.8018]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 06:43:55 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The jaguar falls into the category of feline
The tyrannosaurus falls into the category of dinosaur
The quail falls into the category of fowl
The human falls into the category of primate
The falcon falls into the category of raptor
The coyote falls into the category of canine
The velociraptor falls into the category of dinosaur
The goose falls into the category of
2024-08-01 06:43:56 root INFO     [order_1_approx] starting weight calculation for The quail falls into the category of fowl
The falcon falls into the category of raptor
The velociraptor falls into the category of dinosaur
The jaguar falls into the category of feline
The goose falls into the category of fowl
The tyrannosaurus falls into the category of dinosaur
The human falls into the category of primate
The coyote falls into the category of
2024-08-01 06:43:56 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-08-01 06:46:41 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2429,  0.1221, -0.3979,  ..., -0.1102, -0.0735, -0.0527],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.1006, -6.3633,  0.8569,  ..., -3.8516, -6.4297,  0.8438],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0296, -0.0148,  0.0064,  ..., -0.0093, -0.0057,  0.0134],
        [ 0.0075, -0.0142,  0.0356,  ...,  0.0178,  0.0129,  0.0134],
        [-0.0028,  0.0266,  0.0258,  ..., -0.0543, -0.0276, -0.0099],
        ...,
        [ 0.0064,  0.0158,  0.0042,  ..., -0.0230,  0.0269,  0.0136],
        [ 0.0160,  0.0388,  0.0004,  ...,  0.0298,  0.0244,  0.0101],
        [ 0.0054, -0.0139,  0.0097,  ...,  0.0056,  0.0209,  0.0123]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.3462, -6.4609,  0.5234,  ..., -3.8379, -6.9180,  1.0830]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 06:46:42 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The quail falls into the category of fowl
The falcon falls into the category of raptor
The velociraptor falls into the category of dinosaur
The jaguar falls into the category of feline
The goose falls into the category of fowl
The tyrannosaurus falls into the category of dinosaur
The human falls into the category of primate
The coyote falls into the category of
2024-08-01 06:46:42 root INFO     [order_1_approx] starting weight calculation for The falcon falls into the category of raptor
The tyrannosaurus falls into the category of dinosaur
The coyote falls into the category of canine
The jaguar falls into the category of feline
The goose falls into the category of fowl
The velociraptor falls into the category of dinosaur
The human falls into the category of primate
The quail falls into the category of
2024-08-01 06:46:42 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-08-01 06:49:27 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0305, -0.2427, -0.2028,  ...,  0.0788, -0.2377, -0.1823],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.2227, -3.5156,  2.7266,  ..., -1.4639, -5.1211,  0.3672],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0418,  0.0060, -0.0206,  ..., -0.0263, -0.0119, -0.0073],
        [ 0.0197,  0.0617, -0.0073,  ...,  0.0297, -0.0259, -0.0044],
        [ 0.0237, -0.0422,  0.0702,  ..., -0.0228, -0.0647,  0.0092],
        ...,
        [ 0.0321,  0.0088,  0.0039,  ...,  0.0749, -0.0296, -0.0042],
        [ 0.0218,  0.0110,  0.0081,  ...,  0.0627,  0.0469, -0.0204],
        [-0.0177, -0.0235,  0.0066,  ..., -0.0427, -0.0170,  0.0244]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.6992, -3.7715,  2.7324,  ..., -1.8828, -4.9141,  0.8018]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 06:49:28 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The falcon falls into the category of raptor
The tyrannosaurus falls into the category of dinosaur
The coyote falls into the category of canine
The jaguar falls into the category of feline
The goose falls into the category of fowl
The velociraptor falls into the category of dinosaur
The human falls into the category of primate
The quail falls into the category of
2024-08-01 06:49:28 root INFO     [order_1_approx] starting weight calculation for The jaguar falls into the category of feline
The tyrannosaurus falls into the category of dinosaur
The goose falls into the category of fowl
The coyote falls into the category of canine
The falcon falls into the category of raptor
The human falls into the category of primate
The quail falls into the category of fowl
The velociraptor falls into the category of
2024-08-01 06:49:28 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-08-01 06:52:10 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1147, -0.1655, -0.3223,  ..., -0.2388, -0.2671, -0.0475],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.5205, -5.3516,  2.2402,  ..., -1.3525, -7.5508, -0.1504],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0286,  0.0096, -0.0009,  ...,  0.0065,  0.0069,  0.0050],
        [-0.0008, -0.0078,  0.0093,  ...,  0.0065,  0.0284,  0.0117],
        [ 0.0025, -0.0049, -0.0064,  ...,  0.0075, -0.0272,  0.0074],
        ...,
        [ 0.0042, -0.0002,  0.0138,  ...,  0.0062, -0.0175,  0.0211],
        [ 0.0039,  0.0196, -0.0045,  ..., -0.0256,  0.0204,  0.0076],
        [ 0.0039,  0.0009,  0.0153,  ...,  0.0092,  0.0203,  0.0169]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.3574, -5.0703,  2.1328,  ..., -1.0625, -8.2422, -0.0414]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 06:52:11 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The jaguar falls into the category of feline
The tyrannosaurus falls into the category of dinosaur
The goose falls into the category of fowl
The coyote falls into the category of canine
The falcon falls into the category of raptor
The human falls into the category of primate
The quail falls into the category of fowl
The velociraptor falls into the category of
2024-08-01 06:52:11 root INFO     [order_1_approx] starting weight calculation for The coyote falls into the category of canine
The jaguar falls into the category of feline
The velociraptor falls into the category of dinosaur
The falcon falls into the category of raptor
The human falls into the category of primate
The goose falls into the category of fowl
The quail falls into the category of fowl
The tyrannosaurus falls into the category of
2024-08-01 06:52:11 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-08-01 06:54:59 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0247,  0.0947, -0.4058,  ..., -0.2910, -0.1908, -0.0513],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.9570, -3.7344,  1.7754,  ..., -3.0410, -6.6523, -1.4424],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0293, -0.0397, -0.0116,  ..., -0.0085,  0.0088,  0.0169],
        [-0.0313, -0.0630,  0.0063,  ..., -0.0693,  0.0461,  0.0118],
        [ 0.0389,  0.0206, -0.0055,  ...,  0.0334, -0.0536, -0.0089],
        ...,
        [-0.0055, -0.0247,  0.0334,  ...,  0.0149, -0.0167,  0.0285],
        [ 0.0151,  0.0438, -0.0140,  ...,  0.0295, -0.0084, -0.0044],
        [-0.0116, -0.0883,  0.0342,  ..., -0.0552,  0.0410,  0.0576]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.0625, -3.5996,  1.7188,  ..., -2.9258, -7.3398, -1.0049]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 06:55:00 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The coyote falls into the category of canine
The jaguar falls into the category of feline
The velociraptor falls into the category of dinosaur
The falcon falls into the category of raptor
The human falls into the category of primate
The goose falls into the category of fowl
The quail falls into the category of fowl
The tyrannosaurus falls into the category of
2024-08-01 06:55:00 root INFO     [order_1_approx] starting weight calculation for The tyrannosaurus falls into the category of dinosaur
The goose falls into the category of fowl
The velociraptor falls into the category of dinosaur
The coyote falls into the category of canine
The human falls into the category of primate
The quail falls into the category of fowl
The falcon falls into the category of raptor
The jaguar falls into the category of
2024-08-01 06:55:00 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-08-01 06:57:48 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0227, -0.0254, -0.2195,  ..., -0.0352, -0.1340, -0.2695],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.5625, -5.4609, -1.2363,  ..., -2.8828, -7.7266, -1.9092],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 3.4332e-05, -1.1429e-02,  3.4523e-03,  ..., -5.1346e-03,
         -2.6112e-03,  4.5242e-03],
        [ 7.3814e-03, -8.7357e-04,  1.5945e-03,  ..., -1.0948e-02,
          1.5045e-02,  8.8120e-04],
        [ 2.6226e-04, -1.6846e-02,  1.1665e-02,  ..., -8.0795e-03,
         -2.6894e-03, -3.5057e-03],
        ...,
        [ 1.4467e-03,  1.8034e-03, -7.8049e-03,  ..., -3.0499e-03,
          1.6312e-02,  8.1635e-03],
        [ 5.8365e-03, -3.4599e-03,  6.4011e-03,  ...,  7.3357e-03,
          2.9282e-02,  2.3880e-03],
        [-1.7700e-02,  4.7760e-03, -1.5764e-03,  ..., -1.3237e-02,
          7.0114e-03,  1.0090e-03]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.5732, -5.3594, -1.1123,  ..., -2.8984, -7.6797, -1.8037]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 06:57:49 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The tyrannosaurus falls into the category of dinosaur
The goose falls into the category of fowl
The velociraptor falls into the category of dinosaur
The coyote falls into the category of canine
The human falls into the category of primate
The quail falls into the category of fowl
The falcon falls into the category of raptor
The jaguar falls into the category of
2024-08-01 06:57:49 root INFO     [order_1_approx] starting weight calculation for The velociraptor falls into the category of dinosaur
The falcon falls into the category of raptor
The goose falls into the category of fowl
The tyrannosaurus falls into the category of dinosaur
The jaguar falls into the category of feline
The quail falls into the category of fowl
The coyote falls into the category of canine
The human falls into the category of
2024-08-01 06:57:49 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-08-01 07:00:37 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1085, -0.1876,  0.0941,  ..., -0.0362,  0.0272,  0.0110],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.5278, -6.6641,  2.1719,  ..., -2.3105, -7.0156, -0.3179],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0236, -0.0137, -0.0028,  ...,  0.0273,  0.0129,  0.0007],
        [ 0.0351, -0.0613,  0.0258,  ...,  0.0392,  0.0194, -0.0607],
        [-0.0233,  0.0263,  0.0038,  ..., -0.0433, -0.0316,  0.0205],
        ...,
        [ 0.0098, -0.0065, -0.0029,  ...,  0.0340, -0.0007,  0.0055],
        [ 0.0057,  0.0046,  0.0231,  ..., -0.0147,  0.0048, -0.0378],
        [ 0.0303, -0.0281,  0.0046,  ...,  0.0499,  0.0204, -0.0215]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.4229, -6.4609,  2.2598,  ..., -2.8477, -6.8555, -0.1902]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 07:00:38 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The velociraptor falls into the category of dinosaur
The falcon falls into the category of raptor
The goose falls into the category of fowl
The tyrannosaurus falls into the category of dinosaur
The jaguar falls into the category of feline
The quail falls into the category of fowl
The coyote falls into the category of canine
The human falls into the category of
2024-08-01 07:00:38 root INFO     total operator prediction time: 1337.9685966968536 seconds
2024-08-01 07:00:38 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on hyponyms - misc
2024-08-01 07:00:38 root INFO     building operator hyponyms - misc
2024-08-01 07:00:38 root INFO     [order_1_approx] starting weight calculation for A more specific term for a shirt is polo
A more specific term for a toy is doll
A more specific term for a mixer is blender
A more specific term for a drum is tambourine
A more specific term for a dress is gown
A more specific term for a trousers is jeans
A more specific term for a shoes is sneakers
A more specific term for a citrus is
2024-08-01 07:00:38 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-08-01 07:03:25 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1986, -0.1438, -0.0562,  ..., -0.1327, -0.1895, -0.1022],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.8965, -6.4727, -2.0625,  ..., -1.7402, -5.3984, -3.2500],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0104, -0.0461, -0.0238,  ..., -0.0069, -0.0239,  0.0009],
        [ 0.0065,  0.0239,  0.0150,  ...,  0.0058, -0.0008,  0.0467],
        [ 0.0111, -0.0098,  0.0648,  ...,  0.0285, -0.0162,  0.0034],
        ...,
        [ 0.0118, -0.0299,  0.0004,  ...,  0.0252, -0.0248,  0.0219],
        [-0.0073, -0.0315,  0.0039,  ...,  0.0089,  0.0223, -0.0283],
        [ 0.0295, -0.0507,  0.0195,  ...,  0.0051,  0.0041,  0.0184]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.8945, -6.1406, -2.0586,  ..., -1.3652, -5.1914, -3.0352]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 07:03:26 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more specific term for a shirt is polo
A more specific term for a toy is doll
A more specific term for a mixer is blender
A more specific term for a drum is tambourine
A more specific term for a dress is gown
A more specific term for a trousers is jeans
A more specific term for a shoes is sneakers
A more specific term for a citrus is
2024-08-01 07:03:27 root INFO     [order_1_approx] starting weight calculation for A more specific term for a toy is doll
A more specific term for a trousers is jeans
A more specific term for a shoes is sneakers
A more specific term for a shirt is polo
A more specific term for a mixer is blender
A more specific term for a drum is tambourine
A more specific term for a citrus is lemon
A more specific term for a dress is
2024-08-01 07:03:27 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-08-01 07:06:12 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0441, -0.1772, -0.2167,  ...,  0.1438, -0.1700,  0.0192],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.3101, -4.3633, -1.8105,  ...,  1.5342, -3.5195,  2.0391],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0160, -0.0283, -0.0061,  ..., -0.0650,  0.0749, -0.0240],
        [ 0.0090,  0.0246,  0.0264,  ...,  0.0054, -0.0128, -0.0136],
        [ 0.0041, -0.0197,  0.0646,  ..., -0.0092, -0.0393, -0.0243],
        ...,
        [ 0.0125,  0.0093, -0.0368,  ...,  0.0022,  0.0382, -0.0199],
        [ 0.0090, -0.0060,  0.0057,  ...,  0.0408,  0.0413,  0.0045],
        [-0.0197,  0.0053,  0.0056,  ..., -0.0210, -0.0001,  0.0157]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.0852, -3.8887, -1.6406,  ...,  1.7832, -3.6406,  2.6816]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 07:06:13 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more specific term for a toy is doll
A more specific term for a trousers is jeans
A more specific term for a shoes is sneakers
A more specific term for a shirt is polo
A more specific term for a mixer is blender
A more specific term for a drum is tambourine
A more specific term for a citrus is lemon
A more specific term for a dress is
2024-08-01 07:06:13 root INFO     [order_1_approx] starting weight calculation for A more specific term for a shirt is polo
A more specific term for a toy is doll
A more specific term for a trousers is jeans
A more specific term for a mixer is blender
A more specific term for a citrus is lemon
A more specific term for a shoes is sneakers
A more specific term for a dress is gown
A more specific term for a drum is
2024-08-01 07:06:13 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-08-01 07:09:02 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1138,  0.1514, -0.0831,  ..., -0.2888, -0.2844, -0.0273],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.5742, -5.9141,  0.4951,  ...,  0.4839,  0.2842, -0.1055],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0607,  0.0248,  0.0092,  ..., -0.0255,  0.0354,  0.0072],
        [-0.0041,  0.0285, -0.0499,  ...,  0.0295,  0.0133, -0.0272],
        [ 0.0180, -0.0161,  0.0447,  ..., -0.0167,  0.0005, -0.0077],
        ...,
        [-0.0003,  0.0214,  0.0071,  ...,  0.0361,  0.0004,  0.0134],
        [-0.0241, -0.0021,  0.0272,  ...,  0.0017,  0.0669,  0.0044],
        [-0.0051, -0.0163,  0.0175,  ..., -0.0172, -0.0153,  0.0225]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.1875, -6.0820,  0.1643,  ...,  0.8481, -0.1821,  0.2568]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 07:09:03 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more specific term for a shirt is polo
A more specific term for a toy is doll
A more specific term for a trousers is jeans
A more specific term for a mixer is blender
A more specific term for a citrus is lemon
A more specific term for a shoes is sneakers
A more specific term for a dress is gown
A more specific term for a drum is
2024-08-01 07:09:03 root INFO     [order_1_approx] starting weight calculation for A more specific term for a mixer is blender
A more specific term for a toy is doll
A more specific term for a drum is tambourine
A more specific term for a citrus is lemon
A more specific term for a dress is gown
A more specific term for a shoes is sneakers
A more specific term for a shirt is polo
A more specific term for a trousers is
2024-08-01 07:09:03 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-08-01 07:11:51 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0384, -0.0844, -0.2158,  ...,  0.3044, -0.1804,  0.0958],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.6758, -6.5703, -0.3130,  ...,  1.6094,  0.1558,  1.7793],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0254,  0.0031,  0.0006,  ...,  0.0211, -0.0247,  0.0101],
        [-0.0326, -0.0061,  0.0102,  ..., -0.0173,  0.0284, -0.0082],
        [ 0.0047, -0.0113,  0.0338,  ...,  0.0043, -0.0204,  0.0076],
        ...,
        [-0.0050, -0.0139, -0.0012,  ...,  0.0246,  0.0167, -0.0039],
        [-0.0118, -0.0186, -0.0087,  ..., -0.0141,  0.0395, -0.0079],
        [-0.0207, -0.0149, -0.0010,  ...,  0.0148, -0.0015,  0.0165]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.5117, -6.2461, -0.0547,  ...,  1.7324,  0.0532,  1.9023]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 07:11:52 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more specific term for a mixer is blender
A more specific term for a toy is doll
A more specific term for a drum is tambourine
A more specific term for a citrus is lemon
A more specific term for a dress is gown
A more specific term for a shoes is sneakers
A more specific term for a shirt is polo
A more specific term for a trousers is
2024-08-01 07:11:52 root INFO     [order_1_approx] starting weight calculation for A more specific term for a citrus is lemon
A more specific term for a toy is doll
A more specific term for a shoes is sneakers
A more specific term for a shirt is polo
A more specific term for a dress is gown
A more specific term for a drum is tambourine
A more specific term for a trousers is jeans
A more specific term for a mixer is
2024-08-01 07:11:52 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-08-01 07:14:39 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.3081, -0.0549, -0.1541,  ...,  0.3555, -0.4045, -0.1279],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.1133, -4.7969, -1.5371,  ...,  0.6304, -2.2324, -0.3066],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 2.7618e-02, -3.0960e-02, -2.5131e-02,  ...,  2.0401e-02,
          2.5833e-02, -2.1759e-02],
        [ 1.4069e-02,  3.7262e-02,  1.9379e-02,  ..., -2.2461e-02,
         -2.2217e-02, -8.3923e-05],
        [ 6.4011e-03, -2.2888e-02,  4.5624e-02,  ..., -4.5319e-03,
          6.9695e-03,  3.2379e-02],
        ...,
        [ 2.3941e-02,  4.6753e-02,  3.0655e-02,  ...,  3.4698e-02,
         -6.7810e-02, -1.0376e-02],
        [-4.5715e-02, -8.5144e-03, -2.8473e-02,  ...,  1.0956e-02,
          6.8298e-02,  4.5853e-03],
        [ 2.5955e-02,  5.4901e-02,  4.5563e-02,  ..., -1.9073e-02,
         -2.8656e-02,  4.2603e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.8872, -4.9375, -1.7725,  ...,  1.3369, -2.0039,  0.1667]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 07:14:40 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more specific term for a citrus is lemon
A more specific term for a toy is doll
A more specific term for a shoes is sneakers
A more specific term for a shirt is polo
A more specific term for a dress is gown
A more specific term for a drum is tambourine
A more specific term for a trousers is jeans
A more specific term for a mixer is
2024-08-01 07:14:41 root INFO     [order_1_approx] starting weight calculation for A more specific term for a dress is gown
A more specific term for a trousers is jeans
A more specific term for a mixer is blender
A more specific term for a drum is tambourine
A more specific term for a citrus is lemon
A more specific term for a shirt is polo
A more specific term for a toy is doll
A more specific term for a shoes is
2024-08-01 07:14:41 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-08-01 07:17:31 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0103, -0.1721, -0.0558,  ...,  0.2544, -0.0338, -0.2510],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 6.2148, -6.6289, -1.3809,  ...,  1.0488,  0.2520,  1.3301],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0076, -0.0037, -0.0213,  ..., -0.0055, -0.0109,  0.0086],
        [-0.0060,  0.0170,  0.0108,  ..., -0.0079, -0.0022, -0.0036],
        [-0.0102, -0.0057,  0.0399,  ..., -0.0052, -0.0457,  0.0111],
        ...,
        [ 0.0176, -0.0046,  0.0044,  ..., -0.0023,  0.0150,  0.0116],
        [-0.0023, -0.0044,  0.0232,  ..., -0.0154,  0.0049,  0.0148],
        [-0.0025, -0.0045,  0.0045,  ..., -0.0300,  0.0213,  0.0159]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 6.0859, -6.2539, -1.3672,  ...,  1.3105,  0.0378,  1.3584]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 07:17:32 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more specific term for a dress is gown
A more specific term for a trousers is jeans
A more specific term for a mixer is blender
A more specific term for a drum is tambourine
A more specific term for a citrus is lemon
A more specific term for a shirt is polo
A more specific term for a toy is doll
A more specific term for a shoes is
2024-08-01 07:17:32 root INFO     [order_1_approx] starting weight calculation for A more specific term for a dress is gown
A more specific term for a shoes is sneakers
A more specific term for a trousers is jeans
A more specific term for a drum is tambourine
A more specific term for a shirt is polo
A more specific term for a mixer is blender
A more specific term for a citrus is lemon
A more specific term for a toy is
2024-08-01 07:17:32 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-08-01 07:20:21 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2920,  0.1417, -0.0637,  ..., -0.2998, -0.3132, -0.1753],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-4.3633, -4.4414,  0.8325,  ...,  2.1602, -1.4238,  0.5527],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0540, -0.0216,  0.0294,  ...,  0.0184, -0.0214, -0.0108],
        [-0.0039,  0.0521, -0.0048,  ..., -0.0077,  0.0114, -0.0170],
        [-0.0143, -0.0314,  0.0320,  ..., -0.0119,  0.0086,  0.0106],
        ...,
        [ 0.0127, -0.0017, -0.0142,  ...,  0.0022, -0.0069, -0.0058],
        [-0.0002, -0.0113,  0.0178,  ...,  0.0052,  0.0114, -0.0137],
        [ 0.0172,  0.0081,  0.0029,  ...,  0.0067, -0.0016,  0.0202]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-4.4688, -4.4805,  0.6934,  ...,  2.1211, -1.5088,  0.1611]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 07:20:22 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more specific term for a dress is gown
A more specific term for a shoes is sneakers
A more specific term for a trousers is jeans
A more specific term for a drum is tambourine
A more specific term for a shirt is polo
A more specific term for a mixer is blender
A more specific term for a citrus is lemon
A more specific term for a toy is
2024-08-01 07:20:23 root INFO     [order_1_approx] starting weight calculation for A more specific term for a toy is doll
A more specific term for a dress is gown
A more specific term for a shoes is sneakers
A more specific term for a mixer is blender
A more specific term for a trousers is jeans
A more specific term for a drum is tambourine
A more specific term for a citrus is lemon
A more specific term for a shirt is
2024-08-01 07:20:23 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-08-01 07:23:11 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2408, -0.1343, -0.2974,  ...,  0.1821, -0.4429, -0.1417],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.2695, -2.9375, -1.0215,  ...,  1.9980, -0.9238, -0.1484],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0316, -0.0240, -0.0067,  ..., -0.0113,  0.0265, -0.0086],
        [-0.0085,  0.0338, -0.0019,  ...,  0.0231, -0.0230, -0.0056],
        [ 0.0158, -0.0344,  0.0340,  ...,  0.0058, -0.0307, -0.0055],
        ...,
        [ 0.0298,  0.0124, -0.0267,  ...,  0.0208,  0.0197, -0.0181],
        [-0.0204, -0.0157,  0.0172,  ...,  0.0202,  0.0452, -0.0189],
        [-0.0041,  0.0215, -0.0111,  ...,  0.0130,  0.0282,  0.0302]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.9980, -2.6328, -0.7598,  ...,  1.6055, -0.2905, -0.1600]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 07:23:12 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more specific term for a toy is doll
A more specific term for a dress is gown
A more specific term for a shoes is sneakers
A more specific term for a mixer is blender
A more specific term for a trousers is jeans
A more specific term for a drum is tambourine
A more specific term for a citrus is lemon
A more specific term for a shirt is
2024-08-01 07:23:12 root INFO     total operator prediction time: 1353.417091369629 seconds
2024-08-01 07:23:12 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on antonyms - binary
2024-08-01 07:23:12 root INFO     building operator antonyms - binary
2024-08-01 07:23:12 root INFO     [order_1_approx] starting weight calculation for The opposite of first is last
The opposite of inverse is reverse
The opposite of previously is subsequently
The opposite of west is east
The opposite of rise is sink
The opposite of outward is upward
The opposite of after is before
The opposite of employ is
2024-08-01 07:23:12 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-08-01 07:26:00 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0668,  0.0928, -0.0944,  ...,  0.0128, -0.3025,  0.0070],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.0156, -2.5762,  0.9961,  ...,  1.5762, -3.2793, -0.7485],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0360,  0.0228,  0.0166,  ...,  0.0336,  0.0129, -0.0345],
        [-0.0098,  0.0281,  0.0063,  ...,  0.0071,  0.0411,  0.0389],
        [ 0.0260, -0.0011,  0.0025,  ..., -0.0188,  0.0034, -0.0184],
        ...,
        [-0.0035, -0.0032, -0.0130,  ...,  0.0142,  0.0389,  0.0152],
        [ 0.0160,  0.0122,  0.0258,  ..., -0.0252, -0.0007,  0.0401],
        [-0.0362, -0.0404,  0.0078,  ...,  0.0112,  0.0021,  0.0312]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.5332, -3.4590,  0.8516,  ...,  1.0918, -2.9727, -1.0039]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 07:26:01 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of first is last
The opposite of inverse is reverse
The opposite of previously is subsequently
The opposite of west is east
The opposite of rise is sink
The opposite of outward is upward
The opposite of after is before
The opposite of employ is
2024-08-01 07:26:01 root INFO     [order_1_approx] starting weight calculation for The opposite of outward is upward
The opposite of west is east
The opposite of rise is sink
The opposite of previously is subsequently
The opposite of first is last
The opposite of inverse is reverse
The opposite of employ is dismiss
The opposite of after is
2024-08-01 07:26:01 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-08-01 07:28:51 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1187, -0.1731, -0.2200,  ..., -0.3176, -0.3723,  0.1482],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.7695, -2.4316, -0.3633,  ...,  0.8091, -1.3018, -4.8906],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0371, -0.0096, -0.0071,  ..., -0.0050,  0.0260,  0.0369],
        [ 0.0125,  0.0536,  0.0026,  ..., -0.0346, -0.0011,  0.0002],
        [-0.0132, -0.0044, -0.0135,  ...,  0.0221,  0.0062,  0.0335],
        ...,
        [-0.0161, -0.0286,  0.0263,  ..., -0.0100,  0.0244, -0.0184],
        [ 0.0397, -0.0009,  0.0099,  ..., -0.0085,  0.0464, -0.0264],
        [-0.0008,  0.0347, -0.0228,  ..., -0.0024,  0.0145,  0.0187]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.9688, -2.5352,  0.1064,  ...,  1.3516, -1.9785, -4.1797]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 07:28:52 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of outward is upward
The opposite of west is east
The opposite of rise is sink
The opposite of previously is subsequently
The opposite of first is last
The opposite of inverse is reverse
The opposite of employ is dismiss
The opposite of after is
2024-08-01 07:28:52 root INFO     [order_1_approx] starting weight calculation for The opposite of west is east
The opposite of employ is dismiss
The opposite of previously is subsequently
The opposite of after is before
The opposite of rise is sink
The opposite of inverse is reverse
The opposite of outward is upward
The opposite of first is
2024-08-01 07:28:52 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-08-01 07:31:41 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1711, -0.0791, -0.1414,  ..., -0.1954, -0.2915,  0.0457],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.9805, -2.1562,  0.6797,  ..., -0.5977, -0.1593, -4.1797],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0230, -0.0401,  0.0349,  ...,  0.0459,  0.0564,  0.0309],
        [ 0.0035,  0.0160, -0.0228,  ...,  0.0063,  0.0203,  0.0025],
        [ 0.0179, -0.0117,  0.0165,  ...,  0.0166, -0.0295,  0.0198],
        ...,
        [ 0.0406,  0.0151, -0.0317,  ..., -0.0119,  0.0164,  0.0192],
        [ 0.0202, -0.0243,  0.0074,  ...,  0.0473,  0.0167,  0.0205],
        [ 0.0102, -0.0078, -0.0178,  ...,  0.0523,  0.0195,  0.0532]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.7051, -2.1406,  0.9414,  ..., -0.3428, -1.0312, -3.6680]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 07:31:42 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of west is east
The opposite of employ is dismiss
The opposite of previously is subsequently
The opposite of after is before
The opposite of rise is sink
The opposite of inverse is reverse
The opposite of outward is upward
The opposite of first is
2024-08-01 07:31:42 root INFO     [order_1_approx] starting weight calculation for The opposite of previously is subsequently
The opposite of after is before
The opposite of employ is dismiss
The opposite of rise is sink
The opposite of first is last
The opposite of inverse is reverse
The opposite of outward is upward
The opposite of west is
2024-08-01 07:31:42 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-08-01 07:34:28 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1782, -0.0598, -0.0950,  ..., -0.2153, -0.0259,  0.1348],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.0547, -2.9395, -1.5039,  ..., -0.3022,  0.5679, -1.9385],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0499, -0.0227,  0.0132,  ...,  0.0232,  0.0532,  0.0379],
        [-0.0357,  0.0107, -0.0252,  ..., -0.0262,  0.0046,  0.0013],
        [-0.0303, -0.0424,  0.0072,  ...,  0.0408,  0.0029,  0.0329],
        ...,
        [ 0.0080, -0.0015, -0.0166,  ...,  0.0337,  0.0364, -0.0039],
        [ 0.0207, -0.0215,  0.0212,  ...,  0.0215,  0.0521,  0.0394],
        [ 0.0060,  0.0110, -0.0198,  ...,  0.0211, -0.0241, -0.0015]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.6523, -3.5254, -1.6191,  ..., -0.2129,  0.8042, -2.1250]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 07:34:29 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of previously is subsequently
The opposite of after is before
The opposite of employ is dismiss
The opposite of rise is sink
The opposite of first is last
The opposite of inverse is reverse
The opposite of outward is upward
The opposite of west is
2024-08-01 07:34:29 root INFO     [order_1_approx] starting weight calculation for The opposite of outward is upward
The opposite of employ is dismiss
The opposite of after is before
The opposite of previously is subsequently
The opposite of inverse is reverse
The opposite of first is last
The opposite of west is east
The opposite of rise is
2024-08-01 07:34:29 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-08-01 07:37:18 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0798, -0.1682, -0.2520,  ..., -0.1467, -0.2869,  0.0149],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.9824, -0.6396,  2.4609,  ..., -1.0342, -3.4180, -2.9375],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0060, -0.0402, -0.0344,  ..., -0.0152,  0.0090, -0.0399],
        [-0.0102,  0.0240, -0.0134,  ...,  0.0124,  0.0012,  0.0081],
        [-0.0239,  0.0062, -0.0287,  ..., -0.0080, -0.0088, -0.0177],
        ...,
        [ 0.0149, -0.0143,  0.0427,  ...,  0.0099,  0.0284, -0.0323],
        [-0.0356,  0.0529,  0.0041,  ..., -0.0265,  0.0222,  0.0312],
        [-0.0139, -0.0032,  0.0039,  ...,  0.0197, -0.0003,  0.0176]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.7402, -0.8452,  2.5957,  ..., -1.7217, -3.1621, -2.8066]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 07:37:19 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of outward is upward
The opposite of employ is dismiss
The opposite of after is before
The opposite of previously is subsequently
The opposite of inverse is reverse
The opposite of first is last
The opposite of west is east
The opposite of rise is
2024-08-01 07:37:19 root INFO     [order_1_approx] starting weight calculation for The opposite of rise is sink
The opposite of inverse is reverse
The opposite of west is east
The opposite of employ is dismiss
The opposite of after is before
The opposite of first is last
The opposite of previously is subsequently
The opposite of outward is
2024-08-01 07:37:19 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-08-01 07:40:09 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0764, -0.0347, -0.1014,  ..., -0.1796, -0.1039, -0.0979],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.3389, -1.7393,  1.0039,  ..., -1.5107,  0.3779, -3.9570],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0270, -0.0123,  0.0214,  ..., -0.0318,  0.0465, -0.0290],
        [-0.0411,  0.0412, -0.0210,  ..., -0.0040, -0.0315,  0.0308],
        [ 0.0326, -0.0103,  0.0657,  ...,  0.0329, -0.0760,  0.0218],
        ...,
        [ 0.0091,  0.0275, -0.0654,  ...,  0.0462,  0.0269, -0.0207],
        [ 0.0182,  0.0236,  0.0144,  ...,  0.0841,  0.0431, -0.0242],
        [-0.0244,  0.0054, -0.0313,  ..., -0.0077,  0.0055,  0.0266]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-2.4451e-01, -1.7432e+00,  6.6211e-01,  ..., -1.8115e+00,
         -2.4414e-04, -3.8828e+00]], device='cuda:1', dtype=torch.float16,
       grad_fn=<SubBackward0>) 

                    
2024-08-01 07:40:10 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of rise is sink
The opposite of inverse is reverse
The opposite of west is east
The opposite of employ is dismiss
The opposite of after is before
The opposite of first is last
The opposite of previously is subsequently
The opposite of outward is
2024-08-01 07:40:11 root INFO     [order_1_approx] starting weight calculation for The opposite of west is east
The opposite of employ is dismiss
The opposite of after is before
The opposite of rise is sink
The opposite of inverse is reverse
The opposite of outward is upward
The opposite of first is last
The opposite of previously is
2024-08-01 07:40:11 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-08-01 07:42:57 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0050, -0.2003, -0.1702,  ..., -0.2306, -0.3706,  0.2505],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.9102, -2.4766, -0.3953,  ..., -1.4404, -2.1562, -5.0000],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-2.7649e-02, -7.1030e-03, -8.1787e-03,  ..., -4.5776e-05,
          2.1484e-02,  8.0414e-03],
        [-3.3691e-02,  2.4841e-02, -5.4016e-02,  ...,  2.4841e-02,
         -1.3252e-02,  1.5160e-02],
        [ 6.2866e-02, -9.7351e-03,  4.4647e-02,  ..., -1.1292e-02,
         -4.0588e-02,  3.8567e-03],
        ...,
        [ 4.7989e-03, -3.4332e-03, -2.8687e-02,  ..., -1.3153e-02,
          4.0283e-03, -6.1836e-03],
        [ 4.6844e-02, -3.7384e-02,  1.5022e-02,  ...,  4.2175e-02,
         -2.0981e-03,  5.4779e-03],
        [-4.0283e-02,  1.5266e-02, -3.9062e-02,  ..., -2.0569e-02,
          3.1769e-02,  3.2135e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.8555, -2.3418, -0.7002,  ..., -1.1025, -2.4844, -4.4766]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 07:42:58 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of west is east
The opposite of employ is dismiss
The opposite of after is before
The opposite of rise is sink
The opposite of inverse is reverse
The opposite of outward is upward
The opposite of first is last
The opposite of previously is
2024-08-01 07:42:58 root INFO     [order_1_approx] starting weight calculation for The opposite of rise is sink
The opposite of after is before
The opposite of first is last
The opposite of employ is dismiss
The opposite of west is east
The opposite of outward is upward
The opposite of previously is subsequently
The opposite of inverse is
2024-08-01 07:42:58 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-08-01 07:45:49 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0323,  0.0836, -0.3860,  ...,  0.0067, -0.0969, -0.1450],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.9375, -0.7383,  1.8379,  ..., -2.3027, -4.1953, -1.8516],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.1326, -0.0549, -0.0872,  ..., -0.0803,  0.0553, -0.0519],
        [-0.0502,  0.1056,  0.0676,  ...,  0.0352, -0.0050,  0.0159],
        [ 0.0324, -0.0332, -0.0087,  ...,  0.0432,  0.0041,  0.0144],
        ...,
        [ 0.0179,  0.1047,  0.0421,  ...,  0.1306,  0.0239,  0.0283],
        [-0.0326, -0.0200,  0.0033,  ..., -0.0018,  0.0483,  0.0129],
        [-0.0549,  0.0646,  0.0109,  ..., -0.0142, -0.0264,  0.0110]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.0586, -0.3960,  1.7432,  ..., -0.9023, -3.9355, -2.2305]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 07:45:50 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of rise is sink
The opposite of after is before
The opposite of first is last
The opposite of employ is dismiss
The opposite of west is east
The opposite of outward is upward
The opposite of previously is subsequently
The opposite of inverse is
2024-08-01 07:45:50 root INFO     total operator prediction time: 1358.8499505519867 seconds
2024-08-01 07:45:50 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on meronyms - member
2024-08-01 07:45:50 root INFO     building operator meronyms - member
2024-08-01 07:45:51 root INFO     [order_1_approx] starting weight calculation for A division is a member of a company
A calf is a member of a cattle
A listener is a member of a audience
A soldier is a member of a army
A letter is a member of a alphabet
A policeman is a member of a police
A lion is a member of a pride
A flower is a member of a
2024-08-01 07:45:51 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-08-01 07:48:43 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0599,  0.2737, -0.3025,  ..., -0.1295, -0.0634, -0.0137],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.3018, -4.4258,  1.0781,  ...,  0.5039, -3.0664, -2.1133],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0493,  0.0160, -0.0025,  ..., -0.0031,  0.0098,  0.0351],
        [ 0.0026,  0.0002,  0.0131,  ...,  0.0324,  0.0231, -0.0400],
        [-0.0064, -0.0063,  0.0656,  ...,  0.0027,  0.0008, -0.0474],
        ...,
        [ 0.0506,  0.0377, -0.0521,  ...,  0.0486, -0.0331, -0.0099],
        [-0.0015, -0.0119,  0.0321,  ...,  0.0011,  0.0402,  0.0132],
        [-0.0102, -0.1132,  0.0544,  ...,  0.0114,  0.0443,  0.0046]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.6636, -3.5781,  1.6934,  ...,  0.0959, -3.3242, -1.1787]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 07:48:44 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A division is a member of a company
A calf is a member of a cattle
A listener is a member of a audience
A soldier is a member of a army
A letter is a member of a alphabet
A policeman is a member of a police
A lion is a member of a pride
A flower is a member of a
2024-08-01 07:48:44 root INFO     [order_1_approx] starting weight calculation for A soldier is a member of a army
A listener is a member of a audience
A division is a member of a company
A flower is a member of a bouquet
A calf is a member of a cattle
A policeman is a member of a police
A letter is a member of a alphabet
A lion is a member of a
2024-08-01 07:48:44 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-08-01 07:51:36 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0638,  0.2417, -0.1870,  ..., -0.1940, -0.1804, -0.0244],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 5.8047, -6.9258,  3.4375,  ..., -1.3252, -1.3438, -1.4160],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0538, -0.0088,  0.0164,  ..., -0.0177, -0.0224, -0.0014],
        [ 0.0181,  0.0026,  0.0128,  ...,  0.0130, -0.0424,  0.0064],
        [-0.0299, -0.0041,  0.0403,  ...,  0.0234,  0.0073, -0.0059],
        ...,
        [ 0.0098, -0.0012,  0.0044,  ...,  0.0383,  0.0190, -0.0287],
        [ 0.0338,  0.0431, -0.0166,  ...,  0.0511,  0.0187, -0.0767],
        [-0.0007, -0.0478, -0.0122,  ..., -0.0236, -0.0113,  0.0787]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 5.0391, -6.6680,  3.3691,  ..., -1.2461, -2.2578, -0.9863]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 07:51:37 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A soldier is a member of a army
A listener is a member of a audience
A division is a member of a company
A flower is a member of a bouquet
A calf is a member of a cattle
A policeman is a member of a police
A letter is a member of a alphabet
A lion is a member of a
2024-08-01 07:51:37 root INFO     [order_1_approx] starting weight calculation for A listener is a member of a audience
A flower is a member of a bouquet
A policeman is a member of a police
A calf is a member of a cattle
A letter is a member of a alphabet
A soldier is a member of a army
A lion is a member of a pride
A division is a member of a
2024-08-01 07:51:37 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-08-01 07:54:25 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1746,  0.3457, -0.0606,  ...,  0.0016,  0.2908,  0.2065],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.8271, -4.3789,  3.4043,  ..., -2.0820,  1.2686, -4.6875],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-1.8372e-02,  1.1560e-01, -1.5411e-02,  ..., -1.2927e-01,
          4.2358e-02,  9.7179e-04],
        [ 1.4893e-02, -1.2932e-02, -1.2712e-03,  ..., -2.2827e-02,
          4.2542e-02,  3.1853e-04],
        [-3.5309e-02, -2.7985e-02,  2.5482e-03,  ...,  3.2440e-02,
         -2.9114e-02, -2.7504e-03],
        ...,
        [ 9.4299e-03, -8.1024e-03,  7.0190e-03,  ...,  1.3416e-01,
         -1.1597e-03, -3.7598e-02],
        [-3.6011e-02,  7.6233e-02, -3.4409e-03,  ..., -2.5040e-02,
          6.4331e-02, -2.5749e-05],
        [ 1.0513e-02, -3.4698e-02,  1.3977e-02,  ...,  2.1912e-02,
          6.3416e-02,  9.8724e-03]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.0977, -4.3750,  3.0859,  ..., -2.3848,  0.9971, -4.5234]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 07:54:25 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A listener is a member of a audience
A flower is a member of a bouquet
A policeman is a member of a police
A calf is a member of a cattle
A letter is a member of a alphabet
A soldier is a member of a army
A lion is a member of a pride
A division is a member of a
2024-08-01 07:54:26 root INFO     [order_1_approx] starting weight calculation for A policeman is a member of a police
A letter is a member of a alphabet
A lion is a member of a pride
A listener is a member of a audience
A division is a member of a company
A flower is a member of a bouquet
A soldier is a member of a army
A calf is a member of a
2024-08-01 07:54:26 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-08-01 07:57:17 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3062,  0.1141,  0.0334,  ..., -0.2632, -0.1838, -0.0562],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.1406, -3.1875,  2.6738,  ..., -0.9556,  1.4375, -1.4023],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0578,  0.0420,  0.0076,  ...,  0.0416, -0.0136, -0.0243],
        [-0.0068,  0.0670, -0.0029,  ...,  0.0163, -0.0195,  0.0036],
        [-0.0151, -0.0323,  0.0234,  ..., -0.0112, -0.0084,  0.0014],
        ...,
        [ 0.0303,  0.0042,  0.0236,  ...,  0.0292,  0.0021, -0.0177],
        [ 0.0186,  0.0914, -0.0183,  ...,  0.0643,  0.0795, -0.0038],
        [ 0.0078, -0.0684,  0.0085,  ..., -0.0527,  0.0070,  0.0217]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.6191, -3.5098,  2.9941,  ..., -0.9971,  0.8662, -0.8691]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 07:57:18 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A policeman is a member of a police
A letter is a member of a alphabet
A lion is a member of a pride
A listener is a member of a audience
A division is a member of a company
A flower is a member of a bouquet
A soldier is a member of a army
A calf is a member of a
2024-08-01 07:57:19 root INFO     [order_1_approx] starting weight calculation for A calf is a member of a cattle
A lion is a member of a pride
A policeman is a member of a police
A flower is a member of a bouquet
A soldier is a member of a army
A division is a member of a company
A letter is a member of a alphabet
A listener is a member of a
2024-08-01 07:57:19 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-08-01 08:00:07 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1296, -0.0463, -0.2859,  ..., -0.0901,  0.1871, -0.1628],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.9375, -4.8633,  4.1641,  ...,  2.0508, -0.3276, -2.9648],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0541, -0.0782, -0.0283,  ..., -0.0141, -0.0062,  0.0332],
        [ 0.0324,  0.0104,  0.0685,  ..., -0.0539, -0.0732, -0.0225],
        [-0.0129,  0.0315, -0.0224,  ...,  0.0043,  0.0629,  0.0045],
        ...,
        [ 0.0031,  0.0251, -0.0491,  ...,  0.0626,  0.0015,  0.0075],
        [-0.0453,  0.0656, -0.0493,  ..., -0.0147,  0.0598, -0.0004],
        [ 0.0304, -0.0511, -0.0460,  ..., -0.0090,  0.0142,  0.0162]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.4448, -4.7461,  4.0664,  ...,  1.4004, -0.4731, -2.7246]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 08:00:08 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A calf is a member of a cattle
A lion is a member of a pride
A policeman is a member of a police
A flower is a member of a bouquet
A soldier is a member of a army
A division is a member of a company
A letter is a member of a alphabet
A listener is a member of a
2024-08-01 08:00:08 root INFO     [order_1_approx] starting weight calculation for A policeman is a member of a police
A division is a member of a company
A flower is a member of a bouquet
A listener is a member of a audience
A lion is a member of a pride
A calf is a member of a cattle
A soldier is a member of a army
A letter is a member of a
2024-08-01 08:00:08 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-08-01 08:02:52 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0685,  0.1241, -0.4556,  ..., -0.2664, -0.1050, -0.0061],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.7637, -4.0234, -1.4883,  ...,  1.0322, -1.4941, -2.6172],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0117,  0.1470,  0.0363,  ...,  0.0315, -0.0665, -0.0278],
        [ 0.0352, -0.0980, -0.0126,  ..., -0.0404,  0.0464,  0.0301],
        [ 0.0325, -0.0851,  0.0108,  ...,  0.0381,  0.0156,  0.0427],
        ...,
        [ 0.0416, -0.0085, -0.0081,  ...,  0.0317,  0.0110, -0.0359],
        [ 0.0155,  0.0277,  0.0024,  ..., -0.0012,  0.0171,  0.0104],
        [ 0.0570, -0.1570, -0.0070,  ...,  0.0142,  0.0406,  0.0915]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.8628, -3.7363, -1.5908,  ...,  0.4780, -1.5635, -2.7930]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 08:02:53 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A policeman is a member of a police
A division is a member of a company
A flower is a member of a bouquet
A listener is a member of a audience
A lion is a member of a pride
A calf is a member of a cattle
A soldier is a member of a army
A letter is a member of a
2024-08-01 08:02:53 root INFO     [order_1_approx] starting weight calculation for A listener is a member of a audience
A lion is a member of a pride
A calf is a member of a cattle
A soldier is a member of a army
A division is a member of a company
A letter is a member of a alphabet
A flower is a member of a bouquet
A policeman is a member of a
2024-08-01 08:02:53 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-08-01 08:05:39 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1909,  0.2437, -0.3789,  ..., -0.0358, -0.0255, -0.1149],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.3789, -7.5273,  3.8848,  ..., -1.1924,  3.5273, -8.2422],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0317,  0.0174,  0.0378,  ..., -0.0183,  0.0062, -0.0342],
        [-0.0150, -0.0340, -0.0180,  ..., -0.0208, -0.0090,  0.0487],
        [ 0.0117,  0.0119,  0.0608,  ...,  0.0037, -0.0032, -0.0248],
        ...,
        [ 0.0066, -0.0137,  0.0094,  ...,  0.0071,  0.0095,  0.0153],
        [-0.0144,  0.0684,  0.0278,  ...,  0.0020,  0.0214, -0.0430],
        [-0.0059, -0.0822, -0.0616,  ..., -0.0161, -0.0015,  0.0891]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.5449, -7.2148,  3.9766,  ..., -1.3672,  3.3848, -7.9492]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 08:05:40 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A listener is a member of a audience
A lion is a member of a pride
A calf is a member of a cattle
A soldier is a member of a army
A division is a member of a company
A letter is a member of a alphabet
A flower is a member of a bouquet
A policeman is a member of a
2024-08-01 08:05:40 root INFO     [order_1_approx] starting weight calculation for A calf is a member of a cattle
A listener is a member of a audience
A letter is a member of a alphabet
A division is a member of a company
A lion is a member of a pride
A flower is a member of a bouquet
A policeman is a member of a police
A soldier is a member of a
2024-08-01 08:05:40 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-08-01 08:08:25 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0630,  0.2646, -0.4736,  ..., -0.1002, -0.0586,  0.1401],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.9785, -7.5391,  2.5996,  ..., -2.1973,  1.0566, -4.4805],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0619,  0.0068, -0.0456,  ...,  0.0353, -0.0183, -0.0181],
        [ 0.0254, -0.0072, -0.0171,  ..., -0.0106,  0.0012,  0.0227],
        [-0.0362,  0.0005,  0.0667,  ..., -0.0115, -0.0179, -0.0111],
        ...,
        [ 0.0351, -0.0187,  0.0087,  ...,  0.0073,  0.0036,  0.0165],
        [-0.0501,  0.0742,  0.0138,  ..., -0.0178,  0.0142, -0.0085],
        [ 0.0648, -0.0704, -0.0212,  ..., -0.0206,  0.0353,  0.0465]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.6465, -7.5039,  3.2617,  ..., -2.4258,  1.8574, -5.0234]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 08:08:25 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A calf is a member of a cattle
A listener is a member of a audience
A letter is a member of a alphabet
A division is a member of a company
A lion is a member of a pride
A flower is a member of a bouquet
A policeman is a member of a police
A soldier is a member of a
2024-08-01 08:08:25 root INFO     total operator prediction time: 1355.0164375305176 seconds
2024-08-01 08:08:25 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on noun - plural_irreg
2024-08-01 08:08:25 root INFO     building operator noun - plural_irreg
2024-08-01 08:08:26 root INFO     [order_1_approx] starting weight calculation for The plural form of life is lives
The plural form of duty is duties
The plural form of category is categories
The plural form of university is universities
The plural form of community is communities
The plural form of memory is memories
The plural form of facility is facilities
The plural form of formula is
2024-08-01 08:08:26 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-08-01 08:11:17 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2991, -0.0573,  0.0489,  ..., -0.1494, -0.3083, -0.0184],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.3350, -1.1270,  4.1484,  ..., -0.5557, -2.5352, -0.2246],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0591, -0.0278, -0.0261,  ..., -0.0297,  0.0203,  0.0011],
        [-0.0071,  0.0554, -0.0085,  ...,  0.0174, -0.0514,  0.0296],
        [-0.0107, -0.0122, -0.0159,  ...,  0.0043, -0.0170,  0.0235],
        ...,
        [-0.0014,  0.0149,  0.0293,  ...,  0.0540, -0.0121, -0.0185],
        [ 0.0021,  0.0008, -0.0216,  ..., -0.0014,  0.0152, -0.0048],
        [ 0.0028,  0.0224, -0.0041,  ...,  0.0419, -0.0226,  0.0008]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.4048, -1.9346,  4.5352,  ..., -0.3865, -2.2129, -0.3169]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 08:11:18 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of life is lives
The plural form of duty is duties
The plural form of category is categories
The plural form of university is universities
The plural form of community is communities
The plural form of memory is memories
The plural form of facility is facilities
The plural form of formula is
2024-08-01 08:11:18 root INFO     [order_1_approx] starting weight calculation for The plural form of memory is memories
The plural form of duty is duties
The plural form of life is lives
The plural form of facility is facilities
The plural form of formula is formulae
The plural form of university is universities
The plural form of community is communities
The plural form of category is
2024-08-01 08:11:18 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-08-01 08:14:10 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1924, -0.0344, -0.0058,  ..., -0.0541, -0.4399,  0.1008],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.6992, -2.9180,  2.0137,  ..., -1.1182, -0.0107, -2.2148],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0396, -0.0121, -0.0144,  ...,  0.0170, -0.0291,  0.0040],
        [-0.0222,  0.0385,  0.0144,  ..., -0.0079, -0.0026, -0.0065],
        [-0.0129, -0.0206,  0.0111,  ..., -0.0125, -0.0038,  0.0215],
        ...,
        [-0.0356, -0.0075,  0.0127,  ...,  0.0106, -0.0051, -0.0026],
        [-0.0093,  0.0031, -0.0218,  ..., -0.0162,  0.0367,  0.0196],
        [ 0.0392, -0.0030, -0.0197,  ...,  0.0005, -0.0186,  0.0391]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.5269, -3.0859,  2.0957,  ..., -1.3691, -0.2390, -2.2188]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 08:14:11 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of memory is memories
The plural form of duty is duties
The plural form of life is lives
The plural form of facility is facilities
The plural form of formula is formulae
The plural form of university is universities
The plural form of community is communities
The plural form of category is
2024-08-01 08:14:11 root INFO     [order_1_approx] starting weight calculation for The plural form of category is categories
The plural form of university is universities
The plural form of memory is memories
The plural form of community is communities
The plural form of formula is formulae
The plural form of facility is facilities
The plural form of duty is duties
The plural form of life is
2024-08-01 08:14:12 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-08-01 08:17:03 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1733, -0.0501, -0.1163,  ..., -0.0853, -0.3064, -0.0426],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.5723, -3.0020,  0.1941,  ..., -1.8633, -2.4961, -2.1230],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0124, -0.0164,  0.0172,  ...,  0.0168, -0.0094, -0.0061],
        [ 0.0291, -0.0026,  0.0085,  ...,  0.0342, -0.0342, -0.0323],
        [ 0.0288, -0.0301,  0.0092,  ...,  0.0295, -0.0280,  0.0283],
        ...,
        [ 0.0172, -0.0116, -0.0188,  ...,  0.0149,  0.0008, -0.0241],
        [-0.0338,  0.0470,  0.0198,  ..., -0.0351,  0.0547,  0.0311],
        [ 0.0455, -0.0491, -0.0039,  ...,  0.0340, -0.0363, -0.0047]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.7832, -2.8145,  0.3755,  ..., -1.8096, -2.7988, -2.2129]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 08:17:04 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of category is categories
The plural form of university is universities
The plural form of memory is memories
The plural form of community is communities
The plural form of formula is formulae
The plural form of facility is facilities
The plural form of duty is duties
The plural form of life is
2024-08-01 08:17:04 root INFO     [order_1_approx] starting weight calculation for The plural form of duty is duties
The plural form of category is categories
The plural form of life is lives
The plural form of facility is facilities
The plural form of memory is memories
The plural form of university is universities
The plural form of formula is formulae
The plural form of community is
2024-08-01 08:17:04 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-08-01 08:19:56 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1714,  0.0088, -0.1558,  ..., -0.1613, -0.3042,  0.1322],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.4297, -4.1367,  2.0664,  ..., -3.5156,  0.8115, -1.9980],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 6.7871e-02, -1.4099e-02,  1.5579e-02,  ..., -1.8406e-03,
         -2.2934e-02, -9.9182e-03],
        [-7.1106e-03,  7.4615e-03,  5.4932e-04,  ...,  2.0676e-02,
          2.0889e-02, -1.2230e-02],
        [-1.1147e-02, -1.2047e-02,  2.4048e-02,  ..., -9.1476e-03,
         -4.5288e-02,  3.6072e-02],
        ...,
        [ 8.7738e-05,  2.3315e-02,  1.1658e-02,  ...,  2.6703e-02,
          6.6986e-03, -9.4528e-03],
        [ 1.6785e-03, -1.7357e-03, -9.4986e-03,  ...,  1.2299e-02,
         -9.8419e-03,  3.3752e-02],
        [ 1.9348e-02, -3.1319e-03, -1.3214e-02,  ...,  1.8127e-02,
         -2.3499e-03, -1.6022e-03]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.2949, -3.6699,  1.8213,  ..., -3.3066,  0.2061, -1.9521]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 08:19:56 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of duty is duties
The plural form of category is categories
The plural form of life is lives
The plural form of facility is facilities
The plural form of memory is memories
The plural form of university is universities
The plural form of formula is formulae
The plural form of community is
2024-08-01 08:19:57 root INFO     [order_1_approx] starting weight calculation for The plural form of university is universities
The plural form of category is categories
The plural form of life is lives
The plural form of duty is duties
The plural form of facility is facilities
The plural form of formula is formulae
The plural form of community is communities
The plural form of memory is
2024-08-01 08:19:57 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-08-01 08:22:47 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.3394, -0.0606, -0.1208,  ..., -0.0649,  0.0217,  0.0372],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.9468, -1.3574,  0.5283,  ..., -1.5303, -4.5664, -3.9492],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0461, -0.0066, -0.0036,  ...,  0.0058, -0.0082,  0.0047],
        [ 0.0037,  0.0229,  0.0045,  ..., -0.0074, -0.0329, -0.0042],
        [-0.0039,  0.0105,  0.0075,  ...,  0.0066, -0.0026,  0.0094],
        ...,
        [-0.0037,  0.0043, -0.0208,  ...,  0.0419, -0.0012, -0.0132],
        [ 0.0042, -0.0022, -0.0229,  ...,  0.0117, -0.0036,  0.0417],
        [ 0.0322,  0.0035, -0.0166,  ...,  0.0277,  0.0197, -0.0012]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.5654, -1.5791,  0.8320,  ..., -1.7607, -4.3789, -4.0156]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 08:22:48 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of university is universities
The plural form of category is categories
The plural form of life is lives
The plural form of duty is duties
The plural form of facility is facilities
The plural form of formula is formulae
The plural form of community is communities
The plural form of memory is
2024-08-01 08:22:48 root INFO     [order_1_approx] starting weight calculation for The plural form of category is categories
The plural form of formula is formulae
The plural form of memory is memories
The plural form of community is communities
The plural form of facility is facilities
The plural form of life is lives
The plural form of duty is duties
The plural form of university is
2024-08-01 08:22:48 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-08-01 08:25:40 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.3091, -0.0689, -0.1804,  ...,  0.0803, -0.3267,  0.0903],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.2422, -2.6738,  1.1484,  ..., -0.4209, -0.0631, -0.8955],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 1.4145e-02, -2.6993e-02,  5.3406e-05,  ...,  2.8015e-02,
         -5.4092e-03, -6.7810e-02],
        [-3.2654e-03,  3.4454e-02, -5.8861e-03,  ..., -1.8539e-02,
          3.2104e-02, -1.9287e-02],
        [ 5.9204e-03, -2.7985e-02,  2.2324e-02,  ...,  8.2626e-03,
         -3.5797e-02,  3.4241e-02],
        ...,
        [-3.0869e-02,  2.9449e-02,  8.5144e-03,  ...,  8.6517e-03,
         -1.8417e-02,  3.2074e-02],
        [ 2.4460e-02, -9.2697e-04,  4.2038e-03,  ...,  5.3177e-03,
          1.7487e-02,  3.7323e-02],
        [-1.4885e-02,  1.1154e-02, -4.9973e-03,  ...,  2.1606e-02,
         -1.8677e-02, -2.0782e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.7378, -2.4922,  1.5234,  ..., -1.1738, -0.3550, -0.8428]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 08:25:41 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of category is categories
The plural form of formula is formulae
The plural form of memory is memories
The plural form of community is communities
The plural form of facility is facilities
The plural form of life is lives
The plural form of duty is duties
The plural form of university is
2024-08-01 08:25:41 root INFO     [order_1_approx] starting weight calculation for The plural form of facility is facilities
The plural form of life is lives
The plural form of university is universities
The plural form of memory is memories
The plural form of community is communities
The plural form of category is categories
The plural form of formula is formulae
The plural form of duty is
2024-08-01 08:25:41 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-08-01 08:28:29 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1396,  0.3154, -0.1868,  ..., -0.1581, -0.1417,  0.2202],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.8696, -1.9922,  3.1973,  ..., -1.1338, -2.4609, -3.3906],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0286, -0.0231,  0.0142,  ..., -0.0260, -0.0118, -0.0217],
        [ 0.0207,  0.0244,  0.0278,  ..., -0.0245, -0.0105, -0.0031],
        [ 0.0111, -0.0534,  0.0001,  ...,  0.0291,  0.0172,  0.0194],
        ...,
        [ 0.0217,  0.0033, -0.0029,  ...,  0.0178,  0.0095,  0.0014],
        [ 0.0068,  0.0133, -0.0324,  ...,  0.0074,  0.0033, -0.0359],
        [-0.0082, -0.0166,  0.0095,  ...,  0.0024, -0.0088,  0.0012]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.8330, -1.9121,  3.4551,  ..., -0.8750, -2.4688, -3.4199]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 08:28:30 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of facility is facilities
The plural form of life is lives
The plural form of university is universities
The plural form of memory is memories
The plural form of community is communities
The plural form of category is categories
The plural form of formula is formulae
The plural form of duty is
2024-08-01 08:28:30 root INFO     [order_1_approx] starting weight calculation for The plural form of category is categories
The plural form of formula is formulae
The plural form of life is lives
The plural form of memory is memories
The plural form of community is communities
The plural form of university is universities
The plural form of duty is duties
The plural form of facility is
2024-08-01 08:28:30 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-08-01 08:31:22 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0493, -0.0304, -0.2715,  ..., -0.3787, -0.2710,  0.0635],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.7227, -2.6953,  3.5488,  ...,  0.2278, -0.9082, -1.9727],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0365, -0.0498, -0.0208,  ..., -0.0094, -0.0101, -0.0180],
        [-0.0267,  0.0165,  0.0067,  ...,  0.0103,  0.0065, -0.0171],
        [-0.0144, -0.0130,  0.0389,  ..., -0.0047, -0.0428, -0.0180],
        ...,
        [-0.0356,  0.0005, -0.0167,  ...,  0.0462,  0.0034, -0.0096],
        [ 0.0135, -0.0344, -0.0524,  ...,  0.0124,  0.0283, -0.0138],
        [-0.0054,  0.0078, -0.0109,  ...,  0.0332,  0.0253,  0.0200]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.0293, -3.0938,  3.3867,  ..., -0.4216, -1.1660, -2.1602]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 08:31:23 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of category is categories
The plural form of formula is formulae
The plural form of life is lives
The plural form of memory is memories
The plural form of community is communities
The plural form of university is universities
The plural form of duty is duties
The plural form of facility is
2024-08-01 08:31:23 root INFO     total operator prediction time: 1377.37739610672 seconds
2024-08-01 08:31:23 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on Ving - verb_inf
2024-08-01 08:31:23 root INFO     building operator Ving - verb_inf
2024-08-01 08:31:23 root INFO     [order_1_approx] starting weight calculation for losing is the active form of lose
continuing is the active form of continue
enjoying is the active form of enjoy
encouraging is the active form of encourage
understanding is the active form of understand
providing is the active form of provide
requiring is the active form of require
including is the active form of
2024-08-01 08:31:23 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-08-01 08:34:13 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0270, -0.0207,  0.0203,  ...,  0.1597, -0.0227, -0.1682],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.2383, -1.4639,  0.6377,  ...,  1.0986, -1.5586, -3.1094],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0728,  0.0072, -0.0067,  ..., -0.0014,  0.0160, -0.0029],
        [ 0.0083,  0.0514,  0.0161,  ...,  0.0075, -0.0136, -0.0166],
        [-0.0084, -0.0099,  0.0123,  ...,  0.0020,  0.0066, -0.0111],
        ...,
        [ 0.0007,  0.0147,  0.0057,  ...,  0.0545, -0.0265, -0.0042],
        [ 0.0117, -0.0170, -0.0012,  ..., -0.0007,  0.0283, -0.0077],
        [ 0.0121, -0.0024, -0.0242,  ...,  0.0009,  0.0287,  0.0450]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.4319, -1.4844,  0.9546,  ...,  0.9102, -1.7676, -3.4355]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 08:34:14 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for losing is the active form of lose
continuing is the active form of continue
enjoying is the active form of enjoy
encouraging is the active form of encourage
understanding is the active form of understand
providing is the active form of provide
requiring is the active form of require
including is the active form of
2024-08-01 08:34:14 root INFO     [order_1_approx] starting weight calculation for losing is the active form of lose
enjoying is the active form of enjoy
requiring is the active form of require
continuing is the active form of continue
including is the active form of include
understanding is the active form of understand
encouraging is the active form of encourage
providing is the active form of
2024-08-01 08:34:14 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-08-01 08:37:07 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1161, -0.0057,  0.0270,  ...,  0.0023, -0.0061, -0.0185],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.8926, -6.0000,  1.0752,  ...,  2.4160, -2.2852, -0.9941],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0460, -0.0129, -0.0152,  ..., -0.0221, -0.0115, -0.0051],
        [ 0.0148,  0.0330, -0.0148,  ...,  0.0087,  0.0419,  0.0247],
        [ 0.0041,  0.0057,  0.0172,  ...,  0.0196, -0.0262, -0.0009],
        ...,
        [ 0.0134, -0.0036, -0.0016,  ...,  0.0376, -0.0111,  0.0054],
        [ 0.0037, -0.0038, -0.0051,  ...,  0.0187,  0.0703,  0.0156],
        [ 0.0061,  0.0060, -0.0286,  ..., -0.0024,  0.0499,  0.0417]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.9414, -5.8281,  1.0615,  ...,  2.1055, -2.0547, -0.8984]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 08:37:08 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for losing is the active form of lose
enjoying is the active form of enjoy
requiring is the active form of require
continuing is the active form of continue
including is the active form of include
understanding is the active form of understand
encouraging is the active form of encourage
providing is the active form of
2024-08-01 08:37:08 root INFO     [order_1_approx] starting weight calculation for continuing is the active form of continue
including is the active form of include
providing is the active form of provide
understanding is the active form of understand
losing is the active form of lose
enjoying is the active form of enjoy
encouraging is the active form of encourage
requiring is the active form of
2024-08-01 08:37:08 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-08-01 08:40:00 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0685,  0.0656, -0.0129,  ..., -0.1792, -0.2930,  0.0682],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.6475, -3.7383,  1.1387,  ...,  0.6528, -2.5996, -2.0391],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0392, -0.0133,  0.0128,  ..., -0.0040, -0.0106, -0.0064],
        [-0.0103,  0.0528, -0.0092,  ...,  0.0109,  0.0053,  0.0064],
        [ 0.0106, -0.0128,  0.0157,  ..., -0.0139, -0.0052, -0.0264],
        ...,
        [-0.0006,  0.0129, -0.0203,  ...,  0.0438, -0.0110, -0.0126],
        [ 0.0240,  0.0031,  0.0087,  ..., -0.0043,  0.0524,  0.0259],
        [ 0.0046,  0.0065, -0.0091,  ..., -0.0091,  0.0146,  0.0239]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.3311, -3.6387,  0.9487,  ...,  0.2935, -2.5098, -1.9385]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 08:40:01 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for continuing is the active form of continue
including is the active form of include
providing is the active form of provide
understanding is the active form of understand
losing is the active form of lose
enjoying is the active form of enjoy
encouraging is the active form of encourage
requiring is the active form of
2024-08-01 08:40:01 root INFO     [order_1_approx] starting weight calculation for including is the active form of include
continuing is the active form of continue
understanding is the active form of understand
encouraging is the active form of encourage
requiring is the active form of require
providing is the active form of provide
enjoying is the active form of enjoy
losing is the active form of
2024-08-01 08:40:01 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-08-01 08:42:53 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0370,  0.1699,  0.0688,  ..., -0.0752,  0.0479,  0.0887],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.5137, -2.8965, -0.7324,  ...,  1.0664,  1.1650, -1.3418],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0155, -0.0111,  0.0147,  ...,  0.0016,  0.0102, -0.0148],
        [ 0.0051,  0.0378, -0.0010,  ..., -0.0049,  0.0039, -0.0048],
        [ 0.0111, -0.0104,  0.0027,  ..., -0.0088,  0.0142, -0.0107],
        ...,
        [ 0.0088,  0.0060, -0.0355,  ...,  0.0337, -0.0194,  0.0183],
        [-0.0163,  0.0010,  0.0018,  ..., -0.0118,  0.0134,  0.0157],
        [ 0.0068,  0.0113,  0.0075,  ..., -0.0009,  0.0068,  0.0210]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.7383, -3.1582, -0.6025,  ...,  0.8447,  0.4546, -1.0918]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 08:42:54 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for including is the active form of include
continuing is the active form of continue
understanding is the active form of understand
encouraging is the active form of encourage
requiring is the active form of require
providing is the active form of provide
enjoying is the active form of enjoy
losing is the active form of
2024-08-01 08:42:54 root INFO     [order_1_approx] starting weight calculation for providing is the active form of provide
losing is the active form of lose
enjoying is the active form of enjoy
including is the active form of include
requiring is the active form of require
continuing is the active form of continue
understanding is the active form of understand
encouraging is the active form of
2024-08-01 08:42:54 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-08-01 08:45:43 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2668,  0.0905, -0.0473,  ...,  0.1068, -0.2004, -0.0510],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.9922, -3.0508, -0.7539,  ...,  4.1094, -1.5439, -3.0020],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0058, -0.0118,  0.0002,  ..., -0.0061, -0.0103, -0.0051],
        [-0.0083,  0.0092,  0.0034,  ...,  0.0058, -0.0035,  0.0067],
        [ 0.0046,  0.0035, -0.0004,  ..., -0.0017,  0.0082, -0.0078],
        ...,
        [ 0.0074,  0.0092,  0.0026,  ...,  0.0140,  0.0024, -0.0044],
        [ 0.0008,  0.0032, -0.0137,  ...,  0.0059,  0.0048,  0.0193],
        [ 0.0046,  0.0030, -0.0199,  ...,  0.0033, -0.0004,  0.0188]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.1738, -3.1699, -0.8027,  ...,  3.8164, -1.2910, -2.9316]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 08:45:44 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for providing is the active form of provide
losing is the active form of lose
enjoying is the active form of enjoy
including is the active form of include
requiring is the active form of require
continuing is the active form of continue
understanding is the active form of understand
encouraging is the active form of
2024-08-01 08:45:44 root INFO     [order_1_approx] starting weight calculation for requiring is the active form of require
encouraging is the active form of encourage
providing is the active form of provide
including is the active form of include
losing is the active form of lose
understanding is the active form of understand
continuing is the active form of continue
enjoying is the active form of
2024-08-01 08:45:44 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-08-01 08:48:27 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0521,  0.0853,  0.0711,  ..., -0.0758, -0.2634,  0.0031],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.0820, -3.4238, -0.5195,  ...,  1.4395, -1.7139, -2.3105],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 3.1219e-02, -7.1287e-04, -9.0561e-03,  ..., -8.0032e-03,
         -1.6312e-02,  9.2926e-03],
        [-9.7656e-03,  3.7567e-02, -1.3573e-02,  ..., -1.3351e-05,
          1.1803e-02, -9.5673e-03],
        [ 1.1612e-02,  5.5237e-03, -1.9073e-05,  ..., -3.1548e-03,
         -3.4447e-03, -1.3771e-03],
        ...,
        [ 1.3054e-02,  9.0485e-03,  1.5900e-02,  ...,  2.3270e-02,
          5.1308e-03, -2.8992e-04],
        [-1.0849e-02,  1.0509e-03, -2.8305e-03,  ...,  1.8860e-02,
          3.3691e-02, -2.4681e-03],
        [ 5.9357e-03,  1.7120e-02, -2.8706e-03,  ...,  1.1002e-02,
          1.0300e-04,  1.7120e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.0234, -3.3809, -0.4568,  ...,  1.0840, -1.2988, -2.4082]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 08:48:29 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for requiring is the active form of require
encouraging is the active form of encourage
providing is the active form of provide
including is the active form of include
losing is the active form of lose
understanding is the active form of understand
continuing is the active form of continue
enjoying is the active form of
2024-08-01 08:48:29 root INFO     [order_1_approx] starting weight calculation for continuing is the active form of continue
providing is the active form of provide
losing is the active form of lose
including is the active form of include
enjoying is the active form of enjoy
encouraging is the active form of encourage
requiring is the active form of require
understanding is the active form of
2024-08-01 08:48:29 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-08-01 08:51:19 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2607,  0.2559,  0.0523,  ...,  0.2236, -0.2123,  0.1073],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.1758, -1.8965,  0.7373,  ...,  0.5000, -1.3418,  0.0518],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0549,  0.0019, -0.0121,  ..., -0.0126, -0.0026,  0.0144],
        [-0.0137,  0.0274,  0.0164,  ..., -0.0186, -0.0050,  0.0089],
        [-0.0017, -0.0088,  0.0092,  ..., -0.0062, -0.0145, -0.0106],
        ...,
        [-0.0125, -0.0025, -0.0105,  ...,  0.0385, -0.0007,  0.0153],
        [-0.0062,  0.0083, -0.0098,  ...,  0.0015,  0.0371, -0.0042],
        [ 0.0077, -0.0092,  0.0057,  ..., -0.0025,  0.0088,  0.0177]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.3477, -1.8545,  0.9639,  ...,  0.2161, -1.4502, -0.4009]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 08:51:20 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for continuing is the active form of continue
providing is the active form of provide
losing is the active form of lose
including is the active form of include
enjoying is the active form of enjoy
encouraging is the active form of encourage
requiring is the active form of require
understanding is the active form of
2024-08-01 08:51:20 root INFO     [order_1_approx] starting weight calculation for requiring is the active form of require
including is the active form of include
losing is the active form of lose
providing is the active form of provide
enjoying is the active form of enjoy
understanding is the active form of understand
encouraging is the active form of encourage
continuing is the active form of
2024-08-01 08:51:20 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-08-01 08:54:12 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1338, -0.1978, -0.0992,  ..., -0.0504, -0.2642,  0.0741],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.2988, -4.3281,  1.1260,  ...,  1.3633,  1.1260, -1.9590],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 1.6296e-02,  1.2894e-03, -1.0269e-02,  ..., -1.8494e-02,
         -3.1128e-03,  1.4267e-03],
        [-6.2141e-03,  2.2003e-02, -1.1414e-02,  ..., -2.2964e-03,
          1.1696e-02,  2.5826e-03],
        [ 1.4252e-02,  5.0888e-03,  7.3547e-03,  ...,  5.1956e-03,
         -4.1046e-03,  3.6240e-05],
        ...,
        [ 1.0338e-02,  1.2825e-02,  2.2602e-04,  ...,  2.5162e-02,
         -1.1696e-02,  7.9803e-03],
        [-6.8779e-03, -2.0599e-02, -9.9335e-03,  ...,  4.7226e-03,
          9.2010e-03,  1.1513e-02],
        [-3.3760e-04,  4.5090e-03, -1.2741e-02,  ...,  4.0016e-03,
         -8.3923e-05,  1.9806e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.5542, -4.2969,  1.0977,  ...,  1.2451,  1.3184, -2.0586]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 08:54:13 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for requiring is the active form of require
including is the active form of include
losing is the active form of lose
providing is the active form of provide
enjoying is the active form of enjoy
understanding is the active form of understand
encouraging is the active form of encourage
continuing is the active form of
2024-08-01 08:54:13 root INFO     total operator prediction time: 1370.6145157814026 seconds
2024-08-01 08:54:13 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on verb_Ving - Ved
2024-08-01 08:54:13 root INFO     building operator verb_Ving - Ved
2024-08-01 08:54:14 root INFO     [order_1_approx] starting weight calculation for After something is announcing, it has announced
After something is improving, it has improved
After something is considering, it has considered
After something is expecting, it has expected
After something is existing, it has existed
After something is telling, it has told
After something is creating, it has created
After something is relating, it has
2024-08-01 08:54:14 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-08-01 08:57:07 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0337,  0.0452, -0.0829,  ..., -0.0792, -0.3403, -0.1768],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.4292,  1.1846,  0.8975,  ...,  0.2793, -3.4609, -0.1270],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0121, -0.0149, -0.0133,  ...,  0.0074,  0.0260,  0.0007],
        [-0.0444,  0.0160,  0.0270,  ...,  0.0301, -0.0096, -0.0092],
        [-0.0065,  0.0060,  0.0115,  ...,  0.0279, -0.0234, -0.0221],
        ...,
        [-0.0054,  0.0312,  0.0064,  ..., -0.0028,  0.0149,  0.0027],
        [ 0.0341,  0.0307, -0.0102,  ..., -0.0130,  0.0211, -0.0334],
        [ 0.0132,  0.0077,  0.0100,  ...,  0.0120, -0.0311,  0.0031]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.1711,  1.2119,  1.1338,  ..., -0.1235, -3.1094, -0.0807]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 08:57:08 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for After something is announcing, it has announced
After something is improving, it has improved
After something is considering, it has considered
After something is expecting, it has expected
After something is existing, it has existed
After something is telling, it has told
After something is creating, it has created
After something is relating, it has
2024-08-01 08:57:08 root INFO     [order_1_approx] starting weight calculation for After something is improving, it has improved
After something is creating, it has created
After something is considering, it has considered
After something is expecting, it has expected
After something is relating, it has related
After something is telling, it has told
After something is existing, it has existed
After something is announcing, it has
2024-08-01 08:57:08 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-08-01 08:59:59 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1581,  0.4133,  0.0177,  ..., -0.0850, -0.2502, -0.1460],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.5869, -0.5967,  1.8613,  ..., -0.1162, -2.4043,  1.3730],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0300, -0.0077, -0.0158,  ...,  0.0199, -0.0356,  0.0073],
        [-0.0445, -0.0073,  0.0238,  ..., -0.0420, -0.0085, -0.0034],
        [ 0.0180, -0.0243, -0.0351,  ..., -0.0007, -0.0233, -0.0370],
        ...,
        [-0.0119,  0.0079, -0.0226,  ..., -0.0014,  0.0107, -0.0358],
        [ 0.0075,  0.0228, -0.0014,  ..., -0.0239,  0.0158,  0.0193],
        [-0.0030, -0.0055,  0.0405,  ..., -0.0282, -0.0043, -0.0036]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.2285, -0.3943,  2.0508,  ..., -0.2097, -2.3145,  1.5830]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 09:00:00 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for After something is improving, it has improved
After something is creating, it has created
After something is considering, it has considered
After something is expecting, it has expected
After something is relating, it has related
After something is telling, it has told
After something is existing, it has existed
After something is announcing, it has
2024-08-01 09:00:00 root INFO     [order_1_approx] starting weight calculation for After something is expecting, it has expected
After something is improving, it has improved
After something is considering, it has considered
After something is existing, it has existed
After something is telling, it has told
After something is announcing, it has announced
After something is relating, it has related
After something is creating, it has
2024-08-01 09:00:00 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-08-01 09:02:52 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0706,  0.1256,  0.0399,  ...,  0.0523, -0.1514, -0.0592],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.3242, -0.5361,  1.6191,  ..., -0.5112, -2.0234, -0.1211],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0076,  0.0159, -0.0516,  ...,  0.0273,  0.0413,  0.0173],
        [-0.0262,  0.0804, -0.0110,  ...,  0.0093, -0.0020, -0.0055],
        [ 0.0123, -0.0203, -0.0050,  ...,  0.0127, -0.0059,  0.0086],
        ...,
        [-0.0120,  0.0057,  0.0274,  ..., -0.0099,  0.0147, -0.0424],
        [ 0.0275,  0.0194, -0.0210,  ..., -0.0191, -0.0104,  0.0332],
        [ 0.0199,  0.0014,  0.0109,  ...,  0.0043, -0.0238,  0.0170]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.7666, -0.7261,  1.6484,  ..., -0.2871, -1.5322, -0.4192]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 09:02:53 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for After something is expecting, it has expected
After something is improving, it has improved
After something is considering, it has considered
After something is existing, it has existed
After something is telling, it has told
After something is announcing, it has announced
After something is relating, it has related
After something is creating, it has
2024-08-01 09:02:53 root INFO     [order_1_approx] starting weight calculation for After something is considering, it has considered
After something is relating, it has related
After something is telling, it has told
After something is creating, it has created
After something is improving, it has improved
After something is expecting, it has expected
After something is announcing, it has announced
After something is existing, it has
2024-08-01 09:02:53 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-08-01 09:05:44 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0966,  0.2727, -0.0951,  ..., -0.2815, -0.2266, -0.2710],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.4199,  1.1045, -0.4961,  ..., -1.8447, -1.7354, -1.2598],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0224, -0.0246, -0.0221,  ...,  0.0175,  0.0166,  0.0024],
        [-0.0383,  0.0461, -0.0096,  ..., -0.0271,  0.0045, -0.0408],
        [ 0.0033, -0.0288,  0.0068,  ..., -0.0044, -0.0135, -0.0194],
        ...,
        [ 0.0097,  0.0192, -0.0350,  ...,  0.0654, -0.0252,  0.0053],
        [ 0.0390,  0.0120, -0.0032,  ...,  0.0051,  0.0426,  0.0009],
        [-0.0163,  0.0149, -0.0098,  ...,  0.0178, -0.0229, -0.0220]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.8359,  1.3613, -1.0830,  ..., -1.5225, -1.5273, -1.1777]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 09:05:45 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for After something is considering, it has considered
After something is relating, it has related
After something is telling, it has told
After something is creating, it has created
After something is improving, it has improved
After something is expecting, it has expected
After something is announcing, it has announced
After something is existing, it has
2024-08-01 09:05:45 root INFO     [order_1_approx] starting weight calculation for After something is relating, it has related
After something is improving, it has improved
After something is existing, it has existed
After something is telling, it has told
After something is considering, it has considered
After something is announcing, it has announced
After something is creating, it has created
After something is expecting, it has
2024-08-01 09:05:45 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-08-01 09:08:36 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3105,  0.1004, -0.0635,  ..., -0.1716, -0.1851,  0.1190],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.5391,  0.5703, -2.0312,  ..., -1.7246, -2.8594, -0.1055],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0038,  0.0215, -0.0004,  ..., -0.0465, -0.0222,  0.0047],
        [-0.0357,  0.0687,  0.0246,  ...,  0.0156, -0.0417,  0.0275],
        [ 0.0116, -0.0161,  0.0113,  ..., -0.0298,  0.0108, -0.0285],
        ...,
        [ 0.0023,  0.0221,  0.0215,  ...,  0.0230,  0.0170, -0.0109],
        [ 0.0200,  0.0025,  0.0113,  ..., -0.0116,  0.0558, -0.0065],
        [ 0.0333,  0.0312,  0.0270,  ...,  0.0673,  0.0152,  0.0250]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.5957,  0.0996, -1.9512,  ..., -1.5088, -2.0020, -0.1390]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 09:08:38 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for After something is relating, it has related
After something is improving, it has improved
After something is existing, it has existed
After something is telling, it has told
After something is considering, it has considered
After something is announcing, it has announced
After something is creating, it has created
After something is expecting, it has
2024-08-01 09:08:38 root INFO     [order_1_approx] starting weight calculation for After something is announcing, it has announced
After something is expecting, it has expected
After something is telling, it has told
After something is improving, it has improved
After something is creating, it has created
After something is existing, it has existed
After something is relating, it has related
After something is considering, it has
2024-08-01 09:08:38 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-08-01 09:11:30 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1215,  0.0367, -0.0297,  ..., -0.0505, -0.0920,  0.0286],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.9668, -0.7480,  2.9102,  ..., -1.5381, -1.2461,  0.4629],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0147,  0.0226, -0.0034,  ..., -0.0203,  0.0013,  0.0029],
        [-0.0410,  0.0225,  0.0412,  ..., -0.0430, -0.0549, -0.0197],
        [ 0.0054, -0.0051,  0.0301,  ..., -0.0233, -0.0100, -0.0304],
        ...,
        [-0.0032, -0.0115,  0.0092,  ...,  0.0051, -0.0012, -0.0190],
        [ 0.0555,  0.0264,  0.0218,  ...,  0.0060,  0.0381,  0.0005],
        [-0.0029,  0.0047,  0.0271,  ..., -0.0073, -0.0441, -0.0536]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.3574, -0.9937,  2.8359,  ..., -1.3438, -0.8184,  0.2510]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 09:11:31 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for After something is announcing, it has announced
After something is expecting, it has expected
After something is telling, it has told
After something is improving, it has improved
After something is creating, it has created
After something is existing, it has existed
After something is relating, it has related
After something is considering, it has
2024-08-01 09:11:31 root INFO     [order_1_approx] starting weight calculation for After something is expecting, it has expected
After something is considering, it has considered
After something is announcing, it has announced
After something is telling, it has told
After something is relating, it has related
After something is existing, it has existed
After something is creating, it has created
After something is improving, it has
2024-08-01 09:11:31 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-08-01 09:14:23 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0161,  0.0521,  0.1906,  ..., -0.0535, -0.0329,  0.1650],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.4902, -0.4456,  0.3262,  ..., -1.2822, -1.3154, -1.8838],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0268, -0.0036,  0.0201,  ...,  0.0178, -0.0519, -0.0385],
        [-0.0197,  0.0191, -0.0016,  ...,  0.0047, -0.0018, -0.0364],
        [ 0.0265, -0.0122,  0.0030,  ..., -0.0165, -0.0093, -0.0589],
        ...,
        [ 0.0388, -0.0008,  0.0052,  ...,  0.0234,  0.0055,  0.0050],
        [-0.0280,  0.0317, -0.0118,  ..., -0.0129,  0.0479,  0.0677],
        [-0.0098, -0.0121,  0.0001,  ...,  0.0152, -0.0048,  0.0176]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.0312,  0.3611,  0.9634,  ..., -1.2002, -1.9619, -1.6240]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 09:14:24 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for After something is expecting, it has expected
After something is considering, it has considered
After something is announcing, it has announced
After something is telling, it has told
After something is relating, it has related
After something is existing, it has existed
After something is creating, it has created
After something is improving, it has
2024-08-01 09:14:24 root INFO     [order_1_approx] starting weight calculation for After something is announcing, it has announced
After something is considering, it has considered
After something is relating, it has related
After something is expecting, it has expected
After something is creating, it has created
After something is improving, it has improved
After something is existing, it has existed
After something is telling, it has
2024-08-01 09:14:24 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-08-01 09:17:17 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0746, -0.0234, -0.0015,  ..., -0.1870, -0.2286,  0.0617],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.8008,  1.6533,  3.3398,  ...,  0.5923, -5.1992, -0.7812],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0104, -0.0053, -0.0040,  ...,  0.0029,  0.0046,  0.0139],
        [-0.0461,  0.0686,  0.0044,  ...,  0.0010, -0.0127,  0.0018],
        [-0.0098, -0.0288,  0.0567,  ..., -0.0038,  0.0007,  0.0159],
        ...,
        [ 0.0018, -0.0138, -0.0137,  ...,  0.0036,  0.0089, -0.0170],
        [-0.0133,  0.0085, -0.0131,  ..., -0.0013,  0.0339,  0.0198],
        [-0.0037,  0.0219,  0.0281,  ...,  0.0012,  0.0013, -0.0077]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.7344,  1.6670,  3.5332,  ...,  0.1826, -4.8125, -1.2549]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 09:17:19 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for After something is announcing, it has announced
After something is considering, it has considered
After something is relating, it has related
After something is expecting, it has expected
After something is creating, it has created
After something is improving, it has improved
After something is existing, it has existed
After something is telling, it has
2024-08-01 09:17:19 root INFO     total operator prediction time: 1385.193514585495 seconds
2024-08-01 09:17:19 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on verb_inf - Ved
2024-08-01 09:17:19 root INFO     building operator verb_inf - Ved
2024-08-01 09:17:19 root INFO     [order_1_approx] starting weight calculation for If the present form is involve, the past form is involved
If the present form is describe, the past form is described
If the present form is tell, the past form is told
If the present form is replace, the past form is replaced
If the present form is appear, the past form is appeared
If the present form is achieve, the past form is achieved
If the present form is relate, the past form is related
If the present form is receive, the past form is
2024-08-01 09:17:19 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-08-01 09:20:10 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0614,  0.0724, -0.0949,  ..., -0.2861, -0.2747, -0.0037],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.5586, -0.0762, -0.6665,  ..., -3.1367, -1.3301, -1.4561],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0050, -0.0151,  0.0119,  ..., -0.0257,  0.0333,  0.0164],
        [-0.0332,  0.0438,  0.0348,  ..., -0.0045, -0.0246, -0.0145],
        [ 0.0200, -0.0026,  0.0063,  ..., -0.0275, -0.0409, -0.0069],
        ...,
        [ 0.0122, -0.0258, -0.0111,  ...,  0.0199,  0.0311, -0.0012],
        [ 0.0201, -0.0116, -0.0330,  ..., -0.0548,  0.0582, -0.0036],
        [ 0.0335,  0.0014,  0.0186,  ...,  0.0067, -0.0158,  0.0224]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.8096, -0.3652, -0.5137,  ..., -2.8613, -0.9053, -1.3203]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 09:20:12 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If the present form is involve, the past form is involved
If the present form is describe, the past form is described
If the present form is tell, the past form is told
If the present form is replace, the past form is replaced
If the present form is appear, the past form is appeared
If the present form is achieve, the past form is achieved
If the present form is relate, the past form is related
If the present form is receive, the past form is
2024-08-01 09:20:12 root INFO     [order_1_approx] starting weight calculation for If the present form is achieve, the past form is achieved
If the present form is tell, the past form is told
If the present form is receive, the past form is received
If the present form is replace, the past form is replaced
If the present form is involve, the past form is involved
If the present form is relate, the past form is related
If the present form is appear, the past form is appeared
If the present form is describe, the past form is
2024-08-01 09:20:12 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
2024-08-01 09:23:04 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0808,  0.0975,  0.0447,  ..., -0.2515, -0.3003, -0.0263],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.9717,  0.4412,  4.4219,  ..., -0.9824, -0.7837, -2.4414],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 4.0779e-03, -1.7395e-02, -1.6632e-02,  ..., -2.2720e-02,
         -1.3947e-02, -6.3324e-03],
        [-1.0696e-02,  2.4948e-02, -2.1484e-02,  ..., -1.9684e-03,
         -3.7842e-03, -4.7073e-03],
        [ 3.4103e-03,  6.0196e-03,  1.7578e-02,  ..., -1.2962e-02,
         -8.7128e-03, -1.4481e-02],
        ...,
        [-2.1957e-02,  7.7629e-03, -5.5389e-03,  ...,  3.0624e-02,
          3.8605e-02, -2.8992e-02],
        [ 3.1555e-02,  8.1787e-03, -3.2410e-02,  ..., -2.4246e-02,
          8.6594e-03, -2.2888e-05],
        [ 4.1107e-02,  4.5929e-03,  9.0179e-03,  ..., -1.6144e-02,
         -2.4017e-02,  3.2440e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.6719,  0.7891,  4.1445,  ..., -0.8662, -0.6631, -2.5605]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 09:23:05 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If the present form is achieve, the past form is achieved
If the present form is tell, the past form is told
If the present form is receive, the past form is received
If the present form is replace, the past form is replaced
If the present form is involve, the past form is involved
If the present form is relate, the past form is related
If the present form is appear, the past form is appeared
If the present form is describe, the past form is
2024-08-01 09:23:06 root INFO     [order_1_approx] starting weight calculation for If the present form is involve, the past form is involved
If the present form is tell, the past form is told
If the present form is receive, the past form is received
If the present form is describe, the past form is described
If the present form is replace, the past form is replaced
If the present form is achieve, the past form is achieved
If the present form is relate, the past form is related
If the present form is appear, the past form is
2024-08-01 09:23:06 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.7
