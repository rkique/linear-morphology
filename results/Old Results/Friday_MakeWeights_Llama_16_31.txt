2024-07-28 17:33:14 root INFO     loading model + tokenizer
2024-07-28 17:33:41 root INFO     model + tokenizer loaded
2024-07-28 17:33:41 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on verb+ment_irreg
2024-07-28 17:33:41 root INFO     building operator verb+ment_irreg
2024-07-28 17:33:42 root INFO     [order_1_approx] starting weight calculation for To amend results in a amendment
To excite results in a excitement
To reimburse results in a reimbursement
To require results in a requirement
To appoint results in a appointment
To improve results in a improvement
To infringe results in a infringement
To displace results in a
2024-07-28 17:33:42 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-28 17:35:36 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.6553,  0.1748, -0.6406,  ..., -0.2634,  0.0381,  0.2891],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.6230, -3.7031,  1.0059,  ...,  2.8359, -1.3301, -0.1089],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.1064, -0.0134, -0.0005,  ..., -0.0037,  0.0024, -0.0149],
        [-0.0061,  0.0928,  0.0036,  ...,  0.0140,  0.0068,  0.0005],
        [ 0.0069, -0.0071,  0.0721,  ..., -0.0162,  0.0060, -0.0174],
        ...,
        [ 0.0026,  0.0211, -0.0008,  ...,  0.1003, -0.0041,  0.0058],
        [ 0.0030,  0.0205,  0.0028,  ..., -0.0021,  0.0946, -0.0103],
        [ 0.0212,  0.0052,  0.0032,  ...,  0.0016, -0.0226,  0.1017]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.3105, -3.3398,  0.9453,  ...,  2.6816, -1.4336, -0.3652]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 17:35:37 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To amend results in a amendment
To excite results in a excitement
To reimburse results in a reimbursement
To require results in a requirement
To appoint results in a appointment
To improve results in a improvement
To infringe results in a infringement
To displace results in a
2024-07-28 17:35:37 root INFO     [order_1_approx] starting weight calculation for To amend results in a amendment
To infringe results in a infringement
To displace results in a displacement
To appoint results in a appointment
To require results in a requirement
To improve results in a improvement
To excite results in a excitement
To reimburse results in a
2024-07-28 17:35:38 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-28 17:37:32 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.3228, -0.2441, -0.5776,  ..., -0.5576,  0.0562, -0.1256],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.1719, -4.4102, -0.5840,  ..., -1.4395, -2.4062, -1.1719],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 9.0210e-02, -6.1836e-03,  7.3929e-03,  ..., -5.5313e-03,
         -3.6736e-03,  5.8508e-04],
        [-1.7822e-02,  8.2581e-02, -3.2997e-04,  ...,  2.0203e-02,
          1.3741e-02,  9.5367e-03],
        [-7.4387e-05, -1.0147e-02,  7.0557e-02,  ..., -2.0081e-02,
         -1.0300e-04, -1.0201e-02],
        ...,
        [-3.2845e-03,  1.4153e-02, -5.3253e-03,  ...,  9.9548e-02,
         -1.2455e-03,  2.5978e-03],
        [ 6.0425e-03,  5.7068e-03,  1.5564e-03,  ...,  3.8128e-03,
          8.7463e-02, -1.8677e-02],
        [-6.5804e-04, -5.3940e-03, -1.3718e-02,  ..., -9.5367e-06,
         -1.5373e-02,  9.0515e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.1016, -4.0508, -0.4641,  ..., -1.0752, -2.2871, -1.0645]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 17:37:33 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To amend results in a amendment
To infringe results in a infringement
To displace results in a displacement
To appoint results in a appointment
To require results in a requirement
To improve results in a improvement
To excite results in a excitement
To reimburse results in a
2024-07-28 17:37:33 root INFO     [order_1_approx] starting weight calculation for To require results in a requirement
To displace results in a displacement
To appoint results in a appointment
To excite results in a excitement
To reimburse results in a reimbursement
To improve results in a improvement
To infringe results in a infringement
To amend results in a
2024-07-28 17:37:34 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-28 17:39:30 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2046, -0.1335, -0.8008,  ..., -1.1152, -0.4209,  0.5005],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.7783, -1.5234, -0.5688,  ...,  0.9287, -1.0234, -0.4131],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0803, -0.0064, -0.0026,  ..., -0.0112,  0.0030, -0.0029],
        [-0.0055,  0.0698,  0.0068,  ...,  0.0162, -0.0010,  0.0050],
        [-0.0082, -0.0118,  0.0623,  ..., -0.0027,  0.0020, -0.0128],
        ...,
        [ 0.0050,  0.0162,  0.0044,  ...,  0.0861, -0.0057,  0.0008],
        [ 0.0045,  0.0078,  0.0092,  ...,  0.0033,  0.0688, -0.0069],
        [ 0.0126, -0.0005,  0.0029,  ...,  0.0020, -0.0076,  0.0797]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.6611, -1.4756, -0.4292,  ...,  1.1924, -1.0566, -0.4521]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 17:39:31 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To require results in a requirement
To displace results in a displacement
To appoint results in a appointment
To excite results in a excitement
To reimburse results in a reimbursement
To improve results in a improvement
To infringe results in a infringement
To amend results in a
2024-07-28 17:39:31 root INFO     [order_1_approx] starting weight calculation for To excite results in a excitement
To amend results in a amendment
To require results in a requirement
To infringe results in a infringement
To reimburse results in a reimbursement
To displace results in a displacement
To appoint results in a appointment
To improve results in a
2024-07-28 17:39:31 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-28 17:41:28 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.5938, -0.4917, -0.0352,  ..., -0.7554, -0.1796,  0.2249],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.6797, -2.4355,  0.0786,  ...,  4.6016, -2.8281, -2.4121],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0768,  0.0010, -0.0002,  ..., -0.0091,  0.0058,  0.0080],
        [-0.0044,  0.0604,  0.0033,  ...,  0.0129,  0.0050, -0.0015],
        [-0.0013, -0.0136,  0.0606,  ..., -0.0019,  0.0056, -0.0089],
        ...,
        [ 0.0091,  0.0158, -0.0051,  ...,  0.0789, -0.0011,  0.0061],
        [ 0.0044,  0.0042,  0.0181,  ...,  0.0063,  0.0643, -0.0094],
        [-0.0010, -0.0005,  0.0016,  ..., -0.0124, -0.0160,  0.0597]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.5293, -2.2852,  0.2505,  ...,  4.6367, -2.9453, -2.4805]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 17:41:29 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To excite results in a excitement
To amend results in a amendment
To require results in a requirement
To infringe results in a infringement
To reimburse results in a reimbursement
To displace results in a displacement
To appoint results in a appointment
To improve results in a
2024-07-28 17:41:29 root INFO     [order_1_approx] starting weight calculation for To reimburse results in a reimbursement
To amend results in a amendment
To require results in a requirement
To improve results in a improvement
To excite results in a excitement
To infringe results in a infringement
To displace results in a displacement
To appoint results in a
2024-07-28 17:41:29 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-28 17:43:23 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0510,  0.2183, -0.0750,  ..., -0.0166, -0.5518, -0.5605],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.0547, -4.6406,  1.6074,  ...,  4.2188, -2.2949, -2.1348],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0736,  0.0012,  0.0054,  ..., -0.0073, -0.0067,  0.0024],
        [-0.0028,  0.0729,  0.0093,  ...,  0.0175,  0.0008, -0.0101],
        [ 0.0010, -0.0134,  0.0655,  ..., -0.0061,  0.0006, -0.0118],
        ...,
        [ 0.0166,  0.0216, -0.0150,  ...,  0.0887, -0.0040,  0.0044],
        [ 0.0005,  0.0147,  0.0173,  ..., -0.0059,  0.0631, -0.0154],
        [ 0.0150,  0.0103,  0.0008,  ..., -0.0068, -0.0124,  0.0771]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.1986, -4.1484,  1.4453,  ...,  4.1406, -2.3184, -2.1562]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 17:43:25 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To reimburse results in a reimbursement
To amend results in a amendment
To require results in a requirement
To improve results in a improvement
To excite results in a excitement
To infringe results in a infringement
To displace results in a displacement
To appoint results in a
2024-07-28 17:43:25 root INFO     [order_1_approx] starting weight calculation for To amend results in a amendment
To require results in a requirement
To improve results in a improvement
To infringe results in a infringement
To displace results in a displacement
To appoint results in a appointment
To reimburse results in a reimbursement
To excite results in a
2024-07-28 17:43:25 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-28 17:45:21 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.4648, -0.4570, -1.0127,  ..., -0.6660, -0.3975,  0.8457],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.4492, -2.6523, -0.1350,  ...,  2.9473, -0.7734, -1.7295],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0905, -0.0056,  0.0070,  ...,  0.0097,  0.0138, -0.0032],
        [-0.0034,  0.0948,  0.0043,  ...,  0.0128,  0.0072, -0.0071],
        [ 0.0039, -0.0101,  0.0762,  ..., -0.0005, -0.0101, -0.0074],
        ...,
        [ 0.0085,  0.0241, -0.0004,  ...,  0.0975, -0.0008, -0.0035],
        [ 0.0074,  0.0064,  0.0231,  ...,  0.0039,  0.0938, -0.0034],
        [ 0.0068,  0.0030, -0.0019,  ...,  0.0109, -0.0037,  0.0934]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.3984, -2.4551, -0.2161,  ...,  2.9980, -0.4199, -1.8574]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 17:45:22 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To amend results in a amendment
To require results in a requirement
To improve results in a improvement
To infringe results in a infringement
To displace results in a displacement
To appoint results in a appointment
To reimburse results in a reimbursement
To excite results in a
2024-07-28 17:45:22 root INFO     [order_1_approx] starting weight calculation for To amend results in a amendment
To displace results in a displacement
To excite results in a excitement
To appoint results in a appointment
To improve results in a improvement
To require results in a requirement
To reimburse results in a reimbursement
To infringe results in a
2024-07-28 17:45:22 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-28 17:47:19 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1196, -0.4790, -0.6479,  ..., -0.3806, -0.3833, -0.5010],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.0742, -5.8633,  1.1973,  ...,  1.9492, -1.4629, -0.2168],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 9.5703e-02,  2.1076e-03,  1.2352e-02,  ..., -6.9122e-03,
         -8.0109e-05,  3.9520e-03],
        [-1.6510e-02,  9.0332e-02,  6.5994e-04,  ...,  2.0355e-02,
          1.4740e-02, -4.2686e-03],
        [-7.9269e-03, -1.4595e-02,  6.9519e-02,  ..., -9.8495e-03,
         -1.5640e-03, -1.3824e-02],
        ...,
        [ 4.1504e-03,  1.9943e-02,  6.5422e-04,  ...,  1.0022e-01,
         -3.6812e-03,  4.6310e-03],
        [-5.0011e-03,  1.2451e-02,  1.9798e-03,  ...,  6.4049e-03,
          8.6914e-02, -1.3672e-02],
        [ 8.3542e-03,  1.1826e-02, -4.3869e-04,  ...,  6.6223e-03,
         -6.2561e-03,  9.9487e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.0840, -5.2422,  1.0332,  ...,  2.2715, -1.4902, -0.2568]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 17:47:20 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To amend results in a amendment
To displace results in a displacement
To excite results in a excitement
To appoint results in a appointment
To improve results in a improvement
To require results in a requirement
To reimburse results in a reimbursement
To infringe results in a
2024-07-28 17:47:20 root INFO     [order_1_approx] starting weight calculation for To displace results in a displacement
To excite results in a excitement
To amend results in a amendment
To infringe results in a infringement
To appoint results in a appointment
To improve results in a improvement
To reimburse results in a reimbursement
To require results in a
2024-07-28 17:47:20 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-28 17:49:16 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.6045,  0.0038, -0.6934,  ..., -0.9609, -0.9839, -0.7930],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.5264, -4.1367,  0.2061,  ...,  0.7827, -2.5742, -1.4238],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0776, -0.0048,  0.0084,  ..., -0.0048, -0.0050, -0.0008],
        [-0.0088,  0.0756,  0.0008,  ...,  0.0151,  0.0115,  0.0059],
        [-0.0018, -0.0138,  0.0637,  ..., -0.0272, -0.0104, -0.0068],
        ...,
        [ 0.0018,  0.0246, -0.0048,  ...,  0.1022,  0.0053,  0.0056],
        [-0.0089, -0.0083,  0.0016,  ...,  0.0036,  0.0646, -0.0205],
        [ 0.0026,  0.0070,  0.0136,  ..., -0.0027, -0.0039,  0.0919]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.5254, -4.0703,  0.4019,  ...,  1.1416, -2.5371, -1.0088]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 17:49:17 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To displace results in a displacement
To excite results in a excitement
To amend results in a amendment
To infringe results in a infringement
To appoint results in a appointment
To improve results in a improvement
To reimburse results in a reimbursement
To require results in a
2024-07-28 17:49:17 root INFO     total operator prediction time: 936.2547659873962 seconds
2024-07-28 17:49:17 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on noun+less_reg
2024-07-28 17:49:17 root INFO     building operator noun+less_reg
2024-07-28 17:49:18 root INFO     [order_1_approx] starting weight calculation for Something without leg is legless
Something without remorse is remorseless
Something without ego is egoless
Something without guile is guileless
Something without tooth is toothless
Something without money is moneyless
Something without breath is breathless
Something without sleeve is
2024-07-28 17:49:18 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-28 17:51:14 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3750, -0.7344,  0.5864,  ..., -0.6030, -0.7461, -0.1531],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.1660, -3.7246, -1.8994,  ..., -0.4570, -1.2871,  0.0879],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 6.0211e-02, -1.6785e-03,  2.3251e-03,  ...,  6.0654e-03,
          8.5449e-03,  1.2226e-03],
        [ 4.1695e-03,  3.6865e-02, -5.8060e-03,  ...,  6.2714e-03,
          1.0712e-02, -4.8523e-03],
        [ 1.4282e-02, -5.5504e-03,  4.7882e-02,  ..., -1.0574e-02,
          4.9133e-03, -3.2043e-03],
        ...,
        [-2.5616e-03,  6.2866e-03,  7.0572e-05,  ...,  5.9937e-02,
         -1.7357e-03, -7.3929e-03],
        [ 5.1765e-03,  1.5388e-02,  2.1420e-03,  ..., -6.7329e-03,
          5.5237e-02, -1.6754e-02],
        [-1.5535e-03, -2.2030e-03,  6.9542e-03,  ...,  6.5155e-03,
          2.8706e-03,  4.1870e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.2598, -3.7754, -1.7539,  ..., -0.7559, -1.3174,  0.1289]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 17:51:16 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Something without leg is legless
Something without remorse is remorseless
Something without ego is egoless
Something without guile is guileless
Something without tooth is toothless
Something without money is moneyless
Something without breath is breathless
Something without sleeve is
2024-07-28 17:51:16 root INFO     [order_1_approx] starting weight calculation for Something without guile is guileless
Something without tooth is toothless
Something without leg is legless
Something without money is moneyless
Something without breath is breathless
Something without sleeve is sleeveless
Something without ego is egoless
Something without remorse is
2024-07-28 17:51:16 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-28 17:53:13 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1853, -0.2330, -0.1958,  ..., -0.3296, -0.0539,  0.1975],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.7383, -3.9258, -1.3789,  ..., -3.5508, -0.8770, -1.2656],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0518, -0.0122,  0.0059,  ..., -0.0067, -0.0008,  0.0093],
        [-0.0004,  0.0470,  0.0049,  ...,  0.0094,  0.0053, -0.0105],
        [ 0.0033, -0.0083,  0.0466,  ..., -0.0030, -0.0015, -0.0022],
        ...,
        [ 0.0005,  0.0132, -0.0055,  ...,  0.0522, -0.0012, -0.0016],
        [ 0.0028,  0.0059,  0.0108,  ..., -0.0123,  0.0482, -0.0084],
        [-0.0014, -0.0041, -0.0027,  ..., -0.0020, -0.0105,  0.0512]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.5996, -3.7637, -1.2734,  ..., -3.6328, -1.1865, -1.3936]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 17:53:14 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Something without guile is guileless
Something without tooth is toothless
Something without leg is legless
Something without money is moneyless
Something without breath is breathless
Something without sleeve is sleeveless
Something without ego is egoless
Something without remorse is
2024-07-28 17:53:14 root INFO     [order_1_approx] starting weight calculation for Something without guile is guileless
Something without sleeve is sleeveless
Something without leg is legless
Something without tooth is toothless
Something without remorse is remorseless
Something without money is moneyless
Something without breath is breathless
Something without ego is
2024-07-28 17:53:14 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-28 17:55:10 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2455, -0.4426,  0.0166,  ..., -0.0784, -0.3574, -0.3308],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.1221, -2.7617,  0.2266,  ..., -3.0527, -1.3857, -3.6016],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 7.8613e-02, -2.2644e-02,  2.6321e-04,  ..., -1.1230e-02,
          9.7809e-03, -6.1874e-03],
        [ 1.7853e-03,  6.7810e-02,  2.6951e-03,  ...,  5.7945e-03,
         -1.0773e-02, -6.6566e-03],
        [-1.3142e-03, -1.3992e-02,  7.5806e-02,  ...,  5.8746e-04,
         -9.8419e-03, -5.9128e-05],
        ...,
        [-1.2421e-02,  3.3531e-03, -1.1940e-03,  ...,  6.8359e-02,
          4.8561e-03, -1.2222e-02],
        [ 2.1484e-02,  1.4145e-02,  2.4597e-02,  ..., -2.0935e-02,
          6.4392e-02,  3.5019e-03],
        [ 1.3456e-03, -2.1133e-03, -4.0741e-03,  ..., -2.7542e-03,
         -1.4084e-02,  6.2347e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.5410, -2.1914,  0.0796,  ..., -2.4102, -1.6523, -3.0078]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 17:55:11 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Something without guile is guileless
Something without sleeve is sleeveless
Something without leg is legless
Something without tooth is toothless
Something without remorse is remorseless
Something without money is moneyless
Something without breath is breathless
Something without ego is
2024-07-28 17:55:12 root INFO     [order_1_approx] starting weight calculation for Something without ego is egoless
Something without sleeve is sleeveless
Something without guile is guileless
Something without breath is breathless
Something without tooth is toothless
Something without remorse is remorseless
Something without leg is legless
Something without money is
2024-07-28 17:55:12 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-28 17:57:07 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3044, -0.4705, -0.0897,  ..., -1.1650, -0.3457,  0.1318],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.7754, -2.7852, -1.4902,  ..., -2.6719, -3.6055, -0.3408],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 5.3009e-02,  5.8823e-03, -2.3117e-03,  ..., -6.4011e-03,
          8.7128e-03,  1.5631e-03],
        [ 7.8869e-04,  3.5034e-02,  2.5711e-03,  ...,  1.4503e-02,
          3.8185e-03, -1.3599e-03],
        [ 2.0065e-03, -1.1551e-02,  4.8584e-02,  ..., -5.5389e-03,
         -8.8959e-03,  6.6414e-03],
        ...,
        [ 2.4433e-03,  1.4130e-02,  1.5259e-05,  ...,  5.4901e-02,
         -5.6534e-03,  5.3749e-03],
        [ 2.0778e-04,  7.2746e-03,  2.5406e-03,  ..., -6.5842e-03,
          4.6021e-02, -2.0233e-02],
        [ 2.2697e-03,  4.9858e-03,  2.2106e-03,  ...,  6.3133e-03,
         -1.0223e-03,  4.9133e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.4702, -2.3242, -1.7266,  ..., -2.6289, -3.4004, -0.2415]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 17:57:08 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Something without ego is egoless
Something without sleeve is sleeveless
Something without guile is guileless
Something without breath is breathless
Something without tooth is toothless
Something without remorse is remorseless
Something without leg is legless
Something without money is
2024-07-28 17:57:08 root INFO     [order_1_approx] starting weight calculation for Something without breath is breathless
Something without remorse is remorseless
Something without ego is egoless
Something without sleeve is sleeveless
Something without leg is legless
Something without money is moneyless
Something without guile is guileless
Something without tooth is
2024-07-28 17:57:08 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-28 17:59:04 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2563, -0.2075, -0.1562,  ..., -0.9907, -0.1759, -0.2554],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.4561, -3.1875, -2.6094,  ...,  0.4119, -5.6641, -0.9111],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0483, -0.0025,  0.0100,  ..., -0.0106,  0.0027,  0.0076],
        [ 0.0075,  0.0371, -0.0069,  ...,  0.0219,  0.0122, -0.0070],
        [ 0.0178,  0.0015,  0.0379,  ..., -0.0122,  0.0035,  0.0042],
        ...,
        [-0.0038,  0.0145, -0.0076,  ...,  0.0623,  0.0061, -0.0097],
        [ 0.0046,  0.0111,  0.0052,  ..., -0.0112,  0.0531, -0.0032],
        [-0.0049, -0.0027,  0.0044,  ...,  0.0045, -0.0018,  0.0342]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.2988, -2.5508, -2.7695,  ...,  0.7109, -5.6250, -0.8179]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 17:59:05 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Something without breath is breathless
Something without remorse is remorseless
Something without ego is egoless
Something without sleeve is sleeveless
Something without leg is legless
Something without money is moneyless
Something without guile is guileless
Something without tooth is
2024-07-28 17:59:06 root INFO     [order_1_approx] starting weight calculation for Something without tooth is toothless
Something without leg is legless
Something without guile is guileless
Something without remorse is remorseless
Something without ego is egoless
Something without sleeve is sleeveless
Something without money is moneyless
Something without breath is
2024-07-28 17:59:06 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-28 18:01:02 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4431, -0.6758, -0.1636,  ..., -0.7920,  0.0438, -0.0391],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.0547, -6.0391,  0.4216,  ..., -2.4570, -2.7168, -0.9941],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 5.1025e-02, -2.4452e-03,  2.7809e-03,  ...,  1.4896e-03,
          2.0409e-03,  9.4452e-03],
        [ 2.9564e-03,  5.1147e-02,  7.0572e-05,  ...,  2.0771e-03,
          3.9673e-03,  3.2768e-03],
        [ 1.2283e-02, -4.0550e-03,  4.4281e-02,  ..., -1.3588e-02,
         -3.6583e-03,  3.3302e-03],
        ...,
        [ 2.5463e-03,  2.3254e-02, -5.5466e-03,  ...,  3.8086e-02,
         -1.9474e-03, -2.1988e-02],
        [ 7.8506e-03,  8.2321e-03,  1.9264e-03,  ..., -1.4786e-02,
          3.0121e-02, -8.2855e-03],
        [ 1.4362e-03,  1.0918e-02,  3.0880e-03,  ..., -1.7214e-03,
         -6.1874e-03,  3.6743e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.7500e+00, -5.4766e+00,  3.1738e-03,  ..., -2.4766e+00,
         -3.2832e+00, -1.1826e+00]], device='cuda:1', dtype=torch.float16,
       grad_fn=<SubBackward0>) 

                    
2024-07-28 18:01:03 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Something without tooth is toothless
Something without leg is legless
Something without guile is guileless
Something without remorse is remorseless
Something without ego is egoless
Something without sleeve is sleeveless
Something without money is moneyless
Something without breath is
2024-07-28 18:01:03 root INFO     [order_1_approx] starting weight calculation for Something without remorse is remorseless
Something without leg is legless
Something without sleeve is sleeveless
Something without breath is breathless
Something without money is moneyless
Something without ego is egoless
Something without tooth is toothless
Something without guile is
2024-07-28 18:01:03 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-28 18:03:00 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1119,  0.0598, -0.0083,  ..., -0.1134, -1.1006, -0.2861],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.5195, -2.9844, -0.2671,  ...,  1.1865, -2.3809, -0.2441],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0702, -0.0042,  0.0132,  ..., -0.0078,  0.0211,  0.0076],
        [ 0.0100,  0.0565,  0.0092,  ...,  0.0088,  0.0120,  0.0130],
        [ 0.0008, -0.0187,  0.0639,  ..., -0.0085, -0.0093, -0.0143],
        ...,
        [-0.0013,  0.0147, -0.0028,  ...,  0.0820,  0.0008, -0.0026],
        [ 0.0091,  0.0061,  0.0041,  ..., -0.0127,  0.0693, -0.0197],
        [ 0.0163, -0.0098,  0.0054,  ...,  0.0025, -0.0013,  0.0632]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.5791, -2.7422, -0.3403,  ...,  1.2627, -2.7031, -0.4531]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 18:03:01 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Something without remorse is remorseless
Something without leg is legless
Something without sleeve is sleeveless
Something without breath is breathless
Something without money is moneyless
Something without ego is egoless
Something without tooth is toothless
Something without guile is
2024-07-28 18:03:01 root INFO     [order_1_approx] starting weight calculation for Something without breath is breathless
Something without ego is egoless
Something without tooth is toothless
Something without sleeve is sleeveless
Something without guile is guileless
Something without remorse is remorseless
Something without money is moneyless
Something without leg is
2024-07-28 18:03:02 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-28 18:04:58 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 1.0410, -0.1456, -0.1143,  ..., -0.7793, -0.0088, -0.2223],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.0488, -4.5391, -0.6641,  ...,  0.4287, -0.9209, -2.1992],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0481, -0.0037,  0.0007,  ...,  0.0032,  0.0001, -0.0006],
        [ 0.0056,  0.0126, -0.0034,  ...,  0.0153,  0.0068, -0.0054],
        [ 0.0192,  0.0022,  0.0347,  ..., -0.0121, -0.0078, -0.0020],
        ...,
        [-0.0071,  0.0022, -0.0008,  ...,  0.0440,  0.0060, -0.0093],
        [-0.0141,  0.0170, -0.0005,  ..., -0.0083,  0.0342, -0.0167],
        [-0.0018, -0.0050,  0.0032,  ..., -0.0029, -0.0125,  0.0269]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.0991, -3.3477, -1.0264,  ...,  1.3877, -1.4473, -1.9160]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 18:04:59 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Something without breath is breathless
Something without ego is egoless
Something without tooth is toothless
Something without sleeve is sleeveless
Something without guile is guileless
Something without remorse is remorseless
Something without money is moneyless
Something without leg is
2024-07-28 18:04:59 root INFO     total operator prediction time: 941.9231939315796 seconds
2024-07-28 18:04:59 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on adj+ness_reg
2024-07-28 18:04:59 root INFO     building operator adj+ness_reg
2024-07-28 18:05:00 root INFO     [order_1_approx] starting weight calculation for The state of being hidden is hiddenness
The state of being reasonable is reasonableness
The state of being sacred is sacredness
The state of being effective is effectiveness
The state of being massive is massiveness
The state of being marked is markedness
The state of being broken is brokenness
The state of being strange is
2024-07-28 18:05:00 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-28 18:06:57 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1106, -0.2432,  0.2405,  ..., -1.0508, -0.0035, -0.1392],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.9932, -2.7422, -2.4902,  ..., -2.8750, -3.6875, -1.8604],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0748,  0.0193,  0.0008,  ..., -0.0048, -0.0063,  0.0066],
        [-0.0044,  0.0487,  0.0090,  ...,  0.0214,  0.0161, -0.0013],
        [ 0.0160, -0.0144,  0.0515,  ..., -0.0054, -0.0050, -0.0051],
        ...,
        [ 0.0087,  0.0219, -0.0021,  ...,  0.0602,  0.0004, -0.0076],
        [ 0.0061, -0.0023,  0.0099,  ..., -0.0090,  0.0596, -0.0160],
        [ 0.0048,  0.0049, -0.0068,  ...,  0.0115, -0.0206,  0.0609]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.9932, -2.3867, -2.7617,  ..., -2.8379, -3.7422, -1.8359]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 18:06:58 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The state of being hidden is hiddenness
The state of being reasonable is reasonableness
The state of being sacred is sacredness
The state of being effective is effectiveness
The state of being massive is massiveness
The state of being marked is markedness
The state of being broken is brokenness
The state of being strange is
2024-07-28 18:06:59 root INFO     [order_1_approx] starting weight calculation for The state of being massive is massiveness
The state of being marked is markedness
The state of being reasonable is reasonableness
The state of being sacred is sacredness
The state of being strange is strangeness
The state of being broken is brokenness
The state of being effective is effectiveness
The state of being hidden is
2024-07-28 18:06:59 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-28 18:08:56 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2651, -0.5156,  0.4885,  ..., -0.7637, -0.1912, -0.0435],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-2.1953, -0.5078, -0.1084,  ..., -2.7812, -2.8125,  0.1768],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0739,  0.0002,  0.0069,  ...,  0.0009, -0.0044,  0.0064],
        [-0.0093,  0.0539,  0.0053,  ...,  0.0100,  0.0043, -0.0073],
        [ 0.0059, -0.0166,  0.0716,  ...,  0.0001, -0.0034,  0.0033],
        ...,
        [ 0.0035,  0.0192, -0.0054,  ...,  0.0640, -0.0042,  0.0108],
        [ 0.0164,  0.0072,  0.0084,  ..., -0.0070,  0.0587, -0.0016],
        [-0.0039,  0.0049, -0.0179,  ..., -0.0030, -0.0118,  0.0743]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.9590, -0.5244, -0.4204,  ..., -2.8164, -2.8730, -0.0236]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 18:08:57 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The state of being massive is massiveness
The state of being marked is markedness
The state of being reasonable is reasonableness
The state of being sacred is sacredness
The state of being strange is strangeness
The state of being broken is brokenness
The state of being effective is effectiveness
The state of being hidden is
2024-07-28 18:08:57 root INFO     [order_1_approx] starting weight calculation for The state of being sacred is sacredness
The state of being effective is effectiveness
The state of being strange is strangeness
The state of being broken is brokenness
The state of being reasonable is reasonableness
The state of being massive is massiveness
The state of being hidden is hiddenness
The state of being marked is
2024-07-28 18:08:58 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-28 18:10:53 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0158,  0.4478, -0.7031,  ...,  0.4841, -0.4700, -0.0186],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.3418, -3.1758, -2.4512,  ..., -3.2266, -0.7866, -1.1748],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.1072,  0.0129,  0.0080,  ..., -0.0073, -0.0022,  0.0224],
        [-0.0011,  0.0837, -0.0061,  ...,  0.0281,  0.0367, -0.0260],
        [ 0.0080, -0.0310,  0.0781,  ..., -0.0130,  0.0078,  0.0029],
        ...,
        [ 0.0204,  0.0049,  0.0016,  ...,  0.1135, -0.0100, -0.0008],
        [ 0.0031, -0.0013,  0.0111,  ..., -0.0204,  0.0983, -0.0066],
        [-0.0015,  0.0032, -0.0168,  ...,  0.0236, -0.0150,  0.0872]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.1161, -2.6426, -2.3379,  ..., -2.9414, -0.8057, -0.5073]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 18:10:55 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The state of being sacred is sacredness
The state of being effective is effectiveness
The state of being strange is strangeness
The state of being broken is brokenness
The state of being reasonable is reasonableness
The state of being massive is massiveness
The state of being hidden is hiddenness
The state of being marked is
2024-07-28 18:10:55 root INFO     [order_1_approx] starting weight calculation for The state of being sacred is sacredness
The state of being broken is brokenness
The state of being marked is markedness
The state of being hidden is hiddenness
The state of being strange is strangeness
The state of being reasonable is reasonableness
The state of being effective is effectiveness
The state of being massive is
2024-07-28 18:10:55 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-28 18:12:53 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.8462,  0.0030, -0.0762,  ..., -0.6562, -0.7925, -0.3530],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.5391, -4.0625, -2.8496,  ..., -4.3672, -4.3125, -3.8711],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0765, -0.0054,  0.0053,  ...,  0.0064,  0.0070, -0.0013],
        [-0.0055,  0.0586,  0.0044,  ..., -0.0003,  0.0048, -0.0009],
        [ 0.0107, -0.0072,  0.0646,  ..., -0.0041,  0.0069, -0.0026],
        ...,
        [ 0.0054,  0.0101,  0.0213,  ...,  0.0637, -0.0076,  0.0071],
        [ 0.0071, -0.0004, -0.0005,  ..., -0.0016,  0.0702,  0.0054],
        [ 0.0077,  0.0182, -0.0082,  ..., -0.0057, -0.0252,  0.0624]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.1309, -3.3535, -2.8691,  ..., -4.0586, -4.4688, -3.4297]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 18:12:54 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The state of being sacred is sacredness
The state of being broken is brokenness
The state of being marked is markedness
The state of being hidden is hiddenness
The state of being strange is strangeness
The state of being reasonable is reasonableness
The state of being effective is effectiveness
The state of being massive is
2024-07-28 18:12:54 root INFO     [order_1_approx] starting weight calculation for The state of being hidden is hiddenness
The state of being reasonable is reasonableness
The state of being effective is effectiveness
The state of being strange is strangeness
The state of being broken is brokenness
The state of being marked is markedness
The state of being massive is massiveness
The state of being sacred is
2024-07-28 18:12:54 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-28 18:14:50 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.6807, -0.1987, -0.1404,  ..., -0.6821, -1.7197,  0.3855],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.2520, -3.9570, -0.4199,  ..., -5.9141, -1.9121, -1.3223],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0782, -0.0135,  0.0236,  ...,  0.0058,  0.0107, -0.0125],
        [ 0.0087,  0.0828,  0.0098,  ..., -0.0008, -0.0085,  0.0239],
        [ 0.0035, -0.0170,  0.0661,  ...,  0.0089, -0.0043, -0.0097],
        ...,
        [ 0.0108,  0.0020,  0.0022,  ...,  0.0625, -0.0204,  0.0196],
        [ 0.0040, -0.0165,  0.0141,  ..., -0.0213,  0.0945, -0.0233],
        [ 0.0030,  0.0197, -0.0212,  ...,  0.0019, -0.0307,  0.1003]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.8418, -3.7441, -0.4829,  ..., -6.1875, -1.5654, -2.0859]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 18:14:51 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The state of being hidden is hiddenness
The state of being reasonable is reasonableness
The state of being effective is effectiveness
The state of being strange is strangeness
The state of being broken is brokenness
The state of being marked is markedness
The state of being massive is massiveness
The state of being sacred is
2024-07-28 18:14:52 root INFO     [order_1_approx] starting weight calculation for The state of being effective is effectiveness
The state of being marked is markedness
The state of being massive is massiveness
The state of being sacred is sacredness
The state of being hidden is hiddenness
The state of being strange is strangeness
The state of being broken is brokenness
The state of being reasonable is
2024-07-28 18:14:52 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-28 18:16:47 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3582, -0.7461, -0.2452,  ..., -1.0312, -0.8682, -0.7188],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.0537, -1.6699, -1.1055,  ..., -3.4023, -6.6328, -2.3496],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0848, -0.0022,  0.0036,  ..., -0.0071, -0.0150,  0.0143],
        [-0.0142,  0.0764,  0.0062,  ...,  0.0144,  0.0162, -0.0024],
        [ 0.0171, -0.0186,  0.0740,  ..., -0.0029, -0.0009, -0.0005],
        ...,
        [ 0.0110,  0.0048,  0.0220,  ...,  0.0934, -0.0005,  0.0136],
        [ 0.0193,  0.0085,  0.0196,  ...,  0.0037,  0.0743, -0.0117],
        [-0.0042,  0.0069,  0.0012,  ..., -0.0016, -0.0184,  0.0834]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.7334, -1.8643, -1.2832,  ..., -3.0625, -6.5547, -2.3066]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 18:16:48 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The state of being effective is effectiveness
The state of being marked is markedness
The state of being massive is massiveness
The state of being sacred is sacredness
The state of being hidden is hiddenness
The state of being strange is strangeness
The state of being broken is brokenness
The state of being reasonable is
2024-07-28 18:16:48 root INFO     [order_1_approx] starting weight calculation for The state of being massive is massiveness
The state of being reasonable is reasonableness
The state of being marked is markedness
The state of being strange is strangeness
The state of being hidden is hiddenness
The state of being sacred is sacredness
The state of being broken is brokenness
The state of being effective is
2024-07-28 18:16:48 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-28 18:18:44 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2430, -0.6367,  0.7432,  ..., -0.5835, -0.6743, -0.7466],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.7109, -2.8359, -1.1670,  ..., -1.1709, -2.8867, -4.8047],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0860, -0.0015,  0.0033,  ..., -0.0039, -0.0033,  0.0172],
        [-0.0059,  0.0793,  0.0009,  ...,  0.0042,  0.0184, -0.0016],
        [ 0.0136, -0.0106,  0.0797,  ...,  0.0092,  0.0008,  0.0064],
        ...,
        [ 0.0045,  0.0142,  0.0044,  ...,  0.0790,  0.0027,  0.0051],
        [ 0.0234,  0.0224,  0.0077,  ...,  0.0070,  0.0748, -0.0015],
        [ 0.0101, -0.0002, -0.0158,  ..., -0.0029, -0.0201,  0.0740]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.9150, -2.5352, -1.2930,  ..., -0.8408, -3.3477, -4.1289]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 18:18:45 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The state of being massive is massiveness
The state of being reasonable is reasonableness
The state of being marked is markedness
The state of being strange is strangeness
The state of being hidden is hiddenness
The state of being sacred is sacredness
The state of being broken is brokenness
The state of being effective is
2024-07-28 18:18:46 root INFO     [order_1_approx] starting weight calculation for The state of being sacred is sacredness
The state of being reasonable is reasonableness
The state of being marked is markedness
The state of being hidden is hiddenness
The state of being strange is strangeness
The state of being massive is massiveness
The state of being effective is effectiveness
The state of being broken is
2024-07-28 18:18:46 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-28 18:20:41 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0255, -0.3408, -0.0117,  ..., -0.1863, -0.4192, -0.3672],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.1299, -3.8477, -1.0332,  ..., -1.8535,  0.9023, -0.3394],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 1.0724e-01,  3.5858e-03,  1.0376e-02,  ..., -3.6125e-03,
          5.8823e-03,  7.8583e-03],
        [ 3.5286e-05,  6.4026e-02,  1.6861e-02,  ...,  1.9043e-02,
         -2.6512e-04, -1.9302e-02],
        [ 2.0096e-02, -3.1494e-02,  9.3628e-02,  ..., -1.1864e-02,
          3.5744e-03, -6.8626e-03],
        ...,
        [ 5.8937e-03,  1.4877e-02,  1.7258e-02,  ...,  8.7708e-02,
         -7.0419e-03,  5.4398e-03],
        [-4.0016e-03,  7.4921e-03, -6.6566e-03,  ..., -9.7275e-03,
          8.7646e-02, -2.3537e-03],
        [-7.2212e-03,  1.3702e-02,  3.5286e-04,  ..., -3.2463e-03,
         -2.1042e-02,  8.6609e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.5205, -3.1914, -0.8271,  ..., -1.6914, -0.0205,  0.0881]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 18:20:42 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The state of being sacred is sacredness
The state of being reasonable is reasonableness
The state of being marked is markedness
The state of being hidden is hiddenness
The state of being strange is strangeness
The state of being massive is massiveness
The state of being effective is effectiveness
The state of being broken is
2024-07-28 18:20:42 root INFO     total operator prediction time: 942.8560745716095 seconds
2024-07-28 18:20:42 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on re+verb_reg
2024-07-28 18:20:42 root INFO     building operator re+verb_reg
2024-07-28 18:20:42 root INFO     [order_1_approx] starting weight calculation for To learn again is to relearn
To submit again is to resubmit
To upload again is to reupload
To marry again is to remarry
To consider again is to reconsider
To interpret again is to reinterpret
To tell again is to retell
To negotiate again is to
2024-07-28 18:20:42 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-28 18:22:39 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2444,  0.1249, -0.8706,  ..., -0.4680, -0.7891,  0.1792],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.6064, -2.1484,  1.6885,  ..., -1.7305, -3.7773, -3.2109],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 3.2043e-02,  3.3646e-03,  9.3079e-03,  ..., -3.2234e-03,
          3.0422e-04,  4.9820e-03],
        [-3.8891e-03,  1.7822e-02, -1.0996e-03,  ...,  9.8419e-03,
          2.6855e-03, -1.2941e-03],
        [-1.4944e-03, -1.5011e-03,  2.2430e-02,  ..., -6.2904e-03,
          2.3422e-03, -3.1700e-03],
        ...,
        [ 8.5602e-03, -5.6553e-04, -1.9302e-03,  ...,  3.4515e-02,
         -9.7275e-05,  1.6146e-03],
        [ 5.0964e-03,  7.4921e-03,  4.3488e-03,  ..., -2.8458e-03,
          2.4124e-02, -3.3951e-04],
        [-4.0131e-03, -2.6550e-03, -2.2125e-03,  ..., -5.9319e-03,
         -1.2436e-02,  2.7634e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.5601, -2.1543,  1.7168,  ..., -1.5742, -3.8438, -3.0957]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 18:22:40 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To learn again is to relearn
To submit again is to resubmit
To upload again is to reupload
To marry again is to remarry
To consider again is to reconsider
To interpret again is to reinterpret
To tell again is to retell
To negotiate again is to
2024-07-28 18:22:40 root INFO     [order_1_approx] starting weight calculation for To interpret again is to reinterpret
To upload again is to reupload
To marry again is to remarry
To learn again is to relearn
To negotiate again is to renegotiate
To tell again is to retell
To consider again is to reconsider
To submit again is to
2024-07-28 18:22:40 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-28 18:24:37 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.3003, -0.5176,  0.0190,  ..., -0.4517, -0.3127,  0.7041],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.1064, -3.0508, -0.3792,  ...,  0.1802, -3.4102, -3.1133],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 8.4167e-02, -9.4986e-03,  1.5869e-02,  ..., -1.6434e-02,
          9.7227e-04,  1.5900e-02],
        [ 6.8436e-03,  5.5298e-02,  5.8413e-05,  ...,  7.9193e-03,
         -7.2937e-03,  5.0354e-03],
        [-7.8049e-03, -1.0849e-02,  6.3782e-02,  ..., -9.9564e-04,
          8.4000e-03, -1.1620e-02],
        ...,
        [ 1.7071e-03, -4.5280e-03,  2.1915e-03,  ...,  9.0698e-02,
          7.0229e-03,  5.9013e-03],
        [ 1.3008e-02,  2.4509e-03,  1.5015e-02,  ...,  2.7199e-03,
          5.9143e-02, -4.6082e-03],
        [ 9.1267e-04,  6.3324e-03, -5.0812e-03,  ..., -1.4008e-02,
         -4.6844e-03,  6.9153e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.1221, -2.8086, -0.3132,  ...,  0.3550, -3.7461, -2.9805]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 18:24:38 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To interpret again is to reinterpret
To upload again is to reupload
To marry again is to remarry
To learn again is to relearn
To negotiate again is to renegotiate
To tell again is to retell
To consider again is to reconsider
To submit again is to
2024-07-28 18:24:38 root INFO     [order_1_approx] starting weight calculation for To consider again is to reconsider
To interpret again is to reinterpret
To upload again is to reupload
To negotiate again is to renegotiate
To marry again is to remarry
To submit again is to resubmit
To tell again is to retell
To learn again is to
2024-07-28 18:24:38 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-28 18:26:33 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.3447, -0.5225,  0.5542,  ..., -0.2517, -0.5796,  0.4968],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.5859, -3.3750,  0.8247,  ...,  3.0996, -2.8281, -4.5391],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 3.8635e-02, -2.9812e-03,  5.7220e-05,  ...,  1.2312e-03,
          2.0561e-03,  6.2180e-03],
        [-6.1321e-04,  3.4485e-02, -3.6793e-03,  ...,  7.6103e-03,
         -8.3923e-05,  4.5624e-03],
        [-2.1210e-03, -7.5226e-03,  3.5645e-02,  ..., -2.7485e-03,
         -2.2125e-03, -3.3531e-03],
        ...,
        [ 1.1612e-02,  4.7531e-03, -2.3403e-03,  ...,  4.4189e-02,
          2.1210e-03, -2.0733e-03],
        [ 6.6299e-03,  2.0599e-03,  1.7061e-03,  ...,  6.3286e-03,
          2.1576e-02, -2.3975e-03],
        [-1.2093e-02,  9.8267e-03,  2.0676e-03,  ..., -5.4626e-03,
          4.3411e-03,  4.0955e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.6509, -3.3008,  0.7944,  ...,  3.2754, -3.1582, -4.2539]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 18:26:34 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To consider again is to reconsider
To interpret again is to reinterpret
To upload again is to reupload
To negotiate again is to renegotiate
To marry again is to remarry
To submit again is to resubmit
To tell again is to retell
To learn again is to
2024-07-28 18:26:34 root INFO     [order_1_approx] starting weight calculation for To negotiate again is to renegotiate
To submit again is to resubmit
To tell again is to retell
To marry again is to remarry
To interpret again is to reinterpret
To learn again is to relearn
To consider again is to reconsider
To upload again is to
2024-07-28 18:26:34 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-28 18:28:31 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2654, -1.1084, -0.0148,  ...,  0.1437, -0.3738,  0.6621],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.3508, -3.5332,  1.2988,  ...,  1.6406, -3.3027, -3.2207],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0839,  0.0063,  0.0117,  ..., -0.0052,  0.0135,  0.0078],
        [-0.0114,  0.0603, -0.0011,  ...,  0.0198,  0.0070,  0.0040],
        [-0.0060, -0.0058,  0.0717,  ..., -0.0014,  0.0014, -0.0121],
        ...,
        [ 0.0218, -0.0017, -0.0117,  ...,  0.0736, -0.0060, -0.0111],
        [ 0.0042, -0.0018,  0.0047,  ..., -0.0050,  0.0591, -0.0018],
        [ 0.0012,  0.0064, -0.0058,  ..., -0.0065, -0.0044,  0.0704]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.0361, -3.1738,  1.7607,  ...,  1.8398, -3.5293, -3.0723]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 18:28:32 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To negotiate again is to renegotiate
To submit again is to resubmit
To tell again is to retell
To marry again is to remarry
To interpret again is to reinterpret
To learn again is to relearn
To consider again is to reconsider
To upload again is to
2024-07-28 18:28:32 root INFO     [order_1_approx] starting weight calculation for To interpret again is to reinterpret
To marry again is to remarry
To learn again is to relearn
To upload again is to reupload
To submit again is to resubmit
To negotiate again is to renegotiate
To consider again is to reconsider
To tell again is to
2024-07-28 18:28:33 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-28 18:30:29 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1990, -0.5991,  0.4692,  ..., -0.3594,  0.1326,  0.2080],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.8311, -3.3340,  1.1230,  ...,  0.7104, -4.0391, -2.9902],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 6.2134e-02, -1.4591e-03,  9.7504e-03,  ..., -3.9215e-03,
         -1.5472e-02,  1.3077e-02],
        [-6.4850e-03,  2.9572e-02,  7.1793e-03,  ...,  1.8784e-02,
          1.6479e-02,  6.8665e-05],
        [ 8.7280e-03, -5.3329e-03,  5.0293e-02,  ..., -1.1513e-02,
          8.5831e-04,  3.7308e-03],
        ...,
        [ 1.5121e-02,  1.1120e-03, -5.6763e-03,  ...,  5.9570e-02,
          3.3340e-03,  6.8665e-03],
        [ 7.2632e-03, -8.9569e-03,  1.2756e-02,  ...,  4.1771e-03,
          4.5715e-02,  1.2150e-03],
        [-1.0384e-02, -2.2087e-03, -9.4986e-03,  ..., -7.8430e-03,
          7.0801e-03,  5.0415e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.5845, -3.3203,  1.1523,  ...,  0.7588, -3.9414, -2.8789]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 18:30:31 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To interpret again is to reinterpret
To marry again is to remarry
To learn again is to relearn
To upload again is to reupload
To submit again is to resubmit
To negotiate again is to renegotiate
To consider again is to reconsider
To tell again is to
2024-07-28 18:30:31 root INFO     [order_1_approx] starting weight calculation for To marry again is to remarry
To submit again is to resubmit
To tell again is to retell
To negotiate again is to renegotiate
To interpret again is to reinterpret
To upload again is to reupload
To learn again is to relearn
To consider again is to
2024-07-28 18:30:31 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-28 18:32:26 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2898, -0.3408,  0.2458,  ...,  0.2896, -0.1907,  0.0878],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.0771, -4.5820,  1.9541,  ...,  0.3799, -2.9805, -3.4414],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0715, -0.0019,  0.0080,  ..., -0.0095, -0.0079,  0.0225],
        [-0.0008,  0.0394,  0.0034,  ...,  0.0168, -0.0015,  0.0055],
        [ 0.0014, -0.0042,  0.0625,  ..., -0.0139,  0.0034, -0.0095],
        ...,
        [ 0.0112, -0.0021,  0.0191,  ...,  0.0846,  0.0071,  0.0013],
        [ 0.0108,  0.0183,  0.0013,  ..., -0.0188,  0.0500, -0.0121],
        [-0.0016, -0.0011,  0.0046,  ..., -0.0116, -0.0104,  0.0578]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.3704, -4.8164,  1.8818,  ...,  0.9600, -3.2227, -3.2109]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 18:32:27 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To marry again is to remarry
To submit again is to resubmit
To tell again is to retell
To negotiate again is to renegotiate
To interpret again is to reinterpret
To upload again is to reupload
To learn again is to relearn
To consider again is to
2024-07-28 18:32:27 root INFO     [order_1_approx] starting weight calculation for To learn again is to relearn
To tell again is to retell
To negotiate again is to renegotiate
To submit again is to resubmit
To upload again is to reupload
To consider again is to reconsider
To marry again is to remarry
To interpret again is to
2024-07-28 18:32:27 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-28 18:34:20 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2463, -0.7144,  0.9531,  ...,  0.2269, -0.2158,  1.0957],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.6270, -2.4238,  1.0898,  ..., -0.0566, -2.3164, -4.3867],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0681,  0.0042,  0.0192,  ..., -0.0084,  0.0015,  0.0098],
        [ 0.0008,  0.0468,  0.0043,  ...,  0.0100, -0.0019, -0.0072],
        [ 0.0112,  0.0007,  0.0519,  ..., -0.0006,  0.0044, -0.0085],
        ...,
        [ 0.0205, -0.0016,  0.0022,  ...,  0.0637, -0.0037, -0.0008],
        [ 0.0002, -0.0080,  0.0134,  ..., -0.0112,  0.0463, -0.0068],
        [-0.0065,  0.0144,  0.0018,  ..., -0.0100, -0.0151,  0.0568]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.6636, -2.3184,  1.3828,  ..., -0.2235, -2.3789, -4.3086]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 18:34:22 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To learn again is to relearn
To tell again is to retell
To negotiate again is to renegotiate
To submit again is to resubmit
To upload again is to reupload
To consider again is to reconsider
To marry again is to remarry
To interpret again is to
2024-07-28 18:34:22 root INFO     [order_1_approx] starting weight calculation for To consider again is to reconsider
To upload again is to reupload
To negotiate again is to renegotiate
To tell again is to retell
To learn again is to relearn
To submit again is to resubmit
To interpret again is to reinterpret
To marry again is to
2024-07-28 18:34:22 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-28 18:36:18 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0133, -0.5303, -0.0453,  ...,  0.1000, -0.7349,  0.8984],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.6333, -3.3965,  2.9180,  ..., -1.9180, -4.8672, -3.6758],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 5.9784e-02,  2.1210e-03,  6.1951e-03,  ...,  2.7370e-03,
          4.2343e-03,  1.4481e-02],
        [ 4.1885e-03,  3.9337e-02, -5.1498e-03,  ...,  1.0948e-02,
          8.0109e-05, -7.2784e-03],
        [ 5.3024e-03, -4.5471e-03,  4.4708e-02,  ..., -8.0643e-03,
         -7.3509e-03, -1.0895e-02],
        ...,
        [ 2.0523e-03,  1.2924e-02,  5.0697e-03,  ...,  5.8838e-02,
         -1.2718e-02,  2.6321e-04],
        [ 4.1771e-03,  1.4633e-02,  9.5062e-03,  ..., -1.6623e-03,
          4.0771e-02, -4.0169e-03],
        [ 3.7994e-03, -3.8643e-03, -6.8665e-03,  ..., -6.4049e-03,
         -8.1940e-03,  4.7455e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.5259, -3.4531,  2.8418,  ..., -1.8555, -4.8164, -3.6406]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 18:36:19 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To consider again is to reconsider
To upload again is to reupload
To negotiate again is to renegotiate
To tell again is to retell
To learn again is to relearn
To submit again is to resubmit
To interpret again is to reinterpret
To marry again is to
2024-07-28 18:36:19 root INFO     total operator prediction time: 936.542090177536 seconds
2024-07-28 18:36:19 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on un+adj_reg
2024-07-28 18:36:19 root INFO     building operator un+adj_reg
2024-07-28 18:36:19 root INFO     [order_1_approx] starting weight calculation for The opposite of wanted is unwanted
The opposite of interrupted is uninterrupted
The opposite of conscious is unconscious
The opposite of predictable is unpredictable
The opposite of reasonable is unreasonable
The opposite of suitable is unsuitable
The opposite of paid is unpaid
The opposite of realistic is
2024-07-28 18:36:19 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-28 18:38:16 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0823, -0.0394, -0.6079,  ..., -1.0645, -0.4998, -0.4258],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.1562, -1.1328, -0.7412,  ..., -3.2383, -1.3984, -1.8467],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0637, -0.0098,  0.0119,  ...,  0.0070,  0.0052, -0.0014],
        [-0.0050,  0.0509, -0.0181,  ...,  0.0054,  0.0128, -0.0067],
        [-0.0111, -0.0168,  0.0559,  ..., -0.0002, -0.0026, -0.0022],
        ...,
        [-0.0014,  0.0015, -0.0132,  ...,  0.0656,  0.0003, -0.0002],
        [ 0.0031,  0.0005,  0.0074,  ..., -0.0175,  0.0516, -0.0155],
        [ 0.0105, -0.0102, -0.0102,  ..., -0.0190, -0.0095,  0.0563]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.1426, -1.1416, -0.6416,  ..., -2.6660, -1.3945, -2.2070]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 18:38:17 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of wanted is unwanted
The opposite of interrupted is uninterrupted
The opposite of conscious is unconscious
The opposite of predictable is unpredictable
The opposite of reasonable is unreasonable
The opposite of suitable is unsuitable
The opposite of paid is unpaid
The opposite of realistic is
2024-07-28 18:38:17 root INFO     [order_1_approx] starting weight calculation for The opposite of paid is unpaid
The opposite of realistic is unrealistic
The opposite of reasonable is unreasonable
The opposite of predictable is unpredictable
The opposite of suitable is unsuitable
The opposite of wanted is unwanted
The opposite of conscious is unconscious
The opposite of interrupted is
2024-07-28 18:38:17 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-28 18:40:14 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.6216, -0.2300,  0.0852,  ...,  0.1304, -0.7993,  0.2255],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.4102, -0.3091,  0.4326,  ...,  0.3472, -2.8887, -1.0215],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0897,  0.0082,  0.0086,  ...,  0.0063,  0.0121,  0.0092],
        [-0.0145,  0.0859, -0.0065,  ...,  0.0186,  0.0032, -0.0143],
        [-0.0020, -0.0156,  0.0599,  ..., -0.0186,  0.0070,  0.0068],
        ...,
        [ 0.0073,  0.0278, -0.0142,  ...,  0.0876, -0.0186, -0.0181],
        [ 0.0124, -0.0154,  0.0249,  ..., -0.0064,  0.0654, -0.0145],
        [-0.0077,  0.0018, -0.0201,  ..., -0.0073, -0.0165,  0.0818]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.7070, -0.1262, -0.0076,  ...,  0.5522, -2.7949, -1.3652]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 18:40:15 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of paid is unpaid
The opposite of realistic is unrealistic
The opposite of reasonable is unreasonable
The opposite of predictable is unpredictable
The opposite of suitable is unsuitable
The opposite of wanted is unwanted
The opposite of conscious is unconscious
The opposite of interrupted is
2024-07-28 18:40:15 root INFO     [order_1_approx] starting weight calculation for The opposite of predictable is unpredictable
The opposite of suitable is unsuitable
The opposite of wanted is unwanted
The opposite of interrupted is uninterrupted
The opposite of conscious is unconscious
The opposite of reasonable is unreasonable
The opposite of realistic is unrealistic
The opposite of paid is
2024-07-28 18:40:15 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-28 18:42:10 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2201, -0.4717, -0.5562,  ..., -0.4194, -0.5166, -0.0919],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.9414, -3.4492,  0.7529,  ..., -4.7266, -3.4023, -1.8828],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0983, -0.0110,  0.0052,  ...,  0.0052,  0.0100,  0.0169],
        [-0.0111,  0.0840, -0.0160,  ...,  0.0115,  0.0049, -0.0141],
        [-0.0099, -0.0007,  0.0732,  ..., -0.0177,  0.0182,  0.0088],
        ...,
        [ 0.0017,  0.0255, -0.0231,  ...,  0.1122, -0.0084, -0.0115],
        [-0.0096, -0.0005,  0.0134,  ..., -0.0071,  0.0844, -0.0198],
        [ 0.0025,  0.0041, -0.0266,  ..., -0.0143,  0.0211,  0.1002]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.3027, -3.0898,  0.9395,  ..., -3.9902, -4.0781, -1.4746]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 18:42:11 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of predictable is unpredictable
The opposite of suitable is unsuitable
The opposite of wanted is unwanted
The opposite of interrupted is uninterrupted
The opposite of conscious is unconscious
The opposite of reasonable is unreasonable
The opposite of realistic is unrealistic
The opposite of paid is
2024-07-28 18:42:12 root INFO     [order_1_approx] starting weight calculation for The opposite of realistic is unrealistic
The opposite of reasonable is unreasonable
The opposite of paid is unpaid
The opposite of wanted is unwanted
The opposite of interrupted is uninterrupted
The opposite of predictable is unpredictable
The opposite of conscious is unconscious
The opposite of suitable is
2024-07-28 18:42:12 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-28 18:44:05 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.4924, -0.4824,  0.5151,  ..., -0.4641, -0.0901, -0.4084],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.1016, -1.3809,  0.9971,  ...,  0.6138, -2.3555,  0.0547],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.1028, -0.0154,  0.0199,  ..., -0.0015,  0.0039,  0.0194],
        [-0.0044,  0.0517,  0.0049,  ...,  0.0066,  0.0059,  0.0085],
        [-0.0172, -0.0030,  0.0685,  ..., -0.0164, -0.0060, -0.0030],
        ...,
        [ 0.0055, -0.0033, -0.0108,  ...,  0.0968, -0.0051, -0.0193],
        [-0.0236,  0.0061,  0.0057,  ...,  0.0063,  0.0717, -0.0238],
        [ 0.0079, -0.0023, -0.0309,  ..., -0.0011, -0.0045,  0.0885]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.1660, -1.4434,  1.0488,  ...,  0.4507, -1.3535, -0.1403]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 18:44:06 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of realistic is unrealistic
The opposite of reasonable is unreasonable
The opposite of paid is unpaid
The opposite of wanted is unwanted
The opposite of interrupted is uninterrupted
The opposite of predictable is unpredictable
The opposite of conscious is unconscious
The opposite of suitable is
2024-07-28 18:44:06 root INFO     [order_1_approx] starting weight calculation for The opposite of paid is unpaid
The opposite of suitable is unsuitable
The opposite of predictable is unpredictable
The opposite of interrupted is uninterrupted
The opposite of wanted is unwanted
The opposite of realistic is unrealistic
The opposite of conscious is unconscious
The opposite of reasonable is
2024-07-28 18:44:06 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-28 18:46:02 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2812, -0.4707, -0.7505,  ..., -1.0996, -0.5752, -0.7354],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.7461, -2.2324,  0.2812,  ..., -1.7803, -2.9238, -4.4219],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 7.6050e-02, -2.2125e-03,  2.2400e-02,  ..., -1.9016e-03,
          1.3916e-02,  1.8356e-02],
        [ 9.2316e-03,  5.7312e-02, -2.0355e-02,  ..., -4.2686e-03,
          3.3989e-03,  2.0599e-04],
        [ 6.1035e-05, -5.0774e-03,  6.4026e-02,  ..., -1.3901e-02,
          5.6572e-03,  1.6489e-03],
        ...,
        [ 2.8610e-03,  1.7593e-02,  3.5858e-04,  ...,  8.0139e-02,
         -1.1078e-02, -6.0272e-03],
        [-2.6646e-03,  1.3771e-02,  2.7790e-03,  ..., -1.0300e-04,
          6.6956e-02, -2.6276e-02],
        [ 1.1414e-02, -3.0899e-03, -6.1035e-05,  ..., -2.3712e-02,
         -1.0811e-02,  7.4097e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.7031, -2.4590,  0.5078,  ..., -1.8574, -2.2441, -4.4844]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 18:46:03 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of paid is unpaid
The opposite of suitable is unsuitable
The opposite of predictable is unpredictable
The opposite of interrupted is uninterrupted
The opposite of wanted is unwanted
The opposite of realistic is unrealistic
The opposite of conscious is unconscious
The opposite of reasonable is
2024-07-28 18:46:03 root INFO     [order_1_approx] starting weight calculation for The opposite of reasonable is unreasonable
The opposite of paid is unpaid
The opposite of interrupted is uninterrupted
The opposite of realistic is unrealistic
The opposite of conscious is unconscious
The opposite of predictable is unpredictable
The opposite of suitable is unsuitable
The opposite of wanted is
2024-07-28 18:46:03 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-28 18:47:59 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.3850, -0.1710, -0.6680,  ..., -0.3999, -0.5459,  0.1594],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.6230, -2.3164, -0.1289,  ...,  0.3574, -2.1523, -2.1562],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0617, -0.0043,  0.0039,  ...,  0.0032,  0.0071,  0.0105],
        [-0.0032,  0.0677, -0.0257,  ...,  0.0197, -0.0001, -0.0179],
        [-0.0043,  0.0164,  0.0513,  ..., -0.0269,  0.0011,  0.0067],
        ...,
        [ 0.0132,  0.0152, -0.0105,  ...,  0.0898, -0.0102, -0.0265],
        [-0.0025, -0.0112,  0.0212,  ..., -0.0106,  0.0818, -0.0084],
        [ 0.0159,  0.0078, -0.0248,  ..., -0.0050, -0.0125,  0.0762]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.4199e+00, -1.9336e+00,  1.8311e-03,  ...,  7.1143e-01,
         -2.3555e+00, -1.9775e+00]], device='cuda:1', dtype=torch.float16,
       grad_fn=<SubBackward0>) 

                    
2024-07-28 18:48:00 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of reasonable is unreasonable
The opposite of paid is unpaid
The opposite of interrupted is uninterrupted
The opposite of realistic is unrealistic
The opposite of conscious is unconscious
The opposite of predictable is unpredictable
The opposite of suitable is unsuitable
The opposite of wanted is
2024-07-28 18:48:00 root INFO     [order_1_approx] starting weight calculation for The opposite of wanted is unwanted
The opposite of conscious is unconscious
The opposite of paid is unpaid
The opposite of interrupted is uninterrupted
The opposite of suitable is unsuitable
The opposite of realistic is unrealistic
The opposite of reasonable is unreasonable
The opposite of predictable is
2024-07-28 18:48:01 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-28 18:49:57 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0139,  0.2295, -0.5283,  ..., -0.7017,  0.0689, -0.2173],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.8594,  0.0105, -1.4502,  ...,  0.4326, -0.2061, -2.4668],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 5.7404e-02, -7.9041e-03,  7.3318e-03,  ...,  2.7599e-03,
          4.4365e-03,  1.5259e-02],
        [ 2.3823e-03,  3.9093e-02,  8.1444e-04,  ...,  1.9226e-02,
          5.5199e-03,  6.5517e-04],
        [ 6.5422e-04,  2.8744e-03,  5.2063e-02,  ..., -1.6769e-02,
          9.5367e-07,  6.0997e-03],
        ...,
        [-2.6035e-03,  1.6586e-02, -7.0724e-03,  ...,  6.5918e-02,
         -2.2720e-02, -4.0855e-03],
        [ 3.6926e-03,  6.7368e-03,  6.8474e-03,  ..., -8.1711e-03,
          4.1809e-02, -1.0803e-02],
        [ 8.7357e-03, -6.7291e-03, -8.3923e-03,  ..., -6.0196e-03,
         -7.6675e-03,  5.2734e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.0508,  0.0910, -1.2266,  ...,  0.5566, -0.0394, -2.5684]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 18:49:58 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of wanted is unwanted
The opposite of conscious is unconscious
The opposite of paid is unpaid
The opposite of interrupted is uninterrupted
The opposite of suitable is unsuitable
The opposite of realistic is unrealistic
The opposite of reasonable is unreasonable
The opposite of predictable is
2024-07-28 18:49:58 root INFO     [order_1_approx] starting weight calculation for The opposite of realistic is unrealistic
The opposite of reasonable is unreasonable
The opposite of paid is unpaid
The opposite of predictable is unpredictable
The opposite of wanted is unwanted
The opposite of interrupted is uninterrupted
The opposite of suitable is unsuitable
The opposite of conscious is
2024-07-28 18:49:58 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-28 18:51:54 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4092,  0.0525, -0.5503,  ..., -0.1233, -0.2144,  0.1199],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.7402, -0.9434,  4.5273,  ..., -1.6836,  1.5820, -1.1113],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0949, -0.0053,  0.0034,  ...,  0.0108, -0.0099,  0.0183],
        [ 0.0010,  0.0438, -0.0151,  ...,  0.0170,  0.0096,  0.0020],
        [-0.0031, -0.0115,  0.0814,  ..., -0.0155, -0.0246,  0.0022],
        ...,
        [ 0.0113,  0.0239,  0.0130,  ...,  0.0915, -0.0154, -0.0043],
        [-0.0031, -0.0148,  0.0181,  ...,  0.0055,  0.0942, -0.0387],
        [-0.0026, -0.0008, -0.0097,  ..., -0.0141, -0.0156,  0.0824]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.7344, -0.5400,  4.3516,  ..., -1.3916,  1.5420, -1.4502]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 18:51:55 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of realistic is unrealistic
The opposite of reasonable is unreasonable
The opposite of paid is unpaid
The opposite of predictable is unpredictable
The opposite of wanted is unwanted
The opposite of interrupted is uninterrupted
The opposite of suitable is unsuitable
The opposite of conscious is
2024-07-28 18:51:55 root INFO     total operator prediction time: 936.3239295482635 seconds
2024-07-28 18:51:55 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on verb+able_reg
2024-07-28 18:51:55 root INFO     building operator verb+able_reg
2024-07-28 18:51:55 root INFO     [order_1_approx] starting weight calculation for If you can foresee something, that thing is foreseeable
If you can expand something, that thing is expandable
If you can achieve something, that thing is achieveable
If you can adjust something, that thing is adjustable
If you can rely something, that thing is reliable
If you can execute something, that thing is executable
If you can avoid something, that thing is avoidable
If you can observe something, that thing is
2024-07-28 18:51:55 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-28 18:53:50 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1272,  0.4395,  0.1493,  ..., -0.0496, -0.3706, -0.0341],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.7451, -0.8574, -1.4258,  ..., -3.6523, -6.9453, -0.5293],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0859,  0.0008,  0.0087,  ...,  0.0007, -0.0056,  0.0107],
        [-0.0049,  0.0624, -0.0014,  ...,  0.0075,  0.0119, -0.0051],
        [-0.0020, -0.0063,  0.0790,  ..., -0.0109,  0.0044, -0.0163],
        ...,
        [ 0.0095,  0.0210, -0.0011,  ...,  0.0745, -0.0009, -0.0004],
        [ 0.0119,  0.0133,  0.0053,  ..., -0.0100,  0.0637, -0.0073],
        [ 0.0039,  0.0131, -0.0091,  ..., -0.0043, -0.0162,  0.0620]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.6865, -0.7861, -1.4600,  ..., -3.7539, -7.0312, -0.3154]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 18:53:51 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you can foresee something, that thing is foreseeable
If you can expand something, that thing is expandable
If you can achieve something, that thing is achieveable
If you can adjust something, that thing is adjustable
If you can rely something, that thing is reliable
If you can execute something, that thing is executable
If you can avoid something, that thing is avoidable
If you can observe something, that thing is
2024-07-28 18:53:51 root INFO     [order_1_approx] starting weight calculation for If you can rely something, that thing is reliable
If you can achieve something, that thing is achieveable
If you can foresee something, that thing is foreseeable
If you can expand something, that thing is expandable
If you can execute something, that thing is executable
If you can observe something, that thing is observable
If you can adjust something, that thing is adjustable
If you can avoid something, that thing is
2024-07-28 18:53:51 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-28 18:55:46 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.6494, -0.4316, -0.2065,  ..., -0.0502,  0.7603,  0.4277],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.2334,  0.6318, -3.2344,  ..., -1.0977, -7.1562, -1.5059],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0730,  0.0005,  0.0108,  ..., -0.0065,  0.0029,  0.0144],
        [-0.0037,  0.0462,  0.0051,  ...,  0.0062,  0.0108, -0.0034],
        [ 0.0014, -0.0029,  0.0562,  ..., -0.0041,  0.0052, -0.0090],
        ...,
        [ 0.0205,  0.0173,  0.0031,  ...,  0.0656, -0.0102, -0.0023],
        [ 0.0025, -0.0032,  0.0046,  ..., -0.0192,  0.0672, -0.0137],
        [ 0.0029,  0.0046, -0.0055,  ..., -0.0135, -0.0214,  0.0584]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.5371,  0.5942, -3.3262,  ..., -1.2383, -6.8828, -1.4619]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 18:55:47 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you can rely something, that thing is reliable
If you can achieve something, that thing is achieveable
If you can foresee something, that thing is foreseeable
If you can expand something, that thing is expandable
If you can execute something, that thing is executable
If you can observe something, that thing is observable
If you can adjust something, that thing is adjustable
If you can avoid something, that thing is
2024-07-28 18:55:47 root INFO     [order_1_approx] starting weight calculation for If you can execute something, that thing is executable
If you can foresee something, that thing is foreseeable
If you can adjust something, that thing is adjustable
If you can rely something, that thing is reliable
If you can observe something, that thing is observable
If you can expand something, that thing is expandable
If you can avoid something, that thing is avoidable
If you can achieve something, that thing is
2024-07-28 18:55:47 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-28 18:57:42 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4829,  0.3193, -0.0331,  ...,  0.0818, -0.8052,  0.2295],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.0938,  0.4211, -1.7539,  ..., -4.3672, -8.9062, -3.1934],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 4.6478e-02,  2.5711e-03,  9.3307e-03,  ...,  6.1188e-03,
          3.4351e-03,  4.2725e-03],
        [ 1.7548e-04,  4.3762e-02,  4.8676e-03,  ...,  3.4180e-03,
          1.1597e-02, -4.0588e-03],
        [-2.6245e-03, -5.4398e-03,  4.5197e-02,  ..., -1.2379e-03,
         -9.2773e-03, -5.4169e-03],
        ...,
        [ 9.0485e-03,  2.3956e-02, -4.5776e-05,  ...,  4.7211e-02,
         -5.8784e-03, -4.2915e-04],
        [ 6.1874e-03,  6.6757e-03,  1.0460e-02,  ..., -1.4832e-02,
          2.7618e-02, -8.6288e-03],
        [ 4.4785e-03, -8.7357e-04, -9.8038e-03,  ..., -5.3024e-03,
         -7.2021e-03,  3.9093e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.8398,  0.4341, -1.8857,  ..., -4.1914, -8.8516, -3.1875]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 18:57:43 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you can execute something, that thing is executable
If you can foresee something, that thing is foreseeable
If you can adjust something, that thing is adjustable
If you can rely something, that thing is reliable
If you can observe something, that thing is observable
If you can expand something, that thing is expandable
If you can avoid something, that thing is avoidable
If you can achieve something, that thing is
2024-07-28 18:57:43 root INFO     [order_1_approx] starting weight calculation for If you can observe something, that thing is observable
If you can avoid something, that thing is avoidable
If you can rely something, that thing is reliable
If you can execute something, that thing is executable
If you can expand something, that thing is expandable
If you can foresee something, that thing is foreseeable
If you can achieve something, that thing is achieveable
If you can adjust something, that thing is
2024-07-28 18:57:43 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-28 18:59:39 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.4133, -0.0099, -0.9297,  ..., -0.2754, -0.0288,  0.5532],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.1309, -0.1284, -3.1367,  ..., -2.6895, -7.8008, -0.2168],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0908, -0.0022, -0.0004,  ..., -0.0028,  0.0028,  0.0066],
        [ 0.0098,  0.0705,  0.0065,  ...,  0.0271,  0.0116, -0.0102],
        [-0.0149, -0.0028,  0.0620,  ..., -0.0102,  0.0072, -0.0154],
        ...,
        [ 0.0091,  0.0142, -0.0056,  ...,  0.0759, -0.0073, -0.0014],
        [ 0.0110,  0.0045,  0.0133,  ..., -0.0210,  0.0652, -0.0085],
        [ 0.0004,  0.0123, -0.0091,  ..., -0.0174, -0.0232,  0.0626]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.8711,  0.0928, -2.9141,  ..., -3.0508, -7.5703, -0.2922]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 18:59:40 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you can observe something, that thing is observable
If you can avoid something, that thing is avoidable
If you can rely something, that thing is reliable
If you can execute something, that thing is executable
If you can expand something, that thing is expandable
If you can foresee something, that thing is foreseeable
If you can achieve something, that thing is achieveable
If you can adjust something, that thing is
2024-07-28 18:59:40 root INFO     [order_1_approx] starting weight calculation for If you can avoid something, that thing is avoidable
If you can achieve something, that thing is achieveable
If you can execute something, that thing is executable
If you can adjust something, that thing is adjustable
If you can observe something, that thing is observable
If you can expand something, that thing is expandable
If you can rely something, that thing is reliable
If you can foresee something, that thing is
2024-07-28 18:59:40 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-28 19:01:36 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.3586,  0.7168,  0.1957,  ..., -0.2510, -0.2942,  0.2257],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.4028,  1.8955, -1.4785,  ..., -3.1367, -7.4375, -1.9062],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0413,  0.0013,  0.0037,  ...,  0.0030,  0.0003,  0.0023],
        [-0.0051,  0.0307,  0.0005,  ...,  0.0048, -0.0011, -0.0008],
        [ 0.0011, -0.0001,  0.0396,  ..., -0.0011,  0.0023, -0.0042],
        ...,
        [ 0.0038,  0.0068, -0.0049,  ...,  0.0424, -0.0040,  0.0043],
        [ 0.0009, -0.0017,  0.0060,  ..., -0.0141,  0.0339, -0.0079],
        [-0.0006,  0.0022, -0.0046,  ..., -0.0033, -0.0057,  0.0343]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.4285,  1.8545, -1.4102,  ..., -3.2188, -7.2969, -1.9541]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 19:01:37 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you can avoid something, that thing is avoidable
If you can achieve something, that thing is achieveable
If you can execute something, that thing is executable
If you can adjust something, that thing is adjustable
If you can observe something, that thing is observable
If you can expand something, that thing is expandable
If you can rely something, that thing is reliable
If you can foresee something, that thing is
2024-07-28 19:01:37 root INFO     [order_1_approx] starting weight calculation for If you can observe something, that thing is observable
If you can avoid something, that thing is avoidable
If you can foresee something, that thing is foreseeable
If you can expand something, that thing is expandable
If you can execute something, that thing is executable
If you can achieve something, that thing is achieveable
If you can adjust something, that thing is adjustable
If you can rely something, that thing is
2024-07-28 19:01:37 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-28 19:03:32 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.3262, -0.4541,  0.1512,  ..., -0.0254, -0.3821, -0.5522],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.5869, -0.0134, -1.4697,  ..., -2.5957, -6.8438, -2.0820],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0663, -0.0089,  0.0057,  ..., -0.0007,  0.0031,  0.0181],
        [ 0.0053,  0.0555, -0.0060,  ...,  0.0157,  0.0196, -0.0081],
        [-0.0022, -0.0035,  0.0515,  ..., -0.0010,  0.0049, -0.0022],
        ...,
        [ 0.0154,  0.0198,  0.0031,  ...,  0.0579,  0.0024,  0.0045],
        [ 0.0141,  0.0052,  0.0052,  ..., -0.0083,  0.0626, -0.0096],
        [-0.0011,  0.0138, -0.0173,  ..., -0.0110, -0.0178,  0.0504]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.6611,  0.1935, -1.5039,  ..., -2.7227, -7.1016, -2.1816]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 19:03:33 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you can observe something, that thing is observable
If you can avoid something, that thing is avoidable
If you can foresee something, that thing is foreseeable
If you can expand something, that thing is expandable
If you can execute something, that thing is executable
If you can achieve something, that thing is achieveable
If you can adjust something, that thing is adjustable
If you can rely something, that thing is
2024-07-28 19:03:33 root INFO     [order_1_approx] starting weight calculation for If you can avoid something, that thing is avoidable
If you can rely something, that thing is reliable
If you can foresee something, that thing is foreseeable
If you can achieve something, that thing is achieveable
If you can execute something, that thing is executable
If you can adjust something, that thing is adjustable
If you can observe something, that thing is observable
If you can expand something, that thing is
2024-07-28 19:03:33 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-28 19:05:27 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.7285, -0.2820, -0.6729,  ..., -0.3352, -0.0890, -0.1638],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.6240,  0.1282, -0.2988,  ..., -3.0781, -7.6094, -3.8555],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0818, -0.0002,  0.0090,  ...,  0.0026,  0.0094,  0.0129],
        [ 0.0087,  0.0709,  0.0075,  ...,  0.0112,  0.0125, -0.0052],
        [-0.0018, -0.0108,  0.0707,  ..., -0.0014,  0.0065, -0.0173],
        ...,
        [ 0.0336,  0.0208, -0.0053,  ...,  0.0809,  0.0008,  0.0009],
        [ 0.0066, -0.0072,  0.0138,  ..., -0.0147,  0.0677, -0.0039],
        [-0.0132,  0.0021, -0.0198,  ..., -0.0253, -0.0114,  0.0745]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.8760,  0.2207, -0.0142,  ..., -3.2695, -7.7969, -3.6230]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 19:05:28 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you can avoid something, that thing is avoidable
If you can rely something, that thing is reliable
If you can foresee something, that thing is foreseeable
If you can achieve something, that thing is achieveable
If you can execute something, that thing is executable
If you can adjust something, that thing is adjustable
If you can observe something, that thing is observable
If you can expand something, that thing is
2024-07-28 19:05:28 root INFO     [order_1_approx] starting weight calculation for If you can rely something, that thing is reliable
If you can adjust something, that thing is adjustable
If you can foresee something, that thing is foreseeable
If you can achieve something, that thing is achieveable
If you can avoid something, that thing is avoidable
If you can observe something, that thing is observable
If you can expand something, that thing is expandable
If you can execute something, that thing is
2024-07-28 19:05:28 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-28 19:07:23 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2471,  0.4731, -0.0418,  ...,  0.2175, -0.6309, -0.3760],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.3076, -1.3662,  1.4365,  ..., -2.3359, -6.5625, -4.2891],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0597, -0.0040,  0.0102,  ...,  0.0044,  0.0012,  0.0076],
        [-0.0016,  0.0669,  0.0047,  ...,  0.0112,  0.0142, -0.0005],
        [ 0.0088, -0.0037,  0.0454,  ..., -0.0069, -0.0004, -0.0048],
        ...,
        [ 0.0092,  0.0141, -0.0028,  ...,  0.0676,  0.0008, -0.0068],
        [ 0.0131,  0.0037,  0.0038,  ..., -0.0075,  0.0503, -0.0135],
        [-0.0040, -0.0034, -0.0078,  ..., -0.0096, -0.0089,  0.0580]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.1610, -1.0459,  1.7793,  ..., -2.4688, -6.3320, -4.0234]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 19:07:24 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you can rely something, that thing is reliable
If you can adjust something, that thing is adjustable
If you can foresee something, that thing is foreseeable
If you can achieve something, that thing is achieveable
If you can avoid something, that thing is avoidable
If you can observe something, that thing is observable
If you can expand something, that thing is expandable
If you can execute something, that thing is
2024-07-28 19:07:24 root INFO     total operator prediction time: 928.7382152080536 seconds
2024-07-28 19:07:24 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on verb+tion_irreg
2024-07-28 19:07:24 root INFO     building operator verb+tion_irreg
2024-07-28 19:07:24 root INFO     [order_1_approx] starting weight calculation for To observe results in observation
To continue results in continuation
To minimize results in minimization
To standardize results in standardization
To modernize results in modernization
To organize results in organization
To reorganize results in reorganization
To authorize results in
2024-07-28 19:07:24 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-28 19:09:20 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.3540, -0.2268, -0.5635,  ..., -0.5742, -0.0726,  0.0410],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.5840, -4.0195,  1.6562,  ...,  1.2695, -3.4766, -3.6094],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0895, -0.0071,  0.0149,  ..., -0.0202, -0.0048,  0.0089],
        [-0.0110,  0.0744,  0.0068,  ...,  0.0108,  0.0023,  0.0035],
        [ 0.0083, -0.0085,  0.0747,  ..., -0.0110,  0.0020,  0.0013],
        ...,
        [ 0.0037,  0.0186, -0.0021,  ...,  0.0994, -0.0006, -0.0072],
        [ 0.0046,  0.0112,  0.0067,  ...,  0.0056,  0.0728, -0.0020],
        [ 0.0024,  0.0004, -0.0095,  ...,  0.0057, -0.0089,  0.0772]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.3574, -3.6328,  1.6846,  ...,  1.3691, -3.4980, -3.5488]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 19:09:21 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To observe results in observation
To continue results in continuation
To minimize results in minimization
To standardize results in standardization
To modernize results in modernization
To organize results in organization
To reorganize results in reorganization
To authorize results in
2024-07-28 19:09:21 root INFO     [order_1_approx] starting weight calculation for To standardize results in standardization
To continue results in continuation
To modernize results in modernization
To reorganize results in reorganization
To minimize results in minimization
To authorize results in authorization
To organize results in organization
To observe results in
2024-07-28 19:09:21 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-28 19:11:16 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0994,  0.0863, -0.1794,  ..., -0.6851, -0.1188, -0.0229],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.4697, -3.7695,  2.3242,  ...,  1.1699, -0.2803, -1.2891],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.1332, -0.0068,  0.0095,  ..., -0.0178,  0.0007,  0.0204],
        [-0.0096,  0.1228,  0.0153,  ...,  0.0294,  0.0025,  0.0129],
        [ 0.0122, -0.0193,  0.1194,  ..., -0.0110,  0.0039, -0.0098],
        ...,
        [-0.0042,  0.0174,  0.0055,  ...,  0.1353,  0.0016, -0.0018],
        [ 0.0023,  0.0027,  0.0226,  ...,  0.0132,  0.1077, -0.0226],
        [ 0.0001,  0.0117, -0.0030,  ...,  0.0199, -0.0092,  0.1221]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.8613, -3.1680,  2.3516,  ...,  1.6084, -0.6289, -1.2607]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 19:11:18 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To standardize results in standardization
To continue results in continuation
To modernize results in modernization
To reorganize results in reorganization
To minimize results in minimization
To authorize results in authorization
To organize results in organization
To observe results in
2024-07-28 19:11:18 root INFO     [order_1_approx] starting weight calculation for To authorize results in authorization
To continue results in continuation
To organize results in organization
To modernize results in modernization
To minimize results in minimization
To observe results in observation
To reorganize results in reorganization
To standardize results in
2024-07-28 19:11:18 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-28 19:13:14 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1381, -0.3784, -1.0146,  ..., -0.7275,  0.0058, -0.1909],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.1587, -3.1719,  1.0410,  ...,  1.9121, -1.7471, -2.9082],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0810, -0.0052,  0.0047,  ..., -0.0170,  0.0068, -0.0007],
        [-0.0123,  0.0724,  0.0105,  ...,  0.0130, -0.0048,  0.0129],
        [-0.0024, -0.0054,  0.0732,  ..., -0.0044,  0.0085, -0.0093],
        ...,
        [ 0.0044,  0.0157, -0.0002,  ...,  0.0872, -0.0094,  0.0039],
        [ 0.0031,  0.0023,  0.0027,  ...,  0.0002,  0.0724, -0.0147],
        [-0.0137,  0.0054, -0.0025,  ...,  0.0040, -0.0135,  0.0705]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.0172, -2.9492,  1.1045,  ...,  2.2227, -1.8135, -2.9062]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 19:13:15 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To authorize results in authorization
To continue results in continuation
To organize results in organization
To modernize results in modernization
To minimize results in minimization
To observe results in observation
To reorganize results in reorganization
To standardize results in
2024-07-28 19:13:15 root INFO     [order_1_approx] starting weight calculation for To modernize results in modernization
To observe results in observation
To authorize results in authorization
To minimize results in minimization
To organize results in organization
To standardize results in standardization
To reorganize results in reorganization
To continue results in
2024-07-28 19:13:15 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-28 19:15:08 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.5498, -0.9160, -0.3826,  ..., -0.1975, -1.0176,  0.1797],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.0928, -6.6641,  1.3457,  ...,  1.0537, -0.0125, -2.6055],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 1.1615e-01,  5.2795e-03, -4.3335e-03,  ..., -5.4245e-03,
          5.0659e-03,  1.7151e-02],
        [-8.0185e-03,  9.6924e-02,  2.6245e-02,  ...,  2.1179e-02,
         -5.4054e-03,  5.6915e-03],
        [ 4.9019e-03,  1.4009e-03,  8.5205e-02,  ..., -9.0714e-03,
         -4.5776e-05, -1.9409e-02],
        ...,
        [ 7.4081e-03,  1.1917e-02,  1.0117e-02,  ...,  1.1963e-01,
          3.5858e-04,  1.5381e-02],
        [ 1.2093e-03, -2.8286e-03,  1.4069e-02,  ...,  6.9046e-03,
          9.4971e-02, -3.0640e-02],
        [ 8.5297e-03,  2.7981e-03,  6.1226e-03,  ..., -1.1795e-02,
         -1.6312e-02,  9.7656e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.3813, -5.8750,  1.4941,  ...,  1.4854, -0.5029, -2.5488]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 19:15:09 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To modernize results in modernization
To observe results in observation
To authorize results in authorization
To minimize results in minimization
To organize results in organization
To standardize results in standardization
To reorganize results in reorganization
To continue results in
2024-07-28 19:15:09 root INFO     [order_1_approx] starting weight calculation for To reorganize results in reorganization
To authorize results in authorization
To standardize results in standardization
To minimize results in minimization
To continue results in continuation
To organize results in organization
To observe results in observation
To modernize results in
2024-07-28 19:15:09 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-28 19:17:05 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 4.0918e-01,  1.8359e-01, -1.1191e+00,  ..., -9.6338e-01,
        -3.8574e-01, -1.2207e-04], device='cuda:1', dtype=torch.float16,
       grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.5176, -2.6582, -0.4595,  ...,  0.2319, -3.1289, -1.3516],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0800, -0.0070,  0.0116,  ..., -0.0065,  0.0044,  0.0085],
        [-0.0058,  0.0745,  0.0023,  ...,  0.0094,  0.0005,  0.0037],
        [-0.0009, -0.0049,  0.0732,  ..., -0.0056,  0.0036, -0.0125],
        ...,
        [ 0.0029,  0.0050,  0.0003,  ...,  0.0811, -0.0056, -0.0063],
        [ 0.0027,  0.0079,  0.0093,  ..., -0.0007,  0.0714, -0.0083],
        [-0.0075, -0.0048, -0.0040,  ..., -0.0052, -0.0105,  0.0739]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.5391, -2.6172, -0.3730,  ...,  0.3389, -3.2520, -1.5352]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 19:17:06 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To reorganize results in reorganization
To authorize results in authorization
To standardize results in standardization
To minimize results in minimization
To continue results in continuation
To organize results in organization
To observe results in observation
To modernize results in
2024-07-28 19:17:06 root INFO     [order_1_approx] starting weight calculation for To continue results in continuation
To organize results in organization
To minimize results in minimization
To observe results in observation
To modernize results in modernization
To standardize results in standardization
To authorize results in authorization
To reorganize results in
2024-07-28 19:17:07 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-28 19:19:02 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.7935,  0.0698, -0.9062,  ..., -0.4951, -0.2583, -0.1392],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.0449, -3.2070,  1.5918,  ...,  0.9165, -0.1197, -4.2500],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0445, -0.0018,  0.0015,  ..., -0.0050,  0.0004,  0.0061],
        [-0.0016,  0.0451,  0.0056,  ...,  0.0040,  0.0007,  0.0047],
        [-0.0014, -0.0051,  0.0469,  ..., -0.0046,  0.0043, -0.0005],
        ...,
        [ 0.0070,  0.0113, -0.0021,  ...,  0.0558, -0.0061, -0.0028],
        [ 0.0011,  0.0008, -0.0005,  ...,  0.0026,  0.0455, -0.0051],
        [ 0.0029,  0.0021, -0.0036,  ..., -0.0031, -0.0065,  0.0435]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.1201, -3.1309,  1.6387,  ...,  0.8770, -0.1321, -4.2969]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 19:19:03 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To continue results in continuation
To organize results in organization
To minimize results in minimization
To observe results in observation
To modernize results in modernization
To standardize results in standardization
To authorize results in authorization
To reorganize results in
2024-07-28 19:19:03 root INFO     [order_1_approx] starting weight calculation for To reorganize results in reorganization
To standardize results in standardization
To observe results in observation
To authorize results in authorization
To modernize results in modernization
To organize results in organization
To continue results in continuation
To minimize results in
2024-07-28 19:19:03 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-28 19:20:59 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2690, -0.5054, -0.8975,  ..., -0.9531, -0.1007, -0.3098],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.1562, -0.6748,  1.6045,  ..., -1.0029, -3.0508, -3.5430],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0745, -0.0027, -0.0032,  ..., -0.0218, -0.0030,  0.0130],
        [-0.0045,  0.0637,  0.0094,  ...,  0.0196,  0.0019, -0.0014],
        [-0.0012, -0.0150,  0.0628,  ..., -0.0076,  0.0031, -0.0068],
        ...,
        [-0.0026,  0.0252,  0.0058,  ...,  0.0803,  0.0008,  0.0012],
        [ 0.0035,  0.0064,  0.0047,  ...,  0.0013,  0.0662, -0.0056],
        [-0.0033,  0.0107,  0.0057,  ..., -0.0037, -0.0094,  0.0634]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.3013, -0.6670,  1.5527,  ..., -0.8574, -3.0664, -3.4395]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 19:21:01 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To reorganize results in reorganization
To standardize results in standardization
To observe results in observation
To authorize results in authorization
To modernize results in modernization
To organize results in organization
To continue results in continuation
To minimize results in
2024-07-28 19:21:02 root INFO     [order_1_approx] starting weight calculation for To modernize results in modernization
To standardize results in standardization
To minimize results in minimization
To authorize results in authorization
To observe results in observation
To continue results in continuation
To reorganize results in reorganization
To organize results in
2024-07-28 19:21:02 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-28 19:22:58 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3918,  0.3381, -0.3503,  ..., -1.2051,  0.2043, -0.2451],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.4453, -2.8223,  1.9785,  ...,  1.6807, -2.7305, -4.3984],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 6.0181e-02, -1.6460e-03,  8.4076e-03,  ..., -1.0345e-02,
          4.5128e-03,  6.8359e-03],
        [-9.9182e-03,  5.1880e-02,  7.2575e-04,  ...,  1.3000e-02,
          2.2697e-03,  3.8433e-03],
        [ 6.1464e-04, -5.6458e-03,  5.5420e-02,  ..., -6.0272e-03,
          6.0806e-03, -5.1117e-03],
        ...,
        [ 4.2496e-03,  1.1177e-02, -6.8588e-03,  ...,  6.6223e-02,
         -3.2425e-05, -8.0872e-03],
        [-3.0651e-03,  3.5210e-03,  3.4103e-03,  ...,  5.2643e-03,
          5.7800e-02, -1.2413e-02],
        [-4.0970e-03,  4.4537e-04, -2.1667e-03,  ...,  2.3727e-03,
         -6.3133e-03,  5.3955e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.5586, -2.6309,  1.9531,  ...,  1.6885, -2.6797, -4.3320]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 19:22:59 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To modernize results in modernization
To standardize results in standardization
To minimize results in minimization
To authorize results in authorization
To observe results in observation
To continue results in continuation
To reorganize results in reorganization
To organize results in
2024-07-28 19:22:59 root INFO     total operator prediction time: 934.8277645111084 seconds
2024-07-28 19:22:59 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on adj+ly_reg
2024-07-28 19:22:59 root INFO     building operator adj+ly_reg
2024-07-28 19:22:59 root INFO     [order_1_approx] starting weight calculation for The adjective form of interesting is interestingly
The adjective form of international is internationally
The adjective form of similar is similarly
The adjective form of internal is internally
The adjective form of practical is practically
The adjective form of subsequent is subsequently
The adjective form of successful is successfully
The adjective form of extensive is
2024-07-28 19:22:59 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-28 19:24:55 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0320, -0.1414, -0.4355,  ..., -0.9028, -0.1072, -0.3027],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.4648, -1.0957, -1.3623,  ..., -1.5762, -1.2412, -3.8867],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.1133, -0.0171, -0.0018,  ...,  0.0070,  0.0238,  0.0198],
        [ 0.0036,  0.0860,  0.0121,  ...,  0.0166,  0.0036, -0.0120],
        [ 0.0186, -0.0088,  0.0836,  ..., -0.0065,  0.0031,  0.0035],
        ...,
        [ 0.0068,  0.0301,  0.0094,  ...,  0.1027,  0.0004, -0.0038],
        [ 0.0027,  0.0049, -0.0053,  ...,  0.0006,  0.0703, -0.0207],
        [ 0.0060,  0.0045, -0.0025,  ..., -0.0085, -0.0113,  0.0788]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.1875, -1.0664, -1.3818,  ..., -1.2402, -0.9956, -4.0938]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 19:24:56 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The adjective form of interesting is interestingly
The adjective form of international is internationally
The adjective form of similar is similarly
The adjective form of internal is internally
The adjective form of practical is practically
The adjective form of subsequent is subsequently
The adjective form of successful is successfully
The adjective form of extensive is
2024-07-28 19:24:56 root INFO     [order_1_approx] starting weight calculation for The adjective form of internal is internally
The adjective form of extensive is extensively
The adjective form of similar is similarly
The adjective form of successful is successfully
The adjective form of practical is practically
The adjective form of interesting is interestingly
The adjective form of subsequent is subsequently
The adjective form of international is
2024-07-28 19:24:57 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-28 19:26:53 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2954,  0.2986, -0.0250,  ..., -0.2383, -0.6865, -0.2112],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.3242, -1.0703,  0.1470,  ..., -2.1680,  0.3284, -1.2969],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0875, -0.0251,  0.0112,  ..., -0.0032,  0.0288,  0.0005],
        [-0.0113,  0.0682,  0.0061,  ...,  0.0076, -0.0109, -0.0139],
        [ 0.0322, -0.0011,  0.0771,  ...,  0.0097, -0.0041, -0.0046],
        ...,
        [-0.0045,  0.0487, -0.0036,  ...,  0.0885,  0.0109,  0.0015],
        [-0.0061,  0.0028,  0.0074,  ..., -0.0048,  0.0693, -0.0081],
        [-0.0007, -0.0122, -0.0001,  ..., -0.0173, -0.0343,  0.0705]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.5283, -0.8994,  0.2351,  ..., -2.1504,  0.2217, -1.4912]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 19:26:54 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The adjective form of internal is internally
The adjective form of extensive is extensively
The adjective form of similar is similarly
The adjective form of successful is successfully
The adjective form of practical is practically
The adjective form of interesting is interestingly
The adjective form of subsequent is subsequently
The adjective form of international is
2024-07-28 19:26:54 root INFO     [order_1_approx] starting weight calculation for The adjective form of similar is similarly
The adjective form of extensive is extensively
The adjective form of subsequent is subsequently
The adjective form of practical is practically
The adjective form of international is internationally
The adjective form of interesting is interestingly
The adjective form of internal is internally
The adjective form of successful is
2024-07-28 19:26:54 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-28 19:28:50 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3689, -0.0083,  0.1517,  ..., -0.5195, -1.3408, -0.8843],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.1562, -1.0352,  0.8271,  ...,  0.0889, -0.7026, -2.3145],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0771, -0.0124,  0.0087,  ..., -0.0130,  0.0003,  0.0260],
        [-0.0061,  0.0552,  0.0070,  ...,  0.0201,  0.0065, -0.0098],
        [ 0.0088, -0.0120,  0.0590,  ...,  0.0147, -0.0104, -0.0078],
        ...,
        [-0.0133,  0.0097, -0.0132,  ...,  0.0800,  0.0032,  0.0015],
        [ 0.0128, -0.0045,  0.0060,  ...,  0.0041,  0.0503, -0.0175],
        [-0.0111, -0.0114, -0.0004,  ..., -0.0033, -0.0117,  0.0556]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.8984, -0.9014,  0.8555,  ...,  0.2910, -0.5371, -2.1641]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 19:28:51 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The adjective form of similar is similarly
The adjective form of extensive is extensively
The adjective form of subsequent is subsequently
The adjective form of practical is practically
The adjective form of international is internationally
The adjective form of interesting is interestingly
The adjective form of internal is internally
The adjective form of successful is
2024-07-28 19:28:52 root INFO     [order_1_approx] starting weight calculation for The adjective form of practical is practically
The adjective form of internal is internally
The adjective form of subsequent is subsequently
The adjective form of similar is similarly
The adjective form of successful is successfully
The adjective form of international is internationally
The adjective form of extensive is extensively
The adjective form of interesting is
2024-07-28 19:28:52 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-28 19:30:48 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0660, -0.1689,  0.6206,  ..., -0.0344, -1.2012, -0.4971],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.0703, -1.4199,  1.3242,  ..., -1.4336, -1.6113, -1.7246],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0479, -0.0147,  0.0113,  ..., -0.0162,  0.0127,  0.0131],
        [-0.0138,  0.0495,  0.0046,  ...,  0.0122, -0.0093, -0.0126],
        [ 0.0251,  0.0006,  0.0633,  ...,  0.0042,  0.0023,  0.0060],
        ...,
        [-0.0006,  0.0088, -0.0082,  ...,  0.0746,  0.0004,  0.0051],
        [ 0.0254,  0.0045,  0.0049,  ..., -0.0121,  0.0361, -0.0095],
        [-0.0011, -0.0003,  0.0094,  ..., -0.0149, -0.0204,  0.0497]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.4307, -1.1602,  1.2676,  ..., -1.3740, -1.7334, -1.9023]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 19:30:49 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The adjective form of practical is practically
The adjective form of internal is internally
The adjective form of subsequent is subsequently
The adjective form of similar is similarly
The adjective form of successful is successfully
The adjective form of international is internationally
The adjective form of extensive is extensively
The adjective form of interesting is
2024-07-28 19:30:50 root INFO     [order_1_approx] starting weight calculation for The adjective form of internal is internally
The adjective form of international is internationally
The adjective form of successful is successfully
The adjective form of subsequent is subsequently
The adjective form of interesting is interestingly
The adjective form of similar is similarly
The adjective form of extensive is extensively
The adjective form of practical is
2024-07-28 19:30:50 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-28 19:32:45 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1382,  0.0646,  0.5845,  ..., -0.2209, -0.8232, -0.0477],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.8320, -2.8809, -0.5488,  ..., -1.5049, -0.9360, -0.2402],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 7.0923e-02, -9.5673e-03,  3.2768e-03,  ...,  3.0518e-05,
          5.6000e-03,  1.9531e-02],
        [-1.5564e-02,  5.0293e-02,  2.2793e-04,  ...,  1.6846e-02,
          1.4763e-03, -1.1124e-02],
        [ 1.8120e-04, -1.1803e-02,  8.3801e-02,  ...,  1.3161e-04,
         -1.4954e-02,  5.2071e-03],
        ...,
        [-5.9128e-05,  6.2637e-03, -1.1124e-02,  ...,  9.1675e-02,
         -4.7722e-03, -5.3101e-03],
        [ 1.0178e-02, -5.9433e-03,  1.0269e-02,  ..., -9.3842e-04,
          7.3059e-02, -1.5793e-02],
        [ 6.7482e-03, -2.4128e-03, -7.4921e-03,  ..., -1.3077e-02,
         -1.5427e-02,  6.3599e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.9316, -2.4453, -0.2905,  ..., -1.4189, -0.6733, -0.2214]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 19:32:46 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The adjective form of internal is internally
The adjective form of international is internationally
The adjective form of successful is successfully
The adjective form of subsequent is subsequently
The adjective form of interesting is interestingly
The adjective form of similar is similarly
The adjective form of extensive is extensively
The adjective form of practical is
2024-07-28 19:32:46 root INFO     [order_1_approx] starting weight calculation for The adjective form of interesting is interestingly
The adjective form of international is internationally
The adjective form of internal is internally
The adjective form of extensive is extensively
The adjective form of successful is successfully
The adjective form of practical is practically
The adjective form of subsequent is subsequently
The adjective form of similar is
2024-07-28 19:32:46 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-28 19:34:43 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1885, -0.2778,  0.0046,  ..., -0.1214,  0.0975, -0.2169],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.2168, -0.8662,  1.4863,  ..., -1.5762,  0.4502, -1.7705],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.1093, -0.0102,  0.0287,  ..., -0.0172,  0.0369,  0.0214],
        [ 0.0043,  0.0928,  0.0277,  ...,  0.0112, -0.0018, -0.0065],
        [ 0.0135, -0.0019,  0.0954,  ..., -0.0037, -0.0111, -0.0097],
        ...,
        [ 0.0026,  0.0142,  0.0075,  ...,  0.1083, -0.0007,  0.0014],
        [-0.0094,  0.0079, -0.0122,  ..., -0.0208,  0.0764, -0.0085],
        [-0.0004, -0.0019, -0.0058,  ...,  0.0025, -0.0059,  0.0864]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.9839, -0.6504,  1.8965,  ..., -1.5908,  0.0991, -2.0684]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 19:34:44 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The adjective form of interesting is interestingly
The adjective form of international is internationally
The adjective form of internal is internally
The adjective form of extensive is extensively
The adjective form of successful is successfully
The adjective form of practical is practically
The adjective form of subsequent is subsequently
The adjective form of similar is
2024-07-28 19:34:44 root INFO     [order_1_approx] starting weight calculation for The adjective form of practical is practically
The adjective form of international is internationally
The adjective form of successful is successfully
The adjective form of extensive is extensively
The adjective form of interesting is interestingly
The adjective form of internal is internally
The adjective form of similar is similarly
The adjective form of subsequent is
2024-07-28 19:34:44 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-28 19:36:40 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.3325,  0.3291, -0.1355,  ..., -0.6123, -0.9102, -0.2495],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.3027,  0.3821,  1.7207,  ..., -0.4722,  1.8857, -3.0703],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.1072,  0.0027,  0.0077,  ..., -0.0084,  0.0185,  0.0126],
        [ 0.0161,  0.0931,  0.0218,  ...,  0.0181, -0.0165, -0.0241],
        [ 0.0092, -0.0084,  0.0837,  ..., -0.0159, -0.0231, -0.0010],
        ...,
        [-0.0144,  0.0167, -0.0034,  ...,  0.1140, -0.0007,  0.0085],
        [-0.0016, -0.0020,  0.0034,  ...,  0.0071,  0.0530, -0.0121],
        [ 0.0041,  0.0005, -0.0056,  ..., -0.0022, -0.0214,  0.0728]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.0254, -0.1179,  1.8613,  ...,  0.0342,  2.0840, -3.2324]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 19:36:41 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The adjective form of practical is practically
The adjective form of international is internationally
The adjective form of successful is successfully
The adjective form of extensive is extensively
The adjective form of interesting is interestingly
The adjective form of internal is internally
The adjective form of similar is similarly
The adjective form of subsequent is
2024-07-28 19:36:42 root INFO     [order_1_approx] starting weight calculation for The adjective form of international is internationally
The adjective form of subsequent is subsequently
The adjective form of practical is practically
The adjective form of extensive is extensively
The adjective form of successful is successfully
The adjective form of interesting is interestingly
The adjective form of similar is similarly
The adjective form of internal is
2024-07-28 19:36:42 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-28 19:38:38 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2231, -0.3467,  0.2715,  ..., -0.5762, -0.4272,  0.0299],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.2761, -0.9492,  1.3564,  ..., -3.9375,  1.2041, -3.6055],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 1.3062e-01, -2.1881e-02,  1.1841e-02,  ..., -2.8114e-03,
          2.2812e-02,  1.6754e-02],
        [ 1.0902e-02,  1.0046e-01,  7.4387e-05,  ...,  2.0416e-02,
         -6.9122e-03, -1.4582e-03],
        [ 4.7646e-03,  2.4261e-03,  1.2744e-01,  ...,  3.5477e-04,
          8.8806e-03, -1.4618e-02],
        ...,
        [-1.5244e-02,  3.8361e-02, -1.0910e-02,  ...,  1.2805e-01,
         -2.0485e-03,  3.4943e-03],
        [ 2.8667e-03,  2.1576e-02, -2.2415e-02,  ...,  2.3010e-02,
          1.1304e-01, -2.5192e-02],
        [-1.3275e-02, -7.6485e-03, -1.7288e-02,  ..., -2.8572e-03,
         -2.9541e-02,  1.0254e-01]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.3914, -1.1084,  1.5488,  ..., -3.5859,  0.7012, -3.6172]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 19:38:39 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The adjective form of international is internationally
The adjective form of subsequent is subsequently
The adjective form of practical is practically
The adjective form of extensive is extensively
The adjective form of successful is successfully
The adjective form of interesting is interestingly
The adjective form of similar is similarly
The adjective form of internal is
2024-07-28 19:38:39 root INFO     total operator prediction time: 940.2401204109192 seconds
2024-07-28 19:38:39 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on over+adj_reg
2024-07-28 19:38:39 root INFO     building operator over+adj_reg
2024-07-28 19:38:39 root INFO     [order_1_approx] starting weight calculation for If something is too spent, it is overspent
If something is too zealous, it is overzealous
If something is too filled, it is overfilled
If something is too stated, it is overstated
If something is too qualified, it is overqualified
If something is too turned, it is overturned
If something is too excited, it is overexcited
If something is too stressed, it is
2024-07-28 19:38:39 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-28 19:40:35 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.5605, -0.9707, -0.4360,  ..., -0.8584, -0.5410, -0.2417],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.4082, -2.8047,  0.1191,  ..., -0.2490,  0.5811, -2.4922],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 6.2927e-02, -1.0742e-02,  4.0665e-03,  ...,  1.6422e-03,
         -6.1874e-03,  2.6283e-03],
        [ 2.3365e-03,  5.7129e-02,  2.7905e-03,  ...,  1.4534e-02,
          1.1093e-02,  5.8889e-05],
        [ 3.2349e-03, -8.1329e-03,  4.4861e-02,  ...,  4.1924e-03,
          4.2572e-03, -1.5511e-02],
        ...,
        [ 5.1765e-03,  7.0877e-03, -2.6703e-03,  ...,  5.7495e-02,
          1.0395e-03,  8.2626e-03],
        [ 6.3820e-03,  8.4381e-03,  3.0899e-03,  ..., -6.1150e-03,
          4.7211e-02, -9.3384e-03],
        [-5.6267e-04,  8.4000e-03,  9.6512e-04,  ...,  4.2458e-03,
         -5.6305e-03,  4.9957e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.6367, -2.7539,  0.1802,  ..., -0.3040,  0.6182, -2.2637]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 19:40:36 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is too spent, it is overspent
If something is too zealous, it is overzealous
If something is too filled, it is overfilled
If something is too stated, it is overstated
If something is too qualified, it is overqualified
If something is too turned, it is overturned
If something is too excited, it is overexcited
If something is too stressed, it is
2024-07-28 19:40:37 root INFO     [order_1_approx] starting weight calculation for If something is too qualified, it is overqualified
If something is too filled, it is overfilled
If something is too stressed, it is overstressed
If something is too spent, it is overspent
If something is too zealous, it is overzealous
If something is too turned, it is overturned
If something is too stated, it is overstated
If something is too excited, it is
2024-07-28 19:40:37 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-28 19:42:32 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0849, -0.8516, -1.0342,  ..., -0.5605, -1.1182, -0.1437],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.3828, -4.4141, -0.0293,  ..., -0.2380, -1.3438, -3.9277],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0649, -0.0013,  0.0062,  ..., -0.0052,  0.0114,  0.0085],
        [-0.0037,  0.0653, -0.0054,  ...,  0.0154,  0.0071, -0.0041],
        [ 0.0168, -0.0015,  0.0620,  ...,  0.0021,  0.0035, -0.0072],
        ...,
        [-0.0003,  0.0117, -0.0006,  ...,  0.0731,  0.0058, -0.0015],
        [ 0.0038,  0.0030,  0.0058,  ...,  0.0081,  0.0571, -0.0163],
        [ 0.0043,  0.0099,  0.0046,  ...,  0.0009, -0.0009,  0.0612]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.4204, -4.5391, -0.0699,  ..., -0.0807, -1.3535, -3.9492]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 19:42:33 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is too qualified, it is overqualified
If something is too filled, it is overfilled
If something is too stressed, it is overstressed
If something is too spent, it is overspent
If something is too zealous, it is overzealous
If something is too turned, it is overturned
If something is too stated, it is overstated
If something is too excited, it is
2024-07-28 19:42:33 root INFO     [order_1_approx] starting weight calculation for If something is too stressed, it is overstressed
If something is too stated, it is overstated
If something is too turned, it is overturned
If something is too filled, it is overfilled
If something is too spent, it is overspent
If something is too zealous, it is overzealous
If something is too excited, it is overexcited
If something is too qualified, it is
2024-07-28 19:42:34 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-28 19:44:30 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2686, -0.5713, -0.2471,  ..., -0.7363, -0.2042, -0.2339],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.2910, -3.5859,  0.4487,  ...,  0.3271, -1.3145, -3.5469],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0756, -0.0240,  0.0195,  ..., -0.0201, -0.0008,  0.0053],
        [-0.0084,  0.0621, -0.0083,  ...,  0.0206,  0.0073, -0.0088],
        [ 0.0062, -0.0063,  0.0641,  ..., -0.0123,  0.0146, -0.0075],
        ...,
        [ 0.0002,  0.0176, -0.0163,  ...,  0.0874,  0.0130,  0.0004],
        [-0.0060,  0.0044,  0.0135,  ...,  0.0078,  0.0726, -0.0116],
        [ 0.0025,  0.0012, -0.0021,  ..., -0.0015, -0.0103,  0.0689]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.5439, -3.4062,  0.5684,  ...,  0.5703, -1.0869, -3.5723]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 19:44:31 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is too stressed, it is overstressed
If something is too stated, it is overstated
If something is too turned, it is overturned
If something is too filled, it is overfilled
If something is too spent, it is overspent
If something is too zealous, it is overzealous
If something is too excited, it is overexcited
If something is too qualified, it is
2024-07-28 19:44:31 root INFO     [order_1_approx] starting weight calculation for If something is too turned, it is overturned
If something is too qualified, it is overqualified
If something is too filled, it is overfilled
If something is too spent, it is overspent
If something is too excited, it is overexcited
If something is too stated, it is overstated
If something is too stressed, it is overstressed
If something is too zealous, it is
2024-07-28 19:44:31 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-28 19:46:27 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.7837, -0.7979, -0.2683,  ..., -0.4954, -1.0410,  0.1846],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.4678, -5.0586,  0.2207,  ..., -0.2542, -0.6812, -2.3027],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 7.7454e-02, -5.9509e-03,  1.2627e-02,  ..., -5.6000e-03,
          1.2035e-03,  8.6975e-04],
        [-1.0590e-02,  6.0333e-02,  8.6594e-04,  ...,  1.7654e-02,
          9.7961e-03,  4.0131e-03],
        [ 1.3008e-02, -1.2260e-02,  6.6528e-02,  ..., -7.0076e-03,
          2.4109e-03, -4.4022e-03],
        ...,
        [ 1.0162e-02,  1.4954e-02,  1.1978e-03,  ...,  8.1482e-02,
          6.5689e-03,  5.1498e-05],
        [ 9.5215e-03,  7.6485e-04,  5.6076e-03,  ..., -2.9812e-03,
          5.7861e-02, -9.3613e-03],
        [-3.1738e-03, -6.3095e-03, -3.0065e-04,  ..., -2.7657e-03,
         -1.9562e-02,  6.5247e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.3086, -4.8594,  0.7041,  ...,  0.0708, -0.2075, -2.2500]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 19:46:28 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is too turned, it is overturned
If something is too qualified, it is overqualified
If something is too filled, it is overfilled
If something is too spent, it is overspent
If something is too excited, it is overexcited
If something is too stated, it is overstated
If something is too stressed, it is overstressed
If something is too zealous, it is
2024-07-28 19:46:28 root INFO     [order_1_approx] starting weight calculation for If something is too turned, it is overturned
If something is too qualified, it is overqualified
If something is too filled, it is overfilled
If something is too spent, it is overspent
If something is too zealous, it is overzealous
If something is too stressed, it is overstressed
If something is too excited, it is overexcited
If something is too stated, it is
2024-07-28 19:46:28 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-28 19:48:23 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1652, -0.8877, -0.3540,  ..., -0.7412, -1.2842, -0.4214],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.8770, -2.4707,  0.6079,  ...,  0.3267, -1.9453, -2.2129],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.1296,  0.0017,  0.0150,  ..., -0.0133,  0.0084,  0.0078],
        [-0.0112,  0.1027, -0.0072,  ...,  0.0238,  0.0115, -0.0074],
        [ 0.0076, -0.0199,  0.0861,  ..., -0.0072,  0.0033,  0.0005],
        ...,
        [ 0.0176,  0.0301, -0.0003,  ...,  0.1223, -0.0038,  0.0059],
        [ 0.0016, -0.0096,  0.0346,  ...,  0.0022,  0.0967, -0.0128],
        [ 0.0024,  0.0170, -0.0026,  ..., -0.0100, -0.0175,  0.0969]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.4805, -2.8984,  1.0176,  ...,  0.4893, -1.1953, -2.3750]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 19:48:24 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is too turned, it is overturned
If something is too qualified, it is overqualified
If something is too filled, it is overfilled
If something is too spent, it is overspent
If something is too zealous, it is overzealous
If something is too stressed, it is overstressed
If something is too excited, it is overexcited
If something is too stated, it is
2024-07-28 19:48:24 root INFO     [order_1_approx] starting weight calculation for If something is too filled, it is overfilled
If something is too excited, it is overexcited
If something is too stated, it is overstated
If something is too turned, it is overturned
If something is too stressed, it is overstressed
If something is too qualified, it is overqualified
If something is too zealous, it is overzealous
If something is too spent, it is
2024-07-28 19:48:24 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-28 19:50:16 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0040, -0.4463, -0.1095,  ..., -0.7505, -0.2317, -0.3628],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.8164, -3.8320, -1.4717,  ..., -1.3242, -1.2461, -3.4590],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 8.7036e-02, -1.6775e-03,  1.2581e-02,  ...,  3.1204e-03,
          2.8896e-03,  6.9046e-03],
        [-4.7417e-03,  6.2012e-02, -6.6795e-03,  ...,  2.7206e-02,
          1.8402e-02, -2.5253e-03],
        [ 1.1841e-02, -7.1449e-03,  7.1411e-02,  ..., -4.4365e-03,
          2.8610e-04, -6.9618e-03],
        ...,
        [-6.4182e-04,  1.7059e-02, -4.4861e-03,  ...,  9.0515e-02,
         -2.4490e-03, -9.6130e-04],
        [-7.2098e-03, -8.2016e-05,  6.5079e-03,  ...,  1.7456e-02,
          6.8726e-02, -5.8460e-04],
        [ 4.0817e-03,  1.4824e-02, -4.0588e-03,  ..., -6.4507e-03,
          1.3790e-03,  7.8003e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.0547, -3.5449, -1.5947,  ..., -1.0049, -1.0889, -3.2676]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 19:50:18 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is too filled, it is overfilled
If something is too excited, it is overexcited
If something is too stated, it is overstated
If something is too turned, it is overturned
If something is too stressed, it is overstressed
If something is too qualified, it is overqualified
If something is too zealous, it is overzealous
If something is too spent, it is
2024-07-28 19:50:18 root INFO     [order_1_approx] starting weight calculation for If something is too stated, it is overstated
If something is too qualified, it is overqualified
If something is too spent, it is overspent
If something is too stressed, it is overstressed
If something is too zealous, it is overzealous
If something is too excited, it is overexcited
If something is too turned, it is overturned
If something is too filled, it is
2024-07-28 19:50:18 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-28 19:52:12 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0023, -0.9121, -0.4939,  ..., -0.7041, -0.2161, -0.0992],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.6758, -2.4570,  1.6875,  ...,  0.6230, -1.4014, -2.9414],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 7.1533e-02, -9.2010e-03,  1.5160e-02,  ..., -4.2343e-03,
          1.8280e-02,  3.7460e-03],
        [-2.2354e-03,  5.9296e-02,  4.5776e-04,  ...,  2.1347e-02,
          8.5297e-03,  1.8883e-04],
        [ 8.0338e-03, -9.8991e-04,  6.0791e-02,  ...,  4.6253e-05,
          4.4785e-03, -8.1635e-03],
        ...,
        [ 1.5869e-03, -4.8828e-04,  3.3760e-04,  ...,  6.8237e-02,
         -4.3106e-04, -4.5700e-03],
        [ 1.1292e-03,  4.8370e-03,  1.4412e-02,  ...,  4.1733e-03,
          5.7007e-02, -1.0002e-02],
        [ 3.3665e-04,  5.4092e-03,  4.5433e-03,  ..., -8.3771e-03,
         -1.3428e-02,  5.2399e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.2109, -2.1562,  1.7793,  ...,  0.4487, -1.0840, -2.8867]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 19:52:13 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is too stated, it is overstated
If something is too qualified, it is overqualified
If something is too spent, it is overspent
If something is too stressed, it is overstressed
If something is too zealous, it is overzealous
If something is too excited, it is overexcited
If something is too turned, it is overturned
If something is too filled, it is
2024-07-28 19:52:13 root INFO     [order_1_approx] starting weight calculation for If something is too spent, it is overspent
If something is too zealous, it is overzealous
If something is too excited, it is overexcited
If something is too stated, it is overstated
If something is too qualified, it is overqualified
If something is too filled, it is overfilled
If something is too stressed, it is overstressed
If something is too turned, it is
2024-07-28 19:52:13 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-28 19:54:09 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0354, -0.5088, -0.3518,  ..., -0.1058, -0.4639, -0.6143],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.3398, -3.8691,  0.9287,  ..., -0.2612, -0.6748, -2.0820],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0912,  0.0020,  0.0023,  ..., -0.0052,  0.0092,  0.0032],
        [-0.0062,  0.0640, -0.0118,  ...,  0.0265,  0.0130, -0.0068],
        [ 0.0107, -0.0090,  0.0774,  ..., -0.0019, -0.0015, -0.0135],
        ...,
        [ 0.0142,  0.0044,  0.0020,  ...,  0.0891,  0.0066,  0.0035],
        [-0.0098, -0.0043, -0.0047,  ..., -0.0055,  0.0797, -0.0193],
        [-0.0155,  0.0253,  0.0024,  ..., -0.0208, -0.0238,  0.0748]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.4922, -3.6230,  0.8193,  ..., -0.2106, -0.5928, -2.3574]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 19:54:10 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is too spent, it is overspent
If something is too zealous, it is overzealous
If something is too excited, it is overexcited
If something is too stated, it is overstated
If something is too qualified, it is overqualified
If something is too filled, it is overfilled
If something is too stressed, it is overstressed
If something is too turned, it is
2024-07-28 19:54:10 root INFO     total operator prediction time: 931.0007276535034 seconds
2024-07-28 19:54:10 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on verb+er_irreg
2024-07-28 19:54:10 root INFO     building operator verb+er_irreg
2024-07-28 19:54:10 root INFO     [order_1_approx] starting weight calculation for If you announce something, you are a announcer
If you write something, you are a writer
If you mourn something, you are a mourner
If you eat something, you are a eater
If you learn something, you are a learner
If you tell something, you are a teller
If you follow something, you are a follower
If you observe something, you are a
2024-07-28 19:54:10 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-28 19:56:03 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4961,  0.5186,  0.1655,  ..., -0.2087, -0.4897, -0.2524],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.6196, -1.6318, -0.9854,  ..., -3.3770, -3.0781, -3.8105],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0508,  0.0022,  0.0158,  ...,  0.0108, -0.0059,  0.0108],
        [ 0.0018,  0.0549, -0.0018,  ...,  0.0141,  0.0089, -0.0037],
        [ 0.0121, -0.0064,  0.0439,  ..., -0.0145, -0.0093, -0.0074],
        ...,
        [ 0.0105,  0.0122,  0.0005,  ...,  0.0508,  0.0001, -0.0061],
        [ 0.0041,  0.0090,  0.0129,  ..., -0.0107,  0.0468, -0.0047],
        [ 0.0056,  0.0101, -0.0078,  ..., -0.0054, -0.0143,  0.0497]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.7769, -1.5830, -1.1709,  ..., -3.2734, -3.2695, -3.5723]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 19:56:04 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you announce something, you are a announcer
If you write something, you are a writer
If you mourn something, you are a mourner
If you eat something, you are a eater
If you learn something, you are a learner
If you tell something, you are a teller
If you follow something, you are a follower
If you observe something, you are a
2024-07-28 19:56:04 root INFO     [order_1_approx] starting weight calculation for If you write something, you are a writer
If you tell something, you are a teller
If you follow something, you are a follower
If you announce something, you are a announcer
If you learn something, you are a learner
If you observe something, you are a observer
If you eat something, you are a eater
If you mourn something, you are a
2024-07-28 19:56:04 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-28 19:57:56 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1326,  0.3516,  0.5010,  ...,  0.1318, -0.9834,  1.0059],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.9932, -2.3203,  0.4272,  ..., -1.5381, -3.0156,  0.2393],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0504, -0.0026,  0.0191,  ...,  0.0153,  0.0019,  0.0144],
        [-0.0072,  0.0448, -0.0005,  ...,  0.0129,  0.0183,  0.0062],
        [-0.0057, -0.0041,  0.0565,  ...,  0.0049, -0.0175, -0.0085],
        ...,
        [ 0.0150,  0.0170,  0.0102,  ...,  0.0498, -0.0006,  0.0134],
        [ 0.0093,  0.0166,  0.0085,  ..., -0.0051,  0.0441, -0.0077],
        [-0.0016,  0.0113, -0.0119,  ..., -0.0018, -0.0046,  0.0532]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.0156, -1.7334,  0.5347,  ..., -1.3154, -3.1797, -0.0581]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 19:57:57 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you write something, you are a writer
If you tell something, you are a teller
If you follow something, you are a follower
If you announce something, you are a announcer
If you learn something, you are a learner
If you observe something, you are a observer
If you eat something, you are a eater
If you mourn something, you are a
2024-07-28 19:57:57 root INFO     [order_1_approx] starting weight calculation for If you write something, you are a writer
If you mourn something, you are a mourner
If you learn something, you are a learner
If you announce something, you are a announcer
If you tell something, you are a teller
If you observe something, you are a observer
If you follow something, you are a follower
If you eat something, you are a
2024-07-28 19:57:57 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-28 19:59:47 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2095, -1.3154,  0.8418,  ..., -0.2283, -0.9009,  0.3374],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.7402, -0.1086, -0.5605,  ...,  0.9395, -6.6719, -3.7461],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 4.4525e-02,  9.6989e-04,  1.1148e-03,  ...,  6.6032e-03,
         -2.2354e-03,  1.2421e-02],
        [ 4.6921e-03,  4.7180e-02, -7.0610e-03,  ...,  6.5384e-03,
          5.9624e-03, -1.1444e-05],
        [-1.1177e-03, -5.3596e-03,  3.9825e-02,  ...,  5.6076e-04,
         -6.7406e-03, -5.7678e-03],
        ...,
        [ 1.5274e-02,  8.8882e-03,  4.2725e-03,  ...,  4.0680e-02,
         -3.9406e-03, -3.7193e-03],
        [-3.3493e-03,  3.4409e-03, -2.7657e-03,  ..., -1.2489e-02,
          2.9449e-02, -7.6752e-03],
        [-7.7744e-03, -1.1902e-03, -2.1515e-03,  ..., -7.3967e-03,
         -8.6288e-03,  4.1901e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.7061,  0.0166, -0.5776,  ...,  1.1455, -6.8281, -3.6914]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 19:59:48 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you write something, you are a writer
If you mourn something, you are a mourner
If you learn something, you are a learner
If you announce something, you are a announcer
If you tell something, you are a teller
If you observe something, you are a observer
If you follow something, you are a follower
If you eat something, you are a
2024-07-28 19:59:48 root INFO     [order_1_approx] starting weight calculation for If you learn something, you are a learner
If you observe something, you are a observer
If you announce something, you are a announcer
If you mourn something, you are a mourner
If you tell something, you are a teller
If you eat something, you are a eater
If you write something, you are a writer
If you follow something, you are a
2024-07-28 19:59:48 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-28 20:01:43 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.7129, -0.6631,  0.7822,  ...,  0.7275, -0.2681,  0.1710],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.8945, -2.1504,  3.4746,  ..., -0.2480, -5.5312, -1.6289],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 6.7139e-02, -2.9850e-03,  1.0429e-02,  ...,  1.1833e-02,
          6.6605e-03,  1.3748e-02],
        [-4.2038e-03,  5.6824e-02, -3.8929e-03,  ...,  1.4732e-02,
         -1.5450e-03, -2.0416e-02],
        [ 1.4343e-02,  2.4624e-03,  5.4230e-02,  ..., -1.0155e-02,
         -5.6610e-03, -1.1848e-02],
        ...,
        [ 1.0841e-02,  1.3351e-02,  1.6212e-04,  ...,  5.1208e-02,
         -1.6159e-02,  2.6588e-03],
        [-1.9226e-03,  9.5367e-03,  1.4938e-02,  ..., -3.9291e-03,
          5.0964e-02, -1.7242e-02],
        [-1.8845e-03, -2.6703e-05, -5.3444e-03,  ..., -1.9083e-03,
         -9.5978e-03,  5.7526e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.9102, -2.0957,  3.1719,  ..., -0.2046, -5.7070, -1.5234]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 20:01:44 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you learn something, you are a learner
If you observe something, you are a observer
If you announce something, you are a announcer
If you mourn something, you are a mourner
If you tell something, you are a teller
If you eat something, you are a eater
If you write something, you are a writer
If you follow something, you are a
2024-07-28 20:01:45 root INFO     [order_1_approx] starting weight calculation for If you write something, you are a writer
If you announce something, you are a announcer
If you mourn something, you are a mourner
If you observe something, you are a observer
If you learn something, you are a learner
If you eat something, you are a eater
If you follow something, you are a follower
If you tell something, you are a
2024-07-28 20:01:45 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-28 20:03:40 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3975, -0.4900,  1.2148,  ..., -0.0891,  0.0264, -0.2986],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.3438, -0.7788,  2.7324,  ...,  2.7500, -5.0469, -2.5020],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0449,  0.0053,  0.0034,  ..., -0.0021, -0.0057,  0.0086],
        [-0.0083,  0.0225,  0.0110,  ...,  0.0092,  0.0012, -0.0119],
        [ 0.0165, -0.0165,  0.0429,  ..., -0.0009, -0.0124,  0.0050],
        ...,
        [ 0.0206,  0.0142,  0.0013,  ...,  0.0375, -0.0099,  0.0060],
        [-0.0066, -0.0036,  0.0130,  ..., -0.0032,  0.0407, -0.0015],
        [ 0.0023, -0.0004,  0.0028,  ..., -0.0153, -0.0058,  0.0361]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.3945, -0.7798,  2.6895,  ...,  2.7734, -5.1094, -2.5527]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 20:03:41 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you write something, you are a writer
If you announce something, you are a announcer
If you mourn something, you are a mourner
If you observe something, you are a observer
If you learn something, you are a learner
If you eat something, you are a eater
If you follow something, you are a follower
If you tell something, you are a
2024-07-28 20:03:41 root INFO     [order_1_approx] starting weight calculation for If you eat something, you are a eater
If you tell something, you are a teller
If you announce something, you are a announcer
If you mourn something, you are a mourner
If you observe something, you are a observer
If you follow something, you are a follower
If you write something, you are a writer
If you learn something, you are a
2024-07-28 20:03:42 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-28 20:05:37 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0819, -0.5552,  0.6709,  ..., -0.3257, -1.1338,  0.1553],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.1670, -2.0781,  1.5986,  ...,  1.5283, -4.9688, -5.6016],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0195,  0.0028,  0.0051,  ..., -0.0009,  0.0057,  0.0055],
        [-0.0035,  0.0305,  0.0055,  ...,  0.0120, -0.0027,  0.0052],
        [ 0.0103,  0.0024,  0.0256,  ..., -0.0119, -0.0094, -0.0020],
        ...,
        [ 0.0162,  0.0031,  0.0005,  ...,  0.0386, -0.0050,  0.0006],
        [ 0.0028, -0.0019,  0.0033,  ..., -0.0034,  0.0240, -0.0047],
        [-0.0119, -0.0014, -0.0058,  ..., -0.0054,  0.0043,  0.0238]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.0732, -1.8633,  1.3271,  ...,  1.6650, -4.9453, -5.5469]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 20:05:38 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you eat something, you are a eater
If you tell something, you are a teller
If you announce something, you are a announcer
If you mourn something, you are a mourner
If you observe something, you are a observer
If you follow something, you are a follower
If you write something, you are a writer
If you learn something, you are a
2024-07-28 20:05:38 root INFO     [order_1_approx] starting weight calculation for If you mourn something, you are a mourner
If you follow something, you are a follower
If you write something, you are a writer
If you learn something, you are a learner
If you eat something, you are a eater
If you tell something, you are a teller
If you observe something, you are a observer
If you announce something, you are a
2024-07-28 20:05:38 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-28 20:07:34 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1821,  0.4470,  0.3940,  ..., -0.0808, -0.9609, -0.0510],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.9492, -3.3906,  1.4609,  ...,  3.3633, -4.9688, -2.0469],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0455,  0.0035,  0.0112,  ...,  0.0063, -0.0054,  0.0129],
        [-0.0040,  0.0338,  0.0024,  ...,  0.0124,  0.0108, -0.0037],
        [ 0.0121, -0.0094,  0.0434,  ..., -0.0049, -0.0043,  0.0031],
        ...,
        [ 0.0070,  0.0053,  0.0009,  ...,  0.0526, -0.0022,  0.0033],
        [-0.0047,  0.0015,  0.0068,  ..., -0.0050,  0.0337, -0.0096],
        [ 0.0112, -0.0063, -0.0102,  ..., -0.0103, -0.0101,  0.0463]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.1191, -3.5312,  1.4600,  ...,  3.4648, -4.8320, -1.9590]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 20:07:35 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you mourn something, you are a mourner
If you follow something, you are a follower
If you write something, you are a writer
If you learn something, you are a learner
If you eat something, you are a eater
If you tell something, you are a teller
If you observe something, you are a observer
If you announce something, you are a
2024-07-28 20:07:35 root INFO     [order_1_approx] starting weight calculation for If you mourn something, you are a mourner
If you tell something, you are a teller
If you announce something, you are a announcer
If you follow something, you are a follower
If you learn something, you are a learner
If you eat something, you are a eater
If you observe something, you are a observer
If you write something, you are a
2024-07-28 20:07:35 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-28 20:09:31 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.3645, -0.5537,  0.8257,  ..., -0.5381, -0.2964, -0.2620],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.7354, -3.3906, -0.0483,  ...,  0.9365, -5.2734, -1.3945],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 4.6844e-02,  2.3804e-03,  3.3360e-03,  ...,  1.9093e-03,
         -4.2191e-03,  1.1276e-02],
        [-3.9291e-03,  3.9062e-02, -1.5373e-03,  ...,  1.2283e-02,
          1.4824e-02, -3.1662e-03],
        [ 1.0590e-02, -1.6129e-02,  4.6844e-02,  ..., -7.5111e-03,
         -7.4539e-03,  9.1248e-03],
        ...,
        [ 1.8829e-02,  1.1185e-02,  3.2883e-03,  ...,  4.3243e-02,
         -5.8899e-03, -6.8474e-03],
        [ 1.0918e-02,  8.8501e-03,  3.1109e-03,  ..., -7.8201e-03,
          3.6743e-02,  1.8978e-03],
        [-2.0447e-03,  9.2010e-03, -4.0531e-05,  ..., -1.2810e-02,
         -9.3231e-03,  4.2908e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.6357, -3.3906, -0.1580,  ...,  0.9888, -5.2656, -1.3701]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 20:09:32 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you mourn something, you are a mourner
If you tell something, you are a teller
If you announce something, you are a announcer
If you follow something, you are a follower
If you learn something, you are a learner
If you eat something, you are a eater
If you observe something, you are a observer
If you write something, you are a
2024-07-28 20:09:32 root INFO     total operator prediction time: 921.8440856933594 seconds
2024-07-28 20:09:32 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on adj - superlative
2024-07-28 20:09:32 root INFO     building operator adj - superlative
2024-07-28 20:09:32 root INFO     [order_1_approx] starting weight calculation for If something is the most merry, it is merriest
If something is the most weird, it is weirdest
If something is the most happy, it is happiest
If something is the most costly, it is costliest
If something is the most strange, it is strangest
If something is the most clever, it is cleverest
If something is the most lucky, it is luckiest
If something is the most lengthy, it is
2024-07-28 20:09:32 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-28 20:11:24 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.6133, -0.6914, -0.2347,  ..., -0.8843, -0.8081, -0.5933],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.0879, -4.1523, -0.8374,  ..., -2.9785, -1.2832, -3.3359],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0532, -0.0107,  0.0088,  ..., -0.0025,  0.0092,  0.0145],
        [-0.0034,  0.0454,  0.0089,  ...,  0.0057,  0.0035, -0.0046],
        [-0.0051,  0.0054,  0.0423,  ..., -0.0139, -0.0026, -0.0053],
        ...,
        [ 0.0081,  0.0226,  0.0096,  ...,  0.0549, -0.0005,  0.0014],
        [ 0.0101,  0.0042,  0.0068,  ..., -0.0040,  0.0421, -0.0106],
        [ 0.0016,  0.0047, -0.0031,  ..., -0.0132, -0.0036,  0.0398]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.2480, -4.2852, -0.9819,  ..., -2.7520, -1.1260, -3.2188]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 20:11:25 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is the most merry, it is merriest
If something is the most weird, it is weirdest
If something is the most happy, it is happiest
If something is the most costly, it is costliest
If something is the most strange, it is strangest
If something is the most clever, it is cleverest
If something is the most lucky, it is luckiest
If something is the most lengthy, it is
2024-07-28 20:11:25 root INFO     [order_1_approx] starting weight calculation for If something is the most merry, it is merriest
If something is the most clever, it is cleverest
If something is the most strange, it is strangest
If something is the most lucky, it is luckiest
If something is the most costly, it is costliest
If something is the most lengthy, it is lengthiest
If something is the most happy, it is happiest
If something is the most weird, it is
2024-07-28 20:11:25 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-28 20:13:17 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1094,  0.0955,  0.0774,  ..., -0.7402, -0.4595, -0.3535],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.9551, -4.9414, -0.7627,  ..., -2.0371, -0.5820, -2.9941],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0545,  0.0066,  0.0008,  ..., -0.0017, -0.0005,  0.0115],
        [-0.0092,  0.0494, -0.0013,  ...,  0.0171,  0.0026, -0.0070],
        [ 0.0032, -0.0110,  0.0565,  ..., -0.0083, -0.0136, -0.0051],
        ...,
        [ 0.0031,  0.0220, -0.0098,  ...,  0.0457,  0.0035, -0.0105],
        [ 0.0236,  0.0015,  0.0155,  ..., -0.0105,  0.0436, -0.0160],
        [ 0.0084,  0.0006, -0.0044,  ..., -0.0029, -0.0154,  0.0459]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.6611, -5.0117, -1.0791,  ..., -1.9600, -0.5703, -3.0234]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 20:13:18 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is the most merry, it is merriest
If something is the most clever, it is cleverest
If something is the most strange, it is strangest
If something is the most lucky, it is luckiest
If something is the most costly, it is costliest
If something is the most lengthy, it is lengthiest
If something is the most happy, it is happiest
If something is the most weird, it is
2024-07-28 20:13:19 root INFO     [order_1_approx] starting weight calculation for If something is the most weird, it is weirdest
If something is the most merry, it is merriest
If something is the most happy, it is happiest
If something is the most clever, it is cleverest
If something is the most strange, it is strangest
If something is the most lucky, it is luckiest
If something is the most lengthy, it is lengthiest
If something is the most costly, it is
2024-07-28 20:13:19 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-28 20:15:06 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.6797,  0.0974, -0.3350,  ..., -1.4795, -0.1067, -0.3677],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.6084, -4.9453, -0.7280,  ..., -2.5742, -0.3145,  0.8008],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0535, -0.0074,  0.0128,  ..., -0.0006, -0.0038,  0.0089],
        [-0.0043,  0.0361,  0.0072,  ...,  0.0080,  0.0053,  0.0052],
        [ 0.0008, -0.0011,  0.0343,  ..., -0.0140, -0.0046,  0.0014],
        ...,
        [ 0.0048,  0.0129, -0.0040,  ...,  0.0400,  0.0092,  0.0027],
        [ 0.0085,  0.0070,  0.0030,  ..., -0.0053,  0.0418, -0.0122],
        [-0.0025, -0.0017,  0.0014,  ..., -0.0084, -0.0056,  0.0357]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.5928, -4.8477, -0.8989,  ..., -2.4082, -0.1227,  0.8687]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 20:15:07 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is the most weird, it is weirdest
If something is the most merry, it is merriest
If something is the most happy, it is happiest
If something is the most clever, it is cleverest
If something is the most strange, it is strangest
If something is the most lucky, it is luckiest
If something is the most lengthy, it is lengthiest
If something is the most costly, it is
2024-07-28 20:15:07 root INFO     [order_1_approx] starting weight calculation for If something is the most lengthy, it is lengthiest
If something is the most weird, it is weirdest
If something is the most strange, it is strangest
If something is the most merry, it is merriest
If something is the most costly, it is costliest
If something is the most clever, it is cleverest
If something is the most lucky, it is luckiest
If something is the most happy, it is
2024-07-28 20:15:07 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-28 20:16:57 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0807, -0.6016,  0.1768,  ..., -0.6636, -0.9014, -0.5581],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.0742, -3.4941, -0.0898,  ...,  0.1914, -1.7578, -1.7129],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0425, -0.0031,  0.0147,  ...,  0.0017,  0.0005,  0.0188],
        [-0.0005,  0.0413,  0.0068,  ...,  0.0008,  0.0126,  0.0043],
        [ 0.0019,  0.0006,  0.0347,  ..., -0.0097, -0.0107, -0.0172],
        ...,
        [ 0.0044,  0.0161, -0.0080,  ...,  0.0482,  0.0094, -0.0014],
        [ 0.0053,  0.0075,  0.0059,  ..., -0.0121,  0.0312, -0.0073],
        [-0.0014, -0.0006, -0.0078,  ..., -0.0122,  0.0043,  0.0423]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.0439, -3.2188, -0.3149,  ...,  0.5244, -1.9062, -1.8896]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 20:16:58 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is the most lengthy, it is lengthiest
If something is the most weird, it is weirdest
If something is the most strange, it is strangest
If something is the most merry, it is merriest
If something is the most costly, it is costliest
If something is the most clever, it is cleverest
If something is the most lucky, it is luckiest
If something is the most happy, it is
2024-07-28 20:16:58 root INFO     [order_1_approx] starting weight calculation for If something is the most costly, it is costliest
If something is the most happy, it is happiest
If something is the most weird, it is weirdest
If something is the most lengthy, it is lengthiest
If something is the most strange, it is strangest
If something is the most lucky, it is luckiest
If something is the most merry, it is merriest
If something is the most clever, it is
2024-07-28 20:16:58 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-28 20:18:52 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4263, -0.0529,  0.2366,  ..., -0.7529, -0.4265, -0.0967],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.3940, -2.3848, -0.8516,  ..., -1.0977, -1.0488,  0.6572],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 5.9967e-02, -2.5330e-03,  2.4796e-02,  ..., -3.9673e-04,
         -9.6512e-04,  9.8419e-03],
        [-7.8354e-03,  5.2185e-02,  8.1940e-03,  ...,  2.1622e-02,
          2.3746e-03,  9.2173e-04],
        [ 9.9030e-03, -7.7477e-03,  6.1249e-02,  ..., -8.8787e-04,
         -5.0774e-03, -7.8201e-05],
        ...,
        [-3.1891e-03,  3.8853e-03, -2.3193e-03,  ...,  6.8359e-02,
          3.6640e-03, -6.3591e-03],
        [ 1.2619e-02,  9.3613e-03,  9.2773e-03,  ..., -7.7629e-03,
          4.0863e-02, -1.5564e-02],
        [-7.8583e-04, -8.2855e-03, -4.1809e-03,  ..., -1.2032e-02,
         -5.1422e-03,  5.4626e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.5786, -2.1582, -0.9312,  ..., -0.7188, -0.8257,  0.6592]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 20:18:53 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is the most costly, it is costliest
If something is the most happy, it is happiest
If something is the most weird, it is weirdest
If something is the most lengthy, it is lengthiest
If something is the most strange, it is strangest
If something is the most lucky, it is luckiest
If something is the most merry, it is merriest
If something is the most clever, it is
2024-07-28 20:18:53 root INFO     [order_1_approx] starting weight calculation for If something is the most costly, it is costliest
If something is the most lengthy, it is lengthiest
If something is the most merry, it is merriest
If something is the most happy, it is happiest
If something is the most weird, it is weirdest
If something is the most clever, it is cleverest
If something is the most lucky, it is luckiest
If something is the most strange, it is
2024-07-28 20:18:54 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-28 20:20:45 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2007,  0.0243, -0.0933,  ..., -0.9346,  0.2515, -0.7241],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.8599, -4.1875, -2.3828,  ..., -1.1416, -0.8604, -2.6797],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0694,  0.0015,  0.0097,  ...,  0.0061, -0.0102,  0.0116],
        [ 0.0047,  0.0576,  0.0069,  ...,  0.0184,  0.0004, -0.0068],
        [ 0.0016, -0.0184,  0.0448,  ..., -0.0062, -0.0119, -0.0076],
        ...,
        [ 0.0071,  0.0279, -0.0037,  ...,  0.0580, -0.0009, -0.0035],
        [ 0.0063,  0.0003,  0.0103,  ..., -0.0145,  0.0521, -0.0039],
        [-0.0048,  0.0054, -0.0094,  ..., -0.0138, -0.0193,  0.0514]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.1816, -4.2500, -2.7129,  ..., -1.2568, -1.0283, -2.8613]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 20:20:46 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is the most costly, it is costliest
If something is the most lengthy, it is lengthiest
If something is the most merry, it is merriest
If something is the most happy, it is happiest
If something is the most weird, it is weirdest
If something is the most clever, it is cleverest
If something is the most lucky, it is luckiest
If something is the most strange, it is
2024-07-28 20:20:46 root INFO     [order_1_approx] starting weight calculation for If something is the most happy, it is happiest
If something is the most merry, it is merriest
If something is the most costly, it is costliest
If something is the most clever, it is cleverest
If something is the most weird, it is weirdest
If something is the most strange, it is strangest
If something is the most lengthy, it is lengthiest
If something is the most lucky, it is
2024-07-28 20:20:46 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-28 20:22:36 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2294,  0.7891, -0.1248,  ..., -0.9824, -0.7852, -0.3159],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.3203, -2.9023, -3.0977,  ..., -0.6475, -1.3535, -2.3438],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 3.8513e-02, -1.2007e-03,  5.7373e-03,  ..., -1.1444e-03,
          2.2125e-04,  1.0872e-02],
        [ 4.0169e-03,  2.8763e-02,  8.6975e-03,  ...,  4.3221e-03,
          5.9013e-03, -2.2049e-03],
        [ 5.0697e-03, -5.2872e-03,  2.8122e-02,  ..., -7.6599e-03,
         -6.4163e-03, -1.6785e-02],
        ...,
        [ 1.6270e-03,  1.1032e-02, -4.6082e-03,  ...,  3.7170e-02,
          5.3635e-03,  2.1248e-03],
        [ 1.2054e-02, -1.6136e-03,  3.0994e-03,  ..., -1.3672e-02,
          2.4399e-02, -6.8817e-03],
        [ 1.3962e-03, -8.5754e-03, -7.0572e-05,  ..., -1.6373e-02,
         -3.4447e-03,  3.4607e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.3125, -2.8789, -2.9688,  ..., -0.5820, -1.4766, -2.4023]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 20:22:37 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is the most happy, it is happiest
If something is the most merry, it is merriest
If something is the most costly, it is costliest
If something is the most clever, it is cleverest
If something is the most weird, it is weirdest
If something is the most strange, it is strangest
If something is the most lengthy, it is lengthiest
If something is the most lucky, it is
2024-07-28 20:22:37 root INFO     [order_1_approx] starting weight calculation for If something is the most costly, it is costliest
If something is the most lengthy, it is lengthiest
If something is the most strange, it is strangest
If something is the most clever, it is cleverest
If something is the most happy, it is happiest
If something is the most weird, it is weirdest
If something is the most lucky, it is luckiest
If something is the most merry, it is
2024-07-28 20:22:37 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-28 20:24:31 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1287,  0.4058, -0.1224,  ..., -0.7158, -1.6309, -0.6523],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.9297, -3.6777, -1.9453,  ...,  0.0796, -1.2959, -1.6562],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0516, -0.0091,  0.0248,  ..., -0.0027,  0.0090,  0.0254],
        [-0.0025,  0.0331,  0.0057,  ...,  0.0102,  0.0121,  0.0016],
        [-0.0028, -0.0045,  0.0403,  ..., -0.0079, -0.0089, -0.0139],
        ...,
        [ 0.0058,  0.0083, -0.0073,  ...,  0.0426,  0.0080, -0.0067],
        [ 0.0004,  0.0030, -0.0045,  ..., -0.0037,  0.0406, -0.0058],
        [ 0.0006,  0.0016, -0.0060,  ..., -0.0134,  0.0094,  0.0415]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.7529, -3.2500, -1.9326,  ...,  0.1511, -1.3252, -1.7295]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 20:24:32 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is the most costly, it is costliest
If something is the most lengthy, it is lengthiest
If something is the most strange, it is strangest
If something is the most clever, it is cleverest
If something is the most happy, it is happiest
If something is the most weird, it is weirdest
If something is the most lucky, it is luckiest
If something is the most merry, it is
2024-07-28 20:24:32 root INFO     total operator prediction time: 899.9707078933716 seconds
2024-07-28 20:24:32 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on verb_3pSg - Ved
2024-07-28 20:24:32 root INFO     building operator verb_3pSg - Ved
2024-07-28 20:24:32 root INFO     [order_1_approx] starting weight calculation for When he represents something, something has been represented
When he replaces something, something has been replaced
When he decides something, something has been decided
When he appoints something, something has been appointed
When he requires something, something has been required
When he introduces something, something has been introduced
When he adds something, something has been added
When he expects something, something has been
2024-07-28 20:24:32 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-28 20:26:26 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.5659, -0.2798, -0.4246,  ..., -0.2771, -0.6084, -0.0953],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.6641,  1.1484, -2.3105,  ..., -0.2167, -2.6055, -0.2051],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0481,  0.0041,  0.0237,  ..., -0.0029, -0.0136,  0.0047],
        [-0.0058,  0.0392,  0.0051,  ...,  0.0219, -0.0024,  0.0019],
        [ 0.0051,  0.0032,  0.0361,  ..., -0.0036,  0.0022, -0.0078],
        ...,
        [-0.0032,  0.0117, -0.0079,  ...,  0.0455,  0.0043,  0.0089],
        [ 0.0186, -0.0131,  0.0030,  ..., -0.0038,  0.0334, -0.0048],
        [-0.0022,  0.0013,  0.0057,  ...,  0.0006, -0.0004,  0.0423]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.6816e+00,  1.3066e+00, -2.2363e+00,  ...,  3.2959e-03,
         -2.8457e+00,  5.9570e-02]], device='cuda:1', dtype=torch.float16,
       grad_fn=<SubBackward0>) 

                    
2024-07-28 20:26:26 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When he represents something, something has been represented
When he replaces something, something has been replaced
When he decides something, something has been decided
When he appoints something, something has been appointed
When he requires something, something has been required
When he introduces something, something has been introduced
When he adds something, something has been added
When he expects something, something has been
2024-07-28 20:26:27 root INFO     [order_1_approx] starting weight calculation for When he adds something, something has been added
When he replaces something, something has been replaced
When he decides something, something has been decided
When he requires something, something has been required
When he expects something, something has been expected
When he introduces something, something has been introduced
When he represents something, something has been represented
When he appoints something, something has been
2024-07-28 20:26:27 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-28 20:28:20 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0623, -0.4622, -0.0969,  ...,  0.3403, -0.6230,  0.2776],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.8359,  0.4805,  2.3848,  ...,  0.8623, -1.6680,  0.8867],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 2.0157e-02,  4.5300e-04,  1.1383e-02,  ...,  1.0748e-03,
         -4.6005e-03,  5.9662e-03],
        [-3.4676e-03,  1.1612e-02, -4.0016e-03,  ...,  9.4223e-03,
         -1.5526e-03, -5.9843e-05],
        [-6.0806e-03, -9.8038e-04,  1.5137e-02,  ..., -2.2011e-03,
          5.5695e-04, -3.1910e-03],
        ...,
        [ 2.8133e-03,  2.9716e-03,  7.8726e-04,  ...,  2.4338e-02,
          2.0943e-03,  7.8506e-03],
        [ 7.1640e-03,  5.1928e-04,  4.5166e-03,  ...,  4.3945e-03,
          1.5541e-02, -1.0529e-02],
        [ 1.9197e-03,  1.1997e-03, -3.0518e-05,  ..., -4.7760e-03,
         -6.0940e-04,  1.4549e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.8145,  0.5483,  2.3848,  ...,  0.8340, -1.5615,  0.8496]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 20:28:21 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When he adds something, something has been added
When he replaces something, something has been replaced
When he decides something, something has been decided
When he requires something, something has been required
When he expects something, something has been expected
When he introduces something, something has been introduced
When he represents something, something has been represented
When he appoints something, something has been
2024-07-28 20:28:22 root INFO     [order_1_approx] starting weight calculation for When he adds something, something has been added
When he requires something, something has been required
When he replaces something, something has been replaced
When he represents something, something has been represented
When he expects something, something has been expected
When he decides something, something has been decided
When he appoints something, something has been appointed
When he introduces something, something has been
2024-07-28 20:28:22 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-28 20:30:15 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-1.2217, -0.5205, -0.2040,  ...,  1.0215, -0.4517,  0.6772],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.4619,  1.8223,  2.4531,  ...,  0.6631, -0.9697,  1.4121],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0464, -0.0001,  0.0119,  ..., -0.0031, -0.0034,  0.0033],
        [-0.0009,  0.0375, -0.0019,  ...,  0.0120, -0.0019, -0.0099],
        [-0.0004, -0.0071,  0.0405,  ..., -0.0205, -0.0017, -0.0012],
        ...,
        [ 0.0045, -0.0005,  0.0093,  ...,  0.0491,  0.0008,  0.0121],
        [ 0.0137, -0.0027,  0.0093,  ..., -0.0031,  0.0403, -0.0030],
        [-0.0050,  0.0069, -0.0019,  ..., -0.0045, -0.0001,  0.0457]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.5010,  1.5918,  2.3906,  ...,  0.7095, -1.0068,  1.4355]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 20:30:16 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When he adds something, something has been added
When he requires something, something has been required
When he replaces something, something has been replaced
When he represents something, something has been represented
When he expects something, something has been expected
When he decides something, something has been decided
When he appoints something, something has been appointed
When he introduces something, something has been
2024-07-28 20:30:16 root INFO     [order_1_approx] starting weight calculation for When he replaces something, something has been replaced
When he decides something, something has been decided
When he expects something, something has been expected
When he introduces something, something has been introduced
When he represents something, something has been represented
When he adds something, something has been added
When he appoints something, something has been appointed
When he requires something, something has been
2024-07-28 20:30:17 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-28 20:32:10 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.4160, -0.2737, -0.5713,  ...,  0.0027, -1.0264, -0.3604],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.8662,  0.9287,  1.4180,  ..., -0.1414, -2.6172, -1.3828],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 4.6478e-02, -4.7951e-03,  2.0981e-02,  ...,  3.2997e-03,
         -7.2174e-03,  6.7902e-03],
        [-4.9133e-03,  4.4098e-02, -1.3123e-02,  ...,  1.0803e-02,
          5.7144e-03, -7.9041e-03],
        [-7.6294e-06, -1.3672e-02,  4.3427e-02,  ..., -2.0721e-02,
         -2.3804e-03, -5.4054e-03],
        ...,
        [-1.7490e-03,  1.7151e-02,  1.3618e-03,  ...,  6.1584e-02,
         -2.0943e-03,  9.2163e-03],
        [ 4.7913e-03, -7.7324e-03,  9.2087e-03,  ..., -2.7771e-03,
          5.6580e-02, -1.8066e-02],
        [-1.6998e-02, -7.2136e-03,  1.6769e-02,  ..., -4.7302e-03,
         -3.7766e-03,  5.7953e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.8252,  0.8291,  1.4697,  ..., -0.1016, -2.7578, -0.9707]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 20:32:11 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When he replaces something, something has been replaced
When he decides something, something has been decided
When he expects something, something has been expected
When he introduces something, something has been introduced
When he represents something, something has been represented
When he adds something, something has been added
When he appoints something, something has been appointed
When he requires something, something has been
2024-07-28 20:32:12 root INFO     [order_1_approx] starting weight calculation for When he represents something, something has been represented
When he appoints something, something has been appointed
When he expects something, something has been expected
When he requires something, something has been required
When he decides something, something has been decided
When he introduces something, something has been introduced
When he replaces something, something has been replaced
When he adds something, something has been
2024-07-28 20:32:12 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-28 20:34:04 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1461, -0.9609,  0.5469,  ...,  0.1423, -0.6406,  0.0243],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.1719,  2.5859,  0.2271,  ..., -0.1031, -2.8047,  0.7656],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 6.7932e-02,  6.6528e-03,  1.2573e-02,  ..., -1.2993e-02,
         -3.4142e-03,  2.1877e-03],
        [-1.0986e-02,  3.8269e-02,  9.1553e-05,  ...,  1.6602e-02,
         -7.8821e-04,  5.2490e-03],
        [-4.4479e-03, -4.6768e-03,  4.2114e-02,  ..., -6.2332e-03,
         -2.3460e-03, -1.0239e-02],
        ...,
        [ 1.4351e-02,  8.8654e-03, -1.3847e-03,  ...,  5.4504e-02,
          9.0942e-03,  1.0872e-02],
        [ 2.1576e-02,  4.9629e-03,  4.0550e-03,  ..., -6.0654e-03,
          4.1992e-02, -7.6637e-03],
        [-8.2626e-03, -4.6883e-03,  6.9542e-03,  ..., -1.3817e-02,
         -6.7062e-03,  4.8981e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.1592,  2.6680,  0.3232,  ..., -0.2136, -2.7402,  1.1641]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 20:34:05 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When he represents something, something has been represented
When he appoints something, something has been appointed
When he expects something, something has been expected
When he requires something, something has been required
When he decides something, something has been decided
When he introduces something, something has been introduced
When he replaces something, something has been replaced
When he adds something, something has been
2024-07-28 20:34:06 root INFO     [order_1_approx] starting weight calculation for When he adds something, something has been added
When he introduces something, something has been introduced
When he appoints something, something has been appointed
When he replaces something, something has been replaced
When he requires something, something has been required
When he expects something, something has been expected
When he decides something, something has been decided
When he represents something, something has been
2024-07-28 20:34:06 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-28 20:36:00 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0771,  0.4294, -0.2375,  ..., -0.0363, -0.3735,  0.2910],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.2109,  0.9268,  2.0039,  ...,  0.5200, -1.6865, -0.3184],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 5.9326e-02, -1.8644e-03,  1.3222e-02,  ..., -4.2057e-04,
         -4.2381e-03,  1.3771e-03],
        [-1.3687e-02,  4.9561e-02, -5.5275e-03,  ...,  1.4740e-02,
          1.3065e-03, -5.0049e-03],
        [ 4.9896e-03, -1.3107e-02,  5.7343e-02,  ..., -6.8512e-03,
          5.3139e-03, -9.3307e-03],
        ...,
        [ 4.2419e-03,  6.2599e-03, -8.2703e-03,  ...,  6.5552e-02,
         -2.9488e-03,  1.1887e-02],
        [ 1.7532e-02, -1.0735e-02,  1.0193e-02,  ..., -4.4823e-03,
          5.4260e-02, -2.0050e-02],
        [-5.2605e-03,  5.3101e-03,  9.6321e-05,  ..., -7.9498e-03,
         -5.3215e-03,  5.8472e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.2842,  0.8193,  2.0078,  ...,  0.2722, -1.7070, -0.4702]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 20:36:01 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When he adds something, something has been added
When he introduces something, something has been introduced
When he appoints something, something has been appointed
When he replaces something, something has been replaced
When he requires something, something has been required
When he expects something, something has been expected
When he decides something, something has been decided
When he represents something, something has been
2024-07-28 20:36:01 root INFO     [order_1_approx] starting weight calculation for When he appoints something, something has been appointed
When he expects something, something has been expected
When he represents something, something has been represented
When he replaces something, something has been replaced
When he introduces something, something has been introduced
When he adds something, something has been added
When he requires something, something has been required
When he decides something, something has been
2024-07-28 20:36:01 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-28 20:37:54 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2908, -0.2314, -0.2148,  ...,  0.1682, -1.2002,  0.5220],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.6895, -0.4785,  2.6289,  ...,  1.0752, -1.6895,  0.8398],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0341, -0.0017,  0.0198,  ..., -0.0002, -0.0028,  0.0094],
        [-0.0182,  0.0161,  0.0058,  ...,  0.0170,  0.0025, -0.0002],
        [ 0.0089,  0.0020,  0.0222,  ...,  0.0002, -0.0012, -0.0131],
        ...,
        [ 0.0041,  0.0007,  0.0022,  ...,  0.0331,  0.0025,  0.0174],
        [ 0.0122, -0.0014,  0.0050,  ..., -0.0029,  0.0295, -0.0098],
        [ 0.0026, -0.0035,  0.0031,  ..., -0.0134, -0.0093,  0.0265]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.5078, -0.1941,  2.5859,  ...,  1.0986, -1.5693,  0.8979]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 20:37:55 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When he appoints something, something has been appointed
When he expects something, something has been expected
When he represents something, something has been represented
When he replaces something, something has been replaced
When he introduces something, something has been introduced
When he adds something, something has been added
When he requires something, something has been required
When he decides something, something has been
2024-07-28 20:37:56 root INFO     [order_1_approx] starting weight calculation for When he introduces something, something has been introduced
When he appoints something, something has been appointed
When he requires something, something has been required
When he adds something, something has been added
When he represents something, something has been represented
When he expects something, something has been expected
When he decides something, something has been decided
When he replaces something, something has been
2024-07-28 20:37:56 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-28 20:39:49 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1274, -0.5986, -0.9619,  ...,  0.5479, -0.2412,  0.3091],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.5205,  0.3062,  0.8623,  ..., -0.5830,  0.1396,  1.2871],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0612, -0.0020,  0.0177,  ..., -0.0071,  0.0010,  0.0008],
        [-0.0165,  0.0235, -0.0096,  ...,  0.0270,  0.0077, -0.0096],
        [ 0.0034, -0.0007,  0.0303,  ..., -0.0155,  0.0034, -0.0197],
        ...,
        [ 0.0072,  0.0133, -0.0037,  ...,  0.0513,  0.0036,  0.0153],
        [ 0.0193,  0.0089,  0.0025,  ..., -0.0073,  0.0567, -0.0164],
        [-0.0029,  0.0010, -0.0060,  ..., -0.0082, -0.0059,  0.0478]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.3198,  0.3838,  0.9614,  ..., -0.4033, -0.4336,  1.4248]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 20:39:50 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When he introduces something, something has been introduced
When he appoints something, something has been appointed
When he requires something, something has been required
When he adds something, something has been added
When he represents something, something has been represented
When he expects something, something has been expected
When he decides something, something has been decided
When he replaces something, something has been
2024-07-28 20:39:50 root INFO     total operator prediction time: 917.9267761707306 seconds
2024-07-28 20:39:50 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on noun - plural_reg
2024-07-28 20:39:50 root INFO     building operator noun - plural_reg
2024-07-28 20:39:50 root INFO     [order_1_approx] starting weight calculation for The plural form of week is weeks
The plural form of user is users
The plural form of system is systems
The plural form of problem is problems
The plural form of album is albums
The plural form of member is members
The plural form of thing is things
The plural form of solution is
2024-07-28 20:39:50 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-28 20:41:46 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.6240, -0.0767, -0.8906,  ..., -0.4275, -0.5049,  0.5117],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.8379, -2.1641,  1.0273,  ..., -0.9990, -3.2637, -1.0918],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0953, -0.0003,  0.0121,  ...,  0.0019,  0.0207,  0.0097],
        [-0.0094,  0.0803, -0.0030,  ...,  0.0058, -0.0204,  0.0128],
        [ 0.0021, -0.0052,  0.0799,  ..., -0.0025, -0.0017,  0.0007],
        ...,
        [-0.0019,  0.0221, -0.0103,  ...,  0.1047,  0.0042,  0.0192],
        [ 0.0042,  0.0026, -0.0024,  ...,  0.0036,  0.0646, -0.0268],
        [-0.0096,  0.0061, -0.0082,  ..., -0.0038, -0.0098,  0.0939]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.7188, -2.2578,  1.2646,  ..., -0.6968, -3.2773, -0.9194]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 20:41:47 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of week is weeks
The plural form of user is users
The plural form of system is systems
The plural form of problem is problems
The plural form of album is albums
The plural form of member is members
The plural form of thing is things
The plural form of solution is
2024-07-28 20:41:48 root INFO     [order_1_approx] starting weight calculation for The plural form of system is systems
The plural form of user is users
The plural form of week is weeks
The plural form of solution is solutions
The plural form of problem is problems
The plural form of album is albums
The plural form of member is members
The plural form of thing is
2024-07-28 20:41:48 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-28 20:43:40 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2441, -0.0776, -0.7188,  ..., -0.7847, -0.4360, -0.5942],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.8281, -3.0645,  1.8555,  ..., -0.5127, -1.7822, -2.7891],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 1.0724e-01,  4.9057e-03,  1.7670e-02,  ..., -7.9041e-03,
          2.3941e-02,  1.6312e-02],
        [-1.6022e-02,  7.1716e-02, -6.9504e-03,  ..., -8.0109e-03,
         -3.1677e-02,  8.9951e-03],
        [-1.5961e-02, -7.2250e-03,  1.0449e-01,  ..., -1.1414e-02,
          9.5596e-03,  1.7136e-02],
        ...,
        [-2.9583e-03,  2.3758e-02, -1.8082e-02,  ...,  1.0498e-01,
          1.0319e-03,  1.5511e-02],
        [-1.6525e-02,  3.5782e-03,  3.7918e-03,  ...,  7.4387e-05,
          7.6050e-02, -1.7334e-02],
        [ 4.6539e-04,  1.4854e-02, -2.2720e-02,  ..., -4.9820e-03,
         -2.8122e-02,  1.0059e-01]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.0801, -2.8965,  1.8086,  ...,  0.1147, -1.7842, -2.3691]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 20:43:42 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of system is systems
The plural form of user is users
The plural form of week is weeks
The plural form of solution is solutions
The plural form of problem is problems
The plural form of album is albums
The plural form of member is members
The plural form of thing is
2024-07-28 20:43:42 root INFO     [order_1_approx] starting weight calculation for The plural form of album is albums
The plural form of user is users
The plural form of problem is problems
The plural form of week is weeks
The plural form of thing is things
The plural form of system is systems
The plural form of solution is solutions
The plural form of member is
2024-07-28 20:43:42 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-28 20:45:37 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 1.0342, -0.1677, -0.5483,  ...,  0.2639,  0.3247, -0.4031],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.1943, -1.5137,  1.0713,  ..., -1.4844,  0.2192, -3.7188],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0948,  0.0086,  0.0131,  ..., -0.0029, -0.0134, -0.0065],
        [-0.0175,  0.0814,  0.0051,  ...,  0.0152, -0.0035,  0.0153],
        [ 0.0166, -0.0038,  0.0803,  ..., -0.0252,  0.0037,  0.0003],
        ...,
        [ 0.0151,  0.0152, -0.0033,  ...,  0.1108,  0.0004,  0.0128],
        [-0.0061,  0.0165, -0.0006,  ..., -0.0064,  0.0672, -0.0074],
        [ 0.0037, -0.0005, -0.0050,  ...,  0.0027, -0.0027,  0.0859]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.0209, -1.1328,  1.1387,  ..., -0.9829,  0.0354, -3.2754]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 20:45:38 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of album is albums
The plural form of user is users
The plural form of problem is problems
The plural form of week is weeks
The plural form of thing is things
The plural form of system is systems
The plural form of solution is solutions
The plural form of member is
2024-07-28 20:45:38 root INFO     [order_1_approx] starting weight calculation for The plural form of member is members
The plural form of user is users
The plural form of week is weeks
The plural form of album is albums
The plural form of solution is solutions
The plural form of thing is things
The plural form of problem is problems
The plural form of system is
2024-07-28 20:45:39 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-28 20:47:34 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2119,  0.5967,  0.0365,  ..., -0.1841, -0.8193,  0.5288],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.7598, -2.5332,  0.4097,  ..., -1.3379, -0.8467, -1.7695],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0683,  0.0186,  0.0178,  ..., -0.0043,  0.0038,  0.0061],
        [-0.0127,  0.0455,  0.0119,  ...,  0.0068, -0.0014,  0.0113],
        [ 0.0034, -0.0078,  0.0649,  ..., -0.0134,  0.0001,  0.0024],
        ...,
        [ 0.0146,  0.0074, -0.0010,  ...,  0.0804, -0.0065,  0.0123],
        [-0.0019,  0.0112,  0.0041,  ..., -0.0093,  0.0443, -0.0174],
        [-0.0052,  0.0042, -0.0098,  ..., -0.0024, -0.0107,  0.0670]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.9570, -2.5020,  0.5078,  ..., -1.4609, -0.7397, -1.5234]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 20:47:35 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of member is members
The plural form of user is users
The plural form of week is weeks
The plural form of album is albums
The plural form of solution is solutions
The plural form of thing is things
The plural form of problem is problems
The plural form of system is
2024-07-28 20:47:35 root INFO     [order_1_approx] starting weight calculation for The plural form of member is members
The plural form of solution is solutions
The plural form of user is users
The plural form of problem is problems
The plural form of system is systems
The plural form of album is albums
The plural form of thing is things
The plural form of week is
2024-07-28 20:47:35 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-28 20:49:31 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.4524, -0.1613, -0.1355,  ..., -0.2358, -0.3647, -0.0608],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.8872, -4.0781,  0.2153,  ..., -0.8506,  0.3694, -1.6885],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 7.6904e-02,  3.4666e-04,  1.0651e-02,  ..., -3.6316e-03,
          6.5079e-03,  2.0615e-02],
        [-1.5137e-02,  7.3303e-02,  1.1864e-02,  ...,  2.3483e-02,
          4.1389e-03,  1.9951e-03],
        [ 2.2888e-05,  6.6414e-03,  7.4646e-02,  ..., -4.0359e-03,
         -7.0152e-03,  1.1520e-02],
        ...,
        [-4.5013e-03,  1.7731e-02, -7.0763e-04,  ...,  8.3618e-02,
         -3.3951e-03,  1.0757e-02],
        [-6.9199e-03,  1.0681e-03,  1.5907e-03,  ..., -7.9498e-03,
          7.0862e-02, -1.9073e-02],
        [-9.5825e-03,  1.6388e-02, -5.9395e-03,  ..., -2.7771e-03,
         -1.2459e-02,  9.1248e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.8154, -4.0352,  0.4546,  ..., -0.7778,  0.0454, -0.9663]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 20:49:32 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of member is members
The plural form of solution is solutions
The plural form of user is users
The plural form of problem is problems
The plural form of system is systems
The plural form of album is albums
The plural form of thing is things
The plural form of week is
2024-07-28 20:49:33 root INFO     [order_1_approx] starting weight calculation for The plural form of album is albums
The plural form of thing is things
The plural form of system is systems
The plural form of week is weeks
The plural form of solution is solutions
The plural form of problem is problems
The plural form of member is members
The plural form of user is
2024-07-28 20:49:33 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-28 20:51:27 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3413, -0.3264, -0.3669,  ...,  0.3726, -0.9038,  0.0980],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.8350, -2.8965,  0.9536,  ..., -1.1875, -2.2031, -2.3008],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 7.8674e-02, -4.8351e-04,  1.1627e-02,  ..., -8.0490e-04,
          3.0708e-04,  7.1068e-03],
        [-5.8441e-03,  6.4941e-02, -8.4381e-03,  ...,  7.0724e-03,
         -1.2550e-03,  5.8022e-03],
        [ 1.9646e-03, -1.9150e-03,  8.3191e-02,  ..., -8.5602e-03,
          1.2802e-02,  5.9967e-03],
        ...,
        [ 1.8959e-03,  6.3934e-03, -7.2632e-03,  ...,  9.6924e-02,
          1.4633e-02,  4.3030e-03],
        [ 9.9182e-05,  1.3565e-02, -3.1643e-03,  ..., -8.7433e-03,
          5.2734e-02, -1.6144e-02],
        [ 2.2392e-03,  1.2070e-02, -1.7883e-02,  ..., -1.3206e-02,
         -8.9340e-03,  7.9712e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.5430, -2.6680,  0.9473,  ..., -0.7671, -2.0664, -1.9023]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 20:51:28 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of album is albums
The plural form of thing is things
The plural form of system is systems
The plural form of week is weeks
The plural form of solution is solutions
The plural form of problem is problems
The plural form of member is members
The plural form of user is
2024-07-28 20:51:29 root INFO     [order_1_approx] starting weight calculation for The plural form of solution is solutions
The plural form of week is weeks
The plural form of problem is problems
The plural form of member is members
The plural form of system is systems
The plural form of user is users
The plural form of thing is things
The plural form of album is
2024-07-28 20:51:29 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-28 20:53:22 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2756, -0.0638, -0.5986,  ..., -0.2067, -0.5771,  0.4595],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.3523, -3.8398,  1.4766,  ...,  0.0561, -1.1143, -0.7734],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 1.3257e-01,  8.4076e-03,  1.0094e-02,  ..., -1.4870e-02,
          3.3073e-03, -1.7395e-03],
        [-2.6947e-02,  1.0248e-01, -6.0463e-03,  ...,  2.2995e-02,
         -2.8763e-03,  5.7983e-03],
        [ 9.6130e-03, -8.9340e-03,  1.1389e-01,  ..., -2.0340e-02,
          5.9471e-03,  3.2501e-03],
        ...,
        [-1.1780e-02,  2.0966e-02, -1.7868e-02,  ...,  1.2915e-01,
         -9.0256e-03,  1.2077e-02],
        [-1.5137e-02,  2.1439e-03,  1.4084e-02,  ..., -3.4866e-03,
          8.9172e-02, -1.9989e-02],
        [-3.8242e-03, -1.8969e-03, -1.2684e-04,  ..., -5.8365e-04,
          4.3488e-03,  1.1169e-01]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.6211, -3.7930,  1.8057,  ...,  0.5889, -1.2861,  0.1577]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 20:53:23 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of solution is solutions
The plural form of week is weeks
The plural form of problem is problems
The plural form of member is members
The plural form of system is systems
The plural form of user is users
The plural form of thing is things
The plural form of album is
2024-07-28 20:53:24 root INFO     [order_1_approx] starting weight calculation for The plural form of thing is things
The plural form of week is weeks
The plural form of album is albums
The plural form of solution is solutions
The plural form of user is users
The plural form of member is members
The plural form of system is systems
The plural form of problem is
2024-07-28 20:53:24 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-28 20:55:19 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2451, -0.0365,  0.2612,  ..., -0.6411, -0.8662,  0.0103],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.6035, -2.8125,  0.9546,  ..., -0.0396, -0.3804, -0.4766],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0714, -0.0107,  0.0151,  ...,  0.0090,  0.0071,  0.0011],
        [-0.0072,  0.0608, -0.0040,  ...,  0.0154, -0.0053,  0.0046],
        [ 0.0043, -0.0121,  0.0658,  ..., -0.0062,  0.0081,  0.0088],
        ...,
        [ 0.0051,  0.0262, -0.0051,  ...,  0.0776, -0.0048,  0.0202],
        [-0.0053,  0.0045,  0.0021,  ..., -0.0016,  0.0564, -0.0199],
        [ 0.0068,  0.0122, -0.0097,  ..., -0.0070, -0.0117,  0.0684]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.4336, -2.5703,  0.9854,  ...,  0.2495, -0.6440, -0.5635]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 20:55:20 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of thing is things
The plural form of week is weeks
The plural form of album is albums
The plural form of solution is solutions
The plural form of user is users
The plural form of member is members
The plural form of system is systems
The plural form of problem is
2024-07-28 20:55:20 root INFO     total operator prediction time: 930.2608909606934 seconds
2024-07-28 20:55:20 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on verb_Ving - 3pSg
2024-07-28 20:55:20 root INFO     building operator verb_Ving - 3pSg
2024-07-28 20:55:20 root INFO     [order_1_approx] starting weight calculation for When something is understanding, it understands
When something is describing, it describes
When something is believing, it believes
When something is developing, it develops
When something is involving, it involves
When something is managing, it manages
When something is allowing, it allows
When something is performing, it
2024-07-28 20:55:20 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-28 20:57:16 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.9795, -0.5107, -0.2561,  ..., -0.9131, -0.7739, -1.0303],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.4844, -4.8984,  0.7363,  ..., -1.3633, -6.7539, -2.1133],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0620,  0.0030,  0.0153,  ..., -0.0061, -0.0059,  0.0085],
        [-0.0242,  0.0545, -0.0023,  ...,  0.0162,  0.0077, -0.0064],
        [ 0.0052, -0.0092,  0.0467,  ..., -0.0102,  0.0039, -0.0124],
        ...,
        [-0.0005,  0.0033,  0.0020,  ...,  0.0668,  0.0106,  0.0006],
        [ 0.0041, -0.0278,  0.0142,  ..., -0.0033,  0.0434, -0.0088],
        [ 0.0011, -0.0025,  0.0041,  ..., -0.0027, -0.0039,  0.0579]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.6445, -4.4531,  0.9062,  ..., -0.8896, -6.7734, -2.0801]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 20:57:17 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When something is understanding, it understands
When something is describing, it describes
When something is believing, it believes
When something is developing, it develops
When something is involving, it involves
When something is managing, it manages
When something is allowing, it allows
When something is performing, it
2024-07-28 20:57:17 root INFO     [order_1_approx] starting weight calculation for When something is performing, it performs
When something is developing, it develops
When something is believing, it believes
When something is managing, it manages
When something is describing, it describes
When something is understanding, it understands
When something is allowing, it allows
When something is involving, it
2024-07-28 20:57:17 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-28 20:59:14 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3137, -0.2986,  0.1227,  ..., -0.7676, -1.1719, -0.8789],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.7480, -1.0078,  3.1777,  ..., -0.1191, -5.4922, -4.1875],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0805, -0.0025,  0.0189,  ...,  0.0037,  0.0020,  0.0052],
        [-0.0211,  0.0786, -0.0022,  ...,  0.0122, -0.0059, -0.0109],
        [ 0.0008, -0.0181,  0.0480,  ..., -0.0323, -0.0050, -0.0152],
        ...,
        [ 0.0263,  0.0080, -0.0077,  ...,  0.0779,  0.0014,  0.0129],
        [-0.0076, -0.0077,  0.0033,  ..., -0.0070,  0.0729, -0.0230],
        [-0.0092,  0.0061,  0.0040,  ..., -0.0031, -0.0189,  0.0845]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.0742, -0.7983,  2.5918,  ..., -0.2241, -5.7148, -3.4824]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 20:59:15 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When something is performing, it performs
When something is developing, it develops
When something is believing, it believes
When something is managing, it manages
When something is describing, it describes
When something is understanding, it understands
When something is allowing, it allows
When something is involving, it
2024-07-28 20:59:15 root INFO     [order_1_approx] starting weight calculation for When something is performing, it performs
When something is involving, it involves
When something is understanding, it understands
When something is describing, it describes
When something is managing, it manages
When something is allowing, it allows
When something is believing, it believes
When something is developing, it
2024-07-28 20:59:16 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-28 21:01:11 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.7754, -0.0214, -0.4387,  ..., -0.4299, -0.6694, -0.5200],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.8555, -4.6797,  1.1934,  ...,  0.0869, -6.8398, -1.3955],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0626,  0.0038,  0.0100,  ..., -0.0023, -0.0141, -0.0003],
        [-0.0183,  0.0411,  0.0018,  ...,  0.0137, -0.0002, -0.0034],
        [-0.0008, -0.0063,  0.0434,  ..., -0.0013,  0.0032, -0.0148],
        ...,
        [ 0.0138,  0.0046,  0.0080,  ...,  0.0603, -0.0039,  0.0064],
        [ 0.0108, -0.0070, -0.0026,  ..., -0.0054,  0.0542, -0.0174],
        [-0.0126, -0.0138, -0.0019,  ..., -0.0139, -0.0172,  0.0565]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.6172, -4.6445,  1.3711,  ...,  0.0749, -7.1641, -1.2500]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 21:01:13 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When something is performing, it performs
When something is involving, it involves
When something is understanding, it understands
When something is describing, it describes
When something is managing, it manages
When something is allowing, it allows
When something is believing, it believes
When something is developing, it
2024-07-28 21:01:13 root INFO     [order_1_approx] starting weight calculation for When something is allowing, it allows
When something is understanding, it understands
When something is performing, it performs
When something is believing, it believes
When something is developing, it develops
When something is describing, it describes
When something is involving, it involves
When something is managing, it
2024-07-28 21:01:13 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-28 21:03:08 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3120,  0.1162, -0.3301,  ..., -0.3398, -0.8232, -0.4883],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.8672, -3.2129,  0.7559,  ..., -1.4717, -7.1953, -2.5176],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0525,  0.0066,  0.0082,  ..., -0.0143, -0.0146, -0.0002],
        [-0.0092,  0.0399, -0.0047,  ...,  0.0206,  0.0054,  0.0084],
        [-0.0056, -0.0077,  0.0444,  ..., -0.0093,  0.0135, -0.0238],
        ...,
        [ 0.0057,  0.0019,  0.0062,  ...,  0.0590,  0.0007,  0.0086],
        [-0.0027,  0.0044,  0.0078,  ..., -0.0035,  0.0454, -0.0179],
        [-0.0024,  0.0005,  0.0058,  ..., -0.0178, -0.0153,  0.0426]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.7852, -3.1602,  0.6665,  ..., -1.4912, -7.1758, -2.4141]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 21:03:09 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When something is allowing, it allows
When something is understanding, it understands
When something is performing, it performs
When something is believing, it believes
When something is developing, it develops
When something is describing, it describes
When something is involving, it involves
When something is managing, it
2024-07-28 21:03:10 root INFO     [order_1_approx] starting weight calculation for When something is involving, it involves
When something is performing, it performs
When something is describing, it describes
When something is allowing, it allows
When something is developing, it develops
When something is understanding, it understands
When something is managing, it manages
When something is believing, it
2024-07-28 21:03:10 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-28 21:05:05 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.5684, -0.1882,  0.0081,  ..., -0.4097, -1.5127,  0.1049],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.3320, -4.4805,  1.1152,  ..., -0.0586, -4.8086, -0.2617],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0464,  0.0038, -0.0052,  ...,  0.0056, -0.0013,  0.0040],
        [-0.0025,  0.0461, -0.0007,  ...,  0.0166, -0.0018, -0.0030],
        [-0.0003, -0.0099,  0.0445,  ..., -0.0081,  0.0028, -0.0098],
        ...,
        [ 0.0041, -0.0057, -0.0043,  ...,  0.0445, -0.0049,  0.0093],
        [ 0.0009, -0.0175,  0.0118,  ..., -0.0044,  0.0350, -0.0134],
        [ 0.0031,  0.0071,  0.0067,  ..., -0.0019,  0.0030,  0.0426]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.1680, -4.3555,  1.1113,  ...,  0.1858, -4.8203, -0.3486]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 21:05:06 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When something is involving, it involves
When something is performing, it performs
When something is describing, it describes
When something is allowing, it allows
When something is developing, it develops
When something is understanding, it understands
When something is managing, it manages
When something is believing, it
2024-07-28 21:05:07 root INFO     [order_1_approx] starting weight calculation for When something is allowing, it allows
When something is believing, it believes
When something is managing, it manages
When something is developing, it develops
When something is understanding, it understands
When something is involving, it involves
When something is performing, it performs
When something is describing, it
2024-07-28 21:05:07 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-28 21:07:01 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1073, -0.9585,  0.7749,  ..., -0.2729, -0.4062, -1.2354],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.7461, -3.7520,  4.1719,  ..., -0.2314, -4.3047, -0.9062],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 6.9763e-02, -2.8973e-03,  1.5839e-02,  ..., -8.3923e-05,
          5.2338e-03,  1.8473e-03],
        [-1.5305e-02,  5.5908e-02,  8.1329e-03,  ...,  6.8970e-03,
          3.3112e-03, -9.0103e-03],
        [ 1.4297e-02,  5.5199e-03,  4.3274e-02,  ..., -1.2932e-02,
          4.2496e-03, -1.4977e-02],
        ...,
        [ 4.7646e-03,  6.3782e-03,  1.5343e-02,  ...,  6.9641e-02,
         -3.3760e-03,  9.7046e-03],
        [-2.0714e-03, -8.8501e-03, -5.1117e-03,  ...,  8.5068e-04,
          5.0751e-02, -1.3573e-02],
        [-1.1330e-03,  1.1864e-03,  1.0284e-02,  ..., -9.2468e-03,
         -5.4054e-03,  6.1859e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.5391, -3.1172,  4.2148,  ..., -0.1974, -4.8984, -0.9141]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 21:07:03 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When something is allowing, it allows
When something is believing, it believes
When something is managing, it manages
When something is developing, it develops
When something is understanding, it understands
When something is involving, it involves
When something is performing, it performs
When something is describing, it
2024-07-28 21:07:03 root INFO     [order_1_approx] starting weight calculation for When something is performing, it performs
When something is managing, it manages
When something is allowing, it allows
When something is describing, it describes
When something is believing, it believes
When something is involving, it involves
When something is developing, it develops
When something is understanding, it
2024-07-28 21:07:03 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-28 21:08:58 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3291, -0.7324,  0.4360,  ..., -0.8618, -0.5371, -1.2803],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.0156, -2.4395,  1.1250,  ..., -0.9126, -5.8008,  2.1680],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0463,  0.0074,  0.0009,  ..., -0.0013, -0.0076,  0.0008],
        [-0.0071,  0.0357, -0.0056,  ...,  0.0145, -0.0110, -0.0023],
        [-0.0021, -0.0136,  0.0411,  ..., -0.0061, -0.0038, -0.0175],
        ...,
        [ 0.0048,  0.0052,  0.0128,  ...,  0.0509,  0.0060,  0.0006],
        [ 0.0048, -0.0132,  0.0009,  ..., -0.0027,  0.0376, -0.0094],
        [-0.0014, -0.0004,  0.0043,  ..., -0.0104, -0.0116,  0.0340]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.8008, -2.3340,  1.1758,  ..., -0.7363, -5.9922,  2.0508]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 21:08:59 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When something is performing, it performs
When something is managing, it manages
When something is allowing, it allows
When something is describing, it describes
When something is believing, it believes
When something is involving, it involves
When something is developing, it develops
When something is understanding, it
2024-07-28 21:09:00 root INFO     [order_1_approx] starting weight calculation for When something is understanding, it understands
When something is developing, it develops
When something is describing, it describes
When something is involving, it involves
When something is managing, it manages
When something is believing, it believes
When something is performing, it performs
When something is allowing, it
2024-07-28 21:09:00 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-28 21:10:55 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.5669, -0.5352,  0.1888,  ..., -1.2109, -0.5039, -0.6309],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.6934, -3.6660, -0.2969,  ..., -2.0430, -6.8281,  1.4238],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0797,  0.0071,  0.0094,  ..., -0.0112,  0.0022,  0.0046],
        [ 0.0064,  0.0618, -0.0086,  ...,  0.0086,  0.0028, -0.0057],
        [-0.0127, -0.0113,  0.0705,  ..., -0.0165,  0.0047, -0.0206],
        ...,
        [-0.0004,  0.0047, -0.0012,  ...,  0.0625,  0.0028,  0.0052],
        [-0.0046, -0.0012, -0.0017,  ..., -0.0076,  0.0547, -0.0166],
        [-0.0045, -0.0009, -0.0093,  ..., -0.0138, -0.0104,  0.0699]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.6621, -3.8418, -0.2028,  ..., -1.3633, -6.8047,  1.3486]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 21:10:56 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When something is understanding, it understands
When something is developing, it develops
When something is describing, it describes
When something is involving, it involves
When something is managing, it manages
When something is believing, it believes
When something is performing, it performs
When something is allowing, it
2024-07-28 21:10:56 root INFO     total operator prediction time: 935.7410833835602 seconds
2024-07-28 21:10:56 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on verb_inf - 3pSg
2024-07-28 21:10:56 root INFO     building operator verb_inf - 3pSg
2024-07-28 21:10:56 root INFO     [order_1_approx] starting weight calculation for I enjoy, he enjoys
I apply, he applies
I agree, he agrees
I send, he sends
I include, he includes
I learn, he learns
I maintain, he maintains
I hear, he
2024-07-28 21:10:56 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-28 21:12:53 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1987, -0.5508,  0.3708,  ..., -0.1831, -0.3228,  0.8623],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.7285, -4.1016, -3.0977,  ..., -2.5234, -7.9375, -3.7344],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 7.3975e-02, -4.4632e-03, -6.8665e-05,  ..., -1.6098e-02,
          2.4078e-02,  1.1848e-02],
        [ 1.8444e-03,  6.8909e-02, -1.6220e-02,  ..., -2.9182e-03,
          7.8430e-03, -6.9275e-03],
        [-2.7447e-03,  3.4943e-03,  4.9774e-02,  ..., -1.8959e-03,
          1.1101e-02, -9.4604e-03],
        ...,
        [ 7.5951e-03,  2.8625e-02,  1.6403e-02,  ...,  7.5073e-02,
         -1.2589e-03, -2.2156e-02],
        [-8.7509e-03, -1.0254e-02,  7.2784e-03,  ...,  9.8877e-03,
          3.4729e-02, -6.8932e-03],
        [ 3.3360e-03,  9.1171e-04, -7.9498e-03,  ...,  7.2327e-03,
          4.8637e-03,  4.0405e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.9160, -3.9668, -3.2461,  ..., -2.0820, -7.6562, -3.7344]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 21:12:54 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for I enjoy, he enjoys
I apply, he applies
I agree, he agrees
I send, he sends
I include, he includes
I learn, he learns
I maintain, he maintains
I hear, he
2024-07-28 21:12:54 root INFO     [order_1_approx] starting weight calculation for I hear, he hears
I include, he includes
I learn, he learns
I maintain, he maintains
I send, he sends
I agree, he agrees
I apply, he applies
I enjoy, he
2024-07-28 21:12:54 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-28 21:14:47 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1726, -0.6660, -0.0478,  ..., -1.0723, -0.5054,  0.2563],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.0371, -2.3867, -1.4648,  ..., -1.5283, -6.1055, -0.3613],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 5.5511e-02,  7.0686e-03,  1.1459e-02,  ..., -1.5717e-02,
         -7.8201e-04,  2.4200e-02],
        [-4.8409e-03,  3.9703e-02, -5.1575e-03,  ..., -1.2703e-03,
          8.9645e-05, -6.8016e-03],
        [ 1.7681e-03,  1.2856e-03,  4.3396e-02,  ...,  6.6996e-04,
         -7.6370e-03, -5.5790e-04],
        ...,
        [-5.8212e-03,  1.0773e-02, -6.7635e-03,  ...,  5.3040e-02,
         -1.7653e-03, -6.0425e-03],
        [ 1.1530e-03, -1.4984e-02,  1.0857e-02,  ...,  2.5578e-03,
          3.2898e-02, -3.6201e-03],
        [ 2.3117e-03, -3.2234e-04,  2.9469e-03,  ..., -1.8539e-03,
         -3.6449e-03,  4.1138e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.7500, -2.2969, -1.7051,  ..., -1.2734, -6.3242, -0.4902]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 21:14:48 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for I hear, he hears
I include, he includes
I learn, he learns
I maintain, he maintains
I send, he sends
I agree, he agrees
I apply, he applies
I enjoy, he
2024-07-28 21:14:48 root INFO     [order_1_approx] starting weight calculation for I enjoy, he enjoys
I apply, he applies
I include, he includes
I learn, he learns
I hear, he hears
I maintain, he maintains
I send, he sends
I agree, he
2024-07-28 21:14:48 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-28 21:16:44 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0895, -0.6162, -0.2448,  ..., -0.6392, -0.5742, -0.2854],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.9902, -5.6641,  0.0605,  ..., -0.0898, -5.5820,  1.7090],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0570,  0.0011,  0.0098,  ..., -0.0100,  0.0055,  0.0194],
        [-0.0037,  0.0515,  0.0127,  ...,  0.0156, -0.0038, -0.0141],
        [-0.0036, -0.0004,  0.0340,  ..., -0.0101,  0.0015,  0.0016],
        ...,
        [ 0.0021,  0.0110, -0.0137,  ...,  0.0466, -0.0043, -0.0054],
        [ 0.0014, -0.0140,  0.0018,  ..., -0.0020,  0.0419, -0.0023],
        [ 0.0119, -0.0089,  0.0088,  ..., -0.0069, -0.0156,  0.0445]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.4395, -5.2266, -0.0797,  ...,  0.3193, -5.8320,  1.5215]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 21:16:46 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for I enjoy, he enjoys
I apply, he applies
I include, he includes
I learn, he learns
I hear, he hears
I maintain, he maintains
I send, he sends
I agree, he
2024-07-28 21:16:46 root INFO     [order_1_approx] starting weight calculation for I enjoy, he enjoys
I agree, he agrees
I include, he includes
I learn, he learns
I maintain, he maintains
I hear, he hears
I send, he sends
I apply, he
2024-07-28 21:16:46 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-28 21:18:41 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0879,  0.1074,  0.2214,  ..., -0.2627, -0.9014,  0.0596],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.0312, -2.9727, -1.5508,  ..., -0.5215, -7.0352, -0.4629],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0740,  0.0054,  0.0110,  ..., -0.0098, -0.0011,  0.0187],
        [-0.0069,  0.0570, -0.0026,  ..., -0.0044, -0.0016, -0.0005],
        [-0.0035, -0.0066,  0.0491,  ..., -0.0101, -0.0004, -0.0042],
        ...,
        [ 0.0058,  0.0061, -0.0058,  ...,  0.0755,  0.0011, -0.0114],
        [ 0.0029, -0.0225,  0.0093,  ...,  0.0022,  0.0463, -0.0060],
        [ 0.0090, -0.0020,  0.0031,  ..., -0.0083, -0.0098,  0.0539]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.8428, -3.2461, -1.6494,  ..., -0.4216, -6.7539, -0.3176]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 21:18:42 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for I enjoy, he enjoys
I agree, he agrees
I include, he includes
I learn, he learns
I maintain, he maintains
I hear, he hears
I send, he sends
I apply, he
2024-07-28 21:18:42 root INFO     [order_1_approx] starting weight calculation for I hear, he hears
I send, he sends
I learn, he learns
I include, he includes
I apply, he applies
I enjoy, he enjoys
I agree, he agrees
I maintain, he
2024-07-28 21:18:42 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-28 21:20:35 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.5278, -0.3828,  0.3801,  ..., -0.3340, -1.0176,  0.2441],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.5547, -4.2148, -2.2988,  ..., -1.5371, -6.2383, -0.4922],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0606,  0.0009,  0.0222,  ..., -0.0084,  0.0059,  0.0140],
        [-0.0017,  0.0361, -0.0038,  ...,  0.0085,  0.0032,  0.0011],
        [ 0.0039, -0.0035,  0.0493,  ..., -0.0023, -0.0047, -0.0085],
        ...,
        [ 0.0036,  0.0168, -0.0009,  ...,  0.0544, -0.0098, -0.0003],
        [ 0.0009, -0.0152,  0.0095,  ..., -0.0061,  0.0160, -0.0104],
        [ 0.0086, -0.0008, -0.0024,  ..., -0.0010, -0.0043,  0.0478]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.6523, -3.9062, -2.2598,  ..., -1.6426, -5.8516, -0.3210]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 21:20:36 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for I hear, he hears
I send, he sends
I learn, he learns
I include, he includes
I apply, he applies
I enjoy, he enjoys
I agree, he agrees
I maintain, he
2024-07-28 21:20:36 root INFO     [order_1_approx] starting weight calculation for I agree, he agrees
I include, he includes
I enjoy, he enjoys
I maintain, he maintains
I hear, he hears
I send, he sends
I apply, he applies
I learn, he
2024-07-28 21:20:36 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-28 21:22:28 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0257, -0.5264,  0.3030,  ..., -1.1152, -0.9502,  0.3699],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.6953, -3.5664, -1.1914,  ...,  0.3870, -5.3633, -4.3125],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0475,  0.0013,  0.0118,  ..., -0.0082,  0.0081,  0.0110],
        [-0.0090,  0.0378, -0.0035,  ...,  0.0069, -0.0020, -0.0068],
        [-0.0079, -0.0033,  0.0269,  ..., -0.0059,  0.0012, -0.0077],
        ...,
        [ 0.0108,  0.0112, -0.0044,  ...,  0.0482, -0.0033, -0.0077],
        [ 0.0089, -0.0071, -0.0024,  ...,  0.0009,  0.0336, -0.0024],
        [-0.0190, -0.0008,  0.0026,  ...,  0.0043, -0.0006,  0.0389]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.6016, -3.5820, -1.5156,  ...,  0.5400, -5.3828, -4.0781]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 21:22:29 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for I agree, he agrees
I include, he includes
I enjoy, he enjoys
I maintain, he maintains
I hear, he hears
I send, he sends
I apply, he applies
I learn, he
2024-07-28 21:22:29 root INFO     [order_1_approx] starting weight calculation for I maintain, he maintains
I agree, he agrees
I hear, he hears
I send, he sends
I learn, he learns
I enjoy, he enjoys
I apply, he applies
I include, he
2024-07-28 21:22:29 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-28 21:24:22 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1709,  0.2183,  0.3516,  ..., -0.2542, -0.2620, -0.0752],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.1426, -2.5996,  0.4941,  ..., -0.8662, -6.9219, -1.2979],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0646, -0.0067,  0.0145,  ..., -0.0054,  0.0050,  0.0186],
        [ 0.0003,  0.0576, -0.0051,  ...,  0.0015, -0.0099, -0.0078],
        [-0.0063, -0.0118,  0.0508,  ..., -0.0169, -0.0034, -0.0004],
        ...,
        [ 0.0125,  0.0002, -0.0016,  ...,  0.0709, -0.0092,  0.0074],
        [-0.0005, -0.0094,  0.0145,  ..., -0.0045,  0.0479, -0.0095],
        [-0.0108,  0.0067, -0.0018,  ...,  0.0014, -0.0134,  0.0541]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.2363, -2.4863,  0.7485,  ..., -0.7974, -6.6914, -0.6533]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 21:24:24 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for I maintain, he maintains
I agree, he agrees
I hear, he hears
I send, he sends
I learn, he learns
I enjoy, he enjoys
I apply, he applies
I include, he
2024-07-28 21:24:24 root INFO     [order_1_approx] starting weight calculation for I learn, he learns
I hear, he hears
I enjoy, he enjoys
I apply, he applies
I maintain, he maintains
I agree, he agrees
I include, he includes
I send, he
2024-07-28 21:24:24 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-28 21:26:19 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.3325, -0.3630,  0.2500,  ..., -0.2869,  0.1058,  0.3081],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.2090, -3.0586, -7.1211,  ..., -4.1953, -9.4766, -2.9629],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0513,  0.0037,  0.0010,  ..., -0.0058, -0.0003,  0.0057],
        [-0.0048,  0.0328, -0.0090,  ...,  0.0078,  0.0084, -0.0054],
        [ 0.0028,  0.0019,  0.0190,  ..., -0.0036,  0.0012, -0.0019],
        ...,
        [ 0.0060,  0.0102,  0.0182,  ...,  0.0444,  0.0022, -0.0109],
        [-0.0006, -0.0204,  0.0008,  ...,  0.0062,  0.0307, -0.0019],
        [-0.0037, -0.0001, -0.0056,  ...,  0.0014, -0.0131,  0.0378]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.1328, -2.9531, -6.9258,  ..., -4.2109, -9.3047, -2.8516]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 21:26:20 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for I learn, he learns
I hear, he hears
I enjoy, he enjoys
I apply, he applies
I maintain, he maintains
I agree, he agrees
I include, he includes
I send, he
2024-07-28 21:26:20 root INFO     total operator prediction time: 924.6593647003174 seconds
2024-07-28 21:26:20 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on verb_inf - Ved
2024-07-28 21:26:20 root INFO     building operator verb_inf - Ved
2024-07-28 21:26:21 root INFO     [order_1_approx] starting weight calculation for If the present form is tell, the past form is told
If the present form is locate, the past form is located
If the present form is consider, the past form is considered
If the present form is hear, the past form is heard
If the present form is introduce, the past form is introduced
If the present form is believe, the past form is believed
If the present form is receive, the past form is received
If the present form is appear, the past form is
2024-07-28 21:26:21 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-28 21:28:17 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.6201, -0.5845, -0.3120,  ..., -0.8315, -0.1421, -0.6787],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.0967,  0.5830,  0.6582,  ...,  0.9009, -2.9766,  0.7402],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0862, -0.0205,  0.0096,  ..., -0.0079,  0.0042, -0.0020],
        [-0.0041,  0.0724, -0.0007,  ...,  0.0201, -0.0182, -0.0166],
        [ 0.0072,  0.0044,  0.0756,  ..., -0.0145, -0.0033, -0.0070],
        ...,
        [ 0.0001,  0.0087, -0.0147,  ...,  0.0818, -0.0061, -0.0055],
        [ 0.0067,  0.0053,  0.0117,  ..., -0.0036,  0.0643, -0.0088],
        [ 0.0094,  0.0094, -0.0082,  ..., -0.0170, -0.0094,  0.0662]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.1249,  0.2913,  0.1240,  ...,  0.5337, -3.1504,  1.0254]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 21:28:18 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If the present form is tell, the past form is told
If the present form is locate, the past form is located
If the present form is consider, the past form is considered
If the present form is hear, the past form is heard
If the present form is introduce, the past form is introduced
If the present form is believe, the past form is believed
If the present form is receive, the past form is received
If the present form is appear, the past form is
2024-07-28 21:28:18 root INFO     [order_1_approx] starting weight calculation for If the present form is appear, the past form is appeared
If the present form is hear, the past form is heard
If the present form is introduce, the past form is introduced
If the present form is consider, the past form is considered
If the present form is receive, the past form is received
If the present form is believe, the past form is believed
If the present form is locate, the past form is located
If the present form is tell, the past form is
2024-07-28 21:28:18 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-28 21:30:12 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2140, -0.5884,  0.5557,  ..., -0.6055, -0.3005, -0.1055],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.8730,  0.3979,  1.9141,  ...,  2.5078, -4.6875, -1.9980],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0726,  0.0006,  0.0133,  ..., -0.0041,  0.0064,  0.0168],
        [-0.0143,  0.0643, -0.0056,  ...,  0.0146, -0.0013, -0.0026],
        [ 0.0102, -0.0084,  0.0547,  ..., -0.0169, -0.0069,  0.0111],
        ...,
        [ 0.0157,  0.0163, -0.0168,  ...,  0.0681, -0.0058,  0.0015],
        [ 0.0056, -0.0067,  0.0146,  ...,  0.0056,  0.0656, -0.0024],
        [-0.0009,  0.0093, -0.0011,  ..., -0.0130, -0.0024,  0.0500]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.1270,  0.5767,  1.7148,  ...,  2.4668, -4.7656, -1.9746]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 21:30:13 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If the present form is appear, the past form is appeared
If the present form is hear, the past form is heard
If the present form is introduce, the past form is introduced
If the present form is consider, the past form is considered
If the present form is receive, the past form is received
If the present form is believe, the past form is believed
If the present form is locate, the past form is located
If the present form is tell, the past form is
2024-07-28 21:30:14 root INFO     [order_1_approx] starting weight calculation for If the present form is locate, the past form is located
If the present form is appear, the past form is appeared
If the present form is consider, the past form is considered
If the present form is receive, the past form is received
If the present form is believe, the past form is believed
If the present form is hear, the past form is heard
If the present form is tell, the past form is told
If the present form is introduce, the past form is
2024-07-28 21:30:14 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-28 21:32:08 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.8535, -0.2122, -0.1160,  ..., -0.1010, -0.8057,  0.4341],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.4580,  1.0557,  2.6914,  ...,  0.8330, -2.8555, -1.0801],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0964, -0.0062,  0.0082,  ..., -0.0087,  0.0028, -0.0021],
        [-0.0149,  0.0726, -0.0057,  ...,  0.0272,  0.0021, -0.0199],
        [ 0.0131, -0.0054,  0.0701,  ..., -0.0210, -0.0103, -0.0013],
        ...,
        [ 0.0089,  0.0066, -0.0076,  ...,  0.0922, -0.0043,  0.0163],
        [ 0.0036,  0.0017,  0.0185,  ..., -0.0031,  0.0653, -0.0073],
        [-0.0060,  0.0035, -0.0068,  ..., -0.0083, -0.0135,  0.0757]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.3748,  1.1377,  2.6895,  ...,  0.5664, -2.7754, -0.6372]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 21:32:09 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If the present form is locate, the past form is located
If the present form is appear, the past form is appeared
If the present form is consider, the past form is considered
If the present form is receive, the past form is received
If the present form is believe, the past form is believed
If the present form is hear, the past form is heard
If the present form is tell, the past form is told
If the present form is introduce, the past form is
2024-07-28 21:32:09 root INFO     [order_1_approx] starting weight calculation for If the present form is tell, the past form is told
If the present form is introduce, the past form is introduced
If the present form is consider, the past form is considered
If the present form is hear, the past form is heard
If the present form is appear, the past form is appeared
If the present form is receive, the past form is received
If the present form is locate, the past form is located
If the present form is believe, the past form is
2024-07-28 21:32:09 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-28 21:34:04 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4800,  0.0239, -0.0017,  ..., -0.4727, -1.3223,  0.6055],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.6582, -2.7539,  1.2881,  ..., -0.1521, -2.0898, -1.5146],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0515, -0.0044,  0.0038,  ..., -0.0025,  0.0020,  0.0042],
        [-0.0104,  0.0287,  0.0053,  ...,  0.0180, -0.0084,  0.0006],
        [ 0.0064, -0.0011,  0.0504,  ..., -0.0079, -0.0058,  0.0003],
        ...,
        [ 0.0037,  0.0054, -0.0170,  ...,  0.0546, -0.0089,  0.0022],
        [ 0.0082, -0.0072,  0.0125,  ...,  0.0005,  0.0318, -0.0103],
        [ 0.0028,  0.0087, -0.0020,  ..., -0.0047,  0.0005,  0.0412]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.4688, -2.8320,  1.1172,  ..., -0.1765, -2.2012, -1.5273]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 21:34:05 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If the present form is tell, the past form is told
If the present form is introduce, the past form is introduced
If the present form is consider, the past form is considered
If the present form is hear, the past form is heard
If the present form is appear, the past form is appeared
If the present form is receive, the past form is received
If the present form is locate, the past form is located
If the present form is believe, the past form is
2024-07-28 21:34:05 root INFO     [order_1_approx] starting weight calculation for If the present form is hear, the past form is heard
If the present form is appear, the past form is appeared
If the present form is tell, the past form is told
If the present form is receive, the past form is received
If the present form is believe, the past form is believed
If the present form is locate, the past form is located
If the present form is introduce, the past form is introduced
If the present form is consider, the past form is
2024-07-28 21:34:05 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-28 21:36:00 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4746, -0.4346,  0.3169,  ..., -0.2888, -0.1277,  0.2939],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.8926, -0.3208,  2.1348,  ..., -2.6016, -0.5093,  0.0195],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0834, -0.0140,  0.0127,  ..., -0.0040,  0.0009,  0.0281],
        [-0.0147,  0.0508,  0.0012,  ...,  0.0226,  0.0005, -0.0063],
        [ 0.0015, -0.0050,  0.0559,  ..., -0.0127, -0.0038, -0.0166],
        ...,
        [ 0.0032, -0.0057,  0.0028,  ...,  0.0858, -0.0085,  0.0119],
        [ 0.0301,  0.0136, -0.0017,  ..., -0.0058,  0.0550, -0.0220],
        [-0.0067,  0.0066,  0.0030,  ..., -0.0174, -0.0129,  0.0534]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.0723,  0.2124,  1.7324,  ..., -2.5977, -0.7651,  0.5215]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 21:36:02 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If the present form is hear, the past form is heard
If the present form is appear, the past form is appeared
If the present form is tell, the past form is told
If the present form is receive, the past form is received
If the present form is believe, the past form is believed
If the present form is locate, the past form is located
If the present form is introduce, the past form is introduced
If the present form is consider, the past form is
2024-07-28 21:36:02 root INFO     [order_1_approx] starting weight calculation for If the present form is hear, the past form is heard
If the present form is tell, the past form is told
If the present form is consider, the past form is considered
If the present form is introduce, the past form is introduced
If the present form is believe, the past form is believed
If the present form is appear, the past form is appeared
If the present form is receive, the past form is received
If the present form is locate, the past form is
2024-07-28 21:36:02 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-28 21:37:57 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2018,  0.2440, -0.6787,  ..., -0.5635, -0.7261,  0.0316],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.1104, -0.7256, -1.1523,  ..., -1.9277, -1.5264, -1.8438],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0902, -0.0060,  0.0174,  ...,  0.0039,  0.0078,  0.0107],
        [-0.0084,  0.0555, -0.0115,  ...,  0.0083, -0.0050, -0.0176],
        [ 0.0052,  0.0005,  0.0668,  ..., -0.0203, -0.0044, -0.0006],
        ...,
        [ 0.0011, -0.0002, -0.0081,  ...,  0.0775, -0.0005,  0.0110],
        [ 0.0119,  0.0020,  0.0097,  ...,  0.0071,  0.0572, -0.0100],
        [ 0.0034,  0.0036, -0.0138,  ..., -0.0066, -0.0026,  0.0696]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.1699, -0.8267, -1.3994,  ..., -1.8945, -1.1445, -1.3613]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 21:37:58 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If the present form is hear, the past form is heard
If the present form is tell, the past form is told
If the present form is consider, the past form is considered
If the present form is introduce, the past form is introduced
If the present form is believe, the past form is believed
If the present form is appear, the past form is appeared
If the present form is receive, the past form is received
If the present form is locate, the past form is
2024-07-28 21:37:59 root INFO     [order_1_approx] starting weight calculation for If the present form is introduce, the past form is introduced
If the present form is believe, the past form is believed
If the present form is appear, the past form is appeared
If the present form is locate, the past form is located
If the present form is hear, the past form is heard
If the present form is consider, the past form is considered
If the present form is tell, the past form is told
If the present form is receive, the past form is
2024-07-28 21:37:59 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-28 21:39:53 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0033,  0.0808, -0.0181,  ..., -0.6621, -0.9238,  0.1790],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.2441, -0.1792, -1.1133,  ..., -3.5117, -1.6406, -1.5068],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0825, -0.0120,  0.0209,  ...,  0.0002, -0.0018,  0.0229],
        [-0.0362,  0.0729, -0.0077,  ...,  0.0139,  0.0097, -0.0156],
        [ 0.0112, -0.0141,  0.0447,  ..., -0.0299, -0.0076,  0.0008],
        ...,
        [-0.0011, -0.0024, -0.0055,  ...,  0.1019,  0.0038, -0.0045],
        [ 0.0087,  0.0001, -0.0042,  ..., -0.0052,  0.0593, -0.0140],
        [-0.0121,  0.0085, -0.0103,  ..., -0.0157,  0.0100,  0.0710]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.9482, -0.0516, -1.6309,  ..., -3.8379, -1.7314, -1.1807]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 21:39:54 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If the present form is introduce, the past form is introduced
If the present form is believe, the past form is believed
If the present form is appear, the past form is appeared
If the present form is locate, the past form is located
If the present form is hear, the past form is heard
If the present form is consider, the past form is considered
If the present form is tell, the past form is told
If the present form is receive, the past form is
2024-07-28 21:39:54 root INFO     [order_1_approx] starting weight calculation for If the present form is appear, the past form is appeared
If the present form is receive, the past form is received
If the present form is believe, the past form is believed
If the present form is consider, the past form is considered
If the present form is locate, the past form is located
If the present form is tell, the past form is told
If the present form is introduce, the past form is introduced
If the present form is hear, the past form is
2024-07-28 21:39:54 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-28 21:41:49 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0699, -0.6504,  0.4360,  ...,  0.0146, -0.4177,  0.7642],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.8711, -0.7290,  1.0127,  ..., -0.2532, -3.3340, -2.8047],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 9.0515e-02, -1.7303e-02,  7.1487e-03,  ...,  1.4648e-03,
          1.8158e-02,  6.4888e-03],
        [-3.9635e-03,  6.8359e-02, -8.5754e-03,  ...,  8.0795e-03,
          8.4381e-03, -1.8127e-02],
        [ 6.1989e-04, -2.9526e-03,  6.6223e-02,  ..., -1.7273e-02,
          1.6632e-03, -4.7016e-04],
        ...,
        [ 1.2901e-02,  8.9035e-03, -1.1726e-02,  ...,  7.5928e-02,
         -1.8921e-03, -5.6915e-03],
        [-6.7291e-03,  3.5686e-03,  4.5395e-04,  ...,  9.9335e-03,
          3.6652e-02, -1.3618e-02],
        [-1.0319e-03,  1.8654e-03, -4.5776e-05,  ...,  2.4643e-03,
          1.2665e-02,  5.9174e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.5234, -0.4402,  1.0361,  ..., -0.3828, -3.4062, -2.3965]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 21:41:50 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If the present form is appear, the past form is appeared
If the present form is receive, the past form is received
If the present form is believe, the past form is believed
If the present form is consider, the past form is considered
If the present form is locate, the past form is located
If the present form is tell, the past form is told
If the present form is introduce, the past form is introduced
If the present form is hear, the past form is
2024-07-28 21:41:50 root INFO     total operator prediction time: 929.9429707527161 seconds
2024-07-28 21:41:50 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on verb_Ving - Ved
2024-07-28 21:41:50 root INFO     building operator verb_Ving - Ved
2024-07-28 21:41:51 root INFO     [order_1_approx] starting weight calculation for After something is continuing, it has continued
After something is remaining, it has remained
After something is asking, it has asked
After something is suffering, it has suffered
After something is providing, it has provided
After something is publishing, it has published
After something is replacing, it has replaced
After something is developing, it has
2024-07-28 21:41:51 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-28 21:43:47 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 1.0000, -0.0785, -0.4316,  ..., -0.3735, -0.8354, -0.4858],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.4668, -0.4062,  2.2930,  ..., -2.5312, -2.1602, -1.6738],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 6.3171e-02,  3.0746e-03,  7.9422e-03,  ...,  2.3270e-03,
         -4.5319e-03,  4.9553e-03],
        [-3.0060e-02,  4.7913e-02, -4.5815e-03,  ...,  2.0660e-02,
         -1.7109e-03, -3.8910e-04],
        [ 1.4923e-02,  1.0414e-03,  4.5593e-02,  ..., -8.8882e-04,
          2.5101e-03, -1.0757e-02],
        ...,
        [ 1.4816e-02,  2.7924e-03,  2.1400e-03,  ...,  6.7322e-02,
         -8.0490e-04,  6.4545e-03],
        [ 9.1782e-03,  5.0354e-04, -1.4320e-02,  ..., -6.4850e-05,
          6.7261e-02, -1.1703e-02],
        [-1.8280e-02, -1.3374e-02, -6.1035e-04,  ..., -9.0561e-03,
         -1.6174e-02,  5.4138e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.4004, -0.3235,  2.3301,  ..., -2.5957, -2.3477, -1.4707]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 21:43:48 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for After something is continuing, it has continued
After something is remaining, it has remained
After something is asking, it has asked
After something is suffering, it has suffered
After something is providing, it has provided
After something is publishing, it has published
After something is replacing, it has replaced
After something is developing, it has
2024-07-28 21:43:49 root INFO     [order_1_approx] starting weight calculation for After something is remaining, it has remained
After something is continuing, it has continued
After something is asking, it has asked
After something is replacing, it has replaced
After something is providing, it has provided
After something is developing, it has developed
After something is publishing, it has published
After something is suffering, it has
2024-07-28 21:43:49 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-28 21:45:43 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.3691, -0.7905,  0.3992,  ..., -1.4121, -0.0792, -0.1230],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.2695, -2.5488,  1.0166,  ..., -2.9141,  1.9805,  0.6328],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 6.6528e-02, -4.0894e-03,  2.1637e-02,  ..., -5.6572e-03,
          7.4997e-03,  4.2725e-03],
        [-2.0508e-02,  3.0441e-02,  5.0163e-03,  ...,  2.3285e-02,
          4.9934e-03,  7.0143e-04],
        [ 5.6076e-03,  3.3302e-03,  3.6499e-02,  ..., -1.0201e-02,
          1.0490e-02, -4.3201e-04],
        ...,
        [-8.8501e-04,  6.6986e-03,  6.3095e-03,  ...,  6.0760e-02,
          1.0757e-02,  9.1019e-03],
        [ 1.9577e-02,  6.4926e-03, -6.2561e-03,  ...,  5.8460e-04,
          4.7668e-02, -1.4603e-02],
        [ 7.6141e-03, -4.7188e-03,  2.2888e-05,  ..., -8.9417e-03,
         -1.3359e-02,  4.4098e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.2930, -2.2656,  0.6021,  ..., -2.9316,  1.8984,  0.8174]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 21:45:44 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for After something is remaining, it has remained
After something is continuing, it has continued
After something is asking, it has asked
After something is replacing, it has replaced
After something is providing, it has provided
After something is developing, it has developed
After something is publishing, it has published
After something is suffering, it has
2024-07-28 21:45:44 root INFO     [order_1_approx] starting weight calculation for After something is remaining, it has remained
After something is publishing, it has published
After something is replacing, it has replaced
After something is developing, it has developed
After something is suffering, it has suffered
After something is continuing, it has continued
After something is asking, it has asked
After something is providing, it has
2024-07-28 21:45:44 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-28 21:47:39 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.5337, -0.5439, -0.0161,  ..., -0.3311, -0.3350, -0.6191],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.4590, -3.2500,  2.0605,  ..., -1.5938, -2.1777, -0.2793],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0825, -0.0056,  0.0331,  ...,  0.0076, -0.0046,  0.0059],
        [-0.0549,  0.0561,  0.0016,  ...,  0.0257,  0.0014,  0.0162],
        [ 0.0189, -0.0115,  0.0655,  ..., -0.0156,  0.0074, -0.0065],
        ...,
        [ 0.0088,  0.0112, -0.0040,  ...,  0.0894,  0.0060,  0.0142],
        [ 0.0176, -0.0159, -0.0068,  ..., -0.0016,  0.0734, -0.0191],
        [-0.0103, -0.0007, -0.0029,  ..., -0.0043, -0.0059,  0.0782]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.8242, -2.6504,  2.0449,  ..., -1.7637, -2.2461,  0.0305]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 21:47:40 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for After something is remaining, it has remained
After something is publishing, it has published
After something is replacing, it has replaced
After something is developing, it has developed
After something is suffering, it has suffered
After something is continuing, it has continued
After something is asking, it has asked
After something is providing, it has
2024-07-28 21:47:40 root INFO     [order_1_approx] starting weight calculation for After something is continuing, it has continued
After something is replacing, it has replaced
After something is publishing, it has published
After something is providing, it has provided
After something is developing, it has developed
After something is asking, it has asked
After something is suffering, it has suffered
After something is remaining, it has
2024-07-28 21:47:40 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-28 21:49:36 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.5737, -0.9062,  0.4199,  ..., -0.8628, -0.4380, -0.5215],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.1924, -0.6274,  2.5703,  ..., -3.2148, -0.0684, -2.7188],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0789, -0.0070,  0.0200,  ..., -0.0008,  0.0043,  0.0119],
        [-0.0070,  0.0498, -0.0056,  ...,  0.0212,  0.0193, -0.0140],
        [ 0.0134,  0.0010,  0.0652,  ..., -0.0168, -0.0153, -0.0147],
        ...,
        [ 0.0002,  0.0154,  0.0073,  ...,  0.0748,  0.0134,  0.0079],
        [ 0.0053, -0.0024, -0.0076,  ...,  0.0030,  0.0682, -0.0128],
        [-0.0006,  0.0107,  0.0031,  ..., -0.0018, -0.0112,  0.0543]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.5488, -0.1611,  2.5195,  ..., -3.0547,  0.0643, -2.6250]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 21:49:37 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for After something is continuing, it has continued
After something is replacing, it has replaced
After something is publishing, it has published
After something is providing, it has provided
After something is developing, it has developed
After something is asking, it has asked
After something is suffering, it has suffered
After something is remaining, it has
2024-07-28 21:49:37 root INFO     [order_1_approx] starting weight calculation for After something is providing, it has provided
After something is suffering, it has suffered
After something is continuing, it has continued
After something is asking, it has asked
After something is remaining, it has remained
After something is developing, it has developed
After something is replacing, it has replaced
After something is publishing, it has
2024-07-28 21:49:37 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-28 21:51:30 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0822, -0.5532, -0.0240,  ...,  0.0192, -0.4951,  0.4741],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.5703, -1.8203,  1.4434,  ..., -2.9805, -1.2305,  1.0615],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0534, -0.0048,  0.0135,  ...,  0.0055, -0.0017,  0.0178],
        [-0.0253,  0.0426, -0.0139,  ...,  0.0184,  0.0003,  0.0037],
        [ 0.0134, -0.0125,  0.0585,  ..., -0.0030, -0.0067, -0.0028],
        ...,
        [-0.0071,  0.0105, -0.0013,  ...,  0.0851,  0.0125,  0.0120],
        [ 0.0057, -0.0001, -0.0040,  ..., -0.0036,  0.0558, -0.0133],
        [ 0.0012,  0.0039, -0.0005,  ...,  0.0008, -0.0122,  0.0489]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.8066, -1.8223,  1.3760,  ..., -2.7949, -1.0918,  1.3301]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 21:51:31 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for After something is providing, it has provided
After something is suffering, it has suffered
After something is continuing, it has continued
After something is asking, it has asked
After something is remaining, it has remained
After something is developing, it has developed
After something is replacing, it has replaced
After something is publishing, it has
2024-07-28 21:51:31 root INFO     [order_1_approx] starting weight calculation for After something is providing, it has provided
After something is continuing, it has continued
After something is remaining, it has remained
After something is developing, it has developed
After something is asking, it has asked
After something is suffering, it has suffered
After something is publishing, it has published
After something is replacing, it has
2024-07-28 21:51:31 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-28 21:53:26 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3926, -1.1895, -0.9136,  ..., -0.3752,  0.0134, -0.4521],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.6436, -0.0483,  0.7954,  ..., -1.9863,  0.2495,  0.4844],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0768, -0.0002,  0.0220,  ..., -0.0043,  0.0091,  0.0022],
        [-0.0359,  0.0371, -0.0164,  ...,  0.0260,  0.0190, -0.0179],
        [ 0.0106, -0.0098,  0.0435,  ..., -0.0179,  0.0031, -0.0218],
        ...,
        [ 0.0147,  0.0153, -0.0100,  ...,  0.0719,  0.0003,  0.0056],
        [ 0.0171,  0.0082,  0.0019,  ..., -0.0122,  0.0681, -0.0050],
        [ 0.0090,  0.0045, -0.0027,  ..., -0.0014, -0.0138,  0.0539]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.5430,  0.2454,  0.9478,  ..., -1.9990, -0.1824,  0.4021]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 21:53:27 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for After something is providing, it has provided
After something is continuing, it has continued
After something is remaining, it has remained
After something is developing, it has developed
After something is asking, it has asked
After something is suffering, it has suffered
After something is publishing, it has published
After something is replacing, it has
2024-07-28 21:53:27 root INFO     [order_1_approx] starting weight calculation for After something is continuing, it has continued
After something is publishing, it has published
After something is suffering, it has suffered
After something is developing, it has developed
After something is replacing, it has replaced
After something is providing, it has provided
After something is remaining, it has remained
After something is asking, it has
2024-07-28 21:53:27 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-28 21:55:23 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0789, -1.0674, -0.0815,  ..., -1.0205, -0.8584, -1.2070],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.6836, -0.8350,  0.2568,  ..., -0.0635, -2.6309, -0.5508],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 5.2368e-02, -2.6989e-04,  1.7380e-02,  ...,  1.5259e-05,
          3.5629e-03,  1.3847e-02],
        [-2.0538e-02,  3.9276e-02, -4.2686e-03,  ...,  1.8036e-02,
         -2.3632e-03,  3.7575e-04],
        [-9.7427e-03, -5.5771e-03,  3.7354e-02,  ...,  2.0065e-03,
          2.9430e-03, -9.1019e-03],
        ...,
        [ 6.9695e-03,  1.6052e-02,  1.2321e-03,  ...,  5.0293e-02,
         -1.5965e-03, -1.0300e-02],
        [ 1.0319e-03, -1.4778e-02,  5.2490e-03,  ...,  6.9466e-03,
          5.0354e-02, -7.2479e-03],
        [-1.2302e-04,  1.2741e-03,  1.8015e-03,  ...,  3.8528e-03,
         -3.2806e-04,  4.2358e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.6611, -0.5381,  0.3416,  ..., -0.1624, -2.4023, -0.6279]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 21:55:24 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for After something is continuing, it has continued
After something is publishing, it has published
After something is suffering, it has suffered
After something is developing, it has developed
After something is replacing, it has replaced
After something is providing, it has provided
After something is remaining, it has remained
After something is asking, it has
2024-07-28 21:55:25 root INFO     [order_1_approx] starting weight calculation for After something is suffering, it has suffered
After something is providing, it has provided
After something is replacing, it has replaced
After something is remaining, it has remained
After something is developing, it has developed
After something is publishing, it has published
After something is asking, it has asked
After something is continuing, it has
2024-07-28 21:55:25 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-28 21:57:21 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 1.1680, -0.9248, -0.2874,  ..., -0.5952, -0.7915,  0.1769],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.7324, -1.7373,  2.4180,  ..., -1.4971,  0.1987, -1.6084],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0522,  0.0029,  0.0133,  ...,  0.0013,  0.0095,  0.0008],
        [-0.0202,  0.0373, -0.0008,  ...,  0.0238,  0.0037,  0.0027],
        [ 0.0073,  0.0037,  0.0325,  ..., -0.0121,  0.0045, -0.0105],
        ...,
        [ 0.0004,  0.0046,  0.0068,  ...,  0.0573,  0.0057,  0.0039],
        [ 0.0107,  0.0101, -0.0024,  ..., -0.0102,  0.0398, -0.0162],
        [-0.0022,  0.0003,  0.0031,  ..., -0.0064, -0.0132,  0.0350]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.7246, -1.5752,  2.3516,  ..., -1.4316,  0.0063, -1.5723]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 21:57:21 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for After something is suffering, it has suffered
After something is providing, it has provided
After something is replacing, it has replaced
After something is remaining, it has remained
After something is developing, it has developed
After something is publishing, it has published
After something is asking, it has asked
After something is continuing, it has
2024-07-28 21:57:21 root INFO     total operator prediction time: 931.0749754905701 seconds
2024-07-28 21:57:22 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on Ving - verb_inf
2024-07-28 21:57:22 root INFO     building operator Ving - verb_inf
2024-07-28 21:57:22 root INFO     [order_1_approx] starting weight calculation for identifying is the active form of identify
requiring is the active form of require
sitting is the active form of sit
attending is the active form of attend
maintaining is the active form of maintain
spending is the active form of spend
performing is the active form of perform
encouraging is the active form of
2024-07-28 21:57:22 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-28 21:59:17 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0324, -0.5107, -0.8008,  ..., -0.4321, -0.4497, -0.4995],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.8301, -2.6953, -0.4751,  ...,  4.0508, -1.4463, -2.9395],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0418, -0.0001,  0.0028,  ...,  0.0044,  0.0039,  0.0068],
        [-0.0081,  0.0396, -0.0026,  ...,  0.0096, -0.0003, -0.0040],
        [ 0.0050, -0.0009,  0.0369,  ..., -0.0035, -0.0043,  0.0006],
        ...,
        [ 0.0047,  0.0042, -0.0030,  ...,  0.0495, -0.0003,  0.0004],
        [-0.0016,  0.0008,  0.0009,  ...,  0.0028,  0.0407, -0.0106],
        [-0.0004,  0.0009, -0.0051,  ..., -0.0059, -0.0003,  0.0347]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.8208, -2.7539, -0.5391,  ...,  4.0703, -1.4219, -2.8320]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 21:59:18 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for identifying is the active form of identify
requiring is the active form of require
sitting is the active form of sit
attending is the active form of attend
maintaining is the active form of maintain
spending is the active form of spend
performing is the active form of perform
encouraging is the active form of
2024-07-28 21:59:19 root INFO     [order_1_approx] starting weight calculation for requiring is the active form of require
performing is the active form of perform
attending is the active form of attend
sitting is the active form of sit
spending is the active form of spend
encouraging is the active form of encourage
maintaining is the active form of maintain
identifying is the active form of
2024-07-28 21:59:19 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-28 22:01:13 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.3398, -0.4819, -0.0630,  ...,  0.0632, -0.9209, -0.5850],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.3223, -2.9609,  1.2412,  ...,  1.6465, -2.1914, -2.3047],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0594, -0.0073,  0.0089,  ...,  0.0022,  0.0108,  0.0077],
        [-0.0110,  0.0499, -0.0082,  ...,  0.0140,  0.0011, -0.0012],
        [ 0.0092, -0.0171,  0.0506,  ..., -0.0075,  0.0011,  0.0039],
        ...,
        [ 0.0080,  0.0039,  0.0008,  ...,  0.0694, -0.0034,  0.0046],
        [-0.0005,  0.0056,  0.0095,  ..., -0.0007,  0.0551, -0.0095],
        [ 0.0039,  0.0045,  0.0035,  ..., -0.0085, -0.0009,  0.0496]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.2947, -2.9922,  1.1621,  ...,  1.7432, -2.2129, -2.3750]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 22:01:14 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for requiring is the active form of require
performing is the active form of perform
attending is the active form of attend
sitting is the active form of sit
spending is the active form of spend
encouraging is the active form of encourage
maintaining is the active form of maintain
identifying is the active form of
2024-07-28 22:01:15 root INFO     [order_1_approx] starting weight calculation for maintaining is the active form of maintain
identifying is the active form of identify
attending is the active form of attend
performing is the active form of perform
sitting is the active form of sit
spending is the active form of spend
encouraging is the active form of encourage
requiring is the active form of
2024-07-28 22:01:15 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-28 22:03:08 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0605, -0.4014, -0.7178,  ..., -1.1465, -1.2188, -0.9863],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.1191, -3.8047,  1.7158,  ...,  0.4426, -3.1035, -2.0293],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0574, -0.0103,  0.0114,  ...,  0.0023,  0.0085,  0.0079],
        [-0.0080,  0.0551, -0.0052,  ...,  0.0059, -0.0027, -0.0065],
        [ 0.0138, -0.0047,  0.0460,  ..., -0.0168, -0.0021, -0.0025],
        ...,
        [ 0.0041,  0.0052, -0.0061,  ...,  0.0729, -0.0042,  0.0006],
        [-0.0071, -0.0060,  0.0138,  ...,  0.0003,  0.0533, -0.0133],
        [ 0.0036,  0.0035, -0.0079,  ..., -0.0108, -0.0034,  0.0650]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.8428, -3.7734,  1.5859,  ...,  0.6826, -3.0293, -1.9609]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 22:03:09 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for maintaining is the active form of maintain
identifying is the active form of identify
attending is the active form of attend
performing is the active form of perform
sitting is the active form of sit
spending is the active form of spend
encouraging is the active form of encourage
requiring is the active form of
2024-07-28 22:03:09 root INFO     [order_1_approx] starting weight calculation for spending is the active form of spend
sitting is the active form of sit
requiring is the active form of require
attending is the active form of attend
identifying is the active form of identify
encouraging is the active form of encourage
maintaining is the active form of maintain
performing is the active form of
2024-07-28 22:03:09 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-28 22:04:57 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 1.1699, -0.6074, -0.4021,  ..., -0.9238, -0.5859, -0.7188],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.8262, -4.0234,  2.3633,  ...,  1.9082, -1.2246, -3.1191],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0375, -0.0011,  0.0039,  ...,  0.0006,  0.0012,  0.0054],
        [-0.0044,  0.0222,  0.0018,  ...,  0.0013,  0.0017, -0.0034],
        [ 0.0097, -0.0079,  0.0224,  ..., -0.0025, -0.0034, -0.0065],
        ...,
        [ 0.0083,  0.0042, -0.0075,  ...,  0.0353, -0.0016, -0.0043],
        [-0.0040,  0.0011,  0.0064,  ...,  0.0004,  0.0232, -0.0028],
        [ 0.0015,  0.0048, -0.0012,  ..., -0.0075,  0.0002,  0.0249]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.9229, -4.0078,  2.2637,  ...,  1.9424, -1.2744, -3.1543]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 22:04:58 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for spending is the active form of spend
sitting is the active form of sit
requiring is the active form of require
attending is the active form of attend
identifying is the active form of identify
encouraging is the active form of encourage
maintaining is the active form of maintain
performing is the active form of
2024-07-28 22:04:58 root INFO     [order_1_approx] starting weight calculation for attending is the active form of attend
performing is the active form of perform
spending is the active form of spend
requiring is the active form of require
identifying is the active form of identify
encouraging is the active form of encourage
sitting is the active form of sit
maintaining is the active form of
2024-07-28 22:04:58 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-28 22:06:51 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.7754, -0.5840, -0.0984,  ..., -0.2163, -1.1719, -0.3921],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.2520, -4.8984, -0.4556,  ...,  0.4565, -0.6260, -1.6162],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 6.1951e-02, -1.0849e-02,  3.1891e-03,  ...,  3.8967e-03,
          5.2109e-03,  9.7885e-03],
        [-6.8665e-05,  4.5013e-02,  1.2770e-03,  ...,  1.2390e-02,
          4.3907e-03, -2.7990e-04],
        [ 1.0826e-02,  1.8654e-03,  4.4189e-02,  ..., -3.8395e-03,
         -2.4376e-03, -2.6588e-03],
        ...,
        [ 1.1322e-02,  1.0193e-02, -1.1578e-03,  ...,  5.4657e-02,
         -5.2490e-03,  5.3024e-04],
        [ 5.0621e-03,  1.3115e-02,  8.8654e-03,  ..., -1.5631e-03,
          3.4943e-02,  8.6403e-04],
        [ 6.2675e-03,  9.9487e-03, -6.2027e-03,  ..., -1.3443e-02,
         -1.5173e-03,  4.9225e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.4189, -4.7891, -0.3711,  ...,  0.4236, -0.7305, -1.6475]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 22:06:52 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for attending is the active form of attend
performing is the active form of perform
spending is the active form of spend
requiring is the active form of require
identifying is the active form of identify
encouraging is the active form of encourage
sitting is the active form of sit
maintaining is the active form of
2024-07-28 22:06:52 root INFO     [order_1_approx] starting weight calculation for spending is the active form of spend
encouraging is the active form of encourage
attending is the active form of attend
identifying is the active form of identify
maintaining is the active form of maintain
requiring is the active form of require
performing is the active form of perform
sitting is the active form of
2024-07-28 22:06:52 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-28 22:08:48 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3792, -1.4453, -0.2891,  ...,  0.0076, -1.3389, -0.1604],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.8896, -2.9375, -0.3691,  ..., -0.8477,  0.0479, -3.1973],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0966, -0.0094, -0.0012,  ..., -0.0004,  0.0055, -0.0010],
        [ 0.0024,  0.0709, -0.0057,  ...,  0.0086, -0.0063, -0.0211],
        [-0.0076, -0.0061,  0.0684,  ..., -0.0101,  0.0003, -0.0121],
        ...,
        [ 0.0136,  0.0020, -0.0019,  ...,  0.0797, -0.0188, -0.0125],
        [-0.0049,  0.0100,  0.0022,  ...,  0.0019,  0.0562, -0.0091],
        [ 0.0006,  0.0119, -0.0018,  ..., -0.0129, -0.0046,  0.0717]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.8281, -2.9570, -0.4668,  ..., -0.7285, -0.0745, -3.2500]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 22:08:50 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for spending is the active form of spend
encouraging is the active form of encourage
attending is the active form of attend
identifying is the active form of identify
maintaining is the active form of maintain
requiring is the active form of require
performing is the active form of perform
sitting is the active form of
2024-07-28 22:08:50 root INFO     [order_1_approx] starting weight calculation for maintaining is the active form of maintain
requiring is the active form of require
sitting is the active form of sit
encouraging is the active form of encourage
attending is the active form of attend
identifying is the active form of identify
performing is the active form of perform
spending is the active form of
2024-07-28 22:08:50 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-28 22:10:46 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0309, -0.6401,  0.2012,  ..., -0.3469, -0.5757, -0.6504],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.8896, -2.3828, -2.6562,  ...,  0.4805, -0.6323, -1.7666],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0743, -0.0068,  0.0072,  ...,  0.0004,  0.0038,  0.0115],
        [ 0.0034,  0.0454, -0.0044,  ...,  0.0059,  0.0019, -0.0097],
        [ 0.0082, -0.0013,  0.0499,  ...,  0.0020,  0.0022, -0.0086],
        ...,
        [ 0.0090,  0.0121, -0.0055,  ...,  0.0567, -0.0004,  0.0004],
        [-0.0028,  0.0085,  0.0017,  ...,  0.0074,  0.0480, -0.0093],
        [ 0.0051,  0.0013, -0.0126,  ..., -0.0153, -0.0006,  0.0499]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.8223, -2.3965, -2.6816,  ...,  0.2544, -0.7725, -1.8252]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 22:10:47 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for maintaining is the active form of maintain
requiring is the active form of require
sitting is the active form of sit
encouraging is the active form of encourage
attending is the active form of attend
identifying is the active form of identify
performing is the active form of perform
spending is the active form of
2024-07-28 22:10:47 root INFO     [order_1_approx] starting weight calculation for encouraging is the active form of encourage
identifying is the active form of identify
performing is the active form of perform
requiring is the active form of require
sitting is the active form of sit
maintaining is the active form of maintain
spending is the active form of spend
attending is the active form of
2024-07-28 22:10:47 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-28 22:12:42 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3816, -0.4805, -1.0635,  ..., -0.7578, -1.0010, -0.9795],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.8496, -2.5430, -1.6777,  ...,  2.2520, -3.1758, -3.5039],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0848, -0.0085,  0.0067,  ...,  0.0005,  0.0166,  0.0045],
        [-0.0081,  0.0807,  0.0015,  ...,  0.0034,  0.0003, -0.0176],
        [ 0.0015, -0.0111,  0.0716,  ..., -0.0002,  0.0009,  0.0040],
        ...,
        [ 0.0037,  0.0042,  0.0054,  ...,  0.0899, -0.0122, -0.0082],
        [-0.0124, -0.0015,  0.0046,  ...,  0.0031,  0.0643,  0.0002],
        [ 0.0003,  0.0091, -0.0105,  ..., -0.0052, -0.0033,  0.0775]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.8638, -2.6602, -1.9824,  ...,  2.3555, -3.0742, -3.5547]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 22:12:43 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for encouraging is the active form of encourage
identifying is the active form of identify
performing is the active form of perform
requiring is the active form of require
sitting is the active form of sit
maintaining is the active form of maintain
spending is the active form of spend
attending is the active form of
2024-07-28 22:12:43 root INFO     total operator prediction time: 921.5307974815369 seconds
2024-07-28 22:12:43 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on noun - plural_irreg
2024-07-28 22:12:43 root INFO     building operator noun - plural_irreg
2024-07-28 22:12:43 root INFO     [order_1_approx] starting weight calculation for The plural form of story is stories
The plural form of community is communities
The plural form of safety is safeties
The plural form of industry is industries
The plural form of history is histories
The plural form of family is families
The plural form of analysis is analyses
The plural form of security is
2024-07-28 22:12:43 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-28 22:14:40 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.7163, -0.4243, -0.6904,  ...,  0.0251, -0.2356, -0.3735],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.0896, -1.6289,  1.0615,  ...,  0.1145, -2.1230, -4.9414],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0829, -0.0050,  0.0274,  ..., -0.0016, -0.0050,  0.0273],
        [-0.0172,  0.0630,  0.0123,  ...,  0.0055,  0.0010,  0.0084],
        [ 0.0214,  0.0096,  0.0663,  ..., -0.0059, -0.0057, -0.0007],
        ...,
        [ 0.0100,  0.0131, -0.0095,  ...,  0.0789, -0.0026,  0.0023],
        [ 0.0242,  0.0089,  0.0064,  ...,  0.0068,  0.0687, -0.0193],
        [-0.0122,  0.0139, -0.0192,  ...,  0.0059, -0.0076,  0.0731]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.1241, -1.5400,  1.3936,  ..., -0.1848, -2.2051, -4.3320]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 22:14:41 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of story is stories
The plural form of community is communities
The plural form of safety is safeties
The plural form of industry is industries
The plural form of history is histories
The plural form of family is families
The plural form of analysis is analyses
The plural form of security is
2024-07-28 22:14:41 root INFO     [order_1_approx] starting weight calculation for The plural form of analysis is analyses
The plural form of family is families
The plural form of security is securities
The plural form of story is stories
The plural form of safety is safeties
The plural form of industry is industries
The plural form of community is communities
The plural form of history is
2024-07-28 22:14:41 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-28 22:16:36 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0481, -0.5752,  0.0181,  ..., -0.4807, -0.2020, -0.1025],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.4280, -1.8877,  1.2461,  ..., -2.0371, -3.4883, -2.9648],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0566,  0.0146,  0.0153,  ..., -0.0069, -0.0005,  0.0175],
        [-0.0100,  0.0568, -0.0021,  ...,  0.0164, -0.0100,  0.0024],
        [ 0.0175, -0.0018,  0.0448,  ..., -0.0070, -0.0023,  0.0151],
        ...,
        [ 0.0177,  0.0176, -0.0028,  ...,  0.0769,  0.0008,  0.0034],
        [-0.0028,  0.0074,  0.0114,  ..., -0.0060,  0.0551, -0.0076],
        [-0.0056,  0.0141, -0.0104,  ...,  0.0077, -0.0106,  0.0566]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.4463, -2.0312,  1.1904,  ..., -2.2129, -3.7539, -2.6289]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 22:16:37 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of analysis is analyses
The plural form of family is families
The plural form of security is securities
The plural form of story is stories
The plural form of safety is safeties
The plural form of industry is industries
The plural form of community is communities
The plural form of history is
2024-07-28 22:16:38 root INFO     [order_1_approx] starting weight calculation for The plural form of history is histories
The plural form of story is stories
The plural form of security is securities
The plural form of analysis is analyses
The plural form of family is families
The plural form of safety is safeties
The plural form of community is communities
The plural form of industry is
2024-07-28 22:16:38 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-28 22:18:32 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3989,  0.0624, -0.1436,  ..., -0.8164,  0.0496, -0.2476],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.0000, -3.0547,  0.6846,  ..., -0.8501, -1.5059, -1.7500],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0626,  0.0038, -0.0058,  ..., -0.0059,  0.0002,  0.0225],
        [-0.0089,  0.0401,  0.0041,  ...,  0.0203, -0.0127,  0.0055],
        [ 0.0168, -0.0031,  0.0527,  ..., -0.0205,  0.0080, -0.0112],
        ...,
        [ 0.0269,  0.0091,  0.0070,  ...,  0.0652,  0.0167, -0.0070],
        [-0.0064,  0.0072,  0.0069,  ..., -0.0008,  0.0515, -0.0099],
        [ 0.0001, -0.0049,  0.0008,  ...,  0.0118, -0.0094,  0.0472]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.1094, -2.7812,  0.4019,  ..., -1.3574, -1.2305, -1.3867]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 22:18:33 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of history is histories
The plural form of story is stories
The plural form of security is securities
The plural form of analysis is analyses
The plural form of family is families
The plural form of safety is safeties
The plural form of community is communities
The plural form of industry is
2024-07-28 22:18:33 root INFO     [order_1_approx] starting weight calculation for The plural form of analysis is analyses
The plural form of industry is industries
The plural form of family is families
The plural form of community is communities
The plural form of story is stories
The plural form of history is histories
The plural form of security is securities
The plural form of safety is
2024-07-28 22:18:34 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-28 22:20:28 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3235, -0.3052, -0.1074,  ..., -0.1213, -0.1309, -0.2451],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.6426, -0.4204, -0.6348,  ..., -0.5918, -3.4258, -1.9834],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0892, -0.0074,  0.0154,  ..., -0.0136,  0.0049,  0.0185],
        [-0.0125,  0.0736,  0.0008,  ...,  0.0046, -0.0046, -0.0062],
        [ 0.0077, -0.0063,  0.0817,  ..., -0.0045, -0.0053, -0.0202],
        ...,
        [ 0.0064,  0.0284, -0.0024,  ...,  0.1085, -0.0146, -0.0176],
        [ 0.0154,  0.0101,  0.0087,  ...,  0.0138,  0.0698, -0.0114],
        [-0.0099, -0.0020, -0.0073,  ...,  0.0053, -0.0162,  0.0971]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.1230, -0.6372,  0.0747,  ..., -0.9873, -3.4004, -1.8750]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 22:20:29 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of analysis is analyses
The plural form of industry is industries
The plural form of family is families
The plural form of community is communities
The plural form of story is stories
The plural form of history is histories
The plural form of security is securities
The plural form of safety is
2024-07-28 22:20:29 root INFO     [order_1_approx] starting weight calculation for The plural form of community is communities
The plural form of safety is safeties
The plural form of analysis is analyses
The plural form of industry is industries
The plural form of history is histories
The plural form of security is securities
The plural form of story is stories
The plural form of family is
2024-07-28 22:20:29 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-28 22:22:25 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0776, -0.3374,  0.0177,  ..., -0.0274, -0.6426, -0.3926],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.5156, -0.4688,  3.1289,  ..., -1.4951, -1.9180, -3.2871],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0980,  0.0321,  0.0252,  ..., -0.0167, -0.0204,  0.0108],
        [-0.0301,  0.0557, -0.0122,  ...,  0.0117,  0.0130,  0.0030],
        [ 0.0172,  0.0208,  0.0648,  ..., -0.0175, -0.0037,  0.0072],
        ...,
        [ 0.0071,  0.0094, -0.0136,  ...,  0.0670,  0.0032,  0.0029],
        [ 0.0011,  0.0217,  0.0077,  ..., -0.0019,  0.0504, -0.0069],
        [-0.0085, -0.0088, -0.0144,  ..., -0.0128, -0.0070,  0.0655]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.2754, -0.0964,  3.0020,  ..., -1.3242, -1.8457, -3.4746]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 22:22:26 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of community is communities
The plural form of safety is safeties
The plural form of analysis is analyses
The plural form of industry is industries
The plural form of history is histories
The plural form of security is securities
The plural form of story is stories
The plural form of family is
2024-07-28 22:22:27 root INFO     [order_1_approx] starting weight calculation for The plural form of community is communities
The plural form of history is histories
The plural form of analysis is analyses
The plural form of security is securities
The plural form of family is families
The plural form of industry is industries
The plural form of safety is safeties
The plural form of story is
2024-07-28 22:22:27 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-28 22:24:18 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2355, -0.0026, -0.0370,  ..., -0.4048, -0.9482, -0.1760],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.9922, -2.4922,  0.8057,  ..., -0.8057, -1.6270, -2.1797],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.1013,  0.0160,  0.0143,  ..., -0.0117, -0.0005,  0.0050],
        [ 0.0046,  0.0891, -0.0130,  ...,  0.0270, -0.0078,  0.0200],
        [ 0.0002, -0.0021,  0.0765,  ..., -0.0077, -0.0066,  0.0117],
        ...,
        [ 0.0374,  0.0272, -0.0169,  ...,  0.1224, -0.0004,  0.0130],
        [-0.0130,  0.0233,  0.0131,  ..., -0.0061,  0.0779, -0.0162],
        [ 0.0038,  0.0181,  0.0086,  ..., -0.0024, -0.0154,  0.0982]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.1133, -2.4844,  0.8369,  ..., -0.4451, -1.7100, -1.7666]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 22:24:19 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of community is communities
The plural form of history is histories
The plural form of analysis is analyses
The plural form of security is securities
The plural form of family is families
The plural form of industry is industries
The plural form of safety is safeties
The plural form of story is
2024-07-28 22:24:20 root INFO     [order_1_approx] starting weight calculation for The plural form of safety is safeties
The plural form of community is communities
The plural form of industry is industries
The plural form of history is histories
The plural form of security is securities
The plural form of family is families
The plural form of story is stories
The plural form of analysis is
2024-07-28 22:24:20 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-28 22:26:15 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1143, -0.3447, -0.1144,  ...,  0.4285, -0.4819, -0.1384],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.1709,  0.3645,  3.1660,  ..., -1.4473, -3.2695, -1.3350],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.1006, -0.0001,  0.0029,  ..., -0.0097, -0.0107, -0.0003],
        [-0.0069,  0.0845,  0.0059,  ...,  0.0245, -0.0103,  0.0163],
        [ 0.0013,  0.0058,  0.0801,  ..., -0.0057,  0.0031,  0.0062],
        ...,
        [ 0.0214,  0.0217, -0.0070,  ...,  0.1146, -0.0079,  0.0187],
        [ 0.0013,  0.0184,  0.0039,  ...,  0.0060,  0.0842, -0.0081],
        [-0.0024,  0.0213,  0.0016,  ..., -0.0012, -0.0164,  0.0909]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.3301,  0.5762,  3.1270,  ..., -0.9092, -2.7754, -0.9165]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 22:26:16 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of safety is safeties
The plural form of community is communities
The plural form of industry is industries
The plural form of history is histories
The plural form of security is securities
The plural form of family is families
The plural form of story is stories
The plural form of analysis is
2024-07-28 22:26:16 root INFO     [order_1_approx] starting weight calculation for The plural form of story is stories
The plural form of safety is safeties
The plural form of security is securities
The plural form of analysis is analyses
The plural form of history is histories
The plural form of industry is industries
The plural form of family is families
The plural form of community is
2024-07-28 22:26:16 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-28 22:28:10 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.6006,  0.1270, -0.3140,  ..., -0.1497, -0.6968, -0.2461],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.2871, -3.9141,  1.1709,  ..., -3.6016,  0.9868, -1.4697],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0489,  0.0075,  0.0143,  ...,  0.0010,  0.0072,  0.0224],
        [-0.0057,  0.0388,  0.0060,  ...,  0.0164, -0.0044,  0.0058],
        [ 0.0039, -0.0085,  0.0557,  ..., -0.0143, -0.0106,  0.0150],
        ...,
        [ 0.0204,  0.0017,  0.0093,  ...,  0.0686, -0.0111,  0.0027],
        [ 0.0065,  0.0211, -0.0015,  ..., -0.0044,  0.0480, -0.0136],
        [ 0.0048, -0.0046, -0.0142,  ..., -0.0073, -0.0049,  0.0455]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.1953, -3.5977,  1.0039,  ..., -3.5918,  0.6479, -1.4922]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 22:28:11 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of story is stories
The plural form of safety is safeties
The plural form of security is securities
The plural form of analysis is analyses
The plural form of history is histories
The plural form of industry is industries
The plural form of family is families
The plural form of community is
2024-07-28 22:28:11 root INFO     total operator prediction time: 928.043294429779 seconds
2024-07-28 22:28:11 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on meronyms - member
2024-07-28 22:28:11 root INFO     building operator meronyms - member
2024-07-28 22:28:11 root INFO     [order_1_approx] starting weight calculation for A soldier is a member of a army
A cattle is a member of a herd
A county is a member of a state
A kitten is a member of a litter
A college is a member of a university
A acrobat is a member of a troupe
A letter is a member of a alphabet
A cat is a member of a
2024-07-28 22:28:11 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-28 22:30:08 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0995, -0.8286,  0.3877,  ..., -0.5732, -0.7432,  0.2832],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.7734, -3.7754,  2.3125,  ..., -2.7227, -1.8506, -1.8701],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0271,  0.0023, -0.0078,  ..., -0.0028, -0.0069, -0.0009],
        [ 0.0022,  0.0190, -0.0015,  ..., -0.0007,  0.0141, -0.0021],
        [ 0.0022, -0.0045,  0.0353,  ...,  0.0038, -0.0099, -0.0003],
        ...,
        [ 0.0032, -0.0013,  0.0031,  ...,  0.0228, -0.0015, -0.0075],
        [ 0.0137,  0.0098, -0.0077,  ...,  0.0072,  0.0237, -0.0116],
        [-0.0105,  0.0047,  0.0005,  ..., -0.0135, -0.0041,  0.0247]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.4941, -3.5879,  2.2891,  ..., -2.5820, -2.3906, -1.6348]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 22:30:09 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A soldier is a member of a army
A cattle is a member of a herd
A county is a member of a state
A kitten is a member of a litter
A college is a member of a university
A acrobat is a member of a troupe
A letter is a member of a alphabet
A cat is a member of a
2024-07-28 22:30:09 root INFO     [order_1_approx] starting weight calculation for A letter is a member of a alphabet
A cattle is a member of a herd
A acrobat is a member of a troupe
A college is a member of a university
A soldier is a member of a army
A county is a member of a state
A cat is a member of a clowder
A kitten is a member of a
2024-07-28 22:30:09 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-28 22:32:06 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.4556, -0.2465, -0.2036,  ..., -0.2637, -1.1777, -0.0619],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 5.0820, -2.5293, -1.0039,  ..., -1.1465, -0.1377, -2.0820],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0247, -0.0056, -0.0014,  ..., -0.0073, -0.0018,  0.0071],
        [ 0.0020,  0.0354, -0.0111,  ...,  0.0027,  0.0006, -0.0042],
        [-0.0064, -0.0004,  0.0348,  ...,  0.0045, -0.0120,  0.0039],
        ...,
        [ 0.0028, -0.0009, -0.0066,  ...,  0.0363, -0.0037, -0.0078],
        [ 0.0066,  0.0048, -0.0046,  ...,  0.0071,  0.0251,  0.0009],
        [-0.0033, -0.0026, -0.0045,  ..., -0.0145, -0.0015,  0.0241]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 5.2461, -2.5781, -0.7969,  ..., -1.1641, -0.3984, -1.9111]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 22:32:07 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A letter is a member of a alphabet
A cattle is a member of a herd
A acrobat is a member of a troupe
A college is a member of a university
A soldier is a member of a army
A county is a member of a state
A cat is a member of a clowder
A kitten is a member of a
2024-07-28 22:32:07 root INFO     [order_1_approx] starting weight calculation for A letter is a member of a alphabet
A acrobat is a member of a troupe
A county is a member of a state
A kitten is a member of a litter
A cattle is a member of a herd
A soldier is a member of a army
A cat is a member of a clowder
A college is a member of a
2024-07-28 22:32:07 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-28 22:34:03 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0250,  0.0490, -0.3574,  ..., -0.1333, -0.6240, -0.4299],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.3926, -5.1875,  3.7715,  ..., -2.4727,  1.5830, -1.9043],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 4.1931e-02,  6.0654e-03,  8.8196e-03,  ...,  5.3787e-03,
          3.7537e-03, -6.1274e-04],
        [-3.7689e-03,  3.4393e-02, -5.3406e-05,  ..., -2.7199e-03,
          4.3793e-03, -2.1881e-02],
        [ 6.4850e-03, -7.3395e-03,  3.3020e-02,  ..., -1.5503e-02,
         -6.6452e-03,  7.3776e-03],
        ...,
        [ 1.7792e-02, -7.2098e-04, -1.1497e-02,  ...,  4.4922e-02,
         -3.8147e-06, -1.5915e-02],
        [ 6.2103e-03,  9.8419e-04, -2.7351e-03,  ..., -9.9182e-04,
          3.5706e-02,  8.3771e-03],
        [-9.3079e-03,  1.9775e-02,  4.0321e-03,  ...,  1.1780e-02,
          4.1695e-03,  3.2227e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.1681, -4.8672,  3.7754,  ..., -2.2227,  1.4268, -1.9551]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 22:34:04 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A letter is a member of a alphabet
A acrobat is a member of a troupe
A county is a member of a state
A kitten is a member of a litter
A cattle is a member of a herd
A soldier is a member of a army
A cat is a member of a clowder
A college is a member of a
2024-07-28 22:34:04 root INFO     [order_1_approx] starting weight calculation for A college is a member of a university
A soldier is a member of a army
A cattle is a member of a herd
A letter is a member of a alphabet
A county is a member of a state
A cat is a member of a clowder
A kitten is a member of a litter
A acrobat is a member of a
2024-07-28 22:34:04 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-28 22:35:57 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.6060, -0.2112,  0.5820,  ..., -0.1973, -1.4824, -0.0163],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.8047, -6.0859,  3.7734,  ...,  1.4551, -0.4053, -0.2427],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0401,  0.0026,  0.0125,  ..., -0.0024, -0.0052, -0.0039],
        [-0.0015,  0.0222,  0.0015,  ..., -0.0056,  0.0027, -0.0041],
        [-0.0051, -0.0020,  0.0401,  ...,  0.0035, -0.0062,  0.0041],
        ...,
        [ 0.0162,  0.0018, -0.0022,  ...,  0.0446, -0.0040, -0.0046],
        [ 0.0096,  0.0041, -0.0077,  ...,  0.0041,  0.0410, -0.0014],
        [-0.0076,  0.0058, -0.0121,  ...,  0.0059, -0.0035,  0.0425]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.8516, -6.0078,  3.6250,  ...,  1.2354, -0.5371, -0.3994]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 22:35:59 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A college is a member of a university
A soldier is a member of a army
A cattle is a member of a herd
A letter is a member of a alphabet
A county is a member of a state
A cat is a member of a clowder
A kitten is a member of a litter
A acrobat is a member of a
2024-07-28 22:35:59 root INFO     [order_1_approx] starting weight calculation for A college is a member of a university
A acrobat is a member of a troupe
A cat is a member of a clowder
A letter is a member of a alphabet
A soldier is a member of a army
A county is a member of a state
A kitten is a member of a litter
A cattle is a member of a
2024-07-28 22:35:59 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-28 22:37:55 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0784, -0.2034,  0.0033,  ..., -0.5503, -0.3909,  0.0295],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 5.3203, -2.2246,  2.5078,  ..., -3.5039, -0.8491, -2.2559],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 3.5034e-02, -3.1090e-03,  8.0261e-03,  ..., -7.6981e-03,
          6.7139e-03, -9.2087e-03],
        [ 1.1024e-02,  3.4180e-02, -5.1270e-03,  ...,  6.4468e-03,
         -5.2414e-03, -1.4305e-06],
        [ 2.4624e-03, -1.3275e-03,  2.5864e-02,  ..., -2.9793e-03,
          4.7607e-03, -1.1658e-02],
        ...,
        [ 4.5815e-03, -1.4019e-03, -5.0354e-03,  ...,  4.2419e-02,
         -6.0120e-03, -1.0193e-02],
        [-3.9024e-03,  1.1612e-02, -3.2730e-03,  ...,  8.9035e-03,
          3.6957e-02, -3.9625e-04],
        [-1.0109e-03, -5.9891e-03, -5.0211e-04,  ..., -5.1270e-03,
          5.4550e-04,  4.0344e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 5.2266, -2.5059,  2.6504,  ..., -3.1836, -1.1328, -2.2422]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 22:37:57 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A college is a member of a university
A acrobat is a member of a troupe
A cat is a member of a clowder
A letter is a member of a alphabet
A soldier is a member of a army
A county is a member of a state
A kitten is a member of a litter
A cattle is a member of a
2024-07-28 22:37:58 root INFO     [order_1_approx] starting weight calculation for A kitten is a member of a litter
A cattle is a member of a herd
A letter is a member of a alphabet
A college is a member of a university
A county is a member of a state
A acrobat is a member of a troupe
A cat is a member of a clowder
A soldier is a member of a
2024-07-28 22:37:58 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-28 22:39:55 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0660,  0.6924, -0.6172,  ..., -0.1898, -1.0938, -0.3713],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.3086, -5.9844,  3.3066,  ..., -1.4883,  1.6436, -3.4395],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 3.4637e-02,  5.8517e-03, -1.1749e-03,  ..., -5.8594e-03,
          2.9106e-03, -2.7714e-03],
        [-1.8263e-03,  3.9246e-02,  1.6785e-03,  ..., -6.7368e-03,
          5.5122e-04, -6.1531e-03],
        [ 4.2801e-03,  7.7438e-04,  3.7689e-02,  ..., -2.5024e-03,
          7.3586e-03,  1.8301e-03],
        ...,
        [ 4.4479e-03,  1.0895e-02, -5.9166e-03,  ...,  4.0131e-02,
         -3.9215e-03, -2.3804e-03],
        [ 8.6441e-03,  1.0803e-02, -1.0300e-04,  ...,  5.6763e-03,
          3.4546e-02, -3.7804e-03],
        [ 2.3174e-03, -4.4870e-04, -4.9210e-03,  ..., -2.7676e-03,
         -7.0572e-05,  3.1250e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.4626, -6.0195,  3.3770,  ..., -1.5469,  1.5234, -3.3867]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 22:39:56 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A kitten is a member of a litter
A cattle is a member of a herd
A letter is a member of a alphabet
A college is a member of a university
A county is a member of a state
A acrobat is a member of a troupe
A cat is a member of a clowder
A soldier is a member of a
2024-07-28 22:39:56 root INFO     [order_1_approx] starting weight calculation for A county is a member of a state
A college is a member of a university
A cat is a member of a clowder
A kitten is a member of a litter
A acrobat is a member of a troupe
A soldier is a member of a army
A cattle is a member of a herd
A letter is a member of a
2024-07-28 22:39:56 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-28 22:41:51 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0415, -0.0787, -0.8857,  ..., -0.7510, -0.3711, -0.9580],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.4788, -2.4883, -0.0211,  ...,  1.1113, -2.5508, -1.8154],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0758, -0.0138,  0.0040,  ..., -0.0040, -0.0124,  0.0125],
        [-0.0147,  0.0565, -0.0105,  ..., -0.0076,  0.0186, -0.0055],
        [ 0.0028, -0.0116,  0.0577,  ...,  0.0031,  0.0086,  0.0139],
        ...,
        [ 0.0039,  0.0044, -0.0035,  ...,  0.0496,  0.0040, -0.0002],
        [ 0.0007, -0.0161, -0.0018,  ...,  0.0034,  0.0471, -0.0006],
        [-0.0076,  0.0065, -0.0007,  ..., -0.0102,  0.0190,  0.0649]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.4170, -2.1816,  0.5635,  ...,  0.8506, -2.3320, -1.4863]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 22:41:52 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A county is a member of a state
A college is a member of a university
A cat is a member of a clowder
A kitten is a member of a litter
A acrobat is a member of a troupe
A soldier is a member of a army
A cattle is a member of a herd
A letter is a member of a
2024-07-28 22:41:52 root INFO     [order_1_approx] starting weight calculation for A acrobat is a member of a troupe
A cat is a member of a clowder
A cattle is a member of a herd
A college is a member of a university
A kitten is a member of a litter
A soldier is a member of a army
A letter is a member of a alphabet
A county is a member of a
2024-07-28 22:41:52 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-28 22:43:48 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0676, -0.5469, -0.5542,  ..., -0.5352, -0.0924,  0.4028],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.1138, -5.5312,  3.4434,  ..., -5.5117,  3.9023, -4.1016],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0271,  0.0014,  0.0067,  ..., -0.0040,  0.0105, -0.0046],
        [-0.0124,  0.0403, -0.0044,  ..., -0.0188, -0.0040, -0.0029],
        [ 0.0096,  0.0083,  0.0306,  ...,  0.0066, -0.0071,  0.0031],
        ...,
        [ 0.0087,  0.0070, -0.0035,  ...,  0.0206, -0.0059, -0.0080],
        [ 0.0067, -0.0027, -0.0105,  ...,  0.0145,  0.0292, -0.0065],
        [-0.0166,  0.0096, -0.0047,  ..., -0.0041,  0.0071,  0.0333]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.2524, -4.9531,  3.5410,  ..., -5.4570,  3.5762, -4.1055]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 22:43:49 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A acrobat is a member of a troupe
A cat is a member of a clowder
A cattle is a member of a herd
A college is a member of a university
A kitten is a member of a litter
A soldier is a member of a army
A letter is a member of a alphabet
A county is a member of a
2024-07-28 22:43:49 root INFO     total operator prediction time: 937.9433333873749 seconds
2024-07-28 22:43:49 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on antonyms - binary
2024-07-28 22:43:49 root INFO     building operator antonyms - binary
2024-07-28 22:43:49 root INFO     [order_1_approx] starting weight calculation for The opposite of fall is rise
The opposite of top is bottom
The opposite of toward is away
The opposite of submerge is emerge
The opposite of interior is exterior
The opposite of before is after
The opposite of in is out
The opposite of west is
2024-07-28 22:43:49 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-28 22:45:45 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1923, -0.0298, -0.2014,  ..., -0.3997,  0.7993, -0.4177],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.6387, -3.1445, -1.2207,  ..., -1.1543,  0.7139, -1.6338],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 8.6243e-02, -3.1910e-03, -1.2917e-02,  ...,  4.0436e-04,
          1.4328e-02,  1.9775e-02],
        [ 1.2054e-02,  5.5634e-02, -1.4397e-02,  ...,  9.2621e-03,
          2.7237e-03,  2.3155e-03],
        [-7.2937e-03, -8.3618e-03,  2.6581e-02,  ..., -2.0020e-02,
          6.0034e-04,  1.3779e-02],
        ...,
        [ 1.2985e-02, -1.1887e-02, -2.9354e-03,  ...,  7.9895e-02,
         -3.0937e-03, -8.9645e-05],
        [-1.8631e-02, -4.5563e-02,  1.8005e-02,  ...,  1.6739e-02,
          6.8909e-02,  7.7057e-03],
        [ 2.3937e-03,  1.6422e-03, -9.7198e-03,  ...,  1.7761e-02,
         -8.7967e-03,  3.4485e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.0586, -2.5254, -0.8076,  ..., -0.8457,  0.9883, -1.6309]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 22:46:01 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of fall is rise
The opposite of top is bottom
The opposite of toward is away
The opposite of submerge is emerge
The opposite of interior is exterior
The opposite of before is after
The opposite of in is out
The opposite of west is
2024-07-28 22:46:01 root INFO     [order_1_approx] starting weight calculation for The opposite of toward is away
The opposite of in is out
The opposite of fall is rise
The opposite of top is bottom
The opposite of west is east
The opposite of before is after
The opposite of interior is exterior
The opposite of submerge is
2024-07-28 22:46:01 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-28 22:47:54 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.4111,  0.5332,  0.3816,  ..., -0.5020, -0.8262, -0.3022],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.2676, -0.6772, -0.0425,  ...,  3.9746, -1.6133, -0.2910],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.1118, -0.0027, -0.0361,  ..., -0.0009,  0.0471,  0.0237],
        [-0.0028,  0.0653,  0.0197,  ...,  0.0174, -0.0235, -0.0099],
        [-0.0099,  0.0286,  0.0641,  ..., -0.0076,  0.0124, -0.0037],
        ...,
        [-0.0014,  0.0044,  0.0190,  ...,  0.0879, -0.0171, -0.0071],
        [-0.0064,  0.0204,  0.0431,  ...,  0.0010,  0.0588, -0.0148],
        [-0.0306,  0.0101,  0.0038,  ..., -0.0428, -0.0091,  0.0560]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.4160, -1.1143, -0.0098,  ...,  3.8008, -1.7188, -0.2827]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 22:47:55 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of toward is away
The opposite of in is out
The opposite of fall is rise
The opposite of top is bottom
The opposite of west is east
The opposite of before is after
The opposite of interior is exterior
The opposite of submerge is
2024-07-28 22:47:55 root INFO     [order_1_approx] starting weight calculation for The opposite of toward is away
The opposite of top is bottom
The opposite of submerge is emerge
The opposite of interior is exterior
The opposite of before is after
The opposite of in is out
The opposite of west is east
The opposite of fall is
2024-07-28 22:47:55 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-28 22:49:48 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0057, -0.3308, -0.3042,  ..., -0.4736, -0.4922, -0.9219],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.5918, -0.9180,  2.0898,  ...,  1.9160, -2.0078, -1.7480],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 1.1102e-01, -1.5364e-03,  4.9973e-03,  ...,  2.5452e-02,
          7.5531e-04,  1.7593e-02],
        [ 2.5139e-03,  1.0449e-01, -6.5536e-03,  ...,  1.1589e-02,
          1.0437e-02, -8.9111e-03],
        [-1.5617e-02, -3.5324e-03,  9.5886e-02,  ..., -2.7756e-02,
         -1.0139e-02,  2.8687e-03],
        ...,
        [ 7.2174e-03,  1.1902e-02, -1.1093e-02,  ...,  1.0327e-01,
          3.8147e-06, -7.3814e-03],
        [-4.0649e-02,  3.6507e-03,  1.6479e-03,  ..., -5.0774e-03,
          7.0007e-02,  1.1459e-02],
        [-2.2766e-02,  4.8279e-02,  5.4588e-03,  ..., -2.6886e-02,
          1.4145e-02,  9.8572e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.6904, -0.3291,  1.7842,  ...,  1.6680, -2.2754, -1.2598]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 22:49:49 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of toward is away
The opposite of top is bottom
The opposite of submerge is emerge
The opposite of interior is exterior
The opposite of before is after
The opposite of in is out
The opposite of west is east
The opposite of fall is
2024-07-28 22:49:49 root INFO     [order_1_approx] starting weight calculation for The opposite of before is after
The opposite of in is out
The opposite of top is bottom
The opposite of submerge is emerge
The opposite of fall is rise
The opposite of toward is away
The opposite of west is east
The opposite of interior is
2024-07-28 22:49:49 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-28 22:51:42 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0553, -0.0366,  0.3931,  ..., -0.1143,  0.3108, -0.0332],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.9458, -2.0000,  3.4531,  ..., -1.1436, -0.8428, -3.0117],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.1147,  0.0059,  0.0207,  ..., -0.0093,  0.0205,  0.0111],
        [ 0.0139,  0.1151, -0.0130,  ...,  0.0217, -0.0089, -0.0096],
        [ 0.0122, -0.0091,  0.0832,  ..., -0.0075,  0.0095,  0.0021],
        ...,
        [ 0.0036,  0.0103,  0.0058,  ...,  0.0891,  0.0060, -0.0196],
        [-0.0193,  0.0076,  0.0190,  ...,  0.0009,  0.0875,  0.0093],
        [-0.0082,  0.0287, -0.0254,  ...,  0.0128, -0.0172,  0.1071]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.0273, -1.8164,  2.9844,  ..., -0.7358, -1.2627, -2.4434]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 22:51:43 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of before is after
The opposite of in is out
The opposite of top is bottom
The opposite of submerge is emerge
The opposite of fall is rise
The opposite of toward is away
The opposite of west is east
The opposite of interior is
2024-07-28 22:51:43 root INFO     [order_1_approx] starting weight calculation for The opposite of toward is away
The opposite of submerge is emerge
The opposite of west is east
The opposite of before is after
The opposite of fall is rise
The opposite of top is bottom
The opposite of interior is exterior
The opposite of in is
2024-07-28 22:51:43 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-28 22:53:37 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1553,  0.3755, -0.5776,  ...,  0.0208, -0.1073, -0.6162],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.0195, -4.3594,  1.6406,  ..., -3.1016,  0.2275, -5.5430],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0700, -0.0083, -0.0051,  ...,  0.0044,  0.0109,  0.0136],
        [-0.0049,  0.0561, -0.0180,  ...,  0.0022,  0.0047,  0.0102],
        [-0.0133, -0.0008,  0.0238,  ..., -0.0034,  0.0013, -0.0035],
        ...,
        [-0.0143,  0.0092,  0.0088,  ...,  0.0612,  0.0110, -0.0134],
        [ 0.0124, -0.0013,  0.0054,  ..., -0.0235,  0.0346,  0.0002],
        [-0.0033,  0.0010,  0.0124,  ..., -0.0088, -0.0122,  0.0419]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.2825, -4.2773,  1.8008,  ..., -2.6621,  0.0728, -5.6133]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 22:53:38 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of toward is away
The opposite of submerge is emerge
The opposite of west is east
The opposite of before is after
The opposite of fall is rise
The opposite of top is bottom
The opposite of interior is exterior
The opposite of in is
2024-07-28 22:53:38 root INFO     [order_1_approx] starting weight calculation for The opposite of fall is rise
The opposite of interior is exterior
The opposite of submerge is emerge
The opposite of toward is away
The opposite of west is east
The opposite of before is after
The opposite of in is out
The opposite of top is
2024-07-28 22:53:38 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-28 22:55:35 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1406,  0.1337,  0.2983,  ..., -0.0179, -0.0121, -1.1250],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.3438, -2.3438,  0.0698,  ..., -2.8789,  3.8008, -4.1875],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0942,  0.0054, -0.0042,  ..., -0.0028,  0.0325,  0.0209],
        [ 0.0184,  0.0794, -0.0213,  ...,  0.0166,  0.0111, -0.0117],
        [-0.0103, -0.0063,  0.0872,  ..., -0.0003, -0.0081,  0.0027],
        ...,
        [-0.0041,  0.0044,  0.0017,  ...,  0.1020,  0.0101, -0.0024],
        [-0.0093, -0.0070, -0.0017,  ...,  0.0224,  0.0557,  0.0016],
        [ 0.0113, -0.0238, -0.0034,  ..., -0.0032,  0.0057,  0.0617]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.6699, -2.4238,  0.3320,  ..., -2.4570,  3.0469, -3.8711]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 22:55:36 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of fall is rise
The opposite of interior is exterior
The opposite of submerge is emerge
The opposite of toward is away
The opposite of west is east
The opposite of before is after
The opposite of in is out
The opposite of top is
2024-07-28 22:55:36 root INFO     [order_1_approx] starting weight calculation for The opposite of fall is rise
The opposite of in is out
The opposite of submerge is emerge
The opposite of top is bottom
The opposite of west is east
The opposite of before is after
The opposite of interior is exterior
The opposite of toward is
2024-07-28 22:55:36 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-28 22:57:30 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4946, -0.1088, -0.8784,  ..., -0.2993,  0.3091, -0.1860],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.3672, -3.6992,  1.1338,  ..., -1.0615, -0.6729, -4.3086],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.1021,  0.0193,  0.0080,  ...,  0.0098,  0.0179,  0.0097],
        [-0.0161,  0.0868, -0.0286,  ...,  0.0206,  0.0097, -0.0102],
        [-0.0117, -0.0047,  0.0644,  ..., -0.0059, -0.0186,  0.0073],
        ...,
        [ 0.0063,  0.0206,  0.0011,  ...,  0.1049, -0.0054,  0.0040],
        [-0.0283, -0.0201,  0.0189,  ...,  0.0222,  0.0729, -0.0058],
        [ 0.0046, -0.0126, -0.0078,  ...,  0.0119,  0.0086,  0.0742]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.7778, -3.8242,  1.4531,  ..., -0.6748, -0.3467, -4.0469]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 22:57:31 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of fall is rise
The opposite of in is out
The opposite of submerge is emerge
The opposite of top is bottom
The opposite of west is east
The opposite of before is after
The opposite of interior is exterior
The opposite of toward is
2024-07-28 22:57:31 root INFO     [order_1_approx] starting weight calculation for The opposite of fall is rise
The opposite of top is bottom
The opposite of west is east
The opposite of toward is away
The opposite of in is out
The opposite of interior is exterior
The opposite of submerge is emerge
The opposite of before is
2024-07-28 22:57:31 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-28 22:59:20 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0596, -0.2393, -0.4045,  ..., -0.5557,  0.1431, -0.4382],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.8027, -2.3340, -0.7236,  ...,  0.3037, -2.2656, -3.4492],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0743, -0.0024,  0.0068,  ..., -0.0020,  0.0050,  0.0142],
        [ 0.0030,  0.0627, -0.0241,  ...,  0.0167,  0.0002, -0.0049],
        [-0.0069,  0.0060,  0.0431,  ..., -0.0037, -0.0051, -0.0049],
        ...,
        [ 0.0123,  0.0064,  0.0011,  ...,  0.0632, -0.0032, -0.0119],
        [-0.0247, -0.0012,  0.0089,  ...,  0.0090,  0.0390,  0.0108],
        [-0.0170, -0.0039, -0.0058,  ..., -0.0037,  0.0064,  0.0472]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.7275, -2.0371, -0.5127,  ...,  0.1827, -2.4824, -3.2656]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 22:59:21 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of fall is rise
The opposite of top is bottom
The opposite of west is east
The opposite of toward is away
The opposite of in is out
The opposite of interior is exterior
The opposite of submerge is emerge
The opposite of before is
2024-07-28 22:59:21 root INFO     total operator prediction time: 932.3654510974884 seconds
2024-07-28 22:59:21 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on hyponyms - misc
2024-07-28 22:59:21 root INFO     building operator hyponyms - misc
2024-07-28 22:59:22 root INFO     [order_1_approx] starting weight calculation for A more specific term for a painting is watercolor
A more specific term for a flask is thermos
A more specific term for a tool is rake
A more specific term for a season is spring
A more specific term for a emotion is anger
A more specific term for a month is january
A more specific term for a weapon is gun
A more specific term for a mixer is
2024-07-28 22:59:22 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-28 23:01:12 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2798,  0.0602,  0.1653,  ...,  1.0537, -0.7349, -0.1799],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.5508, -4.3086, -1.9004,  ...,  0.2769, -1.6484, -1.0703],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0671, -0.0053, -0.0059,  ...,  0.0099, -0.0117, -0.0170],
        [ 0.0172,  0.0454,  0.0124,  ...,  0.0028,  0.0034, -0.0121],
        [ 0.0082, -0.0061,  0.0475,  ...,  0.0012,  0.0039,  0.0293],
        ...,
        [ 0.0050,  0.0045, -0.0111,  ...,  0.0789, -0.0139, -0.0032],
        [-0.0176,  0.0007, -0.0060,  ...,  0.0037,  0.0908, -0.0077],
        [ 0.0126,  0.0136, -0.0015,  ..., -0.0060, -0.0107,  0.0595]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.4053, -4.2344, -1.9395,  ...,  0.5781, -1.2891, -1.1221]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 23:01:13 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more specific term for a painting is watercolor
A more specific term for a flask is thermos
A more specific term for a tool is rake
A more specific term for a season is spring
A more specific term for a emotion is anger
A more specific term for a month is january
A more specific term for a weapon is gun
A more specific term for a mixer is
2024-07-28 23:01:13 root INFO     [order_1_approx] starting weight calculation for A more specific term for a emotion is anger
A more specific term for a flask is thermos
A more specific term for a season is spring
A more specific term for a painting is watercolor
A more specific term for a mixer is blender
A more specific term for a weapon is gun
A more specific term for a month is january
A more specific term for a tool is
2024-07-28 23:01:13 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-28 23:03:06 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2742, -1.1289,  0.2896,  ...,  0.2598, -0.1935, -0.0190],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.2573, -4.1875, -0.0664,  ...,  1.3516, -3.4238,  0.3086],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0629, -0.0020,  0.0117,  ..., -0.0023, -0.0054,  0.0092],
        [ 0.0095,  0.0427, -0.0057,  ..., -0.0022,  0.0109, -0.0165],
        [-0.0166, -0.0017,  0.0489,  ...,  0.0007,  0.0050, -0.0005],
        ...,
        [ 0.0168,  0.0056, -0.0118,  ...,  0.0741, -0.0041,  0.0072],
        [ 0.0093,  0.0061, -0.0072,  ..., -0.0034,  0.0628, -0.0063],
        [-0.0009,  0.0258,  0.0017,  ..., -0.0040,  0.0160,  0.0453]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.3816, -4.3789,  0.0237,  ...,  1.6543, -3.1875,  0.1560]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 23:03:07 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more specific term for a emotion is anger
A more specific term for a flask is thermos
A more specific term for a season is spring
A more specific term for a painting is watercolor
A more specific term for a mixer is blender
A more specific term for a weapon is gun
A more specific term for a month is january
A more specific term for a tool is
2024-07-28 23:03:07 root INFO     [order_1_approx] starting weight calculation for A more specific term for a tool is rake
A more specific term for a flask is thermos
A more specific term for a weapon is gun
A more specific term for a painting is watercolor
A more specific term for a mixer is blender
A more specific term for a season is spring
A more specific term for a emotion is anger
A more specific term for a month is
2024-07-28 23:03:07 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-28 23:04:58 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1488, -1.0361, -0.2876,  ...,  0.0332, -0.3340,  0.1957],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 5.0547, -6.4648,  5.5781,  ..., -1.8828,  1.3604,  0.3948],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0517, -0.0097,  0.0075,  ..., -0.0086,  0.0083,  0.0142],
        [ 0.0031,  0.0504,  0.0045,  ...,  0.0027,  0.0123, -0.0002],
        [-0.0065,  0.0018,  0.0402,  ...,  0.0035, -0.0126,  0.0019],
        ...,
        [ 0.0105,  0.0065,  0.0093,  ...,  0.0786,  0.0072, -0.0045],
        [-0.0122,  0.0023, -0.0174,  ..., -0.0129,  0.0448, -0.0033],
        [ 0.0031,  0.0108, -0.0028,  ...,  0.0045,  0.0034,  0.0483]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 5.2539, -6.2422,  5.3438,  ..., -1.7998,  0.9570,  0.5229]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 23:04:59 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more specific term for a tool is rake
A more specific term for a flask is thermos
A more specific term for a weapon is gun
A more specific term for a painting is watercolor
A more specific term for a mixer is blender
A more specific term for a season is spring
A more specific term for a emotion is anger
A more specific term for a month is
2024-07-28 23:05:00 root INFO     [order_1_approx] starting weight calculation for A more specific term for a weapon is gun
A more specific term for a painting is watercolor
A more specific term for a month is january
A more specific term for a tool is rake
A more specific term for a mixer is blender
A more specific term for a season is spring
A more specific term for a emotion is anger
A more specific term for a flask is
2024-07-28 23:05:00 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-28 23:06:53 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.6450, -0.3877, -0.9556,  ..., -0.0333,  0.0756,  0.5303],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.5645, -2.7773,  0.7163,  ..., -0.8135,  2.4961, -1.6543],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.1086,  0.0023, -0.0023,  ..., -0.0077,  0.0058, -0.0029],
        [ 0.0170,  0.0721,  0.0018,  ...,  0.0018,  0.0033, -0.0136],
        [ 0.0188, -0.0077,  0.0878,  ...,  0.0108, -0.0267,  0.0004],
        ...,
        [ 0.0394,  0.0124, -0.0019,  ...,  0.0970,  0.0114,  0.0024],
        [-0.0334,  0.0047,  0.0016,  ...,  0.0059,  0.0926, -0.0016],
        [ 0.0160,  0.0094, -0.0198,  ..., -0.0028,  0.0117,  0.0864]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.3828, -1.9238,  0.6787,  ..., -0.4275,  2.5176, -1.5107]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 23:06:54 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more specific term for a weapon is gun
A more specific term for a painting is watercolor
A more specific term for a month is january
A more specific term for a tool is rake
A more specific term for a mixer is blender
A more specific term for a season is spring
A more specific term for a emotion is anger
A more specific term for a flask is
2024-07-28 23:06:54 root INFO     [order_1_approx] starting weight calculation for A more specific term for a season is spring
A more specific term for a flask is thermos
A more specific term for a painting is watercolor
A more specific term for a tool is rake
A more specific term for a mixer is blender
A more specific term for a emotion is anger
A more specific term for a month is january
A more specific term for a weapon is
2024-07-28 23:06:54 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-28 23:08:47 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0322, -0.3760,  0.1129,  ..., -0.0885, -0.7974, -0.2053],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.9844, -6.4688, -0.6992,  ...,  1.0244, -2.5586,  0.5859],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0492, -0.0081,  0.0028,  ...,  0.0055,  0.0138, -0.0009],
        [ 0.0022,  0.0415,  0.0055,  ..., -0.0127,  0.0021, -0.0133],
        [ 0.0023, -0.0012,  0.0529,  ...,  0.0001,  0.0085,  0.0007],
        ...,
        [ 0.0156,  0.0044, -0.0046,  ...,  0.0513, -0.0019,  0.0034],
        [-0.0063,  0.0070, -0.0043,  ...,  0.0023,  0.0576, -0.0056],
        [ 0.0110,  0.0045, -0.0023,  ..., -0.0066, -0.0046,  0.0457]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.7637, -6.3750, -0.4854,  ...,  1.0498, -2.2129,  0.6328]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 23:08:48 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more specific term for a season is spring
A more specific term for a flask is thermos
A more specific term for a painting is watercolor
A more specific term for a tool is rake
A more specific term for a mixer is blender
A more specific term for a emotion is anger
A more specific term for a month is january
A more specific term for a weapon is
2024-07-28 23:08:48 root INFO     [order_1_approx] starting weight calculation for A more specific term for a mixer is blender
A more specific term for a weapon is gun
A more specific term for a month is january
A more specific term for a flask is thermos
A more specific term for a emotion is anger
A more specific term for a painting is watercolor
A more specific term for a tool is rake
A more specific term for a season is
2024-07-28 23:08:48 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-28 23:10:42 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3330, -0.3799,  0.5059,  ..., -0.0544, -0.1323, -0.3213],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 7.1875, -6.3281,  2.6055,  ...,  0.6284, -0.8887, -1.0576],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0654, -0.0056, -0.0049,  ...,  0.0020,  0.0033,  0.0116],
        [ 0.0019,  0.0684,  0.0072,  ..., -0.0021,  0.0223,  0.0041],
        [-0.0115, -0.0094,  0.0597,  ...,  0.0010, -0.0048,  0.0139],
        ...,
        [ 0.0156,  0.0075,  0.0014,  ...,  0.0814, -0.0061, -0.0045],
        [ 0.0056, -0.0160, -0.0057,  ...,  0.0092,  0.0612,  0.0007],
        [-0.0075,  0.0107, -0.0103,  ..., -0.0019,  0.0052,  0.0768]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 6.9805, -6.0547,  2.9551,  ...,  0.5215, -0.8867, -0.8633]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 23:10:44 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more specific term for a mixer is blender
A more specific term for a weapon is gun
A more specific term for a month is january
A more specific term for a flask is thermos
A more specific term for a emotion is anger
A more specific term for a painting is watercolor
A more specific term for a tool is rake
A more specific term for a season is
2024-07-28 23:10:44 root INFO     [order_1_approx] starting weight calculation for A more specific term for a month is january
A more specific term for a season is spring
A more specific term for a painting is watercolor
A more specific term for a weapon is gun
A more specific term for a tool is rake
A more specific term for a mixer is blender
A more specific term for a flask is thermos
A more specific term for a emotion is
2024-07-28 23:10:44 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-28 23:12:39 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2017, -0.3875,  0.1641,  ..., -0.1714, -0.3545, -0.4500],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 5.3516, -4.2734,  1.0020,  ...,  0.9282, -0.8418, -1.9277],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0505, -0.0081, -0.0029,  ..., -0.0051,  0.0108,  0.0109],
        [-0.0001,  0.0538,  0.0037,  ...,  0.0030,  0.0119,  0.0003],
        [-0.0032, -0.0061,  0.0425,  ...,  0.0026, -0.0134,  0.0017],
        ...,
        [ 0.0031,  0.0142,  0.0004,  ...,  0.0486,  0.0008,  0.0037],
        [-0.0009,  0.0020, -0.0003,  ..., -0.0060,  0.0367, -0.0017],
        [-0.0037,  0.0040, -0.0101,  ...,  0.0043, -0.0113,  0.0495]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.9492, -3.9883,  0.5850,  ...,  0.8452, -1.1289, -2.0137]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 23:12:41 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more specific term for a month is january
A more specific term for a season is spring
A more specific term for a painting is watercolor
A more specific term for a weapon is gun
A more specific term for a tool is rake
A more specific term for a mixer is blender
A more specific term for a flask is thermos
A more specific term for a emotion is
2024-07-28 23:12:41 root INFO     [order_1_approx] starting weight calculation for A more specific term for a tool is rake
A more specific term for a mixer is blender
A more specific term for a weapon is gun
A more specific term for a flask is thermos
A more specific term for a emotion is anger
A more specific term for a season is spring
A more specific term for a month is january
A more specific term for a painting is
2024-07-28 23:12:41 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-28 23:14:34 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0322, -0.5732,  0.3020,  ...,  0.0620, -0.8672,  0.2517],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.7061, -6.5000, -0.1875,  ...,  0.2313, -2.1406, -0.2637],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0852,  0.0071,  0.0013,  ..., -0.0039,  0.0067,  0.0178],
        [ 0.0133,  0.0820, -0.0026,  ..., -0.0114,  0.0024, -0.0205],
        [ 0.0083, -0.0309,  0.1008,  ...,  0.0003, -0.0031, -0.0105],
        ...,
        [ 0.0029, -0.0003, -0.0062,  ...,  0.1091, -0.0036, -0.0057],
        [-0.0036,  0.0094, -0.0012,  ..., -0.0025,  0.0828, -0.0143],
        [ 0.0026,  0.0107, -0.0041,  ...,  0.0039,  0.0048,  0.0782]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.5654, -6.4062,  0.0823,  ...,  0.7671, -2.0625, -0.1887]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 23:14:35 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more specific term for a tool is rake
A more specific term for a mixer is blender
A more specific term for a weapon is gun
A more specific term for a flask is thermos
A more specific term for a emotion is anger
A more specific term for a season is spring
A more specific term for a month is january
A more specific term for a painting is
2024-07-28 23:14:35 root INFO     total operator prediction time: 913.567608833313 seconds
2024-07-28 23:14:35 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on hypernyms - animals
2024-07-28 23:14:35 root INFO     building operator hypernyms - animals
2024-07-28 23:14:35 root INFO     [order_1_approx] starting weight calculation for The porcupine falls into the category of rodent
The quail falls into the category of fowl
The velociraptor falls into the category of dinosaur
The orangutan falls into the category of primate
The leopard falls into the category of feline
The lion falls into the category of feline
The pony falls into the category of bovid
The turkey falls into the category of
2024-07-28 23:14:35 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-28 23:16:30 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.8672, -0.9092, -0.2061,  ...,  0.6729, -0.2452,  0.3191],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.8008, -4.5078,  3.5000,  ..., -1.6328, -8.4219,  0.4590],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0269, -0.0009, -0.0036,  ..., -0.0059, -0.0143, -0.0049],
        [-0.0038,  0.0302, -0.0015,  ...,  0.0034,  0.0004, -0.0029],
        [ 0.0030, -0.0069,  0.0170,  ...,  0.0046, -0.0048, -0.0023],
        ...,
        [ 0.0102, -0.0071,  0.0081,  ...,  0.0211, -0.0045, -0.0064],
        [ 0.0034,  0.0015, -0.0104,  ...,  0.0077,  0.0229, -0.0042],
        [-0.0131,  0.0029, -0.0024,  ..., -0.0036, -0.0087,  0.0274]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.7988, -4.3789,  3.2930,  ..., -1.6523, -8.5547,  0.6943]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 23:16:31 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The porcupine falls into the category of rodent
The quail falls into the category of fowl
The velociraptor falls into the category of dinosaur
The orangutan falls into the category of primate
The leopard falls into the category of feline
The lion falls into the category of feline
The pony falls into the category of bovid
The turkey falls into the category of
2024-07-28 23:16:31 root INFO     [order_1_approx] starting weight calculation for The orangutan falls into the category of primate
The leopard falls into the category of feline
The quail falls into the category of fowl
The pony falls into the category of bovid
The velociraptor falls into the category of dinosaur
The turkey falls into the category of fowl
The lion falls into the category of feline
The porcupine falls into the category of
2024-07-28 23:16:31 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-28 23:18:21 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3687, -0.8438,  0.2167,  ..., -0.1241, -0.4927,  0.1180],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.9023, -3.5000,  0.7480,  ..., -1.9473, -4.1211, -1.6426],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 2.1729e-02,  4.9744e-03, -4.0245e-03,  ..., -8.7967e-03,
         -8.5068e-03, -7.1764e-05],
        [ 7.4482e-04,  8.4686e-03,  6.3419e-04,  ...,  2.3594e-03,
          6.7062e-03, -5.4207e-03],
        [-1.3351e-04,  8.5602e-03,  1.3763e-02,  ...,  2.4185e-03,
          4.5681e-04,  5.0888e-03],
        ...,
        [ 5.7755e-03, -9.7504e-03, -1.3781e-03,  ...,  1.4008e-02,
         -1.3590e-03, -3.5038e-03],
        [ 6.5536e-03, -4.8866e-03, -6.5002e-03,  ..., -1.0254e-02,
          3.3020e-02,  3.3092e-04],
        [-4.8981e-03,  6.1874e-03, -6.7616e-04,  ..., -3.0155e-03,
          2.8076e-03,  2.1011e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.7471, -3.3887,  0.7412,  ..., -1.9844, -4.0508, -1.6934]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 23:18:22 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The orangutan falls into the category of primate
The leopard falls into the category of feline
The quail falls into the category of fowl
The pony falls into the category of bovid
The velociraptor falls into the category of dinosaur
The turkey falls into the category of fowl
The lion falls into the category of feline
The porcupine falls into the category of
2024-07-28 23:18:23 root INFO     [order_1_approx] starting weight calculation for The leopard falls into the category of feline
The porcupine falls into the category of rodent
The orangutan falls into the category of primate
The pony falls into the category of bovid
The lion falls into the category of feline
The turkey falls into the category of fowl
The quail falls into the category of fowl
The velociraptor falls into the category of
2024-07-28 23:18:23 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-28 23:20:16 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.7007, -0.4487, -0.5337,  ..., -0.1295, -0.8359,  0.0105],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.6377, -5.5859,  3.6055,  ..., -1.8711, -9.2188,  0.1455],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0210, -0.0005, -0.0114,  ..., -0.0081, -0.0024, -0.0053],
        [ 0.0041,  0.0208,  0.0004,  ...,  0.0050,  0.0106, -0.0032],
        [ 0.0035,  0.0059,  0.0128,  ..., -0.0008, -0.0014,  0.0029],
        ...,
        [ 0.0135, -0.0030,  0.0053,  ...,  0.0301, -0.0070,  0.0045],
        [-0.0044, -0.0029,  0.0010,  ..., -0.0007,  0.0302, -0.0033],
        [ 0.0071,  0.0014, -0.0024,  ..., -0.0016, -0.0130,  0.0282]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.6523, -5.5664,  3.5332,  ..., -1.8496, -9.2500,  0.2812]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 23:20:17 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The leopard falls into the category of feline
The porcupine falls into the category of rodent
The orangutan falls into the category of primate
The pony falls into the category of bovid
The lion falls into the category of feline
The turkey falls into the category of fowl
The quail falls into the category of fowl
The velociraptor falls into the category of
2024-07-28 23:20:17 root INFO     [order_1_approx] starting weight calculation for The turkey falls into the category of fowl
The orangutan falls into the category of primate
The lion falls into the category of feline
The leopard falls into the category of feline
The velociraptor falls into the category of dinosaur
The quail falls into the category of fowl
The porcupine falls into the category of rodent
The pony falls into the category of
2024-07-28 23:20:17 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-28 23:22:11 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0232, -0.0582, -0.2175,  ..., -0.0093, -0.6143,  0.3196],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.1274, -5.8281,  2.9277,  ..., -0.1367, -6.6758, -0.9678],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0544, -0.0298,  0.0040,  ..., -0.0109, -0.0046, -0.0159],
        [ 0.0098,  0.0337,  0.0051,  ...,  0.0011,  0.0185, -0.0038],
        [ 0.0027,  0.0126,  0.0408,  ...,  0.0019,  0.0023, -0.0082],
        ...,
        [ 0.0165, -0.0066,  0.0117,  ...,  0.0538, -0.0048,  0.0013],
        [ 0.0061,  0.0147, -0.0134,  ...,  0.0188,  0.0475,  0.0132],
        [-0.0048,  0.0026,  0.0081,  ..., -0.0077, -0.0126,  0.0423]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.2437, -5.4102,  2.6348,  ..., -0.2773, -6.7969, -1.0166]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 23:22:12 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The turkey falls into the category of fowl
The orangutan falls into the category of primate
The lion falls into the category of feline
The leopard falls into the category of feline
The velociraptor falls into the category of dinosaur
The quail falls into the category of fowl
The porcupine falls into the category of rodent
The pony falls into the category of
2024-07-28 23:22:12 root INFO     [order_1_approx] starting weight calculation for The velociraptor falls into the category of dinosaur
The lion falls into the category of feline
The pony falls into the category of bovid
The quail falls into the category of fowl
The turkey falls into the category of fowl
The porcupine falls into the category of rodent
The leopard falls into the category of feline
The orangutan falls into the category of
2024-07-28 23:22:13 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-28 23:24:06 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.6938, -1.2314,  0.5454,  ...,  0.1010, -0.9106,  0.3845],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.0537, -4.6172,  0.5137,  ..., -4.4727, -6.5312,  1.3994],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0257, -0.0008,  0.0022,  ..., -0.0032,  0.0005, -0.0040],
        [ 0.0002,  0.0140, -0.0039,  ...,  0.0004,  0.0067, -0.0034],
        [-0.0040,  0.0064,  0.0177,  ...,  0.0101,  0.0041,  0.0025],
        ...,
        [ 0.0113,  0.0037, -0.0014,  ...,  0.0208, -0.0025,  0.0024],
        [-0.0041, -0.0068, -0.0048,  ..., -0.0027,  0.0201, -0.0022],
        [-0.0017, -0.0004,  0.0016,  ..., -0.0038,  0.0009,  0.0151]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.0752, -4.6016,  0.4509,  ..., -4.5078, -6.5547,  1.3281]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 23:24:07 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The velociraptor falls into the category of dinosaur
The lion falls into the category of feline
The pony falls into the category of bovid
The quail falls into the category of fowl
The turkey falls into the category of fowl
The porcupine falls into the category of rodent
The leopard falls into the category of feline
The orangutan falls into the category of
2024-07-28 23:24:08 root INFO     [order_1_approx] starting weight calculation for The orangutan falls into the category of primate
The pony falls into the category of bovid
The quail falls into the category of fowl
The porcupine falls into the category of rodent
The turkey falls into the category of fowl
The leopard falls into the category of feline
The velociraptor falls into the category of dinosaur
The lion falls into the category of
2024-07-28 23:24:08 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-28 23:26:02 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.7407, -0.6577,  0.4226,  ...,  0.1908, -0.9702, -0.4104],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.5552, -6.8281,  0.5830,  ..., -3.7754, -7.1055, -1.0996],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0268, -0.0053, -0.0060,  ..., -0.0045, -0.0087, -0.0033],
        [ 0.0033,  0.0259,  0.0069,  ..., -0.0036,  0.0075,  0.0078],
        [-0.0097, -0.0044,  0.0359,  ...,  0.0080, -0.0030, -0.0080],
        ...,
        [ 0.0099, -0.0005, -0.0008,  ...,  0.0285, -0.0096, -0.0026],
        [-0.0041, -0.0068, -0.0044,  ...,  0.0089,  0.0343,  0.0018],
        [-0.0152,  0.0136, -0.0033,  ...,  0.0010,  0.0050,  0.0396]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.7544, -6.5312,  0.8242,  ..., -3.5977, -7.2891, -1.0859]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 23:26:03 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The orangutan falls into the category of primate
The pony falls into the category of bovid
The quail falls into the category of fowl
The porcupine falls into the category of rodent
The turkey falls into the category of fowl
The leopard falls into the category of feline
The velociraptor falls into the category of dinosaur
The lion falls into the category of
2024-07-28 23:26:03 root INFO     [order_1_approx] starting weight calculation for The orangutan falls into the category of primate
The lion falls into the category of feline
The pony falls into the category of bovid
The turkey falls into the category of fowl
The porcupine falls into the category of rodent
The leopard falls into the category of feline
The velociraptor falls into the category of dinosaur
The quail falls into the category of
2024-07-28 23:26:03 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-28 23:27:57 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3838, -1.0938, -0.3901,  ...,  0.7603, -0.4199, -0.2422],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.8086, -3.6523,  2.9297,  ..., -2.1152, -5.7031,  0.3643],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0460, -0.0014,  0.0013,  ...,  0.0007, -0.0061,  0.0028],
        [ 0.0077,  0.0377, -0.0059,  ...,  0.0028,  0.0124, -0.0008],
        [ 0.0005, -0.0001,  0.0465,  ...,  0.0057, -0.0175,  0.0044],
        ...,
        [ 0.0046,  0.0030, -0.0042,  ...,  0.0499, -0.0074, -0.0087],
        [ 0.0082, -0.0047, -0.0092,  ...,  0.0173,  0.0382, -0.0078],
        [-0.0144,  0.0052,  0.0016,  ..., -0.0040, -0.0139,  0.0465]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.7920, -3.3457,  2.6445,  ..., -2.2715, -5.9023,  0.3892]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 23:27:58 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The orangutan falls into the category of primate
The lion falls into the category of feline
The pony falls into the category of bovid
The turkey falls into the category of fowl
The porcupine falls into the category of rodent
The leopard falls into the category of feline
The velociraptor falls into the category of dinosaur
The quail falls into the category of
2024-07-28 23:27:58 root INFO     [order_1_approx] starting weight calculation for The velociraptor falls into the category of dinosaur
The lion falls into the category of feline
The orangutan falls into the category of primate
The pony falls into the category of bovid
The turkey falls into the category of fowl
The quail falls into the category of fowl
The porcupine falls into the category of rodent
The leopard falls into the category of
2024-07-28 23:27:58 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-28 23:29:52 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1707, -0.9287,  0.3191,  ...,  0.4592, -0.8936,  0.0402],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.1528, -6.4180, -1.2812,  ..., -4.7891, -7.2891, -0.7930],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0243, -0.0020, -0.0086,  ..., -0.0098, -0.0003,  0.0018],
        [ 0.0047,  0.0225, -0.0020,  ..., -0.0042,  0.0142,  0.0049],
        [-0.0002,  0.0039,  0.0230,  ..., -0.0043,  0.0013, -0.0058],
        ...,
        [ 0.0057,  0.0022, -0.0041,  ...,  0.0226, -0.0020, -0.0038],
        [ 0.0009, -0.0064,  0.0006,  ...,  0.0083,  0.0163,  0.0011],
        [-0.0044,  0.0106, -0.0008,  ..., -0.0031,  0.0060,  0.0208]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.1836, -6.2773, -1.1748,  ..., -4.7930, -7.5312, -0.9434]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 23:29:53 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The velociraptor falls into the category of dinosaur
The lion falls into the category of feline
The orangutan falls into the category of primate
The pony falls into the category of bovid
The turkey falls into the category of fowl
The quail falls into the category of fowl
The porcupine falls into the category of rodent
The leopard falls into the category of
2024-07-28 23:29:53 root INFO     total operator prediction time: 918.0773100852966 seconds
2024-07-28 23:29:53 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on synonyms - intensity
2024-07-28 23:29:53 root INFO     building operator synonyms - intensity
2024-07-28 23:29:53 root INFO     [order_1_approx] starting weight calculation for A more intense word for rain is deluge
A more intense word for irritate is enrage
A more intense word for sniffles is pneumonia
A more intense word for house is palace
A more intense word for damp is drenched
A more intense word for poorly is afflicted
A more intense word for chuckle is laugh
A more intense word for want is
2024-07-28 23:29:53 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-28 23:31:48 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 3.2593e-02, -1.2207e-04, -2.3178e-02,  ..., -1.2878e-01,
        -3.7500e-01,  3.5492e-02], device='cuda:1', dtype=torch.float16,
       grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.0781, -3.5312,  0.5464,  ..., -1.6973, -8.3906, -3.8750],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0760, -0.0130,  0.0175,  ..., -0.0012, -0.0070,  0.0382],
        [-0.0094,  0.0843, -0.0154,  ...,  0.0152, -0.0053, -0.0237],
        [-0.0068, -0.0053,  0.0750,  ..., -0.0251, -0.0118,  0.0057],
        ...,
        [ 0.0207,  0.0128, -0.0012,  ...,  0.0886, -0.0008, -0.0186],
        [-0.0163, -0.0016,  0.0170,  ..., -0.0023,  0.0729, -0.0074],
        [ 0.0146,  0.0009, -0.0040,  ..., -0.0121, -0.0160,  0.0717]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.8789, -3.2363,  0.4214,  ..., -1.7588, -8.1953, -3.0547]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 23:31:49 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more intense word for rain is deluge
A more intense word for irritate is enrage
A more intense word for sniffles is pneumonia
A more intense word for house is palace
A more intense word for damp is drenched
A more intense word for poorly is afflicted
A more intense word for chuckle is laugh
A more intense word for want is
2024-07-28 23:31:50 root INFO     [order_1_approx] starting weight calculation for A more intense word for want is crave
A more intense word for rain is deluge
A more intense word for damp is drenched
A more intense word for sniffles is pneumonia
A more intense word for poorly is afflicted
A more intense word for house is palace
A more intense word for chuckle is laugh
A more intense word for irritate is
2024-07-28 23:31:50 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-28 23:33:44 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2544, -0.2385, -1.1270,  ..., -0.6963, -0.6963,  0.3250],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.7344, -5.0312,  0.6724,  ..., -0.7319, -0.2441,  2.2305],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0687,  0.0024,  0.0130,  ...,  0.0093, -0.0035, -0.0014],
        [-0.0027,  0.0467, -0.0067,  ...,  0.0064, -0.0043, -0.0049],
        [-0.0004, -0.0060,  0.0464,  ..., -0.0089,  0.0040, -0.0001],
        ...,
        [ 0.0060,  0.0096,  0.0002,  ...,  0.0651, -0.0122, -0.0037],
        [-0.0005, -0.0043,  0.0131,  ..., -0.0029,  0.0509,  0.0017],
        [-0.0062, -0.0079, -0.0055,  ..., -0.0029, -0.0076,  0.0517]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.6543, -5.1172,  0.5142,  ..., -0.5049, -0.4299,  2.1367]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 23:33:44 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more intense word for want is crave
A more intense word for rain is deluge
A more intense word for damp is drenched
A more intense word for sniffles is pneumonia
A more intense word for poorly is afflicted
A more intense word for house is palace
A more intense word for chuckle is laugh
A more intense word for irritate is
2024-07-28 23:33:45 root INFO     [order_1_approx] starting weight calculation for A more intense word for rain is deluge
A more intense word for want is crave
A more intense word for chuckle is laugh
A more intense word for irritate is enrage
A more intense word for poorly is afflicted
A more intense word for damp is drenched
A more intense word for sniffles is pneumonia
A more intense word for house is
2024-07-28 23:33:45 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-28 23:35:39 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1749,  0.2913, -0.4155,  ..., -0.1445, -0.4939, -0.3677],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-2.9121, -4.9570,  1.0664,  ...,  0.4773, -2.5859,  1.3125],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0937,  0.0114,  0.0132,  ...,  0.0016,  0.0009,  0.0318],
        [-0.0105,  0.0696, -0.0003,  ..., -0.0143,  0.0322, -0.0033],
        [ 0.0041,  0.0066,  0.0817,  ..., -0.0094, -0.0090,  0.0113],
        ...,
        [ 0.0080,  0.0009, -0.0044,  ...,  0.0807, -0.0036, -0.0054],
        [-0.0083,  0.0167,  0.0087,  ..., -0.0004,  0.0955, -0.0151],
        [ 0.0046, -0.0099, -0.0189,  ..., -0.0171, -0.0135,  0.0699]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-2.7148, -4.6914,  0.9829,  ...,  0.4685, -3.0625,  1.2021]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 23:35:40 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more intense word for rain is deluge
A more intense word for want is crave
A more intense word for chuckle is laugh
A more intense word for irritate is enrage
A more intense word for poorly is afflicted
A more intense word for damp is drenched
A more intense word for sniffles is pneumonia
A more intense word for house is
2024-07-28 23:35:40 root INFO     [order_1_approx] starting weight calculation for A more intense word for want is crave
A more intense word for house is palace
A more intense word for damp is drenched
A more intense word for sniffles is pneumonia
A more intense word for irritate is enrage
A more intense word for rain is deluge
A more intense word for chuckle is laugh
A more intense word for poorly is
2024-07-28 23:35:40 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-28 23:37:35 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3486,  0.0896, -0.7197,  ..., -0.5928, -0.4243, -0.2905],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 5.0703, -4.5625,  3.0820,  ..., -3.7988, -1.0615, -2.1758],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 9.5032e-02, -1.3977e-02,  1.1902e-02,  ...,  1.3000e-02,
         -6.1493e-03, -7.0953e-04],
        [-1.8707e-02,  7.2388e-02,  2.8553e-03,  ...,  5.6915e-03,
          1.3504e-03,  6.6757e-04],
        [ 9.7132e-04, -7.8354e-03,  8.0994e-02,  ..., -8.4457e-03,
         -1.0071e-03, -1.5011e-03],
        ...,
        [-1.0147e-02,  2.6733e-02, -2.0905e-02,  ...,  1.1243e-01,
          3.9444e-03, -3.8727e-02],
        [-7.7667e-03,  2.4071e-03, -7.4921e-03,  ...,  5.9128e-03,
          8.7036e-02,  1.6586e-02],
        [-7.8812e-03, -3.0632e-03,  8.7738e-05,  ..., -1.6830e-02,
         -9.0179e-03,  9.1492e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.9297, -4.1211,  3.0840,  ..., -3.2031, -1.8340, -2.0449]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 23:37:36 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more intense word for want is crave
A more intense word for house is palace
A more intense word for damp is drenched
A more intense word for sniffles is pneumonia
A more intense word for irritate is enrage
A more intense word for rain is deluge
A more intense word for chuckle is laugh
A more intense word for poorly is
2024-07-28 23:37:36 root INFO     [order_1_approx] starting weight calculation for A more intense word for chuckle is laugh
A more intense word for sniffles is pneumonia
A more intense word for house is palace
A more intense word for poorly is afflicted
A more intense word for irritate is enrage
A more intense word for want is crave
A more intense word for rain is deluge
A more intense word for damp is
2024-07-28 23:37:36 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-28 23:39:30 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1992, -0.8438, -0.3281,  ...,  0.2441, -1.2793, -0.4500],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 6.8594, -4.6445, -0.1846,  ..., -0.1465, -2.6250, -3.6094],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.1260, -0.0054,  0.0275,  ...,  0.0093,  0.0020,  0.0048],
        [ 0.0037,  0.0739, -0.0200,  ...,  0.0180, -0.0049, -0.0151],
        [-0.0111, -0.0154,  0.0832,  ..., -0.0296,  0.0010, -0.0027],
        ...,
        [ 0.0062,  0.0129,  0.0024,  ...,  0.1019, -0.0059, -0.0065],
        [ 0.0007,  0.0048,  0.0137,  ..., -0.0177,  0.0997, -0.0056],
        [ 0.0005,  0.0017,  0.0180,  ..., -0.0059, -0.0043,  0.0940]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 6.4414, -4.2266,  0.1035,  ..., -0.8828, -2.7168, -3.6660]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 23:39:32 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more intense word for chuckle is laugh
A more intense word for sniffles is pneumonia
A more intense word for house is palace
A more intense word for poorly is afflicted
A more intense word for irritate is enrage
A more intense word for want is crave
A more intense word for rain is deluge
A more intense word for damp is
2024-07-28 23:39:32 root INFO     [order_1_approx] starting weight calculation for A more intense word for damp is drenched
A more intense word for chuckle is laugh
A more intense word for irritate is enrage
A more intense word for sniffles is pneumonia
A more intense word for poorly is afflicted
A more intense word for want is crave
A more intense word for house is palace
A more intense word for rain is
2024-07-28 23:39:32 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-28 23:41:27 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0244, -0.1400, -0.4949,  ..., -0.3264, -0.0969, -0.9927],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.1895, -6.8867, -1.2656,  ..., -0.4907,  0.6348, -3.1855],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0687,  0.0032,  0.0081,  ...,  0.0020,  0.0068,  0.0091],
        [-0.0136,  0.0475, -0.0078,  ...,  0.0049,  0.0115, -0.0147],
        [-0.0057, -0.0194,  0.0593,  ..., -0.0208, -0.0122,  0.0109],
        ...,
        [ 0.0074, -0.0124,  0.0055,  ...,  0.0601, -0.0006, -0.0037],
        [-0.0084, -0.0045,  0.0114,  ...,  0.0062,  0.0492, -0.0015],
        [ 0.0184,  0.0062,  0.0093,  ...,  0.0071,  0.0028,  0.0576]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.1230, -6.3945, -1.0547,  ..., -0.6548,  0.3635, -3.4082]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 23:41:28 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more intense word for damp is drenched
A more intense word for chuckle is laugh
A more intense word for irritate is enrage
A more intense word for sniffles is pneumonia
A more intense word for poorly is afflicted
A more intense word for want is crave
A more intense word for house is palace
A more intense word for rain is
2024-07-28 23:41:28 root INFO     [order_1_approx] starting weight calculation for A more intense word for rain is deluge
A more intense word for want is crave
A more intense word for damp is drenched
A more intense word for house is palace
A more intense word for irritate is enrage
A more intense word for sniffles is pneumonia
A more intense word for poorly is afflicted
A more intense word for chuckle is
2024-07-28 23:41:28 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-28 23:43:21 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1660, -0.7778, -0.8569,  ..., -0.3538, -0.3870,  0.1221],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.5391, -3.1562,  5.2461,  ...,  3.4531, -1.1191,  0.3730],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0939,  0.0136,  0.0138,  ..., -0.0038,  0.0144,  0.0117],
        [-0.0063,  0.0455, -0.0123,  ...,  0.0105,  0.0032,  0.0113],
        [-0.0101, -0.0110,  0.0530,  ...,  0.0033,  0.0038, -0.0072],
        ...,
        [-0.0013,  0.0061, -0.0108,  ...,  0.0552, -0.0074,  0.0094],
        [ 0.0003, -0.0233,  0.0029,  ...,  0.0010,  0.0491,  0.0003],
        [-0.0083,  0.0083, -0.0110,  ..., -0.0071, -0.0122,  0.0566]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.4912, -2.8984,  5.5938,  ...,  3.1914, -1.1211,  0.4045]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 23:43:22 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more intense word for rain is deluge
A more intense word for want is crave
A more intense word for damp is drenched
A more intense word for house is palace
A more intense word for irritate is enrage
A more intense word for sniffles is pneumonia
A more intense word for poorly is afflicted
A more intense word for chuckle is
2024-07-28 23:43:22 root INFO     [order_1_approx] starting weight calculation for A more intense word for chuckle is laugh
A more intense word for want is crave
A more intense word for house is palace
A more intense word for irritate is enrage
A more intense word for rain is deluge
A more intense word for damp is drenched
A more intense word for poorly is afflicted
A more intense word for sniffles is
2024-07-28 23:43:22 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-28 23:45:17 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0525, -0.3860, -1.0527,  ...,  0.1971, -0.7378,  0.3899],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.8047, -1.1279,  2.0352,  ..., -0.4409,  0.6182,  2.2305],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0905, -0.0062,  0.0179,  ...,  0.0128,  0.0243,  0.0140],
        [ 0.0007,  0.0726, -0.0018,  ...,  0.0141,  0.0188,  0.0047],
        [-0.0131, -0.0056,  0.0693,  ...,  0.0097, -0.0126, -0.0191],
        ...,
        [ 0.0215,  0.0191,  0.0014,  ...,  0.0808, -0.0068,  0.0154],
        [ 0.0182,  0.0024, -0.0004,  ...,  0.0043,  0.0724, -0.0015],
        [-0.0105,  0.0006, -0.0053,  ...,  0.0007, -0.0199,  0.0758]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.9336, -1.1230,  2.2207,  ..., -0.3862,  0.5977,  1.9199]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 23:45:18 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more intense word for chuckle is laugh
A more intense word for want is crave
A more intense word for house is palace
A more intense word for irritate is enrage
A more intense word for rain is deluge
A more intense word for damp is drenched
A more intense word for poorly is afflicted
A more intense word for sniffles is
2024-07-28 23:45:18 root INFO     total operator prediction time: 925.3365941047668 seconds
2024-07-28 23:45:18 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on meronyms - substance
2024-07-28 23:45:18 root INFO     building operator meronyms - substance
2024-07-28 23:45:19 root INFO     [order_1_approx] starting weight calculation for A clothing is made up of fabric
A sea is made up of water
A glacier is made up of ice
A jeans is made up of fabric
A snow is made up of water
A yogurt is made up of milk
A beard is made up of hair
A bowl is made up of
2024-07-28 23:45:19 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-28 23:47:15 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4204, -1.4619, -0.6572,  ...,  0.5781, -0.6021,  0.2258],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.4844, -3.5547, -1.5918,  ..., -3.1719,  0.9526,  1.1758],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0623, -0.0020,  0.0039,  ..., -0.0006,  0.0019,  0.0016],
        [-0.0041,  0.0423, -0.0004,  ...,  0.0011,  0.0036, -0.0020],
        [ 0.0116, -0.0038,  0.0507,  ...,  0.0046, -0.0161, -0.0032],
        ...,
        [ 0.0080, -0.0137, -0.0014,  ...,  0.0345, -0.0022, -0.0172],
        [-0.0026, -0.0010, -0.0072,  ...,  0.0043,  0.0390, -0.0046],
        [-0.0062, -0.0107, -0.0031,  ..., -0.0136,  0.0019,  0.0487]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.3711, -3.8320, -1.6064,  ..., -2.7051,  0.6357,  1.3398]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 23:47:16 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A clothing is made up of fabric
A sea is made up of water
A glacier is made up of ice
A jeans is made up of fabric
A snow is made up of water
A yogurt is made up of milk
A beard is made up of hair
A bowl is made up of
2024-07-28 23:47:16 root INFO     [order_1_approx] starting weight calculation for A bowl is made up of glass
A yogurt is made up of milk
A jeans is made up of fabric
A snow is made up of water
A sea is made up of water
A beard is made up of hair
A clothing is made up of fabric
A glacier is made up of
2024-07-28 23:47:16 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-28 23:49:08 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1694,  0.1797,  0.1085,  ..., -1.0938, -1.1465,  0.1592],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.0293, -6.3945,  0.5029,  ..., -3.7578,  2.0352, -2.1484],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0419, -0.0038,  0.0090,  ...,  0.0068,  0.0049, -0.0122],
        [ 0.0086,  0.0151,  0.0077,  ..., -0.0090, -0.0043, -0.0029],
        [-0.0036, -0.0020,  0.0227,  ...,  0.0105, -0.0082, -0.0056],
        ...,
        [ 0.0069, -0.0007, -0.0075,  ...,  0.0407,  0.0031, -0.0237],
        [-0.0012, -0.0027,  0.0016,  ...,  0.0146,  0.0203,  0.0062],
        [ 0.0015,  0.0014, -0.0006,  ..., -0.0024,  0.0051,  0.0277]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.1172, -6.3789,  0.5054,  ..., -3.5488,  1.9434, -1.9678]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 23:49:08 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A bowl is made up of glass
A yogurt is made up of milk
A jeans is made up of fabric
A snow is made up of water
A sea is made up of water
A beard is made up of hair
A clothing is made up of fabric
A glacier is made up of
2024-07-28 23:49:09 root INFO     [order_1_approx] starting weight calculation for A bowl is made up of glass
A clothing is made up of fabric
A jeans is made up of fabric
A beard is made up of hair
A sea is made up of water
A glacier is made up of ice
A yogurt is made up of milk
A snow is made up of
2024-07-28 23:49:09 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-28 23:51:05 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.6309,  0.3623,  0.1520,  ..., -0.6436, -0.8262, -0.6304],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.9180, -3.0527, -0.8223,  ..., -4.9258,  1.4180, -1.1855],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 3.6011e-02, -2.7161e-02,  3.5324e-03,  ...,  2.2980e-02,
          8.8348e-03, -1.4084e-02],
        [-6.7749e-03,  4.1962e-05,  1.9531e-03,  ..., -1.0443e-03,
          6.3019e-03, -7.2098e-03],
        [-4.6234e-03, -7.5531e-04,  2.4872e-02,  ...,  8.1482e-03,
         -3.6287e-04,  5.6381e-03],
        ...,
        [ 5.6381e-03, -1.4679e-02, -5.0011e-03,  ...,  3.0457e-02,
          1.4706e-03, -1.7563e-02],
        [ 2.2469e-03,  7.4387e-03,  3.1357e-03,  ...,  1.1658e-02,
          3.8338e-03,  6.9008e-03],
        [-1.1330e-03, -1.8448e-02, -1.7424e-03,  ...,  8.5754e-03,
          6.4430e-03,  1.3161e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.1445, -3.2344, -0.8511,  ..., -5.0117,  1.3301, -1.0410]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 23:51:07 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A bowl is made up of glass
A clothing is made up of fabric
A jeans is made up of fabric
A beard is made up of hair
A sea is made up of water
A glacier is made up of ice
A yogurt is made up of milk
A snow is made up of
2024-07-28 23:51:07 root INFO     [order_1_approx] starting weight calculation for A yogurt is made up of milk
A beard is made up of hair
A clothing is made up of fabric
A glacier is made up of ice
A sea is made up of water
A bowl is made up of glass
A snow is made up of water
A jeans is made up of
2024-07-28 23:51:07 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-28 23:52:57 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.4727, -0.2295, -0.4460,  ...,  0.4570, -0.5776, -0.3506],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 5.8203, -8.9688,  0.7573,  ..., -0.6973, -2.0723,  1.5742],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0371, -0.0039,  0.0041,  ...,  0.0117,  0.0040,  0.0015],
        [ 0.0107,  0.0314, -0.0040,  ..., -0.0046,  0.0020, -0.0009],
        [ 0.0143,  0.0019,  0.0328,  ...,  0.0073, -0.0066, -0.0102],
        ...,
        [ 0.0084, -0.0084,  0.0024,  ...,  0.0313,  0.0032, -0.0160],
        [ 0.0013,  0.0008, -0.0018,  ...,  0.0075,  0.0255, -0.0030],
        [ 0.0010, -0.0026, -0.0013,  ..., -0.0111,  0.0119,  0.0273]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 5.6094, -9.0391,  0.6538,  ..., -0.6494, -2.0332,  1.5352]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 23:52:58 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A yogurt is made up of milk
A beard is made up of hair
A clothing is made up of fabric
A glacier is made up of ice
A sea is made up of water
A bowl is made up of glass
A snow is made up of water
A jeans is made up of
2024-07-28 23:52:59 root INFO     [order_1_approx] starting weight calculation for A snow is made up of water
A clothing is made up of fabric
A glacier is made up of ice
A jeans is made up of fabric
A sea is made up of water
A beard is made up of hair
A bowl is made up of glass
A yogurt is made up of
2024-07-28 23:52:59 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-28 23:54:52 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.4341, -0.8057,  0.5449,  ..., -0.2336, -0.8916, -0.7500],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.1133, -3.8438,  1.8799,  ..., -4.5547, -0.8911,  0.3320],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0227, -0.0096, -0.0033,  ...,  0.0050, -0.0082,  0.0086],
        [ 0.0021,  0.0222,  0.0097,  ..., -0.0076,  0.0137, -0.0056],
        [ 0.0002,  0.0049,  0.0259,  ...,  0.0130,  0.0040,  0.0057],
        ...,
        [ 0.0026,  0.0024, -0.0042,  ...,  0.0292,  0.0049, -0.0193],
        [ 0.0002,  0.0032, -0.0035,  ...,  0.0111,  0.0266,  0.0019],
        [ 0.0043, -0.0174,  0.0020,  ..., -0.0066,  0.0037,  0.0317]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.0312, -3.9082,  1.8252,  ..., -4.4375, -1.0596,  0.2849]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 23:54:53 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A snow is made up of water
A clothing is made up of fabric
A glacier is made up of ice
A jeans is made up of fabric
A sea is made up of water
A beard is made up of hair
A bowl is made up of glass
A yogurt is made up of
2024-07-28 23:54:53 root INFO     [order_1_approx] starting weight calculation for A sea is made up of water
A bowl is made up of glass
A yogurt is made up of milk
A glacier is made up of ice
A clothing is made up of fabric
A jeans is made up of fabric
A snow is made up of water
A beard is made up of
2024-07-28 23:54:53 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-28 23:56:47 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.8486, -0.6528, -0.6738,  ..., -0.7876, -0.1198,  0.2930],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.3633, -5.9922, -2.8652,  ..., -3.9453,  1.2822, -0.9355],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0521, -0.0163, -0.0043,  ...,  0.0157,  0.0017, -0.0052],
        [ 0.0033,  0.0384, -0.0006,  ..., -0.0158,  0.0126,  0.0018],
        [-0.0069,  0.0009,  0.0454,  ...,  0.0058, -0.0061, -0.0058],
        ...,
        [ 0.0080,  0.0007,  0.0102,  ...,  0.0424, -0.0061, -0.0042],
        [ 0.0015,  0.0022, -0.0165,  ...,  0.0140,  0.0392, -0.0040],
        [ 0.0016, -0.0086,  0.0023,  ..., -0.0058,  0.0096,  0.0326]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.2910, -6.1172, -2.6953,  ..., -4.1172,  1.3076, -0.9707]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 23:56:48 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A sea is made up of water
A bowl is made up of glass
A yogurt is made up of milk
A glacier is made up of ice
A clothing is made up of fabric
A jeans is made up of fabric
A snow is made up of water
A beard is made up of
2024-07-28 23:56:48 root INFO     [order_1_approx] starting weight calculation for A sea is made up of water
A glacier is made up of ice
A beard is made up of hair
A bowl is made up of glass
A jeans is made up of fabric
A snow is made up of water
A yogurt is made up of milk
A clothing is made up of
2024-07-28 23:56:48 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-28 23:58:42 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1092, -0.3328, -0.1902,  ..., -0.1351, -0.5640, -0.5591],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 5.9102, -9.3516,  1.3340,  ..., -2.5938, -1.1084,  1.6650],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 2.6825e-02,  1.9331e-03,  6.6681e-03,  ...,  4.1428e-03,
         -1.0271e-03,  5.9967e-03],
        [-6.2447e-03,  1.8784e-02, -1.3275e-03,  ..., -2.9259e-03,
          7.4272e-03,  2.6798e-03],
        [ 8.0795e-03, -2.0752e-03,  2.8992e-02,  ..., -6.7806e-04,
         -8.1100e-03, -8.0719e-03],
        ...,
        [ 5.0163e-03, -1.3180e-03, -9.5367e-06,  ...,  3.2867e-02,
         -9.1019e-03, -7.7171e-03],
        [-1.1997e-03,  2.8648e-03, -2.4071e-03,  ...,  6.1378e-03,
          2.7466e-02, -5.1003e-03],
        [-3.9215e-03, -8.1177e-03, -2.5673e-03,  ...,  5.2214e-04,
          4.8370e-03,  3.2715e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 5.5898, -9.2969,  1.4131,  ..., -2.4473, -1.1865,  1.5254]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 23:58:43 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A sea is made up of water
A glacier is made up of ice
A beard is made up of hair
A bowl is made up of glass
A jeans is made up of fabric
A snow is made up of water
A yogurt is made up of milk
A clothing is made up of
2024-07-28 23:58:44 root INFO     [order_1_approx] starting weight calculation for A yogurt is made up of milk
A jeans is made up of fabric
A glacier is made up of ice
A bowl is made up of glass
A clothing is made up of fabric
A snow is made up of water
A beard is made up of hair
A sea is made up of
2024-07-28 23:58:44 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 00:00:37 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2603,  0.1583,  0.2832,  ..., -1.1348, -0.4243, -0.0760],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.9570, -2.4375,  0.7993,  ..., -4.5781,  2.9336, -1.7168],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0323,  0.0008,  0.0051,  ..., -0.0031, -0.0031,  0.0045],
        [-0.0015,  0.0140, -0.0035,  ..., -0.0113,  0.0042, -0.0052],
        [ 0.0038, -0.0018,  0.0254,  ..., -0.0039, -0.0021,  0.0101],
        ...,
        [ 0.0066, -0.0025,  0.0092,  ...,  0.0176,  0.0119, -0.0051],
        [ 0.0036,  0.0014,  0.0048,  ...,  0.0019,  0.0176, -0.0026],
        [-0.0043, -0.0035, -0.0038,  ..., -0.0008, -0.0007,  0.0294]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.7715, -2.4551,  0.6562,  ..., -4.6562,  2.7305, -1.5771]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 00:00:38 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A yogurt is made up of milk
A jeans is made up of fabric
A glacier is made up of ice
A bowl is made up of glass
A clothing is made up of fabric
A snow is made up of water
A beard is made up of hair
A sea is made up of
2024-07-29 00:00:38 root INFO     total operator prediction time: 919.2330422401428 seconds
2024-07-29 00:00:38 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on hypernyms - misc
2024-07-29 00:00:38 root INFO     building operator hypernyms - misc
2024-07-29 00:00:38 root INFO     [order_1_approx] starting weight calculation for The skirt falls into the category of clothes
The armchair falls into the category of chair
The shirt falls into the category of clothes
The notebook falls into the category of book
The mascara falls into the category of makeup
The computer falls into the category of device
The juicer falls into the category of utensil
The croissant falls into the category of
2024-07-29 00:00:38 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 00:02:32 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4202, -0.0505, -0.1177,  ...,  0.1575, -0.7876, -0.1619],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.5137, -5.6797, -0.8149,  ..., -1.8203, -3.5977,  0.7529],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0648, -0.0063,  0.0017,  ..., -0.0009, -0.0026,  0.0129],
        [ 0.0200,  0.0487,  0.0051,  ..., -0.0014,  0.0028, -0.0125],
        [ 0.0068, -0.0135,  0.0679,  ..., -0.0071,  0.0055, -0.0075],
        ...,
        [ 0.0291,  0.0044, -0.0064,  ...,  0.0592,  0.0065, -0.0073],
        [ 0.0045, -0.0003,  0.0089,  ..., -0.0048,  0.0532, -0.0139],
        [-0.0048,  0.0030, -0.0041,  ..., -0.0034, -0.0051,  0.0601]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.3320, -5.7344, -0.9253,  ..., -1.8828, -3.3047,  0.4626]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 00:02:33 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The skirt falls into the category of clothes
The armchair falls into the category of chair
The shirt falls into the category of clothes
The notebook falls into the category of book
The mascara falls into the category of makeup
The computer falls into the category of device
The juicer falls into the category of utensil
The croissant falls into the category of
2024-07-29 00:02:33 root INFO     [order_1_approx] starting weight calculation for The croissant falls into the category of pastry
The juicer falls into the category of utensil
The armchair falls into the category of chair
The mascara falls into the category of makeup
The skirt falls into the category of clothes
The computer falls into the category of device
The shirt falls into the category of clothes
The notebook falls into the category of
2024-07-29 00:02:33 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 00:04:25 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1196, -0.5127,  0.1251,  ..., -0.0493, -0.3638,  0.4287],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.7988, -3.9336,  1.9609,  ..., -2.3691, -2.1641, -0.0117],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0449, -0.0088,  0.0080,  ...,  0.0009,  0.0082,  0.0087],
        [ 0.0077,  0.0300, -0.0018,  ...,  0.0020,  0.0130, -0.0038],
        [ 0.0044,  0.0102,  0.0431,  ...,  0.0039, -0.0217, -0.0014],
        ...,
        [ 0.0079, -0.0080, -0.0004,  ...,  0.0451,  0.0075,  0.0026],
        [-0.0051, -0.0063,  0.0074,  ...,  0.0002,  0.0421,  0.0007],
        [ 0.0031, -0.0093,  0.0004,  ..., -0.0117,  0.0068,  0.0375]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.9688, -3.9238,  1.6572,  ..., -2.3535, -2.0703,  0.0554]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 00:04:26 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The croissant falls into the category of pastry
The juicer falls into the category of utensil
The armchair falls into the category of chair
The mascara falls into the category of makeup
The skirt falls into the category of clothes
The computer falls into the category of device
The shirt falls into the category of clothes
The notebook falls into the category of
2024-07-29 00:04:26 root INFO     [order_1_approx] starting weight calculation for The shirt falls into the category of clothes
The croissant falls into the category of pastry
The computer falls into the category of device
The armchair falls into the category of chair
The skirt falls into the category of clothes
The mascara falls into the category of makeup
The notebook falls into the category of book
The juicer falls into the category of
2024-07-29 00:04:26 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 00:06:15 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0435, -0.7729,  0.2268,  ..., -0.2795, -0.6240, -0.0312],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.9082, -4.4258, -0.1292,  ..., -3.3359, -1.0137,  1.3076],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 5.0049e-02,  4.7493e-03,  4.4518e-03,  ...,  4.5300e-06,
          8.5678e-03, -1.1520e-03],
        [ 1.0994e-02,  4.3823e-02, -2.3785e-03,  ...,  4.2343e-04,
          4.5853e-03,  4.6387e-03],
        [-6.3362e-03,  5.0430e-03,  3.8818e-02,  ..., -4.8447e-03,
         -5.5923e-03,  8.2855e-03],
        ...,
        [ 7.2174e-03, -1.9436e-03,  3.2997e-04,  ...,  4.4739e-02,
          1.1063e-03,  4.0016e-03],
        [ 2.6112e-03, -4.2458e-03, -1.3885e-03,  ..., -2.2316e-03,
          5.0049e-02, -1.2047e-02],
        [ 8.5449e-04,  3.0785e-03, -5.8403e-03,  ..., -6.8398e-03,
         -3.3779e-03,  3.8818e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.9863, -4.3633, -0.3987,  ..., -3.1797, -0.6504,  1.4062]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 00:06:16 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The shirt falls into the category of clothes
The croissant falls into the category of pastry
The computer falls into the category of device
The armchair falls into the category of chair
The skirt falls into the category of clothes
The mascara falls into the category of makeup
The notebook falls into the category of book
The juicer falls into the category of
2024-07-29 00:06:16 root INFO     [order_1_approx] starting weight calculation for The computer falls into the category of device
The juicer falls into the category of utensil
The skirt falls into the category of clothes
The notebook falls into the category of book
The armchair falls into the category of chair
The mascara falls into the category of makeup
The croissant falls into the category of pastry
The shirt falls into the category of
2024-07-29 00:06:16 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 00:08:07 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.5483, -0.2832, -0.1120,  ..., -0.0729, -0.1516,  0.2998],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.3984, -4.8438, -1.0391,  ...,  0.3765, -0.1318,  0.3740],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 3.9978e-02, -2.8782e-03,  8.4839e-03,  ...,  3.0003e-03,
          7.7438e-03,  6.2027e-03],
        [ 2.5864e-03,  2.8793e-02, -1.5125e-03,  ...,  3.5286e-03,
          7.1287e-04, -6.4850e-05],
        [ 5.9624e-03, -7.4501e-03,  3.8025e-02,  ..., -3.8414e-03,
         -7.0572e-05, -1.1139e-02],
        ...,
        [ 1.2520e-02,  7.6103e-03,  5.0163e-03,  ...,  3.3691e-02,
         -2.1439e-03,  4.9973e-03],
        [ 5.7983e-03, -3.8795e-03, -4.5776e-03,  ...,  4.4098e-03,
          3.0930e-02, -1.0162e-02],
        [-7.4463e-03,  1.9703e-03,  4.1275e-03,  ..., -8.1024e-03,
         -4.0283e-03,  2.3834e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.3281, -4.8711, -0.9951,  ...,  0.5415, -0.2625,  0.4595]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 00:08:08 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The computer falls into the category of device
The juicer falls into the category of utensil
The skirt falls into the category of clothes
The notebook falls into the category of book
The armchair falls into the category of chair
The mascara falls into the category of makeup
The croissant falls into the category of pastry
The shirt falls into the category of
2024-07-29 00:08:08 root INFO     [order_1_approx] starting weight calculation for The mascara falls into the category of makeup
The skirt falls into the category of clothes
The croissant falls into the category of pastry
The shirt falls into the category of clothes
The armchair falls into the category of chair
The notebook falls into the category of book
The juicer falls into the category of utensil
The computer falls into the category of
2024-07-29 00:08:08 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 00:10:03 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1571, -0.5801,  0.4956,  ..., -0.0719, -0.1599, -0.3325],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.8047, -4.6055, -0.3728,  ..., -1.9473, -2.3027, -1.0830],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 3.6499e-02,  7.0572e-03, -2.5711e-03,  ...,  4.7836e-03,
          9.7351e-03,  9.9335e-03],
        [ 3.7785e-03,  2.7435e-02, -2.4738e-03,  ...,  3.7384e-04,
          7.4959e-03, -4.1885e-03],
        [-1.8845e-03,  4.7636e-04,  3.1769e-02,  ..., -2.2945e-03,
          4.8256e-03,  8.5297e-03],
        ...,
        [ 8.1940e-03,  8.7738e-05,  6.9046e-04,  ...,  1.9669e-02,
          3.5782e-03, -2.3861e-03],
        [ 2.5558e-04,  3.3989e-03,  1.4095e-03,  ...,  8.9111e-03,
          2.6459e-02, -4.7874e-04],
        [ 5.7602e-04, -3.8433e-03, -5.7602e-03,  ..., -8.7204e-03,
          6.4697e-03,  2.4399e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 5.5518e-01, -4.5859e+00,  7.3242e-04,  ..., -1.8008e+00,
         -2.6035e+00, -9.0234e-01]], device='cuda:1', dtype=torch.float16,
       grad_fn=<SubBackward0>) 

                    
2024-07-29 00:10:04 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The mascara falls into the category of makeup
The skirt falls into the category of clothes
The croissant falls into the category of pastry
The shirt falls into the category of clothes
The armchair falls into the category of chair
The notebook falls into the category of book
The juicer falls into the category of utensil
The computer falls into the category of
2024-07-29 00:10:04 root INFO     [order_1_approx] starting weight calculation for The armchair falls into the category of chair
The shirt falls into the category of clothes
The mascara falls into the category of makeup
The croissant falls into the category of pastry
The notebook falls into the category of book
The juicer falls into the category of utensil
The computer falls into the category of device
The skirt falls into the category of
2024-07-29 00:10:04 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 00:11:54 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3308, -0.7705, -0.3948,  ...,  0.6367, -0.1947,  0.1736],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.4199, -6.7148, -0.1548,  ..., -0.0541, -2.4043,  0.2266],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 4.3579e-02, -1.3176e-02,  1.1436e-02,  ..., -7.4539e-03,
          1.4801e-02, -2.4242e-03],
        [ 5.3444e-03,  1.7639e-02,  6.3133e-03,  ..., -1.4046e-02,
         -3.2597e-03, -5.3406e-05],
        [ 1.1398e-02, -2.7103e-03,  3.2166e-02,  ...,  5.2605e-03,
         -5.1231e-03, -9.0485e-03],
        ...,
        [ 7.9727e-03, -4.8218e-03,  8.1406e-03,  ...,  3.1860e-02,
         -1.0796e-03, -3.1395e-03],
        [ 8.7128e-03, -1.0063e-02, -2.1038e-03,  ...,  9.3412e-04,
          3.7659e-02, -1.0529e-02],
        [-8.3618e-03, -3.3302e-03,  1.4580e-02,  ..., -1.2184e-02,
         -1.2802e-02,  2.8259e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.2227, -6.4219, -0.1216,  ...,  0.0118, -2.4512,  0.3853]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 00:11:55 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The armchair falls into the category of chair
The shirt falls into the category of clothes
The mascara falls into the category of makeup
The croissant falls into the category of pastry
The notebook falls into the category of book
The juicer falls into the category of utensil
The computer falls into the category of device
The skirt falls into the category of
2024-07-29 00:11:55 root INFO     [order_1_approx] starting weight calculation for The armchair falls into the category of chair
The shirt falls into the category of clothes
The croissant falls into the category of pastry
The juicer falls into the category of utensil
The skirt falls into the category of clothes
The notebook falls into the category of book
The computer falls into the category of device
The mascara falls into the category of
2024-07-29 00:11:55 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 00:13:43 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.4934, -1.1846, -0.4451,  ..., -0.1211, -0.4165, -0.0797],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.9492, -2.3965, -0.1233,  ..., -0.5830, -1.0742,  2.6719],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0471,  0.0053,  0.0096,  ..., -0.0021,  0.0051,  0.0096],
        [-0.0052,  0.0485, -0.0085,  ...,  0.0023, -0.0052,  0.0098],
        [-0.0063, -0.0001,  0.0425,  ..., -0.0044,  0.0008, -0.0047],
        ...,
        [ 0.0050,  0.0029, -0.0016,  ...,  0.0414, -0.0017,  0.0014],
        [ 0.0066, -0.0010, -0.0026,  ..., -0.0072,  0.0435, -0.0151],
        [-0.0008,  0.0027,  0.0074,  ..., -0.0005, -0.0051,  0.0366]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.6992, -2.4570, -0.0601,  ..., -0.5420, -1.1816,  2.7812]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 00:13:44 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The armchair falls into the category of chair
The shirt falls into the category of clothes
The croissant falls into the category of pastry
The juicer falls into the category of utensil
The skirt falls into the category of clothes
The notebook falls into the category of book
The computer falls into the category of device
The mascara falls into the category of
2024-07-29 00:13:45 root INFO     [order_1_approx] starting weight calculation for The shirt falls into the category of clothes
The juicer falls into the category of utensil
The computer falls into the category of device
The skirt falls into the category of clothes
The croissant falls into the category of pastry
The notebook falls into the category of book
The mascara falls into the category of makeup
The armchair falls into the category of
2024-07-29 00:13:45 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 00:15:40 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3542, -1.2549, -0.1582,  ..., -0.1456, -0.7378,  0.2642],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.7822, -5.3672,  3.4824,  ..., -2.0469, -1.8320,  1.8906],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0273, -0.0026,  0.0056,  ..., -0.0020,  0.0029, -0.0021],
        [-0.0008,  0.0167,  0.0045,  ..., -0.0063,  0.0117, -0.0013],
        [-0.0067,  0.0068,  0.0205,  ...,  0.0044, -0.0041,  0.0011],
        ...,
        [ 0.0128,  0.0066, -0.0014,  ...,  0.0229,  0.0016, -0.0048],
        [ 0.0059,  0.0051, -0.0041,  ...,  0.0004,  0.0247, -0.0072],
        [-0.0032, -0.0027,  0.0004,  ..., -0.0049,  0.0042,  0.0170]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.8120, -5.2695,  3.3398,  ..., -1.9893, -1.8232,  1.9141]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 00:15:41 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The shirt falls into the category of clothes
The juicer falls into the category of utensil
The computer falls into the category of device
The skirt falls into the category of clothes
The croissant falls into the category of pastry
The notebook falls into the category of book
The mascara falls into the category of makeup
The armchair falls into the category of
2024-07-29 00:15:41 root INFO     total operator prediction time: 903.4653794765472 seconds
2024-07-29 00:15:41 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on synonyms - exact
2024-07-29 00:15:41 root INFO     building operator synonyms - exact
2024-07-29 00:15:41 root INFO     [order_1_approx] starting weight calculation for Another word for identical is same
Another word for jewel is gem
Another word for mother is mom
Another word for father is dad
Another word for clothes is clothing
Another word for organized is arranged
Another word for new is modern
Another word for baby is
2024-07-29 00:15:42 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 00:17:37 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.3557, -0.2250, -0.4790,  ..., -0.3350, -1.2705, -0.2368],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.9287, -4.1094, -1.6465,  ..., -0.1104, -2.7461,  2.7734],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0787, -0.0177,  0.0165,  ...,  0.0047, -0.0069,  0.0167],
        [-0.0082,  0.0538, -0.0093,  ...,  0.0040,  0.0256, -0.0082],
        [ 0.0139, -0.0173,  0.0718,  ..., -0.0146, -0.0085,  0.0134],
        ...,
        [-0.0153,  0.0062,  0.0008,  ...,  0.0681,  0.0062, -0.0051],
        [-0.0051,  0.0159,  0.0099,  ..., -0.0008,  0.0500, -0.0337],
        [-0.0009, -0.0119,  0.0063,  ..., -0.0187,  0.0062,  0.0609]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.9551, -3.8164, -1.3164,  ...,  0.0189, -2.8965,  2.0586]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 00:17:39 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Another word for identical is same
Another word for jewel is gem
Another word for mother is mom
Another word for father is dad
Another word for clothes is clothing
Another word for organized is arranged
Another word for new is modern
Another word for baby is
2024-07-29 00:17:42 root INFO     [order_1_approx] starting weight calculation for Another word for father is dad
Another word for clothes is clothing
Another word for identical is same
Another word for jewel is gem
Another word for new is modern
Another word for baby is infant
Another word for mother is mom
Another word for organized is
2024-07-29 00:17:42 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 00:19:37 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0471,  0.5879, -0.6323,  ..., -0.3721,  0.1738,  0.1841],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.7397,  0.6182,  2.5039,  ...,  1.6973, -2.8320, -4.1523],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0917,  0.0063,  0.0296,  ...,  0.0076,  0.0065,  0.0032],
        [-0.0095,  0.0770, -0.0074,  ..., -0.0159,  0.0149, -0.0005],
        [-0.0057, -0.0203,  0.0900,  ..., -0.0079, -0.0049,  0.0099],
        ...,
        [ 0.0127,  0.0138, -0.0198,  ...,  0.1019, -0.0218, -0.0260],
        [-0.0043,  0.0114,  0.0150,  ...,  0.0145,  0.0931, -0.0271],
        [-0.0116,  0.0102, -0.0230,  ..., -0.0223, -0.0165,  0.0848]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.6816,  0.0981,  1.9307,  ...,  1.8193, -2.8750, -3.5254]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 00:19:38 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Another word for father is dad
Another word for clothes is clothing
Another word for identical is same
Another word for jewel is gem
Another word for new is modern
Another word for baby is infant
Another word for mother is mom
Another word for organized is
2024-07-29 00:19:38 root INFO     [order_1_approx] starting weight calculation for Another word for clothes is clothing
Another word for identical is same
Another word for organized is arranged
Another word for jewel is gem
Another word for father is dad
Another word for baby is infant
Another word for new is modern
Another word for mother is
2024-07-29 00:19:38 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 00:21:34 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.6108, -0.0554, -0.1260,  ...,  0.3613, -0.2439, -0.8335],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.3604, -5.5391, -1.1328,  ..., -0.0122, -1.6074, -0.9355],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0603, -0.0170,  0.0122,  ...,  0.0002,  0.0012,  0.0087],
        [-0.0067,  0.0462,  0.0128,  ...,  0.0133,  0.0263, -0.0089],
        [ 0.0159, -0.0100,  0.0586,  ..., -0.0039, -0.0061,  0.0076],
        ...,
        [ 0.0004,  0.0047,  0.0030,  ...,  0.0594, -0.0038, -0.0147],
        [ 0.0010,  0.0125, -0.0104,  ...,  0.0019,  0.0452, -0.0003],
        [-0.0121, -0.0008, -0.0107,  ..., -0.0107, -0.0171,  0.0546]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.4065, -5.3047, -0.7192,  ...,  0.1477, -1.7705, -0.9893]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 00:21:35 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Another word for clothes is clothing
Another word for identical is same
Another word for organized is arranged
Another word for jewel is gem
Another word for father is dad
Another word for baby is infant
Another word for new is modern
Another word for mother is
2024-07-29 00:21:35 root INFO     [order_1_approx] starting weight calculation for Another word for jewel is gem
Another word for organized is arranged
Another word for mother is mom
Another word for clothes is clothing
Another word for father is dad
Another word for identical is same
Another word for baby is infant
Another word for new is
2024-07-29 00:21:35 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 00:23:31 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.3655, -0.2312, -0.8643,  ..., -0.3015, -0.1639, -0.1704],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.3496, -2.5977, -0.9463,  ...,  3.2871, -3.6582, -0.4668],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 7.5195e-02, -3.1967e-03,  1.5144e-02,  ...,  1.8311e-02,
          1.9806e-02,  2.1942e-02],
        [-1.4137e-02,  6.8359e-02,  1.5640e-02,  ...,  5.4131e-03,
          4.1046e-03, -1.9272e-02],
        [ 3.8376e-03,  1.3390e-03,  8.1299e-02,  ..., -6.4507e-03,
         -1.4786e-02,  6.6376e-04],
        ...,
        [-1.5221e-02,  1.5366e-02, -8.3637e-04,  ...,  8.2581e-02,
          7.6294e-06, -1.6434e-02],
        [-2.2926e-03,  8.7967e-03,  1.4427e-02,  ..., -3.9902e-03,
          7.3792e-02,  3.6240e-03],
        [-5.4855e-03, -1.6693e-02, -4.3488e-03,  ..., -2.3834e-02,
         -1.5518e-02,  7.3120e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.9482, -2.3164, -1.2109,  ...,  3.1035, -3.5352, -0.0164]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 00:23:32 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Another word for jewel is gem
Another word for organized is arranged
Another word for mother is mom
Another word for clothes is clothing
Another word for father is dad
Another word for identical is same
Another word for baby is infant
Another word for new is
2024-07-29 00:23:32 root INFO     [order_1_approx] starting weight calculation for Another word for mother is mom
Another word for new is modern
Another word for baby is infant
Another word for jewel is gem
Another word for father is dad
Another word for identical is same
Another word for organized is arranged
Another word for clothes is
2024-07-29 00:23:32 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 00:25:27 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0887, -0.8262, -0.6030,  ...,  0.1357, -0.2791, -0.1145],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.1094, -3.1211,  0.7861,  ..., -1.4580, -2.5215, -1.3545],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0545,  0.0066, -0.0077,  ...,  0.0107,  0.0005,  0.0249],
        [ 0.0064,  0.0325,  0.0007,  ..., -0.0130,  0.0016, -0.0180],
        [ 0.0187, -0.0011,  0.0610,  ..., -0.0288, -0.0013, -0.0030],
        ...,
        [-0.0021, -0.0165,  0.0055,  ...,  0.0630, -0.0071, -0.0086],
        [-0.0001,  0.0149,  0.0031,  ..., -0.0112,  0.0600, -0.0035],
        [-0.0063, -0.0031,  0.0002,  ..., -0.0070, -0.0021,  0.0507]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.7930, -2.9902,  0.2095,  ..., -0.6587, -2.4863, -1.3398]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 00:25:30 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Another word for mother is mom
Another word for new is modern
Another word for baby is infant
Another word for jewel is gem
Another word for father is dad
Another word for identical is same
Another word for organized is arranged
Another word for clothes is
2024-07-29 00:25:31 root INFO     [order_1_approx] starting weight calculation for Another word for clothes is clothing
Another word for baby is infant
Another word for mother is mom
Another word for organized is arranged
Another word for identical is same
Another word for jewel is gem
Another word for new is modern
Another word for father is
2024-07-29 00:25:31 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 00:27:26 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3560, -0.1320, -0.8442,  ..., -0.0743, -0.0284, -0.7178],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.4385, -1.5684, -1.6963,  ...,  0.9180, -1.5488, -0.9902],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0627, -0.0128,  0.0184,  ...,  0.0077,  0.0028,  0.0049],
        [ 0.0042,  0.0430, -0.0008,  ...,  0.0131,  0.0178, -0.0016],
        [ 0.0039, -0.0045,  0.0504,  ..., -0.0059, -0.0103,  0.0149],
        ...,
        [ 0.0027,  0.0004,  0.0060,  ...,  0.0510, -0.0009, -0.0189],
        [-0.0084,  0.0008,  0.0015,  ...,  0.0104,  0.0402, -0.0084],
        [-0.0101, -0.0019, -0.0010,  ..., -0.0064, -0.0043,  0.0451]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.0361, -1.3555, -1.2451,  ...,  0.9482, -1.7441, -1.2305]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 00:27:26 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Another word for clothes is clothing
Another word for baby is infant
Another word for mother is mom
Another word for organized is arranged
Another word for identical is same
Another word for jewel is gem
Another word for new is modern
Another word for father is
2024-07-29 00:27:27 root INFO     [order_1_approx] starting weight calculation for Another word for jewel is gem
Another word for mother is mom
Another word for organized is arranged
Another word for baby is infant
Another word for new is modern
Another word for father is dad
Another word for clothes is clothing
Another word for identical is
2024-07-29 00:27:27 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 00:29:20 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2739, -0.5117, -0.1112,  ...,  0.1832, -0.1064, -0.1263],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.7324,  0.1309,  1.8477,  ...,  0.3088, -3.5117,  0.0293],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.1166, -0.0006,  0.0219,  ...,  0.0153, -0.0013,  0.0164],
        [-0.0143,  0.0981,  0.0026,  ...,  0.0150,  0.0153, -0.0006],
        [ 0.0128, -0.0208,  0.1235,  ..., -0.0079, -0.0066, -0.0145],
        ...,
        [ 0.0162,  0.0147, -0.0063,  ...,  0.1165, -0.0191, -0.0076],
        [ 0.0111, -0.0124,  0.0153,  ..., -0.0087,  0.0839,  0.0044],
        [-0.0046, -0.0107, -0.0161,  ..., -0.0077, -0.0138,  0.1118]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.9521, -0.0096,  2.0840,  ...,  0.7686, -3.5312,  0.1509]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 00:29:21 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Another word for jewel is gem
Another word for mother is mom
Another word for organized is arranged
Another word for baby is infant
Another word for new is modern
Another word for father is dad
Another word for clothes is clothing
Another word for identical is
2024-07-29 00:29:21 root INFO     [order_1_approx] starting weight calculation for Another word for new is modern
Another word for organized is arranged
Another word for mother is mom
Another word for baby is infant
Another word for father is dad
Another word for identical is same
Another word for clothes is clothing
Another word for jewel is
2024-07-29 00:29:21 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 00:31:15 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3950, -0.0962, -0.3774,  ..., -0.0963, -0.6738, -0.7686],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.0791, -3.3203, -3.0039,  ...,  0.2354, -3.0820,  2.4941],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0217,  0.0012,  0.0070,  ..., -0.0022, -0.0050,  0.0036],
        [-0.0021,  0.0170, -0.0036,  ...,  0.0028,  0.0021, -0.0044],
        [ 0.0041,  0.0006,  0.0177,  ..., -0.0052, -0.0100,  0.0031],
        ...,
        [-0.0018,  0.0020, -0.0024,  ...,  0.0204,  0.0003, -0.0006],
        [ 0.0024, -0.0046,  0.0059,  ..., -0.0065,  0.0130,  0.0010],
        [-0.0029,  0.0072, -0.0016,  ..., -0.0032, -0.0021,  0.0136]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.0371, -3.4766, -3.1270,  ...,  0.3472, -3.1602,  2.3652]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 00:31:16 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Another word for new is modern
Another word for organized is arranged
Another word for mother is mom
Another word for baby is infant
Another word for father is dad
Another word for identical is same
Another word for clothes is clothing
Another word for jewel is
2024-07-29 00:31:16 root INFO     total operator prediction time: 935.1907978057861 seconds
2024-07-29 00:31:16 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on animal - youth
2024-07-29 00:31:16 root INFO     building operator animal - youth
2024-07-29 00:31:17 root INFO     [order_1_approx] starting weight calculation for The offspring of a woodchuck is referred to as a kit
The offspring of a weasel is referred to as a kit
The offspring of a pig is referred to as a piglet
The offspring of a beetle is referred to as a larva
The offspring of a cricket is referred to as a larva
The offspring of a shark is referred to as a cub
The offspring of a goat is referred to as a kid
The offspring of a insect is referred to as a
2024-07-29 00:31:17 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 00:33:12 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3523,  0.3911,  0.4468,  ..., -0.0123, -0.0076, -0.3513],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.4062, -2.9512,  0.0776,  ..., -0.9971, -3.5352, -0.2529],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 3.3508e-02, -9.7733e-03,  4.2381e-03,  ...,  2.0752e-03,
         -1.5945e-02, -1.5059e-03],
        [ 5.1346e-03,  1.7776e-02, -1.6594e-03,  ...,  3.6240e-05,
         -7.8125e-03, -2.1038e-03],
        [ 3.0785e-03, -9.7275e-05,  2.6886e-02,  ...,  6.6299e-03,
          1.7719e-03, -3.3531e-03],
        ...,
        [ 4.3983e-03,  5.8594e-03, -1.1093e-02,  ...,  1.4236e-02,
          6.8016e-03,  2.0657e-03],
        [-9.5129e-04, -8.8120e-04,  5.4016e-03,  ...,  3.0212e-03,
          7.2365e-03, -6.0120e-03],
        [ 4.7379e-03,  6.6528e-03, -2.2049e-03,  ..., -2.8954e-03,
          3.5915e-03,  1.7319e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.5371, -3.0098, -0.0192,  ..., -0.9639, -3.6152, -0.2781]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 00:33:13 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The offspring of a woodchuck is referred to as a kit
The offspring of a weasel is referred to as a kit
The offspring of a pig is referred to as a piglet
The offspring of a beetle is referred to as a larva
The offspring of a cricket is referred to as a larva
The offspring of a shark is referred to as a cub
The offspring of a goat is referred to as a kid
The offspring of a insect is referred to as a
2024-07-29 00:33:13 root INFO     [order_1_approx] starting weight calculation for The offspring of a beetle is referred to as a larva
The offspring of a woodchuck is referred to as a kit
The offspring of a cricket is referred to as a larva
The offspring of a weasel is referred to as a kit
The offspring of a insect is referred to as a larva
The offspring of a goat is referred to as a kid
The offspring of a shark is referred to as a cub
The offspring of a pig is referred to as a
2024-07-29 00:33:13 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 00:35:07 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0725, -0.4016,  0.1438,  ..., -0.1917, -0.5713, -0.4771],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.2109, -1.7646, -0.7412,  ...,  0.0430, -1.8125,  1.4980],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0386, -0.0101,  0.0026,  ...,  0.0135, -0.0103, -0.0059],
        [ 0.0086,  0.0176, -0.0067,  ..., -0.0008,  0.0009, -0.0037],
        [ 0.0108,  0.0015,  0.0351,  ...,  0.0081, -0.0127, -0.0109],
        ...,
        [ 0.0016, -0.0023, -0.0030,  ...,  0.0382,  0.0004,  0.0052],
        [ 0.0083, -0.0076,  0.0093,  ..., -0.0076,  0.0186, -0.0052],
        [ 0.0090,  0.0086, -0.0035,  ..., -0.0159,  0.0028,  0.0347]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.1660, -1.6729, -0.9561,  ...,  0.1609, -2.0137,  1.2861]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 00:35:08 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The offspring of a beetle is referred to as a larva
The offspring of a woodchuck is referred to as a kit
The offspring of a cricket is referred to as a larva
The offspring of a weasel is referred to as a kit
The offspring of a insect is referred to as a larva
The offspring of a goat is referred to as a kid
The offspring of a shark is referred to as a cub
The offspring of a pig is referred to as a
2024-07-29 00:35:08 root INFO     [order_1_approx] starting weight calculation for The offspring of a goat is referred to as a kid
The offspring of a insect is referred to as a larva
The offspring of a beetle is referred to as a larva
The offspring of a shark is referred to as a cub
The offspring of a weasel is referred to as a kit
The offspring of a pig is referred to as a piglet
The offspring of a woodchuck is referred to as a kit
The offspring of a cricket is referred to as a
2024-07-29 00:35:08 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 00:37:00 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2944,  0.0901,  0.2365,  ..., -0.0607, -0.4036, -0.1487],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.4226, -2.6758,  0.3428,  ..., -0.2153, -1.3408, -0.0742],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 5.2979e-02, -1.0979e-02,  3.3035e-03,  ...,  5.1727e-03,
         -7.3776e-03, -1.1063e-02],
        [ 5.4169e-04,  3.1616e-02, -4.4022e-03,  ...,  7.8735e-03,
          1.6899e-03, -1.2138e-02],
        [ 7.9060e-04,  6.8855e-03,  4.9805e-02,  ...,  6.6299e-03,
          6.7711e-05,  2.3994e-03],
        ...,
        [ 2.6321e-03, -8.5144e-03, -7.7515e-03,  ...,  3.3875e-02,
         -8.6517e-03,  3.8567e-03],
        [ 9.7504e-03, -4.4060e-04,  1.8539e-02,  ...,  1.5274e-02,
          1.9882e-02, -1.2856e-03],
        [ 1.1597e-03,  1.1116e-02, -5.1346e-03,  ..., -7.9269e-03,
          4.8294e-03,  2.3285e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.5322, -2.5098,  0.2065,  ...,  0.0813, -1.5859, -0.2496]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 00:37:01 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The offspring of a goat is referred to as a kid
The offspring of a insect is referred to as a larva
The offspring of a beetle is referred to as a larva
The offspring of a shark is referred to as a cub
The offspring of a weasel is referred to as a kit
The offspring of a pig is referred to as a piglet
The offspring of a woodchuck is referred to as a kit
The offspring of a cricket is referred to as a
2024-07-29 00:37:01 root INFO     [order_1_approx] starting weight calculation for The offspring of a pig is referred to as a piglet
The offspring of a shark is referred to as a cub
The offspring of a insect is referred to as a larva
The offspring of a beetle is referred to as a larva
The offspring of a woodchuck is referred to as a kit
The offspring of a cricket is referred to as a larva
The offspring of a goat is referred to as a kid
The offspring of a weasel is referred to as a
2024-07-29 00:37:02 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 00:38:46 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4536, -0.3020,  0.5776,  ..., -0.1543, -1.1387, -0.3547],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.2148, -2.8789, -0.4717,  ...,  0.3286, -1.6953,  1.4443],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0098, -0.0015, -0.0014,  ...,  0.0003,  0.0017, -0.0035],
        [-0.0013,  0.0090, -0.0024,  ..., -0.0007,  0.0014,  0.0010],
        [-0.0029,  0.0021,  0.0077,  ...,  0.0022, -0.0016, -0.0026],
        ...,
        [-0.0025,  0.0003,  0.0006,  ...,  0.0073,  0.0048,  0.0035],
        [-0.0027, -0.0006,  0.0023,  ...,  0.0012,  0.0081, -0.0012],
        [-0.0005, -0.0020, -0.0004,  ..., -0.0036, -0.0003,  0.0083]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.2480, -2.8125, -0.4707,  ...,  0.3608, -1.7139,  1.4053]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 00:38:47 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The offspring of a pig is referred to as a piglet
The offspring of a shark is referred to as a cub
The offspring of a insect is referred to as a larva
The offspring of a beetle is referred to as a larva
The offspring of a woodchuck is referred to as a kit
The offspring of a cricket is referred to as a larva
The offspring of a goat is referred to as a kid
The offspring of a weasel is referred to as a
2024-07-29 00:38:47 root INFO     [order_1_approx] starting weight calculation for The offspring of a cricket is referred to as a larva
The offspring of a insect is referred to as a larva
The offspring of a pig is referred to as a piglet
The offspring of a woodchuck is referred to as a kit
The offspring of a goat is referred to as a kid
The offspring of a weasel is referred to as a kit
The offspring of a beetle is referred to as a larva
The offspring of a shark is referred to as a
2024-07-29 00:38:47 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 00:40:37 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.7656,  0.1372, -0.3174,  ..., -0.3188, -0.9209,  0.0687],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.7148, -3.2637, -2.6348,  ..., -1.2305, -3.3047,  0.9248],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 3.1891e-02, -1.4782e-03,  5.6000e-03,  ...,  7.3242e-04,
          3.0212e-03, -2.0885e-03],
        [ 2.2507e-04,  3.7415e-02, -1.5198e-02,  ..., -9.7275e-03,
         -4.3068e-03, -6.3095e-03],
        [ 4.8599e-03,  2.8305e-03,  2.7832e-02,  ...,  9.3307e-03,
         -4.5776e-03, -6.1646e-03],
        ...,
        [ 4.3297e-04, -1.1292e-03,  8.6288e-03,  ...,  2.4582e-02,
         -6.3095e-03,  3.1300e-03],
        [ 1.0536e-02,  2.2182e-03,  9.9258e-03,  ...,  1.4763e-03,
          8.6746e-03, -5.3482e-03],
        [-2.4796e-05, -1.0662e-03,  6.1684e-03,  ..., -3.3340e-03,
         -2.4471e-03,  3.6804e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.6167, -3.3750, -3.0293,  ..., -1.3164, -3.5391,  0.5474]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 00:40:38 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The offspring of a cricket is referred to as a larva
The offspring of a insect is referred to as a larva
The offspring of a pig is referred to as a piglet
The offspring of a woodchuck is referred to as a kit
The offspring of a goat is referred to as a kid
The offspring of a weasel is referred to as a kit
The offspring of a beetle is referred to as a larva
The offspring of a shark is referred to as a
2024-07-29 00:40:38 root INFO     [order_1_approx] starting weight calculation for The offspring of a pig is referred to as a piglet
The offspring of a shark is referred to as a cub
The offspring of a goat is referred to as a kid
The offspring of a insect is referred to as a larva
The offspring of a weasel is referred to as a kit
The offspring of a woodchuck is referred to as a kit
The offspring of a cricket is referred to as a larva
The offspring of a beetle is referred to as a
2024-07-29 00:40:38 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 00:42:29 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4297,  0.1205,  0.0228,  ..., -0.3413, -0.5278, -0.5078],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.9199, -1.7432,  0.0615,  ...,  0.4185, -1.9756, -0.5508],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 2.0737e-02, -5.7983e-03,  1.8845e-03,  ...,  2.9926e-03,
         -4.3831e-03, -3.9330e-03],
        [-9.1982e-04,  7.4425e-03, -2.7885e-03,  ...,  5.0049e-03,
          1.0700e-03, -5.7564e-03],
        [-2.2430e-03, -1.4210e-03,  1.6418e-02,  ...,  2.2182e-03,
          2.1667e-03, -1.2980e-03],
        ...,
        [ 1.4801e-03, -7.4387e-05, -7.0381e-04,  ...,  1.3763e-02,
          5.2872e-03,  1.7490e-03],
        [-7.0238e-04, -6.2637e-03,  5.0011e-03,  ...,  4.6158e-04,
          1.3687e-02, -2.4796e-03],
        [ 1.6441e-03,  5.7678e-03,  1.1921e-03,  ..., -1.1349e-03,
          7.2384e-04,  1.7059e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.9092, -1.7607,  0.0192,  ...,  0.3628, -2.0117, -0.5928]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 00:42:30 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The offspring of a pig is referred to as a piglet
The offspring of a shark is referred to as a cub
The offspring of a goat is referred to as a kid
The offspring of a insect is referred to as a larva
The offspring of a weasel is referred to as a kit
The offspring of a woodchuck is referred to as a kit
The offspring of a cricket is referred to as a larva
The offspring of a beetle is referred to as a
2024-07-29 00:42:30 root INFO     [order_1_approx] starting weight calculation for The offspring of a cricket is referred to as a larva
The offspring of a pig is referred to as a piglet
The offspring of a weasel is referred to as a kit
The offspring of a shark is referred to as a cub
The offspring of a insect is referred to as a larva
The offspring of a goat is referred to as a kid
The offspring of a beetle is referred to as a larva
The offspring of a woodchuck is referred to as a
2024-07-29 00:42:30 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 00:44:23 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3447, -0.2949,  0.0951,  ..., -0.4727, -1.3408, -0.2323],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.8320, -4.0469,  0.8389,  ..., -2.5430, -1.5254,  0.3047],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0464, -0.0110,  0.0094,  ...,  0.0022, -0.0034, -0.0118],
        [ 0.0108,  0.0280, -0.0050,  ...,  0.0020,  0.0105, -0.0076],
        [-0.0073, -0.0001,  0.0203,  ..., -0.0002, -0.0089, -0.0076],
        ...,
        [-0.0064,  0.0016, -0.0024,  ...,  0.0409, -0.0071,  0.0090],
        [-0.0072, -0.0057,  0.0025,  ..., -0.0053,  0.0134, -0.0033],
        [-0.0081,  0.0174, -0.0001,  ..., -0.0182,  0.0004,  0.0289]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.6992, -3.5586,  0.7842,  ..., -2.3633, -1.6035,  0.4514]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 00:44:24 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The offspring of a cricket is referred to as a larva
The offspring of a pig is referred to as a piglet
The offspring of a weasel is referred to as a kit
The offspring of a shark is referred to as a cub
The offspring of a insect is referred to as a larva
The offspring of a goat is referred to as a kid
The offspring of a beetle is referred to as a larva
The offspring of a woodchuck is referred to as a
2024-07-29 00:44:24 root INFO     [order_1_approx] starting weight calculation for The offspring of a shark is referred to as a cub
The offspring of a weasel is referred to as a kit
The offspring of a insect is referred to as a larva
The offspring of a beetle is referred to as a larva
The offspring of a pig is referred to as a piglet
The offspring of a woodchuck is referred to as a kit
The offspring of a cricket is referred to as a larva
The offspring of a goat is referred to as a
2024-07-29 00:44:24 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 00:46:16 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2073, -0.3237,  0.6992,  ..., -0.1420, -0.5146, -0.0605],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.5117, -3.4043,  0.0508,  ...,  0.7480, -2.5312, -1.6055],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 4.1168e-02, -4.0894e-03,  9.4986e-03,  ...,  4.9362e-03,
         -8.0395e-04, -5.0774e-03],
        [ 7.9880e-03,  2.5253e-02, -9.2773e-03,  ...,  5.0583e-03,
          3.2082e-03, -5.9795e-04],
        [-4.5776e-05, -2.2507e-03,  2.2995e-02,  ..., -1.3191e-02,
         -1.3680e-02, -3.4218e-03],
        ...,
        [ 5.1956e-03,  4.6120e-03, -1.3916e-02,  ...,  3.8727e-02,
          8.4991e-03,  5.0278e-03],
        [ 1.8127e-02,  1.3016e-02,  6.2866e-03,  ...,  1.3351e-05,
          1.5717e-02, -2.5673e-03],
        [ 1.3332e-03,  1.1391e-02, -3.6697e-03,  ..., -5.0278e-03,
          9.7275e-03,  2.8336e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.5938, -3.3105,  0.0448,  ...,  0.8872, -2.6641, -1.4688]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 00:46:17 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The offspring of a shark is referred to as a cub
The offspring of a weasel is referred to as a kit
The offspring of a insect is referred to as a larva
The offspring of a beetle is referred to as a larva
The offspring of a pig is referred to as a piglet
The offspring of a woodchuck is referred to as a kit
The offspring of a cricket is referred to as a larva
The offspring of a goat is referred to as a
2024-07-29 00:46:17 root INFO     total operator prediction time: 900.4519546031952 seconds
2024-07-29 00:46:17 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on animal - sound
2024-07-29 00:46:17 root INFO     building operator animal - sound
2024-07-29 00:46:17 root INFO     [order_1_approx] starting weight calculation for The sound that a seal makes is called a bark
The sound that a mule makes is called a bray
The sound that a hound makes is called a bark
The sound that a deer makes is called a bellow
The sound that a beetle makes is called a drone
The sound that a whale makes is called a sing
The sound that a pig makes is called a oink
The sound that a tiger makes is called a
2024-07-29 00:46:17 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 00:48:08 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2666, -0.5850,  0.1827,  ...,  0.6431, -0.3535, -0.0795],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.6797, -7.1875, -1.4854,  ..., -2.3223, -0.8662, -0.0703],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 3.9551e-02, -3.0537e-03,  9.1324e-03,  ...,  1.4626e-02,
         -2.3956e-02, -4.3259e-03],
        [-1.4587e-02,  3.3569e-02, -1.6953e-02,  ...,  6.7215e-03,
          8.1100e-03, -9.0122e-05],
        [-2.8458e-03,  6.3591e-03,  2.7725e-02,  ..., -5.1804e-03,
          1.6602e-02, -1.1932e-02],
        ...,
        [ 1.1932e-02, -9.0790e-03, -7.8583e-03,  ...,  4.7516e-02,
         -4.7684e-03, -4.9362e-03],
        [-6.8665e-04, -6.4163e-03,  1.2177e-02,  ..., -9.1629e-03,
          2.7832e-02,  1.5583e-03],
        [-2.9373e-03,  2.7771e-03, -2.4811e-02,  ..., -1.6602e-02,
          8.2092e-03,  1.9104e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.1055, -7.0000, -0.7773,  ..., -2.4980, -0.9897,  0.0112]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 00:48:09 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The sound that a seal makes is called a bark
The sound that a mule makes is called a bray
The sound that a hound makes is called a bark
The sound that a deer makes is called a bellow
The sound that a beetle makes is called a drone
The sound that a whale makes is called a sing
The sound that a pig makes is called a oink
The sound that a tiger makes is called a
2024-07-29 00:48:09 root INFO     [order_1_approx] starting weight calculation for The sound that a tiger makes is called a growl
The sound that a pig makes is called a oink
The sound that a whale makes is called a sing
The sound that a deer makes is called a bellow
The sound that a seal makes is called a bark
The sound that a hound makes is called a bark
The sound that a beetle makes is called a drone
The sound that a mule makes is called a
2024-07-29 00:48:09 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 00:50:03 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2754, -0.5405,  1.1553,  ...,  0.0357, -0.8984,  0.4678],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.2207, -5.5078,  1.8496,  ..., -1.3926, -2.6562,  1.7939],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0681, -0.0033, -0.0201,  ...,  0.0160, -0.0050, -0.0106],
        [-0.0138,  0.0334, -0.0110,  ...,  0.0106,  0.0140,  0.0170],
        [-0.0082,  0.0103,  0.0704,  ..., -0.0332, -0.0034, -0.0168],
        ...,
        [ 0.0245, -0.0032, -0.0308,  ...,  0.0455, -0.0206, -0.0016],
        [ 0.0021,  0.0099,  0.0040,  ...,  0.0201,  0.0497,  0.0030],
        [ 0.0041, -0.0049,  0.0089,  ..., -0.0084, -0.0154,  0.0215]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.2153, -5.3086,  1.4570,  ..., -1.7393, -3.0996,  1.6484]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 00:50:04 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The sound that a tiger makes is called a growl
The sound that a pig makes is called a oink
The sound that a whale makes is called a sing
The sound that a deer makes is called a bellow
The sound that a seal makes is called a bark
The sound that a hound makes is called a bark
The sound that a beetle makes is called a drone
The sound that a mule makes is called a
2024-07-29 00:50:04 root INFO     [order_1_approx] starting weight calculation for The sound that a tiger makes is called a growl
The sound that a hound makes is called a bark
The sound that a seal makes is called a bark
The sound that a whale makes is called a sing
The sound that a beetle makes is called a drone
The sound that a mule makes is called a bray
The sound that a pig makes is called a oink
The sound that a deer makes is called a
2024-07-29 00:50:04 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 00:52:00 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0699, -0.2209,  0.5254,  ...,  0.4722, -0.2917,  0.7905],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.2061, -2.4785, -1.5234,  ...,  0.1313, -2.9453, -1.0186],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0401,  0.0011,  0.0009,  ...,  0.0107, -0.0089,  0.0045],
        [ 0.0011,  0.0294, -0.0078,  ...,  0.0244,  0.0055, -0.0106],
        [ 0.0044,  0.0246,  0.0360,  ..., -0.0209, -0.0136, -0.0100],
        ...,
        [-0.0018, -0.0009, -0.0008,  ...,  0.0550, -0.0132,  0.0054],
        [-0.0063,  0.0064, -0.0031,  ...,  0.0005,  0.0497, -0.0002],
        [-0.0007,  0.0002,  0.0046,  ..., -0.0105, -0.0086,  0.0304]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.0310, -2.5078, -1.5078,  ...,  0.0600, -2.8828, -1.1484]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 00:52:01 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The sound that a tiger makes is called a growl
The sound that a hound makes is called a bark
The sound that a seal makes is called a bark
The sound that a whale makes is called a sing
The sound that a beetle makes is called a drone
The sound that a mule makes is called a bray
The sound that a pig makes is called a oink
The sound that a deer makes is called a
2024-07-29 00:52:01 root INFO     [order_1_approx] starting weight calculation for The sound that a mule makes is called a bray
The sound that a whale makes is called a sing
The sound that a deer makes is called a bellow
The sound that a hound makes is called a bark
The sound that a pig makes is called a oink
The sound that a seal makes is called a bark
The sound that a tiger makes is called a growl
The sound that a beetle makes is called a
2024-07-29 00:52:01 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 00:53:55 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0314,  0.0134,  0.1963,  ...,  0.2228, -0.3203, -0.3689],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.5908, -1.4346,  3.6211,  ..., -0.0781, -1.8516,  1.4600],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0451, -0.0017,  0.0053,  ...,  0.0066, -0.0037,  0.0034],
        [-0.0036,  0.0104, -0.0040,  ...,  0.0054, -0.0079, -0.0086],
        [ 0.0051, -0.0003,  0.0231,  ...,  0.0009, -0.0106, -0.0057],
        ...,
        [ 0.0053, -0.0031,  0.0007,  ...,  0.0358, -0.0053,  0.0007],
        [-0.0025, -0.0055,  0.0040,  ...,  0.0010,  0.0248, -0.0014],
        [-0.0057,  0.0090, -0.0033,  ..., -0.0120, -0.0127,  0.0250]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.5801, -1.8926,  3.3496,  ..., -0.2666, -1.9424,  1.3467]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 00:53:57 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The sound that a mule makes is called a bray
The sound that a whale makes is called a sing
The sound that a deer makes is called a bellow
The sound that a hound makes is called a bark
The sound that a pig makes is called a oink
The sound that a seal makes is called a bark
The sound that a tiger makes is called a growl
The sound that a beetle makes is called a
2024-07-29 00:53:58 root INFO     [order_1_approx] starting weight calculation for The sound that a seal makes is called a bark
The sound that a hound makes is called a bark
The sound that a whale makes is called a sing
The sound that a mule makes is called a bray
The sound that a tiger makes is called a growl
The sound that a deer makes is called a bellow
The sound that a beetle makes is called a drone
The sound that a pig makes is called a
2024-07-29 00:53:58 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 00:55:53 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.3989, -0.7969,  0.0045,  ...,  0.2085, -0.4302, -0.0995],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.3906, -2.9199,  3.2461,  ..., -1.4785, -0.1357,  1.8027],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0454,  0.0016,  0.0027,  ...,  0.0107, -0.0078, -0.0017],
        [ 0.0161,  0.0195, -0.0098,  ..., -0.0006, -0.0012, -0.0053],
        [-0.0012, -0.0003,  0.0467,  ..., -0.0130, -0.0144, -0.0032],
        ...,
        [ 0.0122, -0.0079, -0.0060,  ...,  0.0344, -0.0156,  0.0099],
        [ 0.0036, -0.0020, -0.0017,  ...,  0.0001,  0.0262,  0.0010],
        [ 0.0109,  0.0033, -0.0006,  ..., -0.0078, -0.0039,  0.0287]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.1758, -2.9004,  3.1992,  ..., -1.9199, -0.3918,  1.9570]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 00:55:54 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The sound that a seal makes is called a bark
The sound that a hound makes is called a bark
The sound that a whale makes is called a sing
The sound that a mule makes is called a bray
The sound that a tiger makes is called a growl
The sound that a deer makes is called a bellow
The sound that a beetle makes is called a drone
The sound that a pig makes is called a
2024-07-29 00:55:54 root INFO     [order_1_approx] starting weight calculation for The sound that a tiger makes is called a growl
The sound that a whale makes is called a sing
The sound that a beetle makes is called a drone
The sound that a deer makes is called a bellow
The sound that a seal makes is called a bark
The sound that a mule makes is called a bray
The sound that a pig makes is called a oink
The sound that a hound makes is called a
2024-07-29 00:55:54 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 00:57:45 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2003, -0.2355,  1.0479,  ...,  0.3899, -0.2964, -0.4199],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.6357, -6.3398, -0.2285,  ..., -1.1543, -1.2510,  3.2988],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0556, -0.0033,  0.0102,  ..., -0.0036, -0.0074, -0.0102],
        [-0.0044,  0.0146, -0.0120,  ...,  0.0121,  0.0042, -0.0148],
        [ 0.0072,  0.0059,  0.0401,  ..., -0.0051, -0.0145, -0.0091],
        ...,
        [ 0.0017, -0.0068,  0.0059,  ...,  0.0522, -0.0043,  0.0031],
        [ 0.0027,  0.0011, -0.0043,  ...,  0.0101,  0.0355, -0.0124],
        [-0.0095, -0.0046, -0.0096,  ..., -0.0123, -0.0161,  0.0337]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-7.9639e-01, -6.3594e+00,  4.0283e-03,  ..., -1.6006e+00,
         -1.4414e+00,  3.1719e+00]], device='cuda:1', dtype=torch.float16,
       grad_fn=<SubBackward0>) 

                    
2024-07-29 00:57:47 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The sound that a tiger makes is called a growl
The sound that a whale makes is called a sing
The sound that a beetle makes is called a drone
The sound that a deer makes is called a bellow
The sound that a seal makes is called a bark
The sound that a mule makes is called a bray
The sound that a pig makes is called a oink
The sound that a hound makes is called a
2024-07-29 00:57:47 root INFO     [order_1_approx] starting weight calculation for The sound that a pig makes is called a oink
The sound that a beetle makes is called a drone
The sound that a tiger makes is called a growl
The sound that a hound makes is called a bark
The sound that a seal makes is called a bark
The sound that a deer makes is called a bellow
The sound that a mule makes is called a bray
The sound that a whale makes is called a
2024-07-29 00:57:47 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 00:59:40 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.6074, -0.2771,  0.4768,  ..., -0.1621, -0.2739,  0.1963],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.0386, -1.8604,  2.8730,  ...,  0.2451, -2.1875,  1.4502],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0310,  0.0117, -0.0062,  ...,  0.0056, -0.0079, -0.0056],
        [ 0.0130,  0.0227, -0.0154,  ..., -0.0082, -0.0104, -0.0114],
        [ 0.0094,  0.0085,  0.0300,  ..., -0.0047, -0.0059, -0.0084],
        ...,
        [ 0.0056, -0.0075,  0.0017,  ...,  0.0367, -0.0074, -0.0089],
        [-0.0013, -0.0003,  0.0021,  ...,  0.0076,  0.0286, -0.0019],
        [-0.0071, -0.0024, -0.0061,  ...,  0.0001,  0.0030,  0.0261]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.1131, -2.3496,  2.7246,  ..., -0.0156, -2.2305,  1.6875]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 00:59:45 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The sound that a pig makes is called a oink
The sound that a beetle makes is called a drone
The sound that a tiger makes is called a growl
The sound that a hound makes is called a bark
The sound that a seal makes is called a bark
The sound that a deer makes is called a bellow
The sound that a mule makes is called a bray
The sound that a whale makes is called a
2024-07-29 00:59:49 root INFO     [order_1_approx] starting weight calculation for The sound that a mule makes is called a bray
The sound that a hound makes is called a bark
The sound that a beetle makes is called a drone
The sound that a pig makes is called a oink
The sound that a deer makes is called a bellow
The sound that a whale makes is called a sing
The sound that a tiger makes is called a growl
The sound that a seal makes is called a
2024-07-29 00:59:49 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 01:01:43 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.7900, -0.3113,  0.3823,  ..., -0.0577, -0.7700,  0.6660],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.6582, -2.1055, -0.0605,  ..., -1.6514, -1.4424,  1.5117],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 6.1829e-02,  6.0387e-03, -8.5068e-03,  ...,  3.8147e-06,
         -8.7585e-03, -1.2527e-02],
        [ 1.2939e-02,  3.5553e-02, -1.8158e-02,  ..., -5.3596e-04,
         -4.1428e-03, -1.0460e-02],
        [ 1.2726e-02,  1.0437e-02,  4.3884e-02,  ..., -9.8953e-03,
         -1.1768e-03, -1.8311e-02],
        ...,
        [ 8.9951e-03, -3.7251e-03,  4.8065e-03,  ...,  4.9438e-02,
         -1.7815e-03, -7.9193e-03],
        [-1.6968e-02, -6.0425e-03, -2.1324e-03,  ...,  7.9346e-03,
          3.5034e-02, -5.5008e-03],
        [-4.1809e-03,  2.1019e-03, -7.6714e-03,  ..., -2.1095e-03,
         -1.3866e-03,  3.4943e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.4668, -2.5547,  0.2087,  ..., -1.7168, -1.5703,  1.6162]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 01:01:44 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The sound that a mule makes is called a bray
The sound that a hound makes is called a bark
The sound that a beetle makes is called a drone
The sound that a pig makes is called a oink
The sound that a deer makes is called a bellow
The sound that a whale makes is called a sing
The sound that a tiger makes is called a growl
The sound that a seal makes is called a
2024-07-29 01:01:44 root INFO     total operator prediction time: 926.6337780952454 seconds
2024-07-29 01:01:44 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on things - color
2024-07-29 01:01:44 root INFO     building operator things - color
2024-07-29 01:01:44 root INFO     [order_1_approx] starting weight calculation for The toothpaste is colored white
The bruise is colored blue
The grass is colored green
The snow is colored white
The sky is colored blue
The soil is colored black
The tea is colored black
The ant is colored
2024-07-29 01:01:44 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 01:03:40 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1478,  0.0341, -0.5059,  ..., -0.5967, -0.0282, -0.3936],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.6626, -3.5801,  0.3501,  ..., -0.4473, -1.4688, -1.5000],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 6.3721e-02,  1.8511e-03,  1.2001e-02,  ...,  2.3308e-03,
          5.1651e-03, -3.8967e-03],
        [ 2.1652e-02,  4.9408e-02,  6.8130e-03,  ...,  5.0240e-03,
          1.8463e-02,  6.5460e-03],
        [ 1.2970e-02, -3.4008e-03,  4.4281e-02,  ...,  1.2955e-02,
         -3.1223e-03, -1.0643e-03],
        ...,
        [ 1.2749e-02, -3.5839e-03,  2.3460e-04,  ...,  5.6702e-02,
          2.3842e-03, -5.9853e-03],
        [ 1.7643e-03,  5.2261e-04, -1.9989e-03,  ...,  1.2924e-02,
          3.1403e-02, -8.5907e-03],
        [ 4.9710e-05,  5.1880e-03,  3.9940e-03,  ...,  3.4065e-03,
          6.5193e-03,  4.9103e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.4556, -3.5840,  0.1039,  ..., -0.5913, -1.4648, -1.2090]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 01:03:41 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The toothpaste is colored white
The bruise is colored blue
The grass is colored green
The snow is colored white
The sky is colored blue
The soil is colored black
The tea is colored black
The ant is colored
2024-07-29 01:03:41 root INFO     [order_1_approx] starting weight calculation for The ant is colored black
The toothpaste is colored white
The bruise is colored blue
The sky is colored blue
The soil is colored black
The grass is colored green
The snow is colored white
The tea is colored
2024-07-29 01:03:41 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 01:05:37 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.5786, -0.6440, -0.2261,  ..., -0.8594, -0.4370, -0.2175],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.7656, -2.5488, -1.3740,  ..., -4.2617, -0.6470,  0.3926],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0596,  0.0070,  0.0028,  ...,  0.0072,  0.0041, -0.0002],
        [ 0.0182,  0.0524,  0.0095,  ...,  0.0034,  0.0083, -0.0072],
        [ 0.0079, -0.0108,  0.0486,  ...,  0.0071, -0.0016, -0.0060],
        ...,
        [ 0.0115, -0.0067,  0.0022,  ...,  0.0513, -0.0012,  0.0047],
        [-0.0079,  0.0043, -0.0051,  ...,  0.0163,  0.0484, -0.0113],
        [-0.0119, -0.0077, -0.0011,  ..., -0.0021,  0.0005,  0.0557]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.0000, -2.5879, -1.4014,  ..., -4.4805, -0.9106,  0.4023]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 01:05:38 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The ant is colored black
The toothpaste is colored white
The bruise is colored blue
The sky is colored blue
The soil is colored black
The grass is colored green
The snow is colored white
The tea is colored
2024-07-29 01:05:38 root INFO     [order_1_approx] starting weight calculation for The ant is colored black
The soil is colored black
The grass is colored green
The snow is colored white
The sky is colored blue
The toothpaste is colored white
The tea is colored black
The bruise is colored
2024-07-29 01:05:38 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 01:07:35 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.3184, -0.2661, -0.3945,  ..., -0.3330, -0.6201,  0.2351],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.0371, -6.8320, -1.7041,  ..., -2.4180,  3.4141,  0.3877],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0618, -0.0028,  0.0104,  ...,  0.0069,  0.0092,  0.0052],
        [ 0.0138,  0.0274, -0.0006,  ...,  0.0071, -0.0014, -0.0135],
        [ 0.0033, -0.0150,  0.0385,  ..., -0.0064,  0.0056, -0.0081],
        ...,
        [ 0.0131, -0.0055,  0.0066,  ...,  0.0493, -0.0018, -0.0011],
        [-0.0029, -0.0041, -0.0038,  ...,  0.0106,  0.0429, -0.0039],
        [-0.0073,  0.0045,  0.0039,  ...,  0.0085, -0.0018,  0.0424]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.9644, -6.7773, -1.5820,  ..., -2.4707,  3.2949,  0.3364]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 01:07:36 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The ant is colored black
The soil is colored black
The grass is colored green
The snow is colored white
The sky is colored blue
The toothpaste is colored white
The tea is colored black
The bruise is colored
2024-07-29 01:07:37 root INFO     [order_1_approx] starting weight calculation for The soil is colored black
The grass is colored green
The ant is colored black
The tea is colored black
The bruise is colored blue
The toothpaste is colored white
The snow is colored white
The sky is colored
2024-07-29 01:07:37 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 01:09:33 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2654, -1.0381,  0.2478,  ..., -0.0708, -0.0740, -0.5752],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-2.1094, -5.8633,  2.8418,  ..., -1.0674,  0.1460, -0.7080],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0396,  0.0020, -0.0026,  ..., -0.0031,  0.0117, -0.0079],
        [ 0.0038,  0.0327,  0.0056,  ..., -0.0011,  0.0009, -0.0021],
        [ 0.0015, -0.0024,  0.0237,  ...,  0.0020, -0.0012,  0.0103],
        ...,
        [ 0.0071,  0.0002,  0.0003,  ...,  0.0301,  0.0091,  0.0016],
        [ 0.0027, -0.0123, -0.0018,  ...,  0.0112,  0.0225, -0.0053],
        [-0.0045, -0.0107,  0.0021,  ..., -0.0021, -0.0083,  0.0290]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-2.2832, -5.5859,  2.3945,  ..., -1.1006, -0.1980, -0.9814]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 01:09:33 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The soil is colored black
The grass is colored green
The ant is colored black
The tea is colored black
The bruise is colored blue
The toothpaste is colored white
The snow is colored white
The sky is colored
2024-07-29 01:09:34 root INFO     [order_1_approx] starting weight calculation for The sky is colored blue
The ant is colored black
The soil is colored black
The toothpaste is colored white
The tea is colored black
The grass is colored green
The bruise is colored blue
The snow is colored
2024-07-29 01:09:34 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 01:11:27 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0403,  0.2054, -0.3491,  ..., -0.6343, -0.8232, -0.4512],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.4824, -4.9727, -0.2766,  ..., -4.6602, -0.1892, -2.9160],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0583, -0.0080, -0.0013,  ..., -0.0002,  0.0077, -0.0060],
        [ 0.0055,  0.0494,  0.0073,  ..., -0.0016,  0.0068, -0.0056],
        [ 0.0054, -0.0090,  0.0424,  ...,  0.0010,  0.0015, -0.0056],
        ...,
        [ 0.0090, -0.0013,  0.0042,  ...,  0.0440,  0.0110, -0.0008],
        [-0.0036,  0.0060,  0.0015,  ...,  0.0135,  0.0413,  0.0003],
        [-0.0132,  0.0004,  0.0090,  ...,  0.0075, -0.0003,  0.0389]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.4668, -5.4922, -0.2019,  ..., -4.2344, -0.0740, -2.3164]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 01:11:28 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The sky is colored blue
The ant is colored black
The soil is colored black
The toothpaste is colored white
The tea is colored black
The grass is colored green
The bruise is colored blue
The snow is colored
2024-07-29 01:11:28 root INFO     [order_1_approx] starting weight calculation for The grass is colored green
The bruise is colored blue
The toothpaste is colored white
The tea is colored black
The ant is colored black
The sky is colored blue
The snow is colored white
The soil is colored
2024-07-29 01:11:28 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 01:13:24 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1290, -0.3535, -0.3745,  ...,  0.0639, -0.7344, -0.4248],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.1758, -5.9922,  0.9536,  ..., -2.3672,  1.0771, -1.9189],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 5.9204e-02,  5.0240e-03,  3.0689e-03,  ...,  5.3825e-03,
          8.6517e-03,  2.8782e-03],
        [ 1.6083e-02,  4.2969e-02,  8.1558e-03,  ...,  2.5444e-03,
          2.1248e-03, -2.3193e-03],
        [-4.1485e-04,  1.8921e-03,  4.1443e-02,  ...,  1.1463e-03,
          3.8052e-03, -8.2016e-04],
        ...,
        [ 2.9182e-03, -5.5389e-03,  7.9117e-03,  ...,  3.7994e-02,
          4.8637e-05, -6.7329e-04],
        [-2.4071e-03,  2.0618e-03, -6.6071e-03,  ...,  1.5007e-02,
          4.5532e-02, -9.0714e-03],
        [-1.2016e-02,  4.9591e-05, -2.1553e-03,  ..., -2.9926e-03,
         -1.3077e-02,  4.0833e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.0122, -5.7656,  0.6514,  ..., -2.3496,  0.8125, -1.9326]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 01:13:25 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The grass is colored green
The bruise is colored blue
The toothpaste is colored white
The tea is colored black
The ant is colored black
The sky is colored blue
The snow is colored white
The soil is colored
2024-07-29 01:13:26 root INFO     [order_1_approx] starting weight calculation for The ant is colored black
The tea is colored black
The grass is colored green
The soil is colored black
The sky is colored blue
The bruise is colored blue
The snow is colored white
The toothpaste is colored
2024-07-29 01:13:26 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 01:15:21 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0972, -1.0342, -0.2729,  ..., -0.4365, -0.8804,  0.1366],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.9473, -2.2441,  0.8555,  ...,  0.0620, -3.3203, -0.4067],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0582, -0.0031,  0.0091,  ...,  0.0035,  0.0005, -0.0012],
        [ 0.0188,  0.0532,  0.0057,  ...,  0.0002,  0.0011,  0.0046],
        [ 0.0158, -0.0013,  0.0606,  ...,  0.0056, -0.0079, -0.0078],
        ...,
        [-0.0004, -0.0010,  0.0014,  ...,  0.0531,  0.0007,  0.0043],
        [ 0.0036,  0.0023, -0.0006,  ...,  0.0085,  0.0524, -0.0147],
        [-0.0053, -0.0107,  0.0102,  ..., -0.0023,  0.0032,  0.0498]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-2.0195, -2.4824,  0.6875,  ...,  0.0083, -3.3164, -0.5620]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 01:15:22 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The ant is colored black
The tea is colored black
The grass is colored green
The soil is colored black
The sky is colored blue
The bruise is colored blue
The snow is colored white
The toothpaste is colored
2024-07-29 01:15:23 root INFO     [order_1_approx] starting weight calculation for The soil is colored black
The tea is colored black
The sky is colored blue
The ant is colored black
The toothpaste is colored white
The snow is colored white
The bruise is colored blue
The grass is colored
2024-07-29 01:15:23 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 01:17:18 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.6602, -0.1566, -0.5356,  ...,  0.0178, -0.1777, -0.5938],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.9824, -5.9766, -2.2324,  ..., -1.2520,  1.1738, -2.4336],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0640,  0.0067,  0.0040,  ...,  0.0027, -0.0007,  0.0058],
        [ 0.0113,  0.0376,  0.0062,  ..., -0.0004,  0.0154, -0.0066],
        [-0.0009, -0.0091,  0.0565,  ..., -0.0001,  0.0080, -0.0117],
        ...,
        [ 0.0073, -0.0028,  0.0058,  ...,  0.0446,  0.0164,  0.0007],
        [-0.0070,  0.0073, -0.0056,  ...,  0.0122,  0.0459, -0.0096],
        [-0.0045, -0.0059, -0.0004,  ...,  0.0022, -0.0007,  0.0433]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.6191, -6.0234, -2.1191,  ..., -0.8701,  0.6440, -2.4082]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 01:17:19 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The soil is colored black
The tea is colored black
The sky is colored blue
The ant is colored black
The toothpaste is colored white
The snow is colored white
The bruise is colored blue
The grass is colored
2024-07-29 01:17:19 root INFO     total operator prediction time: 935.5221829414368 seconds
2024-07-29 01:17:19 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on country - capital
2024-07-29 01:17:19 root INFO     building operator country - capital
2024-07-29 01:17:19 root INFO     [order_1_approx] starting weight calculation for The country with santiago as its capital is known as chile
The country with ankara as its capital is known as turkey
The country with stockholm as its capital is known as sweden
The country with dhaka as its capital is known as bangladesh
The country with dublin as its capital is known as ireland
The country with paris as its capital is known as france
The country with damascus as its capital is known as syria
The country with bangkok as its capital is known as
2024-07-29 01:17:19 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 01:19:10 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.6421, -0.4307, -0.3101,  ...,  0.0364, -0.1538,  0.0873],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.9287, -5.2734,  1.3066,  ..., -0.3066, -1.8467, -3.8027],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 1.1940e-02, -2.3212e-03,  2.7237e-03,  ...,  3.9864e-03,
         -1.6689e-03, -1.9722e-03],
        [-7.4482e-04,  2.8515e-03, -7.4291e-04,  ..., -4.9896e-03,
          5.1460e-03, -7.7438e-03],
        [-2.3365e-04, -1.9093e-03,  1.1688e-02,  ..., -1.5125e-03,
         -9.2697e-04,  2.8610e-05],
        ...,
        [ 5.0964e-03, -6.6042e-04,  4.5700e-03,  ...,  1.5961e-02,
          2.7161e-03,  7.2193e-04],
        [-3.9291e-03, -4.4441e-03, -7.5569e-03,  ...,  3.7556e-03,
          8.5907e-03,  2.7847e-03],
        [-4.1046e-03, -8.7070e-04, -7.0763e-03,  ..., -2.5177e-03,
          7.9651e-03,  1.1299e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.8511, -5.1836,  1.0605,  ..., -0.2964, -1.7412, -3.8828]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 01:19:11 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country with santiago as its capital is known as chile
The country with ankara as its capital is known as turkey
The country with stockholm as its capital is known as sweden
The country with dhaka as its capital is known as bangladesh
The country with dublin as its capital is known as ireland
The country with paris as its capital is known as france
The country with damascus as its capital is known as syria
The country with bangkok as its capital is known as
2024-07-29 01:19:11 root INFO     [order_1_approx] starting weight calculation for The country with stockholm as its capital is known as sweden
The country with dhaka as its capital is known as bangladesh
The country with santiago as its capital is known as chile
The country with paris as its capital is known as france
The country with bangkok as its capital is known as thailand
The country with damascus as its capital is known as syria
The country with ankara as its capital is known as turkey
The country with dublin as its capital is known as
2024-07-29 01:19:11 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 01:21:04 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.9473, -0.5752, -0.5957,  ...,  0.5107,  0.4089, -0.3882],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.4004, -5.7578, -1.2568,  ...,  1.6543, -1.3066, -6.9297],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0312, -0.0028, -0.0033,  ...,  0.0089,  0.0006,  0.0035],
        [-0.0001,  0.0070, -0.0083,  ..., -0.0057,  0.0060, -0.0125],
        [-0.0032,  0.0086,  0.0218,  ..., -0.0034, -0.0049,  0.0046],
        ...,
        [ 0.0042,  0.0008, -0.0036,  ...,  0.0156, -0.0011,  0.0010],
        [-0.0032, -0.0036, -0.0007,  ...,  0.0078,  0.0155, -0.0070],
        [ 0.0012, -0.0078, -0.0031,  ...,  0.0027,  0.0120,  0.0132]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.3633, -5.4102, -1.2656,  ...,  1.2793, -1.2119, -6.5547]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 01:21:05 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country with stockholm as its capital is known as sweden
The country with dhaka as its capital is known as bangladesh
The country with santiago as its capital is known as chile
The country with paris as its capital is known as france
The country with bangkok as its capital is known as thailand
The country with damascus as its capital is known as syria
The country with ankara as its capital is known as turkey
The country with dublin as its capital is known as
2024-07-29 01:21:05 root INFO     [order_1_approx] starting weight calculation for The country with damascus as its capital is known as syria
The country with stockholm as its capital is known as sweden
The country with dhaka as its capital is known as bangladesh
The country with dublin as its capital is known as ireland
The country with bangkok as its capital is known as thailand
The country with santiago as its capital is known as chile
The country with paris as its capital is known as france
The country with ankara as its capital is known as
2024-07-29 01:21:05 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 01:23:00 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4910, -0.6484, -1.3105,  ...,  0.0515, -0.0344,  0.0457],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.5645, -3.8789, -0.8809,  ..., -0.0962,  1.8916, -3.3047],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 2.2034e-02, -1.5659e-03, -5.1422e-03,  ..., -9.8724e-03,
         -2.4986e-03, -9.4652e-04],
        [-2.3117e-03,  5.8365e-04,  2.8744e-03,  ...,  2.0905e-03,
          4.1275e-03, -8.6746e-03],
        [ 3.3836e-03, -1.5736e-04,  1.1429e-02,  ..., -5.0201e-03,
          5.1003e-03,  6.6948e-03],
        ...,
        [ 8.1329e-03,  3.2043e-03, -6.4087e-03,  ...,  2.2827e-02,
         -4.0359e-03,  9.8991e-04],
        [-7.3471e-03,  5.7220e-04,  1.8692e-04,  ...,  3.0994e-03,
          1.7654e-02,  9.4461e-04],
        [-3.7537e-03, -1.0614e-03, -5.3978e-04,  ...,  1.8539e-03,
          9.2506e-05,  1.2764e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.4082, -3.6758, -0.9585,  ..., -0.1101,  1.9062, -3.2793]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 01:23:01 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country with damascus as its capital is known as syria
The country with stockholm as its capital is known as sweden
The country with dhaka as its capital is known as bangladesh
The country with dublin as its capital is known as ireland
The country with bangkok as its capital is known as thailand
The country with santiago as its capital is known as chile
The country with paris as its capital is known as france
The country with ankara as its capital is known as
2024-07-29 01:23:02 root INFO     [order_1_approx] starting weight calculation for The country with paris as its capital is known as france
The country with damascus as its capital is known as syria
The country with ankara as its capital is known as turkey
The country with dublin as its capital is known as ireland
The country with santiago as its capital is known as chile
The country with stockholm as its capital is known as sweden
The country with bangkok as its capital is known as thailand
The country with dhaka as its capital is known as
2024-07-29 01:23:02 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 01:24:53 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2844, -0.5972, -0.3965,  ...,  0.1456, -0.3931,  0.0754],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.6411, -4.9531, -0.5132,  ..., -1.5938, -0.5317, -5.1641],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0204,  0.0059,  0.0004,  ..., -0.0007,  0.0017, -0.0041],
        [-0.0075,  0.0144, -0.0028,  ..., -0.0001,  0.0040, -0.0018],
        [ 0.0054, -0.0014,  0.0176,  ..., -0.0016,  0.0061,  0.0009],
        ...,
        [ 0.0122,  0.0059, -0.0033,  ...,  0.0316, -0.0014,  0.0013],
        [-0.0050,  0.0048, -0.0126,  ..., -0.0003,  0.0189,  0.0038],
        [-0.0115, -0.0071,  0.0006,  ...,  0.0040,  0.0114,  0.0190]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.5835, -4.7734, -0.7148,  ..., -1.5859, -0.5371, -5.1445]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 01:25:06 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country with paris as its capital is known as france
The country with damascus as its capital is known as syria
The country with ankara as its capital is known as turkey
The country with dublin as its capital is known as ireland
The country with santiago as its capital is known as chile
The country with stockholm as its capital is known as sweden
The country with bangkok as its capital is known as thailand
The country with dhaka as its capital is known as
2024-07-29 01:25:06 root INFO     [order_1_approx] starting weight calculation for The country with santiago as its capital is known as chile
The country with dublin as its capital is known as ireland
The country with paris as its capital is known as france
The country with bangkok as its capital is known as thailand
The country with ankara as its capital is known as turkey
The country with damascus as its capital is known as syria
The country with dhaka as its capital is known as bangladesh
The country with stockholm as its capital is known as
2024-07-29 01:25:06 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 01:26:59 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 1.0635, -0.5854, -0.5649,  ...,  0.0267,  0.4753,  0.1841],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.4824, -6.1797, -2.1758,  ..., -1.1445, -1.6475, -3.3008],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 1.6083e-02,  1.1894e-02,  4.7302e-03,  ...,  5.9471e-03,
         -2.4834e-03,  3.6678e-03],
        [-4.6768e-03, -6.9046e-03,  6.3019e-03,  ...,  4.5776e-05,
         -1.6804e-03, -9.7198e-03],
        [-2.6627e-03, -2.5654e-04,  2.5513e-02,  ..., -7.7744e-03,
          2.2030e-04,  2.2488e-03],
        ...,
        [ 4.2801e-03,  2.2697e-04,  3.8776e-03,  ...,  3.2104e-02,
          1.3100e-02,  1.2360e-03],
        [ 6.0768e-03, -2.6627e-03, -1.6846e-02,  ...,  8.6517e-03,
          1.6251e-02,  3.7251e-03],
        [-1.0956e-02, -5.8060e-03, -1.1909e-02,  ..., -8.2092e-03,
         -1.0767e-03,  1.9623e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.3398, -5.9180, -2.2461,  ..., -0.9902, -1.2441, -3.2910]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 01:27:00 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country with santiago as its capital is known as chile
The country with dublin as its capital is known as ireland
The country with paris as its capital is known as france
The country with bangkok as its capital is known as thailand
The country with ankara as its capital is known as turkey
The country with damascus as its capital is known as syria
The country with dhaka as its capital is known as bangladesh
The country with stockholm as its capital is known as
2024-07-29 01:27:00 root INFO     [order_1_approx] starting weight calculation for The country with damascus as its capital is known as syria
The country with stockholm as its capital is known as sweden
The country with ankara as its capital is known as turkey
The country with bangkok as its capital is known as thailand
The country with dhaka as its capital is known as bangladesh
The country with dublin as its capital is known as ireland
The country with santiago as its capital is known as chile
The country with paris as its capital is known as
2024-07-29 01:27:00 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 01:28:55 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4824, -0.5684, -0.3223,  ...,  0.0632,  0.5410,  0.1885],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.9033, -5.0469,  0.7334,  ..., -1.7646,  0.5991, -2.8594],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0185,  0.0042, -0.0018,  ...,  0.0044, -0.0029,  0.0088],
        [-0.0013,  0.0016, -0.0007,  ..., -0.0121,  0.0045, -0.0034],
        [ 0.0061,  0.0019,  0.0271,  ...,  0.0032, -0.0012, -0.0014],
        ...,
        [ 0.0068,  0.0028,  0.0051,  ...,  0.0213,  0.0059, -0.0049],
        [ 0.0019, -0.0030, -0.0023,  ..., -0.0025,  0.0080,  0.0001],
        [-0.0044,  0.0026, -0.0079,  ...,  0.0033,  0.0097,  0.0191]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.1055, -4.7031,  0.1191,  ..., -1.6445,  0.5342, -2.8203]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 01:28:56 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country with damascus as its capital is known as syria
The country with stockholm as its capital is known as sweden
The country with ankara as its capital is known as turkey
The country with bangkok as its capital is known as thailand
The country with dhaka as its capital is known as bangladesh
The country with dublin as its capital is known as ireland
The country with santiago as its capital is known as chile
The country with paris as its capital is known as
2024-07-29 01:28:57 root INFO     [order_1_approx] starting weight calculation for The country with bangkok as its capital is known as thailand
The country with paris as its capital is known as france
The country with ankara as its capital is known as turkey
The country with damascus as its capital is known as syria
The country with dhaka as its capital is known as bangladesh
The country with stockholm as its capital is known as sweden
The country with dublin as its capital is known as ireland
The country with santiago as its capital is known as
2024-07-29 01:28:57 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 01:30:49 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.5708, -0.2832, -0.3701,  ..., -0.0116, -0.1604, -0.0988],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.8789, -0.9531, -0.1439,  ...,  0.6348, -0.4785, -3.0625],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 1.0864e-02,  6.5002e-03, -8.9264e-03,  ...,  1.5364e-03,
         -1.1223e-02,  8.1558e-03],
        [-6.1874e-03,  6.4850e-03,  8.1940e-03,  ..., -6.4850e-05,
          6.6605e-03, -9.7885e-03],
        [ 9.1171e-03, -2.7637e-03,  2.0477e-02,  ..., -1.3268e-02,
         -1.5182e-02,  3.9673e-03],
        ...,
        [ 1.1482e-02,  1.4236e-02, -8.5831e-03,  ...,  3.3386e-02,
          1.4740e-02, -8.4152e-03],
        [ 1.7576e-03, -1.4275e-02, -1.4366e-02,  ...,  1.7456e-02,
          1.3634e-02, -2.8954e-03],
        [-7.1259e-03, -3.9177e-03, -1.2421e-02,  ...,  1.6312e-02,
          1.5137e-02,  2.1347e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.5352, -0.2383, -0.3193,  ...,  0.2214, -0.3501, -2.6895]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 01:30:50 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country with bangkok as its capital is known as thailand
The country with paris as its capital is known as france
The country with ankara as its capital is known as turkey
The country with damascus as its capital is known as syria
The country with dhaka as its capital is known as bangladesh
The country with stockholm as its capital is known as sweden
The country with dublin as its capital is known as ireland
The country with santiago as its capital is known as
2024-07-29 01:30:50 root INFO     [order_1_approx] starting weight calculation for The country with santiago as its capital is known as chile
The country with dhaka as its capital is known as bangladesh
The country with stockholm as its capital is known as sweden
The country with bangkok as its capital is known as thailand
The country with dublin as its capital is known as ireland
The country with paris as its capital is known as france
The country with ankara as its capital is known as turkey
The country with damascus as its capital is known as
2024-07-29 01:30:50 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 01:32:45 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.6646, -0.3215, -0.3464,  ..., -0.0449,  0.1450, -0.2083],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.5957, -5.7109, -1.1396,  ..., -0.4229,  1.8682, -4.6914],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 1.6418e-02, -2.8014e-05,  1.3456e-03,  ...,  3.7727e-03,
          2.1591e-03, -2.7809e-03],
        [-3.5477e-03,  6.2370e-03,  8.7595e-04,  ..., -1.5717e-03,
          6.0120e-03, -5.1270e-03],
        [-3.9244e-04,  2.4652e-04,  1.3191e-02,  ..., -5.0812e-03,
         -2.9564e-05,  4.2534e-04],
        ...,
        [-2.3117e-03,  4.9858e-03, -3.0098e-03,  ...,  1.6357e-02,
         -1.4210e-04,  2.7847e-03],
        [ 2.0905e-03, -2.3499e-03,  2.2831e-03,  ...,  2.1458e-03,
          1.0063e-02, -1.7319e-03],
        [-3.3340e-03, -5.5161e-03, -5.2109e-03,  ...,  1.0166e-03,
          5.6219e-04,  1.4839e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.6094, -5.6445, -1.1846,  ..., -0.4021,  1.8701, -4.7344]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 01:32:46 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country with santiago as its capital is known as chile
The country with dhaka as its capital is known as bangladesh
The country with stockholm as its capital is known as sweden
The country with bangkok as its capital is known as thailand
The country with dublin as its capital is known as ireland
The country with paris as its capital is known as france
The country with ankara as its capital is known as turkey
The country with damascus as its capital is known as
2024-07-29 01:32:46 root INFO     total operator prediction time: 927.2280185222626 seconds
2024-07-29 01:32:46 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on name - occupation
2024-07-29 01:32:46 root INFO     building operator name - occupation
2024-07-29 01:32:46 root INFO     [order_1_approx] starting weight calculation for caesar was known for their work as a  emperor
hume was known for their work as a  philosopher
locke was known for their work as a  philosopher
beethoven was known for their work as a  composer
edison was known for their work as a  inventor
schwarzenegger was known for their work as a  actor
picasso was known for their work as a  painter
raphael was known for their work as a 
2024-07-29 01:32:47 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 01:34:39 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.6245, -0.3855, -0.0120,  ..., -0.5054, -0.5532, -0.0702],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.9492, -6.7812,  2.7930,  ..., -6.8828,  0.2096, -2.3008],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0502,  0.0024, -0.0044,  ...,  0.0049, -0.0016,  0.0010],
        [ 0.0026,  0.0457, -0.0068,  ...,  0.0012,  0.0111, -0.0023],
        [ 0.0013, -0.0061,  0.0537,  ..., -0.0027, -0.0040,  0.0087],
        ...,
        [ 0.0134,  0.0079, -0.0101,  ...,  0.0636,  0.0112,  0.0027],
        [-0.0016, -0.0067,  0.0101,  ...,  0.0005,  0.0365,  0.0058],
        [-0.0004,  0.0158, -0.0147,  ..., -0.0066,  0.0026,  0.0534]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.9453, -6.6328,  2.7227,  ..., -6.7930,  0.1531, -2.1172]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 01:34:40 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for caesar was known for their work as a  emperor
hume was known for their work as a  philosopher
locke was known for their work as a  philosopher
beethoven was known for their work as a  composer
edison was known for their work as a  inventor
schwarzenegger was known for their work as a  actor
picasso was known for their work as a  painter
raphael was known for their work as a 
2024-07-29 01:34:41 root INFO     [order_1_approx] starting weight calculation for schwarzenegger was known for their work as a  actor
hume was known for their work as a  philosopher
caesar was known for their work as a  emperor
beethoven was known for their work as a  composer
picasso was known for their work as a  painter
locke was known for their work as a  philosopher
raphael was known for their work as a  painter
edison was known for their work as a 
2024-07-29 01:34:41 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 01:36:35 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0082, -0.0346, -0.0751,  ..., -0.7520,  0.3311,  0.0564],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.5273, -3.6953,  1.3545,  ..., -1.3447,  1.2822, -1.6299],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0354, -0.0009, -0.0020,  ...,  0.0010, -0.0045, -0.0034],
        [ 0.0023,  0.0314, -0.0004,  ..., -0.0010,  0.0023, -0.0037],
        [ 0.0022,  0.0011,  0.0302,  ...,  0.0010,  0.0003,  0.0072],
        ...,
        [ 0.0102,  0.0038, -0.0108,  ...,  0.0392, -0.0004, -0.0013],
        [-0.0020,  0.0013,  0.0009,  ...,  0.0042,  0.0254, -0.0044],
        [-0.0042, -0.0005, -0.0009,  ..., -0.0034,  0.0008,  0.0346]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.5215, -3.7949,  1.4297,  ..., -1.4756,  1.1982, -1.4805]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 01:36:36 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for schwarzenegger was known for their work as a  actor
hume was known for their work as a  philosopher
caesar was known for their work as a  emperor
beethoven was known for their work as a  composer
picasso was known for their work as a  painter
locke was known for their work as a  philosopher
raphael was known for their work as a  painter
edison was known for their work as a 
2024-07-29 01:36:36 root INFO     [order_1_approx] starting weight calculation for hume was known for their work as a  philosopher
picasso was known for their work as a  painter
raphael was known for their work as a  painter
locke was known for their work as a  philosopher
schwarzenegger was known for their work as a  actor
edison was known for their work as a  inventor
caesar was known for their work as a  emperor
beethoven was known for their work as a 
2024-07-29 01:36:37 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 01:38:30 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0827, -0.6069,  0.0721,  ..., -0.6084, -0.2700,  0.1681],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.4570, -6.6484,  1.2383,  ..., -3.0645,  1.6973, -1.7656],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 1.7319e-02, -1.3371e-03,  3.3703e-03,  ...,  1.8892e-03,
         -1.0519e-03,  8.9264e-04],
        [-3.8433e-04,  1.7517e-02, -3.4761e-04,  ...,  7.3624e-04,
          4.0665e-03, -5.0259e-04],
        [ 2.7409e-03, -1.3828e-05,  1.8707e-02,  ..., -3.7060e-03,
          2.8992e-03,  3.4618e-03],
        ...,
        [ 7.9041e-03,  4.4403e-03, -3.8300e-03,  ...,  2.3102e-02,
          3.5324e-03,  3.6049e-04],
        [ 3.5248e-03,  2.2774e-03, -1.1234e-03,  ..., -7.2718e-05,
          1.5915e-02, -1.9255e-03],
        [-3.2082e-03,  2.1553e-03, -2.1706e-03,  ...,  1.8387e-03,
         -1.4696e-03,  2.0294e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.4160, -6.6016,  1.1914,  ..., -3.0059,  1.6699, -1.7656]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 01:38:31 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for hume was known for their work as a  philosopher
picasso was known for their work as a  painter
raphael was known for their work as a  painter
locke was known for their work as a  philosopher
schwarzenegger was known for their work as a  actor
edison was known for their work as a  inventor
caesar was known for their work as a  emperor
beethoven was known for their work as a 
2024-07-29 01:38:31 root INFO     [order_1_approx] starting weight calculation for hume was known for their work as a  philosopher
edison was known for their work as a  inventor
schwarzenegger was known for their work as a  actor
picasso was known for their work as a  painter
locke was known for their work as a  philosopher
beethoven was known for their work as a  composer
raphael was known for their work as a  painter
caesar was known for their work as a 
2024-07-29 01:38:32 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 01:40:26 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0692, -0.5029, -0.3569,  ..., -0.0254, -0.2117,  0.4590],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.7090, -6.6562,  1.8945,  ..., -1.9785,  1.3525, -0.8369],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0485, -0.0015, -0.0024,  ..., -0.0048, -0.0033, -0.0022],
        [-0.0016,  0.0333,  0.0001,  ..., -0.0070,  0.0009, -0.0020],
        [ 0.0052, -0.0095,  0.0353,  ..., -0.0013,  0.0026,  0.0112],
        ...,
        [ 0.0169,  0.0080, -0.0096,  ...,  0.0585, -0.0005, -0.0072],
        [ 0.0016,  0.0046,  0.0046,  ...,  0.0015,  0.0366, -0.0020],
        [-0.0034,  0.0086, -0.0089,  ...,  0.0036,  0.0020,  0.0436]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.5371, -6.4258,  1.8447,  ..., -2.1543,  1.3516, -0.9849]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 01:40:27 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for hume was known for their work as a  philosopher
edison was known for their work as a  inventor
schwarzenegger was known for their work as a  actor
picasso was known for their work as a  painter
locke was known for their work as a  philosopher
beethoven was known for their work as a  composer
raphael was known for their work as a  painter
caesar was known for their work as a 
2024-07-29 01:40:27 root INFO     [order_1_approx] starting weight calculation for raphael was known for their work as a  painter
locke was known for their work as a  philosopher
hume was known for their work as a  philosopher
caesar was known for their work as a  emperor
edison was known for their work as a  inventor
picasso was known for their work as a  painter
beethoven was known for their work as a  composer
schwarzenegger was known for their work as a 
2024-07-29 01:40:27 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 01:42:22 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4907, -0.1763, -0.1804,  ..., -0.3267, -0.7153,  0.1548],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 6.2734, -3.6133,  4.5703,  ..., -3.5059,  1.8516, -1.7852],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 3.5248e-02, -5.6839e-03, -1.0376e-03,  ...,  2.6608e-04,
         -9.6893e-04, -2.9564e-04],
        [ 3.3855e-03,  3.4332e-02, -2.0123e-04,  ...,  1.9588e-03,
         -1.6356e-03, -2.6436e-03],
        [ 9.2163e-03, -3.2349e-03,  2.5513e-02,  ..., -4.6539e-03,
          4.8637e-05,  8.4076e-03],
        ...,
        [ 1.2115e-02, -1.5078e-03, -6.7806e-04,  ...,  4.2542e-02,
          1.9073e-04,  2.0485e-03],
        [ 2.1191e-03,  3.0956e-03,  1.3065e-03,  ..., -8.8596e-04,
          2.3621e-02,  4.8065e-04],
        [-2.8591e-03,  4.2877e-03, -2.0370e-03,  ..., -2.2049e-03,
         -5.1041e-03,  2.7054e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 6.1484, -3.6738,  4.5078,  ..., -3.4238,  1.8555, -1.6846]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 01:42:23 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for raphael was known for their work as a  painter
locke was known for their work as a  philosopher
hume was known for their work as a  philosopher
caesar was known for their work as a  emperor
edison was known for their work as a  inventor
picasso was known for their work as a  painter
beethoven was known for their work as a  composer
schwarzenegger was known for their work as a 
2024-07-29 01:42:24 root INFO     [order_1_approx] starting weight calculation for schwarzenegger was known for their work as a  actor
hume was known for their work as a  philosopher
caesar was known for their work as a  emperor
edison was known for their work as a  inventor
locke was known for their work as a  philosopher
raphael was known for their work as a  painter
beethoven was known for their work as a  composer
picasso was known for their work as a 
2024-07-29 01:42:24 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 01:44:14 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.3547, -1.2090,  0.0180,  ..., -0.0227,  0.0082, -0.3936],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.6172, -6.4180,  1.0674,  ..., -3.2715, -0.4141, -2.0098],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0192, -0.0020, -0.0002,  ...,  0.0009, -0.0013, -0.0004],
        [ 0.0004,  0.0178, -0.0006,  ..., -0.0006,  0.0016, -0.0021],
        [ 0.0052,  0.0010,  0.0252,  ..., -0.0061,  0.0045,  0.0064],
        ...,
        [ 0.0012,  0.0051, -0.0040,  ...,  0.0274, -0.0011, -0.0005],
        [-0.0012,  0.0008,  0.0032,  ...,  0.0016,  0.0170, -0.0014],
        [-0.0015, -0.0014, -0.0005,  ..., -0.0036,  0.0012,  0.0187]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.6211, -6.3516,  1.2227,  ..., -3.3359, -0.3347, -1.8848]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 01:44:15 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for schwarzenegger was known for their work as a  actor
hume was known for their work as a  philosopher
caesar was known for their work as a  emperor
edison was known for their work as a  inventor
locke was known for their work as a  philosopher
raphael was known for their work as a  painter
beethoven was known for their work as a  composer
picasso was known for their work as a 
2024-07-29 01:44:15 root INFO     [order_1_approx] starting weight calculation for hume was known for their work as a  philosopher
raphael was known for their work as a  painter
beethoven was known for their work as a  composer
caesar was known for their work as a  emperor
picasso was known for their work as a  painter
schwarzenegger was known for their work as a  actor
edison was known for their work as a  inventor
locke was known for their work as a 
2024-07-29 01:44:16 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 01:46:11 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2871, -0.2722, -0.5322,  ..., -0.2358,  0.0332, -0.0643],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.9658, -4.2617,  1.7568,  ..., -6.9414,  1.3164, -2.6367],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0638,  0.0041,  0.0075,  ...,  0.0014, -0.0046, -0.0053],
        [-0.0077,  0.0608, -0.0022,  ...,  0.0089, -0.0024, -0.0002],
        [ 0.0056, -0.0017,  0.0470,  ..., -0.0039,  0.0095,  0.0138],
        ...,
        [ 0.0156,  0.0055, -0.0024,  ...,  0.0646, -0.0001, -0.0002],
        [ 0.0111,  0.0129, -0.0061,  ...,  0.0185,  0.0330,  0.0029],
        [-0.0110,  0.0067, -0.0058,  ..., -0.0120, -0.0046,  0.0589]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.0156, -4.4375,  1.6445,  ..., -6.9180,  1.3301, -2.4238]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 01:46:12 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for hume was known for their work as a  philosopher
raphael was known for their work as a  painter
beethoven was known for their work as a  composer
caesar was known for their work as a  emperor
picasso was known for their work as a  painter
schwarzenegger was known for their work as a  actor
edison was known for their work as a  inventor
locke was known for their work as a 
2024-07-29 01:46:12 root INFO     [order_1_approx] starting weight calculation for locke was known for their work as a  philosopher
edison was known for their work as a  inventor
picasso was known for their work as a  painter
raphael was known for their work as a  painter
schwarzenegger was known for their work as a  actor
caesar was known for their work as a  emperor
beethoven was known for their work as a  composer
hume was known for their work as a 
2024-07-29 01:46:12 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 01:48:03 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1420,  0.1056,  0.2625,  ..., -0.2998,  0.3940,  0.4917],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.0527, -4.0352,  2.2656,  ..., -6.3047,  1.0869, -2.2227],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 6.0669e-02,  4.2200e-05, -5.7297e-03,  ...,  9.0485e-03,
         -1.3084e-03, -1.1749e-03],
        [-4.7379e-03,  5.7129e-02,  4.1199e-03,  ..., -4.7264e-03,
          1.1635e-04,  1.0414e-02],
        [ 5.8136e-03, -5.7793e-03,  4.8584e-02,  ..., -5.6152e-03,
          8.6823e-03, -3.6812e-04],
        ...,
        [ 8.4381e-03,  9.7046e-03,  1.1864e-03,  ...,  6.8481e-02,
          2.4529e-03,  5.6419e-03],
        [ 8.1482e-03,  1.4557e-02,  7.2212e-03,  ...,  1.5778e-02,
          4.8553e-02,  2.9430e-03],
        [-4.6959e-03,  5.9662e-03, -9.9640e-03,  ..., -3.7613e-03,
         -1.1368e-02,  5.6763e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.1572, -4.3477,  2.2656,  ..., -6.2812,  0.7441, -2.0137]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 01:48:04 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for locke was known for their work as a  philosopher
edison was known for their work as a  inventor
picasso was known for their work as a  painter
raphael was known for their work as a  painter
schwarzenegger was known for their work as a  actor
caesar was known for their work as a  emperor
beethoven was known for their work as a  composer
hume was known for their work as a 
2024-07-29 01:48:04 root INFO     total operator prediction time: 917.2562737464905 seconds
2024-07-29 01:48:04 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on male - female
2024-07-29 01:48:04 root INFO     building operator male - female
2024-07-29 01:48:04 root INFO     [order_1_approx] starting weight calculation for A female fisherman is known as a fisherwoman
A female hero is known as a heroine
A female murderer is known as a murderess
A female stepfather is known as a stepmother
A female boy is known as a girl
A female brother is known as a sister
A female sculptor is known as a sculptress
A female headmaster is known as a
2024-07-29 01:48:04 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 01:49:56 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 1.0977,  0.4155, -0.3567,  ..., -0.1409, -1.3184, -0.3003],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 5.3398, -4.1367, -0.7925,  ..., -0.7256, -5.2656, -1.1523],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0485,  0.0030,  0.0089,  ...,  0.0031, -0.0005,  0.0033],
        [ 0.0043,  0.0334, -0.0079,  ...,  0.0054,  0.0120, -0.0095],
        [-0.0141, -0.0014,  0.0481,  ...,  0.0002,  0.0105,  0.0097],
        ...,
        [-0.0015, -0.0050,  0.0034,  ...,  0.0579,  0.0013, -0.0082],
        [-0.0023,  0.0162,  0.0018,  ...,  0.0055,  0.0416, -0.0045],
        [ 0.0139,  0.0043, -0.0019,  ..., -0.0048, -0.0150,  0.0381]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 5.2891, -3.9941, -0.5552,  ..., -0.6372, -5.5000, -0.9756]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 01:50:11 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A female fisherman is known as a fisherwoman
A female hero is known as a heroine
A female murderer is known as a murderess
A female stepfather is known as a stepmother
A female boy is known as a girl
A female brother is known as a sister
A female sculptor is known as a sculptress
A female headmaster is known as a
2024-07-29 01:50:16 root INFO     [order_1_approx] starting weight calculation for A female boy is known as a girl
A female brother is known as a sister
A female murderer is known as a murderess
A female stepfather is known as a stepmother
A female fisherman is known as a fisherwoman
A female hero is known as a heroine
A female headmaster is known as a headmistress
A female sculptor is known as a
2024-07-29 01:50:16 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 01:52:11 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 1.0615, -0.7129, -0.2620,  ..., -1.1367, -0.8569,  0.1346],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.0449, -5.3672, -1.1602,  ...,  0.1914, -2.6836, -0.4443],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0205, -0.0038,  0.0039,  ...,  0.0016, -0.0022, -0.0003],
        [ 0.0046,  0.0165, -0.0016,  ...,  0.0008,  0.0040, -0.0011],
        [ 0.0005, -0.0006,  0.0197,  ...,  0.0023, -0.0010, -0.0015],
        ...,
        [ 0.0011,  0.0030, -0.0010,  ...,  0.0229, -0.0002, -0.0006],
        [ 0.0035,  0.0071,  0.0028,  ..., -0.0034,  0.0168,  0.0003],
        [-0.0003, -0.0009, -0.0004,  ..., -0.0074, -0.0025,  0.0186]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.0039, -5.2266, -1.1338,  ...,  0.2949, -2.6992, -0.3716]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 01:52:12 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A female boy is known as a girl
A female brother is known as a sister
A female murderer is known as a murderess
A female stepfather is known as a stepmother
A female fisherman is known as a fisherwoman
A female hero is known as a heroine
A female headmaster is known as a headmistress
A female sculptor is known as a
2024-07-29 01:52:12 root INFO     [order_1_approx] starting weight calculation for A female boy is known as a girl
A female sculptor is known as a sculptress
A female stepfather is known as a stepmother
A female fisherman is known as a fisherwoman
A female brother is known as a sister
A female headmaster is known as a headmistress
A female hero is known as a heroine
A female murderer is known as a
2024-07-29 01:52:12 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 01:54:07 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 1.0801,  0.1294, -0.5283,  ..., -0.7051, -1.1562, -0.5576],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.3809, -2.6328, -0.6035,  ..., -1.0703, -3.4512,  0.5146],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 2.0950e-02, -3.6983e-03,  9.8877e-03,  ...,  1.8911e-03,
          5.5218e-04,  9.2506e-04],
        [-2.4452e-03,  2.4185e-02,  2.0266e-04,  ...,  2.7542e-03,
          3.8605e-03, -2.0313e-03],
        [ 5.4665e-03,  7.7248e-04,  2.0828e-02,  ..., -4.6234e-03,
         -2.8553e-03, -1.8158e-03],
        ...,
        [-2.3232e-03,  1.1139e-03, -1.6963e-04,  ...,  2.9419e-02,
         -6.1750e-04, -1.7424e-03],
        [ 2.1248e-03,  6.2790e-03,  4.2343e-04,  ..., -8.5354e-05,
          2.6642e-02, -4.0512e-03],
        [-8.2135e-05, -1.3332e-03,  4.8790e-03,  ..., -6.6071e-03,
         -5.2834e-03,  2.3743e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.4180, -2.6836, -0.5161,  ..., -0.9009, -3.4395,  0.6831]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 01:54:08 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A female boy is known as a girl
A female sculptor is known as a sculptress
A female stepfather is known as a stepmother
A female fisherman is known as a fisherwoman
A female brother is known as a sister
A female headmaster is known as a headmistress
A female hero is known as a heroine
A female murderer is known as a
2024-07-29 01:54:08 root INFO     [order_1_approx] starting weight calculation for A female sculptor is known as a sculptress
A female boy is known as a girl
A female stepfather is known as a stepmother
A female murderer is known as a murderess
A female fisherman is known as a fisherwoman
A female headmaster is known as a headmistress
A female brother is known as a sister
A female hero is known as a
2024-07-29 01:54:08 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 01:56:00 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.7588,  0.6221,  0.1619,  ..., -0.3423, -0.8760,  0.0797],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.3711, -5.8906, -1.5742,  ..., -1.8604, -3.3340,  1.0059],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0587, -0.0071,  0.0139,  ...,  0.0092, -0.0041, -0.0096],
        [ 0.0077,  0.0235, -0.0007,  ...,  0.0022,  0.0158, -0.0048],
        [ 0.0064, -0.0094,  0.0479,  ..., -0.0098, -0.0111, -0.0066],
        ...,
        [-0.0004,  0.0053,  0.0024,  ...,  0.0580, -0.0084, -0.0100],
        [ 0.0059,  0.0115,  0.0134,  ...,  0.0014,  0.0420, -0.0007],
        [-0.0051, -0.0006, -0.0065,  ...,  0.0015, -0.0058,  0.0479]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.2559, -5.7109, -1.6221,  ..., -1.4746, -3.7012,  0.9536]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 01:56:01 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A female sculptor is known as a sculptress
A female boy is known as a girl
A female stepfather is known as a stepmother
A female murderer is known as a murderess
A female fisherman is known as a fisherwoman
A female headmaster is known as a headmistress
A female brother is known as a sister
A female hero is known as a
2024-07-29 01:56:01 root INFO     [order_1_approx] starting weight calculation for A female stepfather is known as a stepmother
A female fisherman is known as a fisherwoman
A female sculptor is known as a sculptress
A female headmaster is known as a headmistress
A female murderer is known as a murderess
A female brother is known as a sister
A female hero is known as a heroine
A female boy is known as a
2024-07-29 01:56:01 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 01:57:57 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3914,  0.0316, -0.1162,  ..., -0.3433, -0.7651,  0.4121],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.0859, -0.8379, -2.8555,  ...,  4.0352, -1.2148,  1.1221],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0328, -0.0092,  0.0042,  ..., -0.0017,  0.0023,  0.0142],
        [ 0.0117,  0.0251,  0.0050,  ...,  0.0059,  0.0098, -0.0056],
        [ 0.0062, -0.0015,  0.0408,  ..., -0.0091, -0.0098, -0.0089],
        ...,
        [-0.0010,  0.0019,  0.0033,  ...,  0.0491, -0.0079, -0.0052],
        [ 0.0044,  0.0028,  0.0246,  ..., -0.0058,  0.0175, -0.0121],
        [ 0.0070, -0.0033, -0.0063,  ..., -0.0167,  0.0010,  0.0410]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.0664, -1.3242, -2.7109,  ...,  3.7910, -1.5508,  1.2441]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 01:57:58 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A female stepfather is known as a stepmother
A female fisherman is known as a fisherwoman
A female sculptor is known as a sculptress
A female headmaster is known as a headmistress
A female murderer is known as a murderess
A female brother is known as a sister
A female hero is known as a heroine
A female boy is known as a
2024-07-29 01:57:58 root INFO     [order_1_approx] starting weight calculation for A female hero is known as a heroine
A female murderer is known as a murderess
A female boy is known as a girl
A female headmaster is known as a headmistress
A female sculptor is known as a sculptress
A female stepfather is known as a stepmother
A female fisherman is known as a fisherwoman
A female brother is known as a
2024-07-29 01:57:58 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 01:59:51 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4414,  0.1394, -0.1940,  ..., -0.3047, -0.1660, -0.0698],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.6797, -2.4746, -2.5195,  ...,  0.9907, -0.7695, -0.6499],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0453, -0.0004,  0.0209,  ...,  0.0028,  0.0077,  0.0254],
        [-0.0012,  0.0155,  0.0030,  ...,  0.0134,  0.0073, -0.0091],
        [ 0.0007, -0.0119,  0.0463,  ..., -0.0085, -0.0044, -0.0065],
        ...,
        [-0.0014,  0.0085, -0.0090,  ...,  0.0465,  0.0057, -0.0064],
        [ 0.0131,  0.0077,  0.0121,  ...,  0.0067,  0.0265, -0.0119],
        [ 0.0151,  0.0012, -0.0006,  ...,  0.0058,  0.0086,  0.0439]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.4961, -2.5938, -2.5938,  ...,  1.1387, -0.9712, -0.6230]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 01:59:52 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A female hero is known as a heroine
A female murderer is known as a murderess
A female boy is known as a girl
A female headmaster is known as a headmistress
A female sculptor is known as a sculptress
A female stepfather is known as a stepmother
A female fisherman is known as a fisherwoman
A female brother is known as a
2024-07-29 01:59:52 root INFO     [order_1_approx] starting weight calculation for A female sculptor is known as a sculptress
A female brother is known as a sister
A female fisherman is known as a fisherwoman
A female hero is known as a heroine
A female boy is known as a girl
A female headmaster is known as a headmistress
A female murderer is known as a murderess
A female stepfather is known as a
2024-07-29 01:59:53 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 02:01:44 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.6636,  0.4177,  0.0669,  ..., -0.0458, -0.3608,  0.0310],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.5586,  0.2666, -2.0957,  ...,  1.7012, -2.5762, -0.5889],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 3.9124e-02, -1.5526e-03,  3.8071e-03,  ...,  1.1238e-02,
          1.1147e-02,  1.5915e-02],
        [ 2.8000e-03,  2.4109e-02,  3.8643e-03,  ..., -1.3885e-03,
          5.0507e-03, -1.0300e-02],
        [-7.3624e-04,  2.2907e-03,  3.1799e-02,  ..., -3.0746e-03,
         -1.9302e-03, -1.7548e-03],
        ...,
        [-4.7455e-03, -9.4771e-05, -1.0597e-02,  ...,  4.1870e-02,
          3.8643e-03, -7.7705e-03],
        [ 1.3828e-03,  9.9945e-03, -2.6283e-03,  ...,  9.9182e-03,
          4.1595e-02,  8.5640e-04],
        [ 1.0757e-03, -5.2032e-03, -6.6986e-03,  ..., -4.4289e-03,
         -5.1117e-03,  3.4973e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.4258,  0.3701, -2.1855,  ...,  1.8066, -2.6504, -0.4956]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 02:01:45 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A female sculptor is known as a sculptress
A female brother is known as a sister
A female fisherman is known as a fisherwoman
A female hero is known as a heroine
A female boy is known as a girl
A female headmaster is known as a headmistress
A female murderer is known as a murderess
A female stepfather is known as a
2024-07-29 02:01:45 root INFO     [order_1_approx] starting weight calculation for A female stepfather is known as a stepmother
A female hero is known as a heroine
A female murderer is known as a murderess
A female sculptor is known as a sculptress
A female headmaster is known as a headmistress
A female brother is known as a sister
A female boy is known as a girl
A female fisherman is known as a
2024-07-29 02:01:45 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 02:03:40 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 1.1592, -0.1614, -0.6816,  ..., -1.2109, -0.8491,  0.2312],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.7383, -3.1074, -0.6924,  ...,  0.1270, -4.9766,  0.2764],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 3.1860e-02, -1.0941e-02,  4.8409e-03,  ..., -6.1035e-03,
         -5.7030e-04, -3.9062e-03],
        [ 5.9891e-03,  3.3569e-02, -1.3866e-03,  ...,  9.2697e-04,
          1.3504e-02, -4.3869e-04],
        [ 3.1109e-03, -8.1635e-03,  2.3590e-02,  ..., -9.5367e-05,
         -1.2989e-03,  0.0000e+00],
        ...,
        [-3.1166e-03,  4.9286e-03,  3.4332e-05,  ...,  2.3666e-02,
          1.9073e-06,  4.3793e-03],
        [ 1.7767e-03,  1.7288e-02,  4.4022e-03,  ..., -4.3488e-04,
          2.0569e-02, -1.6098e-03],
        [-1.1196e-03, -2.1019e-03,  3.4389e-03,  ..., -6.0310e-03,
         -4.2038e-03,  2.1362e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.6875, -3.0645, -0.6167,  ...,  0.2063, -4.7656,  0.4004]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 02:03:41 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A female stepfather is known as a stepmother
A female hero is known as a heroine
A female murderer is known as a murderess
A female sculptor is known as a sculptress
A female headmaster is known as a headmistress
A female brother is known as a sister
A female boy is known as a girl
A female fisherman is known as a
2024-07-29 02:03:41 root INFO     total operator prediction time: 937.1519548892975 seconds
2024-07-29 02:03:41 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on animal - shelter
2024-07-29 02:03:41 root INFO     building operator animal - shelter
2024-07-29 02:03:41 root INFO     [order_1_approx] starting weight calculation for The place raven lives in is called nest
The place whale lives in is called sea
The place cattle lives in is called barn
The place baboon lives in is called grove
The place seal lives in is called den
The place goldfish lives in is called pond
The place rat lives in is called nest
The place spider lives in is called
2024-07-29 02:03:41 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 02:05:38 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0621,  0.1643,  0.0535,  ...,  0.4644,  0.8940,  0.4556],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.5195, -4.6016,  2.4512,  ..., -0.5947, -0.8394, -2.2227],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 4.6478e-02, -9.2239e-03, -2.1381e-03,  ..., -1.1864e-03,
          2.9602e-03, -7.1869e-03],
        [-3.2959e-03,  2.7985e-02, -6.1646e-03,  ...,  1.2909e-02,
          3.9291e-04, -1.3763e-02],
        [ 1.4105e-03,  9.8343e-03,  2.4475e-02,  ...,  1.0033e-02,
         -1.0246e-02, -1.6947e-03],
        ...,
        [ 8.2550e-03,  4.9591e-03,  5.3787e-03,  ...,  4.6173e-02,
         -3.1586e-03, -5.7449e-03],
        [ 2.9716e-03, -4.4060e-03, -2.2888e-05,  ..., -1.6785e-04,
          3.0289e-02, -4.8523e-03],
        [-1.5701e-02, -1.8120e-05,  7.0286e-04,  ..., -6.8970e-03,
         -1.0710e-03,  3.8177e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.6333, -4.7070,  2.2480,  ..., -0.7344, -0.7461, -2.3145]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 02:05:38 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The place raven lives in is called nest
The place whale lives in is called sea
The place cattle lives in is called barn
The place baboon lives in is called grove
The place seal lives in is called den
The place goldfish lives in is called pond
The place rat lives in is called nest
The place spider lives in is called
2024-07-29 02:05:39 root INFO     [order_1_approx] starting weight calculation for The place goldfish lives in is called pond
The place cattle lives in is called barn
The place spider lives in is called web
The place rat lives in is called nest
The place seal lives in is called den
The place whale lives in is called sea
The place baboon lives in is called grove
The place raven lives in is called
2024-07-29 02:05:39 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 02:07:34 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4844, -1.2090,  0.3694,  ...,  0.1840,  0.0830,  0.0090],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.7930, -6.1797,  0.4961,  ..., -0.1104,  0.4497, -1.5645],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0443, -0.0039, -0.0090,  ...,  0.0049,  0.0035, -0.0045],
        [-0.0078,  0.0315, -0.0136,  ...,  0.0226,  0.0011, -0.0191],
        [-0.0067, -0.0127,  0.0485,  ...,  0.0095, -0.0058, -0.0004],
        ...,
        [ 0.0057,  0.0048,  0.0018,  ...,  0.0515, -0.0026, -0.0019],
        [ 0.0002,  0.0002, -0.0024,  ...,  0.0132,  0.0315, -0.0070],
        [-0.0124,  0.0027, -0.0024,  ..., -0.0198,  0.0010,  0.0427]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.6406, -5.9375,  0.3281,  ..., -0.3730, -0.4131, -1.6602]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 02:07:35 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The place goldfish lives in is called pond
The place cattle lives in is called barn
The place spider lives in is called web
The place rat lives in is called nest
The place seal lives in is called den
The place whale lives in is called sea
The place baboon lives in is called grove
The place raven lives in is called
2024-07-29 02:07:35 root INFO     [order_1_approx] starting weight calculation for The place whale lives in is called sea
The place spider lives in is called web
The place goldfish lives in is called pond
The place seal lives in is called den
The place raven lives in is called nest
The place cattle lives in is called barn
The place rat lives in is called nest
The place baboon lives in is called
2024-07-29 02:07:35 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 02:09:30 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.6787, -0.9502,  0.6143,  ...,  0.4961, -1.1680,  0.3535],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 5.5391, -5.2578,  0.4043,  ..., -0.5527, -1.7539, -0.3428],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0450, -0.0013, -0.0181,  ...,  0.0158,  0.0136, -0.0036],
        [-0.0173,  0.0429, -0.0117,  ...,  0.0061,  0.0021, -0.0171],
        [-0.0063,  0.0043,  0.0450,  ...,  0.0130, -0.0085, -0.0082],
        ...,
        [ 0.0168,  0.0061, -0.0065,  ...,  0.0621, -0.0096,  0.0061],
        [ 0.0037,  0.0065,  0.0013,  ...,  0.0121,  0.0311,  0.0048],
        [-0.0040,  0.0129,  0.0059,  ..., -0.0199,  0.0182,  0.0424]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 5.4531, -5.3438,  0.2074,  ..., -0.5059, -1.8252, -0.3438]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 02:09:30 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The place whale lives in is called sea
The place spider lives in is called web
The place goldfish lives in is called pond
The place seal lives in is called den
The place raven lives in is called nest
The place cattle lives in is called barn
The place rat lives in is called nest
The place baboon lives in is called
2024-07-29 02:09:31 root INFO     [order_1_approx] starting weight calculation for The place spider lives in is called web
The place seal lives in is called den
The place cattle lives in is called barn
The place raven lives in is called nest
The place rat lives in is called nest
The place baboon lives in is called grove
The place whale lives in is called sea
The place goldfish lives in is called
2024-07-29 02:09:31 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 02:11:27 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1775, -0.4045, -0.0553,  ...,  0.1063, -0.5781,  0.5000],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.2314, -4.0547, -0.4512,  ..., -3.7773,  0.6113, -1.2090],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 4.5013e-02, -9.5291e-03,  1.1551e-02,  ...,  1.1444e-03,
         -2.2030e-03,  8.7585e-03],
        [ 1.3895e-03,  4.1626e-02, -2.2003e-02,  ..., -6.2637e-03,
          8.6517e-03, -4.3411e-03],
        [ 2.0485e-03, -7.8201e-05,  4.5532e-02,  ..., -2.4986e-04,
         -1.4481e-02,  3.9673e-04],
        ...,
        [-6.1760e-03, -7.3891e-03, -1.0674e-02,  ...,  3.6774e-02,
          1.8759e-03, -6.9046e-03],
        [ 6.8626e-03, -3.9673e-03,  1.1421e-02,  ...,  7.7133e-03,
          3.9978e-02, -1.0452e-02],
        [-5.4550e-03, -5.6496e-03,  7.6294e-06,  ..., -3.7003e-03,
         -6.9618e-04,  5.0049e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.3306, -4.0469, -0.7285,  ..., -3.7188,  0.4688, -1.5068]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 02:11:28 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The place spider lives in is called web
The place seal lives in is called den
The place cattle lives in is called barn
The place raven lives in is called nest
The place rat lives in is called nest
The place baboon lives in is called grove
The place whale lives in is called sea
The place goldfish lives in is called
2024-07-29 02:11:28 root INFO     [order_1_approx] starting weight calculation for The place rat lives in is called nest
The place cattle lives in is called barn
The place raven lives in is called nest
The place spider lives in is called web
The place seal lives in is called den
The place baboon lives in is called grove
The place goldfish lives in is called pond
The place whale lives in is called
2024-07-29 02:11:28 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 02:13:23 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4324, -0.7036, -0.3369,  ..., -0.2330,  0.1638,  0.0165],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.7598e+00, -4.4609e+00, -3.7695e-01,  ..., -2.3457e+00,
        -1.4375e+00, -3.9062e-03], device='cuda:1', dtype=torch.float16,
       grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0207,  0.0045, -0.0001,  ...,  0.0051, -0.0074, -0.0071],
        [-0.0044,  0.0312, -0.0100,  ...,  0.0047,  0.0009, -0.0040],
        [-0.0016,  0.0137,  0.0300,  ...,  0.0012, -0.0086,  0.0016],
        ...,
        [ 0.0047, -0.0025,  0.0045,  ...,  0.0360, -0.0039, -0.0073],
        [-0.0048, -0.0013,  0.0072,  ...,  0.0016,  0.0191, -0.0054],
        [-0.0199, -0.0127,  0.0043,  ..., -0.0007,  0.0003,  0.0226]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.5811, -4.7969, -0.7998,  ..., -2.5566, -1.4736, -0.3264]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 02:13:24 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The place rat lives in is called nest
The place cattle lives in is called barn
The place raven lives in is called nest
The place spider lives in is called web
The place seal lives in is called den
The place baboon lives in is called grove
The place goldfish lives in is called pond
The place whale lives in is called
2024-07-29 02:13:24 root INFO     [order_1_approx] starting weight calculation for The place raven lives in is called nest
The place baboon lives in is called grove
The place seal lives in is called den
The place rat lives in is called nest
The place goldfish lives in is called pond
The place spider lives in is called web
The place whale lives in is called sea
The place cattle lives in is called
2024-07-29 02:13:24 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 02:15:21 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0305, -0.8159,  0.1646,  ...,  0.3018,  0.0427,  0.0692],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.8672, -6.9844,  2.8320,  ..., -1.8984,  2.1582, -1.8613],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 2.5482e-02, -6.5613e-03, -6.9809e-04,  ...,  3.8471e-03,
         -2.0905e-03, -9.7504e-03],
        [ 1.1475e-02,  2.7649e-02, -3.2997e-03,  ..., -3.8395e-03,
          6.6452e-03, -7.2250e-03],
        [-3.2005e-03,  2.3098e-03,  1.9440e-02,  ...,  7.0858e-04,
         -4.0665e-03, -1.1574e-02],
        ...,
        [ 4.0894e-03,  3.4332e-05, -1.0742e-02,  ...,  4.1595e-02,
          4.2057e-04, -9.4748e-04],
        [ 4.0665e-03,  5.4588e-03, -1.6308e-03,  ...,  1.0052e-03,
          3.1799e-02, -4.3564e-03],
        [-1.0567e-02, -1.2527e-02,  2.5673e-03,  ..., -1.6708e-03,
         -6.7139e-04,  2.8183e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.9805, -6.9141,  2.6543,  ..., -1.6943,  1.6309, -1.8975]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 02:15:22 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The place raven lives in is called nest
The place baboon lives in is called grove
The place seal lives in is called den
The place rat lives in is called nest
The place goldfish lives in is called pond
The place spider lives in is called web
The place whale lives in is called sea
The place cattle lives in is called
2024-07-29 02:15:22 root INFO     [order_1_approx] starting weight calculation for The place cattle lives in is called barn
The place goldfish lives in is called pond
The place baboon lives in is called grove
The place spider lives in is called web
The place whale lives in is called sea
The place seal lives in is called den
The place raven lives in is called nest
The place rat lives in is called
2024-07-29 02:15:22 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 02:17:19 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2092, -1.4629,  0.2615,  ...,  0.0585,  0.2119, -0.1921],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.7285, -4.2227,  3.2734,  ..., -1.1738, -0.9214, -0.7339],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0453, -0.0090,  0.0038,  ...,  0.0084, -0.0122, -0.0015],
        [ 0.0105,  0.0342, -0.0058,  ...,  0.0076,  0.0175, -0.0050],
        [-0.0093,  0.0209,  0.0460,  ...,  0.0154, -0.0093,  0.0010],
        ...,
        [ 0.0029, -0.0066, -0.0056,  ...,  0.0601,  0.0067, -0.0181],
        [ 0.0076,  0.0088, -0.0023,  ...,  0.0139,  0.0493, -0.0115],
        [ 0.0023,  0.0044,  0.0025,  ..., -0.0170, -0.0067,  0.0559]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.0352, -3.9375,  3.0449,  ..., -0.9736, -1.1523, -0.8115]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 02:17:20 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The place cattle lives in is called barn
The place goldfish lives in is called pond
The place baboon lives in is called grove
The place spider lives in is called web
The place whale lives in is called sea
The place seal lives in is called den
The place raven lives in is called nest
The place rat lives in is called
2024-07-29 02:17:20 root INFO     [order_1_approx] starting weight calculation for The place whale lives in is called sea
The place raven lives in is called nest
The place goldfish lives in is called pond
The place baboon lives in is called grove
The place rat lives in is called nest
The place cattle lives in is called barn
The place spider lives in is called web
The place seal lives in is called
2024-07-29 02:17:20 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 02:19:16 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.7881, -1.0566, -0.1718,  ...,  0.2932, -0.4951,  0.2791],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.6270, -7.5078, -1.3086,  ..., -2.1445, -0.0186,  0.7949],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0461, -0.0050, -0.0088,  ...,  0.0050,  0.0027, -0.0012],
        [-0.0018,  0.0466, -0.0182,  ...,  0.0003, -0.0067,  0.0102],
        [-0.0064, -0.0074,  0.0471,  ...,  0.0044, -0.0067, -0.0011],
        ...,
        [ 0.0057,  0.0034,  0.0042,  ...,  0.0746, -0.0027, -0.0027],
        [ 0.0045, -0.0044, -0.0024,  ...,  0.0003,  0.0468, -0.0182],
        [-0.0080, -0.0006,  0.0166,  ..., -0.0006, -0.0034,  0.0391]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.7109, -7.9297, -1.0352,  ..., -2.5098,  0.5098, -0.0127]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 02:19:17 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The place whale lives in is called sea
The place raven lives in is called nest
The place goldfish lives in is called pond
The place baboon lives in is called grove
The place rat lives in is called nest
The place cattle lives in is called barn
The place spider lives in is called web
The place seal lives in is called
2024-07-29 02:19:17 root INFO     total operator prediction time: 936.1614065170288 seconds
2024-07-29 02:19:17 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on country - language
2024-07-29 02:19:17 root INFO     building operator country - language
2024-07-29 02:19:17 root INFO     [order_1_approx] starting weight calculation for The country of guyana primarily speaks the language of english
The country of brazil primarily speaks the language of portuguese
The country of palestine primarily speaks the language of arabic
The country of switzerland primarily speaks the language of german
The country of bangladesh primarily speaks the language of bengali
The country of venezuela primarily speaks the language of spanish
The country of guam primarily speaks the language of english
The country of andorra primarily speaks the language of
2024-07-29 02:19:17 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 02:21:13 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.5791, -0.6699, -0.2817,  ...,  0.0864, -0.1107,  0.2898],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.0420, -5.2227,  0.6367,  ..., -1.3809, -0.7246,  1.0234],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0188,  0.0041, -0.0038,  ...,  0.0001,  0.0047,  0.0044],
        [ 0.0045,  0.0157,  0.0035,  ..., -0.0020, -0.0028, -0.0088],
        [-0.0005,  0.0047,  0.0183,  ...,  0.0067,  0.0017,  0.0056],
        ...,
        [-0.0032,  0.0043, -0.0103,  ...,  0.0222,  0.0020, -0.0020],
        [-0.0002,  0.0040, -0.0059,  ...,  0.0020,  0.0110, -0.0021],
        [-0.0044, -0.0036, -0.0064,  ...,  0.0003,  0.0042,  0.0242]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.0488, -5.0391,  0.4851,  ..., -1.4453, -0.6519,  1.0371]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 02:21:14 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country of guyana primarily speaks the language of english
The country of brazil primarily speaks the language of portuguese
The country of palestine primarily speaks the language of arabic
The country of switzerland primarily speaks the language of german
The country of bangladesh primarily speaks the language of bengali
The country of venezuela primarily speaks the language of spanish
The country of guam primarily speaks the language of english
The country of andorra primarily speaks the language of
2024-07-29 02:21:14 root INFO     [order_1_approx] starting weight calculation for The country of switzerland primarily speaks the language of german
The country of venezuela primarily speaks the language of spanish
The country of guyana primarily speaks the language of english
The country of guam primarily speaks the language of english
The country of andorra primarily speaks the language of catalan
The country of palestine primarily speaks the language of arabic
The country of brazil primarily speaks the language of portuguese
The country of bangladesh primarily speaks the language of
2024-07-29 02:21:14 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 02:23:11 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3479, -0.5640,  0.1035,  ...,  0.1313, -0.5610,  0.7095],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.7559, -2.8398, -0.0681,  ..., -0.9155, -2.7090, -2.8828],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 4.4174e-03, -5.6267e-04,  1.6928e-03,  ..., -3.6669e-04,
          2.1877e-03, -1.8215e-03],
        [-2.9635e-04,  1.1307e-02, -1.3790e-03,  ..., -2.0924e-03,
          2.1591e-03,  1.4067e-04],
        [ 2.3346e-03,  7.2813e-04,  8.7509e-03,  ...,  2.4643e-03,
         -1.7853e-03,  6.9141e-04],
        ...,
        [ 1.1673e-03, -1.8921e-03, -4.1580e-03,  ...,  7.0610e-03,
          9.3746e-04, -3.9291e-04],
        [-7.6294e-05, -1.4400e-04, -1.4734e-03,  ..., -1.3037e-03,
          5.7335e-03, -1.9236e-03],
        [ 5.5456e-04, -3.2616e-03, -1.2369e-03,  ...,  9.3079e-04,
          1.3866e-03,  1.1581e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.7915, -2.8262, -0.1146,  ..., -0.8867, -2.6426, -2.8633]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 02:23:12 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country of switzerland primarily speaks the language of german
The country of venezuela primarily speaks the language of spanish
The country of guyana primarily speaks the language of english
The country of guam primarily speaks the language of english
The country of andorra primarily speaks the language of catalan
The country of palestine primarily speaks the language of arabic
The country of brazil primarily speaks the language of portuguese
The country of bangladesh primarily speaks the language of
2024-07-29 02:23:12 root INFO     [order_1_approx] starting weight calculation for The country of venezuela primarily speaks the language of spanish
The country of palestine primarily speaks the language of arabic
The country of bangladesh primarily speaks the language of bengali
The country of brazil primarily speaks the language of portuguese
The country of guam primarily speaks the language of english
The country of andorra primarily speaks the language of catalan
The country of guyana primarily speaks the language of english
The country of switzerland primarily speaks the language of
2024-07-29 02:23:12 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 02:25:06 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.7998, -0.4443, -0.8438,  ...,  0.5942,  0.5405,  0.5298],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.2773, -7.3164, -0.1953,  ..., -0.4729, -0.2158, -0.8950],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 1.2215e-02, -3.2578e-03, -2.9335e-03,  ...,  3.0289e-03,
          1.8044e-03,  2.9526e-03],
        [-4.8447e-04,  7.4997e-03, -2.4452e-03,  ..., -5.6534e-03,
          5.2261e-03,  5.9013e-03],
        [ 4.2305e-03,  4.5738e-03,  1.4145e-02,  ...,  9.0942e-03,
         -4.3869e-05,  3.2043e-03],
        ...,
        [-5.4817e-03,  5.1270e-03, -5.3673e-03,  ...,  1.6510e-02,
         -3.1776e-03, -6.0997e-03],
        [ 2.2659e-03,  2.3270e-03,  3.4943e-03,  ..., -1.1845e-03,
          1.2062e-02, -2.0657e-03],
        [-3.5820e-03, -6.4011e-03, -1.1185e-02,  ..., -1.9798e-03,
          3.3588e-03,  2.2446e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.1211, -6.7188, -0.2593,  ..., -0.6685, -0.1814, -0.6670]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 02:25:07 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country of venezuela primarily speaks the language of spanish
The country of palestine primarily speaks the language of arabic
The country of bangladesh primarily speaks the language of bengali
The country of brazil primarily speaks the language of portuguese
The country of guam primarily speaks the language of english
The country of andorra primarily speaks the language of catalan
The country of guyana primarily speaks the language of english
The country of switzerland primarily speaks the language of
2024-07-29 02:25:07 root INFO     [order_1_approx] starting weight calculation for The country of palestine primarily speaks the language of arabic
The country of guam primarily speaks the language of english
The country of switzerland primarily speaks the language of german
The country of brazil primarily speaks the language of portuguese
The country of andorra primarily speaks the language of catalan
The country of guyana primarily speaks the language of english
The country of bangladesh primarily speaks the language of bengali
The country of venezuela primarily speaks the language of
2024-07-29 02:25:07 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 02:27:02 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.6675, -0.7012, -0.1841,  ...,  0.4492, -0.3523, -0.0422],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.5508, -3.3223,  1.4922,  ...,  0.6797,  0.3867, -2.0664],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 1.1742e-02, -8.6117e-04, -1.3247e-03,  ...,  1.6947e-03,
          3.4332e-03,  3.1052e-03],
        [ 6.1607e-04,  1.2680e-02, -1.0548e-03,  ..., -8.7118e-04,
         -1.8063e-03, -5.3635e-03],
        [-2.0828e-03,  2.3975e-03,  1.1665e-02,  ...,  1.8053e-03,
         -1.1969e-03,  2.2144e-03],
        ...,
        [-7.3147e-04,  9.1553e-05, -6.9466e-03,  ...,  1.2512e-02,
          1.9760e-03,  3.1853e-04],
        [-1.0386e-03, -3.9787e-03, -8.6117e-04,  ..., -6.3133e-04,
          9.7733e-03, -6.8569e-04],
        [-5.9545e-05, -4.9782e-03, -1.9970e-03,  ...,  1.2054e-03,
          2.4261e-03,  1.6739e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.5566, -3.3555,  1.4248,  ...,  0.5781,  0.3506, -1.9189]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 02:27:02 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country of palestine primarily speaks the language of arabic
The country of guam primarily speaks the language of english
The country of switzerland primarily speaks the language of german
The country of brazil primarily speaks the language of portuguese
The country of andorra primarily speaks the language of catalan
The country of guyana primarily speaks the language of english
The country of bangladesh primarily speaks the language of bengali
The country of venezuela primarily speaks the language of
2024-07-29 02:27:03 root INFO     [order_1_approx] starting weight calculation for The country of andorra primarily speaks the language of catalan
The country of guam primarily speaks the language of english
The country of bangladesh primarily speaks the language of bengali
The country of palestine primarily speaks the language of arabic
The country of venezuela primarily speaks the language of spanish
The country of switzerland primarily speaks the language of german
The country of guyana primarily speaks the language of english
The country of brazil primarily speaks the language of
2024-07-29 02:27:03 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 02:28:56 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.5200, -0.3113,  0.2783,  ..., -0.0287,  0.0871,  0.1929],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.8652, -3.5586,  0.4561,  ...,  0.5205,  0.9727, -1.9316],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0112,  0.0017, -0.0016,  ...,  0.0062,  0.0015,  0.0041],
        [ 0.0002,  0.0102, -0.0016,  ..., -0.0003, -0.0050, -0.0024],
        [ 0.0023,  0.0040,  0.0140,  ...,  0.0013,  0.0012,  0.0005],
        ...,
        [ 0.0008,  0.0017, -0.0078,  ...,  0.0132, -0.0004, -0.0018],
        [ 0.0040, -0.0016, -0.0032,  ..., -0.0003,  0.0099, -0.0017],
        [ 0.0005, -0.0046, -0.0044,  ..., -0.0013,  0.0020,  0.0166]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.9141, -3.5020,  0.3440,  ...,  0.3726,  0.9497, -1.7822]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 02:28:57 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country of andorra primarily speaks the language of catalan
The country of guam primarily speaks the language of english
The country of bangladesh primarily speaks the language of bengali
The country of palestine primarily speaks the language of arabic
The country of venezuela primarily speaks the language of spanish
The country of switzerland primarily speaks the language of german
The country of guyana primarily speaks the language of english
The country of brazil primarily speaks the language of
2024-07-29 02:28:57 root INFO     [order_1_approx] starting weight calculation for The country of brazil primarily speaks the language of portuguese
The country of guyana primarily speaks the language of english
The country of guam primarily speaks the language of english
The country of venezuela primarily speaks the language of spanish
The country of switzerland primarily speaks the language of german
The country of bangladesh primarily speaks the language of bengali
The country of andorra primarily speaks the language of catalan
The country of palestine primarily speaks the language of
2024-07-29 02:28:57 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 02:30:53 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2998, -0.3323,  0.0747,  ...,  0.2139, -0.3733,  0.1711],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.4648, -4.5508,  0.3870,  ..., -1.6826,  0.4102, -1.0635],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 1.1253e-02,  1.6251e-03, -1.6518e-03,  ...,  2.2945e-03,
         -2.3031e-04,  4.4799e-04],
        [-1.4925e-04,  1.2772e-02,  1.7424e-03,  ..., -1.0815e-03,
          4.3058e-04, -3.5477e-03],
        [-2.0542e-03, -1.3866e-03,  1.3504e-02,  ...,  2.8439e-03,
          2.1820e-03,  1.7052e-03],
        ...,
        [ 3.4237e-04,  1.2064e-04, -1.9684e-03,  ...,  1.5594e-02,
          2.7180e-05,  1.7443e-03],
        [-1.9979e-04,  3.5992e-03, -8.4639e-04,  ..., -2.2507e-04,
          8.3237e-03,  4.4131e-04],
        [-1.0109e-03, -2.0142e-03, -1.5593e-03,  ...,  1.3151e-03,
         -9.4223e-04,  1.4473e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.4441, -4.5312,  0.3359,  ..., -1.6611,  0.4062, -1.0391]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 02:30:54 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country of brazil primarily speaks the language of portuguese
The country of guyana primarily speaks the language of english
The country of guam primarily speaks the language of english
The country of venezuela primarily speaks the language of spanish
The country of switzerland primarily speaks the language of german
The country of bangladesh primarily speaks the language of bengali
The country of andorra primarily speaks the language of catalan
The country of palestine primarily speaks the language of
2024-07-29 02:30:54 root INFO     [order_1_approx] starting weight calculation for The country of switzerland primarily speaks the language of german
The country of bangladesh primarily speaks the language of bengali
The country of venezuela primarily speaks the language of spanish
The country of brazil primarily speaks the language of portuguese
The country of guyana primarily speaks the language of english
The country of andorra primarily speaks the language of catalan
The country of palestine primarily speaks the language of arabic
The country of guam primarily speaks the language of
2024-07-29 02:30:54 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 02:32:48 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0839, -0.2275,  0.0390,  ...,  0.7246, -0.8086,  0.5400],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.8574,  0.9946,  2.1230,  ..., -0.1279, -1.7637, -3.0957],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0201,  0.0034,  0.0018,  ..., -0.0052,  0.0067,  0.0047],
        [ 0.0056,  0.0364,  0.0053,  ...,  0.0044,  0.0084, -0.0049],
        [ 0.0033, -0.0108,  0.0343,  ...,  0.0062, -0.0038, -0.0003],
        ...,
        [ 0.0029,  0.0071, -0.0100,  ...,  0.0432,  0.0014, -0.0043],
        [ 0.0065,  0.0061, -0.0053,  ..., -0.0049,  0.0240,  0.0031],
        [-0.0012, -0.0120, -0.0069,  ...,  0.0147,  0.0092,  0.0432]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.7988,  1.0400,  1.7148,  ..., -0.1152, -1.5244, -2.6719]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 02:32:49 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country of switzerland primarily speaks the language of german
The country of bangladesh primarily speaks the language of bengali
The country of venezuela primarily speaks the language of spanish
The country of brazil primarily speaks the language of portuguese
The country of guyana primarily speaks the language of english
The country of andorra primarily speaks the language of catalan
The country of palestine primarily speaks the language of arabic
The country of guam primarily speaks the language of
2024-07-29 02:32:49 root INFO     [order_1_approx] starting weight calculation for The country of brazil primarily speaks the language of portuguese
The country of venezuela primarily speaks the language of spanish
The country of palestine primarily speaks the language of arabic
The country of switzerland primarily speaks the language of german
The country of andorra primarily speaks the language of catalan
The country of bangladesh primarily speaks the language of bengali
The country of guam primarily speaks the language of english
The country of guyana primarily speaks the language of
2024-07-29 02:32:49 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 02:34:45 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1350, -0.2112,  0.5024,  ..., -0.3811, -0.9834, -0.4211],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.0820,  0.3652,  1.5264,  ...,  1.2979,  0.7051, -3.3027],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 1.6861e-02,  4.5738e-03, -3.6621e-03,  ..., -7.1754e-03,
          1.3580e-03, -3.0727e-03],
        [ 4.2953e-03,  2.4170e-02, -6.1111e-03,  ...,  3.2845e-03,
         -8.9788e-04, -6.6376e-03],
        [ 1.6699e-03, -5.2795e-03,  2.3315e-02,  ...,  2.9526e-03,
          3.9711e-03, -1.4229e-03],
        ...,
        [ 2.3007e-05, -1.6327e-03, -8.9417e-03,  ...,  2.6657e-02,
         -1.8854e-03, -3.3092e-03],
        [ 4.4327e-03,  1.3542e-02, -6.4011e-03,  ..., -7.3547e-03,
          2.2705e-02,  3.6011e-03],
        [ 7.8735e-03, -4.4174e-03, -6.7291e-03,  ...,  1.6947e-03,
          9.4147e-03,  3.2928e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.8076,  0.4897,  1.5117,  ...,  1.2002,  0.7275, -3.0176]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 02:34:46 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country of brazil primarily speaks the language of portuguese
The country of venezuela primarily speaks the language of spanish
The country of palestine primarily speaks the language of arabic
The country of switzerland primarily speaks the language of german
The country of andorra primarily speaks the language of catalan
The country of bangladesh primarily speaks the language of bengali
The country of guam primarily speaks the language of english
The country of guyana primarily speaks the language of
2024-07-29 02:34:46 root INFO     total operator prediction time: 928.9574675559998 seconds
2024-07-29 02:34:46 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on name - nationality
2024-07-29 02:34:46 root INFO     building operator name - nationality
2024-07-29 02:34:46 root INFO     [order_1_approx] starting weight calculation for kepler was german
truman was american
hegel was german
darwin was english
pascal was french
lennon was english
einstein was jewish
mozart was
2024-07-29 02:34:46 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 02:36:44 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2000,  0.3350,  0.3499,  ..., -0.0488, -0.4971, -0.0702],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.1055, -4.3672,  1.7959,  ..., -2.4531, -0.8438, -0.4521],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0609,  0.0051, -0.0029,  ..., -0.0155,  0.0038, -0.0085],
        [ 0.0093,  0.0627,  0.0204,  ..., -0.0046,  0.0115, -0.0009],
        [-0.0022, -0.0127,  0.0635,  ...,  0.0014, -0.0045,  0.0138],
        ...,
        [ 0.0074, -0.0061, -0.0071,  ...,  0.0764,  0.0050, -0.0153],
        [ 0.0110,  0.0054,  0.0022,  ...,  0.0023,  0.0455, -0.0051],
        [ 0.0047, -0.0011, -0.0127,  ...,  0.0144, -0.0020,  0.0617]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.8672, -4.0273,  1.8027,  ..., -2.6055, -0.9575, -0.6021]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 02:36:45 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for kepler was german
truman was american
hegel was german
darwin was english
pascal was french
lennon was english
einstein was jewish
mozart was
2024-07-29 02:36:45 root INFO     [order_1_approx] starting weight calculation for lennon was english
truman was american
darwin was english
einstein was jewish
kepler was german
mozart was german
hegel was german
pascal was
2024-07-29 02:36:45 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 02:38:40 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2130, -0.7144,  0.4409,  ..., -0.4341,  0.1177,  0.7329],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.2188, -0.4341,  2.0938,  ..., -4.3125, -0.1621,  1.8965],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0978, -0.0102,  0.0004,  ..., -0.0123,  0.0024, -0.0087],
        [ 0.0162,  0.0837,  0.0148,  ...,  0.0034, -0.0104, -0.0081],
        [-0.0055, -0.0068,  0.0770,  ...,  0.0005,  0.0070,  0.0003],
        ...,
        [ 0.0215,  0.0042, -0.0040,  ...,  0.0716,  0.0023, -0.0036],
        [ 0.0083,  0.0063, -0.0049,  ...,  0.0229,  0.0654, -0.0044],
        [-0.0086,  0.0079, -0.0132,  ...,  0.0186, -0.0098,  0.0716]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.0273, -0.8535,  1.5098,  ..., -3.8711, -0.0779,  1.4395]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 02:38:41 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for lennon was english
truman was american
darwin was english
einstein was jewish
kepler was german
mozart was german
hegel was german
pascal was
2024-07-29 02:38:41 root INFO     [order_1_approx] starting weight calculation for truman was american
pascal was french
darwin was english
mozart was german
einstein was jewish
kepler was german
hegel was german
lennon was
2024-07-29 02:38:41 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 02:40:35 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.8955,  0.0432, -0.0076,  ...,  0.4561, -0.7476,  0.2910],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.9316, -3.6406,  0.7104,  ..., -2.7422, -0.7100, -1.4648],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 6.7200e-02, -1.5602e-03, -7.7820e-04,  ..., -9.8419e-03,
          6.2981e-03,  2.4681e-03],
        [ 5.6992e-03,  6.9824e-02,  9.3231e-03,  ...,  4.1618e-03,
          6.9199e-03, -2.0721e-02],
        [-1.1337e-02, -5.8670e-03,  6.6833e-02,  ..., -4.8637e-04,
         -1.1208e-02,  1.6785e-02],
        ...,
        [ 8.8348e-03,  8.8120e-03,  3.2120e-03,  ...,  8.5571e-02,
         -6.7902e-04, -1.3489e-02],
        [-1.1559e-03, -1.2245e-03, -4.7302e-04,  ...,  4.4632e-03,
          4.4800e-02,  7.0000e-03],
        [ 6.4468e-03,  7.7248e-05, -1.3245e-02,  ...,  7.4539e-03,
         -2.8000e-03,  7.0374e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.4902, -3.1738,  0.7812,  ..., -3.1875, -0.7461, -1.3574]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 02:40:36 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for truman was american
pascal was french
darwin was english
mozart was german
einstein was jewish
kepler was german
hegel was german
lennon was
2024-07-29 02:40:37 root INFO     [order_1_approx] starting weight calculation for kepler was german
lennon was english
pascal was french
truman was american
mozart was german
darwin was english
einstein was jewish
hegel was
2024-07-29 02:40:37 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 02:42:33 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0918, -0.3762,  0.0757,  ...,  0.0818,  0.0785, -0.6113],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.4062, -5.0898,  1.3096,  ..., -3.6973, -1.4062, -0.2866],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0621, -0.0092, -0.0068,  ..., -0.0066,  0.0011, -0.0059],
        [-0.0062,  0.0526,  0.0096,  ...,  0.0035, -0.0010, -0.0035],
        [ 0.0039, -0.0072,  0.0360,  ..., -0.0009, -0.0041,  0.0091],
        ...,
        [ 0.0186,  0.0010,  0.0007,  ...,  0.0452,  0.0039, -0.0032],
        [ 0.0087, -0.0002,  0.0021,  ..., -0.0008,  0.0415, -0.0092],
        [ 0.0007, -0.0028, -0.0049,  ...,  0.0115, -0.0058,  0.0440]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.6035, -4.7969,  1.3271,  ..., -3.8613, -1.3975, -0.2683]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 02:42:34 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for kepler was german
lennon was english
pascal was french
truman was american
mozart was german
darwin was english
einstein was jewish
hegel was
2024-07-29 02:42:34 root INFO     [order_1_approx] starting weight calculation for truman was american
mozart was german
kepler was german
hegel was german
einstein was jewish
pascal was french
lennon was english
darwin was
2024-07-29 02:42:34 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 02:44:30 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.8164, -0.0815,  0.0529,  ...,  0.0743, -0.3857, -0.0210],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 5.8398, -1.7588,  0.7129,  ..., -3.0586,  0.4473, -1.8135],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0640, -0.0035,  0.0034,  ..., -0.0253, -0.0029, -0.0089],
        [-0.0046,  0.0692,  0.0095,  ..., -0.0126,  0.0130, -0.0126],
        [-0.0012, -0.0054,  0.0626,  ...,  0.0059, -0.0020,  0.0048],
        ...,
        [ 0.0182,  0.0084, -0.0179,  ...,  0.0865, -0.0071, -0.0124],
        [-0.0145,  0.0154, -0.0081,  ...,  0.0106,  0.0630, -0.0114],
        [ 0.0085,  0.0085, -0.0097,  ...,  0.0279, -0.0110,  0.0853]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 6.0508, -1.6982,  0.6597,  ..., -3.1387,  0.6167, -2.0762]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 02:44:31 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for truman was american
mozart was german
kepler was german
hegel was german
einstein was jewish
pascal was french
lennon was english
darwin was
2024-07-29 02:44:31 root INFO     [order_1_approx] starting weight calculation for kepler was german
hegel was german
lennon was english
einstein was jewish
mozart was german
darwin was english
pascal was french
truman was
2024-07-29 02:44:31 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 02:46:23 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1460, -0.0176, -0.2969,  ...,  0.1868, -0.5908,  0.4556],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 5.2852, -2.5547,  0.7725,  ..., -3.1816,  2.5020, -0.2756],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0922, -0.0045,  0.0059,  ...,  0.0003,  0.0052, -0.0055],
        [ 0.0028,  0.0744,  0.0111,  ..., -0.0098,  0.0108, -0.0114],
        [ 0.0064, -0.0006,  0.0775,  ..., -0.0099, -0.0029,  0.0157],
        ...,
        [ 0.0127,  0.0189, -0.0076,  ...,  0.1094, -0.0052,  0.0003],
        [-0.0082,  0.0065, -0.0110,  ...,  0.0028,  0.0780, -0.0108],
        [ 0.0130,  0.0101, -0.0119,  ...,  0.0046, -0.0095,  0.0765]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 5.2188e+00, -2.8203e+00,  4.1064e-01,  ..., -3.2188e+00,
          2.6523e+00,  2.4414e-04]], device='cuda:1', dtype=torch.float16,
       grad_fn=<SubBackward0>) 

                    
2024-07-29 02:46:24 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for kepler was german
hegel was german
lennon was english
einstein was jewish
mozart was german
darwin was english
pascal was french
truman was
2024-07-29 02:46:24 root INFO     [order_1_approx] starting weight calculation for hegel was german
kepler was german
pascal was french
lennon was english
mozart was german
truman was american
darwin was english
einstein was
2024-07-29 02:46:24 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 02:48:18 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0176, -0.6152, -0.2019,  ..., -0.2372, -0.1379,  0.3643],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.1270, -4.8906,  0.6963,  ..., -3.3789, -1.9863,  0.1602],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 6.0120e-02, -8.3771e-03, -8.0566e-03,  ..., -4.9896e-03,
          3.6354e-03, -6.1684e-03],
        [ 1.0292e-02,  5.4321e-02,  9.5291e-03,  ..., -4.1504e-03,
          1.3256e-03, -1.1841e-02],
        [-9.9945e-04,  9.9897e-05,  5.1392e-02,  ...,  3.6430e-03,
          3.0117e-03,  8.0414e-03],
        ...,
        [ 1.6068e-02,  9.4299e-03, -7.1487e-03,  ...,  5.9967e-02,
         -2.9907e-03, -8.1635e-03],
        [-5.5771e-03,  5.4550e-03, -2.4414e-03,  ..., -1.6212e-04,
          3.8818e-02, -1.5038e-02],
        [ 3.5286e-04,  7.8125e-03, -1.1955e-02,  ...,  5.3177e-03,
          2.0218e-04,  5.6244e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.1636, -4.6953,  0.7412,  ..., -3.3125, -1.7471,  0.2047]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 02:48:19 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for hegel was german
kepler was german
pascal was french
lennon was english
mozart was german
truman was american
darwin was english
einstein was
2024-07-29 02:48:19 root INFO     [order_1_approx] starting weight calculation for truman was american
lennon was english
pascal was french
hegel was german
mozart was german
einstein was jewish
darwin was english
kepler was
2024-07-29 02:48:19 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 02:50:14 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1410, -0.4541,  0.3418,  ..., -0.0691, -0.3486,  0.6201],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.2402, -4.6875,  1.8623,  ..., -2.5859, -0.9761,  0.2139],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0928,  0.0041, -0.0155,  ..., -0.0155,  0.0037,  0.0027],
        [ 0.0069,  0.0692,  0.0108,  ...,  0.0114,  0.0130, -0.0017],
        [-0.0060,  0.0017,  0.0688,  ...,  0.0121, -0.0002,  0.0010],
        ...,
        [ 0.0068,  0.0132, -0.0081,  ...,  0.0674,  0.0033,  0.0028],
        [ 0.0129,  0.0026,  0.0012,  ..., -0.0007,  0.0597, -0.0182],
        [ 0.0016,  0.0013, -0.0104,  ...,  0.0138, -0.0074,  0.0862]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.2344, -4.4414,  2.0664,  ..., -1.9141, -0.8877,  0.2678]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 02:50:14 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for truman was american
lennon was english
pascal was french
hegel was german
mozart was german
einstein was jewish
darwin was english
kepler was
2024-07-29 02:50:14 root INFO     total operator prediction time: 928.6381208896637 seconds
2024-07-29 02:50:14 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on UK_city - county
2024-07-29 02:50:14 root INFO     building operator UK_city - county
2024-07-29 02:50:15 root INFO     [order_1_approx] starting weight calculation for In the United Kingdom, the city of chester is in the county of cheshire
In the United Kingdom, the city of preston is in the county of lancashire
In the United Kingdom, the city of edinburgh is in the county of lowlands
In the United Kingdom, the city of crawley is in the county of sussex
In the United Kingdom, the city of gloucester is in the county of gloucestershire
In the United Kingdom, the city of hereford is in the county of herefordshire
In the United Kingdom, the city of ely is in the county of cambridgeshire
In the United Kingdom, the city of newcastle is in the county of
2024-07-29 02:50:15 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 02:52:10 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.7212,  0.4917, -0.0852,  ...,  0.0272, -0.4175,  0.0746],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.0586, -3.7773,  2.7461,  ..., -2.8340, -2.7129, -1.1875],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0126, -0.0020,  0.0112,  ...,  0.0007,  0.0054, -0.0142],
        [ 0.0066,  0.0107,  0.0150,  ..., -0.0015,  0.0142, -0.0076],
        [ 0.0060, -0.0019,  0.0181,  ..., -0.0003,  0.0044, -0.0112],
        ...,
        [ 0.0101, -0.0040,  0.0033,  ...,  0.0278, -0.0064,  0.0035],
        [ 0.0013, -0.0157,  0.0037,  ...,  0.0064,  0.0260,  0.0009],
        [ 0.0108,  0.0050, -0.0127,  ..., -0.0024, -0.0075,  0.0166]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.6719, -3.7598,  2.5293,  ..., -3.0156, -2.4922, -1.2236]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 02:52:11 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for In the United Kingdom, the city of chester is in the county of cheshire
In the United Kingdom, the city of preston is in the county of lancashire
In the United Kingdom, the city of edinburgh is in the county of lowlands
In the United Kingdom, the city of crawley is in the county of sussex
In the United Kingdom, the city of gloucester is in the county of gloucestershire
In the United Kingdom, the city of hereford is in the county of herefordshire
In the United Kingdom, the city of ely is in the county of cambridgeshire
In the United Kingdom, the city of newcastle is in the county of
2024-07-29 02:52:11 root INFO     [order_1_approx] starting weight calculation for In the United Kingdom, the city of ely is in the county of cambridgeshire
In the United Kingdom, the city of edinburgh is in the county of lowlands
In the United Kingdom, the city of hereford is in the county of herefordshire
In the United Kingdom, the city of crawley is in the county of sussex
In the United Kingdom, the city of chester is in the county of cheshire
In the United Kingdom, the city of gloucester is in the county of gloucestershire
In the United Kingdom, the city of newcastle is in the county of northumberland
In the United Kingdom, the city of preston is in the county of
2024-07-29 02:52:11 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 02:54:04 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4004,  0.1968, -0.6055,  ...,  0.4177,  0.3123,  0.3096],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.5977, -5.4375,  2.2598,  ..., -2.6133,  0.3408, -1.5840],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0222,  0.0122, -0.0041,  ...,  0.0075,  0.0030, -0.0125],
        [-0.0013,  0.0095,  0.0081,  ..., -0.0007,  0.0006, -0.0068],
        [ 0.0050,  0.0054,  0.0198,  ...,  0.0043,  0.0007,  0.0018],
        ...,
        [ 0.0225,  0.0022,  0.0005,  ...,  0.0330,  0.0028, -0.0098],
        [-0.0047, -0.0072,  0.0087,  ..., -0.0015,  0.0264, -0.0062],
        [-0.0021, -0.0151, -0.0124,  ...,  0.0061, -0.0102,  0.0236]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.7852, -5.4453,  2.0703,  ..., -2.7852,  0.2998, -1.1328]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 02:54:05 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for In the United Kingdom, the city of ely is in the county of cambridgeshire
In the United Kingdom, the city of edinburgh is in the county of lowlands
In the United Kingdom, the city of hereford is in the county of herefordshire
In the United Kingdom, the city of crawley is in the county of sussex
In the United Kingdom, the city of chester is in the county of cheshire
In the United Kingdom, the city of gloucester is in the county of gloucestershire
In the United Kingdom, the city of newcastle is in the county of northumberland
In the United Kingdom, the city of preston is in the county of
2024-07-29 02:54:05 root INFO     [order_1_approx] starting weight calculation for In the United Kingdom, the city of chester is in the county of cheshire
In the United Kingdom, the city of hereford is in the county of herefordshire
In the United Kingdom, the city of gloucester is in the county of gloucestershire
In the United Kingdom, the city of ely is in the county of cambridgeshire
In the United Kingdom, the city of newcastle is in the county of northumberland
In the United Kingdom, the city of edinburgh is in the county of lowlands
In the United Kingdom, the city of preston is in the county of lancashire
In the United Kingdom, the city of crawley is in the county of
2024-07-29 02:54:05 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 02:56:02 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.7295, -0.0591, -0.6025,  ...,  0.1296, -0.3218, -0.1752],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.2168, -5.4219,  0.5898,  ..., -3.4766,  1.3438, -0.3706],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0220,  0.0181, -0.0020,  ..., -0.0083,  0.0023, -0.0087],
        [-0.0027,  0.0119,  0.0010,  ...,  0.0078,  0.0081, -0.0043],
        [-0.0120, -0.0180,  0.0122,  ..., -0.0103,  0.0017,  0.0105],
        ...,
        [ 0.0077, -0.0055, -0.0064,  ...,  0.0273, -0.0004,  0.0106],
        [-0.0116, -0.0061,  0.0175,  ...,  0.0129,  0.0118, -0.0052],
        [ 0.0062,  0.0034, -0.0201,  ...,  0.0039,  0.0007,  0.0173]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.1406, -5.3398,  0.5981,  ..., -3.7988,  1.3818, -0.6641]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 02:56:07 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for In the United Kingdom, the city of chester is in the county of cheshire
In the United Kingdom, the city of hereford is in the county of herefordshire
In the United Kingdom, the city of gloucester is in the county of gloucestershire
In the United Kingdom, the city of ely is in the county of cambridgeshire
In the United Kingdom, the city of newcastle is in the county of northumberland
In the United Kingdom, the city of edinburgh is in the county of lowlands
In the United Kingdom, the city of preston is in the county of lancashire
In the United Kingdom, the city of crawley is in the county of
2024-07-29 02:56:07 root INFO     [order_1_approx] starting weight calculation for In the United Kingdom, the city of gloucester is in the county of gloucestershire
In the United Kingdom, the city of chester is in the county of cheshire
In the United Kingdom, the city of ely is in the county of cambridgeshire
In the United Kingdom, the city of newcastle is in the county of northumberland
In the United Kingdom, the city of preston is in the county of lancashire
In the United Kingdom, the city of hereford is in the county of herefordshire
In the United Kingdom, the city of crawley is in the county of sussex
In the United Kingdom, the city of edinburgh is in the county of
2024-07-29 02:56:07 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 02:58:05 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.7568,  0.7251, -0.7280,  ..., -0.0787,  0.1968,  0.4287],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.3105, -4.3398,  1.5547,  ..., -1.2617, -0.6777, -1.0078],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-2.0638e-03,  1.3657e-03,  4.7264e-03,  ...,  1.3153e-02,
          4.0627e-04, -3.4466e-03],
        [-1.8692e-03,  7.6866e-03,  5.6725e-03,  ..., -6.1035e-05,
          4.5547e-03, -2.0981e-03],
        [-8.7452e-04,  1.0918e-02,  1.4297e-02,  ...,  6.1684e-03,
         -4.4250e-04, -4.0855e-03],
        ...,
        [ 1.3710e-02, -9.1934e-04,  2.1477e-03,  ...,  2.9648e-02,
          6.6299e-03,  3.6430e-03],
        [-3.7556e-03, -1.0178e-02,  4.2686e-03,  ...,  1.2589e-02,
          1.7410e-02,  3.1166e-03],
        [-5.5580e-03,  1.8139e-03, -6.5918e-03,  ...,  8.1062e-05,
         -9.5940e-04,  1.8616e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.8604, -3.9980,  1.4111,  ..., -1.5469, -0.5322, -1.0742]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 02:58:06 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for In the United Kingdom, the city of gloucester is in the county of gloucestershire
In the United Kingdom, the city of chester is in the county of cheshire
In the United Kingdom, the city of ely is in the county of cambridgeshire
In the United Kingdom, the city of newcastle is in the county of northumberland
In the United Kingdom, the city of preston is in the county of lancashire
In the United Kingdom, the city of hereford is in the county of herefordshire
In the United Kingdom, the city of crawley is in the county of sussex
In the United Kingdom, the city of edinburgh is in the county of
2024-07-29 02:58:06 root INFO     [order_1_approx] starting weight calculation for In the United Kingdom, the city of preston is in the county of lancashire
In the United Kingdom, the city of ely is in the county of cambridgeshire
In the United Kingdom, the city of crawley is in the county of sussex
In the United Kingdom, the city of edinburgh is in the county of lowlands
In the United Kingdom, the city of chester is in the county of cheshire
In the United Kingdom, the city of newcastle is in the county of northumberland
In the United Kingdom, the city of hereford is in the county of herefordshire
In the United Kingdom, the city of gloucester is in the county of
2024-07-29 02:58:06 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 03:00:00 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.7119, -0.4067, -0.2312,  ..., -0.7061, -0.2262,  0.1501],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.7305, -4.0312,  2.3418,  ..., -4.1406,  2.2930, -1.4170],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 6.4812e-03,  3.4771e-03,  1.2531e-03,  ..., -5.7936e-04,
          1.7157e-03, -3.9330e-03],
        [ 4.5967e-04,  7.1144e-03, -2.9564e-03,  ...,  1.4524e-03,
          1.5173e-03, -4.7112e-04],
        [-2.4395e-03, -5.0850e-03,  1.0246e-02,  ..., -2.1076e-04,
          2.1667e-03, -3.3627e-03],
        ...,
        [ 3.5629e-03, -1.1578e-03, -3.4142e-04,  ...,  1.0445e-02,
         -1.0853e-03,  9.7275e-05],
        [-5.9052e-03, -2.5692e-03,  3.5172e-03,  ...,  1.4362e-03,
          2.6131e-03, -2.2430e-03],
        [ 2.8763e-03, -5.3787e-03, -3.1967e-03,  ..., -3.6716e-03,
          5.3358e-04,  5.9662e-03]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.6992, -3.9824,  2.3359,  ..., -4.1094,  2.3203, -1.4395]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 03:00:01 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for In the United Kingdom, the city of preston is in the county of lancashire
In the United Kingdom, the city of ely is in the county of cambridgeshire
In the United Kingdom, the city of crawley is in the county of sussex
In the United Kingdom, the city of edinburgh is in the county of lowlands
In the United Kingdom, the city of chester is in the county of cheshire
In the United Kingdom, the city of newcastle is in the county of northumberland
In the United Kingdom, the city of hereford is in the county of herefordshire
In the United Kingdom, the city of gloucester is in the county of
2024-07-29 03:00:01 root INFO     [order_1_approx] starting weight calculation for In the United Kingdom, the city of hereford is in the county of herefordshire
In the United Kingdom, the city of preston is in the county of lancashire
In the United Kingdom, the city of newcastle is in the county of northumberland
In the United Kingdom, the city of crawley is in the county of sussex
In the United Kingdom, the city of ely is in the county of cambridgeshire
In the United Kingdom, the city of edinburgh is in the county of lowlands
In the United Kingdom, the city of gloucester is in the county of gloucestershire
In the United Kingdom, the city of chester is in the county of
2024-07-29 03:00:01 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 03:01:56 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.5742, -0.3071, -0.1154,  ...,  0.1920,  0.2871,  0.3171],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 5.2812, -4.5703,  1.5938,  ..., -3.6348,  0.1787, -1.2754],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0364,  0.0229, -0.0090,  ...,  0.0201, -0.0172, -0.0115],
        [ 0.0005,  0.0218,  0.0109,  ..., -0.0091,  0.0027,  0.0023],
        [-0.0175, -0.0145,  0.0259,  ...,  0.0073,  0.0061,  0.0035],
        ...,
        [ 0.0218,  0.0008, -0.0054,  ...,  0.0285,  0.0013, -0.0051],
        [-0.0352, -0.0066,  0.0088,  ..., -0.0091, -0.0031,  0.0046],
        [ 0.0132,  0.0147, -0.0088,  ...,  0.0116, -0.0110,  0.0037]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.9727, -4.3672,  1.7754,  ..., -3.9844,  0.2260, -1.3604]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 03:01:57 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for In the United Kingdom, the city of hereford is in the county of herefordshire
In the United Kingdom, the city of preston is in the county of lancashire
In the United Kingdom, the city of newcastle is in the county of northumberland
In the United Kingdom, the city of crawley is in the county of sussex
In the United Kingdom, the city of ely is in the county of cambridgeshire
In the United Kingdom, the city of edinburgh is in the county of lowlands
In the United Kingdom, the city of gloucester is in the county of gloucestershire
In the United Kingdom, the city of chester is in the county of
2024-07-29 03:01:57 root INFO     [order_1_approx] starting weight calculation for In the United Kingdom, the city of crawley is in the county of sussex
In the United Kingdom, the city of edinburgh is in the county of lowlands
In the United Kingdom, the city of chester is in the county of cheshire
In the United Kingdom, the city of gloucester is in the county of gloucestershire
In the United Kingdom, the city of newcastle is in the county of northumberland
In the United Kingdom, the city of ely is in the county of cambridgeshire
In the United Kingdom, the city of preston is in the county of lancashire
In the United Kingdom, the city of hereford is in the county of
2024-07-29 03:01:57 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 03:03:52 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.7227, -0.2345,  0.0563,  ..., -0.0559, -0.3582, -0.0737],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.1270, -5.5195,  2.7969,  ..., -3.2695, -0.2793,  0.1729],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0269,  0.0111,  0.0069,  ...,  0.0020, -0.0020, -0.0087],
        [-0.0019,  0.0186,  0.0033,  ...,  0.0096,  0.0006, -0.0010],
        [ 0.0015,  0.0057,  0.0116,  ...,  0.0004, -0.0018, -0.0082],
        ...,
        [ 0.0116,  0.0023, -0.0037,  ...,  0.0339, -0.0024, -0.0003],
        [-0.0207, -0.0149, -0.0019,  ...,  0.0065,  0.0070,  0.0024],
        [ 0.0122,  0.0061, -0.0027,  ..., -0.0052,  0.0019,  0.0175]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.2168, -5.2656,  2.2188,  ..., -3.2832, -0.3386,  0.0485]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 03:03:53 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for In the United Kingdom, the city of crawley is in the county of sussex
In the United Kingdom, the city of edinburgh is in the county of lowlands
In the United Kingdom, the city of chester is in the county of cheshire
In the United Kingdom, the city of gloucester is in the county of gloucestershire
In the United Kingdom, the city of newcastle is in the county of northumberland
In the United Kingdom, the city of ely is in the county of cambridgeshire
In the United Kingdom, the city of preston is in the county of lancashire
In the United Kingdom, the city of hereford is in the county of
2024-07-29 03:03:53 root INFO     [order_1_approx] starting weight calculation for In the United Kingdom, the city of edinburgh is in the county of lowlands
In the United Kingdom, the city of preston is in the county of lancashire
In the United Kingdom, the city of chester is in the county of cheshire
In the United Kingdom, the city of gloucester is in the county of gloucestershire
In the United Kingdom, the city of hereford is in the county of herefordshire
In the United Kingdom, the city of crawley is in the county of sussex
In the United Kingdom, the city of newcastle is in the county of northumberland
In the United Kingdom, the city of ely is in the county of
2024-07-29 03:03:53 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 03:05:48 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.5684, -0.3162, -0.1138,  ..., -0.2700,  0.1499,  0.3857],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.3252, -2.5781,  0.5459,  ..., -4.9570, -1.0322,  0.9736],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0124,  0.0012, -0.0139,  ..., -0.0020, -0.0055, -0.0348],
        [-0.0154,  0.0282, -0.0054,  ...,  0.0053,  0.0043, -0.0095],
        [-0.0205, -0.0308,  0.0643,  ...,  0.0067,  0.0148, -0.0090],
        ...,
        [ 0.0167,  0.0177,  0.0005,  ...,  0.0501, -0.0032, -0.0326],
        [-0.0128, -0.0128,  0.0314,  ...,  0.0139,  0.0304, -0.0232],
        [-0.0064, -0.0117, -0.0043,  ..., -0.0145, -0.0106,  0.0405]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.0742, -2.0430,  0.6182,  ..., -4.5469, -0.3984,  0.7539]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 03:05:49 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for In the United Kingdom, the city of edinburgh is in the county of lowlands
In the United Kingdom, the city of preston is in the county of lancashire
In the United Kingdom, the city of chester is in the county of cheshire
In the United Kingdom, the city of gloucester is in the county of gloucestershire
In the United Kingdom, the city of hereford is in the county of herefordshire
In the United Kingdom, the city of crawley is in the county of sussex
In the United Kingdom, the city of newcastle is in the county of northumberland
In the United Kingdom, the city of ely is in the county of
2024-07-29 03:05:49 root INFO     total operator prediction time: 934.8681817054749 seconds
2024-07-29 03:05:49 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on verb+ment_irreg
2024-07-29 03:05:49 root INFO     building operator verb+ment_irreg
2024-07-29 03:05:50 root INFO     [order_1_approx] starting weight calculation for To resent results in a resentment
To invest results in a investment
To detach results in a detachment
To accomplish results in a accomplishment
To harass results in a harassment
To embarrass results in a embarrassment
To amuse results in a amusement
To involve results in a
2024-07-29 03:05:50 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 03:07:45 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1184, -0.0714,  0.0776,  ..., -0.4736, -1.0811, -0.8867],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.0322, -2.8750,  1.1973,  ...,  2.0508, -0.1104, -3.5273],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0885,  0.0165,  0.0229,  ..., -0.0014,  0.0079,  0.0215],
        [-0.0137,  0.0713,  0.0021,  ...,  0.0241,  0.0168,  0.0036],
        [ 0.0056, -0.0228,  0.0480,  ..., -0.0232, -0.0164, -0.0026],
        ...,
        [ 0.0107,  0.0200, -0.0179,  ...,  0.0944, -0.0168,  0.0065],
        [-0.0016,  0.0087,  0.0184,  ...,  0.0069,  0.0898, -0.0122],
        [ 0.0094,  0.0054, -0.0022,  ...,  0.0046, -0.0168,  0.0815]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.2324, -2.3359,  0.8394,  ...,  2.1797, -0.0913, -2.8164]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 03:07:46 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To resent results in a resentment
To invest results in a investment
To detach results in a detachment
To accomplish results in a accomplishment
To harass results in a harassment
To embarrass results in a embarrassment
To amuse results in a amusement
To involve results in a
2024-07-29 03:07:46 root INFO     [order_1_approx] starting weight calculation for To involve results in a involvement
To amuse results in a amusement
To accomplish results in a accomplishment
To detach results in a detachment
To resent results in a resentment
To embarrass results in a embarrassment
To harass results in a harassment
To invest results in a
2024-07-29 03:07:46 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 03:09:43 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0345, -0.2668, -0.0513,  ..., -0.5972, -0.3765, -0.3511],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.1172, -3.9023, -0.8584,  ...,  0.3159, -1.9238, -2.8945],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 1.0291e-01,  1.0002e-02, -1.7891e-03,  ..., -2.0096e-02,
          1.8463e-03,  6.1188e-03],
        [-1.1795e-02,  6.2500e-02,  1.1436e-02,  ...,  1.8402e-02,
          2.5635e-02,  9.2773e-03],
        [ 3.9330e-03, -3.6201e-03,  6.8604e-02,  ..., -1.3168e-02,
         -7.2174e-03, -8.5449e-03],
        ...,
        [ 4.1962e-05,  2.2995e-02, -5.7755e-03,  ...,  1.0913e-01,
         -3.5782e-03,  7.2479e-05],
        [-7.0724e-03,  4.6768e-03,  1.7212e-02,  ...,  3.8185e-03,
          8.5083e-02, -1.2970e-02],
        [ 9.2316e-03, -5.1384e-03,  4.2953e-03,  ..., -5.5885e-03,
         -5.1804e-03,  9.2163e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.8359, -3.0898, -0.9888,  ...,  0.7217, -1.9941, -2.7617]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 03:09:44 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To involve results in a involvement
To amuse results in a amusement
To accomplish results in a accomplishment
To detach results in a detachment
To resent results in a resentment
To embarrass results in a embarrassment
To harass results in a harassment
To invest results in a
2024-07-29 03:09:44 root INFO     [order_1_approx] starting weight calculation for To embarrass results in a embarrassment
To involve results in a involvement
To amuse results in a amusement
To detach results in a detachment
To resent results in a resentment
To harass results in a harassment
To invest results in a investment
To accomplish results in a
2024-07-29 03:09:44 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 03:11:40 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1671,  0.2986, -0.6719,  ..., -0.3584, -1.4385, -0.2146],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.5234, -3.6328, -0.8691,  ...,  1.4248, -1.5254, -1.6875],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0762,  0.0024, -0.0037,  ..., -0.0111,  0.0078,  0.0009],
        [-0.0002,  0.0845,  0.0120,  ...,  0.0267,  0.0157,  0.0050],
        [ 0.0035, -0.0051,  0.0623,  ..., -0.0083, -0.0098, -0.0169],
        ...,
        [ 0.0057,  0.0163, -0.0100,  ...,  0.1045, -0.0025,  0.0094],
        [-0.0040,  0.0118,  0.0241,  ...,  0.0008,  0.0673, -0.0038],
        [ 0.0085, -0.0060,  0.0001,  ..., -0.0018, -0.0096,  0.0829]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.5000, -3.0703, -0.5732,  ...,  2.0039, -1.6709, -1.5078]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 03:11:41 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To embarrass results in a embarrassment
To involve results in a involvement
To amuse results in a amusement
To detach results in a detachment
To resent results in a resentment
To harass results in a harassment
To invest results in a investment
To accomplish results in a
2024-07-29 03:11:41 root INFO     [order_1_approx] starting weight calculation for To detach results in a detachment
To invest results in a investment
To embarrass results in a embarrassment
To harass results in a harassment
To amuse results in a amusement
To accomplish results in a accomplishment
To involve results in a involvement
To resent results in a
2024-07-29 03:11:41 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 03:13:37 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.9619, -0.5449, -0.9287,  ..., -0.9629, -0.1052, -0.3308],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.9390, -2.4004, -0.7627,  ..., -1.7461, -0.0159, -1.9648],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0876, -0.0110,  0.0003,  ..., -0.0157, -0.0043,  0.0045],
        [-0.0102,  0.0809,  0.0130,  ...,  0.0211,  0.0171, -0.0009],
        [ 0.0005, -0.0013,  0.0659,  ..., -0.0088, -0.0040, -0.0147],
        ...,
        [ 0.0034,  0.0327,  0.0080,  ...,  0.0946,  0.0009,  0.0046],
        [ 0.0009,  0.0097,  0.0079,  ...,  0.0062,  0.0810, -0.0093],
        [ 0.0023,  0.0018, -0.0135,  ...,  0.0032, -0.0177,  0.0854]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.6045, -1.9521, -0.7710,  ..., -1.2773,  0.1499, -2.3555]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 03:13:45 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To detach results in a detachment
To invest results in a investment
To embarrass results in a embarrassment
To harass results in a harassment
To amuse results in a amusement
To accomplish results in a accomplishment
To involve results in a involvement
To resent results in a
2024-07-29 03:13:45 root INFO     [order_1_approx] starting weight calculation for To invest results in a investment
To harass results in a harassment
To amuse results in a amusement
To involve results in a involvement
To resent results in a resentment
To detach results in a detachment
To accomplish results in a accomplishment
To embarrass results in a
2024-07-29 03:13:45 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 03:15:40 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.9131,  0.2998, -0.5659,  ..., -0.5122, -0.4548,  0.5464],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.1484, -1.1943,  0.6938,  ...,  2.1680,  2.5391, -2.6230],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0645, -0.0027,  0.0054,  ..., -0.0032, -0.0011,  0.0021],
        [ 0.0071,  0.0505,  0.0056,  ...,  0.0199,  0.0115, -0.0022],
        [-0.0026, -0.0099,  0.0430,  ..., -0.0094, -0.0034, -0.0013],
        ...,
        [ 0.0123,  0.0129, -0.0068,  ...,  0.0715, -0.0045,  0.0015],
        [ 0.0068,  0.0038,  0.0045,  ...,  0.0019,  0.0471, -0.0090],
        [ 0.0057,  0.0026,  0.0021,  ...,  0.0028, -0.0090,  0.0633]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.1113, -1.1367,  0.6558,  ...,  2.3125,  2.2344, -2.6406]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 03:15:41 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To invest results in a investment
To harass results in a harassment
To amuse results in a amusement
To involve results in a involvement
To resent results in a resentment
To detach results in a detachment
To accomplish results in a accomplishment
To embarrass results in a
2024-07-29 03:15:41 root INFO     [order_1_approx] starting weight calculation for To involve results in a involvement
To accomplish results in a accomplishment
To harass results in a harassment
To detach results in a detachment
To embarrass results in a embarrassment
To invest results in a investment
To resent results in a resentment
To amuse results in a
2024-07-29 03:15:41 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 03:17:37 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0321,  0.5825,  0.1051,  ..., -0.4756, -0.8525,  0.3220],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.1660, -1.6738,  1.5430,  ...,  2.2988,  0.4336, -1.6436],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0679,  0.0065,  0.0206,  ..., -0.0108,  0.0109,  0.0045],
        [-0.0125,  0.0535,  0.0072,  ...,  0.0254,  0.0140,  0.0081],
        [-0.0061, -0.0112,  0.0515,  ..., -0.0121, -0.0103, -0.0115],
        ...,
        [ 0.0105,  0.0038, -0.0079,  ...,  0.0798, -0.0059,  0.0019],
        [ 0.0083,  0.0105,  0.0058,  ..., -0.0043,  0.0514, -0.0065],
        [ 0.0078,  0.0071, -0.0014,  ...,  0.0045, -0.0060,  0.0693]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.0977, -1.3975,  1.2871,  ...,  2.3301,  0.6489, -1.5898]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 03:17:38 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To involve results in a involvement
To accomplish results in a accomplishment
To harass results in a harassment
To detach results in a detachment
To embarrass results in a embarrassment
To invest results in a investment
To resent results in a resentment
To amuse results in a
2024-07-29 03:17:38 root INFO     [order_1_approx] starting weight calculation for To amuse results in a amusement
To detach results in a detachment
To resent results in a resentment
To embarrass results in a embarrassment
To involve results in a involvement
To accomplish results in a accomplishment
To invest results in a investment
To harass results in a
2024-07-29 03:17:38 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 03:19:34 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1782, -0.3604, -0.6855,  ..., -0.5371, -0.9043, -0.2020],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.5059, -3.0762, -0.8286,  ..., -0.2822,  0.8013, -1.9902],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0776, -0.0108,  0.0047,  ..., -0.0089, -0.0061, -0.0066],
        [-0.0037,  0.0616,  0.0082,  ...,  0.0233,  0.0127,  0.0011],
        [ 0.0017, -0.0061,  0.0526,  ..., -0.0097, -0.0010, -0.0076],
        ...,
        [ 0.0016,  0.0162, -0.0023,  ...,  0.0848,  0.0042,  0.0037],
        [ 0.0075,  0.0146,  0.0080,  ...,  0.0118,  0.0654, -0.0099],
        [ 0.0076,  0.0055, -0.0053,  ...,  0.0063, -0.0050,  0.0677]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.2959, -2.6387, -0.7720,  ..., -0.0607,  0.8369, -1.9014]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 03:19:35 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To amuse results in a amusement
To detach results in a detachment
To resent results in a resentment
To embarrass results in a embarrassment
To involve results in a involvement
To accomplish results in a accomplishment
To invest results in a investment
To harass results in a
2024-07-29 03:19:35 root INFO     [order_1_approx] starting weight calculation for To involve results in a involvement
To resent results in a resentment
To accomplish results in a accomplishment
To invest results in a investment
To embarrass results in a embarrassment
To amuse results in a amusement
To harass results in a harassment
To detach results in a
2024-07-29 03:19:35 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 03:21:30 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-2.4170e-01, -3.7598e-01, -6.1035e-04,  ..., -2.3657e-01,
        -9.7168e-01, -1.1774e-01], device='cuda:1', dtype=torch.float16,
       grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.1367, -3.1250,  0.4170,  ...,  1.5654, -1.3281, -2.3086],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0839,  0.0092,  0.0103,  ..., -0.0013,  0.0113,  0.0061],
        [-0.0044,  0.0637,  0.0057,  ...,  0.0036,  0.0097,  0.0064],
        [ 0.0023, -0.0095,  0.0676,  ..., -0.0026, -0.0028, -0.0106],
        ...,
        [ 0.0085,  0.0058, -0.0063,  ...,  0.0884, -0.0063,  0.0025],
        [ 0.0002, -0.0030,  0.0041,  ...,  0.0090,  0.0673, -0.0041],
        [ 0.0040,  0.0100, -0.0037,  ..., -0.0049, -0.0114,  0.0804]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.2871, -3.0664,  0.5742,  ...,  1.5762, -1.3184, -2.0801]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 03:21:32 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To involve results in a involvement
To resent results in a resentment
To accomplish results in a accomplishment
To invest results in a investment
To embarrass results in a embarrassment
To amuse results in a amusement
To harass results in a harassment
To detach results in a
2024-07-29 03:21:32 root INFO     total operator prediction time: 942.1426310539246 seconds
2024-07-29 03:21:32 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on noun+less_reg
2024-07-29 03:21:32 root INFO     building operator noun+less_reg
2024-07-29 03:21:32 root INFO     [order_1_approx] starting weight calculation for Something without guilt is guiltless
Something without breath is breathless
Something without talent is talentless
Something without arm is armless
Something without thought is thoughtless
Something without spine is spineless
Something without art is artless
Something without path is
2024-07-29 03:21:32 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 03:23:28 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4111, -0.5464, -0.0503,  ..., -0.6870, -0.2571, -0.0803],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 5.0117, -4.8242, -3.2285,  ..., -0.7773, -3.9902, -1.1641],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0743,  0.0042,  0.0104,  ...,  0.0030,  0.0042, -0.0033],
        [-0.0214,  0.0341, -0.0112,  ...,  0.0137,  0.0082, -0.0016],
        [ 0.0139, -0.0210,  0.0566,  ...,  0.0031,  0.0011, -0.0065],
        ...,
        [-0.0053,  0.0159, -0.0088,  ...,  0.0385, -0.0048, -0.0014],
        [ 0.0026,  0.0023,  0.0011,  ..., -0.0104,  0.0551, -0.0177],
        [-0.0073,  0.0065, -0.0067,  ..., -0.0067, -0.0177,  0.0472]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.5625, -4.1914, -3.4648,  ..., -0.8350, -3.7227, -0.9868]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 03:23:29 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Something without guilt is guiltless
Something without breath is breathless
Something without talent is talentless
Something without arm is armless
Something without thought is thoughtless
Something without spine is spineless
Something without art is artless
Something without path is
2024-07-29 03:23:29 root INFO     [order_1_approx] starting weight calculation for Something without path is pathless
Something without breath is breathless
Something without spine is spineless
Something without arm is armless
Something without art is artless
Something without thought is thoughtless
Something without talent is talentless
Something without guilt is
2024-07-29 03:23:29 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 03:25:23 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1299, -0.0637, -0.5317,  ..., -0.1401, -0.3418,  0.1023],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.5430, -2.3965,  1.5391,  ..., -2.7168, -1.9697, -1.7041],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0530, -0.0118,  0.0081,  ...,  0.0092, -0.0016,  0.0068],
        [-0.0053,  0.0455, -0.0069,  ...,  0.0026,  0.0024, -0.0107],
        [ 0.0164, -0.0109,  0.0562,  ..., -0.0106, -0.0071, -0.0022],
        ...,
        [-0.0037,  0.0181, -0.0130,  ...,  0.0591,  0.0048, -0.0108],
        [ 0.0090,  0.0117,  0.0041,  ..., -0.0142,  0.0466, -0.0126],
        [ 0.0097,  0.0019, -0.0071,  ..., -0.0066, -0.0033,  0.0523]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.2637, -2.3242,  1.2539,  ..., -2.4141, -2.3184, -1.7422]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 03:25:24 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Something without path is pathless
Something without breath is breathless
Something without spine is spineless
Something without arm is armless
Something without art is artless
Something without thought is thoughtless
Something without talent is talentless
Something without guilt is
2024-07-29 03:25:24 root INFO     [order_1_approx] starting weight calculation for Something without spine is spineless
Something without talent is talentless
Something without thought is thoughtless
Something without arm is armless
Something without guilt is guiltless
Something without breath is breathless
Something without path is pathless
Something without art is
2024-07-29 03:25:24 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 03:27:21 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4417, -0.6484,  0.0568,  ..., -1.2041, -0.3901, -0.0822],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.4199, -3.4844, -0.5957,  ..., -2.1777, -3.8516, -0.3311],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0360, -0.0078,  0.0064,  ...,  0.0022,  0.0091,  0.0075],
        [ 0.0021,  0.0456, -0.0012,  ...,  0.0030,  0.0040, -0.0003],
        [ 0.0101, -0.0070,  0.0394,  ...,  0.0110, -0.0150, -0.0083],
        ...,
        [ 0.0026,  0.0230, -0.0088,  ...,  0.0358, -0.0011, -0.0037],
        [ 0.0146, -0.0010,  0.0100,  ..., -0.0039,  0.0325, -0.0142],
        [ 0.0017,  0.0049, -0.0010,  ..., -0.0010,  0.0024,  0.0405]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.5820, -3.3730, -0.9873,  ..., -2.0098, -4.0312, -0.3794]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 03:27:22 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Something without spine is spineless
Something without talent is talentless
Something without thought is thoughtless
Something without arm is armless
Something without guilt is guiltless
Something without breath is breathless
Something without path is pathless
Something without art is
2024-07-29 03:27:22 root INFO     [order_1_approx] starting weight calculation for Something without talent is talentless
Something without path is pathless
Something without breath is breathless
Something without spine is spineless
Something without art is artless
Something without thought is thoughtless
Something without guilt is guiltless
Something without arm is
2024-07-29 03:27:22 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 03:29:18 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0403, -0.6230,  0.5225,  ..., -0.5845, -0.1399, -0.2074],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.1055, -4.9453, -1.9531,  ..., -1.6055, -2.5293, -2.3926],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0571, -0.0104,  0.0021,  ...,  0.0117,  0.0063, -0.0016],
        [-0.0005,  0.0466, -0.0078,  ..., -0.0083,  0.0075,  0.0028],
        [ 0.0122, -0.0010,  0.0449,  ..., -0.0072,  0.0086, -0.0009],
        ...,
        [-0.0098,  0.0125, -0.0058,  ...,  0.0448, -0.0005, -0.0066],
        [ 0.0009, -0.0012,  0.0038,  ...,  0.0002,  0.0325, -0.0157],
        [-0.0033,  0.0080, -0.0088,  ..., -0.0040,  0.0081,  0.0379]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.2246, -4.3516, -2.0176,  ..., -1.1309, -2.8848, -2.2344]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 03:29:19 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Something without talent is talentless
Something without path is pathless
Something without breath is breathless
Something without spine is spineless
Something without art is artless
Something without thought is thoughtless
Something without guilt is guiltless
Something without arm is
2024-07-29 03:29:20 root INFO     [order_1_approx] starting weight calculation for Something without thought is thoughtless
Something without arm is armless
Something without guilt is guiltless
Something without path is pathless
Something without breath is breathless
Something without spine is spineless
Something without art is artless
Something without talent is
2024-07-29 03:29:20 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 03:31:11 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.8037, -0.7031,  0.0140,  ..., -1.1602,  0.1014, -0.2466],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.0254, -1.2920,  0.7031,  ..., -3.8906, -4.0898, -2.2832],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 4.3610e-02, -8.7509e-03,  1.3855e-02,  ..., -2.6703e-05,
          1.6602e-02,  7.0801e-03],
        [ 7.1106e-03,  3.2959e-02, -3.0670e-03,  ...,  1.1719e-02,
         -2.6398e-03,  5.6267e-04],
        [ 8.1253e-03,  3.1853e-03,  3.9124e-02,  ...,  8.2397e-03,
          2.0504e-03, -4.8523e-03],
        ...,
        [-1.0696e-02,  1.1215e-02, -1.0042e-03,  ...,  3.3142e-02,
         -1.7242e-03, -1.0910e-02],
        [ 5.0278e-03,  1.2711e-02,  9.8801e-03,  ..., -1.1986e-02,
          3.7109e-02, -1.3840e-02],
        [ 8.2855e-03, -4.7302e-04,  2.0075e-04,  ..., -1.1208e-02,
         -3.8414e-03,  3.9398e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.8340, -1.1650,  0.5513,  ..., -3.5430, -4.2188, -2.0781]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 03:31:12 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Something without thought is thoughtless
Something without arm is armless
Something without guilt is guiltless
Something without path is pathless
Something without breath is breathless
Something without spine is spineless
Something without art is artless
Something without talent is
2024-07-29 03:31:12 root INFO     [order_1_approx] starting weight calculation for Something without spine is spineless
Something without guilt is guiltless
Something without art is artless
Something without talent is talentless
Something without thought is thoughtless
Something without path is pathless
Something without arm is armless
Something without breath is
2024-07-29 03:31:13 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 03:33:08 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3369, -0.5039, -0.0869,  ..., -0.6504, -0.1029,  0.0271],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.1523, -5.0859,  0.2419,  ..., -2.2988, -2.7520, -1.1748],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 3.0838e-02, -8.1940e-03,  3.7050e-04,  ...,  5.3558e-03,
          1.4210e-03,  5.5008e-03],
        [ 2.3079e-03,  2.8503e-02,  4.6844e-03,  ...,  8.9073e-04,
         -3.5524e-05,  5.7755e-03],
        [ 6.3057e-03,  1.9073e-03,  2.8244e-02,  ..., -9.3460e-03,
         -9.7656e-04,  6.8665e-04],
        ...,
        [ 7.0953e-04,  1.6022e-02, -6.1798e-03,  ...,  2.2995e-02,
         -1.7281e-03, -1.8860e-02],
        [ 8.8043e-03,  8.5373e-03,  4.0436e-03,  ..., -1.2222e-02,
          1.8448e-02, -4.2534e-03],
        [ 1.7529e-03,  1.1505e-02,  2.3842e-05,  ..., -1.3466e-03,
         -9.9030e-03,  1.8906e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.9629, -4.8477, -0.1416,  ..., -2.1855, -3.0742, -1.5420]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 03:33:09 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Something without spine is spineless
Something without guilt is guiltless
Something without art is artless
Something without talent is talentless
Something without thought is thoughtless
Something without path is pathless
Something without arm is armless
Something without breath is
2024-07-29 03:33:09 root INFO     [order_1_approx] starting weight calculation for Something without art is artless
Something without path is pathless
Something without breath is breathless
Something without talent is talentless
Something without spine is spineless
Something without guilt is guiltless
Something without arm is armless
Something without thought is
2024-07-29 03:33:09 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 03:35:03 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1573, -0.3818,  0.9072,  ..., -0.9209, -0.2261, -0.0787],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.8750, -2.2500,  1.4453,  ..., -2.2891, -3.8008,  0.0820],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0383,  0.0053, -0.0046,  ..., -0.0084,  0.0061, -0.0016],
        [ 0.0076,  0.0296, -0.0011,  ...,  0.0131, -0.0074, -0.0056],
        [ 0.0184, -0.0084,  0.0437,  ..., -0.0107, -0.0041,  0.0016],
        ...,
        [ 0.0053,  0.0123, -0.0074,  ...,  0.0441, -0.0101,  0.0086],
        [ 0.0049,  0.0117,  0.0043,  ..., -0.0125,  0.0409, -0.0117],
        [ 0.0074,  0.0064, -0.0015,  ...,  0.0076, -0.0114,  0.0415]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.7402e+00, -2.3066e+00,  5.9375e-01,  ..., -2.0625e+00,
         -3.5449e+00, -3.0518e-03]], device='cuda:1', dtype=torch.float16,
       grad_fn=<SubBackward0>) 

                    
2024-07-29 03:35:03 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Something without art is artless
Something without path is pathless
Something without breath is breathless
Something without talent is talentless
Something without spine is spineless
Something without guilt is guiltless
Something without arm is armless
Something without thought is
2024-07-29 03:35:04 root INFO     [order_1_approx] starting weight calculation for Something without arm is armless
Something without path is pathless
Something without talent is talentless
Something without thought is thoughtless
Something without guilt is guiltless
Something without breath is breathless
Something without art is artless
Something without spine is
2024-07-29 03:35:04 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 03:36:56 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.5503, -0.6089, -0.7705,  ..., -0.0588, -0.3479, -0.3904],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.1914, -3.0391, -1.3555,  ..., -2.2109, -2.8945, -1.0840],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 6.2073e-02, -5.0278e-03,  1.5358e-02,  ...,  1.0590e-02,
          2.0203e-02,  3.2806e-04],
        [ 1.3885e-02,  5.2368e-02, -3.2234e-03,  ...,  1.0551e-02,
          1.6022e-02,  6.1378e-03],
        [ 1.8692e-02,  4.6463e-03,  5.2795e-02,  ...,  4.6272e-03,
          1.3752e-03, -4.9782e-03],
        ...,
        [ 1.5686e-02,  1.7731e-02,  4.5929e-03,  ...,  6.1279e-02,
          1.2512e-02, -2.0733e-03],
        [ 1.0956e-02,  2.4826e-02,  6.4621e-03,  ..., -1.4046e-02,
          5.9631e-02, -1.4053e-02],
        [-2.8877e-03,  2.8133e-05, -6.0234e-03,  ..., -4.4785e-03,
         -7.0114e-03,  4.5746e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.2695, -2.9707, -1.4072,  ..., -1.8477, -3.2344, -0.6416]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 03:36:57 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Something without arm is armless
Something without path is pathless
Something without talent is talentless
Something without thought is thoughtless
Something without guilt is guiltless
Something without breath is breathless
Something without art is artless
Something without spine is
2024-07-29 03:36:57 root INFO     total operator prediction time: 925.1030669212341 seconds
2024-07-29 03:36:57 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on adj+ness_reg
2024-07-29 03:36:57 root INFO     building operator adj+ness_reg
2024-07-29 03:36:57 root INFO     [order_1_approx] starting weight calculation for The state of being happy is happiness
The state of being random is randomness
The state of being creative is creativeness
The state of being prepared is preparedness
The state of being innovative is innovativeness
The state of being situated is situatedness
The state of being hidden is hiddenness
The state of being marked is
2024-07-29 03:36:57 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 03:38:53 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1697,  0.4761, -0.7100,  ...,  0.6025, -0.4043, -0.0359],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.9990, -2.1348, -1.7520,  ..., -3.1230, -1.2734, -1.7910],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 1.0797e-01,  7.1259e-03, -1.2207e-04,  ..., -1.6342e-02,
         -9.7036e-04,  1.7288e-02],
        [-1.2560e-03,  8.9600e-02, -4.4174e-03,  ...,  3.9124e-02,
          3.1860e-02, -2.4658e-02],
        [-3.3264e-03, -3.1250e-02,  8.0811e-02,  ..., -1.5350e-02,
          1.2367e-02, -9.4891e-05],
        ...,
        [ 1.4793e-02,  2.0630e-02,  7.7972e-03,  ...,  1.2335e-01,
         -9.2621e-03,  3.4542e-03],
        [-1.4420e-03, -4.8256e-03,  9.3460e-03,  ..., -1.9592e-02,
          1.0022e-01, -5.6000e-03],
        [-3.4561e-03,  1.5198e-02, -7.9498e-03,  ...,  2.7893e-02,
         -1.2436e-02,  8.9417e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.6738, -1.6914, -1.6025,  ..., -2.9609, -1.2764, -1.1533]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 03:38:54 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The state of being happy is happiness
The state of being random is randomness
The state of being creative is creativeness
The state of being prepared is preparedness
The state of being innovative is innovativeness
The state of being situated is situatedness
The state of being hidden is hiddenness
The state of being marked is
2024-07-29 03:38:54 root INFO     [order_1_approx] starting weight calculation for The state of being random is randomness
The state of being creative is creativeness
The state of being situated is situatedness
The state of being hidden is hiddenness
The state of being marked is markedness
The state of being happy is happiness
The state of being innovative is innovativeness
The state of being prepared is
2024-07-29 03:38:54 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 03:40:44 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2261, -0.6611, -0.2861,  ..., -0.8569, -0.3892,  0.3047],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.6484, -5.1328, -1.2959,  ...,  0.7988, -2.0938, -2.5137],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.1017, -0.0063,  0.0053,  ..., -0.0024, -0.0060,  0.0129],
        [-0.0028,  0.0796, -0.0045,  ...,  0.0189,  0.0024,  0.0016],
        [ 0.0015, -0.0149,  0.0784,  ...,  0.0116,  0.0051,  0.0026],
        ...,
        [ 0.0006,  0.0163, -0.0101,  ...,  0.0876, -0.0056,  0.0063],
        [ 0.0265,  0.0008,  0.0163,  ..., -0.0115,  0.0966, -0.0107],
        [ 0.0034,  0.0047, -0.0068,  ..., -0.0060,  0.0043,  0.0903]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.9062, -5.1758, -1.4727,  ...,  0.5410, -2.5020, -2.3535]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 03:40:45 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The state of being random is randomness
The state of being creative is creativeness
The state of being situated is situatedness
The state of being hidden is hiddenness
The state of being marked is markedness
The state of being happy is happiness
The state of being innovative is innovativeness
The state of being prepared is
2024-07-29 03:40:46 root INFO     [order_1_approx] starting weight calculation for The state of being prepared is preparedness
The state of being random is randomness
The state of being happy is happiness
The state of being innovative is innovativeness
The state of being marked is markedness
The state of being creative is creativeness
The state of being situated is situatedness
The state of being hidden is
2024-07-29 03:40:46 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 03:42:41 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1455, -0.3577,  0.3579,  ..., -0.8174,  0.0509, -0.0389],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-2.7188, -0.3652,  0.8271,  ..., -1.8594, -3.1680,  0.1504],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0757,  0.0094,  0.0050,  ..., -0.0020, -0.0043,  0.0058],
        [-0.0097,  0.0545,  0.0026,  ...,  0.0138,  0.0056, -0.0117],
        [ 0.0004, -0.0181,  0.0702,  ..., -0.0005, -0.0017,  0.0006],
        ...,
        [-0.0013,  0.0159, -0.0094,  ...,  0.0663, -0.0055,  0.0136],
        [ 0.0061,  0.0041,  0.0019,  ..., -0.0072,  0.0606, -0.0021],
        [-0.0047, -0.0016, -0.0099,  ..., -0.0035, -0.0095,  0.0753]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-2.5918, -0.4685,  0.6113,  ..., -1.9512, -3.3047,  0.1354]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 03:42:42 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The state of being prepared is preparedness
The state of being random is randomness
The state of being happy is happiness
The state of being innovative is innovativeness
The state of being marked is markedness
The state of being creative is creativeness
The state of being situated is situatedness
The state of being hidden is
2024-07-29 03:42:43 root INFO     [order_1_approx] starting weight calculation for The state of being prepared is preparedness
The state of being hidden is hiddenness
The state of being creative is creativeness
The state of being marked is markedness
The state of being situated is situatedness
The state of being random is randomness
The state of being happy is happiness
The state of being innovative is
2024-07-29 03:42:43 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 03:44:38 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1692, -0.6436,  0.4773,  ..., -0.3469, -0.6465, -0.1635],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.3518, -2.1484, -0.0249,  ...,  1.4043, -0.8965, -1.9902],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 5.9326e-02,  8.8215e-05,  1.2550e-02,  ..., -3.8967e-03,
         -8.3256e-04,  1.5839e-02],
        [-1.0788e-02,  5.9113e-02,  3.4523e-04,  ...,  1.1932e-02,
          1.6846e-02, -1.0605e-02],
        [-2.6779e-03, -1.3489e-02,  6.2744e-02,  ..., -8.5754e-03,
          9.4414e-05,  3.6430e-04],
        ...,
        [ 9.0485e-03,  1.1505e-02, -1.0290e-03,  ...,  6.2256e-02,
         -3.8853e-03,  8.5602e-03],
        [ 1.8585e-02,  1.0262e-02,  6.7024e-03,  ...,  3.0499e-03,
          5.5084e-02, -1.2062e-02],
        [ 1.0506e-02, -1.0735e-02, -3.8147e-03,  ...,  1.6060e-03,
         -1.5518e-02,  5.4230e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.2905, -2.1934, -0.0045,  ...,  1.4883, -1.0303, -1.8477]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 03:44:39 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The state of being prepared is preparedness
The state of being hidden is hiddenness
The state of being creative is creativeness
The state of being marked is markedness
The state of being situated is situatedness
The state of being random is randomness
The state of being happy is happiness
The state of being innovative is
2024-07-29 03:44:39 root INFO     [order_1_approx] starting weight calculation for The state of being situated is situatedness
The state of being innovative is innovativeness
The state of being happy is happiness
The state of being hidden is hiddenness
The state of being marked is markedness
The state of being prepared is preparedness
The state of being creative is creativeness
The state of being random is
2024-07-29 03:44:39 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 03:46:34 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.7563,  0.3440, -0.4370,  ...,  0.0704, -0.4746, -0.3423],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.2988, -2.1797, -1.7344,  ..., -1.0762, -3.3008, -4.6719],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0844,  0.0141,  0.0033,  ..., -0.0040,  0.0029,  0.0080],
        [-0.0035,  0.0562,  0.0093,  ...,  0.0354,  0.0119,  0.0012],
        [ 0.0119, -0.0175,  0.0804,  ..., -0.0134,  0.0051, -0.0088],
        ...,
        [ 0.0008,  0.0092,  0.0023,  ...,  0.0660, -0.0052,  0.0148],
        [ 0.0208,  0.0173, -0.0025,  ..., -0.0129,  0.0728, -0.0085],
        [ 0.0038, -0.0012, -0.0019,  ..., -0.0138, -0.0131,  0.0687]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.1426, -2.1680, -1.2930,  ..., -1.2764, -3.3574, -4.6875]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 03:46:36 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The state of being situated is situatedness
The state of being innovative is innovativeness
The state of being happy is happiness
The state of being hidden is hiddenness
The state of being marked is markedness
The state of being prepared is preparedness
The state of being creative is creativeness
The state of being random is
2024-07-29 03:46:36 root INFO     [order_1_approx] starting weight calculation for The state of being situated is situatedness
The state of being happy is happiness
The state of being random is randomness
The state of being prepared is preparedness
The state of being hidden is hiddenness
The state of being marked is markedness
The state of being innovative is innovativeness
The state of being creative is
2024-07-29 03:46:36 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 03:48:28 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3618, -0.4199,  1.2354,  ..., -0.9756, -0.0443,  0.1688],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.2866, -3.6016,  1.6895,  ...,  0.7119, -1.1621,  0.3486],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0451,  0.0030,  0.0113,  ..., -0.0035, -0.0077,  0.0169],
        [ 0.0038,  0.0334,  0.0081,  ...,  0.0254,  0.0154,  0.0020],
        [ 0.0068, -0.0064,  0.0374,  ..., -0.0016, -0.0024, -0.0035],
        ...,
        [ 0.0095,  0.0077, -0.0004,  ...,  0.0329, -0.0027, -0.0003],
        [ 0.0164,  0.0086, -0.0019,  ..., -0.0147,  0.0374, -0.0067],
        [ 0.0064, -0.0012, -0.0153,  ..., -0.0011, -0.0020,  0.0316]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.2974, -3.5957,  1.5439,  ...,  0.8672, -1.4521,  0.4705]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 03:48:29 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The state of being situated is situatedness
The state of being happy is happiness
The state of being random is randomness
The state of being prepared is preparedness
The state of being hidden is hiddenness
The state of being marked is markedness
The state of being innovative is innovativeness
The state of being creative is
2024-07-29 03:48:29 root INFO     [order_1_approx] starting weight calculation for The state of being creative is creativeness
The state of being situated is situatedness
The state of being hidden is hiddenness
The state of being innovative is innovativeness
The state of being prepared is preparedness
The state of being random is randomness
The state of being marked is markedness
The state of being happy is
2024-07-29 03:48:29 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 03:50:19 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0203, -0.7715,  0.4758,  ..., -0.6021, -0.7607, -0.1232],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.6270,  0.3049,  1.7852,  ..., -1.3330, -5.1875, -1.7939],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0687, -0.0026,  0.0067,  ...,  0.0058,  0.0151,  0.0066],
        [-0.0050,  0.0612, -0.0080,  ..., -0.0014, -0.0010,  0.0036],
        [ 0.0012, -0.0188,  0.0588,  ...,  0.0073,  0.0028, -0.0090],
        ...,
        [ 0.0063,  0.0098,  0.0038,  ...,  0.0580, -0.0104,  0.0093],
        [ 0.0077,  0.0004,  0.0048,  ...,  0.0030,  0.0458, -0.0148],
        [ 0.0025,  0.0035, -0.0103,  ...,  0.0094, -0.0149,  0.0636]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.7617,  0.1378,  1.6406,  ..., -1.1211, -5.3945, -2.1562]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 03:50:20 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The state of being creative is creativeness
The state of being situated is situatedness
The state of being hidden is hiddenness
The state of being innovative is innovativeness
The state of being prepared is preparedness
The state of being random is randomness
The state of being marked is markedness
The state of being happy is
2024-07-29 03:50:20 root INFO     [order_1_approx] starting weight calculation for The state of being happy is happiness
The state of being prepared is preparedness
The state of being innovative is innovativeness
The state of being marked is markedness
The state of being hidden is hiddenness
The state of being random is randomness
The state of being creative is creativeness
The state of being situated is
2024-07-29 03:50:21 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 03:52:12 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.5747,  0.2411, -0.4060,  ..., -0.1836, -1.2305, -0.3193],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.7148, -3.3867, -0.4482,  ..., -2.5840, -3.5781, -2.6836],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.1132,  0.0055,  0.0039,  ...,  0.0050,  0.0137,  0.0091],
        [ 0.0079,  0.0810, -0.0004,  ...,  0.0306, -0.0189, -0.0022],
        [-0.0033, -0.0231,  0.0620,  ..., -0.0184, -0.0074,  0.0021],
        ...,
        [ 0.0069,  0.0248,  0.0035,  ...,  0.0999, -0.0134,  0.0203],
        [-0.0106,  0.0018,  0.0026,  ..., -0.0173,  0.1176, -0.0241],
        [ 0.0131,  0.0216,  0.0100,  ...,  0.0220, -0.0410,  0.0960]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.4648, -2.9434, -0.6440,  ..., -2.4824, -3.8008, -2.6895]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 03:52:13 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The state of being happy is happiness
The state of being prepared is preparedness
The state of being innovative is innovativeness
The state of being marked is markedness
The state of being hidden is hiddenness
The state of being random is randomness
The state of being creative is creativeness
The state of being situated is
2024-07-29 03:52:13 root INFO     total operator prediction time: 916.6833930015564 seconds
2024-07-29 03:52:13 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on re+verb_reg
2024-07-29 03:52:13 root INFO     building operator re+verb_reg
2024-07-29 03:52:14 root INFO     [order_1_approx] starting weight calculation for To assign again is to reassign
To learn again is to relearn
To decorate again is to redecorate
To tell again is to retell
To write again is to rewrite
To appoint again is to reappoint
To publish again is to republish
To create again is to
2024-07-29 03:52:14 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 03:54:02 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0746, -0.0164,  0.0807,  ...,  0.1370, -0.9043,  0.0320],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.9287, -4.8008,  1.4092,  ...,  2.6777, -3.6758, -0.7725],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0643, -0.0220,  0.0194,  ...,  0.0044, -0.0028,  0.0241],
        [-0.0022,  0.0721, -0.0068,  ...,  0.0283,  0.0104, -0.0036],
        [ 0.0114, -0.0002,  0.0822,  ..., -0.0094,  0.0166, -0.0023],
        ...,
        [ 0.0088,  0.0114, -0.0032,  ...,  0.0704, -0.0108, -0.0148],
        [ 0.0127,  0.0132,  0.0168,  ..., -0.0105,  0.0629, -0.0245],
        [-0.0076,  0.0030, -0.0210,  ..., -0.0236, -0.0113,  0.0559]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.6865, -4.8047,  1.4453,  ...,  2.8281, -3.9121, -0.7710]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 03:54:03 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To assign again is to reassign
To learn again is to relearn
To decorate again is to redecorate
To tell again is to retell
To write again is to rewrite
To appoint again is to reappoint
To publish again is to republish
To create again is to
2024-07-29 03:54:03 root INFO     [order_1_approx] starting weight calculation for To tell again is to retell
To publish again is to republish
To create again is to recreate
To write again is to rewrite
To decorate again is to redecorate
To assign again is to reassign
To learn again is to relearn
To appoint again is to
2024-07-29 03:54:03 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 03:55:59 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0396, -0.3030, -0.3369,  ...,  0.1526, -0.8052,  0.0671],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.2793, -4.1914, -0.1656,  ...,  3.2422, -4.6055, -4.0625],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 6.2469e-02, -1.0147e-02,  7.7362e-03,  ..., -2.6665e-03,
          6.5327e-04,  5.8594e-03],
        [ 2.8839e-03,  4.3457e-02, -3.7937e-03,  ...,  1.8890e-02,
         -1.5984e-03, -5.9586e-03],
        [ 5.3482e-03,  4.2419e-03,  5.1392e-02,  ..., -9.8724e-03,
         -5.2299e-03,  1.0405e-03],
        ...,
        [ 1.2032e-02,  7.7782e-03, -7.6981e-03,  ...,  6.7261e-02,
         -6.2943e-03,  1.0010e-02],
        [-2.7485e-03,  8.7585e-03,  1.8091e-03,  ...,  2.5272e-05,
          4.2145e-02, -1.9852e-02],
        [ 9.7885e-03,  4.1733e-03, -1.4839e-02,  ..., -5.9814e-03,
         -9.9335e-03,  5.7312e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.1797, -4.0742, -0.0751,  ...,  3.1836, -4.3867, -3.9648]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 03:56:00 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To tell again is to retell
To publish again is to republish
To create again is to recreate
To write again is to rewrite
To decorate again is to redecorate
To assign again is to reassign
To learn again is to relearn
To appoint again is to
2024-07-29 03:56:00 root INFO     [order_1_approx] starting weight calculation for To appoint again is to reappoint
To tell again is to retell
To write again is to rewrite
To publish again is to republish
To decorate again is to redecorate
To create again is to recreate
To assign again is to reassign
To learn again is to
2024-07-29 03:56:00 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 03:57:55 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.5400, -0.6572,  0.0970,  ..., -0.3733, -0.7500,  0.2688],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.9087, -2.7422,  0.2998,  ...,  3.2344, -3.3281, -4.2344],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 4.0924e-02, -7.2060e-03,  4.7150e-03,  ...,  4.2763e-03,
          8.0490e-03,  1.4633e-02],
        [ 1.4019e-03,  3.6987e-02, -1.0399e-02,  ...,  9.1858e-03,
         -3.3379e-03,  3.3226e-03],
        [-3.3283e-03, -6.1722e-03,  4.9866e-02,  ..., -2.6073e-03,
          8.8024e-04, -1.9913e-03],
        ...,
        [ 1.5602e-02,  2.7161e-03, -5.9509e-03,  ...,  5.4016e-02,
         -3.5038e-03, -6.3705e-03],
        [ 5.9929e-03,  2.3041e-03,  5.9624e-03,  ...,  1.1169e-02,
          3.4546e-02, -5.2490e-03],
        [-8.3771e-03,  7.5302e-03, -4.1962e-05,  ..., -1.2932e-03,
         -5.7030e-03,  4.6478e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.9810, -2.8633,  0.3687,  ...,  3.2656, -3.4297, -4.0000]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 03:57:56 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To appoint again is to reappoint
To tell again is to retell
To write again is to rewrite
To publish again is to republish
To decorate again is to redecorate
To create again is to recreate
To assign again is to reassign
To learn again is to
2024-07-29 03:57:56 root INFO     [order_1_approx] starting weight calculation for To assign again is to reassign
To learn again is to relearn
To publish again is to republish
To tell again is to retell
To create again is to recreate
To appoint again is to reappoint
To decorate again is to redecorate
To write again is to
2024-07-29 03:57:56 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 03:59:47 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.6470, -0.7041, -0.1737,  ..., -0.2676, -0.4507,  0.0960],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.1162, -2.4414,  0.0914,  ...,  2.0371, -3.4004, -2.7773],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0536, -0.0096,  0.0169,  ...,  0.0026,  0.0046,  0.0145],
        [-0.0072,  0.0520, -0.0073,  ...,  0.0081,  0.0042,  0.0037],
        [-0.0021, -0.0035,  0.0620,  ..., -0.0148,  0.0052,  0.0054],
        ...,
        [ 0.0108,  0.0060, -0.0001,  ...,  0.0630, -0.0032,  0.0035],
        [ 0.0193,  0.0029,  0.0119,  ..., -0.0092,  0.0388, -0.0054],
        [-0.0056,  0.0123, -0.0016,  ..., -0.0113, -0.0143,  0.0535]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.1240, -2.6172,  0.0414,  ...,  1.9570, -3.6836, -2.8184]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 03:59:48 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To assign again is to reassign
To learn again is to relearn
To publish again is to republish
To tell again is to retell
To create again is to recreate
To appoint again is to reappoint
To decorate again is to redecorate
To write again is to
2024-07-29 03:59:48 root INFO     [order_1_approx] starting weight calculation for To create again is to recreate
To assign again is to reassign
To write again is to rewrite
To learn again is to relearn
To publish again is to republish
To appoint again is to reappoint
To decorate again is to redecorate
To tell again is to
2024-07-29 03:59:48 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 04:01:40 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1880, -0.7251,  0.5688,  ..., -0.3369,  0.2357,  0.1331],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.1763, -2.5508,  0.4414,  ...,  0.3384, -3.8125, -2.5254],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0701,  0.0009,  0.0060,  ..., -0.0039, -0.0119,  0.0127],
        [-0.0106,  0.0272,  0.0125,  ...,  0.0164,  0.0132, -0.0018],
        [ 0.0114,  0.0018,  0.0588,  ..., -0.0133, -0.0005, -0.0021],
        ...,
        [ 0.0148,  0.0064, -0.0029,  ...,  0.0685, -0.0008,  0.0063],
        [ 0.0127, -0.0030,  0.0136,  ...,  0.0026,  0.0471, -0.0031],
        [-0.0080,  0.0019, -0.0067,  ..., -0.0076,  0.0006,  0.0601]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.3511, -2.6582,  0.6162,  ...,  0.3557, -3.7637, -2.4570]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 04:01:41 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To create again is to recreate
To assign again is to reassign
To write again is to rewrite
To learn again is to relearn
To publish again is to republish
To appoint again is to reappoint
To decorate again is to redecorate
To tell again is to
2024-07-29 04:01:41 root INFO     [order_1_approx] starting weight calculation for To write again is to rewrite
To learn again is to relearn
To appoint again is to reappoint
To create again is to recreate
To publish again is to republish
To tell again is to retell
To assign again is to reassign
To decorate again is to
2024-07-29 04:01:41 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 04:03:34 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0890, -0.5532, -0.2659,  ..., -0.1791, -1.1611,  0.4768],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-2.5039, -2.3145, -0.3198,  ...,  2.0977, -3.7285, -3.0234],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 6.9092e-02, -7.0801e-03,  8.2397e-03,  ..., -7.7133e-03,
         -3.4285e-04,  1.0628e-02],
        [-8.8272e-03,  5.2643e-02, -4.0741e-03,  ...,  1.1452e-02,
          1.1169e-02, -3.3760e-03],
        [ 9.3307e-03, -3.8280e-03,  6.0608e-02,  ..., -1.9394e-02,
         -3.4866e-03, -1.4553e-03],
        ...,
        [-3.7308e-03, -2.5940e-03, -4.1656e-03,  ...,  6.1218e-02,
          9.5248e-05,  3.8314e-04],
        [ 1.1681e-02,  4.7913e-03,  2.9049e-03,  ..., -9.2010e-03,
          5.0354e-02, -1.1292e-02],
        [-1.1244e-03,  4.4289e-03, -1.9722e-03,  ..., -4.3373e-03,
         -1.1665e-02,  5.4352e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-2.7578, -2.3262, -0.2054,  ...,  2.1875, -3.7793, -2.9805]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 04:03:51 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To write again is to rewrite
To learn again is to relearn
To appoint again is to reappoint
To create again is to recreate
To publish again is to republish
To tell again is to retell
To assign again is to reassign
To decorate again is to
2024-07-29 04:03:51 root INFO     [order_1_approx] starting weight calculation for To create again is to recreate
To learn again is to relearn
To appoint again is to reappoint
To decorate again is to redecorate
To write again is to rewrite
To assign again is to reassign
To tell again is to retell
To publish again is to
2024-07-29 04:03:51 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 04:05:46 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.3184, -0.4553, -0.2324,  ...,  0.8501, -0.2422,  0.7593],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.0146, -2.3535, -0.5132,  ...,  1.5537, -2.3867, -2.3379],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0441, -0.0039,  0.0101,  ...,  0.0005, -0.0062,  0.0145],
        [-0.0068,  0.0342, -0.0018,  ...,  0.0042,  0.0029,  0.0016],
        [-0.0063,  0.0043,  0.0468,  ..., -0.0050, -0.0078,  0.0065],
        ...,
        [ 0.0048,  0.0005, -0.0050,  ...,  0.0492,  0.0086,  0.0007],
        [-0.0011,  0.0019,  0.0092,  ...,  0.0032,  0.0359, -0.0035],
        [-0.0044, -0.0051, -0.0062,  ..., -0.0072, -0.0118,  0.0360]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.0791, -2.1504, -0.3652,  ...,  1.7354, -2.5840, -2.0723]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 04:05:47 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To create again is to recreate
To learn again is to relearn
To appoint again is to reappoint
To decorate again is to redecorate
To write again is to rewrite
To assign again is to reassign
To tell again is to retell
To publish again is to
2024-07-29 04:05:47 root INFO     [order_1_approx] starting weight calculation for To learn again is to relearn
To tell again is to retell
To appoint again is to reappoint
To publish again is to republish
To write again is to rewrite
To create again is to recreate
To decorate again is to redecorate
To assign again is to
2024-07-29 04:05:47 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 04:07:40 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2998,  0.1187,  0.3296,  ...,  0.1489, -0.8242, -0.2695],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.0442, -2.9102, -0.8130,  ...,  2.7070, -3.9922, -4.2305],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0787, -0.0019,  0.0072,  ...,  0.0027,  0.0064,  0.0039],
        [-0.0038,  0.0582,  0.0036,  ...,  0.0207,  0.0040, -0.0050],
        [ 0.0053,  0.0027,  0.0823,  ..., -0.0139, -0.0017, -0.0119],
        ...,
        [ 0.0160, -0.0063, -0.0055,  ...,  0.0952, -0.0005,  0.0054],
        [ 0.0023,  0.0112,  0.0122,  ..., -0.0048,  0.0803, -0.0156],
        [-0.0032,  0.0061, -0.0116,  ..., -0.0139, -0.0229,  0.0700]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.1042, -2.4277, -0.6904,  ...,  2.6348, -3.9844, -3.7578]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 04:07:40 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To learn again is to relearn
To tell again is to retell
To appoint again is to reappoint
To publish again is to republish
To write again is to rewrite
To create again is to recreate
To decorate again is to redecorate
To assign again is to
2024-07-29 04:07:40 root INFO     total operator prediction time: 927.1114468574524 seconds
2024-07-29 04:07:40 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on un+adj_reg
2024-07-29 04:07:40 root INFO     building operator un+adj_reg
2024-07-29 04:07:41 root INFO     [order_1_approx] starting weight calculation for The opposite of aware is unaware
The opposite of wanted is unwanted
The opposite of used is unused
The opposite of able is unable
The opposite of identified is unidentified
The opposite of desirable is undesirable
The opposite of healthy is unhealthy
The opposite of pleasant is
2024-07-29 04:07:41 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 04:09:33 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2185, -0.8159, -0.3582,  ..., -0.6978, -0.7168, -0.8340],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.4219, -1.4355, -3.4492,  ..., -1.2725, -1.8311, -1.4521],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0683,  0.0077,  0.0097,  ..., -0.0115,  0.0204,  0.0181],
        [-0.0012,  0.0568, -0.0004,  ...,  0.0046, -0.0034,  0.0072],
        [-0.0075,  0.0119,  0.0658,  ...,  0.0013, -0.0001, -0.0023],
        ...,
        [ 0.0082,  0.0073, -0.0006,  ...,  0.0528, -0.0041,  0.0008],
        [-0.0013, -0.0006,  0.0037,  ..., -0.0079,  0.0479, -0.0168],
        [ 0.0106, -0.0022, -0.0158,  ...,  0.0028, -0.0147,  0.0624]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.0098, -1.7520, -2.9844,  ..., -0.8252, -1.6924, -1.3906]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 04:09:34 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of aware is unaware
The opposite of wanted is unwanted
The opposite of used is unused
The opposite of able is unable
The opposite of identified is unidentified
The opposite of desirable is undesirable
The opposite of healthy is unhealthy
The opposite of pleasant is
2024-07-29 04:09:34 root INFO     [order_1_approx] starting weight calculation for The opposite of identified is unidentified
The opposite of able is unable
The opposite of healthy is unhealthy
The opposite of aware is unaware
The opposite of pleasant is unpleasant
The opposite of desirable is undesirable
The opposite of used is unused
The opposite of wanted is
2024-07-29 04:09:34 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 04:11:29 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.5376, -0.1051, -0.5854,  ..., -0.3069, -0.5439,  0.0796],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.6729, -2.2500, -0.7148,  ...,  0.2482, -1.7070, -2.0449],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0413, -0.0032,  0.0030,  ..., -0.0041,  0.0085,  0.0130],
        [-0.0009,  0.0452, -0.0282,  ...,  0.0186, -0.0041, -0.0131],
        [ 0.0007,  0.0153,  0.0363,  ..., -0.0168,  0.0021,  0.0111],
        ...,
        [ 0.0092,  0.0139, -0.0007,  ...,  0.0568, -0.0063, -0.0209],
        [ 0.0131, -0.0057,  0.0203,  ..., -0.0128,  0.0587, -0.0063],
        [ 0.0099,  0.0055, -0.0232,  ..., -0.0065, -0.0097,  0.0478]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.3027, -1.8232, -0.5903,  ...,  0.5903, -2.1035, -1.6426]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 04:11:31 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of identified is unidentified
The opposite of able is unable
The opposite of healthy is unhealthy
The opposite of aware is unaware
The opposite of pleasant is unpleasant
The opposite of desirable is undesirable
The opposite of used is unused
The opposite of wanted is
2024-07-29 04:11:31 root INFO     [order_1_approx] starting weight calculation for The opposite of pleasant is unpleasant
The opposite of healthy is unhealthy
The opposite of desirable is undesirable
The opposite of identified is unidentified
The opposite of able is unable
The opposite of wanted is unwanted
The opposite of used is unused
The opposite of aware is
2024-07-29 04:11:31 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 04:13:27 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.7080,  0.2307, -1.1250,  ..., -0.6489,  0.0276, -0.0132],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.6270, -2.1953,  2.9062,  ..., -2.4355, -1.7393, -1.1143],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 7.8369e-02, -7.1182e-03,  1.3321e-02,  ...,  1.3504e-02,
          9.5596e-03,  1.4221e-02],
        [-3.2425e-05,  5.0568e-02, -8.2550e-03,  ...,  1.5350e-02,
          2.8973e-03, -8.9874e-03],
        [-8.6517e-03,  5.8823e-03,  7.0984e-02,  ..., -5.4855e-03,
         -4.4556e-03,  3.7460e-03],
        ...,
        [ 2.6054e-03,  2.1454e-02,  2.4014e-03,  ...,  7.3486e-02,
         -2.2202e-03, -5.1003e-03],
        [-6.5346e-03, -7.1106e-03,  3.8052e-03,  ..., -7.4768e-04,
          5.2338e-02, -2.2675e-02],
        [ 4.6844e-03, -7.4539e-03, -1.5419e-02,  ..., -4.6921e-03,
         -9.7122e-03,  6.8359e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.0957, -1.8193,  3.0098,  ..., -2.0859, -1.5791, -0.8350]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 04:13:28 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of pleasant is unpleasant
The opposite of healthy is unhealthy
The opposite of desirable is undesirable
The opposite of identified is unidentified
The opposite of able is unable
The opposite of wanted is unwanted
The opposite of used is unused
The opposite of aware is
2024-07-29 04:13:28 root INFO     [order_1_approx] starting weight calculation for The opposite of identified is unidentified
The opposite of able is unable
The opposite of pleasant is unpleasant
The opposite of wanted is unwanted
The opposite of used is unused
The opposite of aware is unaware
The opposite of desirable is undesirable
The opposite of healthy is
2024-07-29 04:13:28 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 04:15:25 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2520, -1.0820, -0.0137,  ..., -0.7852, -0.0405, -0.3301],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.4727, -2.1855, -0.9907,  ..., -2.6426, -1.2461, -1.3594],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 4.6509e-02, -8.6441e-03, -4.9210e-04,  ..., -7.5607e-03,
          5.0888e-03,  8.7433e-03],
        [ 1.3857e-03,  3.3936e-02,  5.6229e-03,  ...,  1.7975e-02,
          5.9891e-03, -1.1482e-03],
        [-3.3951e-04,  3.6812e-03,  2.0859e-02,  ..., -4.0245e-03,
         -9.2163e-03,  3.1395e-03],
        ...,
        [ 3.7899e-03,  2.3804e-02,  4.6253e-05,  ...,  3.5614e-02,
          1.6174e-03, -7.8583e-03],
        [-1.3168e-02, -1.1360e-02, -4.1428e-03,  ..., -1.5602e-02,
          3.4271e-02, -4.8523e-03],
        [-1.0834e-03, -6.6452e-03, -6.2180e-03,  ..., -1.3741e-02,
         -7.6752e-03,  3.7781e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.4082, -2.2559, -0.6162,  ..., -2.4336, -1.2559, -1.3965]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 04:15:26 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of identified is unidentified
The opposite of able is unable
The opposite of pleasant is unpleasant
The opposite of wanted is unwanted
The opposite of used is unused
The opposite of aware is unaware
The opposite of desirable is undesirable
The opposite of healthy is
2024-07-29 04:15:26 root INFO     [order_1_approx] starting weight calculation for The opposite of aware is unaware
The opposite of identified is unidentified
The opposite of healthy is unhealthy
The opposite of desirable is undesirable
The opposite of wanted is unwanted
The opposite of used is unused
The opposite of pleasant is unpleasant
The opposite of able is
2024-07-29 04:15:26 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 04:17:22 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2230,  0.0789, -0.2084,  ..., -1.3447, -0.5322, -0.2578],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.5996, -5.4688,  2.5625,  ...,  0.6572, -0.8525, -1.2383],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0503,  0.0033,  0.0194,  ...,  0.0034,  0.0022,  0.0071],
        [-0.0076,  0.0322, -0.0221,  ...,  0.0277,  0.0180, -0.0023],
        [-0.0026, -0.0078,  0.0345,  ..., -0.0225,  0.0005,  0.0087],
        ...,
        [ 0.0051,  0.0174,  0.0015,  ...,  0.0437, -0.0014, -0.0031],
        [-0.0204,  0.0040,  0.0202,  ..., -0.0134,  0.0504, -0.0153],
        [ 0.0176, -0.0198, -0.0164,  ..., -0.0193,  0.0011,  0.0490]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.6050, -4.9922,  2.5488,  ...,  1.1689, -0.6968, -1.3730]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 04:17:23 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of aware is unaware
The opposite of identified is unidentified
The opposite of healthy is unhealthy
The opposite of desirable is undesirable
The opposite of wanted is unwanted
The opposite of used is unused
The opposite of pleasant is unpleasant
The opposite of able is
2024-07-29 04:17:23 root INFO     [order_1_approx] starting weight calculation for The opposite of used is unused
The opposite of healthy is unhealthy
The opposite of wanted is unwanted
The opposite of pleasant is unpleasant
The opposite of able is unable
The opposite of identified is unidentified
The opposite of aware is unaware
The opposite of desirable is
2024-07-29 04:17:23 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 04:19:19 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0736, -0.1355, -0.3423,  ..., -0.3459, -0.4790, -0.1222],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.1211, -4.8359,  0.1221,  ..., -0.2974, -4.4609, -3.9141],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0658, -0.0082,  0.0042,  ..., -0.0064,  0.0075,  0.0086],
        [-0.0145,  0.0500, -0.0103,  ...,  0.0148, -0.0059,  0.0034],
        [ 0.0061,  0.0130,  0.0567,  ..., -0.0130, -0.0036, -0.0124],
        ...,
        [ 0.0129,  0.0250,  0.0052,  ...,  0.0879, -0.0108, -0.0167],
        [ 0.0033,  0.0009,  0.0271,  ...,  0.0091,  0.0673, -0.0122],
        [ 0.0059,  0.0037, -0.0203,  ..., -0.0071, -0.0117,  0.0627]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.2803, -4.7305,  0.1232,  ..., -0.2168, -3.5703, -3.7500]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 04:19:28 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of used is unused
The opposite of healthy is unhealthy
The opposite of wanted is unwanted
The opposite of pleasant is unpleasant
The opposite of able is unable
The opposite of identified is unidentified
The opposite of aware is unaware
The opposite of desirable is
2024-07-29 04:19:29 root INFO     [order_1_approx] starting weight calculation for The opposite of wanted is unwanted
The opposite of pleasant is unpleasant
The opposite of aware is unaware
The opposite of able is unable
The opposite of desirable is undesirable
The opposite of healthy is unhealthy
The opposite of used is unused
The opposite of identified is
2024-07-29 04:19:29 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 04:21:25 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.3987,  0.0063, -0.0674,  ...,  0.2086, -0.8994, -0.5317],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.7490, -0.1150,  1.5742,  ..., -0.2441, -1.2051, -1.8262],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 1.0229e-01, -1.0956e-02,  2.1652e-02,  ..., -2.5692e-03,
          1.7653e-03,  1.3931e-02],
        [-2.6001e-02,  7.0435e-02, -5.8136e-03,  ...,  1.4679e-02,
          1.4679e-02, -1.2711e-02],
        [ 1.1642e-02, -1.5213e-02,  7.6416e-02,  ..., -1.0193e-02,
          5.8365e-03,  1.1444e-05],
        ...,
        [ 4.3564e-03,  1.2924e-02,  7.7591e-03,  ...,  1.0309e-01,
         -1.0445e-02, -9.6512e-03],
        [ 5.7030e-03, -4.2877e-03,  3.4424e-02,  ...,  3.3627e-03,
          8.0994e-02, -1.2390e-02],
        [ 3.6240e-03,  4.6158e-03, -1.4549e-02,  ..., -4.5471e-03,
          2.0866e-03,  8.3984e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.1064, -0.1372,  1.6562,  ..., -0.3516, -0.8896, -2.0156]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 04:21:26 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of wanted is unwanted
The opposite of pleasant is unpleasant
The opposite of aware is unaware
The opposite of able is unable
The opposite of desirable is undesirable
The opposite of healthy is unhealthy
The opposite of used is unused
The opposite of identified is
2024-07-29 04:21:27 root INFO     [order_1_approx] starting weight calculation for The opposite of able is unable
The opposite of aware is unaware
The opposite of pleasant is unpleasant
The opposite of healthy is unhealthy
The opposite of identified is unidentified
The opposite of desirable is undesirable
The opposite of wanted is unwanted
The opposite of used is
2024-07-29 04:21:27 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 04:23:23 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0255, -0.5889, -0.4333,  ..., -0.3237, -0.7007,  0.0910],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.4326, -2.7500, -0.3066,  ..., -2.2266, -1.5186, -1.1699],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0873, -0.0138,  0.0102,  ...,  0.0048, -0.0148,  0.0088],
        [-0.0094,  0.0640,  0.0042,  ...,  0.0197,  0.0288,  0.0209],
        [ 0.0038,  0.0188,  0.0693,  ..., -0.0150,  0.0025, -0.0164],
        ...,
        [ 0.0019,  0.0087, -0.0213,  ...,  0.0847, -0.0012, -0.0045],
        [ 0.0112, -0.0076,  0.0031,  ..., -0.0230,  0.0870,  0.0025],
        [-0.0101,  0.0006, -0.0302,  ..., -0.0083, -0.0064,  0.0731]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.2585, -2.4961, -0.7456,  ..., -1.7861, -1.3662, -0.9121]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 04:23:24 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of able is unable
The opposite of aware is unaware
The opposite of pleasant is unpleasant
The opposite of healthy is unhealthy
The opposite of identified is unidentified
The opposite of desirable is undesirable
The opposite of wanted is unwanted
The opposite of used is
2024-07-29 04:23:24 root INFO     total operator prediction time: 943.5990533828735 seconds
2024-07-29 04:23:24 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on verb+able_reg
2024-07-29 04:23:24 root INFO     building operator verb+able_reg
2024-07-29 04:23:24 root INFO     [order_1_approx] starting weight calculation for If you can adapt something, that thing is adaptable
If you can advise something, that thing is advisable
If you can foresee something, that thing is foreseeable
If you can expand something, that thing is expandable
If you can represent something, that thing is representable
If you can sustain something, that thing is sustainable
If you can consider something, that thing is considerable
If you can improve something, that thing is
2024-07-29 04:23:24 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 04:25:19 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2415, -0.6274,  0.0526,  ..., -0.6123, -0.0115,  0.8550],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.2891, -0.3999, -0.1035,  ..., -2.7539, -7.5508, -2.5391],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0625,  0.0054,  0.0083,  ...,  0.0061, -0.0151,  0.0080],
        [ 0.0094,  0.0524,  0.0031,  ...,  0.0166,  0.0045,  0.0019],
        [ 0.0005, -0.0051,  0.0424,  ..., -0.0002,  0.0033, -0.0115],
        ...,
        [ 0.0178,  0.0161, -0.0071,  ...,  0.0504, -0.0061, -0.0055],
        [ 0.0138,  0.0028,  0.0119,  ..., -0.0083,  0.0267, -0.0097],
        [-0.0003, -0.0003, -0.0082,  ..., -0.0231, -0.0102,  0.0359]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.1973, -0.7295,  0.1655,  ..., -2.9023, -7.2969, -2.5605]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 04:25:20 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you can adapt something, that thing is adaptable
If you can advise something, that thing is advisable
If you can foresee something, that thing is foreseeable
If you can expand something, that thing is expandable
If you can represent something, that thing is representable
If you can sustain something, that thing is sustainable
If you can consider something, that thing is considerable
If you can improve something, that thing is
2024-07-29 04:25:20 root INFO     [order_1_approx] starting weight calculation for If you can improve something, that thing is improvable
If you can adapt something, that thing is adaptable
If you can foresee something, that thing is foreseeable
If you can advise something, that thing is advisable
If you can consider something, that thing is considerable
If you can represent something, that thing is representable
If you can sustain something, that thing is sustainable
If you can expand something, that thing is
2024-07-29 04:25:20 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 04:27:16 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.7939, -0.4155, -0.7910,  ..., -0.5996, -0.3511, -0.1450],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.0430, -0.3276, -0.1521,  ..., -2.3398, -7.6094, -3.0098],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0604,  0.0007,  0.0040,  ...,  0.0052,  0.0004,  0.0124],
        [ 0.0038,  0.0529,  0.0095,  ...,  0.0156,  0.0130, -0.0041],
        [ 0.0104, -0.0079,  0.0520,  ..., -0.0029, -0.0028, -0.0131],
        ...,
        [ 0.0310,  0.0183, -0.0069,  ...,  0.0524, -0.0026,  0.0016],
        [ 0.0044, -0.0081,  0.0159,  ..., -0.0163,  0.0550,  0.0050],
        [-0.0125, -0.0011, -0.0114,  ..., -0.0204, -0.0095,  0.0611]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.1892, -0.2422, -0.0126,  ..., -2.4434, -7.7070, -2.7734]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 04:27:17 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you can improve something, that thing is improvable
If you can adapt something, that thing is adaptable
If you can foresee something, that thing is foreseeable
If you can advise something, that thing is advisable
If you can consider something, that thing is considerable
If you can represent something, that thing is representable
If you can sustain something, that thing is sustainable
If you can expand something, that thing is
2024-07-29 04:27:17 root INFO     [order_1_approx] starting weight calculation for If you can represent something, that thing is representable
If you can expand something, that thing is expandable
If you can advise something, that thing is advisable
If you can sustain something, that thing is sustainable
If you can improve something, that thing is improvable
If you can foresee something, that thing is foreseeable
If you can adapt something, that thing is adaptable
If you can consider something, that thing is
2024-07-29 04:27:17 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 04:29:11 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0975, -0.0486,  0.5811,  ...,  0.2363, -0.2322,  0.2167],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.9028,  0.3906,  1.4736,  ..., -3.8633, -6.6875, -1.8428],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0930,  0.0013, -0.0048,  ..., -0.0040, -0.0131,  0.0146],
        [-0.0081,  0.0608,  0.0005,  ...,  0.0215,  0.0017, -0.0018],
        [-0.0067, -0.0117,  0.0769,  ...,  0.0007, -0.0056, -0.0149],
        ...,
        [ 0.0192,  0.0107,  0.0016,  ...,  0.0887, -0.0085, -0.0027],
        [ 0.0064,  0.0119,  0.0248,  ..., -0.0285,  0.0760, -0.0155],
        [-0.0011,  0.0116, -0.0016,  ..., -0.0172, -0.0156,  0.0633]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.7520,  0.4114,  1.3223,  ..., -3.4805, -6.6758, -1.6221]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 04:29:12 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you can represent something, that thing is representable
If you can expand something, that thing is expandable
If you can advise something, that thing is advisable
If you can sustain something, that thing is sustainable
If you can improve something, that thing is improvable
If you can foresee something, that thing is foreseeable
If you can adapt something, that thing is adaptable
If you can consider something, that thing is
2024-07-29 04:29:12 root INFO     [order_1_approx] starting weight calculation for If you can adapt something, that thing is adaptable
If you can consider something, that thing is considerable
If you can advise something, that thing is advisable
If you can represent something, that thing is representable
If you can foresee something, that thing is foreseeable
If you can improve something, that thing is improvable
If you can expand something, that thing is expandable
If you can sustain something, that thing is
2024-07-29 04:29:12 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 04:31:07 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3574, -0.0766,  0.3306,  ...,  0.0641, -0.5356,  0.4268],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.1582, -1.6514, -1.8398,  ..., -2.8574, -5.0391, -2.3320],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 4.3793e-02, -1.5535e-03,  6.0959e-03,  ...,  2.8057e-03,
          5.2452e-03, -2.5558e-03],
        [-2.1839e-03,  3.4271e-02, -4.9829e-05,  ...,  4.7226e-03,
          8.7585e-03, -1.7796e-03],
        [ 1.2350e-03, -5.5885e-03,  3.1799e-02,  ..., -2.2125e-03,
         -2.7637e-03, -1.0010e-02],
        ...,
        [ 1.1192e-02,  8.4152e-03, -5.3253e-03,  ...,  3.9001e-02,
          1.9836e-03, -3.9444e-03],
        [ 5.1422e-03,  5.2948e-03,  3.3302e-03,  ..., -9.1019e-03,
          3.6987e-02, -8.3694e-03],
        [-6.6605e-03,  5.3101e-03, -3.0899e-03,  ..., -1.4702e-02,
         -9.7809e-03,  2.8870e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.0957, -1.5312, -1.8242,  ..., -2.8105, -5.2617, -2.2773]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 04:31:08 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you can adapt something, that thing is adaptable
If you can consider something, that thing is considerable
If you can advise something, that thing is advisable
If you can represent something, that thing is representable
If you can foresee something, that thing is foreseeable
If you can improve something, that thing is improvable
If you can expand something, that thing is expandable
If you can sustain something, that thing is
2024-07-29 04:31:09 root INFO     [order_1_approx] starting weight calculation for If you can improve something, that thing is improvable
If you can expand something, that thing is expandable
If you can consider something, that thing is considerable
If you can foresee something, that thing is foreseeable
If you can represent something, that thing is representable
If you can advise something, that thing is advisable
If you can sustain something, that thing is sustainable
If you can adapt something, that thing is
2024-07-29 04:31:09 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 04:33:04 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.7095,  0.5347, -0.6440,  ..., -0.4541, -0.1882,  0.8027],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.6660,  0.2769, -2.9531,  ..., -1.0215, -8.9219, -0.8516],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0620, -0.0052, -0.0008,  ..., -0.0019,  0.0048,  0.0073],
        [ 0.0017,  0.0523, -0.0017,  ...,  0.0117,  0.0179, -0.0102],
        [ 0.0032, -0.0041,  0.0484,  ...,  0.0040, -0.0004, -0.0169],
        ...,
        [ 0.0137,  0.0205, -0.0067,  ...,  0.0487, -0.0026, -0.0118],
        [ 0.0165,  0.0074,  0.0200,  ..., -0.0235,  0.0581, -0.0042],
        [-0.0024,  0.0031, -0.0049,  ..., -0.0136, -0.0149,  0.0513]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.5439,  0.2947, -2.9180,  ..., -1.5215, -9.1328, -0.8765]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 04:33:05 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you can improve something, that thing is improvable
If you can expand something, that thing is expandable
If you can consider something, that thing is considerable
If you can foresee something, that thing is foreseeable
If you can represent something, that thing is representable
If you can advise something, that thing is advisable
If you can sustain something, that thing is sustainable
If you can adapt something, that thing is
2024-07-29 04:33:05 root INFO     [order_1_approx] starting weight calculation for If you can expand something, that thing is expandable
If you can consider something, that thing is considerable
If you can sustain something, that thing is sustainable
If you can foresee something, that thing is foreseeable
If you can represent something, that thing is representable
If you can adapt something, that thing is adaptable
If you can improve something, that thing is improvable
If you can advise something, that thing is
2024-07-29 04:33:05 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 04:35:00 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4248,  0.0070, -0.6416,  ..., -0.3118, -0.2954,  0.3743],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.7207, -1.3506, -2.2773,  ..., -0.3933, -7.9141, -1.1953],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0645, -0.0017,  0.0032,  ..., -0.0007, -0.0145,  0.0146],
        [-0.0151,  0.0558,  0.0004,  ...,  0.0118,  0.0102, -0.0032],
        [-0.0027, -0.0104,  0.0545,  ..., -0.0014, -0.0017, -0.0066],
        ...,
        [ 0.0135,  0.0205, -0.0197,  ...,  0.0640,  0.0035, -0.0026],
        [ 0.0075,  0.0084,  0.0122,  ...,  0.0013,  0.0500, -0.0096],
        [ 0.0231,  0.0149, -0.0105,  ..., -0.0170, -0.0122,  0.0514]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.4795, -1.4717, -2.4766,  ..., -0.8623, -8.2891, -1.1660]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 04:35:01 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you can expand something, that thing is expandable
If you can consider something, that thing is considerable
If you can sustain something, that thing is sustainable
If you can foresee something, that thing is foreseeable
If you can represent something, that thing is representable
If you can adapt something, that thing is adaptable
If you can improve something, that thing is improvable
If you can advise something, that thing is
2024-07-29 04:35:01 root INFO     [order_1_approx] starting weight calculation for If you can sustain something, that thing is sustainable
If you can expand something, that thing is expandable
If you can consider something, that thing is considerable
If you can represent something, that thing is representable
If you can adapt something, that thing is adaptable
If you can advise something, that thing is advisable
If you can improve something, that thing is improvable
If you can foresee something, that thing is
2024-07-29 04:35:01 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 04:36:57 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.6196,  0.2847,  0.2637,  ..., -0.6777, -0.2405,  0.1920],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.6318,  1.7412, -1.6230,  ..., -3.4414, -7.2070, -1.7549],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 5.1056e-02,  1.1063e-03,  6.9466e-03,  ...,  3.5591e-03,
         -8.9836e-04,  1.7414e-03],
        [-9.2773e-03,  3.6804e-02, -1.3180e-03,  ...,  7.5340e-03,
         -1.2817e-03, -3.6125e-03],
        [-3.0518e-04, -3.1815e-03,  4.9377e-02,  ..., -1.8215e-03,
          1.8511e-03, -6.8512e-03],
        ...,
        [ 2.4986e-03,  8.4610e-03, -7.3166e-03,  ...,  4.9774e-02,
         -2.1744e-03,  4.1885e-03],
        [ 8.6784e-05,  1.1129e-03,  6.0310e-03,  ..., -1.3443e-02,
          3.9673e-02, -8.4076e-03],
        [ 2.4853e-03,  1.9436e-03, -7.6103e-03,  ..., -2.8038e-03,
         -6.6528e-03,  4.1840e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.6611,  1.6484, -1.4883,  ..., -3.4883, -7.1250, -1.8545]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 04:37:07 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you can sustain something, that thing is sustainable
If you can expand something, that thing is expandable
If you can consider something, that thing is considerable
If you can represent something, that thing is representable
If you can adapt something, that thing is adaptable
If you can advise something, that thing is advisable
If you can improve something, that thing is improvable
If you can foresee something, that thing is
2024-07-29 04:37:07 root INFO     [order_1_approx] starting weight calculation for If you can expand something, that thing is expandable
If you can sustain something, that thing is sustainable
If you can improve something, that thing is improvable
If you can adapt something, that thing is adaptable
If you can consider something, that thing is considerable
If you can advise something, that thing is advisable
If you can foresee something, that thing is foreseeable
If you can represent something, that thing is
2024-07-29 04:37:07 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 04:39:02 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2178,  0.3018,  0.0810,  ..., -0.1193, -0.2773, -0.1699],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.2422,  2.2930,  1.9795,  ..., -2.5859, -7.8828, -3.2266],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0782, -0.0100,  0.0056,  ..., -0.0006, -0.0003,  0.0103],
        [-0.0110,  0.0836,  0.0034,  ...,  0.0135,  0.0139, -0.0066],
        [-0.0107, -0.0217,  0.0884,  ..., -0.0023,  0.0088, -0.0159],
        ...,
        [ 0.0163,  0.0210, -0.0109,  ...,  0.0959, -0.0072,  0.0025],
        [ 0.0139, -0.0129,  0.0172,  ..., -0.0121,  0.0679, -0.0191],
        [-0.0110,  0.0089, -0.0148,  ..., -0.0098, -0.0137,  0.0837]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.5752,  2.4375,  2.0586,  ..., -2.8555, -8.1016, -3.1582]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 04:39:03 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you can expand something, that thing is expandable
If you can sustain something, that thing is sustainable
If you can improve something, that thing is improvable
If you can adapt something, that thing is adaptable
If you can consider something, that thing is considerable
If you can advise something, that thing is advisable
If you can foresee something, that thing is foreseeable
If you can represent something, that thing is
2024-07-29 04:39:03 root INFO     total operator prediction time: 939.1081788539886 seconds
2024-07-29 04:39:03 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on verb+tion_irreg
2024-07-29 04:39:03 root INFO     building operator verb+tion_irreg
2024-07-29 04:39:03 root INFO     [order_1_approx] starting weight calculation for To customize results in customization
To occupy results in occupation
To characterize results in characterization
To standardize results in standardization
To privatize results in privatization
To organize results in organization
To randomize results in randomization
To condense results in
2024-07-29 04:39:03 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 04:40:58 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1384, -0.8018, -0.7549,  ..., -0.4180,  0.1919,  0.0135],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.8003, -2.9609,  3.5723,  ...,  1.0645, -1.4893, -2.4043],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 1.2042e-01, -5.8250e-03,  2.5883e-03,  ..., -3.5706e-03,
          1.3359e-02,  4.0894e-03],
        [-1.1797e-03,  9.1675e-02,  1.6556e-02,  ...,  2.4673e-02,
          3.5973e-03, -3.6850e-03],
        [ 1.8368e-03, -1.7471e-02,  1.0077e-01,  ...,  1.5545e-04,
         -7.8506e-03, -7.7705e-03],
        ...,
        [ 1.3523e-03,  1.7258e-02,  5.6839e-03,  ...,  1.1218e-01,
          2.5749e-05, -8.4686e-03],
        [ 1.2836e-03,  6.2866e-03,  1.0201e-02,  ...,  9.1629e-03,
          1.0333e-01, -8.6212e-03],
        [-5.5771e-03,  1.4641e-02, -6.9046e-03,  ..., -1.6800e-02,
         -1.2093e-02,  8.8501e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.8540, -2.8887,  3.1465,  ...,  1.1045, -1.6641, -2.2109]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 04:40:59 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To customize results in customization
To occupy results in occupation
To characterize results in characterization
To standardize results in standardization
To privatize results in privatization
To organize results in organization
To randomize results in randomization
To condense results in
2024-07-29 04:40:59 root INFO     [order_1_approx] starting weight calculation for To customize results in customization
To occupy results in occupation
To privatize results in privatization
To condense results in condensation
To organize results in organization
To standardize results in standardization
To randomize results in randomization
To characterize results in
2024-07-29 04:40:59 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 04:42:53 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0199, -0.9141,  0.1307,  ..., -0.7275,  0.1035, -0.8008],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-2.2773, -0.8784,  2.9062,  ...,  1.6895, -2.0801, -2.3027],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0642, -0.0149, -0.0033,  ..., -0.0179,  0.0011,  0.0011],
        [-0.0026,  0.0653,  0.0140,  ...,  0.0239, -0.0003,  0.0060],
        [-0.0025, -0.0181,  0.0547,  ..., -0.0083,  0.0040, -0.0052],
        ...,
        [ 0.0036,  0.0141,  0.0102,  ...,  0.0672, -0.0082,  0.0092],
        [ 0.0090,  0.0101,  0.0079,  ..., -0.0029,  0.0513, -0.0049],
        [-0.0034,  0.0093,  0.0025,  ...,  0.0016, -0.0101,  0.0566]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-2.4375, -0.8442,  2.6445,  ...,  1.8584, -1.9453, -2.1211]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 04:42:54 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To customize results in customization
To occupy results in occupation
To privatize results in privatization
To condense results in condensation
To organize results in organization
To standardize results in standardization
To randomize results in randomization
To characterize results in
2024-07-29 04:42:54 root INFO     [order_1_approx] starting weight calculation for To customize results in customization
To organize results in organization
To occupy results in occupation
To privatize results in privatization
To condense results in condensation
To randomize results in randomization
To characterize results in characterization
To standardize results in
2024-07-29 04:42:54 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 04:44:48 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0036, -0.5615, -1.1387,  ..., -0.8496, -0.0989, -0.1813],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.8345, -3.0508,  0.0850,  ...,  0.8994, -2.2520, -2.1992],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 1.0010e-01, -8.5144e-03,  4.9829e-04,  ..., -1.6312e-02,
          6.2828e-03, -6.4507e-03],
        [-1.0628e-02,  8.8501e-02,  1.3031e-02,  ...,  1.2512e-02,
         -2.9182e-03,  1.2169e-02],
        [ 5.7220e-06, -1.0712e-02,  8.6548e-02,  ..., -3.0441e-03,
          9.9487e-03, -7.4310e-03],
        ...,
        [ 1.2569e-03,  1.9806e-02,  4.0817e-04,  ...,  1.0553e-01,
         -1.4343e-02,  8.4534e-03],
        [ 2.3861e-03,  3.2883e-03,  2.9564e-03,  ...,  1.7662e-03,
          8.2397e-02, -1.6174e-02],
        [-1.3107e-02,  1.1871e-02,  8.6975e-04,  ...,  1.3256e-03,
         -1.6769e-02,  8.9111e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.4771, -2.6953,  0.2029,  ...,  1.3770, -2.2227, -2.0215]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 04:44:49 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To customize results in customization
To organize results in organization
To occupy results in occupation
To privatize results in privatization
To condense results in condensation
To randomize results in randomization
To characterize results in characterization
To standardize results in
2024-07-29 04:44:50 root INFO     [order_1_approx] starting weight calculation for To occupy results in occupation
To customize results in customization
To standardize results in standardization
To condense results in condensation
To characterize results in characterization
To organize results in organization
To privatize results in privatization
To randomize results in
2024-07-29 04:44:50 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 04:46:44 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0396, -0.1188, -0.8145,  ..., -0.3347, -0.3298, -0.5063],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.5059, -0.7251, -0.8428,  ...,  1.3242, -2.7031, -3.3770],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 9.0759e-02,  8.9493e-03,  4.7874e-03,  ..., -9.1171e-03,
          7.7896e-03,  4.2038e-03],
        [-4.3869e-05,  6.7688e-02,  1.1841e-02,  ...,  2.1973e-02,
         -2.6245e-03,  2.9659e-03],
        [-9.3651e-04, -1.6022e-02,  7.7454e-02,  ..., -1.2383e-02,
          9.1248e-03, -4.5090e-03],
        ...,
        [-1.9341e-03,  1.8677e-02,  3.5973e-03,  ...,  8.7402e-02,
         -1.4603e-02,  6.7596e-03],
        [ 2.8629e-03,  1.2283e-02,  2.0161e-03,  ...,  1.4629e-03,
          7.8308e-02, -1.4572e-03],
        [-3.3264e-03,  3.5210e-03, -4.9858e-03,  ...,  2.3308e-03,
         -1.4709e-02,  8.0200e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.6641, -0.8188, -0.5361,  ...,  1.4961, -2.7363, -3.2480]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 04:46:45 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To occupy results in occupation
To customize results in customization
To standardize results in standardization
To condense results in condensation
To characterize results in characterization
To organize results in organization
To privatize results in privatization
To randomize results in
2024-07-29 04:46:45 root INFO     [order_1_approx] starting weight calculation for To characterize results in characterization
To customize results in customization
To standardize results in standardization
To occupy results in occupation
To privatize results in privatization
To randomize results in randomization
To condense results in condensation
To organize results in
2024-07-29 04:46:45 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 04:48:37 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3906,  0.5547, -0.3774,  ..., -0.8730, -0.0239,  0.2385],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.9775, -3.0137,  1.8652,  ...,  1.4258, -2.8398, -4.2188],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0634, -0.0027,  0.0142,  ..., -0.0181, -0.0057,  0.0098],
        [-0.0074,  0.0587,  0.0076,  ...,  0.0209,  0.0025,  0.0033],
        [ 0.0029, -0.0117,  0.0604,  ..., -0.0061, -0.0007, -0.0062],
        ...,
        [ 0.0136,  0.0158, -0.0051,  ...,  0.0722, -0.0012, -0.0153],
        [-0.0090,  0.0042,  0.0124,  ...,  0.0075,  0.0729, -0.0087],
        [-0.0021, -0.0017, -0.0058,  ...,  0.0046, -0.0151,  0.0625]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.9941, -2.8555,  1.9688,  ...,  1.2021, -2.8359, -4.1445]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 04:48:38 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To characterize results in characterization
To customize results in customization
To standardize results in standardization
To occupy results in occupation
To privatize results in privatization
To randomize results in randomization
To condense results in condensation
To organize results in
2024-07-29 04:48:38 root INFO     [order_1_approx] starting weight calculation for To randomize results in randomization
To condense results in condensation
To privatize results in privatization
To customize results in customization
To standardize results in standardization
To organize results in organization
To characterize results in characterization
To occupy results in
2024-07-29 04:48:38 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 04:50:25 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.6699, -0.7749, -0.2422,  ..., -0.3486, -0.4458,  0.1632],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.3223, -3.9297,  1.7705,  ...,  0.9521, -2.3809, -1.2930],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 9.7290e-02, -4.9591e-05,  4.3793e-03,  ..., -1.2924e-02,
          3.3531e-03,  1.8219e-02],
        [-7.1430e-04,  7.0740e-02,  1.2909e-02,  ...,  1.3344e-02,
          9.0714e-03, -5.5084e-03],
        [-5.1975e-04, -8.1558e-03,  7.7698e-02,  ..., -1.5320e-02,
         -7.5226e-03, -1.0910e-02],
        ...,
        [-5.4312e-04,  7.0801e-03,  2.7695e-03,  ...,  8.7402e-02,
         -1.2413e-02, -1.7891e-03],
        [-5.3291e-03,  2.2335e-03,  7.5293e-04,  ...,  6.0959e-03,
          7.3364e-02, -8.6060e-03],
        [ 1.3077e-02, -2.5349e-03, -7.3013e-03,  ..., -1.0538e-03,
         -1.3481e-02,  8.3923e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.4668, -3.5684,  1.7031,  ...,  0.8105, -2.3125, -1.3242]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 04:50:26 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To randomize results in randomization
To condense results in condensation
To privatize results in privatization
To customize results in customization
To standardize results in standardization
To organize results in organization
To characterize results in characterization
To occupy results in
2024-07-29 04:50:26 root INFO     [order_1_approx] starting weight calculation for To occupy results in occupation
To condense results in condensation
To randomize results in randomization
To customize results in customization
To standardize results in standardization
To organize results in organization
To characterize results in characterization
To privatize results in
2024-07-29 04:50:26 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 04:52:17 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.6831, -0.4658, -0.9731,  ..., -0.6309, -0.5054,  0.0693],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-2.3789, -3.4980,  2.2773,  ..., -1.4980,  0.0925, -2.2441],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0754, -0.0023,  0.0040,  ..., -0.0158, -0.0023,  0.0120],
        [-0.0080,  0.0582,  0.0082,  ...,  0.0140,  0.0016, -0.0013],
        [ 0.0010, -0.0102,  0.0534,  ..., -0.0066,  0.0010, -0.0022],
        ...,
        [-0.0035,  0.0161, -0.0013,  ...,  0.0748, -0.0004, -0.0083],
        [ 0.0026,  0.0013,  0.0018,  ..., -0.0003,  0.0604, -0.0002],
        [ 0.0003,  0.0024, -0.0050,  ..., -0.0035, -0.0139,  0.0585]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-2.3926, -3.3848,  2.2617,  ..., -1.2227,  0.0318, -2.2461]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 04:52:18 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To occupy results in occupation
To condense results in condensation
To randomize results in randomization
To customize results in customization
To standardize results in standardization
To organize results in organization
To characterize results in characterization
To privatize results in
2024-07-29 04:52:19 root INFO     [order_1_approx] starting weight calculation for To randomize results in randomization
To privatize results in privatization
To occupy results in occupation
To organize results in organization
To condense results in condensation
To standardize results in standardization
To characterize results in characterization
To customize results in
2024-07-29 04:52:19 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 04:54:13 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1437, -0.7178, -1.0801,  ..., -0.6865, -0.4878,  0.5186],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.0408, -1.5615,  0.9185,  ...,  0.9272, -2.5488, -0.5957],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 7.8430e-02, -7.1220e-03,  1.7395e-03,  ..., -1.3107e-02,
          6.9427e-03,  3.9902e-03],
        [-8.2321e-03,  7.8369e-02,  8.8043e-03,  ...,  1.4420e-02,
          7.0648e-03,  3.4676e-03],
        [ 3.6583e-03, -1.0597e-02,  6.7261e-02,  ..., -8.2092e-03,
          4.5395e-03, -4.2191e-03],
        ...,
        [-2.7313e-03,  6.4011e-03, -4.1885e-03,  ...,  8.9478e-02,
         -5.4741e-03,  9.3937e-05],
        [ 8.3447e-04,  3.9902e-03,  2.5005e-03,  ...,  3.3379e-03,
          6.5979e-02, -6.2103e-03],
        [-2.3804e-03,  7.5798e-03, -4.1199e-03,  ...,  2.4414e-04,
         -1.1650e-02,  7.2266e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.1863, -1.3701,  1.0342,  ...,  1.1602, -2.4434, -0.5068]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 04:54:14 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To randomize results in randomization
To privatize results in privatization
To occupy results in occupation
To organize results in organization
To condense results in condensation
To standardize results in standardization
To characterize results in characterization
To customize results in
2024-07-29 04:54:14 root INFO     total operator prediction time: 910.6096272468567 seconds
2024-07-29 04:54:14 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on adj+ly_reg
2024-07-29 04:54:14 root INFO     building operator adj+ly_reg
2024-07-29 04:54:14 root INFO     [order_1_approx] starting weight calculation for The adjective form of significant is significantly
The adjective form of regional is regionally
The adjective form of according is accordingly
The adjective form of strong is strongly
The adjective form of famous is famously
The adjective form of creative is creatively
The adjective form of decided is decidedly
The adjective form of unique is
2024-07-29 04:54:14 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 04:56:10 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1145, -0.4656, -0.9624,  ..., -0.2407, -0.6294, -0.0609],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.3569e-03, -1.3652e+00,  5.2930e-01,  ..., -2.1680e+00,
        -3.6836e+00, -1.1289e+00], device='cuda:1', dtype=torch.float16,
       grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 9.1736e-02, -5.5199e-03,  1.4786e-02,  ..., -2.1759e-02,
          1.3840e-02,  1.0239e-02],
        [ 7.1106e-03,  6.5186e-02,  5.4703e-03,  ...,  8.4381e-03,
          1.8997e-03, -1.1009e-02],
        [ 1.2779e-03,  3.1815e-03,  6.8420e-02,  ...,  2.9182e-03,
          1.3321e-02, -1.0147e-02],
        ...,
        [-1.0239e-02,  1.4145e-02, -3.4237e-03,  ...,  7.8430e-02,
          1.2360e-03, -2.1591e-03],
        [ 1.0361e-02,  8.1062e-05,  5.8899e-03,  ..., -7.1449e-03,
          3.7689e-02, -4.9171e-03],
        [ 6.3705e-03, -1.3718e-02, -6.1798e-03,  ..., -1.3390e-02,
         -2.8290e-02,  5.7861e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.2520, -1.2520,  0.5815,  ..., -1.9395, -3.8594, -1.3545]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 04:56:11 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The adjective form of significant is significantly
The adjective form of regional is regionally
The adjective form of according is accordingly
The adjective form of strong is strongly
The adjective form of famous is famously
The adjective form of creative is creatively
The adjective form of decided is decidedly
The adjective form of unique is
2024-07-29 04:56:11 root INFO     [order_1_approx] starting weight calculation for The adjective form of according is accordingly
The adjective form of famous is famously
The adjective form of regional is regionally
The adjective form of decided is decidedly
The adjective form of creative is creatively
The adjective form of unique is uniquely
The adjective form of strong is strongly
The adjective form of significant is
2024-07-29 04:56:11 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 04:58:08 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.5776,  0.1003, -0.8652,  ..., -0.8984, -0.6318, -0.6733],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.1660,  0.0850, -1.2236,  ..., -4.5000, -1.3232, -2.6641],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0804, -0.0145,  0.0153,  ..., -0.0125,  0.0071,  0.0137],
        [ 0.0065,  0.0475,  0.0125,  ...,  0.0106, -0.0046, -0.0083],
        [ 0.0051, -0.0083,  0.0625,  ...,  0.0024,  0.0005,  0.0058],
        ...,
        [-0.0299, -0.0023,  0.0110,  ...,  0.0878,  0.0055, -0.0032],
        [ 0.0054, -0.0031,  0.0077,  ..., -0.0085,  0.0563, -0.0039],
        [ 0.0076, -0.0005, -0.0050,  ..., -0.0088, -0.0294,  0.0538]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.1680, -0.0397, -1.0566,  ..., -4.1094, -1.3701, -2.5059]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 04:58:09 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The adjective form of according is accordingly
The adjective form of famous is famously
The adjective form of regional is regionally
The adjective form of decided is decidedly
The adjective form of creative is creatively
The adjective form of unique is uniquely
The adjective form of strong is strongly
The adjective form of significant is
2024-07-29 04:58:09 root INFO     [order_1_approx] starting weight calculation for The adjective form of significant is significantly
The adjective form of famous is famously
The adjective form of creative is creatively
The adjective form of according is accordingly
The adjective form of unique is uniquely
The adjective form of decided is decidedly
The adjective form of strong is strongly
The adjective form of regional is
2024-07-29 04:58:09 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 05:00:04 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2871, -0.2087,  0.4302,  ..., -0.4045, -0.4709,  0.0641],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.7031, -2.5859,  0.8687,  ..., -4.2305, -2.0801, -2.2988],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0842, -0.0247,  0.0142,  ..., -0.0107,  0.0191,  0.0024],
        [-0.0100,  0.0848,  0.0035,  ...,  0.0232,  0.0048, -0.0192],
        [ 0.0116, -0.0055,  0.1128,  ...,  0.0074,  0.0026, -0.0120],
        ...,
        [-0.0121,  0.0024, -0.0079,  ...,  0.0984, -0.0135,  0.0148],
        [ 0.0120,  0.0053, -0.0099,  ..., -0.0073,  0.0844, -0.0013],
        [-0.0046, -0.0182, -0.0096,  ..., -0.0165, -0.0232,  0.0894]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.8442, -2.7402,  0.8862,  ..., -3.5664, -2.2168, -2.5117]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 05:00:05 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The adjective form of significant is significantly
The adjective form of famous is famously
The adjective form of creative is creatively
The adjective form of according is accordingly
The adjective form of unique is uniquely
The adjective form of decided is decidedly
The adjective form of strong is strongly
The adjective form of regional is
2024-07-29 05:00:05 root INFO     [order_1_approx] starting weight calculation for The adjective form of regional is regionally
The adjective form of significant is significantly
The adjective form of unique is uniquely
The adjective form of famous is famously
The adjective form of according is accordingly
The adjective form of decided is decidedly
The adjective form of strong is strongly
The adjective form of creative is
2024-07-29 05:00:05 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 05:02:02 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3311,  0.0459,  0.4412,  ..., -0.1956, -0.7461,  0.0887],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.1758, -2.0391,  3.4570,  ..., -0.7734, -1.0996,  0.1338],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0883, -0.0276,  0.0161,  ..., -0.0097, -0.0025,  0.0226],
        [-0.0014,  0.0593,  0.0156,  ...,  0.0038, -0.0074, -0.0099],
        [ 0.0091, -0.0005,  0.0814,  ...,  0.0062,  0.0030,  0.0034],
        ...,
        [ 0.0057,  0.0164, -0.0176,  ...,  0.0737,  0.0008,  0.0020],
        [ 0.0097,  0.0118,  0.0049,  ..., -0.0075,  0.0680, -0.0168],
        [ 0.0024, -0.0179, -0.0155,  ..., -0.0146, -0.0144,  0.0640]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.4570, -2.0410,  3.2812,  ..., -0.4048, -1.1621,  0.1520]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 05:02:11 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The adjective form of regional is regionally
The adjective form of significant is significantly
The adjective form of unique is uniquely
The adjective form of famous is famously
The adjective form of according is accordingly
The adjective form of decided is decidedly
The adjective form of strong is strongly
The adjective form of creative is
2024-07-29 05:02:11 root INFO     [order_1_approx] starting weight calculation for The adjective form of unique is uniquely
The adjective form of famous is famously
The adjective form of according is accordingly
The adjective form of significant is significantly
The adjective form of strong is strongly
The adjective form of creative is creatively
The adjective form of regional is regionally
The adjective form of decided is
2024-07-29 05:02:11 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 05:04:09 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3774,  0.2195, -0.6465,  ..., -0.2559, -1.6016, -0.0786],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.8945, -4.8906,  2.2266,  ..., -0.1138, -4.4141, -1.9121],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0846, -0.0217, -0.0030,  ...,  0.0020,  0.0099,  0.0030],
        [-0.0019,  0.0684,  0.0182,  ...,  0.0068, -0.0181, -0.0162],
        [ 0.0110, -0.0138,  0.0751,  ..., -0.0130, -0.0039, -0.0055],
        ...,
        [ 0.0029,  0.0133, -0.0066,  ...,  0.0919, -0.0010,  0.0061],
        [ 0.0137, -0.0057,  0.0269,  ...,  0.0016,  0.0753, -0.0071],
        [ 0.0007, -0.0162,  0.0044,  ..., -0.0244, -0.0289,  0.0739]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.8398, -4.7695,  2.4121,  ...,  0.1733, -4.1914, -1.7451]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 05:04:10 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The adjective form of unique is uniquely
The adjective form of famous is famously
The adjective form of according is accordingly
The adjective form of significant is significantly
The adjective form of strong is strongly
The adjective form of creative is creatively
The adjective form of regional is regionally
The adjective form of decided is
2024-07-29 05:04:10 root INFO     [order_1_approx] starting weight calculation for The adjective form of decided is decidedly
The adjective form of unique is uniquely
The adjective form of significant is significantly
The adjective form of famous is famously
The adjective form of creative is creatively
The adjective form of regional is regionally
The adjective form of according is accordingly
The adjective form of strong is
2024-07-29 05:04:10 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 05:06:05 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1257, -0.8154, -0.0332,  ..., -0.3784, -0.1257, -0.5542],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.5996, -3.6094, -0.7583,  ...,  0.3457, -5.9648, -4.1406],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 8.3435e-02, -1.2154e-02, -2.4643e-03,  ..., -2.2430e-02,
         -2.5234e-03,  1.4137e-02],
        [ 4.7646e-03,  6.3171e-02,  1.8265e-02,  ...,  1.9043e-02,
          4.1809e-03, -8.5831e-03],
        [-6.6605e-03, -1.5259e-02,  6.6895e-02,  ...,  2.6550e-03,
          5.8975e-03, -1.1429e-02],
        ...,
        [ 2.8610e-05,  2.3499e-02, -8.3313e-03,  ...,  7.3120e-02,
          1.1887e-02,  1.3580e-03],
        [ 1.3046e-03, -4.6959e-03,  1.1589e-02,  ..., -1.0307e-02,
          6.8665e-02, -7.9498e-03],
        [-8.9951e-03, -4.1504e-03, -5.7678e-03,  ...,  1.0551e-02,
         -9.5367e-03,  6.5918e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.1602, -3.6738, -0.6548,  ...,  0.4255, -6.1094, -3.8887]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 05:06:06 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The adjective form of decided is decidedly
The adjective form of unique is uniquely
The adjective form of significant is significantly
The adjective form of famous is famously
The adjective form of creative is creatively
The adjective form of regional is regionally
The adjective form of according is accordingly
The adjective form of strong is
2024-07-29 05:06:06 root INFO     [order_1_approx] starting weight calculation for The adjective form of creative is creatively
The adjective form of regional is regionally
The adjective form of famous is famously
The adjective form of decided is decidedly
The adjective form of strong is strongly
The adjective form of unique is uniquely
The adjective form of significant is significantly
The adjective form of according is
2024-07-29 05:06:06 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 05:08:01 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3110, -0.5474, -1.1191,  ..., -0.8047, -0.5894, -0.6235],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.0195, -3.6875,  1.3799,  ...,  2.8555, -2.6855, -0.9492],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0970, -0.0266,  0.0108,  ...,  0.0006,  0.0310,  0.0294],
        [-0.0262,  0.0699,  0.0057,  ...,  0.0305, -0.0096, -0.0125],
        [ 0.0081, -0.0065,  0.0898,  ..., -0.0277, -0.0002, -0.0125],
        ...,
        [-0.0014,  0.0142, -0.0126,  ...,  0.1189, -0.0153,  0.0072],
        [-0.0009, -0.0102,  0.0024,  ..., -0.0215,  0.0714, -0.0255],
        [-0.0112, -0.0230, -0.0090,  ..., -0.0146, -0.0102,  0.0970]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.1141, -3.1777,  2.1445,  ...,  2.2871, -2.8457, -1.1748]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 05:08:02 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The adjective form of creative is creatively
The adjective form of regional is regionally
The adjective form of famous is famously
The adjective form of decided is decidedly
The adjective form of strong is strongly
The adjective form of unique is uniquely
The adjective form of significant is significantly
The adjective form of according is
2024-07-29 05:08:02 root INFO     [order_1_approx] starting weight calculation for The adjective form of strong is strongly
The adjective form of creative is creatively
The adjective form of regional is regionally
The adjective form of significant is significantly
The adjective form of unique is uniquely
The adjective form of decided is decidedly
The adjective form of according is accordingly
The adjective form of famous is
2024-07-29 05:08:02 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 05:09:58 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.6172, -0.1478, -0.8467,  ..., -0.3672, -0.6587, -0.2233],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.9229, -1.3809,  2.1152,  ..., -0.6016, -3.7363, -2.2793],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.1209, -0.0141,  0.0076,  ..., -0.0056, -0.0069,  0.0110],
        [-0.0041,  0.0759, -0.0005,  ...,  0.0123,  0.0060, -0.0184],
        [ 0.0331,  0.0045,  0.1072,  ..., -0.0056, -0.0172, -0.0074],
        ...,
        [ 0.0163,  0.0219, -0.0061,  ...,  0.1073, -0.0073, -0.0034],
        [ 0.0050,  0.0072,  0.0035,  ..., -0.0053,  0.0565, -0.0079],
        [ 0.0134, -0.0022, -0.0101,  ..., -0.0071, -0.0134,  0.0754]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.9922, -0.8921,  2.1289,  ..., -0.4360, -3.8926, -2.4941]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 05:09:59 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The adjective form of strong is strongly
The adjective form of creative is creatively
The adjective form of regional is regionally
The adjective form of significant is significantly
The adjective form of unique is uniquely
The adjective form of decided is decidedly
The adjective form of according is accordingly
The adjective form of famous is
2024-07-29 05:09:59 root INFO     total operator prediction time: 945.4025375843048 seconds
2024-07-29 05:09:59 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on over+adj_reg
2024-07-29 05:09:59 root INFO     building operator over+adj_reg
2024-07-29 05:09:59 root INFO     [order_1_approx] starting weight calculation for If something is too stimulated, it is overstimulated
If something is too played, it is overplayed
If something is too populated, it is overpopulated
If something is too grown, it is overgrown
If something is too thrown, it is overthrown
If something is too simplified, it is oversimplified
If something is too taken, it is overtaken
If something is too confident, it is
2024-07-29 05:09:59 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 05:11:54 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2729, -0.0411, -0.8887,  ...,  0.4175, -0.3389, -0.0472],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.4326, -3.7070,  2.1621,  ...,  1.7188, -1.6641, -1.2305],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0464, -0.0125,  0.0043,  ..., -0.0122,  0.0064,  0.0056],
        [-0.0076,  0.0436, -0.0004,  ...,  0.0222,  0.0144,  0.0013],
        [ 0.0147,  0.0027,  0.0530,  ..., -0.0030, -0.0013, -0.0068],
        ...,
        [-0.0065,  0.0044, -0.0032,  ...,  0.0608,  0.0079,  0.0016],
        [ 0.0126,  0.0077,  0.0192,  ..., -0.0070,  0.0437, -0.0139],
        [ 0.0072,  0.0027, -0.0010,  ..., -0.0017, -0.0077,  0.0437]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.6826, -3.5371,  2.1094,  ...,  1.8008, -2.0391, -1.4775]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 05:11:55 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is too stimulated, it is overstimulated
If something is too played, it is overplayed
If something is too populated, it is overpopulated
If something is too grown, it is overgrown
If something is too thrown, it is overthrown
If something is too simplified, it is oversimplified
If something is too taken, it is overtaken
If something is too confident, it is
2024-07-29 05:11:55 root INFO     [order_1_approx] starting weight calculation for If something is too thrown, it is overthrown
If something is too populated, it is overpopulated
If something is too played, it is overplayed
If something is too grown, it is overgrown
If something is too confident, it is overconfident
If something is too stimulated, it is overstimulated
If something is too taken, it is overtaken
If something is too simplified, it is
2024-07-29 05:11:55 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 05:13:50 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1996,  0.0113, -1.1611,  ..., -1.0820, -0.3733,  0.6938],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.1367, -2.1465,  1.1484,  ..., -1.0098, -2.2598, -0.7471],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 7.1838e-02, -5.8174e-03,  1.2398e-02,  ..., -7.6904e-03,
         -1.5116e-03, -5.1346e-03],
        [ 5.8975e-03,  5.1514e-02,  5.5199e-03,  ...,  2.7180e-03,
          6.0120e-03, -7.9651e-03],
        [ 9.4528e-03, -8.1406e-03,  6.3049e-02,  ..., -8.9645e-05,
         -2.4147e-03, -9.3536e-03],
        ...,
        [ 8.6670e-03,  4.5319e-03,  4.9667e-03,  ...,  7.7637e-02,
          5.7640e-03,  4.0512e-03],
        [-4.4975e-03,  3.5591e-03,  7.2975e-03,  ..., -3.1452e-03,
          6.1523e-02, -1.6083e-02],
        [ 4.2391e-04,  1.9684e-02, -8.1177e-03,  ..., -1.0254e-02,
         -1.2032e-02,  5.2887e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.8887, -1.9941,  0.7817,  ..., -0.7725, -2.4980, -1.0391]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 05:13:51 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is too thrown, it is overthrown
If something is too populated, it is overpopulated
If something is too played, it is overplayed
If something is too grown, it is overgrown
If something is too confident, it is overconfident
If something is too stimulated, it is overstimulated
If something is too taken, it is overtaken
If something is too simplified, it is
2024-07-29 05:13:51 root INFO     [order_1_approx] starting weight calculation for If something is too thrown, it is overthrown
If something is too played, it is overplayed
If something is too simplified, it is oversimplified
If something is too taken, it is overtaken
If something is too confident, it is overconfident
If something is too stimulated, it is overstimulated
If something is too populated, it is overpopulated
If something is too grown, it is
2024-07-29 05:13:52 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 05:15:47 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2000, -0.3853, -0.3953,  ..., -1.1719, -1.6123, -0.4819],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.8872, -3.6309,  1.5762,  ..., -0.2443, -1.0879, -2.1914],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 8.2458e-02, -4.0131e-03,  1.5610e-02,  ...,  3.0518e-05,
          8.1558e-03,  1.6632e-02],
        [ 1.2760e-03,  5.7861e-02, -1.4473e-02,  ...,  1.5732e-02,
         -1.9073e-03, -5.8823e-03],
        [ 1.2161e-02, -6.2027e-03,  8.6182e-02,  ..., -8.7051e-03,
          2.2934e-02,  1.0849e-02],
        ...,
        [-2.9678e-03,  1.0178e-02, -9.3918e-03,  ...,  9.3384e-02,
          9.7809e-03,  1.3962e-03],
        [-1.0971e-02,  4.7073e-03, -7.5531e-04,  ..., -8.4229e-03,
          7.3914e-02, -2.6382e-02],
        [-1.4702e-02,  4.0703e-03, -4.6577e-03,  ..., -1.0902e-02,
         -1.9287e-02,  8.1909e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.0938, -3.6738,  1.7305,  ..., -0.0822, -0.9443, -2.2188]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 05:15:48 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is too thrown, it is overthrown
If something is too played, it is overplayed
If something is too simplified, it is oversimplified
If something is too taken, it is overtaken
If something is too confident, it is overconfident
If something is too stimulated, it is overstimulated
If something is too populated, it is overpopulated
If something is too grown, it is
2024-07-29 05:15:48 root INFO     [order_1_approx] starting weight calculation for If something is too simplified, it is oversimplified
If something is too thrown, it is overthrown
If something is too grown, it is overgrown
If something is too stimulated, it is overstimulated
If something is too taken, it is overtaken
If something is too confident, it is overconfident
If something is too populated, it is overpopulated
If something is too played, it is
2024-07-29 05:15:48 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 05:17:43 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0283, -0.5996, -0.3813,  ..., -0.6289, -1.6504, -0.1543],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.4268, -2.9023,  0.7485,  ..., -0.5415, -1.1797, -2.3184],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.1220, -0.0068,  0.0239,  ...,  0.0048,  0.0121,  0.0051],
        [-0.0090,  0.0867, -0.0246,  ...,  0.0135,  0.0060, -0.0125],
        [ 0.0111, -0.0035,  0.0913,  ..., -0.0087,  0.0124, -0.0027],
        ...,
        [ 0.0010,  0.0193, -0.0157,  ...,  0.1088,  0.0036,  0.0096],
        [ 0.0050,  0.0067,  0.0140,  ..., -0.0168,  0.0983, -0.0184],
        [-0.0011,  0.0144, -0.0088,  ..., -0.0057, -0.0115,  0.0861]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.8535, -3.1816,  0.9238,  ..., -0.6406, -1.0723, -2.2676]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 05:17:44 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is too simplified, it is oversimplified
If something is too thrown, it is overthrown
If something is too grown, it is overgrown
If something is too stimulated, it is overstimulated
If something is too taken, it is overtaken
If something is too confident, it is overconfident
If something is too populated, it is overpopulated
If something is too played, it is
2024-07-29 05:17:44 root INFO     [order_1_approx] starting weight calculation for If something is too taken, it is overtaken
If something is too grown, it is overgrown
If something is too played, it is overplayed
If something is too simplified, it is oversimplified
If something is too confident, it is overconfident
If something is too populated, it is overpopulated
If something is too thrown, it is overthrown
If something is too stimulated, it is
2024-07-29 05:17:44 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 05:19:40 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.7676, -0.1373, -0.5469,  ..., -0.7012, -1.2812, -0.2400],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.1016, -2.0605,  1.4922,  ..., -0.1794, -1.5508, -2.6914],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0618,  0.0002,  0.0061,  ..., -0.0051,  0.0019,  0.0030],
        [-0.0006,  0.0484, -0.0055,  ...,  0.0043,  0.0043, -0.0033],
        [ 0.0095, -0.0058,  0.0350,  ..., -0.0010, -0.0002, -0.0017],
        ...,
        [ 0.0022,  0.0120, -0.0041,  ...,  0.0551,  0.0110,  0.0018],
        [ 0.0038,  0.0049,  0.0055,  ...,  0.0048,  0.0412, -0.0077],
        [-0.0042,  0.0105, -0.0041,  ...,  0.0002, -0.0032,  0.0446]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.1895, -2.0996,  1.3359,  ...,  0.0468, -1.7900, -2.5859]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 05:19:41 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is too taken, it is overtaken
If something is too grown, it is overgrown
If something is too played, it is overplayed
If something is too simplified, it is oversimplified
If something is too confident, it is overconfident
If something is too populated, it is overpopulated
If something is too thrown, it is overthrown
If something is too stimulated, it is
2024-07-29 05:19:41 root INFO     [order_1_approx] starting weight calculation for If something is too simplified, it is oversimplified
If something is too populated, it is overpopulated
If something is too played, it is overplayed
If something is too grown, it is overgrown
If something is too stimulated, it is overstimulated
If something is too taken, it is overtaken
If something is too confident, it is overconfident
If something is too thrown, it is
2024-07-29 05:19:41 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 05:21:35 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2122, -0.6113, -0.6094,  ..., -1.1689, -0.8892,  0.3496],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.5518, -3.3828,  0.7773,  ...,  0.4958, -1.5635, -1.8828],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.1197,  0.0026,  0.0113,  ..., -0.0018,  0.0131,  0.0082],
        [-0.0149,  0.0799, -0.0180,  ...,  0.0146,  0.0076, -0.0081],
        [ 0.0221, -0.0133,  0.0780,  ..., -0.0044, -0.0111, -0.0080],
        ...,
        [-0.0006,  0.0157, -0.0153,  ...,  0.1036,  0.0082,  0.0044],
        [-0.0119, -0.0222,  0.0346,  ..., -0.0023,  0.1121, -0.0112],
        [-0.0049,  0.0186, -0.0117,  ..., -0.0145, -0.0227,  0.0797]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.9053, -3.4844,  0.6230,  ...,  0.5703, -1.2920, -2.0195]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 05:21:36 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is too simplified, it is oversimplified
If something is too populated, it is overpopulated
If something is too played, it is overplayed
If something is too grown, it is overgrown
If something is too stimulated, it is overstimulated
If something is too taken, it is overtaken
If something is too confident, it is overconfident
If something is too thrown, it is
2024-07-29 05:21:37 root INFO     [order_1_approx] starting weight calculation for If something is too grown, it is overgrown
If something is too stimulated, it is overstimulated
If something is too thrown, it is overthrown
If something is too confident, it is overconfident
If something is too played, it is overplayed
If something is too simplified, it is oversimplified
If something is too taken, it is overtaken
If something is too populated, it is
2024-07-29 05:21:37 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 05:23:32 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.3765,  0.4043, -0.3164,  ...,  0.2664, -0.8135, -0.1259],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.1152, -2.4961,  0.7173,  ..., -1.0156, -0.7563, -1.6152],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0572, -0.0104,  0.0037,  ...,  0.0017,  0.0078,  0.0077],
        [ 0.0051,  0.0413, -0.0075,  ...,  0.0150,  0.0081, -0.0057],
        [ 0.0042, -0.0046,  0.0536,  ..., -0.0035,  0.0024, -0.0019],
        ...,
        [ 0.0097,  0.0116,  0.0072,  ...,  0.0553,  0.0064,  0.0028],
        [-0.0027,  0.0087,  0.0039,  ..., -0.0053,  0.0540, -0.0074],
        [-0.0012,  0.0014,  0.0046,  ..., -0.0021, -0.0201,  0.0445]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.1738, -2.3477,  0.8545,  ..., -1.0479, -0.6680, -1.8213]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 05:23:33 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is too grown, it is overgrown
If something is too stimulated, it is overstimulated
If something is too thrown, it is overthrown
If something is too confident, it is overconfident
If something is too played, it is overplayed
If something is too simplified, it is oversimplified
If something is too taken, it is overtaken
If something is too populated, it is
2024-07-29 05:23:33 root INFO     [order_1_approx] starting weight calculation for If something is too confident, it is overconfident
If something is too stimulated, it is overstimulated
If something is too populated, it is overpopulated
If something is too simplified, it is oversimplified
If something is too thrown, it is overthrown
If something is too played, it is overplayed
If something is too grown, it is overgrown
If something is too taken, it is
2024-07-29 05:23:33 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 05:25:28 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2230, -0.3496, -0.4539,  ..., -0.7363, -0.3010, -0.1371],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.2871, -3.3750,  0.6123,  ..., -0.3203, -1.8223, -2.2402],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0970, -0.0168,  0.0213,  ..., -0.0046,  0.0012,  0.0116],
        [-0.0026,  0.0870, -0.0170,  ...,  0.0155,  0.0031, -0.0038],
        [ 0.0075, -0.0232,  0.0846,  ...,  0.0084,  0.0124, -0.0101],
        ...,
        [ 0.0056,  0.0075,  0.0070,  ...,  0.1157,  0.0038, -0.0127],
        [ 0.0001, -0.0091,  0.0167,  ..., -0.0014,  0.1033, -0.0152],
        [-0.0035,  0.0123, -0.0063,  ...,  0.0012, -0.0047,  0.0955]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.2500, -3.4707,  0.7134,  ..., -0.0773, -1.6738, -1.8320]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 05:25:29 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is too confident, it is overconfident
If something is too stimulated, it is overstimulated
If something is too populated, it is overpopulated
If something is too simplified, it is oversimplified
If something is too thrown, it is overthrown
If something is too played, it is overplayed
If something is too grown, it is overgrown
If something is too taken, it is
2024-07-29 05:25:29 root INFO     total operator prediction time: 929.5426931381226 seconds
2024-07-29 05:25:29 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on verb+er_irreg
2024-07-29 05:25:29 root INFO     building operator verb+er_irreg
2024-07-29 05:25:29 root INFO     [order_1_approx] starting weight calculation for If you provide something, you are a provider
If you bake something, you are a baker
If you publish something, you are a publisher
If you follow something, you are a follower
If you listen something, you are a listener
If you molest something, you are a molester
If you determine something, you are a determiner
If you deliver something, you are a
2024-07-29 05:25:29 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 05:27:23 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4414, -0.0541,  0.2981,  ...,  0.0798, -0.5107,  0.3369],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 5.1562, -4.3281,  1.5928,  ..., -1.1104, -4.8750, -2.5137],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0734,  0.0060,  0.0159,  ...,  0.0011,  0.0056,  0.0011],
        [-0.0191,  0.0544,  0.0041,  ...,  0.0167,  0.0142, -0.0100],
        [ 0.0241, -0.0002,  0.0545,  ..., -0.0070, -0.0049, -0.0048],
        ...,
        [ 0.0146,  0.0265, -0.0026,  ...,  0.0705, -0.0107,  0.0061],
        [ 0.0035,  0.0003,  0.0134,  ..., -0.0146,  0.0558, -0.0179],
        [ 0.0018,  0.0013, -0.0067,  ..., -0.0017, -0.0073,  0.0712]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 5.1641, -4.4297,  1.6426,  ..., -1.0879, -5.0000, -2.4824]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 05:27:25 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you provide something, you are a provider
If you bake something, you are a baker
If you publish something, you are a publisher
If you follow something, you are a follower
If you listen something, you are a listener
If you molest something, you are a molester
If you determine something, you are a determiner
If you deliver something, you are a
2024-07-29 05:27:25 root INFO     [order_1_approx] starting weight calculation for If you molest something, you are a molester
If you publish something, you are a publisher
If you provide something, you are a provider
If you determine something, you are a determiner
If you bake something, you are a baker
If you follow something, you are a follower
If you deliver something, you are a deliverer
If you listen something, you are a
2024-07-29 05:27:25 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 05:29:21 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.5278, -0.8281,  0.3291,  ...,  0.0298, -0.4121,  0.0801],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.5195, -2.8730,  1.5723,  ..., -0.0430, -4.3242, -4.3242],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0577,  0.0047,  0.0110,  ...,  0.0045,  0.0014,  0.0152],
        [-0.0099,  0.0565,  0.0007,  ...,  0.0204,  0.0151,  0.0040],
        [ 0.0142, -0.0088,  0.0532,  ..., -0.0104, -0.0073,  0.0034],
        ...,
        [ 0.0192,  0.0028, -0.0025,  ...,  0.0492, -0.0152, -0.0004],
        [ 0.0031, -0.0011,  0.0069,  ..., -0.0129,  0.0478, -0.0102],
        [-0.0063,  0.0025,  0.0007,  ...,  0.0021,  0.0017,  0.0460]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.6094, -2.7500,  1.7920,  ..., -0.0414, -4.7578, -4.2852]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 05:29:22 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you molest something, you are a molester
If you publish something, you are a publisher
If you provide something, you are a provider
If you determine something, you are a determiner
If you bake something, you are a baker
If you follow something, you are a follower
If you deliver something, you are a deliverer
If you listen something, you are a
2024-07-29 05:29:22 root INFO     [order_1_approx] starting weight calculation for If you provide something, you are a provider
If you bake something, you are a baker
If you publish something, you are a publisher
If you listen something, you are a listener
If you deliver something, you are a deliverer
If you follow something, you are a follower
If you determine something, you are a determiner
If you molest something, you are a
2024-07-29 05:29:22 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 05:31:15 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2238, -0.2786,  0.3096,  ..., -0.9243, -1.0713,  0.4607],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.8887, -3.3809, -1.2080,  ..., -2.3633, -4.2383, -0.1924],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0857, -0.0049,  0.0315,  ...,  0.0016, -0.0015, -0.0005],
        [-0.0011,  0.0470, -0.0219,  ...,  0.0316,  0.0075, -0.0056],
        [ 0.0097, -0.0057,  0.0619,  ...,  0.0099, -0.0067, -0.0173],
        ...,
        [ 0.0021,  0.0023, -0.0047,  ...,  0.1122,  0.0004,  0.0091],
        [ 0.0098, -0.0008,  0.0182,  ..., -0.0100,  0.0826, -0.0155],
        [ 0.0090,  0.0190,  0.0031,  ..., -0.0203, -0.0175,  0.0859]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.8066, -3.1348, -0.8379,  ..., -2.2441, -3.9453, -0.2629]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 05:31:16 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you provide something, you are a provider
If you bake something, you are a baker
If you publish something, you are a publisher
If you listen something, you are a listener
If you deliver something, you are a deliverer
If you follow something, you are a follower
If you determine something, you are a determiner
If you molest something, you are a
2024-07-29 05:31:17 root INFO     [order_1_approx] starting weight calculation for If you bake something, you are a baker
If you follow something, you are a follower
If you provide something, you are a provider
If you molest something, you are a molester
If you deliver something, you are a deliverer
If you publish something, you are a publisher
If you listen something, you are a listener
If you determine something, you are a
2024-07-29 05:31:17 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 05:33:08 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1091,  0.0940, -0.0973,  ...,  0.1210, -1.6250, -0.1466],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.3594, -3.6484,  3.0762,  ..., -2.0703, -5.0391, -4.0898],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 8.6914e-02,  1.0452e-02,  2.7283e-02,  ..., -7.6294e-05,
         -8.9417e-03,  1.1806e-03],
        [-7.0610e-03,  6.6223e-02,  1.5778e-02,  ...,  3.9978e-02,
          8.9645e-03, -3.9558e-03],
        [ 1.3550e-02, -8.8806e-03,  6.8054e-02,  ..., -6.5041e-03,
          1.1581e-02, -9.3765e-03],
        ...,
        [ 2.0752e-02,  1.9958e-02,  1.1002e-02,  ...,  8.6121e-02,
         -7.1259e-03,  1.0506e-02],
        [-1.2932e-03,  8.4877e-04,  1.6220e-02,  ..., -4.8676e-03,
          7.8430e-02, -1.1282e-03],
        [ 6.1340e-03,  2.1095e-03, -5.5771e-03,  ..., -2.7313e-03,
         -2.0981e-02,  6.9336e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.1602, -3.1992,  2.9961,  ..., -1.7871, -5.2578, -4.2227]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 05:33:09 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you bake something, you are a baker
If you follow something, you are a follower
If you provide something, you are a provider
If you molest something, you are a molester
If you deliver something, you are a deliverer
If you publish something, you are a publisher
If you listen something, you are a listener
If you determine something, you are a
2024-07-29 05:33:09 root INFO     [order_1_approx] starting weight calculation for If you molest something, you are a molester
If you listen something, you are a listener
If you determine something, you are a determiner
If you deliver something, you are a deliverer
If you bake something, you are a baker
If you publish something, you are a publisher
If you provide something, you are a provider
If you follow something, you are a
2024-07-29 05:33:10 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 05:35:04 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3875, -0.6528,  0.6680,  ...,  0.4885, -0.2666,  0.3701],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.4199, -1.8535,  4.7578,  ..., -0.2715, -7.1484, -1.3887],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 7.1167e-02, -2.0313e-03,  1.4931e-02,  ...,  1.3550e-02,
          4.3449e-03,  1.2924e-02],
        [-7.1640e-03,  6.4880e-02, -1.4725e-03,  ...,  2.2797e-02,
          4.1428e-03, -2.4094e-02],
        [ 1.5137e-02,  7.7629e-04,  5.7281e-02,  ..., -8.2626e-03,
         -6.6757e-05, -1.1032e-02],
        ...,
        [ 4.0054e-03,  1.2573e-02,  4.2152e-04,  ...,  5.6091e-02,
         -1.2192e-02,  1.4629e-03],
        [ 2.6188e-03,  1.4786e-02,  1.7227e-02,  ..., -1.3992e-02,
          5.9021e-02, -2.1500e-02],
        [ 3.0594e-03,  3.6774e-03, -5.8441e-03,  ..., -2.8419e-03,
         -1.1414e-02,  6.3416e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.4434, -1.8945,  4.5859,  ..., -0.1892, -7.2852, -1.3789]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 05:35:05 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you molest something, you are a molester
If you listen something, you are a listener
If you determine something, you are a determiner
If you deliver something, you are a deliverer
If you bake something, you are a baker
If you publish something, you are a publisher
If you provide something, you are a provider
If you follow something, you are a
2024-07-29 05:35:05 root INFO     [order_1_approx] starting weight calculation for If you deliver something, you are a deliverer
If you bake something, you are a baker
If you publish something, you are a publisher
If you follow something, you are a follower
If you determine something, you are a determiner
If you molest something, you are a molester
If you listen something, you are a listener
If you provide something, you are a
2024-07-29 05:35:05 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 05:37:00 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2788, -0.5361,  0.0962,  ...,  0.0665, -0.8262, -0.4482],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.9141, -7.0195,  1.5830,  ...,  0.5869, -5.7891, -1.5859],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0847, -0.0053,  0.0271,  ...,  0.0032, -0.0037,  0.0147],
        [-0.0247,  0.0715, -0.0079,  ...,  0.0261,  0.0178,  0.0009],
        [ 0.0121, -0.0158,  0.0683,  ..., -0.0210, -0.0059, -0.0065],
        ...,
        [ 0.0102,  0.0127,  0.0048,  ...,  0.0832, -0.0009,  0.0182],
        [ 0.0182, -0.0016,  0.0175,  ..., -0.0295,  0.0814, -0.0291],
        [ 0.0173,  0.0140, -0.0060,  ..., -0.0270, -0.0188,  0.0895]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.8535, -7.1641,  1.5352,  ...,  0.6880, -5.7266, -1.4492]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 05:37:01 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you deliver something, you are a deliverer
If you bake something, you are a baker
If you publish something, you are a publisher
If you follow something, you are a follower
If you determine something, you are a determiner
If you molest something, you are a molester
If you listen something, you are a listener
If you provide something, you are a
2024-07-29 05:37:02 root INFO     [order_1_approx] starting weight calculation for If you deliver something, you are a deliverer
If you provide something, you are a provider
If you molest something, you are a molester
If you bake something, you are a baker
If you listen something, you are a listener
If you determine something, you are a determiner
If you follow something, you are a follower
If you publish something, you are a
2024-07-29 05:37:02 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 05:38:57 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.3643, -0.2217,  0.2886,  ...,  0.3979, -0.4846,  0.4729],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.9180, -4.4922,  1.5020,  ..., -0.6523, -5.1250, -2.2129],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0655,  0.0034,  0.0164,  ...,  0.0060, -0.0078,  0.0191],
        [-0.0091,  0.0589, -0.0066,  ...,  0.0205,  0.0069,  0.0012],
        [ 0.0282, -0.0072,  0.0615,  ..., -0.0079, -0.0091,  0.0045],
        ...,
        [ 0.0045,  0.0124, -0.0039,  ...,  0.0656, -0.0015,  0.0027],
        [-0.0016, -0.0031,  0.0105,  ..., -0.0181,  0.0599, -0.0182],
        [ 0.0071,  0.0013,  0.0031,  ..., -0.0179, -0.0105,  0.0584]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.1445, -4.7188,  1.1816,  ..., -0.4888, -5.0781, -2.0840]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 05:38:58 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you deliver something, you are a deliverer
If you provide something, you are a provider
If you molest something, you are a molester
If you bake something, you are a baker
If you listen something, you are a listener
If you determine something, you are a determiner
If you follow something, you are a follower
If you publish something, you are a
2024-07-29 05:38:59 root INFO     [order_1_approx] starting weight calculation for If you deliver something, you are a deliverer
If you determine something, you are a determiner
If you molest something, you are a molester
If you provide something, you are a provider
If you follow something, you are a follower
If you publish something, you are a publisher
If you listen something, you are a listener
If you bake something, you are a
2024-07-29 05:38:59 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 05:40:54 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4883, -0.0181,  0.1084,  ...,  0.2729, -1.4277, -0.1776],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.8984, -1.9629, -0.3047,  ...,  0.2246, -4.7227, -2.9375],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 4.7577e-02, -1.1841e-02,  1.3527e-02,  ..., -1.4954e-02,
          5.3444e-03,  9.3002e-03],
        [-1.1253e-03,  5.3040e-02,  1.2451e-02,  ...,  1.0834e-02,
          9.9564e-03,  9.9030e-03],
        [ 9.4757e-03, -1.3199e-02,  5.1392e-02,  ..., -1.8234e-02,
          8.7128e-03, -4.3602e-03],
        ...,
        [ 2.6207e-03,  8.6899e-03, -7.6294e-06,  ...,  5.7739e-02,
          2.5597e-03, -1.0117e-02],
        [-3.3531e-03,  9.8572e-03,  9.2316e-03,  ..., -2.2522e-02,
          4.7974e-02, -4.6349e-03],
        [-3.0270e-03,  4.9171e-03, -5.2948e-03,  ...,  4.9629e-03,
         -2.3346e-03,  5.5603e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 5.0078, -2.2344, -0.1975,  ...,  0.2341, -4.5273, -2.9082]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 05:40:55 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you deliver something, you are a deliverer
If you determine something, you are a determiner
If you molest something, you are a molester
If you provide something, you are a provider
If you follow something, you are a follower
If you publish something, you are a publisher
If you listen something, you are a listener
If you bake something, you are a
2024-07-29 05:40:55 root INFO     total operator prediction time: 926.2274692058563 seconds
2024-07-29 05:40:55 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on adj - superlative
2024-07-29 05:40:55 root INFO     building operator adj - superlative
2024-07-29 05:40:55 root INFO     [order_1_approx] starting weight calculation for If something is the most scary, it is scariest
If something is the most cruel, it is cruelest
If something is the most weak, it is weakest
If something is the most mild, it is mildest
If something is the most noisy, it is noisiest
If something is the most risky, it is riskiest
If something is the most strong, it is strongest
If something is the most sunny, it is
2024-07-29 05:40:55 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 05:42:49 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2622,  0.1921, -0.0496,  ..., -0.5483, -0.3689, -0.6748],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.4941, -0.5029, -2.2988,  ...,  1.2656, -3.5762, -0.2002],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0676, -0.0168,  0.0042,  ..., -0.0022,  0.0052,  0.0050],
        [-0.0091,  0.0625, -0.0010,  ...,  0.0038,  0.0180, -0.0050],
        [-0.0093, -0.0061,  0.0594,  ..., -0.0065, -0.0029, -0.0086],
        ...,
        [ 0.0135,  0.0185, -0.0017,  ...,  0.0629,  0.0033,  0.0017],
        [ 0.0022, -0.0008, -0.0023,  ...,  0.0035,  0.0557, -0.0056],
        [ 0.0017, -0.0026,  0.0070,  ..., -0.0099, -0.0007,  0.0560]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.5918, -0.3872, -2.2852,  ...,  1.3027, -3.2383, -0.2042]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 05:42:54 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is the most scary, it is scariest
If something is the most cruel, it is cruelest
If something is the most weak, it is weakest
If something is the most mild, it is mildest
If something is the most noisy, it is noisiest
If something is the most risky, it is riskiest
If something is the most strong, it is strongest
If something is the most sunny, it is
2024-07-29 05:42:54 root INFO     [order_1_approx] starting weight calculation for If something is the most cruel, it is cruelest
If something is the most mild, it is mildest
If something is the most weak, it is weakest
If something is the most sunny, it is sunniest
If something is the most strong, it is strongest
If something is the most risky, it is riskiest
If something is the most noisy, it is noisiest
If something is the most scary, it is
2024-07-29 05:42:54 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 05:44:49 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1423,  0.6235, -0.3101,  ..., -0.6035, -0.6885, -0.0094],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-2.2129, -4.2188, -1.2998,  ..., -2.4141, -1.3027, -1.2012],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0484, -0.0004,  0.0222,  ...,  0.0085,  0.0088,  0.0080],
        [ 0.0149,  0.0364,  0.0025,  ...,  0.0020,  0.0178, -0.0119],
        [ 0.0006, -0.0121,  0.0321,  ..., -0.0043, -0.0057, -0.0078],
        ...,
        [ 0.0076,  0.0150, -0.0061,  ...,  0.0352,  0.0064, -0.0023],
        [ 0.0099, -0.0015,  0.0132,  ...,  0.0002,  0.0317, -0.0025],
        [ 0.0090,  0.0038,  0.0027,  ..., -0.0046,  0.0010,  0.0289]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-2.2031, -4.3594, -1.4004,  ..., -2.4043, -1.3047, -1.1436]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 05:44:50 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is the most cruel, it is cruelest
If something is the most mild, it is mildest
If something is the most weak, it is weakest
If something is the most sunny, it is sunniest
If something is the most strong, it is strongest
If something is the most risky, it is riskiest
If something is the most noisy, it is noisiest
If something is the most scary, it is
2024-07-29 05:44:50 root INFO     [order_1_approx] starting weight calculation for If something is the most risky, it is riskiest
If something is the most weak, it is weakest
If something is the most strong, it is strongest
If something is the most scary, it is scariest
If something is the most mild, it is mildest
If something is the most noisy, it is noisiest
If something is the most sunny, it is sunniest
If something is the most cruel, it is
2024-07-29 05:44:50 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 05:46:45 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.7676,  0.3052,  0.2161,  ..., -1.0723, -0.2627,  0.0019],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.1564, -3.9297, -1.2070,  ..., -1.4971,  0.4180,  0.6841],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 5.6732e-02,  2.8801e-04,  2.6306e-02,  ...,  6.0310e-03,
         -7.0381e-04,  1.4824e-02],
        [ 5.1041e-03,  4.5715e-02,  6.2790e-03,  ...,  5.9357e-03,
          1.4374e-02, -3.7289e-03],
        [ 3.6278e-03,  3.8528e-04,  5.7343e-02,  ..., -6.8359e-03,
         -1.1322e-02, -8.1329e-03],
        ...,
        [ 1.1017e-02,  1.7212e-02,  2.4796e-05,  ...,  4.7485e-02,
          1.0452e-03, -5.4016e-03],
        [ 2.2095e-02,  4.7035e-03,  1.5221e-02,  ..., -1.0635e-02,
          5.0262e-02, -1.0834e-02],
        [-5.1956e-03, -2.1057e-03, -8.0490e-03,  ..., -7.5607e-03,
         -1.3752e-03,  3.6560e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.4199, -3.8359, -1.0732,  ..., -1.4043,  0.1697,  0.7217]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 05:46:46 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is the most risky, it is riskiest
If something is the most weak, it is weakest
If something is the most strong, it is strongest
If something is the most scary, it is scariest
If something is the most mild, it is mildest
If something is the most noisy, it is noisiest
If something is the most sunny, it is sunniest
If something is the most cruel, it is
2024-07-29 05:46:46 root INFO     [order_1_approx] starting weight calculation for If something is the most sunny, it is sunniest
If something is the most mild, it is mildest
If something is the most strong, it is strongest
If something is the most scary, it is scariest
If something is the most risky, it is riskiest
If something is the most weak, it is weakest
If something is the most cruel, it is cruelest
If something is the most noisy, it is
2024-07-29 05:46:46 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 05:48:39 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.4192,  0.1418,  0.3267,  ..., -0.2839, -0.4575, -0.2720],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-4.9844, -3.5898, -0.3770,  ..., -1.4150, -1.7422,  0.0527],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0583, -0.0032,  0.0170,  ...,  0.0115, -0.0060,  0.0167],
        [-0.0077,  0.0458,  0.0021,  ...,  0.0116,  0.0149, -0.0060],
        [ 0.0044, -0.0055,  0.0457,  ..., -0.0063,  0.0153, -0.0080],
        ...,
        [ 0.0128,  0.0187,  0.0095,  ...,  0.0412, -0.0057,  0.0044],
        [ 0.0064,  0.0042, -0.0003,  ...,  0.0039,  0.0471, -0.0039],
        [ 0.0034,  0.0067, -0.0088,  ..., -0.0136, -0.0071,  0.0387]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-4.8516, -3.3633, -0.5767,  ..., -1.2725, -1.6357,  0.1287]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 05:48:40 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is the most sunny, it is sunniest
If something is the most mild, it is mildest
If something is the most strong, it is strongest
If something is the most scary, it is scariest
If something is the most risky, it is riskiest
If something is the most weak, it is weakest
If something is the most cruel, it is cruelest
If something is the most noisy, it is
2024-07-29 05:48:40 root INFO     [order_1_approx] starting weight calculation for If something is the most noisy, it is noisiest
If something is the most sunny, it is sunniest
If something is the most cruel, it is cruelest
If something is the most mild, it is mildest
If something is the most scary, it is scariest
If something is the most risky, it is riskiest
If something is the most weak, it is weakest
If something is the most strong, it is
2024-07-29 05:48:41 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 05:50:34 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3794, -0.6035,  0.0266,  ..., -0.5356,  0.0154, -0.8916],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.1602, -6.2617, -2.5645,  ...,  0.1045, -2.1621, -1.9453],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0284, -0.0005, -0.0028,  ..., -0.0173, -0.0059,  0.0061],
        [ 0.0058,  0.0231,  0.0047,  ...,  0.0031,  0.0024,  0.0034],
        [ 0.0038, -0.0058,  0.0165,  ...,  0.0012, -0.0045, -0.0051],
        ...,
        [ 0.0060,  0.0097, -0.0019,  ...,  0.0203,  0.0009,  0.0031],
        [-0.0009, -0.0032,  0.0066,  ..., -0.0094,  0.0193, -0.0092],
        [-0.0026,  0.0013,  0.0017,  ..., -0.0055, -0.0048,  0.0214]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.0176e+00, -6.2344e+00, -2.5566e+00,  ..., -4.2725e-03,
         -2.3926e+00, -2.0918e+00]], device='cuda:1', dtype=torch.float16,
       grad_fn=<SubBackward0>) 

                    
2024-07-29 05:50:35 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is the most noisy, it is noisiest
If something is the most sunny, it is sunniest
If something is the most cruel, it is cruelest
If something is the most mild, it is mildest
If something is the most scary, it is scariest
If something is the most risky, it is riskiest
If something is the most weak, it is weakest
If something is the most strong, it is
2024-07-29 05:50:35 root INFO     [order_1_approx] starting weight calculation for If something is the most strong, it is strongest
If something is the most sunny, it is sunniest
If something is the most mild, it is mildest
If something is the most cruel, it is cruelest
If something is the most noisy, it is noisiest
If something is the most scary, it is scariest
If something is the most weak, it is weakest
If something is the most risky, it is
2024-07-29 05:50:35 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 05:52:25 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.4141,  0.4270, -0.8374,  ..., -0.5845, -0.3198, -0.6152],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-2.8945, -4.8125, -2.2285,  ..., -3.4141, -0.1777,  0.4248],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0446,  0.0013,  0.0180,  ..., -0.0019,  0.0013,  0.0165],
        [-0.0028,  0.0385,  0.0052,  ...,  0.0112,  0.0081, -0.0030],
        [ 0.0041,  0.0016,  0.0311,  ..., -0.0019, -0.0053,  0.0008],
        ...,
        [ 0.0055,  0.0082, -0.0028,  ...,  0.0421,  0.0135,  0.0013],
        [ 0.0155,  0.0005,  0.0031,  ..., -0.0028,  0.0437, -0.0061],
        [ 0.0021, -0.0018,  0.0006,  ..., -0.0034, -0.0068,  0.0329]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-2.9395, -4.7617, -2.1973,  ..., -3.1934, -0.2306,  0.4917]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 05:52:26 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is the most strong, it is strongest
If something is the most sunny, it is sunniest
If something is the most mild, it is mildest
If something is the most cruel, it is cruelest
If something is the most noisy, it is noisiest
If something is the most scary, it is scariest
If something is the most weak, it is weakest
If something is the most risky, it is
2024-07-29 05:52:26 root INFO     [order_1_approx] starting weight calculation for If something is the most strong, it is strongest
If something is the most risky, it is riskiest
If something is the most scary, it is scariest
If something is the most sunny, it is sunniest
If something is the most cruel, it is cruelest
If something is the most noisy, it is noisiest
If something is the most weak, it is weakest
If something is the most mild, it is
2024-07-29 05:52:26 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 05:54:20 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2007,  0.2131, -0.0265,  ..., -0.9531,  0.1337, -0.2156],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.0566, -3.2383, -0.6191,  ..., -2.4102, -2.7676, -2.0977],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0706, -0.0055,  0.0041,  ..., -0.0100, -0.0074,  0.0046],
        [ 0.0081,  0.0577,  0.0093,  ...,  0.0143,  0.0165, -0.0057],
        [-0.0100, -0.0047,  0.0511,  ..., -0.0053, -0.0105, -0.0050],
        ...,
        [ 0.0100,  0.0117,  0.0061,  ...,  0.0708,  0.0084, -0.0093],
        [ 0.0122, -0.0035,  0.0058,  ..., -0.0134,  0.0580, -0.0110],
        [-0.0134,  0.0041,  0.0047,  ...,  0.0037, -0.0054,  0.0559]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.0342, -3.1641, -0.5464,  ..., -2.2090, -2.7754, -2.1074]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 05:54:21 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is the most strong, it is strongest
If something is the most risky, it is riskiest
If something is the most scary, it is scariest
If something is the most sunny, it is sunniest
If something is the most cruel, it is cruelest
If something is the most noisy, it is noisiest
If something is the most weak, it is weakest
If something is the most mild, it is
2024-07-29 05:54:21 root INFO     [order_1_approx] starting weight calculation for If something is the most scary, it is scariest
If something is the most strong, it is strongest
If something is the most noisy, it is noisiest
If something is the most sunny, it is sunniest
If something is the most risky, it is riskiest
If something is the most cruel, it is cruelest
If something is the most mild, it is mildest
If something is the most weak, it is
2024-07-29 05:54:21 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 05:56:13 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0623, -0.4424, -0.7500,  ..., -0.5503,  0.0033, -0.8247],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.6064, -3.7109, -1.9668,  ..., -4.0469,  2.4961, -3.4766],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0590,  0.0007, -0.0059,  ..., -0.0164,  0.0032,  0.0097],
        [-0.0020,  0.0388,  0.0080,  ...,  0.0187,  0.0092, -0.0179],
        [ 0.0092, -0.0012,  0.0357,  ..., -0.0007, -0.0114, -0.0023],
        ...,
        [-0.0009,  0.0151,  0.0042,  ...,  0.0501,  0.0017, -0.0046],
        [ 0.0087,  0.0086, -0.0010,  ..., -0.0146,  0.0418, -0.0098],
        [ 0.0041,  0.0010, -0.0005,  ..., -0.0051, -0.0079,  0.0456]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.2646, -3.5332, -2.2715,  ..., -4.0391,  2.3965, -3.6426]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 05:56:14 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is the most scary, it is scariest
If something is the most strong, it is strongest
If something is the most noisy, it is noisiest
If something is the most sunny, it is sunniest
If something is the most risky, it is riskiest
If something is the most cruel, it is cruelest
If something is the most mild, it is mildest
If something is the most weak, it is
2024-07-29 05:56:14 root INFO     total operator prediction time: 919.5086719989777 seconds
2024-07-29 05:56:14 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on verb_3pSg - Ved
2024-07-29 05:56:14 root INFO     building operator verb_3pSg - Ved
2024-07-29 05:56:15 root INFO     [order_1_approx] starting weight calculation for When he agrees something, something has been agreed
When he tells something, something has been told
When he develops something, something has been developed
When he adds something, something has been added
When he sends something, something has been sent
When he hears something, something has been heard
When he manages something, something has been managed
When he fails something, something has been
2024-07-29 05:56:15 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 05:58:09 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1720,  0.0386, -0.1157,  ..., -0.0176, -0.3799, -0.9775],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.4023, -0.1680,  3.4883,  ..., -1.8164, -2.1113, -1.4814],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0324,  0.0002,  0.0187,  ...,  0.0039,  0.0038,  0.0003],
        [-0.0025,  0.0190, -0.0038,  ...,  0.0159,  0.0090, -0.0081],
        [ 0.0099, -0.0089,  0.0197,  ..., -0.0172,  0.0019, -0.0050],
        ...,
        [ 0.0063,  0.0147, -0.0074,  ...,  0.0360,  0.0066,  0.0078],
        [ 0.0170,  0.0018, -0.0043,  ..., -0.0011,  0.0260, -0.0106],
        [ 0.0088,  0.0029,  0.0024,  ..., -0.0078, -0.0072,  0.0349]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.3672, -0.4087,  3.4707,  ..., -1.6865, -2.1270, -1.3643]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 05:58:10 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When he agrees something, something has been agreed
When he tells something, something has been told
When he develops something, something has been developed
When he adds something, something has been added
When he sends something, something has been sent
When he hears something, something has been heard
When he manages something, something has been managed
When he fails something, something has been
2024-07-29 05:58:10 root INFO     [order_1_approx] starting weight calculation for When he agrees something, something has been agreed
When he manages something, something has been managed
When he sends something, something has been sent
When he adds something, something has been added
When he tells something, something has been told
When he fails something, something has been failed
When he develops something, something has been developed
When he hears something, something has been
2024-07-29 05:58:11 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 06:00:05 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.3486, -0.3960,  0.5347,  ...,  0.3867, -0.2944,  0.8472],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.5400,  0.4082,  1.2002,  ..., -0.1229, -6.1016, -2.5566],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 6.0822e-02, -1.0490e-03,  1.2894e-02,  ..., -3.2063e-03,
          2.9793e-03,  1.1703e-02],
        [-1.3428e-02,  4.1565e-02, -8.1482e-03,  ...,  1.3290e-02,
          8.2626e-03, -8.9111e-03],
        [ 6.7673e-03, -2.7714e-03,  4.2542e-02,  ..., -1.3046e-03,
          8.0566e-03, -5.8365e-03],
        ...,
        [ 1.3596e-02,  7.6561e-03, -1.1692e-03,  ...,  4.2114e-02,
          4.3678e-03,  9.5444e-03],
        [ 1.2939e-02,  8.8692e-04, -9.9182e-05,  ...,  2.4567e-03,
          3.2562e-02, -8.7204e-03],
        [-4.8447e-03,  8.2874e-04,  7.7057e-03,  ...,  7.4844e-03,
          2.0538e-02,  3.6804e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.6133,  0.4421,  1.1621,  ..., -0.1711, -6.0430, -2.4590]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 06:00:07 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When he agrees something, something has been agreed
When he manages something, something has been managed
When he sends something, something has been sent
When he adds something, something has been added
When he tells something, something has been told
When he fails something, something has been failed
When he develops something, something has been developed
When he hears something, something has been
2024-07-29 06:00:08 root INFO     [order_1_approx] starting weight calculation for When he manages something, something has been managed
When he hears something, something has been heard
When he adds something, something has been added
When he sends something, something has been sent
When he agrees something, something has been agreed
When he develops something, something has been developed
When he fails something, something has been failed
When he tells something, something has been
2024-07-29 06:00:08 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 06:02:01 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1833, -0.2925,  0.8516,  ...,  0.0126, -0.0825, -0.0147],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.4258,  0.6123,  4.1367,  ...,  1.2861, -4.8633, -1.4512],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0401,  0.0015, -0.0001,  ..., -0.0099, -0.0037,  0.0134],
        [-0.0210,  0.0180, -0.0023,  ...,  0.0127, -0.0035,  0.0070],
        [ 0.0086, -0.0213,  0.0264,  ..., -0.0071, -0.0074, -0.0044],
        ...,
        [ 0.0147,  0.0047, -0.0041,  ...,  0.0421, -0.0019,  0.0157],
        [ 0.0090, -0.0103,  0.0085,  ..., -0.0003,  0.0310, -0.0057],
        [-0.0036, -0.0029,  0.0044,  ..., -0.0074,  0.0111,  0.0264]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.3105,  0.7324,  3.8750,  ...,  1.2021, -4.8672, -1.2891]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 06:02:02 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When he manages something, something has been managed
When he hears something, something has been heard
When he adds something, something has been added
When he sends something, something has been sent
When he agrees something, something has been agreed
When he develops something, something has been developed
When he fails something, something has been failed
When he tells something, something has been
2024-07-29 06:02:02 root INFO     [order_1_approx] starting weight calculation for When he tells something, something has been told
When he fails something, something has been failed
When he hears something, something has been heard
When he develops something, something has been developed
When he manages something, something has been managed
When he agrees something, something has been agreed
When he adds something, something has been added
When he sends something, something has been
2024-07-29 06:02:02 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 06:03:54 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1760,  0.0132,  0.9727,  ...,  0.7036, -0.2239,  0.1218],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.3105, -1.6523, -1.6074,  ..., -2.9062, -1.4473, -2.6504],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0382,  0.0058,  0.0150,  ..., -0.0001,  0.0030,  0.0027],
        [-0.0099,  0.0275, -0.0050,  ...,  0.0188,  0.0088, -0.0055],
        [ 0.0106, -0.0123,  0.0111,  ..., -0.0096, -0.0001, -0.0049],
        ...,
        [ 0.0077,  0.0200,  0.0003,  ...,  0.0441, -0.0029,  0.0054],
        [ 0.0232, -0.0125, -0.0032,  ..., -0.0029,  0.0261, -0.0168],
        [-0.0036,  0.0074, -0.0028,  ..., -0.0130, -0.0004,  0.0219]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.3340, -1.7520, -1.6719,  ..., -2.9160, -1.7539, -2.4238]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 06:03:55 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When he tells something, something has been told
When he fails something, something has been failed
When he hears something, something has been heard
When he develops something, something has been developed
When he manages something, something has been managed
When he agrees something, something has been agreed
When he adds something, something has been added
When he sends something, something has been
2024-07-29 06:03:55 root INFO     [order_1_approx] starting weight calculation for When he develops something, something has been developed
When he agrees something, something has been agreed
When he fails something, something has been failed
When he tells something, something has been told
When he hears something, something has been heard
When he manages something, something has been managed
When he sends something, something has been sent
When he adds something, something has been
2024-07-29 06:03:55 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 06:05:47 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2268, -0.7104,  0.7490,  ...,  0.1589, -0.7661, -0.0903],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.3486,  1.5488, -1.0391,  ...,  0.1196, -3.8281, -0.4141],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0720,  0.0034,  0.0106,  ..., -0.0132, -0.0031,  0.0002],
        [-0.0131,  0.0423,  0.0025,  ...,  0.0189,  0.0051,  0.0030],
        [ 0.0037, -0.0133,  0.0475,  ..., -0.0073, -0.0037, -0.0086],
        ...,
        [ 0.0157,  0.0127, -0.0059,  ...,  0.0605,  0.0103,  0.0159],
        [ 0.0220,  0.0001,  0.0035,  ..., -0.0044,  0.0456, -0.0078],
        [-0.0055, -0.0019, -0.0003,  ..., -0.0142, -0.0065,  0.0567]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.4346,  1.4629, -1.2305,  ..., -0.0192, -3.7910, -0.0696]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 06:05:49 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When he develops something, something has been developed
When he agrees something, something has been agreed
When he fails something, something has been failed
When he tells something, something has been told
When he hears something, something has been heard
When he manages something, something has been managed
When he sends something, something has been sent
When he adds something, something has been
2024-07-29 06:05:49 root INFO     [order_1_approx] starting weight calculation for When he develops something, something has been developed
When he adds something, something has been added
When he hears something, something has been heard
When he sends something, something has been sent
When he fails something, something has been failed
When he agrees something, something has been agreed
When he tells something, something has been told
When he manages something, something has been
2024-07-29 06:05:49 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 06:07:41 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0913,  0.5625,  0.2593,  ...,  0.4988, -0.4609,  0.4548],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.7949, -0.5996,  2.6172,  ..., -0.3716, -1.6094, -2.8223],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0435,  0.0064,  0.0061,  ..., -0.0061, -0.0110, -0.0033],
        [-0.0137,  0.0321, -0.0038,  ...,  0.0244,  0.0029,  0.0092],
        [ 0.0088, -0.0117,  0.0389,  ..., -0.0061,  0.0014, -0.0201],
        ...,
        [ 0.0061,  0.0047,  0.0008,  ...,  0.0492,  0.0012,  0.0087],
        [ 0.0164,  0.0073,  0.0024,  ...,  0.0003,  0.0358, -0.0175],
        [ 0.0014, -0.0013,  0.0074,  ..., -0.0182, -0.0036,  0.0251]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.6934, -0.3740,  2.2715,  ..., -0.6143, -1.6416, -2.6777]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 06:07:42 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When he develops something, something has been developed
When he adds something, something has been added
When he hears something, something has been heard
When he sends something, something has been sent
When he fails something, something has been failed
When he agrees something, something has been agreed
When he tells something, something has been told
When he manages something, something has been
2024-07-29 06:07:42 root INFO     [order_1_approx] starting weight calculation for When he adds something, something has been added
When he tells something, something has been told
When he manages something, something has been managed
When he hears something, something has been heard
When he fails something, something has been failed
When he develops something, something has been developed
When he sends something, something has been sent
When he agrees something, something has been
2024-07-29 06:07:42 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 06:09:37 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0638, -0.4072, -0.0662,  ...,  0.3379, -0.4258, -0.4338],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.9199, -1.7500,  1.6074,  ...,  0.1211, -1.9297,  0.3145],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0406,  0.0005,  0.0148,  ..., -0.0090, -0.0038,  0.0091],
        [-0.0126,  0.0254,  0.0062,  ...,  0.0232,  0.0016, -0.0100],
        [ 0.0128, -0.0035,  0.0306,  ..., -0.0096, -0.0039, -0.0120],
        ...,
        [ 0.0111,  0.0120, -0.0165,  ...,  0.0348, -0.0015,  0.0142],
        [ 0.0120, -0.0011, -0.0017,  ..., -0.0078,  0.0389, -0.0079],
        [ 0.0101, -0.0016, -0.0058,  ..., -0.0088, -0.0058,  0.0389]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.7852, -1.5596,  1.4307,  ...,  0.2588, -1.9404,  0.4363]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 06:09:38 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When he adds something, something has been added
When he tells something, something has been told
When he manages something, something has been managed
When he hears something, something has been heard
When he fails something, something has been failed
When he develops something, something has been developed
When he sends something, something has been sent
When he agrees something, something has been
2024-07-29 06:09:38 root INFO     [order_1_approx] starting weight calculation for When he hears something, something has been heard
When he tells something, something has been told
When he adds something, something has been added
When he fails something, something has been failed
When he manages something, something has been managed
When he sends something, something has been sent
When he agrees something, something has been agreed
When he develops something, something has been
2024-07-29 06:09:38 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 06:11:32 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.5610,  0.1782, -0.0581,  ...,  0.2505, -0.5820,  0.2333],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.4785, -1.1582,  2.6602,  ..., -1.3496, -2.1992, -2.1406],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 3.0502e-02,  4.4746e-03,  3.4199e-03,  ...,  2.2278e-03,
         -7.5035e-03,  3.2005e-03],
        [-1.1200e-02,  1.5617e-02,  4.9095e-03,  ...,  8.9264e-03,
          5.2032e-03, -5.0354e-04],
        [ 6.5460e-03, -2.5101e-03,  1.9592e-02,  ..., -1.8716e-05,
          3.0327e-04, -5.0201e-03],
        ...,
        [ 9.2468e-03,  4.2000e-03,  3.4485e-03,  ...,  3.0914e-02,
          1.4305e-05,  9.4452e-03],
        [ 1.2848e-02, -3.7079e-03,  1.4114e-03,  ..., -2.5654e-03,
          2.2858e-02, -6.6605e-03],
        [-1.1078e-02, -8.9493e-03,  2.2278e-03,  ..., -1.4610e-02,
         -2.8286e-03,  2.1164e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.5020, -1.1660,  2.6406,  ..., -1.2832, -2.2422, -2.1797]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 06:11:33 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When he hears something, something has been heard
When he tells something, something has been told
When he adds something, something has been added
When he fails something, something has been failed
When he manages something, something has been managed
When he sends something, something has been sent
When he agrees something, something has been agreed
When he develops something, something has been
2024-07-29 06:11:33 root INFO     total operator prediction time: 918.7842235565186 seconds
2024-07-29 06:11:33 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on noun - plural_reg
2024-07-29 06:11:33 root INFO     building operator noun - plural_reg
2024-07-29 06:11:34 root INFO     [order_1_approx] starting weight calculation for The plural form of death is deaths
The plural form of role is roles
The plural form of friend is friends
The plural form of hour is hours
The plural form of system is systems
The plural form of village is villages
The plural form of month is months
The plural form of department is
2024-07-29 06:11:34 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 06:13:30 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2830,  0.4395, -0.2737,  ..., -0.2581, -0.1320, -0.6416],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.3965, -3.2441,  3.0723,  ..., -1.0430,  1.4971, -2.5352],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 9.2651e-02,  1.3092e-02,  1.9531e-02,  ..., -6.4926e-03,
          1.3838e-03,  1.4183e-02],
        [-9.6741e-03,  5.1117e-02,  1.0117e-02,  ...,  1.8021e-02,
          6.9427e-04,  1.1780e-02],
        [ 1.4290e-02,  3.8147e-05,  7.5317e-02,  ..., -5.1613e-03,
         -5.4665e-03,  7.5378e-03],
        ...,
        [ 1.3428e-02,  1.7517e-02,  3.9520e-03,  ...,  8.2031e-02,
         -1.3580e-03,  5.5618e-03],
        [-2.1637e-02,  2.2491e-02, -1.4572e-03,  ..., -5.8317e-04,
          6.0669e-02, -6.8932e-03],
        [ 1.1116e-02, -1.3031e-02, -6.0501e-03,  ..., -1.3023e-02,
         -2.7527e-02,  7.1167e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.3320, -3.0371,  3.1055,  ..., -1.0049,  1.4297, -2.0156]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 06:13:31 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of death is deaths
The plural form of role is roles
The plural form of friend is friends
The plural form of hour is hours
The plural form of system is systems
The plural form of village is villages
The plural form of month is months
The plural form of department is
2024-07-29 06:13:31 root INFO     [order_1_approx] starting weight calculation for The plural form of role is roles
The plural form of month is months
The plural form of system is systems
The plural form of death is deaths
The plural form of hour is hours
The plural form of department is departments
The plural form of friend is friends
The plural form of village is
2024-07-29 06:13:31 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 06:15:28 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.9082,  0.9229, -0.1294,  ..., -0.6172, -0.8120,  0.2749],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.7749, -5.7031,  2.8730,  ..., -2.1914,  1.1807, -1.1221],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.1052,  0.0198,  0.0169,  ..., -0.0050,  0.0084,  0.0145],
        [-0.0052,  0.0603, -0.0179,  ...,  0.0157,  0.0118,  0.0093],
        [ 0.0157,  0.0063,  0.0805,  ..., -0.0195, -0.0018,  0.0062],
        ...,
        [ 0.0083,  0.0037, -0.0007,  ...,  0.0773,  0.0074,  0.0144],
        [ 0.0123,  0.0197,  0.0021,  ..., -0.0114,  0.0458, -0.0158],
        [-0.0006,  0.0135, -0.0193,  ..., -0.0158,  0.0059,  0.0716]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.7837, -5.4258,  2.8477,  ..., -2.3496,  1.4062, -1.0557]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 06:15:29 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of role is roles
The plural form of month is months
The plural form of system is systems
The plural form of death is deaths
The plural form of hour is hours
The plural form of department is departments
The plural form of friend is friends
The plural form of village is
2024-07-29 06:15:29 root INFO     [order_1_approx] starting weight calculation for The plural form of village is villages
The plural form of hour is hours
The plural form of friend is friends
The plural form of department is departments
The plural form of role is roles
The plural form of death is deaths
The plural form of month is months
The plural form of system is
2024-07-29 06:15:29 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 06:17:25 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4385,  0.5625, -0.0742,  ..., -0.0471, -0.7876,  0.5303],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.2070, -2.6270,  0.0588,  ..., -0.9404, -1.0254, -1.9062],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0922,  0.0173,  0.0248,  ..., -0.0043,  0.0159,  0.0079],
        [-0.0140,  0.0662,  0.0142,  ...,  0.0026,  0.0021,  0.0084],
        [ 0.0024, -0.0127,  0.0868,  ..., -0.0154, -0.0012,  0.0079],
        ...,
        [ 0.0149,  0.0114, -0.0044,  ...,  0.0970, -0.0080,  0.0102],
        [-0.0093,  0.0153,  0.0078,  ..., -0.0163,  0.0511, -0.0223],
        [-0.0031,  0.0022, -0.0140,  ..., -0.0049, -0.0168,  0.0773]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.4082, -2.5840,  0.3030,  ..., -1.2363, -0.6689, -1.7793]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 06:17:26 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of village is villages
The plural form of hour is hours
The plural form of friend is friends
The plural form of department is departments
The plural form of role is roles
The plural form of death is deaths
The plural form of month is months
The plural form of system is
2024-07-29 06:17:26 root INFO     [order_1_approx] starting weight calculation for The plural form of role is roles
The plural form of friend is friends
The plural form of system is systems
The plural form of death is deaths
The plural form of department is departments
The plural form of village is villages
The plural form of hour is hours
The plural form of month is
2024-07-29 06:17:26 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 06:19:23 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3530, -0.8223, -0.0133,  ..., -0.0836, -0.6768,  0.2333],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.0254, -4.2969,  0.8291,  ..., -1.1865,  1.0732, -1.4043],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0493,  0.0029,  0.0045,  ..., -0.0053,  0.0108,  0.0182],
        [ 0.0024,  0.0509,  0.0051,  ...,  0.0023,  0.0112,  0.0036],
        [ 0.0015, -0.0015,  0.0476,  ..., -0.0049, -0.0175,  0.0045],
        ...,
        [ 0.0096,  0.0032,  0.0003,  ...,  0.0518,  0.0035,  0.0026],
        [-0.0064,  0.0173, -0.0039,  ..., -0.0041,  0.0258,  0.0007],
        [-0.0059,  0.0071, -0.0101,  ..., -0.0029, -0.0020,  0.0434]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.0801, -4.1836,  0.9766,  ..., -1.4053,  0.7656, -1.1484]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 06:19:23 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of role is roles
The plural form of friend is friends
The plural form of system is systems
The plural form of death is deaths
The plural form of department is departments
The plural form of village is villages
The plural form of hour is hours
The plural form of month is
2024-07-29 06:19:24 root INFO     [order_1_approx] starting weight calculation for The plural form of role is roles
The plural form of friend is friends
The plural form of death is deaths
The plural form of system is systems
The plural form of department is departments
The plural form of month is months
The plural form of village is villages
The plural form of hour is
2024-07-29 06:19:24 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 06:21:19 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4866, -0.5718, -0.0545,  ...,  0.2313, -0.0806,  0.3179],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.4004, -3.1504,  0.8984,  ..., -1.5352,  0.7432, -2.5664],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0930,  0.0133,  0.0178,  ...,  0.0064,  0.0131,  0.0232],
        [-0.0006,  0.0634, -0.0026,  ...,  0.0082,  0.0012, -0.0095],
        [ 0.0007, -0.0018,  0.0730,  ..., -0.0051,  0.0062,  0.0112],
        ...,
        [ 0.0032,  0.0002,  0.0018,  ...,  0.0812, -0.0164,  0.0023],
        [-0.0104, -0.0035,  0.0129,  ..., -0.0020,  0.0517, -0.0015],
        [-0.0029, -0.0040, -0.0050,  ..., -0.0028, -0.0021,  0.0720]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.4290, -2.9609,  1.0137,  ..., -1.5264,  0.8198, -2.1562]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 06:21:20 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of role is roles
The plural form of friend is friends
The plural form of death is deaths
The plural form of system is systems
The plural form of department is departments
The plural form of month is months
The plural form of village is villages
The plural form of hour is
2024-07-29 06:21:20 root INFO     [order_1_approx] starting weight calculation for The plural form of month is months
The plural form of hour is hours
The plural form of department is departments
The plural form of role is roles
The plural form of village is villages
The plural form of system is systems
The plural form of death is deaths
The plural form of friend is
2024-07-29 06:21:21 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 06:23:13 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.5786, -0.4177, -0.0627,  ..., -0.4785, -0.3821, -0.3101],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.3555, -2.6426,  2.9648,  ...,  0.0127, -0.9492, -1.5938],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0900, -0.0099,  0.0010,  ..., -0.0048,  0.0078,  0.0294],
        [-0.0060,  0.0594,  0.0064,  ...,  0.0254, -0.0024, -0.0132],
        [ 0.0099,  0.0105,  0.0813,  ..., -0.0062,  0.0075, -0.0033],
        ...,
        [-0.0015,  0.0110, -0.0015,  ...,  0.1072, -0.0046,  0.0085],
        [ 0.0026,  0.0113,  0.0071,  ...,  0.0015,  0.0639, -0.0226],
        [-0.0052,  0.0116, -0.0015,  ...,  0.0017, -0.0030,  0.0748]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.1562, -2.3242,  3.1602,  ...,  0.2498, -0.7769, -1.8428]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 06:23:13 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of month is months
The plural form of hour is hours
The plural form of department is departments
The plural form of role is roles
The plural form of village is villages
The plural form of system is systems
The plural form of death is deaths
The plural form of friend is
2024-07-29 06:23:14 root INFO     [order_1_approx] starting weight calculation for The plural form of death is deaths
The plural form of department is departments
The plural form of village is villages
The plural form of hour is hours
The plural form of month is months
The plural form of system is systems
The plural form of friend is friends
The plural form of role is
2024-07-29 06:23:14 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 06:25:08 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1274,  0.1891, -0.4265,  ..., -0.2524, -0.1423, -0.3291],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.4209, -2.6797,  0.3262,  ..., -2.7695, -0.0879, -4.3477],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.1131, -0.0033,  0.0249,  ...,  0.0001,  0.0085,  0.0033],
        [-0.0193,  0.0968,  0.0085,  ...,  0.0226,  0.0080,  0.0049],
        [ 0.0016, -0.0157,  0.1125,  ..., -0.0191,  0.0054, -0.0071],
        ...,
        [ 0.0027,  0.0204, -0.0050,  ...,  0.1356, -0.0025,  0.0134],
        [-0.0126,  0.0144, -0.0020,  ..., -0.0261,  0.0984, -0.0147],
        [ 0.0065,  0.0118, -0.0153,  ..., -0.0015,  0.0035,  0.1172]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.8193, -1.9121,  0.6279,  ..., -2.0898, -0.2261, -3.5352]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 06:25:24 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of death is deaths
The plural form of department is departments
The plural form of village is villages
The plural form of hour is hours
The plural form of month is months
The plural form of system is systems
The plural form of friend is friends
The plural form of role is
2024-07-29 06:25:24 root INFO     [order_1_approx] starting weight calculation for The plural form of hour is hours
The plural form of role is roles
The plural form of month is months
The plural form of system is systems
The plural form of department is departments
The plural form of village is villages
The plural form of friend is friends
The plural form of death is
2024-07-29 06:25:25 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 06:27:22 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0952, -0.3281,  0.0417,  ..., -0.5635, -0.3091, -0.0400],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.5283, -3.0820,  2.1250,  ..., -1.8477, -0.7646, -2.5938],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.1085, -0.0109,  0.0195,  ..., -0.0010,  0.0157,  0.0122],
        [-0.0116,  0.0701,  0.0082,  ..., -0.0030, -0.0089, -0.0209],
        [ 0.0003,  0.0128,  0.0803,  ...,  0.0003, -0.0134,  0.0111],
        ...,
        [ 0.0107,  0.0111,  0.0035,  ...,  0.1184, -0.0037, -0.0039],
        [-0.0179,  0.0178,  0.0094,  ..., -0.0031,  0.0803, -0.0126],
        [ 0.0084,  0.0028, -0.0178,  ..., -0.0029, -0.0031,  0.0859]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.4375, -2.7500,  2.2129,  ..., -1.3662, -0.8789, -2.0801]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 06:27:23 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of hour is hours
The plural form of role is roles
The plural form of month is months
The plural form of system is systems
The plural form of department is departments
The plural form of village is villages
The plural form of friend is friends
The plural form of death is
2024-07-29 06:27:23 root INFO     total operator prediction time: 950.0758016109467 seconds
2024-07-29 06:27:23 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on verb_Ving - 3pSg
2024-07-29 06:27:23 root INFO     building operator verb_Ving - 3pSg
2024-07-29 06:27:24 root INFO     [order_1_approx] starting weight calculation for When something is continuing, it continues
When something is publishing, it publishes
When something is developing, it develops
When something is operating, it operates
When something is promoting, it promotes
When something is creating, it creates
When something is allowing, it allows
When something is spending, it
2024-07-29 06:27:24 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 06:29:19 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1028, -0.2983,  0.5107,  ..., -0.2181, -0.2600, -0.4629],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.7305, -1.4395, -3.6660,  ..., -1.5508, -5.4688, -2.2656],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 7.3364e-02, -3.2349e-03,  1.6983e-02,  ..., -9.6359e-03,
          2.7046e-03,  4.4250e-03],
        [-1.2360e-02,  5.4108e-02, -3.7632e-03,  ...,  1.2894e-02,
          8.9874e-03, -8.7509e-03],
        [-8.4457e-03, -8.1253e-04,  5.1361e-02,  ..., -4.3983e-03,
         -5.0545e-05, -1.7593e-02],
        ...,
        [ 7.6904e-03, -4.2076e-03,  6.5079e-03,  ...,  6.8604e-02,
         -4.2343e-03, -7.2632e-03],
        [-7.0190e-03, -4.3564e-03, -2.0771e-03,  ...,  5.7335e-03,
          7.1594e-02, -1.7365e-02],
        [-6.8359e-03, -7.5912e-03, -6.9046e-03,  ..., -5.0583e-03,
         -9.0256e-03,  5.7709e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.9395, -1.3008, -3.6973,  ..., -1.5391, -5.6055, -2.1562]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 06:29:20 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When something is continuing, it continues
When something is publishing, it publishes
When something is developing, it develops
When something is operating, it operates
When something is promoting, it promotes
When something is creating, it creates
When something is allowing, it allows
When something is spending, it
2024-07-29 06:29:20 root INFO     [order_1_approx] starting weight calculation for When something is publishing, it publishes
When something is continuing, it continues
When something is operating, it operates
When something is allowing, it allows
When something is spending, it spends
When something is creating, it creates
When something is promoting, it promotes
When something is developing, it
2024-07-29 06:29:20 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 06:31:17 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 1.0107, -0.1334, -0.4175,  ..., -0.4585, -0.5894, -0.3477],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.1602, -4.0977,  0.3262,  ..., -1.0430, -5.0898, -1.9209],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0682,  0.0062,  0.0046,  ..., -0.0039, -0.0167,  0.0006],
        [-0.0210,  0.0522, -0.0006,  ...,  0.0142,  0.0016, -0.0010],
        [ 0.0031, -0.0094,  0.0530,  ..., -0.0037,  0.0015, -0.0182],
        ...,
        [ 0.0140,  0.0044,  0.0084,  ...,  0.0633, -0.0023,  0.0014],
        [ 0.0119, -0.0066, -0.0057,  ..., -0.0061,  0.0619, -0.0157],
        [-0.0133, -0.0106,  0.0007,  ..., -0.0164, -0.0212,  0.0580]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.9492, -3.9766,  0.3835,  ..., -1.0283, -5.3438, -1.6680]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 06:31:18 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When something is publishing, it publishes
When something is continuing, it continues
When something is operating, it operates
When something is allowing, it allows
When something is spending, it spends
When something is creating, it creates
When something is promoting, it promotes
When something is developing, it
2024-07-29 06:31:18 root INFO     [order_1_approx] starting weight calculation for When something is promoting, it promotes
When something is allowing, it allows
When something is operating, it operates
When something is creating, it creates
When something is spending, it spends
When something is publishing, it publishes
When something is developing, it develops
When something is continuing, it
2024-07-29 06:31:18 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 06:33:15 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 1.3691, -1.0000, -0.1815,  ..., -0.6655, -1.1465,  0.2491],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.3242, -4.0078, -0.1426,  ..., -0.9102, -2.7598, -1.4688],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0573,  0.0024,  0.0045,  ...,  0.0058,  0.0049,  0.0054],
        [-0.0041,  0.0470,  0.0004,  ...,  0.0123,  0.0002,  0.0002],
        [-0.0018,  0.0062,  0.0430,  ..., -0.0130,  0.0076, -0.0096],
        ...,
        [-0.0008,  0.0007,  0.0079,  ...,  0.0641,  0.0078, -0.0051],
        [ 0.0014,  0.0091,  0.0072,  ..., -0.0096,  0.0417, -0.0182],
        [-0.0071, -0.0027,  0.0055,  ..., -0.0176, -0.0122,  0.0438]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.3457, -3.8086, -0.2559,  ..., -0.7832, -2.9082, -1.3867]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 06:33:16 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When something is promoting, it promotes
When something is allowing, it allows
When something is operating, it operates
When something is creating, it creates
When something is spending, it spends
When something is publishing, it publishes
When something is developing, it develops
When something is continuing, it
2024-07-29 06:33:16 root INFO     [order_1_approx] starting weight calculation for When something is continuing, it continues
When something is operating, it operates
When something is spending, it spends
When something is publishing, it publishes
When something is allowing, it allows
When something is developing, it develops
When something is promoting, it promotes
When something is creating, it
2024-07-29 06:33:16 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 06:35:11 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3687, -0.4702,  0.4280,  ..., -0.6807, -0.8975, -0.4497],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.6279, -3.1172,  1.0137,  ...,  0.4277, -5.1367,  0.0977],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0550,  0.0013,  0.0144,  ..., -0.0015, -0.0146,  0.0040],
        [-0.0034,  0.0428, -0.0018,  ...,  0.0235,  0.0051,  0.0010],
        [ 0.0044, -0.0127,  0.0512,  ..., -0.0032,  0.0046, -0.0066],
        ...,
        [ 0.0145,  0.0157,  0.0107,  ...,  0.0400, -0.0079, -0.0083],
        [ 0.0012, -0.0003,  0.0035,  ..., -0.0155,  0.0481, -0.0104],
        [-0.0122, -0.0007, -0.0078,  ..., -0.0092, -0.0097,  0.0458]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.6543, -2.9648,  0.9224,  ...,  0.6479, -5.3438, -0.0153]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 06:35:12 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When something is continuing, it continues
When something is operating, it operates
When something is spending, it spends
When something is publishing, it publishes
When something is allowing, it allows
When something is developing, it develops
When something is promoting, it promotes
When something is creating, it
2024-07-29 06:35:12 root INFO     [order_1_approx] starting weight calculation for When something is operating, it operates
When something is allowing, it allows
When something is creating, it creates
When something is continuing, it continues
When something is developing, it develops
When something is promoting, it promotes
When something is spending, it spends
When something is publishing, it
2024-07-29 06:35:12 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 06:37:09 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1117, -0.5298, -0.0013,  ...,  0.0173, -0.7510,  0.2981],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.3477, -3.7168, -0.1055,  ..., -1.7207, -5.4258,  0.0254],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0604, -0.0053,  0.0135,  ...,  0.0062, -0.0127,  0.0151],
        [-0.0210,  0.0421,  0.0015,  ...,  0.0171, -0.0005, -0.0051],
        [ 0.0073, -0.0147,  0.0504,  ..., -0.0052, -0.0178, -0.0020],
        ...,
        [-0.0090, -0.0043,  0.0036,  ...,  0.0673,  0.0150,  0.0023],
        [ 0.0031, -0.0016, -0.0013,  ..., -0.0092,  0.0525, -0.0149],
        [ 0.0035, -0.0046,  0.0051,  ..., -0.0040, -0.0178,  0.0477]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.4746, -3.7168, -0.3306,  ..., -1.6562, -5.2852,  0.2433]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 06:37:10 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When something is operating, it operates
When something is allowing, it allows
When something is creating, it creates
When something is continuing, it continues
When something is developing, it develops
When something is promoting, it promotes
When something is spending, it spends
When something is publishing, it
2024-07-29 06:37:10 root INFO     [order_1_approx] starting weight calculation for When something is operating, it operates
When something is publishing, it publishes
When something is creating, it creates
When something is spending, it spends
When something is developing, it develops
When something is promoting, it promotes
When something is continuing, it continues
When something is allowing, it
2024-07-29 06:37:10 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 06:39:04 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1873, -0.4382,  0.0943,  ..., -1.3711, -0.3892, -0.3899],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.5605, -3.5898, -0.7598,  ..., -1.4541, -5.9492,  1.5156],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0827,  0.0061,  0.0102,  ..., -0.0117,  0.0026,  0.0073],
        [ 0.0042,  0.0637, -0.0149,  ...,  0.0130,  0.0041, -0.0050],
        [-0.0123, -0.0155,  0.0742,  ..., -0.0089,  0.0053, -0.0201],
        ...,
        [ 0.0012,  0.0051, -0.0008,  ...,  0.0640,  0.0047, -0.0010],
        [-0.0112,  0.0057, -0.0021,  ..., -0.0107,  0.0612, -0.0154],
        [-0.0024,  0.0026, -0.0083,  ..., -0.0141, -0.0117,  0.0740]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.6328, -3.7383, -0.8315,  ..., -0.7910, -5.9062,  1.4268]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 06:39:05 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When something is operating, it operates
When something is publishing, it publishes
When something is creating, it creates
When something is spending, it spends
When something is developing, it develops
When something is promoting, it promotes
When something is continuing, it continues
When something is allowing, it
2024-07-29 06:39:05 root INFO     [order_1_approx] starting weight calculation for When something is continuing, it continues
When something is spending, it spends
When something is publishing, it publishes
When something is developing, it develops
When something is allowing, it allows
When something is creating, it creates
When something is operating, it operates
When something is promoting, it
2024-07-29 06:39:05 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 06:41:00 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2333, -0.1703, -0.0558,  ..., -0.1929, -0.4541, -0.2209],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.1484, -3.3809, -0.9121,  ..., -0.3740, -6.6719, -0.0820],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 6.2378e-02,  4.9591e-03,  1.7944e-02,  ..., -7.9269e-03,
         -3.9597e-03,  8.6060e-03],
        [-1.4725e-02,  4.9561e-02, -6.5880e-03,  ...,  2.3651e-02,
          3.0823e-03, -4.8599e-03],
        [-3.6163e-03, -1.0635e-02,  5.7312e-02,  ..., -8.5373e-03,
         -4.8447e-04, -7.9956e-03],
        ...,
        [-1.4372e-03,  5.7220e-05,  6.9313e-03,  ...,  6.3293e-02,
          6.8893e-03,  2.3632e-03],
        [-9.0742e-04, -6.7368e-03, -7.2365e-03,  ..., -1.1063e-03,
          6.6650e-02, -2.3834e-02],
        [-7.2250e-03, -3.0098e-03, -1.9236e-03,  ..., -9.0332e-03,
         -1.2146e-02,  5.0018e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.2539, -3.1973, -0.9258,  ..., -0.2905, -6.5977, -0.0620]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 06:41:03 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When something is continuing, it continues
When something is spending, it spends
When something is publishing, it publishes
When something is developing, it develops
When something is allowing, it allows
When something is creating, it creates
When something is operating, it operates
When something is promoting, it
2024-07-29 06:41:05 root INFO     [order_1_approx] starting weight calculation for When something is continuing, it continues
When something is allowing, it allows
When something is publishing, it publishes
When something is promoting, it promotes
When something is spending, it spends
When something is creating, it creates
When something is developing, it develops
When something is operating, it
2024-07-29 06:41:05 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 06:43:01 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.6494, -0.2281, -0.6050,  ..., -0.6104, -0.6562, -0.4983],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.8828, -4.5781, -0.3340,  ..., -2.1152, -5.2578, -0.6475],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0649,  0.0069,  0.0021,  ..., -0.0171, -0.0157,  0.0113],
        [-0.0237,  0.0463,  0.0009,  ...,  0.0264,  0.0083, -0.0064],
        [-0.0078,  0.0032,  0.0573,  ..., -0.0189,  0.0032, -0.0129],
        ...,
        [-0.0109,  0.0090, -0.0027,  ...,  0.0726,  0.0105, -0.0100],
        [ 0.0025, -0.0083, -0.0038,  ..., -0.0042,  0.0475, -0.0281],
        [-0.0044, -0.0045,  0.0011,  ..., -0.0066, -0.0169,  0.0581]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.0176, -4.3281, -0.3179,  ..., -1.9678, -5.2773, -0.2812]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 06:43:02 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When something is continuing, it continues
When something is allowing, it allows
When something is publishing, it publishes
When something is promoting, it promotes
When something is spending, it spends
When something is creating, it creates
When something is developing, it develops
When something is operating, it
2024-07-29 06:43:02 root INFO     total operator prediction time: 938.5974962711334 seconds
2024-07-29 06:43:02 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on verb_inf - 3pSg
2024-07-29 06:43:02 root INFO     building operator verb_inf - 3pSg
2024-07-29 06:43:02 root INFO     [order_1_approx] starting weight calculation for I continue, he continues
I include, he includes
I happen, he happens
I suggest, he suggests
I receive, he receives
I promote, he promotes
I send, he sends
I enable, he
2024-07-29 06:43:02 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 06:44:59 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.5229, -0.5073, -0.0494,  ..., -1.0410, -0.7178,  0.9604],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.9238, -2.2559, -1.5977,  ..., -0.9482, -9.6328, -1.2676],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0369,  0.0047,  0.0177,  ..., -0.0031, -0.0060,  0.0042],
        [-0.0065,  0.0274,  0.0038,  ...,  0.0121,  0.0085, -0.0089],
        [ 0.0032, -0.0022,  0.0272,  ..., -0.0133, -0.0020, -0.0016],
        ...,
        [-0.0056,  0.0134, -0.0016,  ...,  0.0383,  0.0091, -0.0097],
        [ 0.0058, -0.0051,  0.0015,  ...,  0.0106,  0.0303, -0.0011],
        [-0.0005, -0.0112,  0.0084,  ..., -0.0056, -0.0167,  0.0419]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.1094, -2.1113, -1.7139,  ..., -0.5781, -9.2031, -1.1914]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 06:45:00 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for I continue, he continues
I include, he includes
I happen, he happens
I suggest, he suggests
I receive, he receives
I promote, he promotes
I send, he sends
I enable, he
2024-07-29 06:45:00 root INFO     [order_1_approx] starting weight calculation for I receive, he receives
I happen, he happens
I continue, he continues
I include, he includes
I promote, he promotes
I enable, he enables
I send, he sends
I suggest, he
2024-07-29 06:45:00 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 06:46:57 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2830, -0.3315,  0.4077,  ..., -0.3047, -0.4165, -0.0189],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 6.3164, -2.5195, -2.2324,  ...,  1.1523, -6.7852,  1.0039],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0464, -0.0049,  0.0062,  ..., -0.0205, -0.0004,  0.0176],
        [-0.0109,  0.0306,  0.0043,  ..., -0.0022, -0.0046, -0.0068],
        [-0.0011, -0.0065,  0.0209,  ..., -0.0014, -0.0028, -0.0052],
        ...,
        [-0.0085,  0.0005,  0.0069,  ...,  0.0435,  0.0038, -0.0009],
        [-0.0044, -0.0080,  0.0074,  ..., -0.0009,  0.0272, -0.0063],
        [-0.0010,  0.0006,  0.0047,  ..., -0.0061, -0.0090,  0.0231]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 5.7578, -2.4316, -2.1641,  ...,  1.4072, -7.0977,  0.7915]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 06:46:58 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for I receive, he receives
I happen, he happens
I continue, he continues
I include, he includes
I promote, he promotes
I enable, he enables
I send, he sends
I suggest, he
2024-07-29 06:46:58 root INFO     [order_1_approx] starting weight calculation for I enable, he enables
I suggest, he suggests
I include, he includes
I receive, he receives
I continue, he continues
I promote, he promotes
I send, he sends
I happen, he
2024-07-29 06:46:58 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 06:48:53 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.5820, -0.6709,  0.0247,  ..., -0.9805, -0.2588, -0.3237],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.4434, -1.8086, -1.1953,  ..., -0.5742, -8.2266, -0.5078],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 4.1992e-02,  1.1158e-03, -7.0953e-03,  ...,  7.1716e-04,
          3.7575e-04,  7.6561e-03],
        [-5.7983e-03,  3.5614e-02,  1.2760e-03,  ...,  1.0971e-02,
          3.7727e-03, -4.4441e-03],
        [-1.3065e-03, -3.5381e-03,  2.7618e-02,  ..., -1.8036e-02,
          4.2839e-03, -4.7493e-03],
        ...,
        [ 7.8888e-03,  2.4033e-02, -6.4621e-03,  ...,  4.0039e-02,
         -2.2583e-03,  3.1643e-03],
        [-1.9073e-05, -5.6534e-03,  1.3763e-02,  ..., -2.2446e-02,
          2.4384e-02,  2.2278e-03],
        [-4.5242e-03, -8.6365e-03,  2.5349e-03,  ...,  1.2197e-03,
         -1.4877e-02,  4.1809e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.3887, -1.5908, -1.5117,  ..., -0.2429, -8.5469, -0.8760]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 06:48:54 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for I enable, he enables
I suggest, he suggests
I include, he includes
I receive, he receives
I continue, he continues
I promote, he promotes
I send, he sends
I happen, he
2024-07-29 06:48:54 root INFO     [order_1_approx] starting weight calculation for I enable, he enables
I suggest, he suggests
I include, he includes
I happen, he happens
I receive, he receives
I continue, he continues
I send, he sends
I promote, he
2024-07-29 06:48:54 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 06:50:47 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2842, -0.1824, -0.2510,  ..., -0.4048, -0.3567,  0.6934],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.1953, -3.9805, -0.3320,  ...,  0.5840, -8.1953, -0.1016],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0413,  0.0017,  0.0155,  ..., -0.0097, -0.0025,  0.0149],
        [-0.0162,  0.0280,  0.0009,  ...,  0.0130,  0.0006, -0.0079],
        [-0.0066, -0.0004,  0.0441,  ..., -0.0055,  0.0002, -0.0074],
        ...,
        [-0.0091,  0.0091,  0.0004,  ...,  0.0450,  0.0130, -0.0044],
        [-0.0021, -0.0141,  0.0087,  ...,  0.0046,  0.0330, -0.0148],
        [ 0.0028, -0.0007,  0.0079,  ..., -0.0179, -0.0136,  0.0363]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.0195, -3.7207, -0.5063,  ...,  0.9736, -7.9766, -0.2037]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 06:50:48 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for I enable, he enables
I suggest, he suggests
I include, he includes
I happen, he happens
I receive, he receives
I continue, he continues
I send, he sends
I promote, he
2024-07-29 06:50:48 root INFO     [order_1_approx] starting weight calculation for I continue, he continues
I include, he includes
I suggest, he suggests
I send, he sends
I enable, he enables
I promote, he promotes
I happen, he happens
I receive, he
2024-07-29 06:50:49 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 06:52:46 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.3384,  0.3452, -0.2930,  ..., -0.9180, -0.5083,  0.4600],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.5938, -1.5146, -4.3203,  ..., -2.7402, -7.3359, -2.4199],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0340,  0.0093,  0.0070,  ...,  0.0072, -0.0016,  0.0155],
        [-0.0199,  0.0394,  0.0011,  ...,  0.0065,  0.0133, -0.0140],
        [-0.0005,  0.0016,  0.0290,  ..., -0.0106,  0.0064, -0.0017],
        ...,
        [ 0.0007,  0.0096,  0.0082,  ...,  0.0502,  0.0016, -0.0101],
        [ 0.0083, -0.0077, -0.0074,  ..., -0.0011,  0.0328, -0.0034],
        [-0.0076,  0.0031, -0.0077,  ..., -0.0031,  0.0015,  0.0321]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.7305, -1.4922, -4.2617,  ..., -2.8555, -7.1094, -2.3711]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 06:52:47 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for I continue, he continues
I include, he includes
I suggest, he suggests
I send, he sends
I enable, he enables
I promote, he promotes
I happen, he happens
I receive, he
2024-07-29 06:52:47 root INFO     [order_1_approx] starting weight calculation for I continue, he continues
I enable, he enables
I suggest, he suggests
I receive, he receives
I happen, he happens
I promote, he promotes
I include, he includes
I send, he
2024-07-29 06:52:47 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 06:54:44 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.4619, -0.3394,  0.4248,  ..., -0.3606,  0.0033,  0.2446],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.6367, -2.5938, -5.6523,  ..., -2.7969, -6.9922, -2.5391],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 5.3986e-02,  8.2550e-03,  3.3684e-03,  ..., -4.0741e-03,
         -6.2180e-04,  5.3787e-04],
        [-6.6032e-03,  3.8605e-02, -7.4730e-03,  ...,  6.6948e-03,
          1.1124e-02, -1.3504e-02],
        [-1.8253e-03,  3.3131e-03,  1.5121e-02,  ..., -5.1155e-03,
          7.6866e-04, -1.5259e-05],
        ...,
        [ 8.4991e-03,  9.8801e-03,  1.5251e-02,  ...,  4.3732e-02,
         -5.8784e-03, -2.8458e-03],
        [ 7.2765e-04, -2.1835e-02, -4.4861e-03,  ...,  3.8757e-03,
          3.4973e-02, -7.3853e-03],
        [-7.9575e-03, -2.4910e-03, -2.5978e-03,  ...,  1.3638e-03,
         -1.6876e-02,  4.0802e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.6924, -2.5332, -5.4414,  ..., -2.8047, -6.7305, -2.5293]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 06:54:45 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for I continue, he continues
I enable, he enables
I suggest, he suggests
I receive, he receives
I happen, he happens
I promote, he promotes
I include, he includes
I send, he
2024-07-29 06:54:45 root INFO     [order_1_approx] starting weight calculation for I promote, he promotes
I continue, he continues
I happen, he happens
I send, he sends
I receive, he receives
I enable, he enables
I suggest, he suggests
I include, he
2024-07-29 06:54:45 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 06:56:42 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2109,  0.1924,  0.4873,  ..., -0.0704, -0.3523, -0.0437],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.7734, -1.5762, -0.3926,  ..., -0.0723, -6.9688, -1.4326],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0568,  0.0011,  0.0110,  ..., -0.0009,  0.0054,  0.0185],
        [-0.0141,  0.0574,  0.0074,  ...,  0.0065, -0.0011, -0.0099],
        [ 0.0010, -0.0059,  0.0460,  ..., -0.0143, -0.0010, -0.0009],
        ...,
        [ 0.0038, -0.0025, -0.0078,  ...,  0.0543,  0.0045,  0.0042],
        [ 0.0037, -0.0020,  0.0098,  ..., -0.0020,  0.0438, -0.0070],
        [-0.0069,  0.0069, -0.0015,  ...,  0.0055, -0.0146,  0.0506]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.9160, -1.4990,  0.1138,  ..., -0.2327, -6.7148, -0.9854]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 06:56:43 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for I promote, he promotes
I continue, he continues
I happen, he happens
I send, he sends
I receive, he receives
I enable, he enables
I suggest, he suggests
I include, he
2024-07-29 06:56:43 root INFO     [order_1_approx] starting weight calculation for I enable, he enables
I send, he sends
I promote, he promotes
I suggest, he suggests
I include, he includes
I happen, he happens
I receive, he receives
I continue, he
2024-07-29 06:56:43 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 06:58:39 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.8633, -0.6377, -0.6904,  ..., -0.4546, -1.1084,  1.3721],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.4688, -4.6055, -2.2227,  ..., -1.3955, -5.5391, -0.5840],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0405, -0.0006,  0.0061,  ..., -0.0113,  0.0071,  0.0215],
        [-0.0188,  0.0441,  0.0105,  ...,  0.0043, -0.0087, -0.0141],
        [-0.0062,  0.0033,  0.0210,  ..., -0.0139,  0.0072, -0.0028],
        ...,
        [-0.0044,  0.0097, -0.0009,  ...,  0.0462,  0.0022, -0.0068],
        [ 0.0073,  0.0001,  0.0025,  ..., -0.0158,  0.0346, -0.0093],
        [-0.0042, -0.0015,  0.0130,  ..., -0.0128, -0.0152,  0.0370]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.3906, -4.2617, -2.3027,  ..., -1.2949, -5.7500, -0.6890]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 06:58:44 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for I enable, he enables
I send, he sends
I promote, he promotes
I suggest, he suggests
I include, he includes
I happen, he happens
I receive, he receives
I continue, he
2024-07-29 06:58:44 root INFO     total operator prediction time: 941.9647545814514 seconds
2024-07-29 06:58:44 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on verb_inf - Ved
2024-07-29 06:58:44 root INFO     building operator verb_inf - Ved
2024-07-29 06:58:44 root INFO     [order_1_approx] starting weight calculation for If the present form is lose, the past form is lost
If the present form is become, the past form is became
If the present form is provide, the past form is provided
If the present form is enjoy, the past form is enjoyed
If the present form is receive, the past form is received
If the present form is include, the past form is included
If the present form is allow, the past form is allowed
If the present form is unite, the past form is
2024-07-29 06:58:44 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 07:00:39 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2297, -0.7847, -0.3647,  ...,  0.1438, -0.8574,  0.2468],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.2354, -0.6978,  1.8516,  ...,  0.1687, -0.1494,  0.5078],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0762, -0.0056,  0.0154,  ...,  0.0047,  0.0047, -0.0035],
        [-0.0104,  0.0483,  0.0091,  ...,  0.0305, -0.0052, -0.0223],
        [-0.0040, -0.0060,  0.0453,  ..., -0.0027, -0.0013, -0.0070],
        ...,
        [ 0.0033,  0.0111, -0.0096,  ...,  0.0837, -0.0011, -0.0122],
        [-0.0015,  0.0077,  0.0045,  ..., -0.0121,  0.0537, -0.0052],
        [-0.0092, -0.0102, -0.0083,  ..., -0.0201, -0.0141,  0.0645]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.3022, -0.3823,  1.5918,  ..., -0.0425, -0.0214,  0.9194]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 07:00:40 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If the present form is lose, the past form is lost
If the present form is become, the past form is became
If the present form is provide, the past form is provided
If the present form is enjoy, the past form is enjoyed
If the present form is receive, the past form is received
If the present form is include, the past form is included
If the present form is allow, the past form is allowed
If the present form is unite, the past form is
2024-07-29 07:00:40 root INFO     [order_1_approx] starting weight calculation for If the present form is receive, the past form is received
If the present form is become, the past form is became
If the present form is provide, the past form is provided
If the present form is lose, the past form is lost
If the present form is enjoy, the past form is enjoyed
If the present form is unite, the past form is united
If the present form is allow, the past form is allowed
If the present form is include, the past form is
2024-07-29 07:00:40 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 07:02:34 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2957, -0.0741,  0.3096,  ..., -0.0217,  0.1738, -0.3215],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.7480,  0.6367,  0.3340,  ..., -1.1318, -0.4072, -1.6387],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 7.5867e-02, -1.2939e-02,  2.4078e-02,  ..., -4.9067e-04,
         -2.5215e-03,  6.8665e-03],
        [-1.8066e-02,  6.2866e-02, -9.8495e-03,  ...,  1.6968e-02,
         -5.9738e-03, -1.3565e-02],
        [ 3.1242e-03, -8.4610e-03,  5.3345e-02,  ..., -1.9684e-02,
         -7.7324e-03,  7.8964e-03],
        ...,
        [ 1.7090e-02,  9.2926e-03, -1.4183e-02,  ...,  7.3792e-02,
          3.4485e-03,  2.2964e-03],
        [ 4.8065e-03, -3.8147e-06,  1.0353e-02,  ..., -1.1185e-02,
          4.7791e-02, -1.6937e-02],
        [-1.6663e-02,  5.5618e-03, -1.8358e-03,  ..., -6.4850e-04,
         -1.4450e-02,  6.2225e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.4224,  1.0312,  0.4065,  ..., -1.8262, -0.2014, -0.9375]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 07:02:35 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If the present form is receive, the past form is received
If the present form is become, the past form is became
If the present form is provide, the past form is provided
If the present form is lose, the past form is lost
If the present form is enjoy, the past form is enjoyed
If the present form is unite, the past form is united
If the present form is allow, the past form is allowed
If the present form is include, the past form is
2024-07-29 07:02:35 root INFO     [order_1_approx] starting weight calculation for If the present form is enjoy, the past form is enjoyed
If the present form is lose, the past form is lost
If the present form is unite, the past form is united
If the present form is allow, the past form is allowed
If the present form is provide, the past form is provided
If the present form is become, the past form is became
If the present form is include, the past form is included
If the present form is receive, the past form is
2024-07-29 07:02:35 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 07:04:26 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1041,  0.1384, -0.2137,  ..., -0.9102, -0.8657,  0.0503],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-2.0645, -0.4600, -1.0332,  ..., -3.3359, -1.2305, -1.2842],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0763, -0.0181,  0.0198,  ..., -0.0015,  0.0004,  0.0251],
        [-0.0379,  0.0784, -0.0033,  ...,  0.0228,  0.0042, -0.0137],
        [ 0.0119, -0.0169,  0.0409,  ..., -0.0298, -0.0096,  0.0035],
        ...,
        [ 0.0006, -0.0002, -0.0109,  ...,  0.1006,  0.0103, -0.0042],
        [ 0.0095,  0.0034, -0.0033,  ...,  0.0030,  0.0632, -0.0109],
        [-0.0166,  0.0061, -0.0058,  ..., -0.0112,  0.0077,  0.0673]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.9082, -0.2496, -1.3682,  ..., -3.7070, -1.1162, -0.8706]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 07:04:27 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If the present form is enjoy, the past form is enjoyed
If the present form is lose, the past form is lost
If the present form is unite, the past form is united
If the present form is allow, the past form is allowed
If the present form is provide, the past form is provided
If the present form is become, the past form is became
If the present form is include, the past form is included
If the present form is receive, the past form is
2024-07-29 07:04:28 root INFO     [order_1_approx] starting weight calculation for If the present form is allow, the past form is allowed
If the present form is provide, the past form is provided
If the present form is lose, the past form is lost
If the present form is include, the past form is included
If the present form is enjoy, the past form is enjoyed
If the present form is unite, the past form is united
If the present form is receive, the past form is received
If the present form is become, the past form is
2024-07-29 07:04:28 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 07:06:22 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.6245,  0.1236, -0.0780,  ..., -0.2410, -0.5928,  0.0598],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.0156, -0.4277,  1.2422,  ...,  0.1150,  0.8340, -1.4951],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0791, -0.0177,  0.0136,  ..., -0.0110,  0.0032,  0.0019],
        [-0.0267,  0.0630,  0.0093,  ...,  0.0194,  0.0091, -0.0111],
        [ 0.0208, -0.0063,  0.0540,  ..., -0.0266, -0.0037, -0.0094],
        ...,
        [ 0.0144,  0.0107, -0.0028,  ...,  0.0777, -0.0035,  0.0059],
        [ 0.0075,  0.0087,  0.0014,  ..., -0.0097,  0.0464,  0.0004],
        [-0.0074,  0.0162, -0.0031,  ..., -0.0086, -0.0119,  0.0564]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.9209, -0.1140,  0.9863,  ...,  0.1339,  0.6948, -1.3574]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 07:06:23 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If the present form is allow, the past form is allowed
If the present form is provide, the past form is provided
If the present form is lose, the past form is lost
If the present form is include, the past form is included
If the present form is enjoy, the past form is enjoyed
If the present form is unite, the past form is united
If the present form is receive, the past form is received
If the present form is become, the past form is
2024-07-29 07:06:23 root INFO     [order_1_approx] starting weight calculation for If the present form is unite, the past form is united
If the present form is provide, the past form is provided
If the present form is become, the past form is became
If the present form is include, the past form is included
If the present form is lose, the past form is lost
If the present form is allow, the past form is allowed
If the present form is receive, the past form is received
If the present form is enjoy, the past form is
2024-07-29 07:06:23 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 07:08:18 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.3872, -0.7373,  0.1299,  ..., -1.0801, -0.6689,  0.1855],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.0078, -0.7524,  0.9316,  ..., -2.0117, -4.3203, -0.4990],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0497, -0.0028,  0.0169,  ...,  0.0007,  0.0095,  0.0188],
        [-0.0101,  0.0518, -0.0075,  ...,  0.0131,  0.0040, -0.0065],
        [ 0.0119, -0.0057,  0.0537,  ..., -0.0149, -0.0106, -0.0013],
        ...,
        [-0.0026,  0.0097, -0.0155,  ...,  0.0642,  0.0036, -0.0086],
        [ 0.0203,  0.0010,  0.0024,  ...,  0.0074,  0.0253, -0.0056],
        [-0.0008,  0.0069, -0.0025,  ..., -0.0081, -0.0021,  0.0447]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.0388, -0.6270,  0.8330,  ..., -1.6494, -4.3086, -0.5127]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 07:08:19 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If the present form is unite, the past form is united
If the present form is provide, the past form is provided
If the present form is become, the past form is became
If the present form is include, the past form is included
If the present form is lose, the past form is lost
If the present form is allow, the past form is allowed
If the present form is receive, the past form is received
If the present form is enjoy, the past form is
2024-07-29 07:08:19 root INFO     [order_1_approx] starting weight calculation for If the present form is allow, the past form is allowed
If the present form is unite, the past form is united
If the present form is include, the past form is included
If the present form is become, the past form is became
If the present form is enjoy, the past form is enjoyed
If the present form is receive, the past form is received
If the present form is provide, the past form is provided
If the present form is lose, the past form is
2024-07-29 07:08:20 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 07:10:13 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1740,  0.1456,  0.5645,  ..., -1.2725,  0.1234, -0.2142],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.5957, -1.3623, -0.1113,  ..., -0.4700, -0.8809, -1.4590],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0701, -0.0051,  0.0036,  ..., -0.0095,  0.0124,  0.0022],
        [-0.0142,  0.0492, -0.0080,  ...,  0.0161,  0.0019, -0.0090],
        [-0.0024, -0.0005,  0.0581,  ..., -0.0057, -0.0037, -0.0039],
        ...,
        [ 0.0134,  0.0122, -0.0197,  ...,  0.0602,  0.0020,  0.0033],
        [ 0.0034,  0.0124,  0.0033,  ..., -0.0022,  0.0413, -0.0166],
        [ 0.0050, -0.0068, -0.0006,  ..., -0.0200, -0.0062,  0.0390]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.4307, -1.2637, -0.1517,  ..., -0.5332, -0.8994, -1.1182]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 07:10:14 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If the present form is allow, the past form is allowed
If the present form is unite, the past form is united
If the present form is include, the past form is included
If the present form is become, the past form is became
If the present form is enjoy, the past form is enjoyed
If the present form is receive, the past form is received
If the present form is provide, the past form is provided
If the present form is lose, the past form is
2024-07-29 07:10:15 root INFO     [order_1_approx] starting weight calculation for If the present form is include, the past form is included
If the present form is allow, the past form is allowed
If the present form is unite, the past form is united
If the present form is lose, the past form is lost
If the present form is receive, the past form is received
If the present form is enjoy, the past form is enjoyed
If the present form is become, the past form is became
If the present form is provide, the past form is
2024-07-29 07:10:15 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 07:12:10 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1660, -0.3965, -0.1820,  ..., -0.6743, -0.3015, -0.0635],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.3457, -2.7695,  1.7500,  ..., -1.4307, -2.2305,  0.7676],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 1.0089e-01, -1.8158e-02,  2.2964e-02,  ...,  3.5934e-03,
         -2.6207e-03,  2.3880e-03],
        [-4.1626e-02,  6.1615e-02,  5.0125e-03,  ...,  1.5244e-02,
          2.9163e-03, -1.2268e-02],
        [ 1.4786e-02, -1.1261e-02,  7.0801e-02,  ..., -2.2781e-02,
          3.8147e-06,  3.0136e-04],
        ...,
        [ 8.4534e-03, -4.7684e-03, -1.9531e-03,  ...,  1.1755e-01,
          8.0643e-03,  1.3596e-02],
        [ 8.4229e-03, -3.9215e-03,  1.5259e-04,  ...,  8.2245e-03,
          7.5745e-02, -1.7746e-02],
        [-8.6594e-03,  2.7885e-03, -5.1422e-03,  ..., -1.1337e-02,
         -1.0818e-02,  9.2468e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.6016, -2.2520,  1.6406,  ..., -1.4775, -1.9170,  1.3369]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 07:12:11 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If the present form is include, the past form is included
If the present form is allow, the past form is allowed
If the present form is unite, the past form is united
If the present form is lose, the past form is lost
If the present form is receive, the past form is received
If the present form is enjoy, the past form is enjoyed
If the present form is become, the past form is became
If the present form is provide, the past form is
2024-07-29 07:12:11 root INFO     [order_1_approx] starting weight calculation for If the present form is receive, the past form is received
If the present form is include, the past form is included
If the present form is unite, the past form is united
If the present form is lose, the past form is lost
If the present form is become, the past form is became
If the present form is enjoy, the past form is enjoyed
If the present form is provide, the past form is provided
If the present form is allow, the past form is
2024-07-29 07:12:11 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 07:14:06 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.6196, -0.3315,  0.2678,  ..., -0.8828, -0.1443, -0.2246],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.0889, -2.8203, -0.5039,  ..., -0.4734, -2.1875,  0.5859],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 5.9906e-02, -5.4359e-03,  1.1284e-02,  ..., -1.3580e-02,
          3.4618e-04,  4.9591e-05],
        [-1.4038e-03,  3.9764e-02, -1.7395e-02,  ...,  1.9653e-02,
          4.2801e-03, -1.1948e-02],
        [ 3.6659e-03, -2.5272e-03,  4.6692e-02,  ..., -1.4969e-02,
         -3.8376e-03, -3.8147e-05],
        ...,
        [ 7.0190e-04,  6.5575e-03, -1.5717e-02,  ...,  6.2561e-02,
          5.1537e-03, -1.1292e-03],
        [ 2.9144e-03,  1.3298e-02, -1.1917e-02,  ..., -3.2501e-03,
          3.6560e-02, -2.5726e-02],
        [ 2.9354e-03, -1.8578e-03, -2.3155e-03,  ..., -9.1400e-03,
         -1.1940e-02,  5.2979e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.2305, -2.8672, -0.6826,  ..., -0.3472, -2.0430,  0.9868]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 07:14:07 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If the present form is receive, the past form is received
If the present form is include, the past form is included
If the present form is unite, the past form is united
If the present form is lose, the past form is lost
If the present form is become, the past form is became
If the present form is enjoy, the past form is enjoyed
If the present form is provide, the past form is provided
If the present form is allow, the past form is
2024-07-29 07:14:07 root INFO     total operator prediction time: 923.0861999988556 seconds
2024-07-29 07:14:07 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on verb_Ving - Ved
2024-07-29 07:14:07 root INFO     building operator verb_Ving - Ved
2024-07-29 07:14:07 root INFO     [order_1_approx] starting weight calculation for After something is publishing, it has published
After something is uniting, it has united
After something is operating, it has operated
After something is appearing, it has appeared
After something is hearing, it has heard
After something is containing, it has contained
After something is sending, it has sent
After something is considering, it has
2024-07-29 07:14:07 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 07:16:03 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3430, -0.7090,  0.6294,  ..., -0.2842, -0.1921, -0.3130],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.6582, -0.9644,  3.3691,  ..., -2.2090, -0.6260, -0.1152],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0646,  0.0035,  0.0139,  ..., -0.0035, -0.0073,  0.0159],
        [-0.0124,  0.0283,  0.0011,  ...,  0.0165, -0.0042,  0.0042],
        [ 0.0003, -0.0059,  0.0513,  ..., -0.0047,  0.0004, -0.0190],
        ...,
        [ 0.0033,  0.0088,  0.0141,  ...,  0.0589,  0.0046,  0.0151],
        [ 0.0104,  0.0026, -0.0030,  ..., -0.0058,  0.0490, -0.0116],
        [-0.0005, -0.0014,  0.0105,  ...,  0.0021, -0.0093,  0.0396]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.6543, -0.7651,  3.1309,  ..., -1.7969, -0.9170, -0.0986]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 07:16:04 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for After something is publishing, it has published
After something is uniting, it has united
After something is operating, it has operated
After something is appearing, it has appeared
After something is hearing, it has heard
After something is containing, it has contained
After something is sending, it has sent
After something is considering, it has
2024-07-29 07:16:05 root INFO     [order_1_approx] starting weight calculation for After something is uniting, it has united
After something is considering, it has considered
After something is appearing, it has appeared
After something is containing, it has contained
After something is hearing, it has heard
After something is sending, it has sent
After something is operating, it has operated
After something is publishing, it has
2024-07-29 07:16:05 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 07:17:59 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0624, -0.3811,  0.0016,  ...,  0.0631, -0.5781,  0.3755],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.4805, -1.4521,  0.9590,  ..., -2.9844, -1.5156,  1.0195],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0467, -0.0057,  0.0165,  ...,  0.0015, -0.0026,  0.0182],
        [-0.0241,  0.0324, -0.0111,  ...,  0.0167, -0.0004,  0.0038],
        [ 0.0229, -0.0116,  0.0545,  ..., -0.0010, -0.0053,  0.0011],
        ...,
        [-0.0095,  0.0090, -0.0011,  ...,  0.0765,  0.0118,  0.0115],
        [ 0.0115, -0.0038, -0.0033,  ..., -0.0010,  0.0421, -0.0128],
        [-0.0013,  0.0059,  0.0015,  ..., -0.0077, -0.0142,  0.0415]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.6895, -1.4199,  0.8691,  ..., -2.7559, -1.4414,  1.1855]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 07:18:00 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for After something is uniting, it has united
After something is considering, it has considered
After something is appearing, it has appeared
After something is containing, it has contained
After something is hearing, it has heard
After something is sending, it has sent
After something is operating, it has operated
After something is publishing, it has
2024-07-29 07:18:00 root INFO     [order_1_approx] starting weight calculation for After something is sending, it has sent
After something is uniting, it has united
After something is hearing, it has heard
After something is appearing, it has appeared
After something is publishing, it has published
After something is operating, it has operated
After something is considering, it has considered
After something is containing, it has
2024-07-29 07:18:01 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 07:19:56 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.6768, -1.0137, -0.7642,  ..., -0.2101, -0.1240, -0.1653],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.6646,  1.4121,  2.9160,  ..., -2.9648, -0.4932, -3.0918],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0737, -0.0048,  0.0116,  ..., -0.0025,  0.0006,  0.0047],
        [-0.0236,  0.0399, -0.0047,  ...,  0.0102,  0.0010, -0.0136],
        [ 0.0068, -0.0052,  0.0441,  ..., -0.0138,  0.0031, -0.0173],
        ...,
        [-0.0086,  0.0093,  0.0005,  ...,  0.0705,  0.0010,  0.0157],
        [ 0.0114, -0.0052, -0.0024,  ...,  0.0010,  0.0640, -0.0108],
        [ 0.0031,  0.0099,  0.0059,  ..., -0.0020, -0.0182,  0.0493]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.7920,  1.8281,  3.0410,  ..., -2.7852, -0.2920, -3.1699]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 07:19:57 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for After something is sending, it has sent
After something is uniting, it has united
After something is hearing, it has heard
After something is appearing, it has appeared
After something is publishing, it has published
After something is operating, it has operated
After something is considering, it has considered
After something is containing, it has
2024-07-29 07:19:58 root INFO     [order_1_approx] starting weight calculation for After something is appearing, it has appeared
After something is operating, it has operated
After something is sending, it has sent
After something is considering, it has considered
After something is publishing, it has published
After something is containing, it has contained
After something is hearing, it has heard
After something is uniting, it has
2024-07-29 07:19:58 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 07:21:54 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.7163, -0.8735,  0.0309,  ...,  0.1472, -0.8442,  0.2004],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.6152,  0.5142,  3.6992,  ..., -1.2363, -0.4092, -0.1377],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0447, -0.0152,  0.0158,  ...,  0.0153,  0.0071, -0.0135],
        [-0.0233,  0.0427, -0.0008,  ...,  0.0228, -0.0086, -0.0125],
        [-0.0073, -0.0125,  0.0331,  ..., -0.0084,  0.0136, -0.0153],
        ...,
        [ 0.0121,  0.0280,  0.0042,  ...,  0.0550,  0.0055, -0.0059],
        [ 0.0107,  0.0053, -0.0086,  ..., -0.0187,  0.0656,  0.0019],
        [ 0.0046, -0.0080, -0.0039,  ..., -0.0204, -0.0226,  0.0553]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.6724,  0.5786,  3.5547,  ..., -1.4590, -0.2800, -0.1556]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 07:21:55 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for After something is appearing, it has appeared
After something is operating, it has operated
After something is sending, it has sent
After something is considering, it has considered
After something is publishing, it has published
After something is containing, it has contained
After something is hearing, it has heard
After something is uniting, it has
2024-07-29 07:21:55 root INFO     [order_1_approx] starting weight calculation for After something is hearing, it has heard
After something is appearing, it has appeared
After something is publishing, it has published
After something is uniting, it has united
After something is containing, it has contained
After something is operating, it has operated
After something is considering, it has considered
After something is sending, it has
2024-07-29 07:21:55 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 07:23:51 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1193, -0.6167,  0.7905,  ..., -0.1367, -0.0764, -0.2000],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.5332, -0.9775, -0.6719,  ..., -2.7930, -0.0898, -1.7959],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0684, -0.0001,  0.0314,  ...,  0.0003,  0.0029, -0.0027],
        [-0.0205,  0.0529, -0.0056,  ...,  0.0216,  0.0175, -0.0049],
        [ 0.0112, -0.0067,  0.0469,  ...,  0.0032,  0.0117,  0.0036],
        ...,
        [-0.0002,  0.0155,  0.0017,  ...,  0.0700,  0.0014,  0.0021],
        [ 0.0143, -0.0164, -0.0043,  ..., -0.0014,  0.0504, -0.0072],
        [-0.0070,  0.0179, -0.0004,  ..., -0.0073, -0.0083,  0.0596]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.7656, -0.9985, -0.3894,  ..., -2.7969, -0.2347, -1.7031]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 07:23:52 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for After something is hearing, it has heard
After something is appearing, it has appeared
After something is publishing, it has published
After something is uniting, it has united
After something is containing, it has contained
After something is operating, it has operated
After something is considering, it has considered
After something is sending, it has
2024-07-29 07:23:52 root INFO     [order_1_approx] starting weight calculation for After something is uniting, it has united
After something is considering, it has considered
After something is hearing, it has heard
After something is publishing, it has published
After something is containing, it has contained
After something is sending, it has sent
After something is appearing, it has appeared
After something is operating, it has
2024-07-29 07:23:53 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 07:25:49 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.8286, -0.4810, -0.7354,  ..., -0.5864, -0.9199, -0.5376],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.5298,  0.4136,  1.1367,  ..., -3.4863, -1.7275,  0.2676],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 4.9835e-02, -1.0910e-03,  1.1292e-02,  ..., -6.8235e-04,
         -1.1963e-02,  1.1459e-02],
        [-2.2400e-02,  3.8910e-02, -7.8125e-03,  ...,  1.8799e-02,
          9.9106e-03, -1.9188e-03],
        [ 9.7504e-03,  3.0756e-04,  4.5074e-02,  ..., -1.1215e-02,
          7.3547e-03, -4.2915e-03],
        ...,
        [-1.0773e-02,  1.4420e-02, -1.4862e-02,  ...,  6.9702e-02,
          9.1019e-03, -7.2479e-05],
        [ 1.5106e-02, -5.9814e-03, -1.4542e-02,  ...,  8.3160e-03,
          5.0018e-02, -1.7883e-02],
        [ 8.7929e-04, -4.9782e-03, -4.7455e-03,  ..., -2.8877e-03,
         -1.6510e-02,  4.0558e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.5991,  0.5820,  1.1982,  ..., -3.2656, -1.8809,  0.6353]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 07:25:50 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for After something is uniting, it has united
After something is considering, it has considered
After something is hearing, it has heard
After something is publishing, it has published
After something is containing, it has contained
After something is sending, it has sent
After something is appearing, it has appeared
After something is operating, it has
2024-07-29 07:25:50 root INFO     [order_1_approx] starting weight calculation for After something is containing, it has contained
After something is operating, it has operated
After something is publishing, it has published
After something is uniting, it has united
After something is hearing, it has heard
After something is sending, it has sent
After something is considering, it has considered
After something is appearing, it has
2024-07-29 07:25:50 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 07:27:46 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.7676, -0.4988, -0.1118,  ..., -0.6934,  0.0509, -1.0859],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.0869,  0.8516,  1.2393,  ...,  0.2812, -1.6230,  1.6875],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0770, -0.0012,  0.0284,  ...,  0.0046, -0.0032,  0.0115],
        [-0.0147,  0.0731,  0.0018,  ...,  0.0259, -0.0103, -0.0172],
        [ 0.0010,  0.0044,  0.0817,  ..., -0.0086,  0.0027, -0.0093],
        ...,
        [ 0.0031,  0.0236, -0.0113,  ...,  0.0872, -0.0016, -0.0071],
        [ 0.0098, -0.0003,  0.0121,  ..., -0.0031,  0.0725, -0.0062],
        [ 0.0085,  0.0026,  0.0020,  ..., -0.0122, -0.0109,  0.0674]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.2385,  0.6128,  1.5459,  ...,  0.5073, -2.0645,  1.6504]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 07:27:47 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for After something is containing, it has contained
After something is operating, it has operated
After something is publishing, it has published
After something is uniting, it has united
After something is hearing, it has heard
After something is sending, it has sent
After something is considering, it has considered
After something is appearing, it has
2024-07-29 07:27:48 root INFO     [order_1_approx] starting weight calculation for After something is considering, it has considered
After something is operating, it has operated
After something is uniting, it has united
After something is publishing, it has published
After something is appearing, it has appeared
After something is containing, it has contained
After something is sending, it has sent
After something is hearing, it has
2024-07-29 07:27:48 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 07:29:44 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0343, -0.9033,  0.3684,  ..., -0.2732, -0.7729,  0.3264],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.0664, -0.1836,  1.0771,  ..., -0.0436, -4.3516, -3.0078],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0563, -0.0012,  0.0188,  ..., -0.0102,  0.0189,  0.0014],
        [-0.0112,  0.0463, -0.0065,  ...,  0.0066,  0.0101, -0.0057],
        [ 0.0112, -0.0041,  0.0437,  ..., -0.0023,  0.0126,  0.0043],
        ...,
        [ 0.0086,  0.0155,  0.0034,  ...,  0.0528,  0.0071,  0.0012],
        [ 0.0095, -0.0084,  0.0003,  ...,  0.0074,  0.0348, -0.0123],
        [-0.0130,  0.0156,  0.0100,  ...,  0.0076,  0.0112,  0.0363]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.1034,  0.1587,  0.9775,  ...,  0.0201, -4.1953, -2.9277]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 07:29:44 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for After something is considering, it has considered
After something is operating, it has operated
After something is uniting, it has united
After something is publishing, it has published
After something is appearing, it has appeared
After something is containing, it has contained
After something is sending, it has sent
After something is hearing, it has
2024-07-29 07:29:44 root INFO     total operator prediction time: 937.4354667663574 seconds
2024-07-29 07:29:44 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on Ving - verb_inf
2024-07-29 07:29:44 root INFO     building operator Ving - verb_inf
2024-07-29 07:29:45 root INFO     [order_1_approx] starting weight calculation for involving is the active form of involve
representing is the active form of represent
developing is the active form of develop
reducing is the active form of reduce
protecting is the active form of protect
preventing is the active form of prevent
spending is the active form of spend
promoting is the active form of
2024-07-29 07:29:45 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 07:31:41 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3518, -0.2144, -0.5410,  ..., -0.3208, -0.5605, -0.2355],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.4121, -3.4258, -0.4741,  ...,  2.1289, -2.7266, -1.9414],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 5.6305e-02, -7.8201e-05,  6.5880e-03,  ...,  6.0463e-04,
         -1.8415e-03,  6.4316e-03],
        [-6.2180e-03,  4.6448e-02, -2.7275e-03,  ...,  9.3231e-03,
          1.3304e-04, -4.8180e-03],
        [ 3.7804e-03, -1.1749e-02,  4.4739e-02,  ..., -3.8853e-03,
         -8.5163e-04,  1.2913e-03],
        ...,
        [ 2.7103e-03,  6.9885e-03,  8.7547e-04,  ...,  6.0272e-02,
         -1.2112e-04, -2.5463e-04],
        [-4.4250e-03,  2.8172e-03, -1.6890e-03,  ...,  1.2482e-02,
          4.2847e-02, -1.4503e-02],
        [ 2.9297e-03,  2.0847e-03, -9.6817e-03,  ..., -6.3782e-03,
         -5.4703e-03,  4.1931e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.3398, -3.3750, -0.4702,  ...,  2.1973, -2.6094, -1.9277]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 07:31:41 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for involving is the active form of involve
representing is the active form of represent
developing is the active form of develop
reducing is the active form of reduce
protecting is the active form of protect
preventing is the active form of prevent
spending is the active form of spend
promoting is the active form of
2024-07-29 07:31:42 root INFO     [order_1_approx] starting weight calculation for preventing is the active form of prevent
protecting is the active form of protect
spending is the active form of spend
developing is the active form of develop
representing is the active form of represent
promoting is the active form of promote
involving is the active form of involve
reducing is the active form of
2024-07-29 07:31:42 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 07:33:37 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1439, -0.5532, -0.4207,  ..., -0.6152, -0.3118, -0.8042],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.9209, -3.5820, -0.9326,  ..., -1.0176, -0.8960, -4.2578],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 6.2073e-02, -6.4850e-05,  1.0063e-02,  ...,  5.0697e-03,
          2.4071e-03,  1.3107e-02],
        [-2.1992e-03,  5.7281e-02,  3.2787e-03,  ...,  1.0536e-02,
          3.3665e-04, -5.6763e-03],
        [ 5.0201e-03, -1.2718e-02,  5.0323e-02,  ..., -6.4316e-03,
         -4.9133e-03, -5.5361e-04],
        ...,
        [ 9.3079e-04,  1.2558e-02, -9.1782e-03,  ...,  6.5796e-02,
          3.2539e-03,  5.2834e-03],
        [-6.5002e-03,  7.1869e-03, -5.4598e-04,  ...,  9.5825e-03,
          5.8929e-02, -1.1703e-02],
        [-8.0566e-03,  3.4828e-03, -5.9967e-03,  ..., -1.3000e-02,
         -2.5539e-03,  4.8737e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.8618, -3.5859, -1.0684,  ..., -0.9907, -0.8218, -4.1172]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 07:33:38 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for preventing is the active form of prevent
protecting is the active form of protect
spending is the active form of spend
developing is the active form of develop
representing is the active form of represent
promoting is the active form of promote
involving is the active form of involve
reducing is the active form of
2024-07-29 07:33:38 root INFO     [order_1_approx] starting weight calculation for promoting is the active form of promote
preventing is the active form of prevent
protecting is the active form of protect
reducing is the active form of reduce
developing is the active form of develop
involving is the active form of involve
spending is the active form of spend
representing is the active form of
2024-07-29 07:33:38 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 07:35:35 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2109, -0.0770, -0.8262,  ..., -0.8179, -0.6953, -0.4873],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.6113, -3.0020,  2.1934,  ...,  1.5820, -2.3047, -3.5039],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 5.3986e-02,  1.5802e-03,  6.7101e-03,  ..., -5.5790e-04,
          9.1648e-04,  8.2245e-03],
        [-7.9880e-03,  4.9835e-02, -5.1117e-03,  ...,  6.8130e-03,
         -9.0694e-04, -3.6201e-03],
        [ 8.4534e-03, -7.7095e-03,  4.1718e-02,  ..., -5.4817e-03,
         -5.0583e-03, -1.4153e-03],
        ...,
        [-1.7471e-03,  5.4893e-03, -4.5891e-03,  ...,  5.6763e-02,
         -2.4147e-03,  2.8133e-05],
        [ 1.5564e-03, -1.7023e-03,  8.9645e-03,  ...,  1.3924e-03,
          4.5685e-02, -7.1754e-03],
        [ 3.2349e-03,  7.8487e-04, -7.1754e-03,  ..., -3.9787e-03,
         -3.5744e-03,  5.0201e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.6167, -2.9980,  2.1484,  ...,  1.6504, -2.3359, -3.5332]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 07:35:36 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for promoting is the active form of promote
preventing is the active form of prevent
protecting is the active form of protect
reducing is the active form of reduce
developing is the active form of develop
involving is the active form of involve
spending is the active form of spend
representing is the active form of
2024-07-29 07:35:36 root INFO     [order_1_approx] starting weight calculation for promoting is the active form of promote
representing is the active form of represent
spending is the active form of spend
developing is the active form of develop
protecting is the active form of protect
reducing is the active form of reduce
preventing is the active form of prevent
involving is the active form of
2024-07-29 07:35:36 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 07:37:29 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4590, -0.2705,  0.1555,  ..., -0.8140, -0.9731, -1.0420],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.3691, -2.2617,  1.6270,  ...,  2.6309, -0.2168, -5.0977],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0502, -0.0013,  0.0004,  ...,  0.0027,  0.0020,  0.0095],
        [-0.0064,  0.0430, -0.0006,  ..., -0.0008, -0.0063, -0.0008],
        [ 0.0045, -0.0098,  0.0387,  ..., -0.0085, -0.0005,  0.0041],
        ...,
        [ 0.0072,  0.0034, -0.0045,  ...,  0.0555, -0.0090, -0.0021],
        [-0.0027,  0.0027,  0.0001,  ...,  0.0037,  0.0438, -0.0120],
        [ 0.0004,  0.0034, -0.0089,  ..., -0.0055, -0.0039,  0.0442]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.4216, -2.4141,  1.3965,  ...,  2.5879, -0.1871, -4.9102]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 07:37:30 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for promoting is the active form of promote
representing is the active form of represent
spending is the active form of spend
developing is the active form of develop
protecting is the active form of protect
reducing is the active form of reduce
preventing is the active form of prevent
involving is the active form of
2024-07-29 07:37:30 root INFO     [order_1_approx] starting weight calculation for representing is the active form of represent
developing is the active form of develop
promoting is the active form of promote
involving is the active form of involve
reducing is the active form of reduce
protecting is the active form of protect
preventing is the active form of prevent
spending is the active form of
2024-07-29 07:37:30 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 07:39:27 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0083, -0.4133,  0.1082,  ..., -0.1868, -0.4875, -0.4465],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.4775, -2.2031, -2.3047,  ...,  0.6377, -0.8564, -2.1035],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0540, -0.0089,  0.0060,  ..., -0.0015,  0.0047,  0.0091],
        [-0.0001,  0.0422,  0.0005,  ...,  0.0047,  0.0021, -0.0047],
        [ 0.0071,  0.0046,  0.0350,  ..., -0.0011, -0.0034, -0.0159],
        ...,
        [ 0.0073,  0.0064, -0.0007,  ...,  0.0487, -0.0038, -0.0010],
        [-0.0032,  0.0009,  0.0025,  ...,  0.0092,  0.0440, -0.0076],
        [ 0.0072,  0.0043, -0.0121,  ..., -0.0099,  0.0011,  0.0401]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.4834, -2.1387, -2.1738,  ...,  0.6348, -1.0684, -2.0117]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 07:39:28 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for representing is the active form of represent
developing is the active form of develop
promoting is the active form of promote
involving is the active form of involve
reducing is the active form of reduce
protecting is the active form of protect
preventing is the active form of prevent
spending is the active form of
2024-07-29 07:39:28 root INFO     [order_1_approx] starting weight calculation for reducing is the active form of reduce
promoting is the active form of promote
spending is the active form of spend
representing is the active form of represent
preventing is the active form of prevent
involving is the active form of involve
developing is the active form of develop
protecting is the active form of
2024-07-29 07:39:28 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 07:41:23 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.6982, -0.9453, -0.4377,  ..., -0.7549, -0.7173, -0.4634],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.0254, -5.1875, -1.1660,  ...,  1.7617, -0.9888, -2.1484],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 2.9114e-02, -7.7248e-04,  5.3024e-03,  ..., -4.8447e-04,
         -5.0545e-05,  7.2861e-03],
        [-8.7662e-03,  2.9633e-02,  9.4223e-04,  ...,  4.4479e-03,
          2.7046e-03, -7.0238e-04],
        [ 5.8365e-03, -1.7815e-03,  2.3865e-02,  ..., -1.2350e-03,
         -3.5515e-03, -5.6124e-04],
        ...,
        [ 6.1035e-03,  3.8567e-03, -3.3512e-03,  ...,  2.8091e-02,
          4.3449e-03,  2.8362e-03],
        [ 1.6832e-03,  2.8515e-03,  4.3755e-03,  ...,  3.3455e-03,
          2.4841e-02, -7.4959e-03],
        [-3.0880e-03,  1.8139e-03, -2.6112e-03,  ..., -7.0267e-03,
         -1.6537e-03,  2.9922e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.9602e-03, -5.1172e+00, -1.1758e+00,  ...,  1.8125e+00,
         -1.0596e+00, -2.1367e+00]], device='cuda:1', dtype=torch.float16,
       grad_fn=<SubBackward0>) 

                    
2024-07-29 07:41:24 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for reducing is the active form of reduce
promoting is the active form of promote
spending is the active form of spend
representing is the active form of represent
preventing is the active form of prevent
involving is the active form of involve
developing is the active form of develop
protecting is the active form of
2024-07-29 07:41:24 root INFO     [order_1_approx] starting weight calculation for involving is the active form of involve
spending is the active form of spend
protecting is the active form of protect
promoting is the active form of promote
reducing is the active form of reduce
representing is the active form of represent
preventing is the active form of prevent
developing is the active form of
2024-07-29 07:41:24 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 07:43:18 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.7954, -0.0164, -0.5249,  ..., -0.4131, -0.5835, -0.6504],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.9844, -4.2500,  2.2559,  ...,  2.0039, -1.6572, -2.8281],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0375,  0.0001,  0.0037,  ...,  0.0037, -0.0031,  0.0029],
        [-0.0064,  0.0334,  0.0012,  ..., -0.0007,  0.0015, -0.0015],
        [ 0.0019, -0.0064,  0.0302,  ...,  0.0011, -0.0003, -0.0023],
        ...,
        [ 0.0072, -0.0002, -0.0040,  ...,  0.0381, -0.0071,  0.0028],
        [ 0.0027, -0.0002,  0.0033,  ...,  0.0082,  0.0294, -0.0071],
        [-0.0004, -0.0030, -0.0045,  ..., -0.0082, -0.0033,  0.0320]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.9141, -4.2773,  2.2305,  ...,  1.9688, -1.6953, -2.8066]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 07:43:19 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for involving is the active form of involve
spending is the active form of spend
protecting is the active form of protect
promoting is the active form of promote
reducing is the active form of reduce
representing is the active form of represent
preventing is the active form of prevent
developing is the active form of
2024-07-29 07:43:19 root INFO     [order_1_approx] starting weight calculation for involving is the active form of involve
promoting is the active form of promote
protecting is the active form of protect
spending is the active form of spend
reducing is the active form of reduce
developing is the active form of develop
representing is the active form of represent
preventing is the active form of
2024-07-29 07:43:19 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 07:45:09 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1777, -1.1592, -0.0431,  ..., -0.6914, -0.1182, -0.4746],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.0225, -3.5840, -1.4473,  ...,  2.0566, -0.8091, -2.7676],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0384, -0.0044,  0.0019,  ..., -0.0027, -0.0023,  0.0011],
        [-0.0022,  0.0300, -0.0018,  ...,  0.0054, -0.0019, -0.0043],
        [ 0.0023, -0.0010,  0.0220,  ..., -0.0035, -0.0004, -0.0017],
        ...,
        [ 0.0054,  0.0026, -0.0029,  ...,  0.0352,  0.0005, -0.0011],
        [-0.0025,  0.0018, -0.0013,  ...,  0.0073,  0.0289, -0.0070],
        [-0.0011,  0.0064, -0.0058,  ..., -0.0017, -0.0019,  0.0248]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.9907, -3.6621, -1.5303,  ...,  2.0977, -0.7871, -2.7598]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 07:45:10 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for involving is the active form of involve
promoting is the active form of promote
protecting is the active form of protect
spending is the active form of spend
reducing is the active form of reduce
developing is the active form of develop
representing is the active form of represent
preventing is the active form of
2024-07-29 07:45:10 root INFO     total operator prediction time: 925.412703037262 seconds
2024-07-29 07:45:10 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on noun - plural_irreg
2024-07-29 07:45:10 root INFO     building operator noun - plural_irreg
2024-07-29 07:45:10 root INFO     [order_1_approx] starting weight calculation for The plural form of success is successes
The plural form of strategy is strategies
The plural form of formula is formulae
The plural form of business is businesses
The plural form of wife is wives
The plural form of variety is varieties
The plural form of family is families
The plural form of energy is
2024-07-29 07:45:10 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 07:47:07 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.5869, -0.4214, -0.3860,  ..., -0.2839, -0.0248, -0.2251],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.7349,  0.8022,  1.0508,  ..., -2.5059, -2.9883, -2.7480],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0751,  0.0059,  0.0199,  ...,  0.0001, -0.0167,  0.0209],
        [-0.0038,  0.0592,  0.0026,  ...,  0.0344, -0.0071,  0.0198],
        [-0.0032,  0.0092,  0.0567,  ..., -0.0135,  0.0162,  0.0125],
        ...,
        [ 0.0097,  0.0079,  0.0006,  ...,  0.0808,  0.0127,  0.0028],
        [ 0.0143,  0.0151, -0.0073,  ..., -0.0181,  0.0529, -0.0078],
        [-0.0051,  0.0044,  0.0010,  ..., -0.0047, -0.0170,  0.0573]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.4971,  0.4492,  1.2510,  ..., -1.9414, -2.9316, -2.5547]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 07:47:07 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of success is successes
The plural form of strategy is strategies
The plural form of formula is formulae
The plural form of business is businesses
The plural form of wife is wives
The plural form of variety is varieties
The plural form of family is families
The plural form of energy is
2024-07-29 07:47:08 root INFO     [order_1_approx] starting weight calculation for The plural form of energy is energies
The plural form of formula is formulae
The plural form of variety is varieties
The plural form of success is successes
The plural form of family is families
The plural form of wife is wives
The plural form of strategy is strategies
The plural form of business is
2024-07-29 07:47:08 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 07:49:02 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1223,  0.7354, -0.1067,  ..., -0.1842, -0.6108,  0.0067],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.5703, -2.0781, -0.9399,  ...,  0.6172,  0.1604, -1.5449],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0635,  0.0107, -0.0013,  ...,  0.0010, -0.0105,  0.0289],
        [-0.0182,  0.0570,  0.0070,  ...,  0.0238, -0.0076,  0.0087],
        [ 0.0145, -0.0030,  0.0706,  ..., -0.0060,  0.0169,  0.0077],
        ...,
        [ 0.0126, -0.0013,  0.0038,  ...,  0.0695,  0.0125, -0.0031],
        [-0.0004,  0.0081,  0.0136,  ..., -0.0046,  0.0614, -0.0215],
        [-0.0069, -0.0020, -0.0069,  ...,  0.0039, -0.0072,  0.0704]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.9336, -1.6914, -0.6807,  ...,  0.5137, -0.2812, -1.1084]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 07:49:03 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of energy is energies
The plural form of formula is formulae
The plural form of variety is varieties
The plural form of success is successes
The plural form of family is families
The plural form of wife is wives
The plural form of strategy is strategies
The plural form of business is
2024-07-29 07:49:04 root INFO     [order_1_approx] starting weight calculation for The plural form of family is families
The plural form of business is businesses
The plural form of strategy is strategies
The plural form of formula is formulae
The plural form of wife is wives
The plural form of success is successes
The plural form of energy is energies
The plural form of variety is
2024-07-29 07:49:04 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 07:50:59 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 8.8867e-01,  1.4062e-01, -3.1494e-01,  ..., -8.5449e-04,
        -7.0068e-01,  1.0828e-01], device='cuda:1', dtype=torch.float16,
       grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.3047, -2.2461,  0.7412,  ..., -2.7734, -3.8984, -2.0957],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.1026,  0.0075,  0.0243,  ...,  0.0032,  0.0084,  0.0341],
        [-0.0099,  0.0975,  0.0094,  ...,  0.0263, -0.0126, -0.0024],
        [ 0.0256,  0.0005,  0.0699,  ..., -0.0328, -0.0014,  0.0182],
        ...,
        [ 0.0383,  0.0146, -0.0014,  ...,  0.0992,  0.0060,  0.0004],
        [ 0.0023,  0.0113,  0.0097,  ..., -0.0190,  0.0882, -0.0158],
        [ 0.0060,  0.0244,  0.0006,  ..., -0.0028, -0.0168,  0.0707]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.9688, -2.0977,  0.6978,  ..., -2.8613, -4.0156, -1.7754]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 07:51:00 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of family is families
The plural form of business is businesses
The plural form of strategy is strategies
The plural form of formula is formulae
The plural form of wife is wives
The plural form of success is successes
The plural form of energy is energies
The plural form of variety is
2024-07-29 07:51:00 root INFO     [order_1_approx] starting weight calculation for The plural form of family is families
The plural form of variety is varieties
The plural form of energy is energies
The plural form of formula is formulae
The plural form of business is businesses
The plural form of strategy is strategies
The plural form of success is successes
The plural form of wife is
2024-07-29 07:51:00 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 07:52:56 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4456, -0.0612, -0.1312,  ..., -0.3862, -0.4922, -0.1154],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.2734, -3.4453,  1.5938,  ..., -0.9648, -0.5752,  1.5010],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0814,  0.0055,  0.0028,  ..., -0.0092, -0.0094,  0.0194],
        [-0.0139,  0.0591,  0.0184,  ...,  0.0034,  0.0167,  0.0056],
        [ 0.0010,  0.0129,  0.0746,  ..., -0.0062,  0.0116, -0.0077],
        ...,
        [ 0.0018,  0.0161, -0.0067,  ...,  0.0852,  0.0024,  0.0004],
        [ 0.0077,  0.0200, -0.0009,  ..., -0.0142,  0.0446, -0.0167],
        [-0.0015,  0.0083, -0.0257,  ...,  0.0039, -0.0065,  0.0664]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.4258, -3.0820,  1.5342,  ..., -0.7280, -0.6201,  1.4238]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 07:52:57 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of family is families
The plural form of variety is varieties
The plural form of energy is energies
The plural form of formula is formulae
The plural form of business is businesses
The plural form of strategy is strategies
The plural form of success is successes
The plural form of wife is
2024-07-29 07:52:57 root INFO     [order_1_approx] starting weight calculation for The plural form of energy is energies
The plural form of family is families
The plural form of business is businesses
The plural form of formula is formulae
The plural form of strategy is strategies
The plural form of wife is wives
The plural form of variety is varieties
The plural form of success is
2024-07-29 07:52:57 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 07:54:52 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4399,  0.3936,  0.2373,  ...,  0.1356, -0.8218, -0.4114],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.0898, -0.3262, -0.9297,  ..., -1.5850, -3.0234, -2.4434],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.1168,  0.0044, -0.0064,  ..., -0.0137, -0.0046,  0.0075],
        [-0.0228,  0.0684,  0.0049,  ...,  0.0059,  0.0123, -0.0089],
        [ 0.0072, -0.0041,  0.0887,  ..., -0.0067, -0.0020,  0.0023],
        ...,
        [ 0.0074,  0.0089,  0.0074,  ...,  0.1215, -0.0031, -0.0012],
        [-0.0102,  0.0098,  0.0217,  ..., -0.0031,  0.0827, -0.0055],
        [-0.0113,  0.0054, -0.0018,  ..., -0.0018,  0.0059,  0.0882]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.6328, -0.3892, -0.7578,  ..., -1.5010, -2.7109, -1.9434]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 07:54:53 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of energy is energies
The plural form of family is families
The plural form of business is businesses
The plural form of formula is formulae
The plural form of strategy is strategies
The plural form of wife is wives
The plural form of variety is varieties
The plural form of success is
2024-07-29 07:54:53 root INFO     [order_1_approx] starting weight calculation for The plural form of business is businesses
The plural form of energy is energies
The plural form of success is successes
The plural form of strategy is strategies
The plural form of variety is varieties
The plural form of wife is wives
The plural form of formula is formulae
The plural form of family is
2024-07-29 07:54:53 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 07:56:47 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1360, -0.2812,  0.1072,  ...,  0.1198, -0.6914, -0.3369],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.7734, -1.1465,  3.2227,  ..., -1.3516, -2.3301, -3.0898],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0946,  0.0372,  0.0253,  ..., -0.0070, -0.0221,  0.0157],
        [-0.0279,  0.0596, -0.0027,  ...,  0.0199,  0.0176, -0.0016],
        [ 0.0096,  0.0143,  0.0699,  ..., -0.0153, -0.0043,  0.0117],
        ...,
        [ 0.0074,  0.0096, -0.0141,  ...,  0.0720,  0.0050, -0.0013],
        [ 0.0078,  0.0244,  0.0091,  ...,  0.0016,  0.0499, -0.0081],
        [-0.0092, -0.0064, -0.0134,  ..., -0.0074, -0.0065,  0.0736]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.3828, -0.8018,  3.2695,  ..., -1.1338, -2.3145, -3.2363]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 07:56:47 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of business is businesses
The plural form of energy is energies
The plural form of success is successes
The plural form of strategy is strategies
The plural form of variety is varieties
The plural form of wife is wives
The plural form of formula is formulae
The plural form of family is
2024-07-29 07:56:48 root INFO     [order_1_approx] starting weight calculation for The plural form of wife is wives
The plural form of family is families
The plural form of formula is formulae
The plural form of business is businesses
The plural form of variety is varieties
The plural form of success is successes
The plural form of energy is energies
The plural form of strategy is
2024-07-29 07:56:48 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 07:58:44 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.5957, -0.1232,  0.1176,  ..., -0.2183,  0.2198, -0.1334],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.9863, -2.1211,  1.0508,  ...,  0.5435, -2.2227, -3.3633],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 6.4697e-02, -5.0278e-03,  3.8280e-03,  ..., -3.4180e-03,
          3.0098e-03,  1.6754e-02],
        [-7.4348e-03,  6.6833e-02,  1.4366e-02,  ...,  1.3031e-02,
          1.3695e-03,  5.4359e-03],
        [ 7.0000e-03,  3.1700e-03,  4.6783e-02,  ..., -1.6739e-02,
         -1.4582e-03,  5.5008e-03],
        ...,
        [ 5.5580e-03,  1.5244e-02, -6.9857e-04,  ...,  6.7383e-02,
          1.0056e-02,  1.3458e-02],
        [-3.3894e-03,  5.7220e-05,  7.7782e-03,  ..., -2.6321e-03,
          6.6833e-02, -7.3395e-03],
        [ 1.6724e-02,  5.3940e-03,  1.9608e-03,  ..., -8.2626e-03,
         -1.4320e-02,  4.4464e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.4609, -2.0039,  1.1709,  ...,  0.4409, -2.3633, -2.8691]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 07:58:45 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of wife is wives
The plural form of family is families
The plural form of formula is formulae
The plural form of business is businesses
The plural form of variety is varieties
The plural form of success is successes
The plural form of energy is energies
The plural form of strategy is
2024-07-29 07:58:45 root INFO     [order_1_approx] starting weight calculation for The plural form of business is businesses
The plural form of variety is varieties
The plural form of family is families
The plural form of energy is energies
The plural form of success is successes
The plural form of strategy is strategies
The plural form of wife is wives
The plural form of formula is
2024-07-29 07:58:45 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 08:00:39 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.7896, -0.2651, -0.0859,  ..., -0.1904, -0.5151,  0.2312],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.1777, -1.2510,  3.7891,  ..., -0.7939, -2.3203,  0.0137],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.1362, -0.0271, -0.0102,  ..., -0.0344,  0.0016, -0.0137],
        [-0.0310,  0.1304,  0.0064,  ...,  0.0383,  0.0020,  0.0295],
        [ 0.0272, -0.0199,  0.0928,  ..., -0.0057,  0.0139,  0.0079],
        ...,
        [ 0.0096,  0.0092, -0.0007,  ...,  0.1339,  0.0004,  0.0266],
        [-0.0154,  0.0027, -0.0077,  ...,  0.0011,  0.1074, -0.0089],
        [-0.0052,  0.0256,  0.0003,  ...,  0.0051, -0.0148,  0.1287]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.3560, -1.3174,  3.7559,  ..., -0.1992, -1.7021,  0.1412]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 08:00:40 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of business is businesses
The plural form of variety is varieties
The plural form of family is families
The plural form of energy is energies
The plural form of success is successes
The plural form of strategy is strategies
The plural form of wife is wives
The plural form of formula is
2024-07-29 08:00:40 root INFO     total operator prediction time: 930.2174792289734 seconds
2024-07-29 08:00:40 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on meronyms - member
2024-07-29 08:00:40 root INFO     building operator meronyms - member
2024-07-29 08:00:40 root INFO     [order_1_approx] starting weight calculation for A crow is a member of a murder
A goose is a member of a gaggle
A spouse is a member of a couple
A member is a member of a club
A policeman is a member of a police
A wolf is a member of a pack
A player is a member of a team
A senator is a member of a
2024-07-29 08:00:40 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 08:02:33 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.6167,  0.1343, -0.5493,  ..., -0.4072, -0.9478, -0.1432],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.6484, -4.0078,  4.0859,  ..., -2.5527,  2.3711, -1.1514],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0227, -0.0012,  0.0050,  ..., -0.0115, -0.0017,  0.0050],
        [ 0.0039,  0.0249,  0.0030,  ..., -0.0051,  0.0045, -0.0048],
        [-0.0017, -0.0028,  0.0250,  ...,  0.0054, -0.0053,  0.0001],
        ...,
        [ 0.0060,  0.0034, -0.0047,  ...,  0.0258,  0.0004, -0.0037],
        [-0.0006, -0.0038,  0.0015,  ...,  0.0032,  0.0213, -0.0022],
        [ 0.0007, -0.0010, -0.0040,  ..., -0.0018,  0.0020,  0.0288]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.6250, -3.9414,  4.0820,  ..., -2.4629,  2.2852, -1.2314]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 08:02:34 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A crow is a member of a murder
A goose is a member of a gaggle
A spouse is a member of a couple
A member is a member of a club
A policeman is a member of a police
A wolf is a member of a pack
A player is a member of a team
A senator is a member of a
2024-07-29 08:02:34 root INFO     [order_1_approx] starting weight calculation for A member is a member of a club
A senator is a member of a senate
A crow is a member of a murder
A policeman is a member of a police
A spouse is a member of a couple
A wolf is a member of a pack
A player is a member of a team
A goose is a member of a
2024-07-29 08:02:35 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 08:04:29 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.9937, -0.2273, -0.0457,  ..., -0.3889, -0.5762, -0.2043],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.9102, -1.3174,  2.9375,  ...,  0.0957, -4.7148,  2.3828],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 4.8798e-02,  1.2711e-02,  1.1414e-02,  ..., -5.5542e-03,
          1.5717e-02,  1.0132e-02],
        [ 4.8218e-03,  4.4617e-02,  1.4496e-04,  ...,  5.9986e-04,
         -4.3678e-03, -8.2779e-03],
        [ 1.8280e-02,  1.1353e-02,  5.1025e-02,  ..., -4.5738e-03,
         -1.5850e-03,  2.5120e-03],
        ...,
        [ 9.1553e-04, -7.8888e-03, -3.1528e-03,  ...,  6.1340e-02,
          2.7580e-03, -1.5625e-02],
        [ 1.9821e-02,  7.7324e-03,  7.6065e-03,  ...,  2.7885e-03,
          4.7150e-02, -5.3406e-05],
        [ 7.4081e-03,  3.3855e-03, -3.0022e-03,  ..., -1.2848e-02,
          9.4032e-04,  4.6082e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.8340, -1.3428,  2.6426,  ...,  0.1696, -4.7148,  2.0840]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 08:04:30 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A member is a member of a club
A senator is a member of a senate
A crow is a member of a murder
A policeman is a member of a police
A spouse is a member of a couple
A wolf is a member of a pack
A player is a member of a team
A goose is a member of a
2024-07-29 08:04:30 root INFO     [order_1_approx] starting weight calculation for A member is a member of a club
A wolf is a member of a pack
A goose is a member of a gaggle
A senator is a member of a senate
A player is a member of a team
A crow is a member of a murder
A policeman is a member of a police
A spouse is a member of a
2024-07-29 08:04:30 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 08:06:26 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2727,  0.0837,  0.0651,  ...,  0.1731, -0.8647, -0.1240],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.2637, -3.5977,  2.4492,  ..., -1.7627, -1.3721,  2.1660],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0384, -0.0030,  0.0106,  ..., -0.0096,  0.0011,  0.0093],
        [-0.0061,  0.0305,  0.0058,  ..., -0.0034,  0.0069, -0.0055],
        [-0.0080, -0.0079,  0.0475,  ..., -0.0003,  0.0041,  0.0038],
        ...,
        [ 0.0126,  0.0006,  0.0006,  ...,  0.0494, -0.0067, -0.0070],
        [ 0.0025,  0.0048,  0.0003,  ...,  0.0126,  0.0376, -0.0104],
        [ 0.0066, -0.0033, -0.0152,  ..., -0.0101, -0.0099,  0.0378]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.3887, -3.5332,  2.6738,  ..., -1.6611, -1.4941,  1.8438]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 08:06:27 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A member is a member of a club
A wolf is a member of a pack
A goose is a member of a gaggle
A senator is a member of a senate
A player is a member of a team
A crow is a member of a murder
A policeman is a member of a police
A spouse is a member of a
2024-07-29 08:06:27 root INFO     [order_1_approx] starting weight calculation for A senator is a member of a senate
A crow is a member of a murder
A spouse is a member of a couple
A goose is a member of a gaggle
A policeman is a member of a police
A member is a member of a club
A player is a member of a team
A wolf is a member of a
2024-07-29 08:06:27 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 08:08:20 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.7158, -0.1654,  0.2239,  ..., -0.1328, -0.7773, -0.0981],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 6.5820, -4.3828,  1.5215,  ..., -2.2871, -1.9395,  0.6758],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0486, -0.0011, -0.0006,  ..., -0.0116,  0.0040,  0.0104],
        [ 0.0019,  0.0342, -0.0097,  ..., -0.0031,  0.0036, -0.0071],
        [ 0.0043,  0.0042,  0.0569,  ..., -0.0097, -0.0099,  0.0007],
        ...,
        [ 0.0096, -0.0085, -0.0031,  ...,  0.0734, -0.0107,  0.0006],
        [ 0.0057,  0.0105, -0.0015,  ..., -0.0023,  0.0429,  0.0051],
        [ 0.0050,  0.0136, -0.0079,  ..., -0.0101, -0.0100,  0.0396]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 6.4922, -4.2852,  1.5391,  ..., -2.5410, -2.2656,  0.9258]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 08:08:21 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A senator is a member of a senate
A crow is a member of a murder
A spouse is a member of a couple
A goose is a member of a gaggle
A policeman is a member of a police
A member is a member of a club
A player is a member of a team
A wolf is a member of a
2024-07-29 08:08:21 root INFO     [order_1_approx] starting weight calculation for A spouse is a member of a couple
A member is a member of a club
A player is a member of a team
A policeman is a member of a police
A goose is a member of a gaggle
A senator is a member of a senate
A wolf is a member of a pack
A crow is a member of a
2024-07-29 08:08:21 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 08:10:12 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2231, -0.3147,  0.6201,  ..., -0.5518, -0.7188, -0.0262],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 5.8594, -1.4336,  3.0820,  ...,  0.4258, -3.1680,  0.8198],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 2.8534e-02,  6.6223e-03,  1.0864e-02,  ...,  7.4387e-05,
          2.9240e-03,  6.3782e-03],
        [-1.4305e-02,  2.1423e-02,  2.9678e-03,  ...,  2.8488e-02,
          6.4802e-04, -4.2114e-03],
        [ 6.4850e-03, -5.0735e-03,  4.1931e-02,  ..., -2.8324e-03,
          4.7646e-03, -1.6365e-03],
        ...,
        [ 5.4626e-03, -7.5989e-03,  2.9602e-03,  ...,  5.5481e-02,
         -3.8967e-03, -2.1052e-04],
        [ 7.1068e-03,  1.5358e-02, -2.0782e-02,  ..., -1.7624e-03,
          3.3173e-02, -5.3177e-03],
        [-2.6932e-03,  2.3746e-03, -7.1869e-03,  ..., -3.3970e-03,
          7.9117e-03,  3.6285e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 6.0000, -1.2949,  3.0117,  ...,  0.5156, -3.6953,  1.0254]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 08:10:13 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A spouse is a member of a couple
A member is a member of a club
A player is a member of a team
A policeman is a member of a police
A goose is a member of a gaggle
A senator is a member of a senate
A wolf is a member of a pack
A crow is a member of a
2024-07-29 08:10:13 root INFO     [order_1_approx] starting weight calculation for A wolf is a member of a pack
A crow is a member of a murder
A spouse is a member of a couple
A goose is a member of a gaggle
A member is a member of a club
A senator is a member of a senate
A policeman is a member of a police
A player is a member of a
2024-07-29 08:10:14 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 08:12:05 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1666, -0.0406, -0.0255,  ..., -0.3059, -1.2354, -0.5352],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.6074, -7.9648,  1.4180,  ..., -1.8047,  0.2852, -4.7578],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0595, -0.0097,  0.0063,  ..., -0.0015, -0.0020,  0.0088],
        [ 0.0036,  0.0601, -0.0085,  ...,  0.0045,  0.0211, -0.0042],
        [ 0.0087,  0.0046,  0.0521,  ...,  0.0025, -0.0025,  0.0026],
        ...,
        [ 0.0022,  0.0113, -0.0104,  ...,  0.0784, -0.0039,  0.0011],
        [ 0.0098, -0.0051,  0.0025,  ..., -0.0027,  0.0689, -0.0111],
        [ 0.0099,  0.0080, -0.0129,  ...,  0.0016,  0.0065,  0.0506]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.7031, -7.7188,  1.9805,  ..., -1.3730,  0.6870, -4.3203]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 08:12:06 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A wolf is a member of a pack
A crow is a member of a murder
A spouse is a member of a couple
A goose is a member of a gaggle
A member is a member of a club
A senator is a member of a senate
A policeman is a member of a police
A player is a member of a
2024-07-29 08:12:06 root INFO     [order_1_approx] starting weight calculation for A policeman is a member of a police
A senator is a member of a senate
A wolf is a member of a pack
A crow is a member of a murder
A player is a member of a team
A goose is a member of a gaggle
A spouse is a member of a couple
A member is a member of a
2024-07-29 08:12:06 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 08:13:57 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 1.1895, -0.3311, -0.2727,  ..., -0.0252,  0.6680, -0.4531],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.7383, -3.0762,  3.5176,  ..., -3.1348,  0.3740, -0.6797],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 1.1086e-02, -8.7166e-04,  7.7820e-04,  ..., -2.9068e-03,
          4.9973e-04, -4.2915e-04],
        [-1.3714e-03,  1.0010e-02,  1.1721e-03,  ..., -6.7215e-03,
          3.4027e-03, -1.6365e-03],
        [-1.0386e-03, -1.6899e-03,  1.0719e-02,  ...,  4.4489e-04,
         -1.5211e-04, -8.0681e-04],
        ...,
        [ 6.8474e-04,  1.9789e-04,  1.7023e-03,  ...,  1.4755e-02,
         -1.2913e-03,  1.9150e-03],
        [ 2.1801e-03, -8.4305e-04,  4.3344e-04,  ...,  4.1809e-03,
          1.1658e-02, -5.0068e-04],
        [ 3.0956e-03, -5.5580e-03,  2.5482e-03,  ..., -3.1590e-06,
         -3.7766e-03,  9.6893e-03]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.8379, -3.0195,  3.5547,  ..., -3.1113,  0.3264, -0.6191]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 08:13:58 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A policeman is a member of a police
A senator is a member of a senate
A wolf is a member of a pack
A crow is a member of a murder
A player is a member of a team
A goose is a member of a gaggle
A spouse is a member of a couple
A member is a member of a
2024-07-29 08:13:58 root INFO     [order_1_approx] starting weight calculation for A member is a member of a club
A crow is a member of a murder
A player is a member of a team
A spouse is a member of a couple
A wolf is a member of a pack
A goose is a member of a gaggle
A senator is a member of a senate
A policeman is a member of a
2024-07-29 08:13:58 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 08:15:51 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.6128,  0.2988, -0.0398,  ..., -0.7471, -1.3906, -0.8545],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.0039, -6.8672,  3.8477,  ..., -1.0898,  1.0127, -6.6055],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 2.2690e-02,  2.4128e-03,  3.1147e-03,  ..., -1.5869e-03,
          6.4774e-03,  2.8515e-03],
        [ 6.4182e-04,  2.2522e-02,  1.9493e-03,  ...,  7.5245e-04,
         -2.8849e-04, -2.6970e-03],
        [ 3.0441e-03, -2.7618e-03,  2.3621e-02,  ...,  9.5367e-06,
          2.9755e-04,  3.8147e-06],
        ...,
        [ 3.3665e-04,  2.1887e-04, -2.2469e-03,  ...,  3.0350e-02,
          1.1339e-03, -1.4639e-03],
        [ 5.9433e-03,  6.9809e-03, -8.9455e-04,  ..., -2.5043e-03,
          2.2354e-02, -9.0408e-03],
        [ 2.7981e-03, -1.5163e-03, -4.0283e-03,  ..., -2.2507e-03,
         -4.9515e-03,  2.4261e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.9961, -6.7852,  3.9785,  ..., -1.0850,  0.9878, -6.4922]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 08:15:51 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A member is a member of a club
A crow is a member of a murder
A player is a member of a team
A spouse is a member of a couple
A wolf is a member of a pack
A goose is a member of a gaggle
A senator is a member of a senate
A policeman is a member of a
2024-07-29 08:15:51 root INFO     total operator prediction time: 911.3054351806641 seconds
2024-07-29 08:15:51 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on antonyms - binary
2024-07-29 08:15:51 root INFO     building operator antonyms - binary
2024-07-29 08:15:52 root INFO     [order_1_approx] starting weight calculation for The opposite of inhale is exhale
The opposite of toward is away
The opposite of uphill is downhill
The opposite of top is bottom
The opposite of over is under
The opposite of below is above
The opposite of input is output
The opposite of off is
2024-07-29 08:15:52 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 08:17:47 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2930, -0.4126, -0.5439,  ..., -0.3413, -0.0671, -0.8506],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-2.1191, -3.9062, -0.5898,  ..., -0.0742,  0.8633, -1.6719],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.1268,  0.0274, -0.0011,  ..., -0.0023,  0.0050, -0.0007],
        [-0.0007,  0.1075, -0.0132,  ...,  0.0088,  0.0027,  0.0214],
        [-0.0084,  0.0301,  0.1056,  ..., -0.0179,  0.0027, -0.0081],
        ...,
        [ 0.0008,  0.0021, -0.0367,  ...,  0.1296, -0.0200, -0.0160],
        [-0.0106, -0.0118, -0.0099,  ..., -0.0198,  0.0858, -0.0060],
        [ 0.0062,  0.0205, -0.0229,  ..., -0.0088, -0.0019,  0.1324]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.5469, -4.3203, -0.9414,  ...,  0.1838,  0.8462, -1.6836]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 08:17:48 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of inhale is exhale
The opposite of toward is away
The opposite of uphill is downhill
The opposite of top is bottom
The opposite of over is under
The opposite of below is above
The opposite of input is output
The opposite of off is
2024-07-29 08:17:48 root INFO     [order_1_approx] starting weight calculation for The opposite of toward is away
The opposite of uphill is downhill
The opposite of inhale is exhale
The opposite of off is on
The opposite of top is bottom
The opposite of below is above
The opposite of over is under
The opposite of input is
2024-07-29 08:17:49 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 08:19:45 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.3372, -0.5864, -0.0220,  ...,  0.8662, -0.8506, -0.1356],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.8291, -1.9541, -0.8760,  ..., -0.8965,  0.9429, -2.3340],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 9.9609e-02,  2.4384e-02, -1.8082e-03,  ..., -2.2812e-03,
          2.6215e-02,  1.0338e-02],
        [-2.7908e-02,  8.9050e-02, -7.2479e-05,  ...,  6.2561e-03,
         -2.3499e-03,  5.0735e-04],
        [ 7.9651e-03,  1.2314e-02,  6.0822e-02,  ..., -1.9180e-02,
         -2.2888e-04, -1.9592e-02],
        ...,
        [ 2.0828e-03,  1.5259e-02, -1.6953e-02,  ...,  1.0614e-01,
         -8.5754e-03, -1.3969e-02],
        [-2.5757e-02, -3.4637e-02, -1.3664e-02,  ...,  1.6308e-03,
          9.1797e-02,  6.9275e-03],
        [-1.6342e-02,  1.9958e-02, -1.3138e-02,  ...,  3.2997e-03,
          1.9836e-04,  9.3811e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.4590, -1.6953, -1.0195,  ..., -0.6558,  1.4199, -1.8408]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 08:19:46 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of toward is away
The opposite of uphill is downhill
The opposite of inhale is exhale
The opposite of off is on
The opposite of top is bottom
The opposite of below is above
The opposite of over is under
The opposite of input is
2024-07-29 08:19:46 root INFO     [order_1_approx] starting weight calculation for The opposite of below is above
The opposite of over is under
The opposite of inhale is exhale
The opposite of toward is away
The opposite of top is bottom
The opposite of input is output
The opposite of off is on
The opposite of uphill is
2024-07-29 08:19:46 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 08:21:41 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1039, -0.2903, -0.6401,  ..., -0.8057, -0.5063, -1.2441],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.3772, -0.7012,  0.5859,  ..., -1.6777, -3.0098, -1.1797],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0736, -0.0144,  0.0045,  ...,  0.0187,  0.0063,  0.0012],
        [ 0.0083,  0.0550, -0.0089,  ...,  0.0105,  0.0104, -0.0150],
        [-0.0058,  0.0120,  0.0386,  ..., -0.0039,  0.0002,  0.0077],
        ...,
        [-0.0057,  0.0025, -0.0002,  ...,  0.0523, -0.0070, -0.0006],
        [ 0.0001, -0.0008,  0.0014,  ..., -0.0026,  0.0539,  0.0017],
        [ 0.0003,  0.0189,  0.0007,  ..., -0.0112, -0.0012,  0.0357]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.4678, -0.6616,  0.6226,  ..., -1.8701, -3.0645, -0.9844]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 08:21:42 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of below is above
The opposite of over is under
The opposite of inhale is exhale
The opposite of toward is away
The opposite of top is bottom
The opposite of input is output
The opposite of off is on
The opposite of uphill is
2024-07-29 08:21:42 root INFO     [order_1_approx] starting weight calculation for The opposite of off is on
The opposite of below is above
The opposite of inhale is exhale
The opposite of over is under
The opposite of uphill is downhill
The opposite of toward is away
The opposite of input is output
The opposite of top is
2024-07-29 08:21:42 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 08:23:38 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2030,  0.2910,  0.2717,  ..., -0.0964,  0.0302, -0.8428],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.2266, -2.0293, -0.4624,  ..., -2.9062,  4.4688, -3.5234],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 8.8318e-02, -1.4477e-03, -6.3972e-03,  ...,  1.2512e-03,
          2.7786e-02,  1.3809e-02],
        [ 1.6113e-02,  7.1777e-02, -1.6479e-02,  ...,  2.7679e-02,
          1.9897e-02, -1.0399e-02],
        [-8.3923e-05, -8.4991e-03,  8.5144e-02,  ..., -1.5717e-02,
         -9.8190e-03,  9.0027e-03],
        ...,
        [-5.5237e-03,  1.2650e-02,  1.7033e-03,  ...,  1.0205e-01,
          1.0849e-02, -7.4615e-03],
        [-1.9440e-02, -8.1863e-03,  2.0552e-04,  ...,  9.3231e-03,
          7.2327e-02, -1.0681e-03],
        [ 1.5701e-02, -1.8372e-02, -5.2910e-03,  ..., -5.5695e-03,
          4.4479e-03,  6.8665e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.7324, -2.1934, -0.3179,  ..., -2.7441,  3.4707, -3.1543]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 08:23:39 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of off is on
The opposite of below is above
The opposite of inhale is exhale
The opposite of over is under
The opposite of uphill is downhill
The opposite of toward is away
The opposite of input is output
The opposite of top is
2024-07-29 08:23:39 root INFO     [order_1_approx] starting weight calculation for The opposite of top is bottom
The opposite of off is on
The opposite of uphill is downhill
The opposite of below is above
The opposite of over is under
The opposite of input is output
The opposite of inhale is exhale
The opposite of toward is
2024-07-29 08:23:39 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 08:25:35 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.5557, -0.1798, -0.9150,  ..., -0.1777,  0.1211, -0.2124],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.4648, -3.4727,  1.3135,  ..., -1.6914, -0.5039, -3.9707],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.1058,  0.0104,  0.0076,  ...,  0.0113,  0.0285, -0.0034],
        [-0.0048,  0.0850, -0.0259,  ...,  0.0187,  0.0184, -0.0092],
        [-0.0208,  0.0031,  0.0586,  ..., -0.0152, -0.0166,  0.0106],
        ...,
        [ 0.0057,  0.0147, -0.0088,  ...,  0.0985,  0.0013, -0.0067],
        [-0.0237, -0.0227,  0.0059,  ..., -0.0035,  0.0560, -0.0070],
        [ 0.0107, -0.0177, -0.0056,  ...,  0.0127,  0.0257,  0.0764]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.9839, -3.7383,  1.4238,  ..., -1.5342, -0.4460, -3.8047]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 08:25:36 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of top is bottom
The opposite of off is on
The opposite of uphill is downhill
The opposite of below is above
The opposite of over is under
The opposite of input is output
The opposite of inhale is exhale
The opposite of toward is
2024-07-29 08:25:36 root INFO     [order_1_approx] starting weight calculation for The opposite of uphill is downhill
The opposite of input is output
The opposite of top is bottom
The opposite of over is under
The opposite of inhale is exhale
The opposite of toward is away
The opposite of off is on
The opposite of below is
2024-07-29 08:25:36 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 08:27:32 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1641, -0.7227, -0.0204,  ..., -0.1147, -0.2048, -0.5586],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.6602, -1.6484,  1.4414,  ..., -0.4290,  2.8730, -0.1387],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 8.2336e-02, -5.9052e-03,  1.6083e-02,  ...,  2.2400e-02,
          1.4229e-03,  1.2497e-02],
        [ 9.7809e-03,  6.2042e-02, -4.7073e-03,  ...,  4.3411e-03,
          1.5457e-02,  3.6507e-03],
        [ 1.4725e-03, -8.1406e-03,  5.1147e-02,  ..., -2.5543e-02,
          4.5433e-03,  1.5900e-02],
        ...,
        [ 8.4076e-03,  9.9335e-03, -9.1743e-04,  ...,  7.1228e-02,
         -2.1458e-05, -1.5259e-03],
        [-8.6670e-03, -1.9547e-02,  6.2485e-03,  ..., -1.1017e-02,
          5.1392e-02, -7.4005e-04],
        [ 9.0790e-04, -1.2260e-02,  8.6212e-04,  ..., -5.2261e-04,
          4.1771e-03,  6.9946e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.7441, -1.7695,  1.4922,  ..., -0.5146,  2.2070, -0.0906]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 08:27:33 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of uphill is downhill
The opposite of input is output
The opposite of top is bottom
The opposite of over is under
The opposite of inhale is exhale
The opposite of toward is away
The opposite of off is on
The opposite of below is
2024-07-29 08:27:33 root INFO     [order_1_approx] starting weight calculation for The opposite of over is under
The opposite of uphill is downhill
The opposite of below is above
The opposite of toward is away
The opposite of off is on
The opposite of input is output
The opposite of top is bottom
The opposite of inhale is
2024-07-29 08:27:33 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 08:29:29 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1216, -0.2212, -1.6445,  ..., -0.5010, -0.0803, -0.3691],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.0215, -2.1172,  2.2090,  ..., -2.1367,  0.6895,  1.5723],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 7.1533e-02, -1.2520e-02,  6.0196e-03,  ...,  2.8519e-02,
          2.0477e-02,  8.2932e-03],
        [ 6.3400e-03,  5.3894e-02,  4.8943e-03,  ...,  1.3245e-02,
          1.1032e-02, -6.1874e-03],
        [ 1.6613e-03, -9.5825e-03,  4.0283e-02,  ..., -1.3855e-02,
          2.4109e-03, -1.3565e-02],
        ...,
        [ 5.3101e-03,  7.7515e-03,  3.3760e-04,  ...,  4.7638e-02,
          2.8305e-03,  5.1422e-03],
        [-5.0430e-03,  4.1084e-03, -2.3003e-03,  ..., -1.9073e-05,
          4.3793e-02,  1.1635e-03],
        [-2.8419e-03,  1.2207e-04, -7.3891e-03,  ..., -7.7667e-03,
         -6.0883e-03,  4.1443e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.0400, -2.4062,  2.2266,  ..., -2.1543,  0.6626,  1.6094]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 08:29:30 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of over is under
The opposite of uphill is downhill
The opposite of below is above
The opposite of toward is away
The opposite of off is on
The opposite of input is output
The opposite of top is bottom
The opposite of inhale is
2024-07-29 08:29:30 root INFO     [order_1_approx] starting weight calculation for The opposite of input is output
The opposite of uphill is downhill
The opposite of toward is away
The opposite of below is above
The opposite of inhale is exhale
The opposite of top is bottom
The opposite of off is on
The opposite of over is
2024-07-29 08:29:30 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 08:31:26 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2964,  0.2581, -0.6060,  ..., -0.4458,  0.1807, -0.0293],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.4727, -1.8555,  1.2275,  ..., -1.8008,  2.3164, -0.2256],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 1.1005e-01, -8.8577e-03, -6.7329e-03,  ..., -8.0566e-03,
         -2.3594e-03,  3.5877e-03],
        [ 1.4954e-03,  8.1848e-02, -3.6072e-02,  ...,  1.5457e-02,
          1.8616e-02,  8.9722e-03],
        [ 9.5749e-03, -1.0513e-02,  8.7341e-02,  ..., -3.5919e-02,
         -4.3221e-03, -6.7062e-03],
        ...,
        [ 1.0223e-02,  2.3224e-02, -1.8539e-03,  ...,  1.1133e-01,
         -3.4332e-05, -9.3079e-03],
        [-1.2817e-02, -1.8631e-02,  3.5706e-02,  ..., -1.7456e-02,
          8.3740e-02, -1.8692e-03],
        [ 4.7684e-03, -9.4757e-03,  5.1498e-05,  ..., -8.8882e-03,
         -1.0361e-02,  8.9661e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.4980, -2.6484,  0.9365,  ..., -2.0859,  1.6270, -0.4414]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 08:31:27 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of input is output
The opposite of uphill is downhill
The opposite of toward is away
The opposite of below is above
The opposite of inhale is exhale
The opposite of top is bottom
The opposite of off is on
The opposite of over is
2024-07-29 08:31:27 root INFO     total operator prediction time: 935.3767926692963 seconds
2024-07-29 08:31:27 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on hyponyms - misc
2024-07-29 08:31:27 root INFO     building operator hyponyms - misc
2024-07-29 08:31:27 root INFO     [order_1_approx] starting weight calculation for A more specific term for a tool is rake
A more specific term for a book is paperback
A more specific term for a cutlery is knife
A more specific term for a boat is ferry
A more specific term for a weekday is monday
A more specific term for a jewelry is bracelet
A more specific term for a spice is pepper
A more specific term for a color is
2024-07-29 08:31:27 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 08:33:22 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.6924, -1.4883, -0.0121,  ...,  0.4829, -0.2354, -0.2935],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-2.5195, -3.5508,  0.4302,  ...,  1.8193, -2.9277,  0.0269],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0568,  0.0093,  0.0107,  ...,  0.0095, -0.0004,  0.0219],
        [ 0.0105,  0.0539,  0.0008,  ..., -0.0077,  0.0138, -0.0112],
        [-0.0103, -0.0075,  0.0498,  ..., -0.0084, -0.0037, -0.0090],
        ...,
        [ 0.0141,  0.0010,  0.0030,  ...,  0.0579,  0.0003,  0.0007],
        [-0.0053, -0.0026, -0.0046,  ..., -0.0058,  0.0474, -0.0047],
        [-0.0014, -0.0001, -0.0018,  ...,  0.0015,  0.0011,  0.0560]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-2.4570, -3.5508,  0.2607,  ...,  1.8906, -3.0898,  0.0361]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 08:33:23 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more specific term for a tool is rake
A more specific term for a book is paperback
A more specific term for a cutlery is knife
A more specific term for a boat is ferry
A more specific term for a weekday is monday
A more specific term for a jewelry is bracelet
A more specific term for a spice is pepper
A more specific term for a color is
2024-07-29 08:33:24 root INFO     [order_1_approx] starting weight calculation for A more specific term for a book is paperback
A more specific term for a color is white
A more specific term for a jewelry is bracelet
A more specific term for a weekday is monday
A more specific term for a tool is rake
A more specific term for a spice is pepper
A more specific term for a cutlery is knife
A more specific term for a boat is
2024-07-29 08:33:24 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 08:35:21 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3911, -0.7695,  0.0847,  ..., -0.2642, -0.6411,  0.2241],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.1797, -5.7969,  0.5547,  ...,  0.8389, -0.2217, -0.0400],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0605,  0.0020,  0.0078,  ..., -0.0006,  0.0055, -0.0011],
        [ 0.0018,  0.0505, -0.0027,  ..., -0.0066,  0.0051, -0.0070],
        [ 0.0043, -0.0077,  0.0620,  ...,  0.0064, -0.0163,  0.0027],
        ...,
        [ 0.0136,  0.0107, -0.0105,  ...,  0.0510, -0.0055, -0.0031],
        [-0.0132,  0.0041,  0.0009,  ..., -0.0044,  0.0605, -0.0054],
        [ 0.0076,  0.0047, -0.0028,  ..., -0.0077, -0.0081,  0.0538]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.1855, -5.5820,  0.4067,  ...,  0.9893, -0.2291,  0.1036]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 08:35:22 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more specific term for a book is paperback
A more specific term for a color is white
A more specific term for a jewelry is bracelet
A more specific term for a weekday is monday
A more specific term for a tool is rake
A more specific term for a spice is pepper
A more specific term for a cutlery is knife
A more specific term for a boat is
2024-07-29 08:35:22 root INFO     [order_1_approx] starting weight calculation for A more specific term for a color is white
A more specific term for a spice is pepper
A more specific term for a tool is rake
A more specific term for a boat is ferry
A more specific term for a weekday is monday
A more specific term for a book is paperback
A more specific term for a jewelry is bracelet
A more specific term for a cutlery is
2024-07-29 08:35:22 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 08:37:16 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2512, -0.1676, -0.3809,  ..., -0.5264, -0.9580, -0.5059],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.5088, -4.4062, -3.5371,  ..., -0.2344, -1.3252, -0.9946],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0630,  0.0020,  0.0054,  ...,  0.0007, -0.0012, -0.0126],
        [ 0.0117,  0.0479,  0.0035,  ..., -0.0036,  0.0112, -0.0213],
        [-0.0074, -0.0024,  0.0536,  ..., -0.0013, -0.0098, -0.0029],
        ...,
        [ 0.0234,  0.0040, -0.0072,  ...,  0.0539, -0.0075,  0.0081],
        [ 0.0024,  0.0086, -0.0086,  ..., -0.0122,  0.0664,  0.0036],
        [ 0.0040,  0.0089,  0.0017,  ..., -0.0068,  0.0055,  0.0407]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.5825, -4.4375, -3.3848,  ..., -0.0978, -1.3828, -1.0166]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 08:37:17 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more specific term for a color is white
A more specific term for a spice is pepper
A more specific term for a tool is rake
A more specific term for a boat is ferry
A more specific term for a weekday is monday
A more specific term for a book is paperback
A more specific term for a jewelry is bracelet
A more specific term for a cutlery is
2024-07-29 08:37:17 root INFO     [order_1_approx] starting weight calculation for A more specific term for a tool is rake
A more specific term for a spice is pepper
A more specific term for a weekday is monday
A more specific term for a cutlery is knife
A more specific term for a boat is ferry
A more specific term for a color is white
A more specific term for a jewelry is bracelet
A more specific term for a book is
2024-07-29 08:37:17 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 08:39:12 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0742, -0.9888, -0.0042,  ...,  0.1213, -0.1122,  0.0909],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.4121, -6.0781,  2.1816,  ...,  1.1543, -2.0078, -2.8086],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0812,  0.0074,  0.0109,  ...,  0.0021, -0.0061,  0.0032],
        [-0.0074,  0.0597,  0.0006,  ..., -0.0024,  0.0172,  0.0014],
        [-0.0219, -0.0108,  0.0873,  ...,  0.0020, -0.0258, -0.0037],
        ...,
        [ 0.0244,  0.0079, -0.0100,  ...,  0.0883, -0.0085, -0.0031],
        [-0.0035,  0.0034, -0.0027,  ..., -0.0016,  0.0590, -0.0005],
        [ 0.0017, -0.0094, -0.0027,  ..., -0.0034,  0.0153,  0.0724]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.0625, -5.8516,  2.0781,  ...,  1.4111, -1.9561, -2.2773]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 08:39:13 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more specific term for a tool is rake
A more specific term for a spice is pepper
A more specific term for a weekday is monday
A more specific term for a cutlery is knife
A more specific term for a boat is ferry
A more specific term for a color is white
A more specific term for a jewelry is bracelet
A more specific term for a book is
2024-07-29 08:39:13 root INFO     [order_1_approx] starting weight calculation for A more specific term for a tool is rake
A more specific term for a weekday is monday
A more specific term for a spice is pepper
A more specific term for a cutlery is knife
A more specific term for a book is paperback
A more specific term for a color is white
A more specific term for a boat is ferry
A more specific term for a jewelry is
2024-07-29 08:39:13 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 08:41:10 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0179, -0.5161, -0.0047,  ..., -0.6113, -0.9834,  0.0688],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.4883, -3.2578, -5.4453,  ...,  0.5210, -2.7480,  1.5488],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0291, -0.0023,  0.0030,  ..., -0.0065, -0.0037,  0.0071],
        [ 0.0024,  0.0283, -0.0030,  ..., -0.0001,  0.0044, -0.0037],
        [ 0.0027,  0.0005,  0.0207,  ..., -0.0048,  0.0014,  0.0024],
        ...,
        [ 0.0035,  0.0022, -0.0044,  ...,  0.0321, -0.0012, -0.0001],
        [-0.0015, -0.0006,  0.0021,  ..., -0.0016,  0.0267,  0.0036],
        [-0.0016,  0.0076,  0.0037,  ..., -0.0026, -0.0088,  0.0228]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.4375, -3.2422, -5.2930,  ...,  0.6807, -2.8516,  1.4648]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 08:41:10 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more specific term for a tool is rake
A more specific term for a weekday is monday
A more specific term for a spice is pepper
A more specific term for a cutlery is knife
A more specific term for a book is paperback
A more specific term for a color is white
A more specific term for a boat is ferry
A more specific term for a jewelry is
2024-07-29 08:41:11 root INFO     [order_1_approx] starting weight calculation for A more specific term for a tool is rake
A more specific term for a cutlery is knife
A more specific term for a color is white
A more specific term for a boat is ferry
A more specific term for a weekday is monday
A more specific term for a book is paperback
A more specific term for a jewelry is bracelet
A more specific term for a spice is
2024-07-29 08:41:11 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 08:43:05 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0511, -0.1428, -0.0087,  ..., -0.1321, -0.0912, -0.8921],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.5957, -4.1758, -1.0820,  ..., -1.3574, -2.4434, -5.6758],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0615, -0.0036,  0.0059,  ..., -0.0064,  0.0064,  0.0065],
        [ 0.0185,  0.0431,  0.0022,  ...,  0.0004,  0.0108, -0.0033],
        [-0.0068, -0.0097,  0.0555,  ..., -0.0029, -0.0072,  0.0053],
        ...,
        [ 0.0177,  0.0081, -0.0061,  ...,  0.0715, -0.0017, -0.0067],
        [ 0.0155,  0.0119,  0.0095,  ..., -0.0022,  0.0650,  0.0153],
        [ 0.0144, -0.0118, -0.0020,  ..., -0.0160,  0.0066,  0.0502]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.4941, -3.9043, -1.4277,  ..., -1.1055, -2.7207, -5.2266]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 08:43:06 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more specific term for a tool is rake
A more specific term for a cutlery is knife
A more specific term for a color is white
A more specific term for a boat is ferry
A more specific term for a weekday is monday
A more specific term for a book is paperback
A more specific term for a jewelry is bracelet
A more specific term for a spice is
2024-07-29 08:43:06 root INFO     [order_1_approx] starting weight calculation for A more specific term for a spice is pepper
A more specific term for a book is paperback
A more specific term for a boat is ferry
A more specific term for a color is white
A more specific term for a cutlery is knife
A more specific term for a jewelry is bracelet
A more specific term for a tool is rake
A more specific term for a weekday is
2024-07-29 08:43:06 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 08:45:02 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2881, -0.2399,  0.1931,  ..., -0.3877, -0.6655, -0.3262],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 5.6094, -3.6641,  2.9844,  ...,  0.5596, -0.9961, -1.9355],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 7.9895e-02, -3.0785e-03,  1.0063e-02,  ...,  9.9792e-03,
         -7.0076e-03,  7.7095e-03],
        [-3.9444e-03,  5.5725e-02,  5.5695e-04,  ...,  3.9215e-03,
          1.0880e-02, -9.1629e-03],
        [-4.9591e-04, -5.6076e-03,  6.9458e-02,  ...,  6.7673e-03,
         -4.8180e-03,  1.8778e-03],
        ...,
        [ 5.2567e-03,  1.3321e-02, -3.9024e-03,  ...,  6.9214e-02,
         -7.3814e-03, -8.4686e-04],
        [-9.6741e-03, -1.3361e-03, -1.3947e-02,  ...,  5.8479e-03,
          6.1707e-02,  9.3613e-03],
        [ 3.6144e-03, -1.5259e-05, -1.2455e-03,  ..., -1.0681e-04,
         -1.3489e-02,  6.5063e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 5.5156, -3.5176,  2.6914,  ...,  0.7451, -1.1719, -1.7881]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 08:45:03 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more specific term for a spice is pepper
A more specific term for a book is paperback
A more specific term for a boat is ferry
A more specific term for a color is white
A more specific term for a cutlery is knife
A more specific term for a jewelry is bracelet
A more specific term for a tool is rake
A more specific term for a weekday is
2024-07-29 08:45:03 root INFO     [order_1_approx] starting weight calculation for A more specific term for a boat is ferry
A more specific term for a book is paperback
A more specific term for a color is white
A more specific term for a cutlery is knife
A more specific term for a weekday is monday
A more specific term for a spice is pepper
A more specific term for a jewelry is bracelet
A more specific term for a tool is
2024-07-29 08:45:03 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 08:46:59 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0627, -1.0488,  0.1049,  ...,  0.3447, -0.1772, -0.1189],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.3784, -4.3438, -0.9385,  ...,  2.2578, -4.1172,  0.4004],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0645, -0.0050,  0.0081,  ..., -0.0020, -0.0053,  0.0060],
        [ 0.0144,  0.0511, -0.0050,  ..., -0.0003,  0.0061, -0.0127],
        [-0.0233, -0.0038,  0.0572,  ..., -0.0001,  0.0057, -0.0038],
        ...,
        [ 0.0174,  0.0089, -0.0070,  ...,  0.0805, -0.0070,  0.0092],
        [ 0.0053,  0.0034, -0.0051,  ..., -0.0076,  0.0670, -0.0017],
        [ 0.0112,  0.0238, -0.0012,  ..., -0.0013,  0.0115,  0.0529]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.5962, -4.5273, -0.9932,  ...,  2.5430, -3.7617,  0.2700]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 08:47:00 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more specific term for a boat is ferry
A more specific term for a book is paperback
A more specific term for a color is white
A more specific term for a cutlery is knife
A more specific term for a weekday is monday
A more specific term for a spice is pepper
A more specific term for a jewelry is bracelet
A more specific term for a tool is
2024-07-29 08:47:00 root INFO     total operator prediction time: 932.948974609375 seconds
2024-07-29 08:47:00 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on hypernyms - animals
2024-07-29 08:47:00 root INFO     building operator hypernyms - animals
2024-07-29 08:47:00 root INFO     [order_1_approx] starting weight calculation for The duck falls into the category of fowl
The rattlesnake falls into the category of snake
The tyrannosaurus falls into the category of dinosaur
The tiger falls into the category of feline
The turkey falls into the category of fowl
The mamba falls into the category of snake
The gorilla falls into the category of primate
The butterfly falls into the category of
2024-07-29 08:47:00 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 08:48:55 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4045, -0.3308,  0.3611,  ...,  0.2321, -0.5518,  0.1874],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.3047, -3.3945,  2.9766,  ..., -1.8682, -1.7764, -2.2109],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0310, -0.0052, -0.0021,  ..., -0.0115,  0.0007,  0.0037],
        [ 0.0055,  0.0135,  0.0002,  ..., -0.0004,  0.0089,  0.0043],
        [ 0.0055,  0.0026,  0.0240,  ...,  0.0086, -0.0052, -0.0018],
        ...,
        [ 0.0066,  0.0135, -0.0035,  ...,  0.0297, -0.0016,  0.0013],
        [-0.0019,  0.0051, -0.0109,  ..., -0.0016,  0.0260, -0.0024],
        [-0.0112,  0.0046, -0.0022,  ..., -0.0010,  0.0005,  0.0314]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.3047, -3.2480,  2.8008,  ..., -1.8418, -2.0020, -1.9199]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 08:48:56 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The duck falls into the category of fowl
The rattlesnake falls into the category of snake
The tyrannosaurus falls into the category of dinosaur
The tiger falls into the category of feline
The turkey falls into the category of fowl
The mamba falls into the category of snake
The gorilla falls into the category of primate
The butterfly falls into the category of
2024-07-29 08:48:56 root INFO     [order_1_approx] starting weight calculation for The duck falls into the category of fowl
The butterfly falls into the category of insect
The mamba falls into the category of snake
The tyrannosaurus falls into the category of dinosaur
The gorilla falls into the category of primate
The tiger falls into the category of feline
The rattlesnake falls into the category of snake
The turkey falls into the category of
2024-07-29 08:48:56 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 08:50:52 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.8218, -0.8135, -0.3423,  ...,  0.5137, -0.3477,  0.4727],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.9199, -4.4414,  3.3281,  ..., -1.4414, -7.0781,  1.8145],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0359, -0.0102,  0.0030,  ..., -0.0076, -0.0120, -0.0079],
        [ 0.0010,  0.0383, -0.0001,  ...,  0.0012,  0.0065, -0.0029],
        [ 0.0016, -0.0054,  0.0341,  ...,  0.0074, -0.0048,  0.0041],
        ...,
        [ 0.0183, -0.0024,  0.0100,  ...,  0.0401, -0.0095, -0.0075],
        [ 0.0090,  0.0066, -0.0113,  ...,  0.0140,  0.0413, -0.0029],
        [-0.0180, -0.0030, -0.0027,  ...,  0.0005, -0.0072,  0.0382]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.0566, -4.2188,  3.0391,  ..., -1.4736, -7.1484,  1.9873]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 08:50:53 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The duck falls into the category of fowl
The butterfly falls into the category of insect
The mamba falls into the category of snake
The tyrannosaurus falls into the category of dinosaur
The gorilla falls into the category of primate
The tiger falls into the category of feline
The rattlesnake falls into the category of snake
The turkey falls into the category of
2024-07-29 08:50:53 root INFO     [order_1_approx] starting weight calculation for The tiger falls into the category of feline
The butterfly falls into the category of insect
The gorilla falls into the category of primate
The mamba falls into the category of snake
The duck falls into the category of fowl
The tyrannosaurus falls into the category of dinosaur
The turkey falls into the category of fowl
The rattlesnake falls into the category of
2024-07-29 08:50:53 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 08:52:49 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4438, -0.3789, -0.2524,  ..., -0.0554, -0.5732, -0.2930],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.6201, -4.5469,  0.3403,  ..., -2.5098,  0.2437, -0.9199],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 2.6001e-02, -1.0246e-02,  1.9741e-04,  ..., -8.8959e-03,
          5.2528e-03, -2.5711e-03],
        [-9.2773e-03,  2.1149e-02,  9.2125e-04,  ...,  6.3400e-03,
          1.4168e-02, -1.5984e-03],
        [-9.8228e-04, -1.3485e-03,  3.1830e-02,  ..., -9.3689e-03,
         -5.1880e-03,  4.8485e-03],
        ...,
        [ 1.3870e-02,  4.1962e-05,  1.5020e-03,  ...,  3.3844e-02,
          3.7575e-03, -1.1505e-02],
        [ 6.9656e-03, -2.7542e-03,  4.6730e-05,  ...,  4.1924e-03,
          2.5177e-02, -3.5591e-03],
        [-3.4218e-03,  2.5883e-03,  4.1580e-03,  ..., -6.9618e-04,
          6.6376e-03,  2.9526e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.7783, -4.4922,  0.2791,  ..., -2.4492,  0.0264, -0.8247]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 08:52:50 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The tiger falls into the category of feline
The butterfly falls into the category of insect
The gorilla falls into the category of primate
The mamba falls into the category of snake
The duck falls into the category of fowl
The tyrannosaurus falls into the category of dinosaur
The turkey falls into the category of fowl
The rattlesnake falls into the category of
2024-07-29 08:52:50 root INFO     [order_1_approx] starting weight calculation for The tyrannosaurus falls into the category of dinosaur
The duck falls into the category of fowl
The butterfly falls into the category of insect
The turkey falls into the category of fowl
The rattlesnake falls into the category of snake
The gorilla falls into the category of primate
The mamba falls into the category of snake
The tiger falls into the category of
2024-07-29 08:52:50 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 08:54:45 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4468, -0.6416,  0.2405,  ...,  0.4944, -0.4548, -0.3921],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.8867, -7.1836, -0.5293,  ..., -3.3574, -6.4531,  0.1064],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0310, -0.0094, -0.0071,  ..., -0.0068,  0.0026, -0.0085],
        [-0.0012,  0.0349,  0.0029,  ..., -0.0126,  0.0120,  0.0012],
        [-0.0070,  0.0034,  0.0386,  ...,  0.0021, -0.0057, -0.0065],
        ...,
        [ 0.0086,  0.0103,  0.0024,  ...,  0.0390, -0.0102, -0.0043],
        [ 0.0071, -0.0051, -0.0037,  ...,  0.0080,  0.0408,  0.0023],
        [-0.0200,  0.0183, -0.0026,  ..., -0.0002,  0.0015,  0.0381]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.0537, -6.8086, -0.3579,  ..., -3.1348, -6.6602,  0.2246]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 08:54:46 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The tyrannosaurus falls into the category of dinosaur
The duck falls into the category of fowl
The butterfly falls into the category of insect
The turkey falls into the category of fowl
The rattlesnake falls into the category of snake
The gorilla falls into the category of primate
The mamba falls into the category of snake
The tiger falls into the category of
2024-07-29 08:54:46 root INFO     [order_1_approx] starting weight calculation for The duck falls into the category of fowl
The mamba falls into the category of snake
The butterfly falls into the category of insect
The tyrannosaurus falls into the category of dinosaur
The turkey falls into the category of fowl
The rattlesnake falls into the category of snake
The tiger falls into the category of feline
The gorilla falls into the category of
2024-07-29 08:54:46 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 08:56:41 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.7363, -1.0381,  0.7129,  ..., -0.2507, -0.8804,  0.2002],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.7100, -5.4922,  0.8428,  ..., -2.8398, -7.8203,  1.6543],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 2.6398e-02, -3.3512e-03, -3.1414e-03,  ..., -3.9139e-03,
         -1.0361e-02, -7.0343e-03],
        [ 2.8267e-03,  1.9669e-02, -5.8250e-03,  ..., -3.8071e-03,
          3.6449e-03, -1.4019e-04],
        [-4.7951e-03,  9.3918e-03,  3.3478e-02,  ...,  8.6365e-03,
          2.2736e-02,  4.4823e-05],
        ...,
        [ 1.2589e-02,  7.0839e-03, -8.2474e-03,  ...,  2.4933e-02,
         -7.4997e-03,  2.7580e-03],
        [ 6.1989e-04, -4.0970e-03, -2.0332e-03,  ...,  1.5736e-03,
          2.3987e-02, -6.8207e-03],
        [-1.1017e-02, -4.7379e-03, -6.3705e-03,  ..., -6.8092e-03,
         -9.3613e-03,  2.5146e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.5566, -5.6641,  0.9844,  ..., -2.8203, -8.0469,  1.5391]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 08:56:42 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The duck falls into the category of fowl
The mamba falls into the category of snake
The butterfly falls into the category of insect
The tyrannosaurus falls into the category of dinosaur
The turkey falls into the category of fowl
The rattlesnake falls into the category of snake
The tiger falls into the category of feline
The gorilla falls into the category of
2024-07-29 08:56:42 root INFO     [order_1_approx] starting weight calculation for The turkey falls into the category of fowl
The mamba falls into the category of snake
The butterfly falls into the category of insect
The tyrannosaurus falls into the category of dinosaur
The rattlesnake falls into the category of snake
The tiger falls into the category of feline
The gorilla falls into the category of primate
The duck falls into the category of
2024-07-29 08:56:42 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 08:58:37 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2959, -1.0449,  0.4868,  ..., -0.1555, -0.9102,  0.0941],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.9404, -1.8799,  3.6426,  ..., -1.7285, -7.3359,  1.3926],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0369, -0.0055,  0.0005,  ..., -0.0078,  0.0026,  0.0031],
        [-0.0004,  0.0327, -0.0062,  ..., -0.0011,  0.0145, -0.0051],
        [ 0.0019, -0.0023,  0.0302,  ...,  0.0102, -0.0155,  0.0008],
        ...,
        [ 0.0171, -0.0033,  0.0020,  ...,  0.0432, -0.0083, -0.0068],
        [ 0.0065, -0.0001, -0.0017,  ..., -0.0019,  0.0398, -0.0079],
        [-0.0101,  0.0073,  0.0007,  ..., -0.0007, -0.0010,  0.0363]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.9248, -1.7314,  3.2734,  ..., -1.5889, -7.4961,  1.3936]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 08:58:38 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The turkey falls into the category of fowl
The mamba falls into the category of snake
The butterfly falls into the category of insect
The tyrannosaurus falls into the category of dinosaur
The rattlesnake falls into the category of snake
The tiger falls into the category of feline
The gorilla falls into the category of primate
The duck falls into the category of
2024-07-29 08:58:39 root INFO     [order_1_approx] starting weight calculation for The rattlesnake falls into the category of snake
The tiger falls into the category of feline
The turkey falls into the category of fowl
The duck falls into the category of fowl
The gorilla falls into the category of primate
The butterfly falls into the category of insect
The mamba falls into the category of snake
The tyrannosaurus falls into the category of
2024-07-29 08:58:39 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 09:00:34 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 1.0928, -0.8145, -0.8936,  ..., -0.1760, -0.9917, -0.2900],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.0898, -5.0195,  2.1973,  ..., -2.1016, -5.1875, -1.3350],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0322, -0.0038, -0.0061,  ...,  0.0026, -0.0028, -0.0062],
        [-0.0001,  0.0280, -0.0075,  ..., -0.0041,  0.0109, -0.0009],
        [ 0.0057,  0.0050,  0.0241,  ...,  0.0010, -0.0084,  0.0002],
        ...,
        [ 0.0085,  0.0032,  0.0012,  ...,  0.0443, -0.0012,  0.0026],
        [ 0.0027, -0.0048, -0.0035,  ..., -0.0034,  0.0331,  0.0019],
        [-0.0046, -0.0003, -0.0031,  ..., -0.0039, -0.0041,  0.0325]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.9082, -4.9180,  2.1035,  ..., -2.1309, -5.0742, -1.4834]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 09:00:35 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The rattlesnake falls into the category of snake
The tiger falls into the category of feline
The turkey falls into the category of fowl
The duck falls into the category of fowl
The gorilla falls into the category of primate
The butterfly falls into the category of insect
The mamba falls into the category of snake
The tyrannosaurus falls into the category of
2024-07-29 09:00:35 root INFO     [order_1_approx] starting weight calculation for The butterfly falls into the category of insect
The turkey falls into the category of fowl
The tiger falls into the category of feline
The rattlesnake falls into the category of snake
The duck falls into the category of fowl
The tyrannosaurus falls into the category of dinosaur
The gorilla falls into the category of primate
The mamba falls into the category of
2024-07-29 09:00:35 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 09:02:30 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0881, -0.8242,  0.1116,  ...,  0.4883, -0.9985, -0.1593],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.8164, -3.5039,  1.3047,  ..., -0.8608, -2.7500, -0.0903],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0652, -0.0003,  0.0088,  ..., -0.0092,  0.0065, -0.0051],
        [-0.0194,  0.0670, -0.0046,  ...,  0.0116,  0.0159, -0.0123],
        [ 0.0089, -0.0108,  0.0656,  ..., -0.0075, -0.0155, -0.0015],
        ...,
        [ 0.0180,  0.0118,  0.0051,  ...,  0.0717,  0.0042, -0.0201],
        [-0.0051, -0.0113, -0.0037,  ..., -0.0055,  0.0570,  0.0005],
        [-0.0078,  0.0187,  0.0001,  ..., -0.0008,  0.0076,  0.0456]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.8955, -3.2793,  1.1143,  ..., -0.9556, -3.0723, -0.0126]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 09:02:32 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The butterfly falls into the category of insect
The turkey falls into the category of fowl
The tiger falls into the category of feline
The rattlesnake falls into the category of snake
The duck falls into the category of fowl
The tyrannosaurus falls into the category of dinosaur
The gorilla falls into the category of primate
The mamba falls into the category of
2024-07-29 09:02:32 root INFO     total operator prediction time: 931.771945476532 seconds
2024-07-29 09:02:32 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on synonyms - intensity
2024-07-29 09:02:32 root INFO     building operator synonyms - intensity
2024-07-29 09:02:32 root INFO     [order_1_approx] starting weight calculation for A more intense word for sniffles is pneumonia
A more intense word for indulge is pamper
A more intense word for interesting is exciting
A more intense word for necessary is essential
A more intense word for pony is horse
A more intense word for drizzle is rain
A more intense word for house is palace
A more intense word for tired is
2024-07-29 09:02:32 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 09:04:27 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.8496, -0.6328, -0.6016,  ...,  0.2568, -0.4668,  0.4717],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.1406, -6.1016,  4.6562,  ..., -2.6602, -1.0010, -0.3867],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0737,  0.0059, -0.0028,  ...,  0.0143,  0.0216,  0.0177],
        [ 0.0046,  0.0544, -0.0036,  ..., -0.0020,  0.0205, -0.0035],
        [-0.0168, -0.0110,  0.0647,  ...,  0.0029, -0.0108,  0.0046],
        ...,
        [ 0.0057,  0.0126, -0.0104,  ...,  0.0791,  0.0059, -0.0199],
        [-0.0016, -0.0038, -0.0034,  ...,  0.0007,  0.0612, -0.0127],
        [-0.0111, -0.0031, -0.0069,  ..., -0.0030, -0.0031,  0.0624]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.2324, -5.8945,  4.8516,  ..., -2.7734, -0.9209, -0.5591]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 09:04:28 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more intense word for sniffles is pneumonia
A more intense word for indulge is pamper
A more intense word for interesting is exciting
A more intense word for necessary is essential
A more intense word for pony is horse
A more intense word for drizzle is rain
A more intense word for house is palace
A more intense word for tired is
2024-07-29 09:04:28 root INFO     [order_1_approx] starting weight calculation for A more intense word for drizzle is rain
A more intense word for tired is exhausted
A more intense word for sniffles is pneumonia
A more intense word for pony is horse
A more intense word for indulge is pamper
A more intense word for necessary is essential
A more intense word for interesting is exciting
A more intense word for house is
2024-07-29 09:04:28 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 09:06:23 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0200,  0.2389, -0.3516,  ..., -0.1472, -0.2529, -0.3235],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-2.7461, -5.5625,  1.3906,  ..., -0.6440, -1.1426,  0.7207],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 9.8267e-02,  5.7983e-03,  1.7868e-02,  ...,  9.0637e-03,
          2.4376e-03,  2.6459e-02],
        [-1.2878e-02,  7.8918e-02,  8.9188e-03,  ..., -1.0574e-02,
          2.4963e-02,  4.1580e-04],
        [ 7.8735e-03,  5.1727e-03,  7.9468e-02,  ..., -4.5776e-03,
         -8.8120e-03,  9.2773e-03],
        ...,
        [ 9.4833e-03,  4.4136e-03, -1.6155e-03,  ...,  8.4961e-02,
         -8.9645e-05, -6.5384e-03],
        [-4.2801e-03,  9.4147e-03,  1.5106e-03,  ...,  9.8419e-04,
          9.5520e-02, -1.0643e-02],
        [-4.6768e-03, -1.8188e-02, -1.3641e-02,  ..., -1.2337e-02,
         -1.5137e-02,  7.5012e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-2.8145, -5.2188,  1.3174,  ..., -0.5796, -1.7588,  0.5010]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 09:06:24 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more intense word for drizzle is rain
A more intense word for tired is exhausted
A more intense word for sniffles is pneumonia
A more intense word for pony is horse
A more intense word for indulge is pamper
A more intense word for necessary is essential
A more intense word for interesting is exciting
A more intense word for house is
2024-07-29 09:06:24 root INFO     [order_1_approx] starting weight calculation for A more intense word for necessary is essential
A more intense word for tired is exhausted
A more intense word for interesting is exciting
A more intense word for indulge is pamper
A more intense word for sniffles is pneumonia
A more intense word for house is palace
A more intense word for pony is horse
A more intense word for drizzle is
2024-07-29 09:06:24 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 09:08:17 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3325, -0.7461, -1.1270,  ..., -0.6953, -0.1946, -0.5229],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.5820, -5.1094, -1.4512,  ...,  1.2578,  0.6626, -2.1250],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0390, -0.0035,  0.0128,  ..., -0.0031, -0.0012, -0.0016],
        [ 0.0010,  0.0353, -0.0013,  ...,  0.0061, -0.0005, -0.0051],
        [-0.0052, -0.0102,  0.0330,  ..., -0.0088,  0.0023, -0.0027],
        ...,
        [ 0.0012, -0.0064,  0.0019,  ...,  0.0333,  0.0007,  0.0047],
        [ 0.0011, -0.0098,  0.0020,  ...,  0.0039,  0.0276, -0.0028],
        [ 0.0058, -0.0032, -0.0017,  ..., -0.0031,  0.0005,  0.0294]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.6133, -5.0078, -1.5176,  ...,  1.1670,  0.6113, -2.1074]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 09:08:18 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more intense word for necessary is essential
A more intense word for tired is exhausted
A more intense word for interesting is exciting
A more intense word for indulge is pamper
A more intense word for sniffles is pneumonia
A more intense word for house is palace
A more intense word for pony is horse
A more intense word for drizzle is
2024-07-29 09:08:19 root INFO     [order_1_approx] starting weight calculation for A more intense word for indulge is pamper
A more intense word for pony is horse
A more intense word for tired is exhausted
A more intense word for interesting is exciting
A more intense word for house is palace
A more intense word for sniffles is pneumonia
A more intense word for drizzle is rain
A more intense word for necessary is
2024-07-29 09:08:19 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 09:10:14 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2367,  0.1429, -0.6509,  ..., -0.7549, -0.5400, -0.5215],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 6.1328, -0.3359, -0.1724,  ..., -0.1230, -6.3906, -2.2070],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 8.9661e-02, -1.7761e-02,  2.7115e-02,  ...,  1.5686e-02,
          8.0872e-03,  2.0370e-02],
        [-3.1433e-02,  8.3557e-02, -5.7220e-06,  ...,  1.4557e-02,
          1.4954e-03, -1.5869e-02],
        [ 2.6951e-03, -3.2578e-03,  1.1047e-01,  ..., -3.2593e-02,
         -3.0937e-03, -2.5139e-03],
        ...,
        [ 5.0201e-03,  2.1576e-02, -3.0632e-03,  ...,  1.3416e-01,
         -1.7242e-02, -2.5345e-02],
        [ 9.7885e-03,  8.9035e-03,  1.0269e-02,  ..., -2.5253e-02,
          1.0565e-01, -1.8631e-02],
        [-6.5804e-03, -1.6830e-02, -1.9257e-02,  ...,  5.6915e-03,
         -1.8860e-02,  1.1285e-01]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 5.8945, -0.3784,  0.1606,  ..., -0.0228, -6.2656, -1.7402]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 09:10:15 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more intense word for indulge is pamper
A more intense word for pony is horse
A more intense word for tired is exhausted
A more intense word for interesting is exciting
A more intense word for house is palace
A more intense word for sniffles is pneumonia
A more intense word for drizzle is rain
A more intense word for necessary is
2024-07-29 09:10:15 root INFO     [order_1_approx] starting weight calculation for A more intense word for interesting is exciting
A more intense word for necessary is essential
A more intense word for pony is horse
A more intense word for tired is exhausted
A more intense word for sniffles is pneumonia
A more intense word for house is palace
A more intense word for drizzle is rain
A more intense word for indulge is
2024-07-29 09:10:15 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 09:12:11 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2042,  0.2091, -0.5146,  ..., -0.3940, -1.4316,  0.5674],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.6875, -3.0957, -2.6055,  ...,  1.3174, -4.6211,  2.1992],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0862, -0.0045,  0.0148,  ..., -0.0030, -0.0054,  0.0066],
        [ 0.0001,  0.0706, -0.0105,  ...,  0.0082,  0.0004, -0.0129],
        [-0.0078, -0.0152,  0.0580,  ..., -0.0118, -0.0032, -0.0095],
        ...,
        [ 0.0120, -0.0028, -0.0040,  ...,  0.0807, -0.0091, -0.0011],
        [-0.0121, -0.0011,  0.0074,  ..., -0.0091,  0.0629, -0.0047],
        [-0.0017, -0.0155, -0.0014,  ..., -0.0134, -0.0110,  0.0561]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.5918, -2.9570, -2.7910,  ...,  1.3350, -4.6016,  2.1641]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 09:12:12 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more intense word for interesting is exciting
A more intense word for necessary is essential
A more intense word for pony is horse
A more intense word for tired is exhausted
A more intense word for sniffles is pneumonia
A more intense word for house is palace
A more intense word for drizzle is rain
A more intense word for indulge is
2024-07-29 09:12:12 root INFO     [order_1_approx] starting weight calculation for A more intense word for sniffles is pneumonia
A more intense word for house is palace
A more intense word for necessary is essential
A more intense word for tired is exhausted
A more intense word for indulge is pamper
A more intense word for drizzle is rain
A more intense word for pony is horse
A more intense word for interesting is
2024-07-29 09:12:12 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 09:14:06 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0467, -0.1398,  0.4426,  ...,  0.2393, -0.8140, -0.1101],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.5352,  1.7461,  1.6133,  ..., -0.1234, -6.1172, -2.0762],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0848, -0.0002,  0.0081,  ...,  0.0093, -0.0068,  0.0094],
        [-0.0199,  0.0610,  0.0075,  ...,  0.0080,  0.0099, -0.0035],
        [ 0.0076, -0.0204,  0.0806,  ..., -0.0136,  0.0028,  0.0036],
        ...,
        [ 0.0064,  0.0029,  0.0064,  ...,  0.1066,  0.0067, -0.0038],
        [ 0.0156,  0.0160,  0.0029,  ...,  0.0022,  0.0648, -0.0068],
        [ 0.0037, -0.0062, -0.0079,  ..., -0.0038,  0.0009,  0.0811]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.6797,  1.4785,  1.6934,  ..., -0.2312, -6.2109, -1.8945]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 09:14:07 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more intense word for sniffles is pneumonia
A more intense word for house is palace
A more intense word for necessary is essential
A more intense word for tired is exhausted
A more intense word for indulge is pamper
A more intense word for drizzle is rain
A more intense word for pony is horse
A more intense word for interesting is
2024-07-29 09:14:08 root INFO     [order_1_approx] starting weight calculation for A more intense word for sniffles is pneumonia
A more intense word for tired is exhausted
A more intense word for house is palace
A more intense word for interesting is exciting
A more intense word for drizzle is rain
A more intense word for necessary is essential
A more intense word for indulge is pamper
A more intense word for pony is
2024-07-29 09:14:08 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 09:16:03 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2935,  0.3711, -0.6670,  ..., -0.3345, -0.5723,  0.4380],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.5908, -4.2578, -0.1260,  ...,  2.0586, -3.4727, -0.9434],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.1151, -0.0069,  0.0115,  ...,  0.0107,  0.0106, -0.0113],
        [-0.0125,  0.0654,  0.0128,  ...,  0.0107,  0.0359, -0.0186],
        [ 0.0009, -0.0203,  0.1013,  ..., -0.0310, -0.0109, -0.0183],
        ...,
        [ 0.0315, -0.0141, -0.0073,  ...,  0.1343,  0.0072, -0.0354],
        [-0.0282,  0.0054,  0.0020,  ...,  0.0181,  0.1014,  0.0033],
        [-0.0036, -0.0225,  0.0088,  ..., -0.0235,  0.0019,  0.0827]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.9258, -3.5742, -0.6289,  ...,  2.3340, -3.5527, -0.8828]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 09:16:04 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more intense word for sniffles is pneumonia
A more intense word for tired is exhausted
A more intense word for house is palace
A more intense word for interesting is exciting
A more intense word for drizzle is rain
A more intense word for necessary is essential
A more intense word for indulge is pamper
A more intense word for pony is
2024-07-29 09:16:05 root INFO     [order_1_approx] starting weight calculation for A more intense word for house is palace
A more intense word for interesting is exciting
A more intense word for pony is horse
A more intense word for necessary is essential
A more intense word for indulge is pamper
A more intense word for tired is exhausted
A more intense word for drizzle is rain
A more intense word for sniffles is
2024-07-29 09:16:05 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 09:18:00 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2693, -0.2729, -0.9414,  ...,  0.1456, -0.8584,  0.4980],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.1055, -1.2803,  3.8652,  ..., -0.2178,  1.1641,  2.6055],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0792, -0.0107,  0.0122,  ...,  0.0119,  0.0190,  0.0085],
        [ 0.0005,  0.0684,  0.0001,  ...,  0.0047,  0.0178,  0.0113],
        [-0.0106, -0.0008,  0.0692,  ...,  0.0127, -0.0134, -0.0156],
        ...,
        [ 0.0132,  0.0177,  0.0009,  ...,  0.0818, -0.0090,  0.0118],
        [ 0.0151,  0.0033,  0.0021,  ...,  0.0096,  0.0644,  0.0067],
        [-0.0081,  0.0047, -0.0058,  ...,  0.0017, -0.0197,  0.0725]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.3164e+00, -1.3906e+00,  4.0430e+00,  ...,  2.6855e-03,
          1.0684e+00,  2.2129e+00]], device='cuda:1', dtype=torch.float16,
       grad_fn=<SubBackward0>) 

                    
2024-07-29 09:18:01 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more intense word for house is palace
A more intense word for interesting is exciting
A more intense word for pony is horse
A more intense word for necessary is essential
A more intense word for indulge is pamper
A more intense word for tired is exhausted
A more intense word for drizzle is rain
A more intense word for sniffles is
2024-07-29 09:18:01 root INFO     total operator prediction time: 928.9228208065033 seconds
2024-07-29 09:18:01 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on meronyms - substance
2024-07-29 09:18:01 root INFO     building operator meronyms - substance
2024-07-29 09:18:01 root INFO     [order_1_approx] starting weight calculation for A glacier is made up of ice
A pastry is made up of flour
A chocolate is made up of cocoa
A icicle is made up of ice
A roof is made up of shingles
A cocktail is made up of alcohol
A doorknob is made up of metal
A snow is made up of
2024-07-29 09:18:01 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 09:19:55 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.7173,  0.4045,  0.2959,  ..., -0.5049, -0.5420, -0.7070],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.9790, -3.7031, -0.5801,  ..., -5.3984,  0.6899, -0.6826],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 3.6682e-02, -1.6602e-02,  3.4523e-03,  ...,  1.5503e-02,
          5.6190e-03, -1.0818e-02],
        [-1.2123e-02,  7.7171e-03,  3.1815e-03,  ..., -4.3869e-03,
         -6.1035e-05, -2.8038e-03],
        [-3.6392e-03, -2.9106e-03,  2.8076e-02,  ...,  8.0566e-03,
          5.0201e-03,  4.6692e-03],
        ...,
        [ 3.7813e-04, -1.0262e-02, -1.9531e-03,  ...,  3.1677e-02,
         -5.7220e-05, -1.4313e-02],
        [ 6.4964e-03,  5.0735e-03,  2.7523e-03,  ...,  1.1658e-02,
          7.7591e-03,  5.0964e-03],
        [-1.0509e-03, -1.1757e-02, -2.7599e-03,  ...,  4.3259e-03,
         -1.9407e-03,  1.5839e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.1426, -3.9590, -0.5430,  ..., -5.5195,  0.6006, -0.5195]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 09:19:56 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A glacier is made up of ice
A pastry is made up of flour
A chocolate is made up of cocoa
A icicle is made up of ice
A roof is made up of shingles
A cocktail is made up of alcohol
A doorknob is made up of metal
A snow is made up of
2024-07-29 09:19:56 root INFO     [order_1_approx] starting weight calculation for A icicle is made up of ice
A chocolate is made up of cocoa
A pastry is made up of flour
A roof is made up of shingles
A glacier is made up of ice
A snow is made up of water
A cocktail is made up of alcohol
A doorknob is made up of
2024-07-29 09:19:56 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 09:21:50 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0318, -0.4277, -0.5039,  ..., -0.0703, -0.9336, -0.5439],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.1426, -2.8535, -2.1836,  ..., -2.2324, -0.3438, -0.1123],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0471, -0.0044, -0.0013,  ...,  0.0009, -0.0124,  0.0009],
        [-0.0019,  0.0268,  0.0012,  ...,  0.0017,  0.0066,  0.0075],
        [ 0.0101,  0.0094,  0.0392,  ..., -0.0086,  0.0009, -0.0009],
        ...,
        [ 0.0131,  0.0012, -0.0058,  ...,  0.0413, -0.0049, -0.0047],
        [ 0.0025,  0.0113, -0.0062,  ...,  0.0123,  0.0328,  0.0024],
        [ 0.0090, -0.0023,  0.0075,  ..., -0.0024, -0.0033,  0.0363]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.8887, -2.7402, -2.1387,  ..., -2.1445, -0.5977,  0.0431]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 09:21:51 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A icicle is made up of ice
A chocolate is made up of cocoa
A pastry is made up of flour
A roof is made up of shingles
A glacier is made up of ice
A snow is made up of water
A cocktail is made up of alcohol
A doorknob is made up of
2024-07-29 09:21:52 root INFO     [order_1_approx] starting weight calculation for A doorknob is made up of metal
A snow is made up of water
A chocolate is made up of cocoa
A icicle is made up of ice
A roof is made up of shingles
A pastry is made up of flour
A glacier is made up of ice
A cocktail is made up of
2024-07-29 09:21:52 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
2024-07-29 09:23:47 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1210, -0.9126, -0.2681,  ..., -0.6812, -0.7134, -0.8394],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.0352, -7.1523, -3.6738,  ..., -2.1875, -1.1680, -4.5625],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0378, -0.0093,  0.0037,  ..., -0.0038, -0.0063,  0.0042],
        [-0.0023,  0.0217,  0.0081,  ..., -0.0045,  0.0115, -0.0138],
        [-0.0025, -0.0037,  0.0413,  ..., -0.0073, -0.0004, -0.0058],
        ...,
        [-0.0019, -0.0062,  0.0041,  ...,  0.0468,  0.0032, -0.0194],
        [-0.0034,  0.0079, -0.0048,  ...,  0.0048,  0.0363,  0.0001],
        [ 0.0125, -0.0090, -0.0020,  ..., -0.0182,  0.0042,  0.0234]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.8379, -7.0430, -3.6992,  ..., -1.9971, -1.4014, -4.4688]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 09:23:48 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A doorknob is made up of metal
A snow is made up of water
A chocolate is made up of cocoa
A icicle is made up of ice
A roof is made up of shingles
A pastry is made up of flour
A glacier is made up of ice
A cocktail is made up of
2024-07-29 09:23:48 root INFO     [order_1_approx] starting weight calculation for A cocktail is made up of alcohol
A icicle is made up of ice
A pastry is made up of flour
A roof is made up of shingles
A chocolate is made up of cocoa
A doorknob is made up of metal
A snow is made up of water
A glacier is made up of
2024-07-29 09:23:48 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.16
