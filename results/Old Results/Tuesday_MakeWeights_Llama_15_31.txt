2024-07-30 17:17:06 root INFO     loading model + tokenizer
2024-07-30 17:17:09 root INFO     model + tokenizer loaded
2024-07-30 17:17:09 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on verb+ment_irreg
2024-07-30 17:17:09 root INFO     building operator verb+ment_irreg
2024-07-30 17:17:10 root INFO     [order_1_approx] starting weight calculation for To entitle results in a entitlement
To involve results in a involvement
To develop results in a development
To encourage results in a encouragement
To assign results in a assignment
To align results in a alignment
To reimburse results in a reimbursement
To adjust results in a
2024-07-30 17:17:10 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-30 17:19:02 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1953, -0.1351, -0.7388,  ..., -0.4580, -0.1216,  0.4937],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.0332, -1.9316, -1.3184,  ...,  0.5986, -1.1191, -1.3418],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0804,  0.0104,  0.0080,  ..., -0.0182,  0.0050, -0.0061],
        [ 0.0109,  0.0856,  0.0037,  ...,  0.0392,  0.0048,  0.0276],
        [-0.0045, -0.0024,  0.0619,  ..., -0.0082,  0.0010, -0.0123],
        ...,
        [ 0.0068,  0.0045, -0.0133,  ...,  0.1004, -0.0155,  0.0085],
        [-0.0110, -0.0004,  0.0207,  ..., -0.0010,  0.0707, -0.0285],
        [ 0.0257, -0.0036, -0.0015,  ..., -0.0109, -0.0097,  0.0757]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.3105, -1.3008, -1.4600,  ...,  0.9849, -1.4453, -1.4150]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 17:19:03 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To entitle results in a entitlement
To involve results in a involvement
To develop results in a development
To encourage results in a encouragement
To assign results in a assignment
To align results in a alignment
To reimburse results in a reimbursement
To adjust results in a
2024-07-30 17:19:03 root INFO     [order_1_approx] starting weight calculation for To encourage results in a encouragement
To adjust results in a adjustment
To develop results in a development
To align results in a alignment
To entitle results in a entitlement
To reimburse results in a reimbursement
To assign results in a assignment
To involve results in a
2024-07-30 17:19:03 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-30 17:20:53 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0012,  0.2952,  0.2356,  ..., -0.1951, -0.9102, -0.5649],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.2129, -2.2891,  2.5703,  ...,  2.0664, -0.4219, -5.1094],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0617,  0.0181,  0.0150,  ..., -0.0039,  0.0095,  0.0153],
        [-0.0108,  0.0655,  0.0042,  ...,  0.0236,  0.0031,  0.0076],
        [ 0.0042, -0.0132,  0.0374,  ..., -0.0204, -0.0091, -0.0018],
        ...,
        [ 0.0028,  0.0053, -0.0150,  ...,  0.0699, -0.0150,  0.0063],
        [-0.0116,  0.0019,  0.0249,  ...,  0.0040,  0.0588, -0.0233],
        [ 0.0032,  0.0058, -0.0127,  ..., -0.0005, -0.0150,  0.0611]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.7539, -1.9219,  2.2129,  ...,  2.0977, -0.9053, -4.3906]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 17:20:54 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To encourage results in a encouragement
To adjust results in a adjustment
To develop results in a development
To align results in a alignment
To entitle results in a entitlement
To reimburse results in a reimbursement
To assign results in a assignment
To involve results in a
2024-07-30 17:20:54 root INFO     [order_1_approx] starting weight calculation for To encourage results in a encouragement
To align results in a alignment
To involve results in a involvement
To reimburse results in a reimbursement
To develop results in a development
To assign results in a assignment
To adjust results in a adjustment
To entitle results in a
2024-07-30 17:20:54 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-30 17:22:47 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1241, -0.3198, -0.1667,  ..., -0.4624, -0.3623,  0.1898],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.2881, -3.1758,  0.9385,  ...,  1.1875, -1.3223, -2.5000],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0873, -0.0248,  0.0162,  ..., -0.0039,  0.0034,  0.0029],
        [-0.0047,  0.1041, -0.0127,  ...,  0.0336, -0.0011,  0.0178],
        [ 0.0073, -0.0305,  0.0723,  ..., -0.0205, -0.0003, -0.0088],
        ...,
        [ 0.0005,  0.0175, -0.0065,  ...,  0.1066, -0.0040,  0.0073],
        [-0.0062, -0.0063,  0.0223,  ...,  0.0140,  0.0939, -0.0180],
        [ 0.0198, -0.0098, -0.0177,  ...,  0.0190, -0.0229,  0.0945]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.0029, -2.2383,  0.3994,  ...,  1.6289, -1.3555, -2.5879]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 17:22:48 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To encourage results in a encouragement
To align results in a alignment
To involve results in a involvement
To reimburse results in a reimbursement
To develop results in a development
To assign results in a assignment
To adjust results in a adjustment
To entitle results in a
2024-07-30 17:22:49 root INFO     [order_1_approx] starting weight calculation for To assign results in a assignment
To encourage results in a encouragement
To involve results in a involvement
To entitle results in a entitlement
To reimburse results in a reimbursement
To adjust results in a adjustment
To align results in a alignment
To develop results in a
2024-07-30 17:22:49 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-30 17:24:45 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3816,  0.4937,  0.0233,  ...,  0.0525, -0.4524, -0.1093],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.1289, -3.9512,  0.3628,  ...,  2.7715, -1.0557, -2.6289],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0893,  0.0254,  0.0025,  ..., -0.0120, -0.0169,  0.0016],
        [-0.0096,  0.0918,  0.0057,  ...,  0.0287,  0.0120,  0.0277],
        [ 0.0004, -0.0121,  0.0819,  ..., -0.0163,  0.0058, -0.0190],
        ...,
        [ 0.0059, -0.0108, -0.0127,  ...,  0.1196, -0.0119,  0.0230],
        [-0.0056,  0.0009,  0.0210,  ..., -0.0016,  0.0861, -0.0364],
        [-0.0052, -0.0067, -0.0080,  ...,  0.0019, -0.0175,  0.1002]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.1777, -3.5566,  0.5908,  ...,  2.7402, -1.5068, -2.6387]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 17:24:46 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To assign results in a assignment
To encourage results in a encouragement
To involve results in a involvement
To entitle results in a entitlement
To reimburse results in a reimbursement
To adjust results in a adjustment
To align results in a alignment
To develop results in a
2024-07-30 17:24:47 root INFO     [order_1_approx] starting weight calculation for To reimburse results in a reimbursement
To involve results in a involvement
To align results in a alignment
To adjust results in a adjustment
To encourage results in a encouragement
To develop results in a development
To entitle results in a entitlement
To assign results in a
2024-07-30 17:24:47 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-30 17:26:41 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.5762,  0.7070,  0.3875,  ...,  0.0737, -0.2024, -0.3730],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.2529, -3.3672,  0.4158,  ...,  2.5879, -2.1562, -2.4941],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0540,  0.0117, -0.0121,  ..., -0.0158,  0.0121,  0.0034],
        [ 0.0074,  0.0710,  0.0224,  ...,  0.0487, -0.0028,  0.0106],
        [-0.0097, -0.0072,  0.0582,  ..., -0.0111,  0.0033, -0.0236],
        ...,
        [ 0.0127,  0.0197, -0.0098,  ...,  0.0936, -0.0153, -0.0010],
        [ 0.0010,  0.0025,  0.0168,  ..., -0.0039,  0.0723, -0.0226],
        [ 0.0126,  0.0030, -0.0056,  ..., -0.0109, -0.0302,  0.0736]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.6914, -2.9199,  0.4531,  ...,  2.1387, -2.3516, -2.2480]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 17:26:42 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To reimburse results in a reimbursement
To involve results in a involvement
To align results in a alignment
To adjust results in a adjustment
To encourage results in a encouragement
To develop results in a development
To entitle results in a entitlement
To assign results in a
2024-07-30 17:26:42 root INFO     [order_1_approx] starting weight calculation for To align results in a alignment
To involve results in a involvement
To develop results in a development
To reimburse results in a reimbursement
To adjust results in a adjustment
To entitle results in a entitlement
To assign results in a assignment
To encourage results in a
2024-07-30 17:26:42 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-30 17:28:31 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1255,  0.0480, -0.6582,  ..., -0.2460, -0.1699, -0.2170],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.6865, -1.9717,  0.1884,  ...,  2.4531, -1.1709, -2.7383],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0714,  0.0054,  0.0010,  ..., -0.0111, -0.0042,  0.0123],
        [-0.0090,  0.0868, -0.0073,  ...,  0.0277,  0.0058,  0.0003],
        [ 0.0105, -0.0071,  0.0601,  ..., -0.0058, -0.0058, -0.0036],
        ...,
        [-0.0080, -0.0068, -0.0060,  ...,  0.0900,  0.0004, -0.0068],
        [-0.0045,  0.0027,  0.0137,  ..., -0.0018,  0.0701, -0.0220],
        [ 0.0086, -0.0070, -0.0122,  ...,  0.0103, -0.0135,  0.0730]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.4795, -1.8516,  0.3374,  ...,  2.4238, -1.3027, -2.5898]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 17:28:32 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To align results in a alignment
To involve results in a involvement
To develop results in a development
To reimburse results in a reimbursement
To adjust results in a adjustment
To entitle results in a entitlement
To assign results in a assignment
To encourage results in a
2024-07-30 17:28:33 root INFO     [order_1_approx] starting weight calculation for To assign results in a assignment
To involve results in a involvement
To entitle results in a entitlement
To reimburse results in a reimbursement
To encourage results in a encouragement
To develop results in a development
To adjust results in a adjustment
To align results in a
2024-07-30 17:28:33 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-30 17:30:30 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.3120,  0.2808, -0.2808,  ...,  0.2178, -0.0247,  0.1302],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.7520, -2.1055, -1.2402,  ...,  2.5039, -2.1445, -0.8789],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0688,  0.0136, -0.0019,  ..., -0.0176,  0.0127,  0.0115],
        [ 0.0072,  0.0736,  0.0188,  ...,  0.0403,  0.0054,  0.0087],
        [-0.0008,  0.0008,  0.0718,  ..., -0.0080,  0.0010, -0.0249],
        ...,
        [ 0.0028, -0.0047,  0.0044,  ...,  0.0986, -0.0139, -0.0082],
        [-0.0158,  0.0092,  0.0026,  ..., -0.0055,  0.0654, -0.0181],
        [ 0.0153, -0.0153,  0.0083,  ...,  0.0114, -0.0201,  0.0720]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.3027, -1.6680, -1.3711,  ...,  2.8457, -2.4648, -1.0264]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 17:30:31 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To assign results in a assignment
To involve results in a involvement
To entitle results in a entitlement
To reimburse results in a reimbursement
To encourage results in a encouragement
To develop results in a development
To adjust results in a adjustment
To align results in a
2024-07-30 17:30:31 root INFO     [order_1_approx] starting weight calculation for To adjust results in a adjustment
To develop results in a development
To involve results in a involvement
To entitle results in a entitlement
To assign results in a assignment
To align results in a alignment
To encourage results in a encouragement
To reimburse results in a
2024-07-30 17:30:31 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-30 17:32:30 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1743, -0.2242, -0.5601,  ..., -0.2498,  0.1520, -0.0657],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.7461, -2.4902, -0.3982,  ..., -0.7959, -1.9561, -2.9258],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 8.5999e-02, -2.2259e-03,  1.3443e-02,  ..., -2.4452e-03,
         -4.9210e-04,  7.8583e-03],
        [-1.4214e-02,  8.4839e-02,  1.3218e-03,  ...,  2.1759e-02,
          1.1124e-02,  1.1490e-02],
        [ 1.1139e-02,  5.7602e-04,  7.0984e-02,  ..., -2.0493e-02,
          1.2779e-03, -8.7738e-03],
        ...,
        [-8.8959e-03,  1.2833e-02, -8.2245e-03,  ...,  9.8145e-02,
         -1.0117e-02, -3.1662e-04],
        [ 6.8665e-05, -2.2888e-05,  1.4359e-02,  ...,  3.7918e-03,
          8.1055e-02, -2.5558e-02],
        [ 6.4898e-04, -8.6746e-03, -2.3315e-02,  ...,  9.8572e-03,
         -1.7609e-02,  7.6416e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.7090, -2.2266, -0.3008,  ..., -0.7690, -1.8613, -3.2656]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 17:32:31 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To adjust results in a adjustment
To develop results in a development
To involve results in a involvement
To entitle results in a entitlement
To assign results in a assignment
To align results in a alignment
To encourage results in a encouragement
To reimburse results in a
2024-07-30 17:32:31 root INFO     total operator prediction time: 922.0118131637573 seconds
2024-07-30 17:32:31 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on noun+less_reg
2024-07-30 17:32:31 root INFO     building operator noun+less_reg
2024-07-30 17:32:31 root INFO     [order_1_approx] starting weight calculation for Something without bone is boneless
Something without emotion is emotionless
Something without heart is heartless
Something without hair is hairless
Something without effort is effortless
Something without remorse is remorseless
Something without leg is legless
Something without spine is
2024-07-30 17:32:31 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-30 17:34:28 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1274, -0.6338, -0.4846,  ...,  0.0620, -0.1823,  0.2825],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.5840, -2.1953, -1.6104,  ..., -1.9121, -2.3066, -1.3154],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0577, -0.0019,  0.0090,  ...,  0.0050,  0.0274,  0.0051],
        [ 0.0130,  0.0508, -0.0014,  ...,  0.0113,  0.0156, -0.0013],
        [ 0.0139,  0.0030,  0.0367,  ..., -0.0041, -0.0005, -0.0113],
        ...,
        [ 0.0114,  0.0126, -0.0030,  ...,  0.0555,  0.0089, -0.0069],
        [-0.0036,  0.0169, -0.0001,  ..., -0.0152,  0.0426, -0.0134],
        [-0.0016, -0.0046, -0.0054,  ...,  0.0002, -0.0116,  0.0342]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.8711, -2.1055, -1.8379,  ..., -1.6064, -2.4609, -0.8047]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 17:34:40 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Something without bone is boneless
Something without emotion is emotionless
Something without heart is heartless
Something without hair is hairless
Something without effort is effortless
Something without remorse is remorseless
Something without leg is legless
Something without spine is
2024-07-30 17:34:40 root INFO     [order_1_approx] starting weight calculation for Something without bone is boneless
Something without heart is heartless
Something without spine is spineless
Something without emotion is emotionless
Something without remorse is remorseless
Something without leg is legless
Something without effort is effortless
Something without hair is
2024-07-30 17:34:40 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-30 17:36:32 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2578, -0.9395, -0.3696,  ..., -0.0675,  0.4927,  0.2966],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.6035, -2.8164, -2.3984,  ..., -1.8467, -3.9102, -1.4062],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0506, -0.0058,  0.0047,  ...,  0.0087,  0.0129,  0.0078],
        [-0.0057,  0.0734,  0.0019,  ..., -0.0070, -0.0040,  0.0047],
        [ 0.0172,  0.0032,  0.0524,  ...,  0.0026,  0.0048, -0.0186],
        ...,
        [ 0.0054,  0.0077, -0.0013,  ...,  0.0494, -0.0020, -0.0116],
        [-0.0213,  0.0141,  0.0143,  ..., -0.0229,  0.0678, -0.0269],
        [ 0.0142, -0.0049,  0.0029,  ..., -0.0033, -0.0067,  0.0450]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.7207, -2.6309, -2.4277,  ..., -1.6104, -4.0664, -1.2402]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 17:36:33 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Something without bone is boneless
Something without heart is heartless
Something without spine is spineless
Something without emotion is emotionless
Something without remorse is remorseless
Something without leg is legless
Something without effort is effortless
Something without hair is
2024-07-30 17:36:33 root INFO     [order_1_approx] starting weight calculation for Something without emotion is emotionless
Something without remorse is remorseless
Something without leg is legless
Something without spine is spineless
Something without heart is heartless
Something without hair is hairless
Something without effort is effortless
Something without bone is
2024-07-30 17:36:33 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-30 17:38:31 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.5684,  0.0657, -0.5200,  ..., -0.2834, -0.7769,  0.3486],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.0061, -1.3545, -0.1987,  ..., -2.3770, -2.1172, -1.9150],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0431, -0.0183,  0.0032,  ...,  0.0100,  0.0096,  0.0122],
        [ 0.0001,  0.0544,  0.0022,  ..., -0.0028,  0.0101,  0.0031],
        [ 0.0017,  0.0136,  0.0231,  ...,  0.0008,  0.0091, -0.0115],
        ...,
        [ 0.0022,  0.0184, -0.0135,  ...,  0.0266, -0.0019, -0.0107],
        [-0.0224,  0.0124, -0.0007,  ..., -0.0157,  0.0380, -0.0076],
        [ 0.0220,  0.0054,  0.0077,  ...,  0.0017, -0.0033,  0.0147]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.1237, -1.3975, -0.5620,  ..., -2.4707, -2.1777, -1.5391]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 17:38:32 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Something without emotion is emotionless
Something without remorse is remorseless
Something without leg is legless
Something without spine is spineless
Something without heart is heartless
Something without hair is hairless
Something without effort is effortless
Something without bone is
2024-07-30 17:38:32 root INFO     [order_1_approx] starting weight calculation for Something without spine is spineless
Something without bone is boneless
Something without remorse is remorseless
Something without leg is legless
Something without hair is hairless
Something without effort is effortless
Something without emotion is emotionless
Something without heart is
2024-07-30 17:38:32 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-30 17:40:28 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0737, -0.0734,  0.1886,  ..., -0.1456, -0.5127,  0.4299],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.6904, -4.4141, -1.5430,  ..., -2.9453, -2.4609, -2.0215],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0410, -0.0123,  0.0072,  ...,  0.0031,  0.0045,  0.0064],
        [-0.0060,  0.0441,  0.0047,  ...,  0.0030,  0.0027,  0.0055],
        [ 0.0014, -0.0128,  0.0332,  ..., -0.0056, -0.0008, -0.0009],
        ...,
        [ 0.0045,  0.0108, -0.0021,  ...,  0.0316, -0.0030,  0.0021],
        [-0.0091, -0.0080, -0.0070,  ..., -0.0147,  0.0480, -0.0206],
        [ 0.0060, -0.0090, -0.0017,  ..., -0.0029, -0.0075,  0.0291]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.7041, -4.3047, -1.5693,  ..., -2.8926, -2.5488, -2.0586]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 17:40:29 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Something without spine is spineless
Something without bone is boneless
Something without remorse is remorseless
Something without leg is legless
Something without hair is hairless
Something without effort is effortless
Something without emotion is emotionless
Something without heart is
2024-07-30 17:40:29 root INFO     [order_1_approx] starting weight calculation for Something without spine is spineless
Something without leg is legless
Something without hair is hairless
Something without emotion is emotionless
Something without heart is heartless
Something without bone is boneless
Something without remorse is remorseless
Something without effort is
2024-07-30 17:40:29 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-30 17:42:26 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1186, -0.1628, -0.1582,  ..., -0.9209, -0.5444,  0.1908],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.6836, -5.1641, -1.6562,  ..., -2.8984, -4.7188, -5.3320],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0358, -0.0170,  0.0013,  ..., -0.0042,  0.0113, -0.0018],
        [ 0.0017,  0.0573, -0.0139,  ...,  0.0009, -0.0141,  0.0098],
        [ 0.0076, -0.0158,  0.0391,  ...,  0.0049,  0.0038, -0.0005],
        ...,
        [-0.0187,  0.0263, -0.0167,  ...,  0.0348, -0.0066,  0.0079],
        [-0.0099,  0.0103, -0.0031,  ...,  0.0031,  0.0538, -0.0160],
        [ 0.0231, -0.0023, -0.0024,  ...,  0.0047, -0.0072,  0.0538]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.6426, -4.7930, -1.6582,  ..., -2.6387, -4.6992, -5.3906]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 17:42:28 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Something without spine is spineless
Something without leg is legless
Something without hair is hairless
Something without emotion is emotionless
Something without heart is heartless
Something without bone is boneless
Something without remorse is remorseless
Something without effort is
2024-07-30 17:42:28 root INFO     [order_1_approx] starting weight calculation for Something without effort is effortless
Something without leg is legless
Something without heart is heartless
Something without hair is hairless
Something without bone is boneless
Something without spine is spineless
Something without emotion is emotionless
Something without remorse is
2024-07-30 17:42:28 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-30 17:44:24 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([0.2585, 0.0144, 0.1088,  ..., 0.1051, 0.2617, 0.2886], device='cuda:1',
       dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.8086, -3.5586,  0.0605,  ..., -4.1406, -1.7949, -1.8457],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 3.6713e-02, -1.3046e-02,  7.1602e-03,  ...,  3.5439e-03,
          1.2718e-02,  5.2032e-03],
        [ 7.4425e-03,  4.4617e-02, -3.1967e-03,  ..., -2.6112e-03,
         -5.4474e-03, -2.4929e-03],
        [ 1.0513e-02, -7.7248e-03,  4.0985e-02,  ...,  7.8201e-05,
         -1.2703e-03, -4.7760e-03],
        ...,
        [-2.7895e-04, -5.9509e-04, -8.3237e-03,  ...,  2.8839e-02,
         -1.1658e-02,  1.1032e-02],
        [-1.1444e-04,  4.3373e-03,  1.1948e-02,  ..., -9.1858e-03,
          4.7455e-02, -1.4252e-02],
        [ 1.7761e-02, -1.1452e-02, -1.0185e-03,  ..., -1.1726e-02,
         -2.1790e-02,  4.7363e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.8555, -3.8730,  0.1659,  ..., -4.2422, -2.0293, -2.1348]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 17:44:25 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Something without effort is effortless
Something without leg is legless
Something without heart is heartless
Something without hair is hairless
Something without bone is boneless
Something without spine is spineless
Something without emotion is emotionless
Something without remorse is
2024-07-30 17:44:25 root INFO     [order_1_approx] starting weight calculation for Something without hair is hairless
Something without spine is spineless
Something without remorse is remorseless
Something without heart is heartless
Something without effort is effortless
Something without emotion is emotionless
Something without bone is boneless
Something without leg is
2024-07-30 17:44:25 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-30 17:46:17 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.7461,  0.0310, -0.1466,  ..., -0.3599,  0.0891, -0.3752],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.8018, -4.3711, -0.9487,  ..., -1.3525, -1.4678, -2.2031],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0461, -0.0262,  0.0066,  ...,  0.0112,  0.0077,  0.0015],
        [ 0.0069,  0.0449, -0.0019,  ...,  0.0162,  0.0089, -0.0035],
        [ 0.0161, -0.0005,  0.0321,  ..., -0.0152, -0.0091, -0.0066],
        ...,
        [ 0.0002,  0.0126, -0.0111,  ...,  0.0466, -0.0048, -0.0033],
        [-0.0247,  0.0233, -0.0101,  ..., -0.0150,  0.0327, -0.0113],
        [-0.0021,  0.0039,  0.0019,  ..., -0.0064, -0.0175,  0.0230]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.0293, -3.9824, -1.2861,  ..., -1.4014, -1.8320, -2.2246]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 17:46:18 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Something without hair is hairless
Something without spine is spineless
Something without remorse is remorseless
Something without heart is heartless
Something without effort is effortless
Something without emotion is emotionless
Something without bone is boneless
Something without leg is
2024-07-30 17:46:18 root INFO     [order_1_approx] starting weight calculation for Something without leg is legless
Something without spine is spineless
Something without remorse is remorseless
Something without effort is effortless
Something without heart is heartless
Something without bone is boneless
Something without hair is hairless
Something without emotion is
2024-07-30 17:46:18 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-30 17:48:12 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0370, -0.5283,  0.0189,  ..., -0.6147,  0.0269,  0.3413],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.9590, -1.6914, -0.1289,  ..., -3.4141, -2.1719, -3.1680],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0411, -0.0081,  0.0109,  ..., -0.0029,  0.0027,  0.0119],
        [-0.0124,  0.0520, -0.0151,  ...,  0.0082, -0.0038, -0.0060],
        [ 0.0055, -0.0131,  0.0187,  ...,  0.0096, -0.0168, -0.0025],
        ...,
        [ 0.0034,  0.0139, -0.0102,  ...,  0.0260, -0.0041,  0.0015],
        [-0.0074,  0.0123,  0.0042,  ..., -0.0140,  0.0341, -0.0132],
        [ 0.0079, -0.0096,  0.0004,  ...,  0.0090,  0.0084,  0.0284]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.7637, -1.6582, -0.3113,  ..., -3.1230, -2.4766, -3.0195]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 17:48:13 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Something without leg is legless
Something without spine is spineless
Something without remorse is remorseless
Something without effort is effortless
Something without heart is heartless
Something without bone is boneless
Something without hair is hairless
Something without emotion is
2024-07-30 17:48:13 root INFO     total operator prediction time: 942.4003570079803 seconds
2024-07-30 17:48:13 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on adj+ness_reg
2024-07-30 17:48:13 root INFO     building operator adj+ness_reg
2024-07-30 17:48:14 root INFO     [order_1_approx] starting weight calculation for The state of being broken is brokenness
The state of being aware is awareness
The state of being distinctive is distinctiveness
The state of being fixed is fixedness
The state of being impressive is impressiveness
The state of being odd is oddness
The state of being directed is directedness
The state of being amazing is
2024-07-30 17:48:14 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-30 17:50:08 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1603,  0.0452, -0.2068,  ..., -0.7925, -0.5801, -0.4189],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.0586, -1.6797, -1.3486,  ..., -2.1621, -4.0352, -3.4688],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0496, -0.0050, -0.0014,  ..., -0.0018, -0.0171, -0.0028],
        [-0.0064,  0.0576,  0.0095,  ...,  0.0149,  0.0247,  0.0129],
        [ 0.0099, -0.0173,  0.0349,  ..., -0.0106, -0.0137, -0.0077],
        ...,
        [ 0.0076,  0.0120,  0.0007,  ...,  0.0410, -0.0044,  0.0078],
        [ 0.0213,  0.0146,  0.0144,  ..., -0.0044,  0.0331, -0.0047],
        [-0.0015,  0.0042, -0.0043,  ...,  0.0013, -0.0019,  0.0511]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.9941, -1.7510, -1.4297,  ..., -2.0117, -4.0234, -3.4336]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 17:50:09 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The state of being broken is brokenness
The state of being aware is awareness
The state of being distinctive is distinctiveness
The state of being fixed is fixedness
The state of being impressive is impressiveness
The state of being odd is oddness
The state of being directed is directedness
The state of being amazing is
2024-07-30 17:50:10 root INFO     [order_1_approx] starting weight calculation for The state of being amazing is amazingness
The state of being directed is directedness
The state of being broken is brokenness
The state of being fixed is fixedness
The state of being odd is oddness
The state of being distinctive is distinctiveness
The state of being aware is awareness
The state of being impressive is
2024-07-30 17:50:10 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-30 17:52:08 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0667,  0.1892, -0.1702,  ..., -0.3127, -0.3645, -0.1411],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.9375, -2.7090, -2.4102,  ..., -1.5986, -5.7656, -4.8047],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0509,  0.0006,  0.0064,  ..., -0.0106, -0.0120,  0.0077],
        [-0.0018,  0.0569,  0.0011,  ...,  0.0104,  0.0106, -0.0050],
        [ 0.0147, -0.0043,  0.0527,  ..., -0.0106, -0.0007, -0.0012],
        ...,
        [ 0.0023, -0.0034, -0.0015,  ...,  0.0488, -0.0045,  0.0028],
        [ 0.0265,  0.0174,  0.0126,  ..., -0.0095,  0.0387, -0.0113],
        [ 0.0036,  0.0048, -0.0039,  ...,  0.0020, -0.0142,  0.0424]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.7891, -2.9043, -2.4492,  ..., -1.4619, -5.7969, -4.6914]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 17:52:09 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The state of being amazing is amazingness
The state of being directed is directedness
The state of being broken is brokenness
The state of being fixed is fixedness
The state of being odd is oddness
The state of being distinctive is distinctiveness
The state of being aware is awareness
The state of being impressive is
2024-07-30 17:52:09 root INFO     [order_1_approx] starting weight calculation for The state of being broken is brokenness
The state of being aware is awareness
The state of being amazing is amazingness
The state of being odd is oddness
The state of being directed is directedness
The state of being distinctive is distinctiveness
The state of being impressive is impressiveness
The state of being fixed is
2024-07-30 17:52:09 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-30 17:54:09 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0168, -0.2964, -1.0566,  ..., -0.2131, -0.2781,  0.7607],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.7539, -4.6523,  0.6934,  ...,  0.3210, -3.2871, -2.2148],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0997,  0.0055,  0.0179,  ..., -0.0129,  0.0024,  0.0259],
        [-0.0002,  0.0846, -0.0106,  ...,  0.0200, -0.0044, -0.0124],
        [ 0.0004, -0.0051,  0.0709,  ..., -0.0201, -0.0061, -0.0057],
        ...,
        [ 0.0023, -0.0039, -0.0059,  ...,  0.1079, -0.0192, -0.0072],
        [-0.0012,  0.0018, -0.0036,  ...,  0.0018,  0.0798, -0.0186],
        [ 0.0016,  0.0108, -0.0182,  ..., -0.0016, -0.0104,  0.0941]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.0762, -4.2305,  0.6455,  ...,  0.0046, -3.8613, -2.2324]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 17:54:10 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The state of being broken is brokenness
The state of being aware is awareness
The state of being amazing is amazingness
The state of being odd is oddness
The state of being directed is directedness
The state of being distinctive is distinctiveness
The state of being impressive is impressiveness
The state of being fixed is
2024-07-30 17:54:10 root INFO     [order_1_approx] starting weight calculation for The state of being impressive is impressiveness
The state of being amazing is amazingness
The state of being distinctive is distinctiveness
The state of being broken is brokenness
The state of being directed is directedness
The state of being odd is oddness
The state of being fixed is fixedness
The state of being aware is
2024-07-30 17:54:10 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-30 17:56:09 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1970,  0.0385, -0.4282,  ..., -0.0541,  0.2815,  0.1910],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.4189, -2.4766, -0.4717,  ..., -0.6216, -4.7695,  0.5273],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0748, -0.0061,  0.0009,  ...,  0.0085, -0.0023,  0.0233],
        [-0.0042,  0.0651,  0.0070,  ...,  0.0074,  0.0100,  0.0048],
        [ 0.0073, -0.0109,  0.0559,  ..., -0.0250, -0.0128,  0.0060],
        ...,
        [ 0.0103,  0.0188, -0.0151,  ...,  0.0576, -0.0181,  0.0137],
        [ 0.0145,  0.0071,  0.0144,  ..., -0.0078,  0.0546, -0.0232],
        [ 0.0086,  0.0041, -0.0096,  ..., -0.0065, -0.0128,  0.0740]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.7539, -2.3672, -0.8252,  ..., -0.7793, -4.9609,  0.4331]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 17:56:10 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The state of being impressive is impressiveness
The state of being amazing is amazingness
The state of being distinctive is distinctiveness
The state of being broken is brokenness
The state of being directed is directedness
The state of being odd is oddness
The state of being fixed is fixedness
The state of being aware is
2024-07-30 17:56:10 root INFO     [order_1_approx] starting weight calculation for The state of being fixed is fixedness
The state of being distinctive is distinctiveness
The state of being odd is oddness
The state of being aware is awareness
The state of being impressive is impressiveness
The state of being amazing is amazingness
The state of being broken is brokenness
The state of being directed is
2024-07-30 17:56:10 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-30 17:58:09 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2954, -0.0520, -0.3054,  ...,  0.0727, -0.6201,  0.3696],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.4844, -4.4961, -1.8135,  ...,  1.2559, -3.8418, -5.0742],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0947,  0.0091,  0.0017,  ...,  0.0005,  0.0085,  0.0156],
        [-0.0169,  0.0936,  0.0069,  ...,  0.0185, -0.0048, -0.0077],
        [ 0.0137, -0.0012,  0.0583,  ..., -0.0305, -0.0192, -0.0161],
        ...,
        [ 0.0137,  0.0018, -0.0184,  ...,  0.0836, -0.0107,  0.0025],
        [ 0.0074,  0.0160,  0.0121,  ..., -0.0127,  0.0575, -0.0239],
        [ 0.0088,  0.0004,  0.0106,  ...,  0.0034, -0.0084,  0.0782]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.8398, -4.6406, -1.7168,  ...,  1.4600, -4.0391, -4.6719]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 17:58:09 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The state of being fixed is fixedness
The state of being distinctive is distinctiveness
The state of being odd is oddness
The state of being aware is awareness
The state of being impressive is impressiveness
The state of being amazing is amazingness
The state of being broken is brokenness
The state of being directed is
2024-07-30 17:58:10 root INFO     [order_1_approx] starting weight calculation for The state of being directed is directedness
The state of being fixed is fixedness
The state of being aware is awareness
The state of being impressive is impressiveness
The state of being amazing is amazingness
The state of being broken is brokenness
The state of being distinctive is distinctiveness
The state of being odd is
2024-07-30 17:58:10 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-30 18:00:10 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.5605,  0.2158,  0.4409,  ..., -0.6440, -0.2256,  0.2510],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.7173, -3.3633, -3.0996,  ..., -3.6777, -5.0156, -1.7295],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0593,  0.0095,  0.0180,  ...,  0.0090, -0.0056,  0.0081],
        [ 0.0148,  0.0558,  0.0009,  ...,  0.0144,  0.0082,  0.0011],
        [ 0.0200, -0.0077,  0.0643,  ..., -0.0075,  0.0028,  0.0026],
        ...,
        [ 0.0016,  0.0011,  0.0030,  ...,  0.0365, -0.0195, -0.0096],
        [ 0.0100,  0.0096,  0.0084,  ..., -0.0164,  0.0414, -0.0225],
        [ 0.0146, -0.0081, -0.0154,  ...,  0.0011, -0.0069,  0.0429]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.3440, -3.2129, -3.2617,  ..., -3.5547, -5.2812, -1.8789]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 18:00:11 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The state of being directed is directedness
The state of being fixed is fixedness
The state of being aware is awareness
The state of being impressive is impressiveness
The state of being amazing is amazingness
The state of being broken is brokenness
The state of being distinctive is distinctiveness
The state of being odd is
2024-07-30 18:00:11 root INFO     [order_1_approx] starting weight calculation for The state of being broken is brokenness
The state of being impressive is impressiveness
The state of being aware is awareness
The state of being fixed is fixedness
The state of being amazing is amazingness
The state of being odd is oddness
The state of being directed is directedness
The state of being distinctive is
2024-07-30 18:00:11 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-30 18:02:09 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1702, -0.4929, -0.4106,  ..., -0.1396, -0.3999, -0.0599],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.2549, -2.5410, -1.3594,  ..., -1.9375, -4.2031, -1.2529],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0328, -0.0006,  0.0130,  ..., -0.0022,  0.0058,  0.0100],
        [-0.0055,  0.0440,  0.0078,  ...,  0.0109,  0.0141, -0.0021],
        [ 0.0087, -0.0133,  0.0315,  ..., -0.0141, -0.0031,  0.0046],
        ...,
        [ 0.0084,  0.0022,  0.0033,  ...,  0.0292, -0.0082, -0.0005],
        [ 0.0128,  0.0021,  0.0075,  ..., -0.0028,  0.0254, -0.0081],
        [ 0.0058,  0.0060, -0.0064,  ..., -0.0040, -0.0164,  0.0278]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.2617, -2.8828, -1.2666,  ..., -2.0234, -4.1953, -1.3340]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 18:02:10 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The state of being broken is brokenness
The state of being impressive is impressiveness
The state of being aware is awareness
The state of being fixed is fixedness
The state of being amazing is amazingness
The state of being odd is oddness
The state of being directed is directedness
The state of being distinctive is
2024-07-30 18:02:11 root INFO     [order_1_approx] starting weight calculation for The state of being fixed is fixedness
The state of being aware is awareness
The state of being odd is oddness
The state of being directed is directedness
The state of being impressive is impressiveness
The state of being amazing is amazingness
The state of being distinctive is distinctiveness
The state of being broken is
2024-07-30 18:02:11 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-30 18:04:11 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0490, -0.0839,  0.0259,  ..., -0.0694, -0.1570, -0.0838],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.3730, -4.4609, -1.0283,  ..., -2.0469,  0.5469, -1.0352],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.1136,  0.0059,  0.0008,  ..., -0.0137, -0.0100,  0.0256],
        [ 0.0088,  0.0854,  0.0025,  ...,  0.0217,  0.0045, -0.0038],
        [ 0.0250, -0.0159,  0.0823,  ..., -0.0004, -0.0014, -0.0091],
        ...,
        [ 0.0069,  0.0103, -0.0009,  ...,  0.0873, -0.0148, -0.0011],
        [-0.0094,  0.0032,  0.0058,  ...,  0.0047,  0.0768, -0.0225],
        [-0.0126,  0.0091, -0.0096,  ..., -0.0126, -0.0032,  0.0856]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.5947, -4.4766, -0.8115,  ..., -2.0000,  0.1965, -1.0664]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 18:04:12 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The state of being fixed is fixedness
The state of being aware is awareness
The state of being odd is oddness
The state of being directed is directedness
The state of being impressive is impressiveness
The state of being amazing is amazingness
The state of being distinctive is distinctiveness
The state of being broken is
2024-07-30 18:04:12 root INFO     total operator prediction time: 958.4594838619232 seconds
2024-07-30 18:04:12 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on re+verb_reg
2024-07-30 18:04:12 root INFO     building operator re+verb_reg
2024-07-30 18:04:12 root INFO     [order_1_approx] starting weight calculation for To grow again is to regrow
To cognize again is to recognize
To tell again is to retell
To marry again is to remarry
To integrate again is to reintegrate
To organize again is to reorganize
To configure again is to reconfigure
To emerge again is to
2024-07-30 18:04:12 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-30 18:06:04 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1836, -0.1713, -0.2700,  ..., -0.0388, -0.1770,  0.7100],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.6113, -1.1211, -0.6602,  ...,  3.5469, -5.9023, -2.8320],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0725,  0.0075, -0.0052,  ...,  0.0004,  0.0030,  0.0228],
        [-0.0091,  0.0518,  0.0114,  ...,  0.0052,  0.0048, -0.0061],
        [ 0.0044,  0.0098,  0.0490,  ...,  0.0028, -0.0075, -0.0147],
        ...,
        [ 0.0005,  0.0028, -0.0015,  ...,  0.0651, -0.0150, -0.0014],
        [ 0.0021,  0.0266, -0.0141,  ..., -0.0007,  0.0612, -0.0217],
        [-0.0076, -0.0078, -0.0002,  ..., -0.0114, -0.0254,  0.0583]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.7432, -1.1406, -0.4717,  ...,  3.6406, -6.2734, -2.5273]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 18:06:05 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To grow again is to regrow
To cognize again is to recognize
To tell again is to retell
To marry again is to remarry
To integrate again is to reintegrate
To organize again is to reorganize
To configure again is to reconfigure
To emerge again is to
2024-07-30 18:06:05 root INFO     [order_1_approx] starting weight calculation for To marry again is to remarry
To tell again is to retell
To grow again is to regrow
To configure again is to reconfigure
To organize again is to reorganize
To cognize again is to recognize
To emerge again is to reemerge
To integrate again is to
2024-07-30 18:06:06 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-30 18:08:02 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0815,  0.2559, -0.2128,  ...,  0.0489, -0.2659,  0.3379],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.2529, -2.7188,  1.4668,  ...,  1.6543, -4.5938, -4.7812],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0789,  0.0106,  0.0122,  ..., -0.0033,  0.0058,  0.0184],
        [-0.0172,  0.0791,  0.0013,  ...,  0.0258, -0.0051,  0.0100],
        [ 0.0058,  0.0103,  0.0690,  ..., -0.0116,  0.0075, -0.0080],
        ...,
        [ 0.0004, -0.0009, -0.0107,  ...,  0.0811, -0.0034, -0.0096],
        [ 0.0009,  0.0057,  0.0086,  ..., -0.0139,  0.0695, -0.0326],
        [-0.0031, -0.0014, -0.0184,  ..., -0.0059, -0.0183,  0.0720]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.4341, -2.4355,  1.7383,  ...,  1.7607, -4.4883, -4.5625]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 18:08:03 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To marry again is to remarry
To tell again is to retell
To grow again is to regrow
To configure again is to reconfigure
To organize again is to reorganize
To cognize again is to recognize
To emerge again is to reemerge
To integrate again is to
2024-07-30 18:08:04 root INFO     [order_1_approx] starting weight calculation for To cognize again is to recognize
To integrate again is to reintegrate
To emerge again is to reemerge
To grow again is to regrow
To configure again is to reconfigure
To organize again is to reorganize
To marry again is to remarry
To tell again is to
2024-07-30 18:08:04 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-30 18:10:00 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2209, -0.0091,  0.5391,  ..., -0.4539, -0.0920,  0.3435],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.6431, -2.4512,  0.9395,  ...,  0.2896, -5.1445, -2.2539],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0695,  0.0094,  0.0079,  ..., -0.0061, -0.0177,  0.0180],
        [-0.0062,  0.0424,  0.0070,  ...,  0.0188,  0.0085,  0.0092],
        [ 0.0059,  0.0064,  0.0541,  ..., -0.0038, -0.0055, -0.0072],
        ...,
        [ 0.0161, -0.0107, -0.0046,  ...,  0.0735, -0.0134,  0.0059],
        [ 0.0027,  0.0039,  0.0153,  ..., -0.0090,  0.0529, -0.0118],
        [-0.0008, -0.0058, -0.0113,  ..., -0.0008, -0.0146,  0.0558]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.5669, -2.3848,  1.1641,  ...,  0.3003, -5.1094, -2.4004]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 18:10:01 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To cognize again is to recognize
To integrate again is to reintegrate
To emerge again is to reemerge
To grow again is to regrow
To configure again is to reconfigure
To organize again is to reorganize
To marry again is to remarry
To tell again is to
2024-07-30 18:10:01 root INFO     [order_1_approx] starting weight calculation for To cognize again is to recognize
To marry again is to remarry
To grow again is to regrow
To integrate again is to reintegrate
To tell again is to retell
To organize again is to reorganize
To emerge again is to reemerge
To configure again is to
2024-07-30 18:10:01 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-30 18:11:58 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3286, -0.0772, -0.6421,  ..., -0.1252, -0.4214, -0.0194],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.0664, -1.6436,  2.4160,  ...,  3.8242, -3.0977, -3.5898],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0904,  0.0046,  0.0161,  ..., -0.0046,  0.0065,  0.0138],
        [-0.0064,  0.0873, -0.0064,  ...,  0.0256,  0.0245,  0.0042],
        [ 0.0070,  0.0218,  0.0805,  ..., -0.0329,  0.0131, -0.0225],
        ...,
        [ 0.0087, -0.0019, -0.0182,  ...,  0.0883, -0.0154, -0.0089],
        [ 0.0087,  0.0145,  0.0003,  ..., -0.0154,  0.0812, -0.0396],
        [-0.0049,  0.0008, -0.0144,  ..., -0.0178, -0.0319,  0.0638]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.1289, -1.6084,  2.2695,  ...,  3.8984, -3.2988, -3.6016]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 18:11:59 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To cognize again is to recognize
To marry again is to remarry
To grow again is to regrow
To integrate again is to reintegrate
To tell again is to retell
To organize again is to reorganize
To emerge again is to reemerge
To configure again is to
2024-07-30 18:11:59 root INFO     [order_1_approx] starting weight calculation for To integrate again is to reintegrate
To organize again is to reorganize
To tell again is to retell
To configure again is to reconfigure
To marry again is to remarry
To emerge again is to reemerge
To cognize again is to recognize
To grow again is to
2024-07-30 18:11:59 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-30 18:13:54 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0851, -0.1700,  0.2137,  ..., -0.4482, -0.9702,  0.0570],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.5977, -2.8535, -0.1211,  ...,  0.1045, -6.3828, -3.5469],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0764, -0.0030,  0.0212,  ...,  0.0083,  0.0018,  0.0251],
        [-0.0035,  0.0564, -0.0105,  ...,  0.0090, -0.0039,  0.0174],
        [ 0.0190, -0.0105,  0.0460,  ..., -0.0052,  0.0072, -0.0198],
        ...,
        [-0.0074,  0.0130, -0.0020,  ...,  0.0884, -0.0217, -0.0021],
        [-0.0037,  0.0255, -0.0056,  ..., -0.0090,  0.0544, -0.0404],
        [-0.0066,  0.0021, -0.0155,  ..., -0.0125, -0.0177,  0.0663]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.3760, -3.2812, -0.1924,  ..., -0.0190, -5.9922, -3.4551]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 18:13:55 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To integrate again is to reintegrate
To organize again is to reorganize
To tell again is to retell
To configure again is to reconfigure
To marry again is to remarry
To emerge again is to reemerge
To cognize again is to recognize
To grow again is to
2024-07-30 18:13:55 root INFO     [order_1_approx] starting weight calculation for To cognize again is to recognize
To configure again is to reconfigure
To integrate again is to reintegrate
To grow again is to regrow
To emerge again is to reemerge
To marry again is to remarry
To tell again is to retell
To organize again is to
2024-07-30 18:13:56 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-30 18:15:47 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4351,  0.7295, -0.1228,  ..., -0.3984, -0.4331,  0.3003],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.2227, -3.1895,  1.4150,  ...,  1.4316, -1.6768, -4.2109],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 6.6040e-02,  1.1005e-03,  1.5480e-02,  ..., -2.6398e-03,
         -6.3705e-04,  1.0689e-02],
        [ 1.2207e-03,  6.1401e-02, -6.3477e-03,  ...,  1.3161e-02,
          7.4692e-03,  8.5068e-04],
        [ 2.5330e-03,  8.0719e-03,  4.4037e-02,  ..., -1.8291e-03,
          2.2888e-05, -7.3242e-03],
        ...,
        [ 1.2732e-03, -5.0735e-03, -4.6425e-03,  ...,  5.8502e-02,
         -1.3382e-02, -2.1477e-03],
        [-1.0185e-02,  9.7885e-03,  1.0252e-05,  ..., -1.3733e-02,
          5.6763e-02, -1.3855e-02],
        [ 2.9411e-03, -6.3477e-03, -1.0056e-02,  ..., -1.1330e-02,
         -2.2125e-02,  5.7007e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.2363, -3.3418,  1.4756,  ...,  1.4434, -1.8906, -4.0859]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 18:15:48 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To cognize again is to recognize
To configure again is to reconfigure
To integrate again is to reintegrate
To grow again is to regrow
To emerge again is to reemerge
To marry again is to remarry
To tell again is to retell
To organize again is to
2024-07-30 18:15:48 root INFO     [order_1_approx] starting weight calculation for To integrate again is to reintegrate
To tell again is to retell
To configure again is to reconfigure
To organize again is to reorganize
To cognize again is to recognize
To grow again is to regrow
To emerge again is to reemerge
To marry again is to
2024-07-30 18:15:48 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-30 18:17:44 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0377,  0.0759, -0.0833,  ..., -0.0159, -1.0420,  0.7734],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.4272, -2.8184,  2.1621,  ..., -1.3398, -5.8320, -3.6211],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0623,  0.0026,  0.0083,  ...,  0.0106,  0.0039,  0.0159],
        [-0.0084,  0.0467, -0.0071,  ...,  0.0109, -0.0015,  0.0081],
        [ 0.0145,  0.0006,  0.0464,  ..., -0.0147, -0.0148, -0.0103],
        ...,
        [ 0.0015,  0.0017,  0.0010,  ...,  0.0688, -0.0067, -0.0008],
        [-0.0055,  0.0178,  0.0108,  ..., -0.0100,  0.0466, -0.0087],
        [ 0.0012,  0.0044, -0.0098,  ...,  0.0026, -0.0126,  0.0610]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.5000, -2.7734,  2.1309,  ..., -1.0439, -5.8828, -3.6543]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 18:17:45 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To integrate again is to reintegrate
To tell again is to retell
To configure again is to reconfigure
To organize again is to reorganize
To cognize again is to recognize
To grow again is to regrow
To emerge again is to reemerge
To marry again is to
2024-07-30 18:17:45 root INFO     [order_1_approx] starting weight calculation for To tell again is to retell
To organize again is to reorganize
To marry again is to remarry
To emerge again is to reemerge
To integrate again is to reintegrate
To configure again is to reconfigure
To grow again is to regrow
To cognize again is to
2024-07-30 18:17:45 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-30 18:19:42 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1973,  0.0365,  0.0965,  ..., -0.3826, -0.5869,  0.4956],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-3.5996, -2.4531,  2.8438,  ...,  0.6997, -3.5566, -1.5488],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0641, -0.0135,  0.0151,  ...,  0.0060, -0.0058,  0.0124],
        [-0.0012,  0.0534, -0.0022,  ...,  0.0188, -0.0090,  0.0016],
        [-0.0029, -0.0033,  0.0398,  ..., -0.0192,  0.0117, -0.0048],
        ...,
        [ 0.0182,  0.0085, -0.0118,  ...,  0.0668, -0.0150,  0.0102],
        [-0.0032,  0.0145,  0.0161,  ..., -0.0101,  0.0415, -0.0159],
        [-0.0046, -0.0063, -0.0107,  ..., -0.0145, -0.0171,  0.0468]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-3.2988, -2.3008,  2.8867,  ...,  1.2705, -3.3828, -1.7129]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 18:19:43 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To tell again is to retell
To organize again is to reorganize
To marry again is to remarry
To emerge again is to reemerge
To integrate again is to reintegrate
To configure again is to reconfigure
To grow again is to regrow
To cognize again is to
2024-07-30 18:19:43 root INFO     total operator prediction time: 930.7964408397675 seconds
2024-07-30 18:19:43 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on un+adj_reg
2024-07-30 18:19:43 root INFO     building operator un+adj_reg
2024-07-30 18:19:43 root INFO     [order_1_approx] starting weight calculation for The opposite of specified is unspecified
The opposite of related is unrelated
The opposite of reliable is unreliable
The opposite of lawful is unlawful
The opposite of fortunate is unfortunate
The opposite of predictable is unpredictable
The opposite of employed is unemployed
The opposite of conscious is
2024-07-30 18:19:43 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-30 18:21:43 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0242,  0.2720, -0.3921,  ...,  0.0600,  0.0624,  0.4824],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.6016, -0.6924,  4.0625,  ..., -1.8379,  1.7305, -1.4912],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0757, -0.0202, -0.0014,  ...,  0.0070, -0.0021,  0.0129],
        [-0.0078,  0.0541, -0.0164,  ...,  0.0178,  0.0114,  0.0121],
        [-0.0122, -0.0185,  0.0454,  ..., -0.0006, -0.0287, -0.0024],
        ...,
        [ 0.0108,  0.0161,  0.0046,  ...,  0.0554, -0.0144, -0.0071],
        [-0.0146, -0.0094,  0.0147,  ..., -0.0083,  0.0714, -0.0424],
        [-0.0037,  0.0034, -0.0036,  ..., -0.0210, -0.0108,  0.0715]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.2969, -0.2476,  4.1641,  ..., -1.6484,  1.9141, -1.9424]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 18:21:44 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of specified is unspecified
The opposite of related is unrelated
The opposite of reliable is unreliable
The opposite of lawful is unlawful
The opposite of fortunate is unfortunate
The opposite of predictable is unpredictable
The opposite of employed is unemployed
The opposite of conscious is
2024-07-30 18:21:44 root INFO     [order_1_approx] starting weight calculation for The opposite of lawful is unlawful
The opposite of employed is unemployed
The opposite of specified is unspecified
The opposite of conscious is unconscious
The opposite of fortunate is unfortunate
The opposite of predictable is unpredictable
The opposite of related is unrelated
The opposite of reliable is
2024-07-30 18:21:44 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-30 18:23:42 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2101, -0.1895, -0.7275,  ..., -0.2463,  0.2705, -0.3784],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.5200, -1.4678, -0.5796,  ...,  0.5601, -0.1484, -2.6016],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0682, -0.0266,  0.0125,  ..., -0.0071,  0.0069,  0.0182],
        [-0.0260,  0.0968, -0.0012,  ...,  0.0321,  0.0219,  0.0161],
        [ 0.0058,  0.0059,  0.0533,  ..., -0.0230,  0.0006, -0.0013],
        ...,
        [ 0.0011,  0.0270, -0.0138,  ...,  0.0528, -0.0270, -0.0098],
        [-0.0098, -0.0005,  0.0006,  ...,  0.0275,  0.0397, -0.0191],
        [ 0.0007, -0.0230, -0.0072,  ..., -0.0195,  0.0054,  0.0814]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.7490, -1.3486, -0.1873,  ...,  0.6431, -0.0159, -3.4336]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 18:23:43 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of lawful is unlawful
The opposite of employed is unemployed
The opposite of specified is unspecified
The opposite of conscious is unconscious
The opposite of fortunate is unfortunate
The opposite of predictable is unpredictable
The opposite of related is unrelated
The opposite of reliable is
2024-07-30 18:23:43 root INFO     [order_1_approx] starting weight calculation for The opposite of specified is unspecified
The opposite of lawful is unlawful
The opposite of reliable is unreliable
The opposite of conscious is unconscious
The opposite of predictable is unpredictable
The opposite of related is unrelated
The opposite of employed is unemployed
The opposite of fortunate is
2024-07-30 18:23:43 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-30 18:25:43 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1431,  1.1084, -0.5728,  ..., -0.3274, -0.4092,  0.2075],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.9297,  0.4707, -0.9297,  ..., -1.6680,  1.0430, -4.3984],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0405, -0.0204, -0.0033,  ...,  0.0063, -0.0051,  0.0284],
        [-0.0025,  0.0309,  0.0037,  ...,  0.0241,  0.0036,  0.0167],
        [-0.0004, -0.0082,  0.0273,  ..., -0.0089, -0.0144, -0.0058],
        ...,
        [ 0.0134,  0.0201, -0.0049,  ...,  0.0385,  0.0027,  0.0076],
        [ 0.0088, -0.0102,  0.0201,  ..., -0.0118,  0.0466, -0.0172],
        [ 0.0029, -0.0139, -0.0113,  ...,  0.0041, -0.0034,  0.0671]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.6562,  0.2357, -0.2861,  ..., -1.5752,  1.2471, -4.3164]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 18:25:44 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of specified is unspecified
The opposite of lawful is unlawful
The opposite of reliable is unreliable
The opposite of conscious is unconscious
The opposite of predictable is unpredictable
The opposite of related is unrelated
The opposite of employed is unemployed
The opposite of fortunate is
2024-07-30 18:25:44 root INFO     [order_1_approx] starting weight calculation for The opposite of fortunate is unfortunate
The opposite of lawful is unlawful
The opposite of predictable is unpredictable
The opposite of related is unrelated
The opposite of conscious is unconscious
The opposite of specified is unspecified
The opposite of reliable is unreliable
The opposite of employed is
2024-07-30 18:25:44 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-30 18:27:39 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2671,  0.0106, -0.2402,  ...,  0.1019, -0.5894, -0.0415],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.1396, -1.0566, -0.1348,  ...,  0.7549,  0.5259, -2.3242],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0660, -0.0143,  0.0102,  ...,  0.0050,  0.0052,  0.0025],
        [-0.0243,  0.0611, -0.0094,  ...,  0.0103,  0.0056,  0.0097],
        [-0.0082,  0.0006,  0.0315,  ..., -0.0087,  0.0063, -0.0049],
        ...,
        [ 0.0021,  0.0133, -0.0103,  ...,  0.0506, -0.0085, -0.0110],
        [-0.0022,  0.0082,  0.0153,  ..., -0.0109,  0.0465,  0.0289],
        [-0.0009,  0.0053, -0.0056,  ..., -0.0278,  0.0007,  0.0693]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.6406, -1.1543, -0.8921,  ...,  0.9048,  0.4180, -2.3027]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 18:27:40 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of fortunate is unfortunate
The opposite of lawful is unlawful
The opposite of predictable is unpredictable
The opposite of related is unrelated
The opposite of conscious is unconscious
The opposite of specified is unspecified
The opposite of reliable is unreliable
The opposite of employed is
2024-07-30 18:27:40 root INFO     [order_1_approx] starting weight calculation for The opposite of related is unrelated
The opposite of predictable is unpredictable
The opposite of employed is unemployed
The opposite of reliable is unreliable
The opposite of fortunate is unfortunate
The opposite of lawful is unlawful
The opposite of conscious is unconscious
The opposite of specified is
2024-07-30 18:27:40 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-30 18:29:36 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1484, -0.1389, -0.5908,  ...,  0.0979, -0.4556, -0.2490],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.5488,  1.0791,  0.9316,  ...,  1.8809,  0.4062, -1.4395],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0941,  0.0140,  0.0155,  ..., -0.0097,  0.0147,  0.0138],
        [-0.0294,  0.0662, -0.0121,  ...,  0.0144,  0.0002, -0.0003],
        [-0.0188,  0.0046,  0.0754,  ...,  0.0038,  0.0233, -0.0033],
        ...,
        [-0.0017,  0.0176, -0.0263,  ...,  0.0636, -0.0340,  0.0003],
        [ 0.0143,  0.0307,  0.0308,  ..., -0.0127,  0.0773,  0.0205],
        [-0.0118, -0.0075, -0.0229,  ..., -0.0370, -0.0090,  0.1001]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.0508,  0.8823,  1.1504,  ...,  2.3262, -0.1416, -1.1143]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 18:29:37 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of related is unrelated
The opposite of predictable is unpredictable
The opposite of employed is unemployed
The opposite of reliable is unreliable
The opposite of fortunate is unfortunate
The opposite of lawful is unlawful
The opposite of conscious is unconscious
The opposite of specified is
2024-07-30 18:29:37 root INFO     [order_1_approx] starting weight calculation for The opposite of conscious is unconscious
The opposite of reliable is unreliable
The opposite of related is unrelated
The opposite of specified is unspecified
The opposite of predictable is unpredictable
The opposite of employed is unemployed
The opposite of fortunate is unfortunate
The opposite of lawful is
2024-07-30 18:29:37 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-30 18:31:32 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4067,  0.0873, -0.2147,  ..., -0.3740, -0.4014, -0.3582],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.1509, -2.0352,  1.2148,  ...,  2.3457,  0.4746, -1.2607],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0520, -0.0105,  0.0121,  ..., -0.0128,  0.0080,  0.0163],
        [ 0.0173,  0.0615, -0.0134,  ...,  0.0252,  0.0075, -0.0012],
        [-0.0006,  0.0314,  0.0373,  ..., -0.0058, -0.0275,  0.0049],
        ...,
        [-0.0022,  0.0142, -0.0189,  ...,  0.0303, -0.0205, -0.0137],
        [-0.0097,  0.0095,  0.0110,  ..., -0.0107,  0.0371, -0.0190],
        [ 0.0132, -0.0041, -0.0338,  ..., -0.0227, -0.0206,  0.0757]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.1298, -2.1289,  1.4492,  ...,  2.5664,  0.6270, -1.4316]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 18:31:33 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of conscious is unconscious
The opposite of reliable is unreliable
The opposite of related is unrelated
The opposite of specified is unspecified
The opposite of predictable is unpredictable
The opposite of employed is unemployed
The opposite of fortunate is unfortunate
The opposite of lawful is
2024-07-30 18:31:33 root INFO     [order_1_approx] starting weight calculation for The opposite of employed is unemployed
The opposite of lawful is unlawful
The opposite of fortunate is unfortunate
The opposite of predictable is unpredictable
The opposite of specified is unspecified
The opposite of conscious is unconscious
The opposite of reliable is unreliable
The opposite of related is
2024-07-30 18:31:33 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-30 18:33:32 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0544, -0.0745, -0.4763,  ..., -0.3237, -0.1592, -0.5996],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.5234,  0.6636, -0.1494,  ..., -0.8320,  0.5098, -3.0137],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0624,  0.0013,  0.0311,  ...,  0.0072,  0.0342,  0.0271],
        [-0.0186,  0.0792, -0.0135,  ...,  0.0040, -0.0258, -0.0033],
        [-0.0095, -0.0201,  0.0742,  ...,  0.0094,  0.0014, -0.0102],
        ...,
        [ 0.0208,  0.0319, -0.0196,  ...,  0.0671, -0.0158, -0.0118],
        [ 0.0153,  0.0010,  0.0208,  ..., -0.0030,  0.0695, -0.0020],
        [ 0.0128, -0.0018, -0.0114,  ..., -0.0229, -0.0106,  0.0848]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.4199,  0.5352, -0.0902,  ..., -0.7202, -0.0234, -3.1270]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 18:33:35 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of employed is unemployed
The opposite of lawful is unlawful
The opposite of fortunate is unfortunate
The opposite of predictable is unpredictable
The opposite of specified is unspecified
The opposite of conscious is unconscious
The opposite of reliable is unreliable
The opposite of related is
2024-07-30 18:33:38 root INFO     [order_1_approx] starting weight calculation for The opposite of related is unrelated
The opposite of employed is unemployed
The opposite of fortunate is unfortunate
The opposite of conscious is unconscious
The opposite of reliable is unreliable
The opposite of specified is unspecified
The opposite of lawful is unlawful
The opposite of predictable is
2024-07-30 18:33:38 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-30 18:35:34 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1921,  0.4419, -0.3887,  ..., -0.2300,  0.2086,  0.2109],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.3945,  0.3247, -1.3242,  ...,  0.6064, -0.1328, -2.5918],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0485, -0.0046, -0.0011,  ..., -0.0121,  0.0165,  0.0141],
        [-0.0054,  0.0558,  0.0031,  ...,  0.0197,  0.0215,  0.0037],
        [ 0.0046, -0.0073,  0.0594,  ..., -0.0091, -0.0101,  0.0219],
        ...,
        [-0.0027,  0.0251, -0.0050,  ...,  0.0614, -0.0342, -0.0024],
        [ 0.0086,  0.0083,  0.0256,  ...,  0.0012,  0.0287, -0.0085],
        [ 0.0115, -0.0100, -0.0174,  ..., -0.0029, -0.0052,  0.0550]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.4707,  0.2737, -0.9521,  ...,  0.7593,  0.0411, -2.6074]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 18:35:35 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of related is unrelated
The opposite of employed is unemployed
The opposite of fortunate is unfortunate
The opposite of conscious is unconscious
The opposite of reliable is unreliable
The opposite of specified is unspecified
The opposite of lawful is unlawful
The opposite of predictable is
2024-07-30 18:35:35 root INFO     total operator prediction time: 952.6137492656708 seconds
2024-07-30 18:35:35 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on verb+able_reg
2024-07-30 18:35:35 root INFO     building operator verb+able_reg
2024-07-30 18:35:36 root INFO     [order_1_approx] starting weight calculation for If you can accept something, that thing is acceptable
If you can admire something, that thing is admirable
If you can avoid something, that thing is avoidable
If you can observe something, that thing is observable
If you can enjoy something, that thing is enjoyable
If you can identify something, that thing is identifiable
If you can prevent something, that thing is preventable
If you can believe something, that thing is
2024-07-30 18:35:36 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-30 18:37:32 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3184,  0.0883,  0.4717,  ..., -0.0735, -0.5059,  0.6294],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.3906, -0.8848,  0.6128,  ..., -3.8906, -6.1367, -2.6953],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 4.3365e-02, -7.4043e-03,  8.9111e-03,  ...,  2.0638e-03,
         -2.0599e-02,  7.4310e-03],
        [ 5.9509e-03,  3.1433e-02,  1.3641e-02,  ...,  1.0841e-02,
          1.5697e-03,  2.5196e-03],
        [ 3.2196e-03, -2.5940e-03,  3.6804e-02,  ..., -4.0817e-03,
         -1.9932e-03, -6.2790e-03],
        ...,
        [-2.5635e-03,  8.9264e-03, -7.1869e-03,  ...,  4.8462e-02,
         -1.3443e-02, -1.0460e-02],
        [ 1.5381e-02,  1.1162e-02, -1.2999e-03,  ..., -8.6823e-03,
          3.1738e-02, -1.2154e-02],
        [-6.1035e-05,  4.8790e-03, -1.2138e-02,  ...,  1.1044e-03,
          2.5749e-03,  3.1525e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.1641, -0.8794,  0.4229,  ..., -3.3828, -6.0938, -2.9785]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 18:37:33 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you can accept something, that thing is acceptable
If you can admire something, that thing is admirable
If you can avoid something, that thing is avoidable
If you can observe something, that thing is observable
If you can enjoy something, that thing is enjoyable
If you can identify something, that thing is identifiable
If you can prevent something, that thing is preventable
If you can believe something, that thing is
2024-07-30 18:37:33 root INFO     [order_1_approx] starting weight calculation for If you can admire something, that thing is admirable
If you can enjoy something, that thing is enjoyable
If you can observe something, that thing is observable
If you can believe something, that thing is believeable
If you can prevent something, that thing is preventable
If you can avoid something, that thing is avoidable
If you can accept something, that thing is acceptable
If you can identify something, that thing is
2024-07-30 18:37:33 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-30 18:39:31 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.5444, -0.0289,  0.2262,  ...,  0.6079, -0.5562, -0.7559],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.5078,  1.4873,  0.9609,  ..., -2.3359, -9.5078, -0.7910],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 7.7026e-02, -5.6000e-03,  8.3923e-05,  ...,  5.1880e-03,
         -8.4991e-03,  1.6357e-02],
        [-1.1169e-02,  6.6650e-02,  5.7220e-03,  ...,  9.7733e-03,
          4.9667e-03,  6.4392e-03],
        [ 8.9340e-03, -1.7578e-02,  7.1350e-02,  ..., -1.4481e-02,
         -3.7231e-03, -9.8267e-03],
        ...,
        [ 1.7578e-02,  2.6398e-03,  5.6152e-03,  ...,  8.3618e-02,
         -1.0391e-02, -4.5815e-03],
        [-6.8665e-05,  1.1749e-02,  2.5192e-02,  ..., -5.7449e-03,
          5.5939e-02, -1.8435e-03],
        [-3.0098e-03,  5.9853e-03, -3.2387e-03,  ...,  7.7362e-03,
         -1.7868e-02,  6.0883e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.4695,  1.3203,  0.9883,  ..., -2.4668, -9.1797, -0.6890]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 18:39:32 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you can admire something, that thing is admirable
If you can enjoy something, that thing is enjoyable
If you can observe something, that thing is observable
If you can believe something, that thing is believeable
If you can prevent something, that thing is preventable
If you can avoid something, that thing is avoidable
If you can accept something, that thing is acceptable
If you can identify something, that thing is
2024-07-30 18:39:33 root INFO     [order_1_approx] starting weight calculation for If you can identify something, that thing is identifiable
If you can prevent something, that thing is preventable
If you can enjoy something, that thing is enjoyable
If you can believe something, that thing is believeable
If you can avoid something, that thing is avoidable
If you can admire something, that thing is admirable
If you can observe something, that thing is observable
If you can accept something, that thing is
2024-07-30 18:39:33 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-30 18:41:31 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1021,  0.4365, -0.2227,  ...,  0.3208, -0.2578,  0.4438],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.9453,  1.3477, -2.9199,  ..., -2.6934, -8.4688, -1.2607],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0445, -0.0029, -0.0009,  ...,  0.0025, -0.0048,  0.0142],
        [-0.0080,  0.0396, -0.0013,  ...,  0.0102,  0.0001, -0.0145],
        [ 0.0076, -0.0013,  0.0464,  ..., -0.0122,  0.0005, -0.0177],
        ...,
        [ 0.0186,  0.0037, -0.0070,  ...,  0.0392, -0.0031, -0.0129],
        [ 0.0105,  0.0117,  0.0048,  ..., -0.0179,  0.0392, -0.0027],
        [ 0.0053,  0.0105, -0.0149,  ..., -0.0211, -0.0058,  0.0359]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.9053,  1.4424, -3.2852,  ..., -2.9180, -8.3516, -1.6934]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 18:41:32 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you can identify something, that thing is identifiable
If you can prevent something, that thing is preventable
If you can enjoy something, that thing is enjoyable
If you can believe something, that thing is believeable
If you can avoid something, that thing is avoidable
If you can admire something, that thing is admirable
If you can observe something, that thing is observable
If you can accept something, that thing is
2024-07-30 18:41:32 root INFO     [order_1_approx] starting weight calculation for If you can enjoy something, that thing is enjoyable
If you can believe something, that thing is believeable
If you can observe something, that thing is observable
If you can accept something, that thing is acceptable
If you can avoid something, that thing is avoidable
If you can admire something, that thing is admirable
If you can identify something, that thing is identifiable
If you can prevent something, that thing is
2024-07-30 18:41:32 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-30 18:43:28 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.3123, -0.6875,  0.3315,  ..., -0.0691,  0.1370, -0.2112],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.3652, -1.7617, -2.7598,  ..., -2.4570, -6.7266, -2.9648],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0654,  0.0185,  0.0178,  ...,  0.0070,  0.0030,  0.0309],
        [-0.0120,  0.0433,  0.0057,  ...,  0.0033,  0.0137,  0.0014],
        [ 0.0136, -0.0045,  0.0432,  ..., -0.0145,  0.0012, -0.0211],
        ...,
        [ 0.0115,  0.0015,  0.0003,  ...,  0.0605,  0.0019, -0.0002],
        [ 0.0157, -0.0034,  0.0152,  ..., -0.0130,  0.0523, -0.0160],
        [-0.0002,  0.0066,  0.0011,  ..., -0.0154, -0.0164,  0.0394]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.2236, -1.9434, -2.8887,  ..., -2.4961, -6.8203, -2.9941]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 18:43:30 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you can enjoy something, that thing is enjoyable
If you can believe something, that thing is believeable
If you can observe something, that thing is observable
If you can accept something, that thing is acceptable
If you can avoid something, that thing is avoidable
If you can admire something, that thing is admirable
If you can identify something, that thing is identifiable
If you can prevent something, that thing is
2024-07-30 18:43:31 root INFO     [order_1_approx] starting weight calculation for If you can identify something, that thing is identifiable
If you can enjoy something, that thing is enjoyable
If you can admire something, that thing is admirable
If you can believe something, that thing is believeable
If you can observe something, that thing is observable
If you can prevent something, that thing is preventable
If you can accept something, that thing is acceptable
If you can avoid something, that thing is
2024-07-30 18:43:31 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-30 18:45:25 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.5723, -0.1941,  0.1096,  ...,  0.0000,  0.8223, -0.0713],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.1953,  0.4766, -3.2363,  ..., -0.7676, -6.7539, -2.2891],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 6.1249e-02, -3.8223e-03,  6.3019e-03,  ..., -3.7498e-03,
          9.9335e-03,  4.1199e-02],
        [ 4.4060e-03,  3.4119e-02,  4.1199e-03,  ..., -6.9809e-03,
          9.9945e-04,  7.6294e-05],
        [ 2.3529e-02, -2.5406e-03,  4.4556e-02,  ..., -1.0773e-02,
         -8.4305e-03, -1.3794e-02],
        ...,
        [ 2.4689e-02,  1.6541e-02,  1.2636e-03,  ...,  5.1239e-02,
         -9.5596e-03, -6.1188e-03],
        [ 1.7075e-02,  5.2109e-03,  1.6571e-02,  ..., -1.4908e-02,
          5.4596e-02, -1.2886e-02],
        [ 7.8011e-03,  6.8703e-03, -5.3368e-03,  ..., -1.5869e-02,
         -1.9135e-02,  4.6234e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.0695,  0.2438, -3.4492,  ..., -1.0635, -6.7969, -2.3477]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 18:45:26 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you can identify something, that thing is identifiable
If you can enjoy something, that thing is enjoyable
If you can admire something, that thing is admirable
If you can believe something, that thing is believeable
If you can observe something, that thing is observable
If you can prevent something, that thing is preventable
If you can accept something, that thing is acceptable
If you can avoid something, that thing is
2024-07-30 18:45:27 root INFO     [order_1_approx] starting weight calculation for If you can avoid something, that thing is avoidable
If you can observe something, that thing is observable
If you can prevent something, that thing is preventable
If you can believe something, that thing is believeable
If you can enjoy something, that thing is enjoyable
If you can identify something, that thing is identifiable
If you can accept something, that thing is acceptable
If you can admire something, that thing is
2024-07-30 18:45:27 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-30 18:47:20 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([0.2089, 0.2157, 0.2253,  ..., 0.2825, 0.1982, 0.3960], device='cuda:1',
       dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 5.7031, -0.2769, -3.2656,  ..., -2.3672, -6.1250, -1.4277],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 5.8777e-02,  5.6686e-03,  3.8471e-03,  ..., -1.0513e-02,
         -6.4087e-03,  2.6932e-03],
        [-6.2943e-05,  4.3945e-02, -1.4486e-03,  ...,  1.4473e-02,
          2.9945e-03,  3.4733e-03],
        [ 4.4250e-03, -1.8482e-03,  5.3467e-02,  ...,  2.3422e-03,
         -6.5384e-03, -1.8341e-02],
        ...,
        [ 1.4557e-02,  1.1490e-02, -1.1314e-02,  ...,  5.2277e-02,
          4.1809e-03, -4.7760e-03],
        [ 2.6455e-03,  3.8605e-03,  7.4005e-03,  ..., -1.4900e-02,
          4.0314e-02, -2.1935e-05],
        [ 2.4929e-03,  3.1815e-03, -1.3306e-02,  ..., -7.8506e-03,
         -9.5520e-03,  3.9948e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 5.3750, -0.0541, -3.6465,  ..., -2.3379, -6.5625, -1.5010]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 18:47:21 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you can avoid something, that thing is avoidable
If you can observe something, that thing is observable
If you can prevent something, that thing is preventable
If you can believe something, that thing is believeable
If you can enjoy something, that thing is enjoyable
If you can identify something, that thing is identifiable
If you can accept something, that thing is acceptable
If you can admire something, that thing is
2024-07-30 18:47:21 root INFO     [order_1_approx] starting weight calculation for If you can accept something, that thing is acceptable
If you can enjoy something, that thing is enjoyable
If you can believe something, that thing is believeable
If you can avoid something, that thing is avoidable
If you can identify something, that thing is identifiable
If you can prevent something, that thing is preventable
If you can admire something, that thing is admirable
If you can observe something, that thing is
2024-07-30 18:47:21 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-30 18:49:18 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1028,  0.7124,  0.1271,  ..., -0.0145, -0.2101, -0.3975],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.0884, -0.7769, -1.2812,  ..., -4.5469, -6.7031, -0.7129],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0607,  0.0011,  0.0125,  ...,  0.0079, -0.0076,  0.0252],
        [-0.0076,  0.0491,  0.0003,  ...,  0.0017, -0.0047, -0.0033],
        [ 0.0047, -0.0062,  0.0540,  ..., -0.0082, -0.0027, -0.0176],
        ...,
        [ 0.0070, -0.0027, -0.0041,  ...,  0.0531,  0.0072, -0.0065],
        [ 0.0027,  0.0025,  0.0022,  ..., -0.0114,  0.0463, -0.0011],
        [ 0.0158,  0.0015, -0.0122,  ..., -0.0012, -0.0126,  0.0437]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.0665, -0.7266, -1.3320,  ..., -4.5781, -6.8125, -1.0156]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 18:49:19 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you can accept something, that thing is acceptable
If you can enjoy something, that thing is enjoyable
If you can believe something, that thing is believeable
If you can avoid something, that thing is avoidable
If you can identify something, that thing is identifiable
If you can prevent something, that thing is preventable
If you can admire something, that thing is admirable
If you can observe something, that thing is
2024-07-30 18:49:19 root INFO     [order_1_approx] starting weight calculation for If you can believe something, that thing is believeable
If you can observe something, that thing is observable
If you can prevent something, that thing is preventable
If you can identify something, that thing is identifiable
If you can avoid something, that thing is avoidable
If you can admire something, that thing is admirable
If you can accept something, that thing is acceptable
If you can enjoy something, that thing is
2024-07-30 18:49:19 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-30 18:51:15 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.3499, -0.4565,  0.2449,  ..., -0.4490, -0.5161, -0.0775],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.2422, -0.5537, -2.8047,  ..., -2.5684, -7.7148, -2.7012],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 3.5614e-02,  1.9073e-05,  2.1301e-02,  ...,  9.0790e-03,
         -2.3155e-03,  2.7313e-02],
        [-2.9678e-03,  4.8523e-02, -3.1414e-03,  ...,  5.4321e-03,
         -3.0365e-03,  5.0659e-03],
        [ 9.4070e-03,  5.5122e-03,  5.0293e-02,  ...,  9.6512e-04,
         -2.5604e-02, -2.0325e-02],
        ...,
        [ 1.4565e-02,  5.6763e-03, -8.3389e-03,  ...,  4.1443e-02,
         -3.5858e-03, -7.9193e-03],
        [ 1.4526e-02,  1.6968e-02,  2.6512e-03,  ..., -1.2192e-02,
          4.4983e-02,  1.3371e-03],
        [-1.4782e-03, -6.6147e-03, -1.7426e-02,  ..., -4.0359e-03,
         -7.4577e-04,  3.0426e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.6743, -0.5259, -2.9785,  ..., -2.8867, -7.8789, -2.9688]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 18:51:16 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you can believe something, that thing is believeable
If you can observe something, that thing is observable
If you can prevent something, that thing is preventable
If you can identify something, that thing is identifiable
If you can avoid something, that thing is avoidable
If you can admire something, that thing is admirable
If you can accept something, that thing is acceptable
If you can enjoy something, that thing is
2024-07-30 18:51:16 root INFO     total operator prediction time: 940.3327283859253 seconds
2024-07-30 18:51:16 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on verb+tion_irreg
2024-07-30 18:51:16 root INFO     building operator verb+tion_irreg
2024-07-30 18:51:16 root INFO     [order_1_approx] starting weight calculation for To maximize results in maximization
To continue results in continuation
To expire results in expiration
To civilize results in civilization
To starve results in starvation
To determine results in determination
To condense results in condensation
To imagine results in
2024-07-30 18:51:16 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-30 18:53:10 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2781, -0.1969,  0.7402,  ..., -0.8174, -0.3616, -0.2200],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.5117, -3.3281,  5.9453,  ...,  2.2090, -2.9727, -0.5786],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0780, -0.0067,  0.0024,  ..., -0.0011, -0.0120,  0.0020],
        [ 0.0170,  0.0828,  0.0208,  ...,  0.0301, -0.0021,  0.0084],
        [ 0.0054, -0.0137,  0.0613,  ..., -0.0026, -0.0058, -0.0208],
        ...,
        [ 0.0114,  0.0172,  0.0006,  ...,  0.0740, -0.0005, -0.0071],
        [ 0.0108,  0.0257,  0.0256,  ..., -0.0081,  0.0727, -0.0056],
        [ 0.0129,  0.0032, -0.0106,  ...,  0.0030, -0.0249,  0.0849]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.6211, -2.8848,  5.9648,  ...,  2.4434, -3.1172, -0.7852]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 18:53:11 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To maximize results in maximization
To continue results in continuation
To expire results in expiration
To civilize results in civilization
To starve results in starvation
To determine results in determination
To condense results in condensation
To imagine results in
2024-07-30 18:53:11 root INFO     [order_1_approx] starting weight calculation for To determine results in determination
To starve results in starvation
To expire results in expiration
To imagine results in imagination
To civilize results in civilization
To continue results in continuation
To maximize results in maximization
To condense results in
2024-07-30 18:53:12 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-30 18:55:06 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2300,  0.0441, -0.9072,  ..., -0.4202,  0.1400, -0.0900],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.0884, -3.4180,  3.7539,  ...,  0.5156, -2.0801, -1.3975],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0833,  0.0041,  0.0006,  ..., -0.0050, -0.0007,  0.0085],
        [-0.0005,  0.0710,  0.0095,  ...,  0.0104,  0.0015, -0.0068],
        [-0.0074, -0.0128,  0.0629,  ...,  0.0089, -0.0053, -0.0087],
        ...,
        [ 0.0016,  0.0019,  0.0095,  ...,  0.0898,  0.0042, -0.0010],
        [-0.0043,  0.0175,  0.0068,  ...,  0.0021,  0.0780, -0.0182],
        [ 0.0033,  0.0193, -0.0076,  ..., -0.0128, -0.0127,  0.0741]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.1699, -3.6191,  3.4688,  ...,  0.4404, -2.0879, -1.6787]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 18:55:07 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To determine results in determination
To starve results in starvation
To expire results in expiration
To imagine results in imagination
To civilize results in civilization
To continue results in continuation
To maximize results in maximization
To condense results in
2024-07-30 18:55:07 root INFO     [order_1_approx] starting weight calculation for To imagine results in imagination
To maximize results in maximization
To expire results in expiration
To civilize results in civilization
To starve results in starvation
To condense results in condensation
To continue results in continuation
To determine results in
2024-07-30 18:55:07 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-30 18:57:06 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0690,  0.1681, -0.2072,  ...,  0.1437, -0.7490,  0.0281],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.4199, -3.7891,  1.5391,  ..., -0.1606, -3.7871, -1.9434],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0936, -0.0003,  0.0042,  ..., -0.0140,  0.0008, -0.0016],
        [ 0.0183,  0.1077,  0.0261,  ...,  0.0449, -0.0132,  0.0284],
        [-0.0027, -0.0218,  0.0638,  ..., -0.0112,  0.0052, -0.0238],
        ...,
        [ 0.0130,  0.0361,  0.0130,  ...,  0.0920, -0.0226,  0.0278],
        [-0.0142,  0.0119,  0.0235,  ...,  0.0029,  0.0841, -0.0210],
        [ 0.0144,  0.0254, -0.0025,  ..., -0.0051, -0.0263,  0.0882]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.3242, -3.0410,  1.5830,  ..., -0.2064, -3.6191, -2.1387]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 18:57:07 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To imagine results in imagination
To maximize results in maximization
To expire results in expiration
To civilize results in civilization
To starve results in starvation
To condense results in condensation
To continue results in continuation
To determine results in
2024-07-30 18:57:07 root INFO     [order_1_approx] starting weight calculation for To starve results in starvation
To civilize results in civilization
To expire results in expiration
To imagine results in imagination
To maximize results in maximization
To condense results in condensation
To determine results in determination
To continue results in
2024-07-30 18:57:07 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-30 18:59:02 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0272, -0.2563, -0.4534,  ..., -0.5127, -0.6885,  0.5635],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.9839, -6.8281,  1.4980,  ...,  1.4375, -1.1250, -3.0625],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0667, -0.0119, -0.0086,  ..., -0.0082, -0.0145,  0.0152],
        [ 0.0145,  0.0740,  0.0113,  ...,  0.0338,  0.0020,  0.0297],
        [-0.0081, -0.0032,  0.0326,  ..., -0.0097, -0.0009, -0.0152],
        ...,
        [ 0.0259,  0.0003,  0.0128,  ...,  0.0842, -0.0024,  0.0174],
        [-0.0198,  0.0250,  0.0071,  ..., -0.0017,  0.0642, -0.0425],
        [ 0.0101,  0.0303, -0.0020,  ...,  0.0002, -0.0108,  0.0907]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.9277, -6.2539,  1.4746,  ...,  1.8232, -1.4199, -3.1582]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 18:59:23 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To starve results in starvation
To civilize results in civilization
To expire results in expiration
To imagine results in imagination
To maximize results in maximization
To condense results in condensation
To determine results in determination
To continue results in
2024-07-30 18:59:23 root INFO     [order_1_approx] starting weight calculation for To maximize results in maximization
To starve results in starvation
To condense results in condensation
To imagine results in imagination
To continue results in continuation
To expire results in expiration
To determine results in determination
To civilize results in
2024-07-30 18:59:23 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-30 19:01:19 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3530,  0.6221, -1.0391,  ..., -0.5137, -0.3354,  0.2228],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.1846, -3.4336,  2.5469,  ...,  0.6562, -1.3506, -1.7422],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0637, -0.0120,  0.0056,  ..., -0.0060,  0.0046, -0.0007],
        [ 0.0035,  0.0673,  0.0090,  ...,  0.0216, -0.0004,  0.0044],
        [-0.0013, -0.0108,  0.0490,  ..., -0.0065,  0.0042, -0.0129],
        ...,
        [ 0.0101,  0.0112,  0.0048,  ...,  0.0700, -0.0035,  0.0109],
        [ 0.0049,  0.0177,  0.0079,  ...,  0.0055,  0.0623, -0.0162],
        [ 0.0041, -0.0013, -0.0058,  ..., -0.0034, -0.0259,  0.0691]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.0634, -3.3418,  2.4727,  ...,  0.8784, -1.3545, -1.5244]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 19:01:20 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To maximize results in maximization
To starve results in starvation
To condense results in condensation
To imagine results in imagination
To continue results in continuation
To expire results in expiration
To determine results in determination
To civilize results in
2024-07-30 19:01:20 root INFO     [order_1_approx] starting weight calculation for To continue results in continuation
To civilize results in civilization
To determine results in determination
To starve results in starvation
To condense results in condensation
To maximize results in maximization
To imagine results in imagination
To expire results in
2024-07-30 19:01:20 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-30 19:03:16 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.3877, -0.2391, -1.2500,  ..., -0.4702, -0.2480, -0.4836],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.4150, -3.4258,  1.6406,  ..., -1.1133, -0.7412, -2.2891],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0848, -0.0070,  0.0061,  ..., -0.0092, -0.0060,  0.0116],
        [-0.0010,  0.0679, -0.0051,  ...,  0.0108, -0.0006, -0.0015],
        [ 0.0003, -0.0005,  0.0562,  ..., -0.0127, -0.0159, -0.0105],
        ...,
        [ 0.0085,  0.0137, -0.0063,  ...,  0.0792, -0.0089, -0.0100],
        [ 0.0060,  0.0028,  0.0194,  ...,  0.0078,  0.0574, -0.0041],
        [ 0.0273, -0.0038, -0.0127,  ..., -0.0121, -0.0213,  0.0887]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.1638, -2.7383,  1.4531,  ..., -1.1475, -1.1328, -2.5156]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 19:03:17 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To continue results in continuation
To civilize results in civilization
To determine results in determination
To starve results in starvation
To condense results in condensation
To maximize results in maximization
To imagine results in imagination
To expire results in
2024-07-30 19:03:17 root INFO     [order_1_approx] starting weight calculation for To condense results in condensation
To determine results in determination
To civilize results in civilization
To starve results in starvation
To expire results in expiration
To imagine results in imagination
To continue results in continuation
To maximize results in
2024-07-30 19:03:17 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-30 19:05:15 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3301, -0.1709, -0.6636,  ..., -0.3762, -0.1699, -0.2423],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.6074, -2.2402,  1.0664,  ..., -0.9053, -4.4844, -2.3906],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0790,  0.0068,  0.0026,  ..., -0.0061, -0.0058,  0.0147],
        [-0.0023,  0.0792,  0.0153,  ...,  0.0232, -0.0054,  0.0021],
        [-0.0080, -0.0035,  0.0596,  ..., -0.0070,  0.0029, -0.0049],
        ...,
        [-0.0013,  0.0059,  0.0037,  ...,  0.0824, -0.0038,  0.0095],
        [ 0.0069,  0.0025,  0.0069,  ...,  0.0074,  0.0868, -0.0050],
        [ 0.0001,  0.0053, -0.0115,  ..., -0.0162, -0.0189,  0.0749]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.5439, -2.3906,  1.3184,  ..., -0.8481, -4.3125, -2.4844]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 19:05:16 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To condense results in condensation
To determine results in determination
To civilize results in civilization
To starve results in starvation
To expire results in expiration
To imagine results in imagination
To continue results in continuation
To maximize results in
2024-07-30 19:05:16 root INFO     [order_1_approx] starting weight calculation for To determine results in determination
To imagine results in imagination
To expire results in expiration
To condense results in condensation
To civilize results in civilization
To maximize results in maximization
To continue results in continuation
To starve results in
2024-07-30 19:05:16 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-30 19:07:15 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0808, -0.5771, -0.5107,  ..., -0.8203, -0.1877,  0.0665],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.5059, -3.3613,  3.4766,  ...,  0.2603, -2.2168, -1.6348],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0682,  0.0020,  0.0127,  ...,  0.0046, -0.0078,  0.0113],
        [-0.0040,  0.0604,  0.0013,  ...,  0.0165, -0.0012,  0.0016],
        [ 0.0079, -0.0144,  0.0574,  ..., -0.0081, -0.0054, -0.0088],
        ...,
        [ 0.0120,  0.0128, -0.0031,  ...,  0.0623, -0.0016, -0.0006],
        [-0.0023,  0.0186,  0.0090,  ..., -0.0017,  0.0517, -0.0089],
        [ 0.0082,  0.0040, -0.0091,  ..., -0.0005, -0.0135,  0.0742]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.1035, -3.1270,  3.3867,  ...,  0.3667, -1.9727, -1.5322]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 19:07:16 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To determine results in determination
To imagine results in imagination
To expire results in expiration
To condense results in condensation
To civilize results in civilization
To maximize results in maximization
To continue results in continuation
To starve results in
2024-07-30 19:07:16 root INFO     total operator prediction time: 960.5160963535309 seconds
2024-07-30 19:07:16 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on adj+ly_reg
2024-07-30 19:07:16 root INFO     building operator adj+ly_reg
2024-07-30 19:07:16 root INFO     [order_1_approx] starting weight calculation for The adjective form of according is accordingly
The adjective form of clinical is clinically
The adjective form of historical is historically
The adjective form of financial is financially
The adjective form of federal is federally
The adjective form of political is politically
The adjective form of extensive is extensively
The adjective form of traditional is
2024-07-30 19:07:16 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-30 19:09:15 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.5288, -0.2095, -0.6045,  ..., -0.6567, -0.3787, -0.0884],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.3184, -2.6074,  0.9370,  ...,  0.1875, -2.5352,  0.2178],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0897, -0.0391,  0.0080,  ..., -0.0026, -0.0055,  0.0017],
        [-0.0186,  0.1008,  0.0201,  ...,  0.0242, -0.0081, -0.0227],
        [ 0.0003, -0.0063,  0.0867,  ...,  0.0178, -0.0017, -0.0065],
        ...,
        [ 0.0010,  0.0102, -0.0123,  ...,  0.0734, -0.0150, -0.0026],
        [ 0.0070,  0.0087,  0.0053,  ..., -0.0270,  0.0822,  0.0013],
        [ 0.0020, -0.0056, -0.0015,  ...,  0.0031, -0.0138,  0.0648]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.2695, -2.2188,  0.9785,  ..., -0.0297, -2.6934, -0.0145]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 19:09:15 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The adjective form of according is accordingly
The adjective form of clinical is clinically
The adjective form of historical is historically
The adjective form of financial is financially
The adjective form of federal is federally
The adjective form of political is politically
The adjective form of extensive is extensively
The adjective form of traditional is
2024-07-30 19:09:16 root INFO     [order_1_approx] starting weight calculation for The adjective form of historical is historically
The adjective form of extensive is extensively
The adjective form of according is accordingly
The adjective form of financial is financially
The adjective form of political is politically
The adjective form of federal is federally
The adjective form of traditional is traditionally
The adjective form of clinical is
2024-07-30 19:09:16 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-30 19:11:14 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3972, -0.0856,  0.0701,  ..., -0.7090, -0.5366, -0.4243],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.8779, -0.3550, -0.4434,  ..., -1.3262,  2.2559,  0.1992],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0904, -0.0121,  0.0119,  ...,  0.0016, -0.0006,  0.0261],
        [-0.0183,  0.0813,  0.0050,  ...,  0.0158,  0.0002,  0.0036],
        [-0.0035, -0.0099,  0.1031,  ...,  0.0064,  0.0074,  0.0043],
        ...,
        [ 0.0080,  0.0371, -0.0312,  ...,  0.1007, -0.0052,  0.0186],
        [-0.0118,  0.0256,  0.0066,  ..., -0.0064,  0.0778, -0.0126],
        [-0.0090, -0.0182, -0.0004,  ..., -0.0168, -0.0128,  0.0775]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.7549, -0.4895, -0.4802,  ..., -1.1475,  2.2773,  0.2480]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 19:11:15 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The adjective form of historical is historically
The adjective form of extensive is extensively
The adjective form of according is accordingly
The adjective form of financial is financially
The adjective form of political is politically
The adjective form of federal is federally
The adjective form of traditional is traditionally
The adjective form of clinical is
2024-07-30 19:11:15 root INFO     [order_1_approx] starting weight calculation for The adjective form of traditional is traditionally
The adjective form of according is accordingly
The adjective form of federal is federally
The adjective form of extensive is extensively
The adjective form of political is politically
The adjective form of clinical is clinically
The adjective form of historical is historically
The adjective form of financial is
2024-07-30 19:11:15 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-30 19:13:14 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1962, -0.6289, -0.2529,  ..., -0.7109,  0.0057, -0.1995],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.7964, -0.5308,  2.7480,  ..., -2.1309, -1.6328, -0.3418],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0648, -0.0307,  0.0118,  ..., -0.0263,  0.0193,  0.0195],
        [-0.0244,  0.0814,  0.0219,  ..., -0.0025, -0.0209, -0.0185],
        [-0.0063, -0.0052,  0.0748,  ...,  0.0016,  0.0024, -0.0087],
        ...,
        [-0.0073, -0.0029, -0.0228,  ...,  0.1061,  0.0151,  0.0034],
        [-0.0166,  0.0351, -0.0170,  ..., -0.0124,  0.0955, -0.0265],
        [ 0.0017, -0.0215, -0.0038,  ...,  0.0005, -0.0070,  0.0580]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.7695, -0.1858,  3.0273,  ..., -1.8955, -1.5469, -0.3386]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 19:13:15 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The adjective form of traditional is traditionally
The adjective form of according is accordingly
The adjective form of federal is federally
The adjective form of extensive is extensively
The adjective form of political is politically
The adjective form of clinical is clinically
The adjective form of historical is historically
The adjective form of financial is
2024-07-30 19:13:15 root INFO     [order_1_approx] starting weight calculation for The adjective form of according is accordingly
The adjective form of political is politically
The adjective form of financial is financially
The adjective form of traditional is traditionally
The adjective form of clinical is clinically
The adjective form of extensive is extensively
The adjective form of federal is federally
The adjective form of historical is
2024-07-30 19:13:15 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-30 19:15:15 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0148, -0.1420, -0.1241,  ..., -0.8374, -0.4607, -0.2534],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.7041, -1.2920,  0.9380,  ..., -3.1660, -2.4375, -0.8789],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0973, -0.0242,  0.0271,  ..., -0.0099,  0.0024,  0.0219],
        [-0.0208,  0.1176,  0.0091,  ...,  0.0084, -0.0004, -0.0140],
        [ 0.0076,  0.0004,  0.0922,  ..., -0.0058,  0.0106, -0.0093],
        ...,
        [ 0.0060,  0.0102, -0.0349,  ...,  0.1145, -0.0030,  0.0029],
        [ 0.0017,  0.0342,  0.0114,  ..., -0.0035,  0.0936, -0.0141],
        [ 0.0224, -0.0115, -0.0220,  ..., -0.0021, -0.0219,  0.0623]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.3665, -1.3545,  0.8589,  ..., -3.0645, -2.4395, -0.8486]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 19:15:22 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The adjective form of according is accordingly
The adjective form of political is politically
The adjective form of financial is financially
The adjective form of traditional is traditionally
The adjective form of clinical is clinically
The adjective form of extensive is extensively
The adjective form of federal is federally
The adjective form of historical is
2024-07-30 19:15:25 root INFO     [order_1_approx] starting weight calculation for The adjective form of traditional is traditionally
The adjective form of federal is federally
The adjective form of extensive is extensively
The adjective form of financial is financially
The adjective form of clinical is clinically
The adjective form of historical is historically
The adjective form of according is accordingly
The adjective form of political is
2024-07-30 19:15:25 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-30 19:17:25 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0051,  0.4443,  0.0160,  ..., -0.3418, -0.8706, -0.0674],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.2256, -2.7207,  0.8638,  ..., -2.5586, -0.1348,  0.4473],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0648, -0.0101,  0.0199,  ..., -0.0073,  0.0079,  0.0148],
        [-0.0068,  0.0699,  0.0146,  ...,  0.0094, -0.0112, -0.0116],
        [ 0.0071,  0.0086,  0.0892,  ...,  0.0292, -0.0029,  0.0033],
        ...,
        [ 0.0121, -0.0075, -0.0263,  ...,  0.0951,  0.0163,  0.0071],
        [ 0.0015,  0.0198, -0.0094,  ..., -0.0175,  0.0883, -0.0272],
        [ 0.0100, -0.0212, -0.0112,  ..., -0.0030, -0.0250,  0.0636]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.4805, -2.5312,  0.8716,  ..., -2.3398, -0.2158,  0.4463]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 19:17:26 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The adjective form of traditional is traditionally
The adjective form of federal is federally
The adjective form of extensive is extensively
The adjective form of financial is financially
The adjective form of clinical is clinically
The adjective form of historical is historically
The adjective form of according is accordingly
The adjective form of political is
2024-07-30 19:17:26 root INFO     [order_1_approx] starting weight calculation for The adjective form of traditional is traditionally
The adjective form of historical is historically
The adjective form of according is accordingly
The adjective form of political is politically
The adjective form of federal is federally
The adjective form of financial is financially
The adjective form of clinical is clinically
The adjective form of extensive is
2024-07-30 19:17:26 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-30 19:19:25 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0768, -0.2139, -0.2585,  ..., -0.6099,  0.0171, -0.1990],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.6680, -0.7822, -1.3809,  ..., -1.5645, -1.0889, -3.1152],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.1136, -0.0212,  0.0101,  ...,  0.0073,  0.0305,  0.0189],
        [ 0.0199,  0.1250,  0.0060,  ...,  0.0028,  0.0036,  0.0002],
        [ 0.0171, -0.0116,  0.1008,  ..., -0.0180,  0.0092, -0.0019],
        ...,
        [ 0.0048,  0.0089,  0.0197,  ...,  0.1191,  0.0092, -0.0092],
        [ 0.0131,  0.0116, -0.0071,  ...,  0.0105,  0.0783, -0.0184],
        [ 0.0388,  0.0121,  0.0137,  ..., -0.0126, -0.0116,  0.0716]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.2695, -1.1328, -1.0742,  ..., -1.3262, -0.4121, -3.1660]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 19:19:26 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The adjective form of traditional is traditionally
The adjective form of historical is historically
The adjective form of according is accordingly
The adjective form of political is politically
The adjective form of federal is federally
The adjective form of financial is financially
The adjective form of clinical is clinically
The adjective form of extensive is
2024-07-30 19:19:26 root INFO     [order_1_approx] starting weight calculation for The adjective form of political is politically
The adjective form of according is accordingly
The adjective form of historical is historically
The adjective form of financial is financially
The adjective form of traditional is traditionally
The adjective form of extensive is extensively
The adjective form of clinical is clinically
The adjective form of federal is
2024-07-30 19:19:26 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-30 19:21:23 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.6201,  0.1058, -0.4719,  ..., -0.6978, -0.3394, -0.2417],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.1465, -1.1357,  3.7637,  ..., -1.4834, -0.3975, -0.0771],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0824, -0.0281,  0.0121,  ..., -0.0007,  0.0186,  0.0230],
        [ 0.0129,  0.1096,  0.0268,  ...,  0.0160, -0.0116, -0.0234],
        [ 0.0186,  0.0342,  0.0850,  ..., -0.0018,  0.0032, -0.0096],
        ...,
        [-0.0229, -0.0137, -0.0147,  ...,  0.0867,  0.0212, -0.0261],
        [-0.0040,  0.0129,  0.0033,  ...,  0.0062,  0.1006, -0.0192],
        [ 0.0205, -0.0280, -0.0066,  ..., -0.0073, -0.0435,  0.0874]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.9326, -1.1934,  3.8184,  ..., -1.2080, -0.3357, -0.6899]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 19:21:24 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The adjective form of political is politically
The adjective form of according is accordingly
The adjective form of historical is historically
The adjective form of financial is financially
The adjective form of traditional is traditionally
The adjective form of extensive is extensively
The adjective form of clinical is clinically
The adjective form of federal is
2024-07-30 19:21:24 root INFO     [order_1_approx] starting weight calculation for The adjective form of federal is federally
The adjective form of traditional is traditionally
The adjective form of political is politically
The adjective form of extensive is extensively
The adjective form of historical is historically
The adjective form of financial is financially
The adjective form of clinical is clinically
The adjective form of according is
2024-07-30 19:21:24 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-30 19:23:22 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2484, -0.0276, -0.9941,  ..., -0.7769, -0.3335, -0.5586],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.2925, -4.3633,  1.4990,  ...,  2.5762, -2.4629, -0.9229],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.1028, -0.0211,  0.0154,  ...,  0.0062,  0.0161,  0.0260],
        [-0.0223,  0.0919, -0.0031,  ...,  0.0249,  0.0012,  0.0019],
        [ 0.0027,  0.0024,  0.1008,  ..., -0.0278, -0.0135, -0.0114],
        ...,
        [-0.0128,  0.0009, -0.0174,  ...,  0.1219, -0.0057,  0.0046],
        [ 0.0246, -0.0025,  0.0160,  ..., -0.0158,  0.0598, -0.0316],
        [-0.0003, -0.0340, -0.0121,  ..., -0.0184, -0.0004,  0.0840]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.1041, -4.0117,  2.0859,  ...,  2.3320, -2.1992, -1.1191]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 19:23:23 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The adjective form of federal is federally
The adjective form of traditional is traditionally
The adjective form of political is politically
The adjective form of extensive is extensively
The adjective form of historical is historically
The adjective form of financial is financially
The adjective form of clinical is clinically
The adjective form of according is
2024-07-30 19:23:23 root INFO     total operator prediction time: 966.4458191394806 seconds
2024-07-30 19:23:23 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on over+adj_reg
2024-07-30 19:23:23 root INFO     building operator over+adj_reg
2024-07-30 19:23:23 root INFO     [order_1_approx] starting weight calculation for If something is too represented, it is overrepresented
If something is too stocked, it is overstocked
If something is too stressed, it is overstressed
If something is too turned, it is overturned
If something is too inflated, it is overinflated
If something is too compensated, it is overcompensated
If something is too stimulated, it is overstimulated
If something is too qualified, it is
2024-07-30 19:23:23 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-30 19:25:21 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.3091, -0.5444, -0.4519,  ..., -0.4719, -0.2625,  0.1093],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.4204, -2.6973,  0.0293,  ...,  0.9600, -1.0254, -2.8887],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0781, -0.0196,  0.0193,  ..., -0.0347,  0.0003,  0.0071],
        [-0.0093,  0.0706,  0.0028,  ...,  0.0263,  0.0133, -0.0127],
        [ 0.0062, -0.0020,  0.0701,  ..., -0.0151,  0.0162, -0.0124],
        ...,
        [-0.0009,  0.0141, -0.0273,  ...,  0.0972,  0.0115, -0.0071],
        [-0.0203,  0.0181,  0.0105,  ...,  0.0107,  0.0833, -0.0110],
        [ 0.0066, -0.0021, -0.0071,  ..., -0.0010, -0.0166,  0.0688]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.4602, -2.6230,  0.0536,  ...,  1.1074, -1.0576, -3.0527]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 19:25:22 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is too represented, it is overrepresented
If something is too stocked, it is overstocked
If something is too stressed, it is overstressed
If something is too turned, it is overturned
If something is too inflated, it is overinflated
If something is too compensated, it is overcompensated
If something is too stimulated, it is overstimulated
If something is too qualified, it is
2024-07-30 19:25:22 root INFO     [order_1_approx] starting weight calculation for If something is too stimulated, it is overstimulated
If something is too stressed, it is overstressed
If something is too represented, it is overrepresented
If something is too qualified, it is overqualified
If something is too turned, it is overturned
If something is too stocked, it is overstocked
If something is too inflated, it is overinflated
If something is too compensated, it is
2024-07-30 19:25:22 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-30 19:27:17 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.6660, -0.3286, -0.6650,  ..., -0.9336, -0.7285, -0.1057],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.8066, -3.0195,  0.9858,  ..., -0.6387, -0.3000, -1.9531],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0627, -0.0148,  0.0202,  ..., -0.0095, -0.0016, -0.0061],
        [-0.0145,  0.0496, -0.0081,  ...,  0.0246,  0.0095, -0.0015],
        [ 0.0023,  0.0084,  0.0482,  ..., -0.0081,  0.0064, -0.0105],
        ...,
        [-0.0025,  0.0066, -0.0070,  ...,  0.0734,  0.0093, -0.0079],
        [-0.0091,  0.0068,  0.0059,  ..., -0.0048,  0.0635, -0.0104],
        [-0.0007,  0.0065, -0.0121,  ..., -0.0041, -0.0081,  0.0565]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.8306, -2.9590,  1.1152,  ..., -0.3762, -0.0403, -2.1133]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 19:27:18 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is too stimulated, it is overstimulated
If something is too stressed, it is overstressed
If something is too represented, it is overrepresented
If something is too qualified, it is overqualified
If something is too turned, it is overturned
If something is too stocked, it is overstocked
If something is too inflated, it is overinflated
If something is too compensated, it is
2024-07-30 19:27:18 root INFO     [order_1_approx] starting weight calculation for If something is too stimulated, it is overstimulated
If something is too compensated, it is overcompensated
If something is too inflated, it is overinflated
If something is too turned, it is overturned
If something is too qualified, it is overqualified
If something is too represented, it is overrepresented
If something is too stressed, it is overstressed
If something is too stocked, it is
2024-07-30 19:27:18 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-30 19:29:14 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2095,  0.1694, -0.9785,  ..., -0.1602, -0.5703,  0.1492],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.4746, -2.6328, -0.3726,  ..., -0.5605, -1.3535, -2.6699],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0857, -0.0113, -0.0016,  ..., -0.0100,  0.0061,  0.0054],
        [-0.0050,  0.0684, -0.0041,  ...,  0.0211,  0.0239, -0.0030],
        [ 0.0064,  0.0113,  0.0621,  ..., -0.0035, -0.0028, -0.0005],
        ...,
        [-0.0108, -0.0067, -0.0046,  ...,  0.0812,  0.0047, -0.0069],
        [-0.0097,  0.0106,  0.0014,  ..., -0.0015,  0.0661, -0.0096],
        [-0.0028, -0.0017, -0.0123,  ..., -0.0112, -0.0154,  0.0616]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.5527, -2.4609, -0.3208,  ..., -0.5103, -0.9355, -2.6211]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 19:29:15 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is too stimulated, it is overstimulated
If something is too compensated, it is overcompensated
If something is too inflated, it is overinflated
If something is too turned, it is overturned
If something is too qualified, it is overqualified
If something is too represented, it is overrepresented
If something is too stressed, it is overstressed
If something is too stocked, it is
2024-07-30 19:29:15 root INFO     [order_1_approx] starting weight calculation for If something is too represented, it is overrepresented
If something is too turned, it is overturned
If something is too compensated, it is overcompensated
If something is too qualified, it is overqualified
If something is too stocked, it is overstocked
If something is too stressed, it is overstressed
If something is too inflated, it is overinflated
If something is too stimulated, it is
2024-07-30 19:29:15 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-30 19:31:13 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4780, -0.2551, -0.8213,  ..., -0.4951, -0.7739,  0.0406],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.0781, -2.2773,  0.5796,  ...,  0.4590, -1.3086, -2.9258],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 7.7637e-02,  2.7409e-03,  5.9662e-03,  ..., -1.8707e-02,
          2.1343e-03, -8.9359e-04],
        [ 6.1703e-04,  7.2754e-02,  5.1155e-03,  ...,  3.5820e-03,
          1.1436e-02, -5.4970e-03],
        [ 1.0979e-02,  1.5144e-03,  4.8798e-02,  ..., -7.8049e-03,
          1.0727e-02, -4.9477e-03],
        ...,
        [-5.3787e-03,  9.1782e-03, -9.2773e-03,  ...,  8.0750e-02,
          1.2314e-02,  4.9591e-03],
        [ 4.9591e-05,  7.3471e-03,  6.3438e-03,  ...,  2.0828e-03,
          6.4453e-02, -1.1902e-02],
        [-7.5455e-03,  9.3231e-03, -1.4221e-02,  ...,  1.9875e-03,
         -1.1276e-02,  6.7200e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.2266, -2.5586,  0.3115,  ...,  0.5825, -1.4033, -2.9629]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 19:31:14 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is too represented, it is overrepresented
If something is too turned, it is overturned
If something is too compensated, it is overcompensated
If something is too qualified, it is overqualified
If something is too stocked, it is overstocked
If something is too stressed, it is overstressed
If something is too inflated, it is overinflated
If something is too stimulated, it is
2024-07-30 19:31:14 root INFO     [order_1_approx] starting weight calculation for If something is too turned, it is overturned
If something is too represented, it is overrepresented
If something is too qualified, it is overqualified
If something is too compensated, it is overcompensated
If something is too stimulated, it is overstimulated
If something is too inflated, it is overinflated
If something is too stocked, it is overstocked
If something is too stressed, it is
2024-07-30 19:31:14 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-30 19:33:06 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3164, -0.5986, -0.4385,  ..., -0.2920, -0.2947,  0.2206],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.8711, -2.7773,  0.2598,  ...,  0.4722,  0.4355, -2.5078],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0621, -0.0099,  0.0023,  ..., -0.0041, -0.0115, -0.0049],
        [ 0.0003,  0.0652,  0.0041,  ...,  0.0153,  0.0098,  0.0034],
        [ 0.0112, -0.0081,  0.0465,  ..., -0.0010,  0.0011, -0.0135],
        ...,
        [ 0.0040,  0.0054, -0.0040,  ...,  0.0668,  0.0057,  0.0060],
        [ 0.0085,  0.0076,  0.0060,  ..., -0.0039,  0.0591, -0.0215],
        [-0.0035,  0.0061, -0.0055,  ..., -0.0013, -0.0149,  0.0588]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.9326, -2.4844,  0.2603,  ...,  0.2739,  0.2290, -2.3359]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 19:33:31 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is too turned, it is overturned
If something is too represented, it is overrepresented
If something is too qualified, it is overqualified
If something is too compensated, it is overcompensated
If something is too stimulated, it is overstimulated
If something is too inflated, it is overinflated
If something is too stocked, it is overstocked
If something is too stressed, it is
2024-07-30 19:33:32 root INFO     [order_1_approx] starting weight calculation for If something is too stimulated, it is overstimulated
If something is too turned, it is overturned
If something is too stocked, it is overstocked
If something is too stressed, it is overstressed
If something is too compensated, it is overcompensated
If something is too qualified, it is overqualified
If something is too inflated, it is overinflated
If something is too represented, it is
2024-07-30 19:33:32 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-30 19:35:26 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2264,  0.7080, -0.5269,  ..., -0.4683, -0.6562, -0.1992],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.8496, -2.2285,  0.2207,  ..., -0.0649, -1.9043, -3.9824],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0945, -0.0056,  0.0236,  ..., -0.0066,  0.0064, -0.0035],
        [-0.0010,  0.0774, -0.0126,  ...,  0.0171,  0.0087, -0.0060],
        [ 0.0023, -0.0118,  0.0894,  ..., -0.0098,  0.0005, -0.0117],
        ...,
        [-0.0007,  0.0041, -0.0077,  ...,  0.1112,  0.0125, -0.0111],
        [-0.0077,  0.0152,  0.0115,  ...,  0.0019,  0.0902, -0.0073],
        [-0.0147, -0.0057, -0.0058,  ...,  0.0154, -0.0130,  0.0888]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.0674, -2.6230,  0.5254,  ..., -0.3359, -1.5869, -3.8984]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 19:35:27 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is too stimulated, it is overstimulated
If something is too turned, it is overturned
If something is too stocked, it is overstocked
If something is too stressed, it is overstressed
If something is too compensated, it is overcompensated
If something is too qualified, it is overqualified
If something is too inflated, it is overinflated
If something is too represented, it is
2024-07-30 19:35:27 root INFO     [order_1_approx] starting weight calculation for If something is too inflated, it is overinflated
If something is too compensated, it is overcompensated
If something is too represented, it is overrepresented
If something is too stimulated, it is overstimulated
If something is too stressed, it is overstressed
If something is too stocked, it is overstocked
If something is too qualified, it is overqualified
If something is too turned, it is
2024-07-30 19:35:27 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-30 19:37:23 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1553, -0.1519, -0.3733,  ...,  0.1117, -0.4692, -0.0610],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.6309, -3.7461,  1.1504,  ...,  0.0762, -0.8379, -1.6621],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 1.0980e-01,  5.8594e-03, -4.6062e-04,  ..., -2.5024e-02,
          3.3855e-03, -7.2174e-03],
        [ 2.8648e-03,  8.4778e-02, -1.0513e-02,  ...,  2.9938e-02,
          1.0620e-02,  5.7125e-04],
        [ 2.3560e-02, -1.7746e-02,  9.1064e-02,  ..., -2.1248e-03,
          6.3667e-03, -1.3123e-02],
        ...,
        [ 8.1787e-03,  6.0797e-04,  1.0643e-03,  ...,  1.0120e-01,
          9.5291e-03, -7.0839e-03],
        [-1.5640e-02, -3.0327e-03, -1.0281e-03,  ..., -1.2787e-02,
          8.2031e-02, -1.8829e-02],
        [-1.7349e-02,  1.6663e-02,  3.2902e-05,  ..., -2.1240e-02,
         -1.8219e-02,  7.8003e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.6387, -3.6035,  0.7822,  ..., -0.0043, -0.9067, -2.1387]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 19:37:24 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is too inflated, it is overinflated
If something is too compensated, it is overcompensated
If something is too represented, it is overrepresented
If something is too stimulated, it is overstimulated
If something is too stressed, it is overstressed
If something is too stocked, it is overstocked
If something is too qualified, it is overqualified
If something is too turned, it is
2024-07-30 19:37:24 root INFO     [order_1_approx] starting weight calculation for If something is too stimulated, it is overstimulated
If something is too stressed, it is overstressed
If something is too stocked, it is overstocked
If something is too represented, it is overrepresented
If something is too qualified, it is overqualified
If something is too turned, it is overturned
If something is too compensated, it is overcompensated
If something is too inflated, it is
2024-07-30 19:37:24 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-30 19:39:19 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3975, -0.0883, -1.1289,  ..., -0.1389,  0.1700,  0.4863],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.3799, -2.8926,  0.6343,  ..., -0.9204,  0.3472, -1.9414],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0983, -0.0026,  0.0097,  ..., -0.0179,  0.0061,  0.0072],
        [-0.0063,  0.0784, -0.0027,  ...,  0.0132,  0.0182, -0.0068],
        [ 0.0253,  0.0055,  0.0622,  ..., -0.0170, -0.0061, -0.0152],
        ...,
        [-0.0222,  0.0091, -0.0147,  ...,  0.1049,  0.0111, -0.0042],
        [-0.0082, -0.0079, -0.0063,  ..., -0.0021,  0.0793, -0.0218],
        [-0.0119, -0.0082, -0.0048,  ..., -0.0022, -0.0067,  0.0684]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.5635, -2.8926,  0.6709,  ..., -0.6855, -0.0439, -2.1582]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 19:39:20 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is too stimulated, it is overstimulated
If something is too stressed, it is overstressed
If something is too stocked, it is overstocked
If something is too represented, it is overrepresented
If something is too qualified, it is overqualified
If something is too turned, it is overturned
If something is too compensated, it is overcompensated
If something is too inflated, it is
2024-07-30 19:39:20 root INFO     total operator prediction time: 957.4869585037231 seconds
2024-07-30 19:39:20 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on verb+er_irreg
2024-07-30 19:39:20 root INFO     building operator verb+er_irreg
2024-07-30 19:39:20 root INFO     [order_1_approx] starting weight calculation for If you write something, you are a writer
If you believe something, you are a believer
If you preach something, you are a preacher
If you slay something, you are a slayer
If you compose something, you are a composer
If you publish something, you are a publisher
If you deliver something, you are a deliverer
If you manage something, you are a
2024-07-30 19:39:20 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-30 19:41:17 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3972,  0.8462,  0.1404,  ...,  0.0996, -0.6592, -0.0795],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.5801, -3.1035,  3.3672,  ..., -0.8901, -3.3672, -4.2031],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0339, -0.0023,  0.0059,  ..., -0.0039, -0.0119,  0.0205],
        [-0.0104,  0.0363, -0.0001,  ...,  0.0049,  0.0161, -0.0015],
        [ 0.0015, -0.0059,  0.0257,  ..., -0.0222, -0.0189, -0.0145],
        ...,
        [ 0.0151,  0.0047,  0.0150,  ...,  0.0574, -0.0006,  0.0025],
        [-0.0017,  0.0183,  0.0215,  ..., -0.0062,  0.0475, -0.0070],
        [ 0.0067,  0.0146, -0.0008,  ..., -0.0192, -0.0086,  0.0262]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.6777, -3.0801,  3.3027,  ..., -0.5903, -3.1875, -4.1992]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 19:41:18 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you write something, you are a writer
If you believe something, you are a believer
If you preach something, you are a preacher
If you slay something, you are a slayer
If you compose something, you are a composer
If you publish something, you are a publisher
If you deliver something, you are a deliverer
If you manage something, you are a
2024-07-30 19:41:19 root INFO     [order_1_approx] starting weight calculation for If you believe something, you are a believer
If you compose something, you are a composer
If you manage something, you are a manager
If you write something, you are a writer
If you publish something, you are a publisher
If you preach something, you are a preacher
If you deliver something, you are a deliverer
If you slay something, you are a
2024-07-30 19:41:19 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-30 19:43:09 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0743, -0.2754, -0.1508,  ..., -0.3506, -0.0802,  0.3062],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.8477, -3.5781, -1.4277,  ..., -4.2500, -2.5059, -1.5332],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0724, -0.0137,  0.0206,  ...,  0.0075, -0.0026,  0.0127],
        [-0.0055,  0.0602,  0.0104,  ...,  0.0022,  0.0204,  0.0075],
        [-0.0089, -0.0172,  0.0741,  ...,  0.0253,  0.0034,  0.0050],
        ...,
        [ 0.0030,  0.0142,  0.0116,  ...,  0.0680, -0.0076, -0.0011],
        [-0.0294,  0.0132,  0.0187,  ..., -0.0127,  0.0539, -0.0054],
        [ 0.0171,  0.0027, -0.0100,  ..., -0.0251,  0.0016,  0.0681]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.2832, -3.5469, -1.0879,  ..., -4.1445, -2.3945, -1.6426]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 19:43:10 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you believe something, you are a believer
If you compose something, you are a composer
If you manage something, you are a manager
If you write something, you are a writer
If you publish something, you are a publisher
If you preach something, you are a preacher
If you deliver something, you are a deliverer
If you slay something, you are a
2024-07-30 19:43:10 root INFO     [order_1_approx] starting weight calculation for If you manage something, you are a manager
If you slay something, you are a slayer
If you preach something, you are a preacher
If you deliver something, you are a deliverer
If you publish something, you are a publisher
If you believe something, you are a believer
If you write something, you are a writer
If you compose something, you are a
2024-07-30 19:43:10 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-30 19:45:03 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4382,  0.2744, -0.0341,  ..., -0.9214, -0.8438,  0.7021],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.0918, -2.2988,  0.1460,  ..., -0.1367, -2.1230, -0.1309],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 5.1392e-02, -6.2370e-03,  1.9577e-02,  ...,  7.0152e-03,
         -1.1734e-02,  2.0203e-02],
        [ 2.6512e-03,  4.5135e-02, -9.3613e-03,  ...,  1.1215e-02,
          1.8646e-02, -9.2163e-03],
        [ 1.4404e-02,  1.1749e-03,  5.1147e-02,  ...,  4.1199e-04,
         -5.8136e-03,  9.7275e-05],
        ...,
        [ 1.5289e-02,  9.6436e-03,  1.6117e-04,  ...,  6.1371e-02,
         -8.7204e-03, -2.4124e-02],
        [ 1.9012e-02,  1.6571e-02,  1.8959e-03,  ..., -2.0905e-02,
          4.3274e-02, -2.1553e-03],
        [-1.8482e-03, -1.0815e-03, -5.2261e-03,  ..., -9.2850e-03,
         -1.3336e-02,  4.3854e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.0215, -2.4863,  0.0806,  ...,  0.1035, -1.9521, -0.4177]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 19:45:03 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you manage something, you are a manager
If you slay something, you are a slayer
If you preach something, you are a preacher
If you deliver something, you are a deliverer
If you publish something, you are a publisher
If you believe something, you are a believer
If you write something, you are a writer
If you compose something, you are a
2024-07-30 19:45:04 root INFO     [order_1_approx] starting weight calculation for If you deliver something, you are a deliverer
If you publish something, you are a publisher
If you compose something, you are a composer
If you believe something, you are a believer
If you manage something, you are a manager
If you write something, you are a writer
If you slay something, you are a slayer
If you preach something, you are a
2024-07-30 19:45:04 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-30 19:46:56 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0442, -0.1058,  0.1691,  ..., -0.1775, -1.0342,  0.7837],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.5156, -5.3672,  3.5879,  ...,  0.7051, -2.6855, -0.8750],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0598,  0.0046,  0.0158,  ...,  0.0143, -0.0011, -0.0001],
        [ 0.0020,  0.0518,  0.0074,  ...,  0.0148,  0.0209, -0.0020],
        [ 0.0054, -0.0022,  0.0476,  ...,  0.0056, -0.0047,  0.0020],
        ...,
        [ 0.0048,  0.0084, -0.0117,  ...,  0.0721,  0.0004, -0.0058],
        [-0.0082,  0.0107,  0.0031,  ..., -0.0099,  0.0406, -0.0076],
        [ 0.0003,  0.0071, -0.0047,  ...,  0.0110, -0.0030,  0.0557]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.9414, -5.2188,  3.6738,  ...,  1.0234, -2.7168, -0.6367]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 19:46:56 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you deliver something, you are a deliverer
If you publish something, you are a publisher
If you compose something, you are a composer
If you believe something, you are a believer
If you manage something, you are a manager
If you write something, you are a writer
If you slay something, you are a slayer
If you preach something, you are a
2024-07-30 19:46:57 root INFO     [order_1_approx] starting weight calculation for If you deliver something, you are a deliverer
If you compose something, you are a composer
If you write something, you are a writer
If you believe something, you are a believer
If you slay something, you are a slayer
If you preach something, you are a preacher
If you manage something, you are a manager
If you publish something, you are a
2024-07-30 19:46:57 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-30 19:48:55 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2362,  0.0903,  0.2135,  ...,  0.4619, -0.2263,  0.4507],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.5859, -4.4219,  1.0957,  ..., -0.0654, -4.2266, -2.6270],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 5.4626e-02,  1.8301e-03,  1.7578e-02,  ...,  7.2556e-03,
         -1.2985e-02,  2.2217e-02],
        [-4.2648e-03,  5.2063e-02, -1.8940e-03,  ...,  1.3779e-02,
          7.4387e-03, -5.5161e-03],
        [ 2.0233e-02, -4.1924e-03,  6.0669e-02,  ...,  1.8120e-05,
         -1.7029e-02,  9.1553e-03],
        ...,
        [ 3.2806e-03,  2.0554e-02, -3.8528e-04,  ...,  4.9866e-02,
         -7.2575e-04, -5.2071e-04],
        [-6.0425e-03,  6.8207e-03,  5.0583e-03,  ..., -1.7426e-02,
          5.2277e-02, -1.6647e-02],
        [ 1.0803e-02, -4.2248e-04,  7.5302e-03,  ..., -1.7044e-02,
         -1.0468e-02,  4.7699e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.0352, -4.5820,  1.1855,  ...,  0.1296, -4.0312, -2.5527]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 19:48:56 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you deliver something, you are a deliverer
If you compose something, you are a composer
If you write something, you are a writer
If you believe something, you are a believer
If you slay something, you are a slayer
If you preach something, you are a preacher
If you manage something, you are a manager
If you publish something, you are a
2024-07-30 19:48:56 root INFO     [order_1_approx] starting weight calculation for If you believe something, you are a believer
If you manage something, you are a manager
If you publish something, you are a publisher
If you preach something, you are a preacher
If you compose something, you are a composer
If you slay something, you are a slayer
If you deliver something, you are a deliverer
If you write something, you are a
2024-07-30 19:48:56 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-30 19:50:49 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.5215, -0.5708,  0.4907,  ..., -0.8633, -0.3359, -0.4084],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.1895, -4.2070,  0.8721,  ..., -0.0537, -3.9180, -0.9990],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0464,  0.0010,  0.0043,  ...,  0.0046, -0.0175,  0.0160],
        [-0.0024,  0.0387,  0.0038,  ...,  0.0083,  0.0200, -0.0109],
        [ 0.0193, -0.0112,  0.0441,  ..., -0.0083, -0.0148,  0.0165],
        ...,
        [ 0.0239,  0.0168,  0.0043,  ...,  0.0327, -0.0093, -0.0100],
        [-0.0004,  0.0157,  0.0034,  ..., -0.0033,  0.0347,  0.0092],
        [-0.0004,  0.0150, -0.0035,  ..., -0.0133, -0.0107,  0.0359]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.3145, -4.1328,  0.8901,  ...,  0.2808, -3.8145, -1.1611]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 19:50:50 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you believe something, you are a believer
If you manage something, you are a manager
If you publish something, you are a publisher
If you preach something, you are a preacher
If you compose something, you are a composer
If you slay something, you are a slayer
If you deliver something, you are a deliverer
If you write something, you are a
2024-07-30 19:50:50 root INFO     [order_1_approx] starting weight calculation for If you preach something, you are a preacher
If you slay something, you are a slayer
If you manage something, you are a manager
If you write something, you are a writer
If you publish something, you are a publisher
If you compose something, you are a composer
If you believe something, you are a believer
If you deliver something, you are a
2024-07-30 19:50:50 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-30 19:52:49 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4351,  0.2463,  0.1627,  ...,  0.1724, -0.7930,  0.6108],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 6.1016, -4.8984,  2.2637,  ..., -0.0400, -3.5703, -1.8047],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0771,  0.0068,  0.0194,  ...,  0.0026, -0.0030,  0.0014],
        [-0.0269,  0.0571,  0.0005,  ...,  0.0164,  0.0287,  0.0012],
        [ 0.0218, -0.0003,  0.0562,  ...,  0.0040, -0.0274, -0.0118],
        ...,
        [ 0.0103,  0.0183,  0.0087,  ...,  0.0633, -0.0164,  0.0104],
        [-0.0049,  0.0118,  0.0133,  ..., -0.0123,  0.0573, -0.0071],
        [ 0.0008,  0.0015, -0.0156,  ..., -0.0067, -0.0049,  0.0586]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 5.7266, -4.2891,  2.4512,  ...,  0.2285, -3.3516, -1.7578]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 19:52:50 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you preach something, you are a preacher
If you slay something, you are a slayer
If you manage something, you are a manager
If you write something, you are a writer
If you publish something, you are a publisher
If you compose something, you are a composer
If you believe something, you are a believer
If you deliver something, you are a
2024-07-30 19:52:50 root INFO     [order_1_approx] starting weight calculation for If you manage something, you are a manager
If you compose something, you are a composer
If you write something, you are a writer
If you preach something, you are a preacher
If you slay something, you are a slayer
If you publish something, you are a publisher
If you deliver something, you are a deliverer
If you believe something, you are a
2024-07-30 19:52:50 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-30 19:54:47 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0229,  0.0913,  0.2734,  ..., -0.0144, -0.6440,  0.4529],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 5.3984, -4.8555,  3.4863,  ..., -1.3760, -3.5000, -2.1191],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0289,  0.0109,  0.0067,  ...,  0.0140, -0.0124,  0.0148],
        [-0.0073,  0.0269,  0.0189,  ...,  0.0249,  0.0118, -0.0102],
        [ 0.0127, -0.0159,  0.0314,  ..., -0.0046, -0.0094,  0.0085],
        ...,
        [ 0.0034, -0.0050, -0.0080,  ...,  0.0243, -0.0024, -0.0069],
        [ 0.0045,  0.0056,  0.0152,  ..., -0.0051,  0.0246, -0.0057],
        [ 0.0029,  0.0043, -0.0067,  ..., -0.0093, -0.0036,  0.0208]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 5.3164, -4.7539,  3.5781,  ..., -1.0488, -3.4707, -2.1758]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 19:54:47 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you manage something, you are a manager
If you compose something, you are a composer
If you write something, you are a writer
If you preach something, you are a preacher
If you slay something, you are a slayer
If you publish something, you are a publisher
If you deliver something, you are a deliverer
If you believe something, you are a
2024-07-30 19:54:47 root INFO     total operator prediction time: 927.3325946331024 seconds
2024-07-30 19:54:47 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on adj - superlative
2024-07-30 19:54:47 root INFO     building operator adj - superlative
2024-07-30 19:54:48 root INFO     [order_1_approx] starting weight calculation for If something is the most rare, it is rarest
If something is the most dumb, it is dumbest
If something is the most pure, it is purest
If something is the most happy, it is happiest
If something is the most nasty, it is nastiest
If something is the most subtle, it is subtlest
If something is the most sad, it is saddest
If something is the most healthy, it is
2024-07-30 19:54:48 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-30 19:56:40 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1294, -0.3833,  0.0539,  ..., -0.5098, -0.2341, -0.4919],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.3105, -6.8359, -0.9092,  ..., -0.4551, -1.8535, -2.0371],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 3.3905e-02, -7.5836e-03,  1.1139e-02,  ..., -7.3929e-03,
         -7.3624e-04,  4.2381e-03],
        [ 1.7090e-03,  4.8218e-02,  1.3252e-02,  ..., -9.3536e-03,
          1.5778e-02,  1.0178e-02],
        [ 6.6605e-03, -7.3929e-03,  3.2074e-02,  ..., -5.5962e-03,
         -9.1400e-03, -6.7101e-03],
        ...,
        [ 4.8866e-03,  9.5367e-03, -7.3547e-03,  ...,  4.1901e-02,
          4.5166e-03,  1.4954e-03],
        [-3.3617e-05,  2.0294e-03,  2.2354e-03,  ..., -4.6730e-05,
          4.2053e-02, -1.2344e-02],
        [-1.7700e-03, -9.5367e-03, -3.0041e-04,  ..., -7.0992e-03,
          2.5520e-03,  3.2471e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.2529, -6.6562, -0.9351,  ..., -0.2900, -1.6367, -2.0527]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 19:56:41 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is the most rare, it is rarest
If something is the most dumb, it is dumbest
If something is the most pure, it is purest
If something is the most happy, it is happiest
If something is the most nasty, it is nastiest
If something is the most subtle, it is subtlest
If something is the most sad, it is saddest
If something is the most healthy, it is
2024-07-30 19:56:41 root INFO     [order_1_approx] starting weight calculation for If something is the most subtle, it is subtlest
If something is the most rare, it is rarest
If something is the most healthy, it is healthiest
If something is the most sad, it is saddest
If something is the most happy, it is happiest
If something is the most pure, it is purest
If something is the most dumb, it is dumbest
If something is the most nasty, it is
2024-07-30 19:56:41 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-30 19:58:41 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0441, -0.3560, -0.1936,  ..., -0.4907, -0.1093, -0.3325],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.4563, -6.8633, -3.7461,  ..., -4.8789, -2.9180, -0.2305],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0365,  0.0017,  0.0167,  ..., -0.0130, -0.0063,  0.0009],
        [ 0.0035,  0.0295,  0.0035,  ...,  0.0023,  0.0117,  0.0018],
        [ 0.0022,  0.0080,  0.0214,  ...,  0.0030, -0.0054, -0.0021],
        ...,
        [ 0.0085,  0.0040, -0.0073,  ...,  0.0286,  0.0022, -0.0060],
        [ 0.0076,  0.0007,  0.0038,  ...,  0.0043,  0.0292, -0.0060],
        [-0.0010,  0.0063, -0.0007,  ..., -0.0033,  0.0009,  0.0250]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.4702, -6.6562, -3.5156,  ..., -4.9688, -2.6914, -0.2015]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 19:58:47 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is the most subtle, it is subtlest
If something is the most rare, it is rarest
If something is the most healthy, it is healthiest
If something is the most sad, it is saddest
If something is the most happy, it is happiest
If something is the most pure, it is purest
If something is the most dumb, it is dumbest
If something is the most nasty, it is
2024-07-30 19:58:47 root INFO     [order_1_approx] starting weight calculation for If something is the most nasty, it is nastiest
If something is the most sad, it is saddest
If something is the most happy, it is happiest
If something is the most healthy, it is healthiest
If something is the most dumb, it is dumbest
If something is the most rare, it is rarest
If something is the most subtle, it is subtlest
If something is the most pure, it is
2024-07-30 19:58:47 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-30 20:00:40 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0753,  0.1626,  0.9238,  ..., -0.1238,  0.1664,  0.0618],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.3320, -3.3125, -2.2949,  ..., -1.8408, -1.4951, -1.3398],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0526, -0.0141,  0.0022,  ..., -0.0108,  0.0070,  0.0080],
        [-0.0066,  0.0508,  0.0284,  ..., -0.0007,  0.0161,  0.0009],
        [ 0.0164, -0.0037,  0.0424,  ...,  0.0014, -0.0113, -0.0046],
        ...,
        [ 0.0058,  0.0113, -0.0172,  ...,  0.0446,  0.0053, -0.0091],
        [-0.0040, -0.0002, -0.0072,  ..., -0.0078,  0.0478, -0.0185],
        [-0.0012, -0.0112, -0.0052,  ...,  0.0010,  0.0107,  0.0399]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.5156, -3.3301, -2.2871,  ..., -1.7197, -1.0957, -1.6699]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 20:00:41 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is the most nasty, it is nastiest
If something is the most sad, it is saddest
If something is the most happy, it is happiest
If something is the most healthy, it is healthiest
If something is the most dumb, it is dumbest
If something is the most rare, it is rarest
If something is the most subtle, it is subtlest
If something is the most pure, it is
2024-07-30 20:00:41 root INFO     [order_1_approx] starting weight calculation for If something is the most nasty, it is nastiest
If something is the most healthy, it is healthiest
If something is the most dumb, it is dumbest
If something is the most sad, it is saddest
If something is the most pure, it is purest
If something is the most happy, it is happiest
If something is the most subtle, it is subtlest
If something is the most rare, it is
2024-07-30 20:00:41 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-30 20:02:39 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1357, -0.0708, -0.6719,  ..., -0.8154,  0.7759,  0.0387],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-3.7598, -3.8535, -1.2725,  ..., -3.8242, -1.8057, -2.2715],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0486, -0.0173,  0.0172,  ..., -0.0170, -0.0015,  0.0037],
        [ 0.0088,  0.0594,  0.0212,  ...,  0.0026,  0.0150,  0.0045],
        [ 0.0159, -0.0059,  0.0310,  ..., -0.0197, -0.0120,  0.0049],
        ...,
        [ 0.0098,  0.0186,  0.0011,  ...,  0.0444, -0.0113, -0.0093],
        [-0.0018,  0.0200,  0.0204,  ...,  0.0093,  0.0514, -0.0147],
        [-0.0001, -0.0134, -0.0119,  ..., -0.0134,  0.0073,  0.0499]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-3.7539, -3.8242, -1.4326,  ..., -4.0391, -1.6074, -2.5273]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 20:02:40 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is the most nasty, it is nastiest
If something is the most healthy, it is healthiest
If something is the most dumb, it is dumbest
If something is the most sad, it is saddest
If something is the most pure, it is purest
If something is the most happy, it is happiest
If something is the most subtle, it is subtlest
If something is the most rare, it is
2024-07-30 20:02:40 root INFO     [order_1_approx] starting weight calculation for If something is the most rare, it is rarest
If something is the most subtle, it is subtlest
If something is the most healthy, it is healthiest
If something is the most nasty, it is nastiest
If something is the most pure, it is purest
If something is the most dumb, it is dumbest
If something is the most happy, it is happiest
If something is the most sad, it is
2024-07-30 20:02:40 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-30 20:04:35 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1250, -0.0243, -0.3855,  ..., -0.0066, -0.6421,  0.0906],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.4229, -6.0547, -2.7520,  ..., -5.6680,  0.3027, -2.0195],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0189, -0.0080,  0.0003,  ..., -0.0090,  0.0063,  0.0057],
        [ 0.0084,  0.0224,  0.0113,  ...,  0.0065,  0.0133,  0.0009],
        [ 0.0059, -0.0060,  0.0162,  ...,  0.0003, -0.0073, -0.0052],
        ...,
        [ 0.0040,  0.0089,  0.0008,  ...,  0.0135, -0.0182,  0.0085],
        [ 0.0041, -0.0040,  0.0135,  ...,  0.0110,  0.0289, -0.0126],
        [-0.0006,  0.0069, -0.0038,  ..., -0.0153, -0.0029,  0.0215]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.3584, -5.8828, -2.6797,  ..., -5.7578,  0.3706, -2.0918]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 20:04:35 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is the most rare, it is rarest
If something is the most subtle, it is subtlest
If something is the most healthy, it is healthiest
If something is the most nasty, it is nastiest
If something is the most pure, it is purest
If something is the most dumb, it is dumbest
If something is the most happy, it is happiest
If something is the most sad, it is
2024-07-30 20:04:36 root INFO     [order_1_approx] starting weight calculation for If something is the most pure, it is purest
If something is the most dumb, it is dumbest
If something is the most sad, it is saddest
If something is the most nasty, it is nastiest
If something is the most healthy, it is healthiest
If something is the most rare, it is rarest
If something is the most subtle, it is subtlest
If something is the most happy, it is
2024-07-30 20:04:36 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-30 20:06:33 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1465, -0.1737,  0.1344,  ..., -0.4395, -0.5791, -0.2401],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.2363, -3.0684,  0.0928,  ...,  0.1777, -2.1777, -0.7402],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0391, -0.0058,  0.0148,  ...,  0.0054,  0.0040,  0.0158],
        [-0.0085,  0.0338,  0.0156,  ..., -0.0009,  0.0049,  0.0027],
        [ 0.0070, -0.0027,  0.0356,  ..., -0.0071, -0.0142, -0.0093],
        ...,
        [ 0.0014,  0.0140, -0.0147,  ...,  0.0405,  0.0009, -0.0055],
        [ 0.0031,  0.0036,  0.0114,  ..., -0.0068,  0.0370, -0.0178],
        [ 0.0044, -0.0076, -0.0053,  ..., -0.0063,  0.0040,  0.0439]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.0997, -2.7070, -0.0667,  ...,  0.5107, -2.2910, -0.8726]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 20:06:34 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is the most pure, it is purest
If something is the most dumb, it is dumbest
If something is the most sad, it is saddest
If something is the most nasty, it is nastiest
If something is the most healthy, it is healthiest
If something is the most rare, it is rarest
If something is the most subtle, it is subtlest
If something is the most happy, it is
2024-07-30 20:06:34 root INFO     [order_1_approx] starting weight calculation for If something is the most sad, it is saddest
If something is the most healthy, it is healthiest
If something is the most rare, it is rarest
If something is the most happy, it is happiest
If something is the most dumb, it is dumbest
If something is the most pure, it is purest
If something is the most nasty, it is nastiest
If something is the most subtle, it is
2024-07-30 20:06:34 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-30 20:08:28 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2212,  0.1515, -0.2430,  ..., -0.3477, -0.1208,  0.0607],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.0605, -1.5391, -0.2307,  ..., -2.4629, -1.7871, -1.5205],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0637, -0.0069,  0.0055,  ..., -0.0188,  0.0065, -0.0051],
        [ 0.0016,  0.0626,  0.0146,  ...,  0.0037,  0.0051, -0.0016],
        [ 0.0142, -0.0097,  0.0602,  ..., -0.0040, -0.0091, -0.0061],
        ...,
        [ 0.0062,  0.0237,  0.0067,  ...,  0.0565, -0.0003, -0.0074],
        [ 0.0115,  0.0092,  0.0079,  ..., -0.0059,  0.0558, -0.0073],
        [-0.0050, -0.0002,  0.0056,  ..., -0.0142, -0.0083,  0.0526]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.9302, -1.6719, -0.4429,  ..., -2.3418, -1.5781, -1.1641]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 20:08:29 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is the most sad, it is saddest
If something is the most healthy, it is healthiest
If something is the most rare, it is rarest
If something is the most happy, it is happiest
If something is the most dumb, it is dumbest
If something is the most pure, it is purest
If something is the most nasty, it is nastiest
If something is the most subtle, it is
2024-07-30 20:08:29 root INFO     [order_1_approx] starting weight calculation for If something is the most rare, it is rarest
If something is the most nasty, it is nastiest
If something is the most subtle, it is subtlest
If something is the most healthy, it is healthiest
If something is the most sad, it is saddest
If something is the most pure, it is purest
If something is the most happy, it is happiest
If something is the most dumb, it is
2024-07-30 20:08:30 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-30 20:10:26 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1379,  0.0125, -0.3203,  ..., -0.5195, -0.5781,  0.4546],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.7344, -3.3047,  2.3711,  ..., -4.3359, -1.5801, -0.9541],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 3.4943e-02, -1.0162e-02,  2.0569e-02,  ..., -1.9026e-03,
          1.8448e-02, -1.0292e-02],
        [-6.6452e-03,  4.5654e-02,  1.8387e-02,  ...,  1.0170e-02,
          9.8877e-03, -2.6703e-05],
        [ 3.7445e-02,  9.1858e-03,  3.7109e-02,  ..., -1.7761e-02,
         -1.3306e-02, -1.1253e-02],
        ...,
        [ 1.8585e-02,  1.5175e-02,  4.0169e-03,  ...,  5.1514e-02,
         -1.6266e-02, -1.5678e-03],
        [ 2.1973e-02,  1.6113e-02,  1.5533e-02,  ..., -1.4467e-03,
          3.6743e-02, -1.9470e-02],
        [-4.6539e-04,  1.4069e-02, -1.7233e-03,  ..., -2.5787e-02,
          6.7253e-03,  5.2185e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.6123, -3.3301,  1.5117,  ..., -4.6250, -1.5703, -1.1445]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 20:10:27 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is the most rare, it is rarest
If something is the most nasty, it is nastiest
If something is the most subtle, it is subtlest
If something is the most healthy, it is healthiest
If something is the most sad, it is saddest
If something is the most pure, it is purest
If something is the most happy, it is happiest
If something is the most dumb, it is
2024-07-30 20:10:27 root INFO     total operator prediction time: 939.5176048278809 seconds
2024-07-30 20:10:27 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on verb_3pSg - Ved
2024-07-30 20:10:27 root INFO     building operator verb_3pSg - Ved
2024-07-30 20:10:27 root INFO     [order_1_approx] starting weight calculation for When he publishes something, something has been published
When he appoints something, something has been appointed
When he involves something, something has been involved
When he tells something, something has been told
When he occurs something, something has been occurred
When he believes something, something has been believed
When he allows something, something has been allowed
When he seems something, something has been
2024-07-30 20:10:27 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-30 20:12:28 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1836, -0.1538,  0.1401,  ..., -0.0094, -0.3193, -0.1775],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.4805,  0.8071, -0.1277,  ...,  2.0039, -2.0781, -1.6055],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0712, -0.0344,  0.0280,  ..., -0.0014,  0.0096,  0.0146],
        [-0.0146,  0.0468,  0.0055,  ..., -0.0021, -0.0127, -0.0093],
        [-0.0007, -0.0065,  0.0640,  ..., -0.0159, -0.0044, -0.0166],
        ...,
        [-0.0009,  0.0167, -0.0023,  ...,  0.0661, -0.0040,  0.0139],
        [ 0.0154,  0.0051, -0.0196,  ...,  0.0024,  0.0552, -0.0181],
        [-0.0128,  0.0109,  0.0235,  ...,  0.0079, -0.0023,  0.0425]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.6309,  0.7285,  0.0887,  ...,  1.8848, -2.1055, -1.2559]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 20:12:29 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When he publishes something, something has been published
When he appoints something, something has been appointed
When he involves something, something has been involved
When he tells something, something has been told
When he occurs something, something has been occurred
When he believes something, something has been believed
When he allows something, something has been allowed
When he seems something, something has been
2024-07-30 20:12:29 root INFO     [order_1_approx] starting weight calculation for When he involves something, something has been involved
When he publishes something, something has been published
When he believes something, something has been believed
When he occurs something, something has been occurred
When he seems something, something has been seemed
When he tells something, something has been told
When he allows something, something has been allowed
When he appoints something, something has been
2024-07-30 20:12:29 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-30 20:14:28 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2957, -0.4678, -0.1040,  ...,  0.1880, -0.4114,  0.0968],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.9609, -0.0806,  1.2705,  ...,  0.9849, -2.3008,  0.2402],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0262, -0.0072,  0.0237,  ..., -0.0048, -0.0040,  0.0115],
        [-0.0052,  0.0236, -0.0064,  ...,  0.0137,  0.0021, -0.0092],
        [ 0.0027, -0.0022,  0.0147,  ..., -0.0001, -0.0049, -0.0127],
        ...,
        [-0.0011,  0.0037,  0.0049,  ...,  0.0257, -0.0073,  0.0091],
        [ 0.0039,  0.0058,  0.0038,  ...,  0.0106,  0.0288, -0.0303],
        [-0.0023,  0.0004,  0.0026,  ..., -0.0034, -0.0042,  0.0104]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.9277, -0.1810,  1.1875,  ...,  0.9746, -2.1680,  0.0470]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 20:14:33 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When he involves something, something has been involved
When he publishes something, something has been published
When he believes something, something has been believed
When he occurs something, something has been occurred
When he seems something, something has been seemed
When he tells something, something has been told
When he allows something, something has been allowed
When he appoints something, something has been
2024-07-30 20:14:33 root INFO     [order_1_approx] starting weight calculation for When he allows something, something has been allowed
When he seems something, something has been seemed
When he involves something, something has been involved
When he publishes something, something has been published
When he occurs something, something has been occurred
When he appoints something, something has been appointed
When he believes something, something has been believed
When he tells something, something has been
2024-07-30 20:14:34 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-30 20:16:27 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0057, -0.4141,  0.7568,  ..., -0.1912, -0.4487, -0.0018],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.1953,  0.7261,  3.2461,  ...,  3.0625, -5.1680, -1.9805],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0453, -0.0088,  0.0189,  ..., -0.0098, -0.0074,  0.0204],
        [-0.0302,  0.0185, -0.0063,  ...,  0.0124, -0.0084,  0.0030],
        [ 0.0086, -0.0111,  0.0238,  ..., -0.0084, -0.0145, -0.0154],
        ...,
        [-0.0076,  0.0057, -0.0018,  ...,  0.0404, -0.0105,  0.0086],
        [ 0.0106, -0.0095,  0.0020,  ..., -0.0122,  0.0368, -0.0146],
        [-0.0115,  0.0021,  0.0115,  ..., -0.0061,  0.0174,  0.0227]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.1250,  0.8018,  3.2500,  ...,  3.0469, -5.1602, -1.9961]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 20:16:28 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When he allows something, something has been allowed
When he seems something, something has been seemed
When he involves something, something has been involved
When he publishes something, something has been published
When he occurs something, something has been occurred
When he appoints something, something has been appointed
When he believes something, something has been believed
When he tells something, something has been
2024-07-30 20:16:28 root INFO     [order_1_approx] starting weight calculation for When he seems something, something has been seemed
When he publishes something, something has been published
When he allows something, something has been allowed
When he appoints something, something has been appointed
When he occurs something, something has been occurred
When he tells something, something has been told
When he believes something, something has been believed
When he involves something, something has been
2024-07-30 20:16:28 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-30 20:18:27 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3010, -0.4248,  0.3718,  ..., -0.0017, -0.6035, -0.2964],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.5098,  0.6675,  2.9648,  ...,  0.8193, -0.3643, -4.1953],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0590,  0.0013,  0.0354,  ...,  0.0006,  0.0011,  0.0158],
        [-0.0213,  0.0413,  0.0052,  ...,  0.0170, -0.0098, -0.0091],
        [ 0.0051, -0.0320,  0.0380,  ..., -0.0273, -0.0042, -0.0231],
        ...,
        [ 0.0090,  0.0001, -0.0100,  ...,  0.0548, -0.0185,  0.0169],
        [-0.0047,  0.0180, -0.0046,  ...,  0.0094,  0.0610, -0.0377],
        [-0.0171,  0.0206,  0.0296,  ...,  0.0094, -0.0019,  0.0548]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.3418,  0.8506,  2.7207,  ...,  0.6284, -0.3137, -3.6406]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 20:18:28 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When he seems something, something has been seemed
When he publishes something, something has been published
When he allows something, something has been allowed
When he appoints something, something has been appointed
When he occurs something, something has been occurred
When he tells something, something has been told
When he believes something, something has been believed
When he involves something, something has been
2024-07-30 20:18:28 root INFO     [order_1_approx] starting weight calculation for When he appoints something, something has been appointed
When he publishes something, something has been published
When he tells something, something has been told
When he involves something, something has been involved
When he allows something, something has been allowed
When he believes something, something has been believed
When he seems something, something has been seemed
When he occurs something, something has been
2024-07-30 20:18:29 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-30 20:20:28 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.3145, -0.1411,  0.0135,  ..., -0.1985, -0.0286, -0.6558],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.3428,  1.0479,  1.6338,  ...,  0.3975, -1.6729,  0.7041],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0529, -0.0150,  0.0525,  ...,  0.0217, -0.0102,  0.0327],
        [-0.0187,  0.0385, -0.0103,  ...,  0.0181, -0.0002, -0.0179],
        [ 0.0017, -0.0026,  0.0496,  ..., -0.0273, -0.0115, -0.0126],
        ...,
        [-0.0083,  0.0105,  0.0032,  ...,  0.0430, -0.0197,  0.0011],
        [ 0.0179,  0.0174,  0.0046,  ..., -0.0094,  0.0525, -0.0392],
        [ 0.0141,  0.0014,  0.0040,  ...,  0.0037, -0.0145,  0.0567]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.1328,  0.8618,  2.3613,  ...,  0.4626, -1.7441,  0.7188]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 20:20:29 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When he appoints something, something has been appointed
When he publishes something, something has been published
When he tells something, something has been told
When he involves something, something has been involved
When he allows something, something has been allowed
When he believes something, something has been believed
When he seems something, something has been seemed
When he occurs something, something has been
2024-07-30 20:20:29 root INFO     [order_1_approx] starting weight calculation for When he seems something, something has been seemed
When he allows something, something has been allowed
When he tells something, something has been told
When he occurs something, something has been occurred
When he appoints something, something has been appointed
When he involves something, something has been involved
When he believes something, something has been believed
When he publishes something, something has been
2024-07-30 20:20:29 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-30 20:22:29 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0167, -0.2861,  0.0682,  ...,  0.2021, -0.0169,  0.8145],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.4023, -3.2070,  2.3145,  ..., -1.4336, -3.3047, -0.0977],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0197, -0.0016,  0.0218,  ...,  0.0034, -0.0208,  0.0334],
        [-0.0178,  0.0123,  0.0116,  ...,  0.0121,  0.0073,  0.0058],
        [ 0.0193, -0.0072,  0.0294,  ..., -0.0032, -0.0148, -0.0037],
        ...,
        [-0.0094,  0.0025, -0.0015,  ...,  0.0261, -0.0001, -0.0014],
        [ 0.0088, -0.0038, -0.0130,  ..., -0.0098,  0.0289, -0.0285],
        [-0.0035,  0.0007,  0.0003,  ..., -0.0052, -0.0026, -0.0018]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.6836, -3.5098,  2.8008,  ..., -1.8311, -3.2520, -0.6182]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 20:22:30 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When he seems something, something has been seemed
When he allows something, something has been allowed
When he tells something, something has been told
When he occurs something, something has been occurred
When he appoints something, something has been appointed
When he involves something, something has been involved
When he believes something, something has been believed
When he publishes something, something has been
2024-07-30 20:22:30 root INFO     [order_1_approx] starting weight calculation for When he involves something, something has been involved
When he believes something, something has been believed
When he publishes something, something has been published
When he occurs something, something has been occurred
When he tells something, something has been told
When he seems something, something has been seemed
When he appoints something, something has been appointed
When he allows something, something has been
2024-07-30 20:22:30 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-30 20:24:28 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.4988,  0.0715,  0.1539,  ..., -0.5513, -0.3291,  0.1611],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.9727, -3.1348,  0.1121,  ...,  0.9600, -2.4473,  0.4082],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0566, -0.0084,  0.0226,  ..., -0.0081, -0.0150,  0.0082],
        [ 0.0009,  0.0344, -0.0015,  ...,  0.0249,  0.0090, -0.0029],
        [ 0.0009, -0.0123,  0.0407,  ..., -0.0258,  0.0029, -0.0342],
        ...,
        [-0.0060,  0.0129,  0.0022,  ...,  0.0511,  0.0072,  0.0094],
        [ 0.0066,  0.0123, -0.0040,  ...,  0.0056,  0.0461, -0.0327],
        [-0.0066, -0.0087,  0.0074,  ..., -0.0054, -0.0102,  0.0396]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.8398, -2.9082,  0.2959,  ...,  1.4199, -2.2773,  0.6328]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 20:24:29 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When he involves something, something has been involved
When he believes something, something has been believed
When he publishes something, something has been published
When he occurs something, something has been occurred
When he tells something, something has been told
When he seems something, something has been seemed
When he appoints something, something has been appointed
When he allows something, something has been
2024-07-30 20:24:29 root INFO     [order_1_approx] starting weight calculation for When he appoints something, something has been appointed
When he seems something, something has been seemed
When he occurs something, something has been occurred
When he tells something, something has been told
When he allows something, something has been allowed
When he involves something, something has been involved
When he publishes something, something has been published
When he believes something, something has been
2024-07-30 20:24:29 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-30 20:26:25 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0549,  0.1698,  0.0506,  ..., -0.0823, -0.6172,  0.7236],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.9961, -2.1445,  0.5972,  ...,  1.6533, -4.1641, -0.8184],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 2.0432e-02, -1.7967e-03,  7.8506e-03,  ...,  6.7215e-03,
         -6.4087e-03,  1.4198e-02],
        [-9.0256e-03,  2.2339e-02,  1.3481e-02,  ...,  2.7283e-02,
          1.2760e-03,  6.6605e-03],
        [ 2.6970e-03, -1.6499e-03,  2.7405e-02,  ..., -8.5144e-03,
         -1.8120e-05, -1.3748e-02],
        ...,
        [-3.8872e-03,  4.6425e-03,  2.8801e-04,  ...,  3.0243e-02,
         -2.5864e-03,  3.2730e-03],
        [ 1.7685e-02, -2.2926e-03,  2.5940e-04,  ..., -5.6725e-03,
          1.8570e-02, -2.7649e-02],
        [-4.6005e-03,  2.4014e-03,  2.0309e-02,  ..., -6.4621e-03,
          3.3092e-03,  1.1086e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 5.0234, -2.0137,  0.5835,  ...,  1.8086, -4.2734, -0.9590]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 20:26:26 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When he appoints something, something has been appointed
When he seems something, something has been seemed
When he occurs something, something has been occurred
When he tells something, something has been told
When he allows something, something has been allowed
When he involves something, something has been involved
When he publishes something, something has been published
When he believes something, something has been
2024-07-30 20:26:26 root INFO     total operator prediction time: 958.9631876945496 seconds
2024-07-30 20:26:26 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on noun - plural_reg
2024-07-30 20:26:26 root INFO     building operator noun - plural_reg
2024-07-30 20:26:26 root INFO     [order_1_approx] starting weight calculation for The plural form of version is versions
The plural form of street is streets
The plural form of night is nights
The plural form of student is students
The plural form of town is towns
The plural form of resource is resources
The plural form of difference is differences
The plural form of language is
2024-07-30 20:26:26 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-30 20:28:25 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.8608, -0.0327, -0.7974,  ...,  0.1572, -0.5850,  0.1093],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.2168, -2.8438,  1.4521,  ...,  1.1670, -1.8301, -3.2520],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0838,  0.0005,  0.0094,  ...,  0.0089, -0.0018,  0.0121],
        [-0.0119,  0.0885,  0.0117,  ...,  0.0165,  0.0045,  0.0004],
        [-0.0215, -0.0033,  0.0757,  ..., -0.0098,  0.0050,  0.0026],
        ...,
        [ 0.0139,  0.0050,  0.0015,  ...,  0.0853, -0.0078, -0.0044],
        [ 0.0007,  0.0152, -0.0009,  ..., -0.0217,  0.0625, -0.0063],
        [-0.0189, -0.0061, -0.0090,  ..., -0.0090, -0.0119,  0.0757]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.7012, -3.0508,  1.3857,  ...,  1.2090, -1.7129, -2.8555]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 20:28:26 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of version is versions
The plural form of street is streets
The plural form of night is nights
The plural form of student is students
The plural form of town is towns
The plural form of resource is resources
The plural form of difference is differences
The plural form of language is
2024-07-30 20:28:26 root INFO     [order_1_approx] starting weight calculation for The plural form of student is students
The plural form of resource is resources
The plural form of language is languages
The plural form of street is streets
The plural form of night is nights
The plural form of town is towns
The plural form of difference is differences
The plural form of version is
2024-07-30 20:28:26 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-30 20:30:26 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.6523,  0.3696,  0.0751,  ...,  0.1472, -0.0239, -0.0107],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.0254, -4.0156, -0.5562,  ..., -1.5703, -2.3008, -1.3379],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.1103, -0.0211,  0.0036,  ..., -0.0144, -0.0112, -0.0219],
        [-0.0112,  0.1106, -0.0090,  ...,  0.0143,  0.0153,  0.0227],
        [ 0.0162, -0.0072,  0.0947,  ..., -0.0170, -0.0214,  0.0010],
        ...,
        [ 0.0084,  0.0187, -0.0141,  ...,  0.1129,  0.0071,  0.0273],
        [-0.0059, -0.0088,  0.0152,  ..., -0.0215,  0.0614, -0.0155],
        [-0.0131,  0.0270, -0.0092,  ...,  0.0110, -0.0114,  0.1066]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.0283, -4.2461, -0.1770,  ..., -1.4443, -2.2773, -1.2871]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 20:30:27 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of student is students
The plural form of resource is resources
The plural form of language is languages
The plural form of street is streets
The plural form of night is nights
The plural form of town is towns
The plural form of difference is differences
The plural form of version is
2024-07-30 20:30:28 root INFO     [order_1_approx] starting weight calculation for The plural form of town is towns
The plural form of student is students
The plural form of language is languages
The plural form of street is streets
The plural form of night is nights
The plural form of resource is resources
The plural form of version is versions
The plural form of difference is
2024-07-30 20:30:28 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-30 20:32:25 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0575,  0.0085, -0.1627,  ...,  0.1140, -0.2410,  0.0726],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.9170, -1.0137,  3.0742,  ..., -2.9141, -3.0059, -1.5820],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0857,  0.0034, -0.0080,  ...,  0.0058,  0.0021,  0.0235],
        [ 0.0159,  0.0818,  0.0020,  ...,  0.0138,  0.0020,  0.0089],
        [-0.0081, -0.0057,  0.0453,  ..., -0.0154, -0.0102,  0.0060],
        ...,
        [ 0.0073,  0.0220,  0.0135,  ...,  0.0850, -0.0198,  0.0167],
        [-0.0209,  0.0056, -0.0005,  ..., -0.0074,  0.0747, -0.0215],
        [ 0.0140,  0.0291,  0.0044,  ...,  0.0040, -0.0347,  0.0941]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.1367, -1.4395,  2.9277,  ..., -2.5859, -3.1934, -1.2363]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 20:32:32 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of town is towns
The plural form of student is students
The plural form of language is languages
The plural form of street is streets
The plural form of night is nights
The plural form of resource is resources
The plural form of version is versions
The plural form of difference is
2024-07-30 20:32:32 root INFO     [order_1_approx] starting weight calculation for The plural form of language is languages
The plural form of difference is differences
The plural form of resource is resources
The plural form of version is versions
The plural form of street is streets
The plural form of town is towns
The plural form of student is students
The plural form of night is
2024-07-30 20:32:32 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-30 20:34:26 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3254,  0.1101, -0.0624,  ..., -0.0165, -0.5244,  0.0093],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.5864, -3.9531,  1.1992,  ..., -0.3787, -0.2344, -2.1797],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0905,  0.0073,  0.0016,  ...,  0.0135,  0.0139,  0.0405],
        [ 0.0092,  0.0995, -0.0043,  ...,  0.0072,  0.0199,  0.0057],
        [-0.0076,  0.0136,  0.0536,  ...,  0.0063, -0.0216,  0.0155],
        ...,
        [-0.0213,  0.0041, -0.0060,  ...,  0.0766, -0.0352, -0.0078],
        [-0.0067,  0.0015, -0.0012,  ..., -0.0080,  0.0495,  0.0057],
        [-0.0016,  0.0321, -0.0043,  ..., -0.0112,  0.0101,  0.0741]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.4966, -4.0312,  1.0576,  ..., -0.6172, -0.1279, -1.9551]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 20:34:27 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of language is languages
The plural form of difference is differences
The plural form of resource is resources
The plural form of version is versions
The plural form of street is streets
The plural form of town is towns
The plural form of student is students
The plural form of night is
2024-07-30 20:34:27 root INFO     [order_1_approx] starting weight calculation for The plural form of difference is differences
The plural form of street is streets
The plural form of version is versions
The plural form of town is towns
The plural form of night is nights
The plural form of resource is resources
The plural form of language is languages
The plural form of student is
2024-07-30 20:34:27 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-30 20:36:26 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1935,  0.1063, -0.4683,  ..., -0.1665, -0.2900,  0.0018],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.2070, -1.7012,  3.0000,  ..., -0.4829,  0.1631, -1.3105],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0614, -0.0071,  0.0175,  ..., -0.0089, -0.0135, -0.0246],
        [ 0.0022,  0.0789, -0.0128,  ..., -0.0014,  0.0084,  0.0162],
        [ 0.0086,  0.0059,  0.0654,  ..., -0.0116,  0.0004,  0.0038],
        ...,
        [ 0.0143,  0.0142, -0.0073,  ...,  0.0871,  0.0042,  0.0121],
        [-0.0137,  0.0189,  0.0068,  ..., -0.0180,  0.0500, -0.0123],
        [ 0.0046,  0.0039, -0.0201,  ...,  0.0019, -0.0166,  0.0803]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.2129, -1.9121,  3.0664,  ..., -0.3540,  0.3755, -0.9868]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 20:36:27 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of difference is differences
The plural form of street is streets
The plural form of version is versions
The plural form of town is towns
The plural form of night is nights
The plural form of resource is resources
The plural form of language is languages
The plural form of student is
2024-07-30 20:36:27 root INFO     [order_1_approx] starting weight calculation for The plural form of town is towns
The plural form of night is nights
The plural form of language is languages
The plural form of difference is differences
The plural form of street is streets
The plural form of version is versions
The plural form of student is students
The plural form of resource is
2024-07-30 20:36:27 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-30 20:38:27 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1685,  0.3862, -0.5474,  ..., -0.3318,  0.0561,  0.2793],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.0073, -3.2812,  0.4185,  ..., -1.8135, -1.4434, -1.1914],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0964, -0.0020,  0.0055,  ..., -0.0117,  0.0028, -0.0058],
        [-0.0242,  0.0795,  0.0152,  ...,  0.0176,  0.0219,  0.0155],
        [ 0.0050, -0.0020,  0.0919,  ...,  0.0061, -0.0033, -0.0037],
        ...,
        [-0.0107,  0.0051,  0.0002,  ...,  0.1124, -0.0107,  0.0039],
        [-0.0212,  0.0121, -0.0001,  ..., -0.0331,  0.0702, -0.0076],
        [ 0.0150, -0.0098,  0.0072,  ...,  0.0112, -0.0085,  0.0908]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.1665, -2.8789,  0.4783,  ..., -1.2520, -1.5186, -0.5493]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 20:38:28 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of town is towns
The plural form of night is nights
The plural form of language is languages
The plural form of difference is differences
The plural form of street is streets
The plural form of version is versions
The plural form of student is students
The plural form of resource is
2024-07-30 20:38:28 root INFO     [order_1_approx] starting weight calculation for The plural form of student is students
The plural form of resource is resources
The plural form of street is streets
The plural form of version is versions
The plural form of language is languages
The plural form of night is nights
The plural form of difference is differences
The plural form of town is
2024-07-30 20:38:28 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-30 20:40:26 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3499,  0.3662, -0.0364,  ..., -0.1826, -0.0720, -0.2554],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.5332, -4.1641,  0.4768,  ..., -0.6367,  0.5093, -1.3193],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0833,  0.0094,  0.0054,  ..., -0.0086, -0.0040,  0.0234],
        [ 0.0077,  0.0751, -0.0125,  ...,  0.0098,  0.0209,  0.0002],
        [ 0.0121,  0.0060,  0.0773,  ...,  0.0062, -0.0014,  0.0100],
        ...,
        [ 0.0087,  0.0039,  0.0031,  ...,  0.0640,  0.0032,  0.0048],
        [-0.0243,  0.0019,  0.0026,  ...,  0.0015,  0.0572, -0.0206],
        [-0.0049, -0.0014, -0.0011,  ..., -0.0074,  0.0011,  0.0655]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.1875, -4.1562,  0.5132,  ..., -0.7607,  0.4526, -1.5420]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 20:40:27 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of student is students
The plural form of resource is resources
The plural form of street is streets
The plural form of version is versions
The plural form of language is languages
The plural form of night is nights
The plural form of difference is differences
The plural form of town is
2024-07-30 20:40:28 root INFO     [order_1_approx] starting weight calculation for The plural form of night is nights
The plural form of student is students
The plural form of difference is differences
The plural form of language is languages
The plural form of town is towns
The plural form of resource is resources
The plural form of version is versions
The plural form of street is
2024-07-30 20:40:28 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-30 20:42:27 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1520,  0.1714,  0.1570,  ..., -0.3857,  0.1809,  0.0503],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.6699, -4.1797, -0.6650,  ...,  0.7622, -0.1726, -2.4297],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0747, -0.0091, -0.0456,  ..., -0.0225, -0.0225, -0.0242],
        [ 0.0026,  0.1030,  0.0213,  ...,  0.0245,  0.0227,  0.0094],
        [-0.0003,  0.0283,  0.0806,  ..., -0.0071, -0.0018,  0.0200],
        ...,
        [ 0.0136,  0.0355,  0.0191,  ...,  0.0812,  0.0054,  0.0215],
        [-0.0327,  0.0315, -0.0094,  ..., -0.0156,  0.0648,  0.0071],
        [ 0.0075,  0.0298,  0.0137,  ...,  0.0107,  0.0051,  0.0917]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.9902, -4.3594, -0.5137,  ...,  1.0537,  0.0304, -1.8281]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 20:42:28 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of night is nights
The plural form of student is students
The plural form of difference is differences
The plural form of language is languages
The plural form of town is towns
The plural form of resource is resources
The plural form of version is versions
The plural form of street is
2024-07-30 20:42:28 root INFO     total operator prediction time: 961.8100752830505 seconds
2024-07-30 20:42:28 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on verb_Ving - 3pSg
2024-07-30 20:42:28 root INFO     building operator verb_Ving - 3pSg
2024-07-30 20:42:28 root INFO     [order_1_approx] starting weight calculation for When something is teaching, it teaches
When something is believing, it believes
When something is following, it follows
When something is performing, it performs
When something is providing, it provides
When something is explaining, it explains
When something is considering, it considers
When something is developing, it
2024-07-30 20:42:28 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-30 20:44:28 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.7705,  0.1102, -0.3135,  ..., -0.2434, -0.3574, -0.2539],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.0859, -4.5547,  0.2676,  ..., -0.9336, -5.7344, -1.9111],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0545,  0.0082,  0.0078,  ..., -0.0022, -0.0145,  0.0039],
        [-0.0157,  0.0493,  0.0026,  ...,  0.0169,  0.0058,  0.0086],
        [ 0.0030, -0.0080,  0.0447,  ..., -0.0126,  0.0079, -0.0264],
        ...,
        [ 0.0112,  0.0015,  0.0165,  ...,  0.0639, -0.0094,  0.0039],
        [ 0.0045, -0.0011, -0.0024,  ..., -0.0140,  0.0551, -0.0258],
        [-0.0129, -0.0136, -0.0079,  ..., -0.0159, -0.0241,  0.0630]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.9316, -4.8867,  0.6143,  ..., -0.7285, -5.6953, -1.8906]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 20:44:29 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When something is teaching, it teaches
When something is believing, it believes
When something is following, it follows
When something is performing, it performs
When something is providing, it provides
When something is explaining, it explains
When something is considering, it considers
When something is developing, it
2024-07-30 20:44:29 root INFO     [order_1_approx] starting weight calculation for When something is performing, it performs
When something is providing, it provides
When something is developing, it develops
When something is explaining, it explains
When something is believing, it believes
When something is following, it follows
When something is considering, it considers
When something is teaching, it
2024-07-30 20:44:29 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-30 20:46:29 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2791,  0.4360, -0.3521,  ..., -0.6465, -0.7891,  0.4834],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.1055, -2.6855,  2.0664,  ...,  0.5449, -7.4023, -3.4023],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 3.6102e-02,  1.8997e-02, -2.5635e-03,  ..., -4.3640e-03,
         -1.0437e-02,  1.2886e-02],
        [-1.1909e-02,  3.8971e-02, -5.9814e-03,  ...,  5.7449e-03,
         -9.7198e-03,  7.3204e-03],
        [ 2.7657e-03, -3.1433e-03,  3.4515e-02,  ..., -1.2543e-02,
          4.7379e-03, -2.4506e-02],
        ...,
        [-9.9182e-05, -1.4259e-02,  1.1177e-02,  ...,  4.0100e-02,
         -7.5684e-03, -7.1754e-03],
        [-8.2703e-03, -1.1444e-02,  4.4250e-03,  ..., -6.7673e-03,
          4.1168e-02, -2.4048e-02],
        [-7.8659e-03,  7.4005e-04, -8.9645e-05,  ...,  6.2675e-03,
          5.4321e-03,  3.7109e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.9668, -2.6074,  2.4531,  ...,  0.5918, -7.4375, -3.3223]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 20:46:30 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When something is performing, it performs
When something is providing, it provides
When something is developing, it develops
When something is explaining, it explains
When something is believing, it believes
When something is following, it follows
When something is considering, it considers
When something is teaching, it
2024-07-30 20:46:30 root INFO     [order_1_approx] starting weight calculation for When something is teaching, it teaches
When something is considering, it considers
When something is developing, it develops
When something is believing, it believes
When something is explaining, it explains
When something is following, it follows
When something is providing, it provides
When something is performing, it
2024-07-30 20:46:30 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-30 20:48:26 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.6465, -0.0012, -0.1005,  ..., -0.8623, -0.4707, -0.8247],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.9375, -5.2148, -0.0273,  ..., -2.1055, -6.6641, -1.4395],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0511,  0.0072,  0.0052,  ..., -0.0009, -0.0020,  0.0212],
        [-0.0158,  0.0406, -0.0006,  ...,  0.0203,  0.0052,  0.0071],
        [ 0.0114,  0.0076,  0.0290,  ..., -0.0111, -0.0012, -0.0122],
        ...,
        [-0.0011, -0.0056,  0.0019,  ...,  0.0508, -0.0019,  0.0086],
        [ 0.0017, -0.0251,  0.0214,  ..., -0.0185,  0.0466, -0.0282],
        [ 0.0073, -0.0022,  0.0028,  ..., -0.0055, -0.0010,  0.0428]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.0469, -4.9453,  0.1511,  ..., -1.6514, -6.4570, -1.3887]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 20:48:29 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When something is teaching, it teaches
When something is considering, it considers
When something is developing, it develops
When something is believing, it believes
When something is explaining, it explains
When something is following, it follows
When something is providing, it provides
When something is performing, it
2024-07-30 20:48:30 root INFO     [order_1_approx] starting weight calculation for When something is explaining, it explains
When something is teaching, it teaches
When something is developing, it develops
When something is believing, it believes
When something is considering, it considers
When something is providing, it provides
When something is performing, it performs
When something is following, it
2024-07-30 20:48:30 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-30 20:50:29 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2163, -0.4014,  0.0246,  ...,  0.0681, -0.0874,  0.2830],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.0469, -2.5195,  1.4688,  ..., -1.4004, -7.1133, -1.4150],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0783, -0.0045,  0.0016,  ...,  0.0068,  0.0207,  0.0298],
        [-0.0078,  0.0646, -0.0110,  ...,  0.0105, -0.0021, -0.0020],
        [ 0.0012,  0.0207,  0.0578,  ..., -0.0140, -0.0092, -0.0313],
        ...,
        [-0.0118, -0.0012,  0.0050,  ...,  0.0622, -0.0196, -0.0117],
        [-0.0029,  0.0120, -0.0041,  ..., -0.0072,  0.0424, -0.0322],
        [ 0.0136,  0.0063, -0.0131,  ..., -0.0103,  0.0008,  0.0667]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.0801, -2.5176,  1.5244,  ..., -1.1709, -7.1523, -1.6582]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 20:50:30 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When something is explaining, it explains
When something is teaching, it teaches
When something is developing, it develops
When something is believing, it believes
When something is considering, it considers
When something is providing, it provides
When something is performing, it performs
When something is following, it
2024-07-30 20:50:30 root INFO     [order_1_approx] starting weight calculation for When something is teaching, it teaches
When something is explaining, it explains
When something is performing, it performs
When something is believing, it believes
When something is developing, it develops
When something is following, it follows
When something is considering, it considers
When something is providing, it
2024-07-30 20:50:30 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-30 20:52:24 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2732, -0.3472,  0.0753,  ..., -0.3228, -0.2448, -0.2083],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.3691, -6.4766,  0.1250,  ..., -1.4170, -7.2188, -0.2500],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 9.3262e-02,  2.4605e-03,  1.3214e-02,  ..., -3.2501e-03,
         -8.5831e-03,  1.8677e-02],
        [-3.1616e-02,  7.3303e-02,  8.2626e-03,  ...,  2.3453e-02,
          1.2772e-02,  2.0325e-02],
        [ 1.3474e-02, -1.3504e-03,  7.3486e-02,  ..., -2.5284e-02,
          1.3763e-02, -2.0370e-02],
        ...,
        [ 9.9182e-05, -9.8190e-03,  1.9135e-02,  ...,  8.0078e-02,
         -1.3306e-02,  1.6031e-03],
        [ 1.0345e-02, -1.9379e-02,  2.8610e-04,  ..., -2.0599e-02,
          8.7463e-02, -4.3762e-02],
        [-2.9125e-03,  9.2163e-03, -1.3840e-02,  ..., -1.8311e-02,
         -1.2970e-03,  8.9111e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.3828, -6.2227,  0.3003,  ..., -1.1934, -7.2344, -0.5977]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 20:52:25 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When something is teaching, it teaches
When something is explaining, it explains
When something is performing, it performs
When something is believing, it believes
When something is developing, it develops
When something is following, it follows
When something is considering, it considers
When something is providing, it
2024-07-30 20:52:25 root INFO     [order_1_approx] starting weight calculation for When something is performing, it performs
When something is developing, it develops
When something is following, it follows
When something is believing, it believes
When something is explaining, it explains
When something is teaching, it teaches
When something is providing, it provides
When something is considering, it
2024-07-30 20:52:25 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-30 20:54:25 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2900, -0.2251, -0.0207,  ..., -0.1458,  0.1820, -0.2334],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.0625, -4.1953,  2.3359,  ..., -2.0820, -4.9141, -0.1562],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0701, -0.0071,  0.0033,  ...,  0.0004, -0.0056,  0.0196],
        [-0.0113,  0.0465, -0.0023,  ...,  0.0083, -0.0001,  0.0097],
        [ 0.0029, -0.0017,  0.0606,  ..., -0.0215, -0.0018, -0.0368],
        ...,
        [-0.0037, -0.0106,  0.0316,  ...,  0.0640, -0.0046,  0.0086],
        [ 0.0006,  0.0087, -0.0011,  ..., -0.0204,  0.0513, -0.0353],
        [ 0.0073,  0.0003,  0.0078,  ..., -0.0048, -0.0126,  0.0500]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.9414, -4.1250,  2.2090,  ..., -1.3799, -5.4375, -0.2383]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 20:54:26 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When something is performing, it performs
When something is developing, it develops
When something is following, it follows
When something is believing, it believes
When something is explaining, it explains
When something is teaching, it teaches
When something is providing, it provides
When something is considering, it
2024-07-30 20:54:26 root INFO     [order_1_approx] starting weight calculation for When something is following, it follows
When something is performing, it performs
When something is explaining, it explains
When something is teaching, it teaches
When something is providing, it provides
When something is developing, it develops
When something is considering, it considers
When something is believing, it
2024-07-30 20:54:26 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-30 20:56:24 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3525,  0.1193,  0.0735,  ..., -0.2856, -0.6553,  0.6426],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.0547, -4.5234,  1.5312,  ..., -0.5020, -3.9961, -0.5625],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 3.1052e-02,  6.6566e-03,  1.1520e-03,  ...,  9.2468e-03,
         -3.3398e-03,  5.0583e-03],
        [-6.5994e-03,  4.9622e-02,  3.9177e-03,  ...,  1.9440e-02,
         -3.0994e-05,  1.1246e-02],
        [ 3.0022e-03, -1.6155e-03,  3.3417e-02,  ..., -1.4542e-02,
          2.5196e-03, -6.4697e-03],
        ...,
        [ 3.9978e-03, -1.8066e-02,  3.0460e-03,  ...,  2.7954e-02,
         -1.0979e-02,  3.8109e-03],
        [ 5.5695e-04, -1.5587e-02,  8.1558e-03,  ..., -1.6479e-02,
          3.2104e-02, -1.3306e-02],
        [ 9.0714e-03, -6.9427e-04,  1.0239e-02,  ..., -8.6212e-03,
         -2.0638e-03,  2.9343e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.0938, -4.5039,  1.7520,  ..., -0.2468, -4.2461, -0.8906]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 20:56:25 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When something is following, it follows
When something is performing, it performs
When something is explaining, it explains
When something is teaching, it teaches
When something is providing, it provides
When something is developing, it develops
When something is considering, it considers
When something is believing, it
2024-07-30 20:56:26 root INFO     [order_1_approx] starting weight calculation for When something is performing, it performs
When something is believing, it believes
When something is providing, it provides
When something is developing, it develops
When something is considering, it considers
When something is following, it follows
When something is teaching, it teaches
When something is explaining, it
2024-07-30 20:56:26 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-30 20:58:24 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1406, -0.7607,  0.3835,  ..., -0.5825, -0.0092, -0.3542],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.9883, -4.1719,  2.7734,  ...,  0.5454, -5.1484,  1.1602],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0298,  0.0135,  0.0081,  ...,  0.0041,  0.0007,  0.0166],
        [-0.0184,  0.0371,  0.0038,  ...,  0.0215,  0.0012, -0.0036],
        [ 0.0015,  0.0003,  0.0272,  ..., -0.0289,  0.0095, -0.0302],
        ...,
        [-0.0057, -0.0042,  0.0150,  ...,  0.0415,  0.0005, -0.0004],
        [ 0.0077, -0.0128,  0.0090,  ..., -0.0151,  0.0364, -0.0199],
        [ 0.0109,  0.0007,  0.0073,  ..., -0.0040, -0.0033,  0.0430]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.7461, -4.0352,  2.9902,  ...,  0.9365, -5.2383,  0.7275]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 20:58:25 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When something is performing, it performs
When something is believing, it believes
When something is providing, it provides
When something is developing, it develops
When something is considering, it considers
When something is following, it follows
When something is teaching, it teaches
When something is explaining, it
2024-07-30 20:58:25 root INFO     total operator prediction time: 957.4866178035736 seconds
2024-07-30 20:58:25 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on verb_inf - 3pSg
2024-07-30 20:58:25 root INFO     building operator verb_inf - 3pSg
2024-07-30 20:58:25 root INFO     [order_1_approx] starting weight calculation for I exist, he exists
I provide, he provides
I receive, he receives
I include, he includes
I understand, he understands
I refer, he refers
I apply, he applies
I become, he
2024-07-30 20:58:26 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-30 21:00:25 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2976,  0.3110, -0.0335,  ..., -0.0510, -0.3247,  0.7437],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.9805, -1.4199, -1.0918,  ..., -0.5811, -3.0664, -0.9258],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0419, -0.0120,  0.0088,  ..., -0.0033, -0.0084,  0.0227],
        [-0.0109,  0.0264, -0.0012,  ...,  0.0018,  0.0050, -0.0051],
        [ 0.0050,  0.0032,  0.0137,  ..., -0.0249, -0.0017, -0.0116],
        ...,
        [-0.0094, -0.0068,  0.0092,  ...,  0.0356, -0.0046,  0.0051],
        [ 0.0128,  0.0037, -0.0048,  ..., -0.0234,  0.0188,  0.0011],
        [-0.0036, -0.0013,  0.0006,  ...,  0.0025, -0.0131,  0.0261]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.5156, -1.4199, -1.1650,  ..., -0.4604, -3.2812, -0.6987]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 21:00:26 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for I exist, he exists
I provide, he provides
I receive, he receives
I include, he includes
I understand, he understands
I refer, he refers
I apply, he applies
I become, he
2024-07-30 21:00:26 root INFO     [order_1_approx] starting weight calculation for I receive, he receives
I become, he becomes
I apply, he applies
I exist, he exists
I provide, he provides
I include, he includes
I refer, he refers
I understand, he
2024-07-30 21:00:26 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-30 21:02:25 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1045, -0.2131,  0.1399,  ..., -0.1245, -0.2142, -0.2311],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.3945, -1.9854, -0.8379,  ..., -1.3691, -5.1953,  2.2363],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 4.0039e-02, -3.2539e-03,  4.0436e-03,  ..., -7.2861e-03,
          4.0007e-04,  1.5251e-02],
        [ 1.6479e-03,  3.8055e-02, -2.7237e-03,  ..., -1.5621e-03,
         -2.4128e-03,  3.7289e-03],
        [-9.4528e-03, -5.6648e-04,  2.5085e-02,  ..., -1.6754e-02,
         -2.6169e-03, -1.3718e-02],
        ...,
        [-2.6798e-03, -4.3793e-03,  1.0490e-05,  ...,  3.4180e-02,
         -1.3285e-03, -3.8300e-03],
        [-7.8125e-03, -5.3864e-03,  6.7749e-03,  ..., -1.8753e-02,
          2.8564e-02, -7.8049e-03],
        [ 2.1496e-03, -3.5591e-03,  2.9469e-03,  ..., -1.0490e-02,
         -1.1581e-02,  2.7557e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.9824, -1.9453, -0.5889,  ..., -1.3027, -5.2734,  2.0312]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 21:02:26 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for I receive, he receives
I become, he becomes
I apply, he applies
I exist, he exists
I provide, he provides
I include, he includes
I refer, he refers
I understand, he
2024-07-30 21:02:26 root INFO     [order_1_approx] starting weight calculation for I apply, he applies
I exist, he exists
I receive, he receives
I include, he includes
I understand, he understands
I become, he becomes
I refer, he refers
I provide, he
2024-07-30 21:02:26 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-30 21:04:25 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0454, -0.1772, -0.0997,  ..., -0.4258, -0.0812,  0.2595],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.2031, -3.8340, -0.0332,  ..., -1.9121, -7.4922,  1.0156],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0300, -0.0072,  0.0236,  ..., -0.0030, -0.0024,  0.0362],
        [-0.0181,  0.0305,  0.0148,  ...,  0.0047,  0.0124,  0.0115],
        [-0.0111, -0.0028,  0.0166,  ..., -0.0269,  0.0012, -0.0090],
        ...,
        [-0.0062, -0.0007,  0.0178,  ...,  0.0472, -0.0011,  0.0040],
        [ 0.0036, -0.0060, -0.0041,  ..., -0.0158,  0.0232, -0.0075],
        [-0.0091,  0.0034,  0.0140,  ..., -0.0187, -0.0129,  0.0407]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.0527, -3.6016,  0.0538,  ..., -1.6533, -7.1719,  1.0947]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 21:04:26 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for I apply, he applies
I exist, he exists
I receive, he receives
I include, he includes
I understand, he understands
I become, he becomes
I refer, he refers
I provide, he
2024-07-30 21:04:26 root INFO     [order_1_approx] starting weight calculation for I exist, he exists
I provide, he provides
I understand, he understands
I become, he becomes
I refer, he refers
I receive, he receives
I include, he includes
I apply, he
2024-07-30 21:04:26 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-30 21:06:23 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1829,  0.0900,  0.2085,  ..., -0.2039, -0.7520, -0.2708],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.9746, -2.6035, -0.9355,  ..., -1.2754, -7.4297,  0.0625],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 4.1870e-02, -4.2725e-04,  1.4404e-02,  ..., -3.3913e-03,
         -3.9520e-03,  1.9333e-02],
        [-7.4348e-03,  3.5309e-02,  9.1553e-05,  ..., -1.0902e-02,
          2.9411e-03,  5.8022e-03],
        [-2.8839e-03, -4.1122e-03,  1.2238e-02,  ..., -2.2583e-02,
          3.1643e-03, -1.7807e-02],
        ...,
        [-6.7444e-03, -1.7624e-03,  3.8757e-03,  ...,  4.4128e-02,
          5.8289e-03,  1.0080e-03],
        [-5.9395e-03, -8.5983e-03,  9.6588e-03,  ..., -1.2360e-03,
          3.5309e-02, -1.1772e-02],
        [ 6.0539e-03, -2.1420e-03,  1.3008e-02,  ..., -1.2299e-02,
         -1.9409e-02,  4.7882e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.6426, -2.7090, -0.9058,  ..., -1.5049, -7.1406,  0.3350]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 21:06:30 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for I exist, he exists
I provide, he provides
I understand, he understands
I become, he becomes
I refer, he refers
I receive, he receives
I include, he includes
I apply, he
2024-07-30 21:06:30 root INFO     [order_1_approx] starting weight calculation for I exist, he exists
I understand, he understands
I include, he includes
I provide, he provides
I apply, he applies
I become, he becomes
I receive, he receives
I refer, he
2024-07-30 21:06:30 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-30 21:08:28 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.5913, -0.2878, -0.2788,  ..., -0.5088,  0.0549,  0.4346],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.6611, -3.1270, -1.3096,  ..., -0.3823, -9.1406, -1.5674],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0386, -0.0013,  0.0043,  ..., -0.0066,  0.0081,  0.0109],
        [-0.0099,  0.0469, -0.0042,  ..., -0.0112,  0.0026, -0.0023],
        [-0.0065,  0.0046,  0.0346,  ..., -0.0152, -0.0040, -0.0056],
        ...,
        [ 0.0064,  0.0039,  0.0093,  ...,  0.0471, -0.0154,  0.0091],
        [-0.0102, -0.0073, -0.0047,  ..., -0.0100,  0.0298, -0.0173],
        [ 0.0006,  0.0026, -0.0014,  ..., -0.0064, -0.0037,  0.0432]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.4121, -3.1211, -1.3203,  ..., -0.5820, -9.0938, -1.4814]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 21:08:29 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for I exist, he exists
I understand, he understands
I include, he includes
I provide, he provides
I apply, he applies
I become, he becomes
I receive, he receives
I refer, he
2024-07-30 21:08:29 root INFO     [order_1_approx] starting weight calculation for I refer, he refers
I apply, he applies
I provide, he provides
I receive, he receives
I understand, he understands
I include, he includes
I become, he becomes
I exist, he
2024-07-30 21:08:29 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-30 21:10:26 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.6504, -0.1504, -0.9014,  ..., -0.3711, -0.4011, -0.0059],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.7295, -3.9023, -0.9473,  ..., -1.2227, -4.0234,  0.9873],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 1.1963e-02, -8.4457e-03,  2.1629e-03,  ..., -2.2755e-03,
         -6.8626e-03,  1.6602e-02],
        [-5.3291e-03,  1.9272e-02, -5.6572e-03,  ...,  7.7057e-03,
          6.8130e-03, -1.2535e-02],
        [ 6.3019e-03,  1.1734e-02,  1.2764e-02,  ..., -2.4750e-02,
         -1.7471e-02, -5.6801e-03],
        ...,
        [-1.3962e-02,  4.9515e-03,  1.5900e-02,  ...,  2.6871e-02,
         -2.2163e-03, -8.1711e-03],
        [-1.2299e-02, -5.7678e-03,  2.9049e-03,  ..., -1.1932e-02,
          1.4771e-02,  8.3923e-04],
        [-9.4414e-05, -3.7746e-03, -4.6272e-03,  ..., -1.0101e-02,
         -1.9119e-02,  1.8814e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.3975, -3.6406, -1.0156,  ..., -0.7988, -3.9922,  1.2393]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 21:10:26 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for I refer, he refers
I apply, he applies
I provide, he provides
I receive, he receives
I understand, he understands
I include, he includes
I become, he becomes
I exist, he
2024-07-30 21:10:27 root INFO     [order_1_approx] starting weight calculation for I exist, he exists
I understand, he understands
I receive, he receives
I provide, he provides
I refer, he refers
I become, he becomes
I apply, he applies
I include, he
2024-07-30 21:10:27 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-30 21:12:26 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.4158,  0.4546,  0.1516,  ...,  0.0631,  0.0413, -0.2993],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.6387, -1.1445, -0.4062,  ..., -1.9023, -6.3828, -0.8750],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0366, -0.0119,  0.0130,  ..., -0.0005, -0.0014,  0.0199],
        [-0.0085,  0.0410, -0.0038,  ..., -0.0090, -0.0085,  0.0024],
        [ 0.0008,  0.0006,  0.0208,  ..., -0.0252, -0.0054, -0.0011],
        ...,
        [ 0.0002, -0.0145,  0.0024,  ...,  0.0499, -0.0075,  0.0145],
        [-0.0093, -0.0022,  0.0126,  ..., -0.0146,  0.0305, -0.0134],
        [-0.0059,  0.0059,  0.0028,  ..., -0.0066, -0.0110,  0.0394]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.9668, -0.9756, -0.0483,  ..., -1.7812, -6.1289, -0.1470]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 21:12:27 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for I exist, he exists
I understand, he understands
I receive, he receives
I provide, he provides
I refer, he refers
I become, he becomes
I apply, he applies
I include, he
2024-07-30 21:12:27 root INFO     [order_1_approx] starting weight calculation for I become, he becomes
I refer, he refers
I exist, he exists
I apply, he applies
I include, he includes
I provide, he provides
I understand, he understands
I receive, he
2024-07-30 21:12:27 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-30 21:14:24 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.3865,  0.4277,  0.0372,  ..., -0.2766, -0.5674,  0.7432],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.1240, -1.9717, -2.9844,  ..., -2.3926, -7.3711, -2.3320],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0433,  0.0043,  0.0181,  ..., -0.0036, -0.0087,  0.0294],
        [-0.0143,  0.0398, -0.0048,  ..., -0.0014, -0.0003, -0.0018],
        [-0.0023,  0.0096,  0.0186,  ..., -0.0150, -0.0032, -0.0098],
        ...,
        [-0.0088,  0.0084,  0.0099,  ...,  0.0458, -0.0061, -0.0041],
        [ 0.0010, -0.0086, -0.0037,  ..., -0.0100,  0.0161, -0.0236],
        [ 0.0014,  0.0125,  0.0019,  ..., -0.0063, -0.0023,  0.0367]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.3435, -2.0977, -2.6250,  ..., -2.2109, -7.0938, -1.9512]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 21:14:25 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for I become, he becomes
I refer, he refers
I exist, he exists
I apply, he applies
I include, he includes
I provide, he provides
I understand, he understands
I receive, he
2024-07-30 21:14:25 root INFO     total operator prediction time: 960.1581976413727 seconds
2024-07-30 21:14:25 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on verb_inf - Ved
2024-07-30 21:14:25 root INFO     building operator verb_inf - Ved
2024-07-30 21:14:26 root INFO     [order_1_approx] starting weight calculation for If the present form is improve, the past form is improved
If the present form is provide, the past form is provided
If the present form is remain, the past form is remained
If the present form is reduce, the past form is reduced
If the present form is expect, the past form is expected
If the present form is replace, the past form is replaced
If the present form is apply, the past form is applied
If the present form is seem, the past form is
2024-07-30 21:14:26 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-30 21:16:17 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1832,  0.0485,  0.1155,  ..., -0.0575, -0.3433,  0.3564],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.5537,  0.5000, -0.2349,  ...,  0.5962, -2.3145, -2.1914],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.1193, -0.0264,  0.0249,  ...,  0.0004,  0.0208,  0.0071],
        [-0.0191,  0.1144,  0.0043,  ..., -0.0042, -0.0237, -0.0235],
        [ 0.0047,  0.0067,  0.0972,  ..., -0.0163,  0.0004, -0.0115],
        ...,
        [-0.0086,  0.0075, -0.0131,  ...,  0.1349, -0.0219,  0.0113],
        [ 0.0012, -0.0116, -0.0108,  ..., -0.0228,  0.0777, -0.0063],
        [-0.0011,  0.0027,  0.0002,  ..., -0.0126, -0.0119,  0.0968]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.8145,  0.7686, -0.6235,  ...,  0.4741, -2.3945, -2.1797]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 21:16:18 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If the present form is improve, the past form is improved
If the present form is provide, the past form is provided
If the present form is remain, the past form is remained
If the present form is reduce, the past form is reduced
If the present form is expect, the past form is expected
If the present form is replace, the past form is replaced
If the present form is apply, the past form is applied
If the present form is seem, the past form is
2024-07-30 21:16:18 root INFO     [order_1_approx] starting weight calculation for If the present form is replace, the past form is replaced
If the present form is reduce, the past form is reduced
If the present form is improve, the past form is improved
If the present form is remain, the past form is remained
If the present form is provide, the past form is provided
If the present form is apply, the past form is applied
If the present form is seem, the past form is seemed
If the present form is expect, the past form is
2024-07-30 21:16:18 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-30 21:18:14 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2422, -0.0084, -0.4087,  ..., -0.8174, -0.2374, -0.6851],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.5781,  0.9155, -1.0537,  ..., -1.4834, -2.6484, -2.3398],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0556, -0.0106,  0.0029,  ...,  0.0092,  0.0092,  0.0200],
        [-0.0186,  0.0557, -0.0028,  ...,  0.0046, -0.0061, -0.0065],
        [ 0.0136,  0.0055,  0.0398,  ..., -0.0125, -0.0107, -0.0007],
        ...,
        [ 0.0037, -0.0100, -0.0109,  ...,  0.0553, -0.0065,  0.0072],
        [-0.0016,  0.0058,  0.0057,  ..., -0.0076,  0.0380, -0.0200],
        [ 0.0028, -0.0024,  0.0095,  ..., -0.0003, -0.0111,  0.0422]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.5723,  1.0840, -1.0107,  ..., -1.3506, -2.4980, -2.2227]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 21:18:15 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If the present form is replace, the past form is replaced
If the present form is reduce, the past form is reduced
If the present form is improve, the past form is improved
If the present form is remain, the past form is remained
If the present form is provide, the past form is provided
If the present form is apply, the past form is applied
If the present form is seem, the past form is seemed
If the present form is expect, the past form is
2024-07-30 21:18:15 root INFO     [order_1_approx] starting weight calculation for If the present form is reduce, the past form is reduced
If the present form is remain, the past form is remained
If the present form is replace, the past form is replaced
If the present form is provide, the past form is provided
If the present form is improve, the past form is improved
If the present form is seem, the past form is seemed
If the present form is expect, the past form is expected
If the present form is apply, the past form is
2024-07-30 21:18:15 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-30 21:20:11 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2566, -0.1445,  0.3989,  ..., -0.1746, -0.5479, -0.3193],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.5703, -0.9502, -1.0859,  ..., -0.3206, -2.4062, -1.4258],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0826, -0.0114,  0.0190,  ...,  0.0041, -0.0013,  0.0154],
        [-0.0119,  0.0663, -0.0125,  ..., -0.0026, -0.0255, -0.0091],
        [ 0.0209, -0.0047,  0.0433,  ..., -0.0240, -0.0050, -0.0037],
        ...,
        [ 0.0026, -0.0155, -0.0186,  ...,  0.0869, -0.0092, -0.0004],
        [ 0.0173,  0.0016,  0.0052,  ..., -0.0137,  0.0554, -0.0171],
        [-0.0111, -0.0016, -0.0095,  ..., -0.0169, -0.0167,  0.0492]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.2881, -1.1426, -1.2119,  ..., -0.3262, -2.4727, -1.4658]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 21:20:12 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If the present form is reduce, the past form is reduced
If the present form is remain, the past form is remained
If the present form is replace, the past form is replaced
If the present form is provide, the past form is provided
If the present form is improve, the past form is improved
If the present form is seem, the past form is seemed
If the present form is expect, the past form is expected
If the present form is apply, the past form is
2024-07-30 21:20:12 root INFO     [order_1_approx] starting weight calculation for If the present form is seem, the past form is seemed
If the present form is provide, the past form is provided
If the present form is reduce, the past form is reduced
If the present form is improve, the past form is improved
If the present form is expect, the past form is expected
If the present form is remain, the past form is remained
If the present form is apply, the past form is applied
If the present form is replace, the past form is
2024-07-30 21:20:12 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-30 21:22:10 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1599, -0.1772, -0.6240,  ..., -0.4272, -0.2991, -0.2164],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.9023, -0.0071, -0.6846,  ..., -2.0781,  0.3364,  0.1416],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0820, -0.0264,  0.0185,  ..., -0.0047,  0.0100,  0.0173],
        [-0.0280,  0.0593, -0.0039,  ...,  0.0189,  0.0039,  0.0014],
        [ 0.0280, -0.0220,  0.0293,  ..., -0.0241, -0.0083, -0.0018],
        ...,
        [ 0.0011, -0.0010, -0.0269,  ...,  0.0822,  0.0026,  0.0050],
        [ 0.0255,  0.0128, -0.0035,  ..., -0.0158,  0.0722, -0.0157],
        [-0.0017, -0.0100, -0.0042,  ..., -0.0184, -0.0086,  0.0470]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.7578,  0.2922, -0.6646,  ..., -1.8516,  0.3857,  0.0386]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 21:22:12 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If the present form is seem, the past form is seemed
If the present form is provide, the past form is provided
If the present form is reduce, the past form is reduced
If the present form is improve, the past form is improved
If the present form is expect, the past form is expected
If the present form is remain, the past form is remained
If the present form is apply, the past form is applied
If the present form is replace, the past form is
2024-07-30 21:22:12 root INFO     [order_1_approx] starting weight calculation for If the present form is replace, the past form is replaced
If the present form is expect, the past form is expected
If the present form is apply, the past form is applied
If the present form is seem, the past form is seemed
If the present form is provide, the past form is provided
If the present form is remain, the past form is remained
If the present form is improve, the past form is improved
If the present form is reduce, the past form is
2024-07-30 21:22:12 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-30 21:24:11 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0307,  0.1984, -0.1038,  ..., -0.8125,  0.0282, -0.1946],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-2.7715, -0.2856,  0.9258,  ..., -3.7539, -0.9570, -4.1797],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0789, -0.0141,  0.0200,  ...,  0.0038,  0.0124,  0.0132],
        [-0.0171,  0.0693,  0.0027,  ...,  0.0030,  0.0069, -0.0003],
        [ 0.0233,  0.0134,  0.0610,  ..., -0.0098, -0.0128, -0.0129],
        ...,
        [ 0.0018, -0.0114, -0.0169,  ...,  0.0820,  0.0096,  0.0008],
        [ 0.0020,  0.0033, -0.0135,  ..., -0.0063,  0.0772, -0.0057],
        [-0.0233, -0.0215, -0.0089,  ..., -0.0244, -0.0018,  0.0547]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-2.4473, -0.3743,  0.6211,  ..., -3.7402, -0.8262, -4.1250]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 21:24:12 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If the present form is replace, the past form is replaced
If the present form is expect, the past form is expected
If the present form is apply, the past form is applied
If the present form is seem, the past form is seemed
If the present form is provide, the past form is provided
If the present form is remain, the past form is remained
If the present form is improve, the past form is improved
If the present form is reduce, the past form is
2024-07-30 21:24:13 root INFO     [order_1_approx] starting weight calculation for If the present form is apply, the past form is applied
If the present form is provide, the past form is provided
If the present form is reduce, the past form is reduced
If the present form is seem, the past form is seemed
If the present form is expect, the past form is expected
If the present form is replace, the past form is replaced
If the present form is remain, the past form is remained
If the present form is improve, the past form is
2024-07-30 21:24:13 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-30 21:26:12 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1910, -0.0853, -0.1639,  ..., -0.9028, -0.2700,  0.3647],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.2754, -0.5771,  0.8770,  ..., -1.3008, -1.1387, -1.7891],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0691, -0.0187, -0.0026,  ..., -0.0114,  0.0003,  0.0160],
        [-0.0095,  0.0577,  0.0064,  ...,  0.0172,  0.0031,  0.0003],
        [ 0.0279,  0.0070,  0.0478,  ..., -0.0023, -0.0056, -0.0117],
        ...,
        [ 0.0101, -0.0029, -0.0076,  ...,  0.0730,  0.0024, -0.0009],
        [ 0.0033,  0.0101,  0.0059,  ...,  0.0077,  0.0415, -0.0175],
        [-0.0105, -0.0175,  0.0009,  ..., -0.0043, -0.0281,  0.0425]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.4473, -0.8730,  0.5840,  ..., -1.4561, -0.9268, -2.0488]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 21:26:13 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If the present form is apply, the past form is applied
If the present form is provide, the past form is provided
If the present form is reduce, the past form is reduced
If the present form is seem, the past form is seemed
If the present form is expect, the past form is expected
If the present form is replace, the past form is replaced
If the present form is remain, the past form is remained
If the present form is improve, the past form is
2024-07-30 21:26:13 root INFO     [order_1_approx] starting weight calculation for If the present form is expect, the past form is expected
If the present form is reduce, the past form is reduced
If the present form is improve, the past form is improved
If the present form is replace, the past form is replaced
If the present form is seem, the past form is seemed
If the present form is remain, the past form is remained
If the present form is apply, the past form is applied
If the present form is provide, the past form is
2024-07-30 21:26:13 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-30 21:28:12 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0434, -0.1192, -0.0288,  ..., -0.6963, -0.3169,  0.1071],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.0205, -2.5273,  1.4971,  ..., -1.8828, -2.2598, -0.0410],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.1160, -0.0219,  0.0271,  ..., -0.0061, -0.0100,  0.0081],
        [-0.0364,  0.0776, -0.0020,  ...,  0.0114, -0.0053, -0.0067],
        [ 0.0135, -0.0142,  0.0646,  ..., -0.0345, -0.0026, -0.0004],
        ...,
        [-0.0060, -0.0260, -0.0065,  ...,  0.1240, -0.0033,  0.0133],
        [ 0.0156, -0.0117, -0.0116,  ..., -0.0017,  0.0815, -0.0213],
        [-0.0132,  0.0030, -0.0106,  ..., -0.0126, -0.0149,  0.0858]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.3467, -2.1602,  1.3213,  ..., -1.7256, -1.8535,  0.1068]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 21:28:13 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If the present form is expect, the past form is expected
If the present form is reduce, the past form is reduced
If the present form is improve, the past form is improved
If the present form is replace, the past form is replaced
If the present form is seem, the past form is seemed
If the present form is remain, the past form is remained
If the present form is apply, the past form is applied
If the present form is provide, the past form is
2024-07-30 21:28:14 root INFO     [order_1_approx] starting weight calculation for If the present form is replace, the past form is replaced
If the present form is expect, the past form is expected
If the present form is seem, the past form is seemed
If the present form is apply, the past form is applied
If the present form is reduce, the past form is reduced
If the present form is provide, the past form is provided
If the present form is improve, the past form is improved
If the present form is remain, the past form is
2024-07-30 21:28:14 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-30 21:30:11 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2402, -0.1758,  0.3372,  ..., -0.7397, -0.2273, -0.1536],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.7808, -1.0557,  0.2842,  ..., -2.2188, -0.6118, -1.9893],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.1215, -0.0248,  0.0069,  ..., -0.0131,  0.0326,  0.0332],
        [-0.0468,  0.0783, -0.0111,  ...,  0.0121,  0.0199, -0.0144],
        [ 0.0044,  0.0104,  0.0803,  ..., -0.0332, -0.0325, -0.0095],
        ...,
        [-0.0186,  0.0061,  0.0023,  ...,  0.1207, -0.0089, -0.0073],
        [ 0.0310, -0.0084, -0.0239,  ..., -0.0178,  0.0530,  0.0021],
        [-0.0179,  0.0142, -0.0267,  ..., -0.0086, -0.0184,  0.0674]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.7109, -0.7715,  0.0115,  ..., -1.8857, -0.9150, -2.4062]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 21:30:12 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If the present form is replace, the past form is replaced
If the present form is expect, the past form is expected
If the present form is seem, the past form is seemed
If the present form is apply, the past form is applied
If the present form is reduce, the past form is reduced
If the present form is provide, the past form is provided
If the present form is improve, the past form is improved
If the present form is remain, the past form is
2024-07-30 21:30:12 root INFO     total operator prediction time: 946.3830227851868 seconds
2024-07-30 21:30:12 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on verb_Ving - Ved
2024-07-30 21:30:12 root INFO     building operator verb_Ving - Ved
2024-07-30 21:30:12 root INFO     [order_1_approx] starting weight calculation for After something is hearing, it has heard
After something is including, it has included
After something is appointing, it has appointed
After something is describing, it has described
After something is receiving, it has received
After something is adding, it has added
After something is announcing, it has announced
After something is failing, it has
2024-07-30 21:30:12 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-30 21:32:04 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0718, -0.2278, -0.5742,  ..., -0.3638, -0.0646, -0.2549],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.1641,  0.0771,  3.6602,  ..., -2.5879, -1.5039, -1.7168],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0577, -0.0042,  0.0212,  ..., -0.0036,  0.0072,  0.0197],
        [-0.0238,  0.0555, -0.0224,  ...,  0.0088,  0.0212, -0.0085],
        [ 0.0278,  0.0069,  0.0429,  ..., -0.0138,  0.0157, -0.0175],
        ...,
        [-0.0090, -0.0100,  0.0110,  ...,  0.0682, -0.0044, -0.0009],
        [ 0.0220,  0.0027,  0.0026,  ..., -0.0166,  0.0608, -0.0205],
        [ 0.0069,  0.0193, -0.0093,  ..., -0.0056,  0.0004,  0.0641]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.2405,  0.5186,  3.5527,  ..., -2.0020, -1.3340, -2.0664]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 21:32:05 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for After something is hearing, it has heard
After something is including, it has included
After something is appointing, it has appointed
After something is describing, it has described
After something is receiving, it has received
After something is adding, it has added
After something is announcing, it has announced
After something is failing, it has
2024-07-30 21:32:05 root INFO     [order_1_approx] starting weight calculation for After something is failing, it has failed
After something is appointing, it has appointed
After something is announcing, it has announced
After something is hearing, it has heard
After something is receiving, it has received
After something is including, it has included
After something is describing, it has described
After something is adding, it has
2024-07-30 21:32:06 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-30 21:33:59 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1123, -0.7539,  0.3892,  ..., -0.4502, -0.4224, -0.2756],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.4111,  0.8037, -0.5332,  ..., -0.2090, -2.9727, -1.0537],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0922, -0.0049,  0.0246,  ..., -0.0104, -0.0049,  0.0153],
        [-0.0211,  0.0775, -0.0112,  ...,  0.0216,  0.0139,  0.0023],
        [ 0.0112, -0.0061,  0.0764,  ...,  0.0044,  0.0099, -0.0055],
        ...,
        [ 0.0153,  0.0170, -0.0007,  ...,  0.0864,  0.0064, -0.0025],
        [ 0.0225,  0.0080, -0.0026,  ..., -0.0045,  0.0822, -0.0187],
        [-0.0097,  0.0161, -0.0060,  ..., -0.0130, -0.0150,  0.0780]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.6074,  0.6733, -0.1743,  ..., -0.2983, -2.6797, -1.1582]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 21:34:00 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for After something is failing, it has failed
After something is appointing, it has appointed
After something is announcing, it has announced
After something is hearing, it has heard
After something is receiving, it has received
After something is including, it has included
After something is describing, it has described
After something is adding, it has
2024-07-30 21:34:00 root INFO     [order_1_approx] starting weight calculation for After something is appointing, it has appointed
After something is including, it has included
After something is announcing, it has announced
After something is hearing, it has heard
After something is adding, it has added
After something is failing, it has failed
After something is receiving, it has received
After something is describing, it has
2024-07-30 21:34:00 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-30 21:35:49 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0969, -0.5610,  0.3428,  ..., -0.1719, -0.3237, -0.7383],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.4434, -0.4268,  4.3047,  ..., -0.4150,  0.5684, -2.6758],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0769,  0.0084,  0.0207,  ..., -0.0005,  0.0172,  0.0113],
        [-0.0211,  0.0734, -0.0006,  ...,  0.0063,  0.0175, -0.0037],
        [ 0.0163, -0.0059,  0.0540,  ..., -0.0226,  0.0064, -0.0295],
        ...,
        [ 0.0018,  0.0040,  0.0089,  ...,  0.0820,  0.0024,  0.0113],
        [ 0.0095, -0.0078, -0.0014,  ..., -0.0060,  0.0553, -0.0029],
        [ 0.0015,  0.0124,  0.0133,  ..., -0.0118, -0.0136,  0.0580]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.3359,  0.0344,  4.4180,  ..., -0.2913,  0.2085, -2.7227]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 21:35:49 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for After something is appointing, it has appointed
After something is including, it has included
After something is announcing, it has announced
After something is hearing, it has heard
After something is adding, it has added
After something is failing, it has failed
After something is receiving, it has received
After something is describing, it has
2024-07-30 21:35:50 root INFO     [order_1_approx] starting weight calculation for After something is appointing, it has appointed
After something is announcing, it has announced
After something is including, it has included
After something is describing, it has described
After something is failing, it has failed
After something is adding, it has added
After something is receiving, it has received
After something is hearing, it has
2024-07-30 21:35:50 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-30 21:37:48 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0085, -0.1064,  0.2737,  ..., -0.3516, -0.3577,  0.3960],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.6719, -1.1055,  1.5469,  ..., -0.4287, -4.1406, -3.4902],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0605, -0.0001,  0.0271,  ..., -0.0111,  0.0048,  0.0091],
        [-0.0134,  0.0746, -0.0084,  ...,  0.0053,  0.0082, -0.0089],
        [ 0.0111,  0.0005,  0.0457,  ..., -0.0089,  0.0098, -0.0049],
        ...,
        [ 0.0161,  0.0109,  0.0098,  ...,  0.0655, -0.0076, -0.0062],
        [ 0.0066, -0.0008, -0.0011,  ..., -0.0096,  0.0475, -0.0260],
        [-0.0048,  0.0198,  0.0219,  ...,  0.0167,  0.0086,  0.0308]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.7930, -1.0186,  1.6064,  ..., -0.4353, -4.0664, -3.3770]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 21:37:49 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for After something is appointing, it has appointed
After something is announcing, it has announced
After something is including, it has included
After something is describing, it has described
After something is failing, it has failed
After something is adding, it has added
After something is receiving, it has received
After something is hearing, it has
2024-07-30 21:37:49 root INFO     [order_1_approx] starting weight calculation for After something is including, it has included
After something is failing, it has failed
After something is announcing, it has announced
After something is receiving, it has received
After something is adding, it has added
After something is hearing, it has heard
After something is describing, it has described
After something is appointing, it has
2024-07-30 21:37:49 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-30 21:39:44 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1753, -0.6377,  0.0056,  ...,  0.0034, -0.4497, -0.2639],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.3574, -0.7051,  2.4766,  ..., -1.4795, -1.1270, -0.2539],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0282, -0.0064,  0.0152,  ..., -0.0047, -0.0039,  0.0015],
        [-0.0238,  0.0297, -0.0083,  ...,  0.0106, -0.0028, -0.0119],
        [ 0.0025, -0.0116,  0.0258,  ..., -0.0013,  0.0021, -0.0142],
        ...,
        [ 0.0035, -0.0002, -0.0040,  ...,  0.0343, -0.0082,  0.0064],
        [ 0.0080, -0.0090,  0.0095,  ..., -0.0023,  0.0363, -0.0062],
        [ 0.0087,  0.0056, -0.0006,  ..., -0.0019, -0.0095,  0.0316]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.4519, -0.5967,  2.4141,  ..., -1.2793, -1.1025, -0.3601]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 21:39:45 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for After something is including, it has included
After something is failing, it has failed
After something is announcing, it has announced
After something is receiving, it has received
After something is adding, it has added
After something is hearing, it has heard
After something is describing, it has described
After something is appointing, it has
2024-07-30 21:39:45 root INFO     [order_1_approx] starting weight calculation for After something is appointing, it has appointed
After something is receiving, it has received
After something is describing, it has described
After something is adding, it has added
After something is announcing, it has announced
After something is hearing, it has heard
After something is failing, it has failed
After something is including, it has
2024-07-30 21:39:45 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-30 21:41:39 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2009, -0.0308,  0.1873,  ..., -0.0149, -0.0593, -0.7866],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.5820,  1.0566,  0.7842,  ..., -1.7148, -0.3564, -2.8770],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0810, -0.0116,  0.0364,  ...,  0.0027, -0.0003,  0.0088],
        [-0.0322,  0.0731, -0.0172,  ...,  0.0134, -0.0112, -0.0084],
        [ 0.0101, -0.0122,  0.0550,  ..., -0.0157, -0.0043, -0.0072],
        ...,
        [ 0.0092,  0.0037,  0.0065,  ...,  0.0829, -0.0010,  0.0042],
        [ 0.0117,  0.0176,  0.0198,  ..., -0.0118,  0.0674, -0.0146],
        [-0.0051,  0.0232, -0.0041,  ..., -0.0054, -0.0168,  0.0632]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.8965,  1.6631,  1.3555,  ..., -1.3887, -0.5425, -2.7910]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 21:41:40 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for After something is appointing, it has appointed
After something is receiving, it has received
After something is describing, it has described
After something is adding, it has added
After something is announcing, it has announced
After something is hearing, it has heard
After something is failing, it has failed
After something is including, it has
2024-07-30 21:41:41 root INFO     [order_1_approx] starting weight calculation for After something is hearing, it has heard
After something is announcing, it has announced
After something is including, it has included
After something is describing, it has described
After something is failing, it has failed
After something is adding, it has added
After something is appointing, it has appointed
After something is receiving, it has
2024-07-30 21:41:41 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-30 21:43:34 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0856,  0.2600,  0.1678,  ..., -0.1946, -0.7920,  0.0798],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.1865,  0.1558, -0.2827,  ..., -2.4727, -1.6133, -2.6680],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0848, -0.0112,  0.0260,  ..., -0.0145,  0.0023,  0.0259],
        [-0.0381,  0.0617, -0.0171,  ...,  0.0079,  0.0144, -0.0130],
        [ 0.0248,  0.0035,  0.0484,  ..., -0.0197,  0.0027, -0.0117],
        ...,
        [ 0.0037,  0.0111,  0.0107,  ...,  0.0865, -0.0231,  0.0013],
        [ 0.0205,  0.0131, -0.0022,  ..., -0.0127,  0.0708, -0.0141],
        [-0.0171,  0.0130,  0.0016,  ..., -0.0035,  0.0041,  0.0521]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.1504,  0.0815, -0.0288,  ..., -2.4258, -1.6123, -2.6719]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 21:43:35 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for After something is hearing, it has heard
After something is announcing, it has announced
After something is including, it has included
After something is describing, it has described
After something is failing, it has failed
After something is adding, it has added
After something is appointing, it has appointed
After something is receiving, it has
2024-07-30 21:43:35 root INFO     [order_1_approx] starting weight calculation for After something is including, it has included
After something is hearing, it has heard
After something is receiving, it has received
After something is describing, it has described
After something is adding, it has added
After something is appointing, it has appointed
After something is failing, it has failed
After something is announcing, it has
2024-07-30 21:43:35 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-30 21:45:34 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2302,  0.4163, -0.0056,  ..., -0.1266, -0.4229,  0.1042],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.7754, -2.0078,  2.5938,  ..., -0.4026, -1.6582,  0.7891],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0613, -0.0141,  0.0229,  ...,  0.0030, -0.0059,  0.0284],
        [-0.0318,  0.0475, -0.0031,  ...,  0.0135,  0.0009, -0.0064],
        [ 0.0087, -0.0042,  0.0418,  ..., -0.0047,  0.0006, -0.0019],
        ...,
        [-0.0037,  0.0020, -0.0106,  ...,  0.0508,  0.0023,  0.0117],
        [ 0.0173,  0.0061,  0.0044,  ..., -0.0008,  0.0400, -0.0074],
        [ 0.0111,  0.0101,  0.0017,  ..., -0.0132, -0.0096,  0.0323]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.8584, -1.8428,  2.9863,  ..., -0.1047, -1.6094,  0.4663]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 21:45:35 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for After something is including, it has included
After something is hearing, it has heard
After something is receiving, it has received
After something is describing, it has described
After something is adding, it has added
After something is appointing, it has appointed
After something is failing, it has failed
After something is announcing, it has
2024-07-30 21:45:35 root INFO     total operator prediction time: 923.3011274337769 seconds
2024-07-30 21:45:35 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on Ving - verb_inf
2024-07-30 21:45:35 root INFO     building operator Ving - verb_inf
2024-07-30 21:45:35 root INFO     [order_1_approx] starting weight calculation for receiving is the active form of receive
improving is the active form of improve
establishing is the active form of establish
believing is the active form of believe
sitting is the active form of sit
developing is the active form of develop
seeming is the active form of seem
applying is the active form of
2024-07-30 21:45:35 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-30 21:47:36 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2338, -0.1653,  0.5342,  ..., -0.0012, -0.4133, -0.5518],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.3281, -3.6406, -1.1172,  ...,  2.9414, -2.8438, -2.8145],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0981, -0.0160,  0.0137,  ...,  0.0070, -0.0073,  0.0162],
        [-0.0043,  0.0732, -0.0033,  ..., -0.0181, -0.0030,  0.0083],
        [ 0.0145, -0.0081,  0.0576,  ..., -0.0100,  0.0013,  0.0031],
        ...,
        [-0.0030, -0.0019, -0.0098,  ...,  0.0822, -0.0114, -0.0010],
        [-0.0055,  0.0040,  0.0103,  ...,  0.0002,  0.0696, -0.0114],
        [ 0.0100,  0.0060, -0.0118,  ..., -0.0075, -0.0111,  0.0932]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.4504, -4.0039, -1.2705,  ...,  3.0352, -2.9434, -2.5234]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 21:47:37 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for receiving is the active form of receive
improving is the active form of improve
establishing is the active form of establish
believing is the active form of believe
sitting is the active form of sit
developing is the active form of develop
seeming is the active form of seem
applying is the active form of
2024-07-30 21:47:37 root INFO     [order_1_approx] starting weight calculation for establishing is the active form of establish
believing is the active form of believe
sitting is the active form of sit
applying is the active form of apply
developing is the active form of develop
seeming is the active form of seem
improving is the active form of improve
receiving is the active form of
2024-07-30 21:47:37 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-30 21:49:37 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2952,  0.3208,  0.0739,  ..., -0.2083, -0.4998,  0.2456],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.5957, -3.6406, -1.8477,  ...,  0.0415, -0.5830, -4.0195],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0808, -0.0117,  0.0239,  ...,  0.0050,  0.0050,  0.0423],
        [-0.0075,  0.0688, -0.0097,  ..., -0.0028,  0.0058, -0.0049],
        [ 0.0177, -0.0061,  0.0422,  ..., -0.0222, -0.0083, -0.0029],
        ...,
        [ 0.0010, -0.0044, -0.0106,  ...,  0.0759, -0.0232, -0.0119],
        [-0.0093,  0.0064,  0.0075,  ..., -0.0113,  0.0607, -0.0182],
        [ 0.0031,  0.0024, -0.0112,  ..., -0.0042,  0.0072,  0.0762]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.2244, -3.7793, -1.9482,  ...,  0.0375, -0.6689, -3.8555]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 21:49:37 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for establishing is the active form of establish
believing is the active form of believe
sitting is the active form of sit
applying is the active form of apply
developing is the active form of develop
seeming is the active form of seem
improving is the active form of improve
receiving is the active form of
2024-07-30 21:49:38 root INFO     [order_1_approx] starting weight calculation for believing is the active form of believe
applying is the active form of apply
developing is the active form of develop
receiving is the active form of receive
improving is the active form of improve
seeming is the active form of seem
sitting is the active form of sit
establishing is the active form of
2024-07-30 21:49:38 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-30 21:51:38 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1799, -0.1227, -0.2598,  ..., -0.0360, -0.9570,  0.0909],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.9863, -4.8398,  0.4902,  ...,  2.9805, -2.4570, -3.0078],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0518, -0.0062,  0.0162,  ...,  0.0030, -0.0012,  0.0191],
        [ 0.0019,  0.0459,  0.0035,  ...,  0.0016,  0.0006, -0.0030],
        [ 0.0062, -0.0034,  0.0371,  ..., -0.0015,  0.0005,  0.0005],
        ...,
        [ 0.0167,  0.0037, -0.0072,  ...,  0.0439, -0.0127, -0.0062],
        [ 0.0016,  0.0194,  0.0114,  ..., -0.0034,  0.0367, -0.0088],
        [ 0.0085,  0.0039, -0.0090,  ..., -0.0114, -0.0070,  0.0416]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.2197, -4.8516,  0.4656,  ...,  3.0820, -2.5371, -3.0586]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 21:51:39 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for believing is the active form of believe
applying is the active form of apply
developing is the active form of develop
receiving is the active form of receive
improving is the active form of improve
seeming is the active form of seem
sitting is the active form of sit
establishing is the active form of
2024-07-30 21:51:39 root INFO     [order_1_approx] starting weight calculation for developing is the active form of develop
improving is the active form of improve
applying is the active form of apply
receiving is the active form of receive
believing is the active form of believe
sitting is the active form of sit
establishing is the active form of establish
seeming is the active form of
2024-07-30 21:51:39 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-30 21:53:39 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1516, -0.3562,  0.4380,  ..., -0.4790, -0.5234, -0.2467],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.5723, -3.8965, -1.0723,  ...,  2.6367, -0.6934, -4.0859],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 7.9590e-02, -1.2772e-02,  1.7914e-02,  ...,  8.0185e-03,
         -7.9269e-03,  1.8555e-02],
        [ 6.5231e-04,  6.7505e-02,  1.2642e-02,  ...,  9.3842e-03,
         -1.8478e-02, -1.3664e-02],
        [ 6.2370e-03, -1.0239e-02,  5.2185e-02,  ..., -1.1032e-02,
          1.2894e-02, -1.1292e-02],
        ...,
        [ 1.7166e-05,  1.0048e-02, -1.6441e-03,  ...,  7.5195e-02,
         -2.0172e-02,  5.3787e-03],
        [ 1.6041e-03, -5.6458e-04,  6.8169e-03,  ..., -1.6830e-02,
          5.3772e-02, -1.8265e-02],
        [ 4.1161e-03,  8.8196e-03,  5.0354e-04,  ..., -8.5678e-03,
         -1.1795e-02,  6.6162e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.4893, -3.9238, -1.0215,  ...,  2.8281, -0.6230, -3.8965]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 21:53:40 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for developing is the active form of develop
improving is the active form of improve
applying is the active form of apply
receiving is the active form of receive
believing is the active form of believe
sitting is the active form of sit
establishing is the active form of establish
seeming is the active form of
2024-07-30 21:53:40 root INFO     [order_1_approx] starting weight calculation for receiving is the active form of receive
establishing is the active form of establish
applying is the active form of apply
seeming is the active form of seem
developing is the active form of develop
sitting is the active form of sit
believing is the active form of believe
improving is the active form of
2024-07-30 21:53:40 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-30 21:55:34 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0096, -0.5767, -0.2244,  ..., -0.5869, -0.0721,  0.3621],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.9648, -4.4844, -1.3057,  ...,  2.8125, -1.0176, -3.0312],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0607,  0.0007,  0.0055,  ..., -0.0038, -0.0069,  0.0195],
        [ 0.0025,  0.0414,  0.0053,  ..., -0.0016,  0.0053, -0.0011],
        [ 0.0113, -0.0089,  0.0424,  ..., -0.0060,  0.0009, -0.0038],
        ...,
        [ 0.0003,  0.0131, -0.0041,  ...,  0.0543, -0.0051, -0.0072],
        [-0.0049,  0.0085,  0.0057,  ...,  0.0086,  0.0421, -0.0119],
        [-0.0023, -0.0054, -0.0112,  ..., -0.0009, -0.0090,  0.0446]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.8730, -4.5430, -1.3574,  ...,  2.6289, -0.9629, -2.9844]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 21:55:35 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for receiving is the active form of receive
establishing is the active form of establish
applying is the active form of apply
seeming is the active form of seem
developing is the active form of develop
sitting is the active form of sit
believing is the active form of believe
improving is the active form of
2024-07-30 21:55:35 root INFO     [order_1_approx] starting weight calculation for establishing is the active form of establish
improving is the active form of improve
seeming is the active form of seem
applying is the active form of apply
sitting is the active form of sit
believing is the active form of believe
receiving is the active form of receive
developing is the active form of
2024-07-30 21:55:35 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-30 21:57:33 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.5674, -0.0288, -0.6460,  ..., -0.3582, -0.3940, -0.0758],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.8164, -4.7031,  2.3906,  ...,  1.5625, -1.7266, -2.9102],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 4.4189e-02, -2.7390e-03,  9.9182e-03,  ...,  1.0281e-03,
         -7.1869e-03,  1.4435e-02],
        [-6.3515e-04,  3.5187e-02,  5.7220e-03,  ..., -7.5455e-03,
          3.5667e-03, -2.5730e-03],
        [ 1.4832e-02, -7.1526e-05,  2.6230e-02,  ..., -1.0880e-02,
          2.3518e-03, -6.5842e-03],
        ...,
        [ 4.8523e-03,  1.6403e-03, -1.8940e-03,  ...,  3.7384e-02,
         -1.2222e-02,  3.4370e-03],
        [ 1.7300e-03,  1.4412e-02,  2.8362e-03,  ...,  2.5101e-03,
          3.0121e-02, -1.3680e-02],
        [-3.5114e-03, -1.9102e-03, -8.4000e-03,  ..., -9.8038e-03,
         -7.1487e-03,  3.8940e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.7969, -4.6836,  2.2637,  ...,  1.5859, -1.8809, -2.7852]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 21:57:34 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for establishing is the active form of establish
improving is the active form of improve
seeming is the active form of seem
applying is the active form of apply
sitting is the active form of sit
believing is the active form of believe
receiving is the active form of receive
developing is the active form of
2024-07-30 21:57:34 root INFO     [order_1_approx] starting weight calculation for establishing is the active form of establish
sitting is the active form of sit
seeming is the active form of seem
improving is the active form of improve
applying is the active form of apply
developing is the active form of develop
receiving is the active form of receive
believing is the active form of
2024-07-30 21:57:34 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-30 21:59:31 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3188,  0.3716, -0.0718,  ..., -0.3340, -0.5449,  0.6953],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.7930, -6.0156,  0.6719,  ...,  1.5371, -1.5254, -3.2227],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 5.1117e-02, -1.5793e-03,  6.0120e-03,  ..., -4.0398e-03,
         -9.1476e-03,  1.5335e-02],
        [ 1.4076e-03,  4.5563e-02,  8.4610e-03,  ...,  1.3687e-02,
          4.6730e-03,  5.8823e-03],
        [ 1.8555e-02,  1.4744e-03,  3.5339e-02,  ..., -1.2604e-02,
         -6.5422e-03,  1.3504e-03],
        ...,
        [ 3.5477e-03, -9.2850e-03, -2.0103e-03,  ...,  5.2551e-02,
         -9.4757e-03, -7.6294e-05],
        [ 1.1406e-02,  1.2009e-02,  6.2332e-03,  ..., -1.5278e-03,
          4.1321e-02, -1.3321e-02],
        [ 1.7014e-02, -8.2855e-03, -2.5768e-03,  ...,  3.9673e-04,
         -8.0261e-03,  4.7424e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.6055, -5.9375,  0.3848,  ...,  1.6816, -1.5869, -3.2578]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 21:59:31 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for establishing is the active form of establish
sitting is the active form of sit
seeming is the active form of seem
improving is the active form of improve
applying is the active form of apply
developing is the active form of develop
receiving is the active form of receive
believing is the active form of
2024-07-30 21:59:32 root INFO     [order_1_approx] starting weight calculation for receiving is the active form of receive
believing is the active form of believe
applying is the active form of apply
improving is the active form of improve
seeming is the active form of seem
developing is the active form of develop
establishing is the active form of establish
sitting is the active form of
2024-07-30 21:59:32 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-30 22:01:32 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4644, -0.7637, -0.4829,  ...,  0.0842, -0.7700, -0.0482],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.5381, -2.9180, -0.5381,  ..., -0.6719,  0.6143, -3.5195],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 1.0809e-01, -1.1772e-02,  3.7193e-03,  ...,  3.2806e-03,
         -7.5722e-04,  6.4545e-03],
        [ 1.5305e-02,  7.8491e-02,  2.5826e-03,  ..., -3.9940e-03,
         -8.7891e-03, -1.7977e-03],
        [-4.7417e-03, -4.1733e-03,  6.8665e-02,  ..., -1.8356e-02,
         -8.8348e-03, -1.0612e-02],
        ...,
        [ 4.8971e-04, -7.9193e-03,  3.9864e-04,  ...,  8.1116e-02,
         -1.3664e-02, -1.8082e-02],
        [ 2.7580e-03,  8.0490e-03, -5.3787e-04,  ..., -1.5686e-02,
          6.0730e-02, -8.1863e-03],
        [-4.0817e-03,  1.1932e-02, -1.2054e-02,  ...,  9.5367e-06,
         -6.7673e-03,  8.1604e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.4043, -3.1445, -0.7266,  ..., -0.4302,  0.4111, -3.5391]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 22:01:33 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for receiving is the active form of receive
believing is the active form of believe
applying is the active form of apply
improving is the active form of improve
seeming is the active form of seem
developing is the active form of develop
establishing is the active form of establish
sitting is the active form of
2024-07-30 22:01:33 root INFO     total operator prediction time: 957.9605460166931 seconds
2024-07-30 22:01:33 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on noun - plural_irreg
2024-07-30 22:01:33 root INFO     building operator noun - plural_irreg
2024-07-30 22:01:33 root INFO     [order_1_approx] starting weight calculation for The plural form of authority is authorities
The plural form of army is armies
The plural form of duty is duties
The plural form of species is species
The plural form of technology is technologies
The plural form of variety is varieties
The plural form of analysis is analyses
The plural form of story is
2024-07-30 22:01:33 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-30 22:03:33 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.4106,  0.4075, -0.0249,  ..., -0.3115, -0.7285, -0.4141],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.9570, -2.0039,  1.0645,  ..., -0.4316, -1.4775, -1.9893],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 9.4543e-02,  1.3657e-03,  2.9602e-02,  ..., -1.1414e-02,
         -4.6234e-03,  7.4463e-03],
        [-3.2158e-03,  8.6975e-02, -1.1795e-02,  ...,  8.7509e-03,
          2.2964e-03,  1.9836e-02],
        [-1.0330e-02,  1.1683e-03,  6.8420e-02,  ...,  8.7976e-04,
         -1.1650e-02,  1.4343e-02],
        ...,
        [ 1.5808e-02,  2.1317e-02, -2.1301e-02,  ...,  9.8022e-02,
         -1.0254e-02,  1.0254e-02],
        [-1.8707e-02,  1.6235e-02,  1.8646e-02,  ...,  4.6234e-03,
          6.5796e-02, -1.9958e-02],
        [ 8.1482e-03,  1.8509e-02,  3.5048e-05,  ..., -3.2735e-04,
         -8.4610e-03,  8.8074e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.3906, -2.2617,  1.3135,  ..., -0.5015, -1.6191, -1.8203]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 22:03:34 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of authority is authorities
The plural form of army is armies
The plural form of duty is duties
The plural form of species is species
The plural form of technology is technologies
The plural form of variety is varieties
The plural form of analysis is analyses
The plural form of story is
2024-07-30 22:03:34 root INFO     [order_1_approx] starting weight calculation for The plural form of army is armies
The plural form of authority is authorities
The plural form of variety is varieties
The plural form of analysis is analyses
The plural form of story is stories
The plural form of duty is duties
The plural form of species is species
The plural form of technology is
2024-07-30 22:03:34 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-30 22:05:32 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4778,  0.1982, -0.0962,  ..., -0.3140, -0.4673, -0.3882],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.3047, -0.5918,  0.8149,  ...,  1.3105, -4.1797, -2.1484],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0649, -0.0042,  0.0022,  ..., -0.0161, -0.0014,  0.0133],
        [-0.0136,  0.0835, -0.0163,  ...,  0.0144, -0.0029,  0.0061],
        [ 0.0080,  0.0107,  0.0568,  ..., -0.0078,  0.0079,  0.0124],
        ...,
        [ 0.0178,  0.0093, -0.0023,  ...,  0.0768, -0.0074, -0.0013],
        [ 0.0004,  0.0228,  0.0175,  ..., -0.0089,  0.0558, -0.0075],
        [-0.0057, -0.0003, -0.0092,  ..., -0.0228, -0.0166,  0.0598]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.1797, -0.8550,  0.9746,  ...,  1.3867, -3.7559, -1.5254]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 22:05:35 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of army is armies
The plural form of authority is authorities
The plural form of variety is varieties
The plural form of analysis is analyses
The plural form of story is stories
The plural form of duty is duties
The plural form of species is species
The plural form of technology is
2024-07-30 22:05:38 root INFO     [order_1_approx] starting weight calculation for The plural form of variety is varieties
The plural form of duty is duties
The plural form of analysis is analyses
The plural form of technology is technologies
The plural form of story is stories
The plural form of authority is authorities
The plural form of army is armies
The plural form of species is
2024-07-30 22:05:39 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-30 22:07:29 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4919,  0.2725, -0.3054,  ...,  0.3098, -0.1531,  0.3894],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.8750, -3.1934,  0.1631,  ..., -0.1260, -3.3867, -3.0664],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 6.6589e-02,  3.6392e-03,  2.0279e-02,  ..., -1.2207e-02,
          2.0279e-02,  4.3182e-03],
        [ 1.1810e-02,  6.5796e-02,  1.0826e-02,  ...,  6.8741e-03,
          1.2146e-02,  5.0850e-03],
        [ 3.9597e-03, -1.5717e-02,  4.7089e-02,  ..., -7.3242e-03,
         -4.5967e-03,  1.7456e-02],
        ...,
        [-1.3046e-03, -9.9258e-03,  5.7678e-03,  ...,  7.4707e-02,
         -5.0621e-03,  3.7460e-03],
        [-1.2024e-02,  1.5472e-02, -3.6926e-03,  ..., -2.6108e-02,
          5.1880e-02,  9.9182e-03],
        [-3.0975e-03,  1.1459e-02, -6.1035e-05,  ...,  1.8494e-02,
         -9.7122e-03,  6.4148e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.9326, -3.4258,  0.4697,  ..., -0.1592, -3.4336, -2.8164]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 22:07:30 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of variety is varieties
The plural form of duty is duties
The plural form of analysis is analyses
The plural form of technology is technologies
The plural form of story is stories
The plural form of authority is authorities
The plural form of army is armies
The plural form of species is
2024-07-30 22:07:30 root INFO     [order_1_approx] starting weight calculation for The plural form of technology is technologies
The plural form of species is species
The plural form of story is stories
The plural form of army is armies
The plural form of variety is varieties
The plural form of authority is authorities
The plural form of duty is duties
The plural form of analysis is
2024-07-30 22:07:30 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-30 22:09:26 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0271,  0.4744, -0.1716,  ...,  0.2212, -0.5361,  0.0929],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.5879,  0.2296,  3.3438,  ..., -1.0938, -3.2188, -1.6016],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.1055,  0.0238,  0.0172,  ..., -0.0146, -0.0167,  0.0286],
        [ 0.0031,  0.1060,  0.0063,  ...,  0.0180, -0.0017,  0.0032],
        [-0.0037, -0.0173,  0.0835,  ..., -0.0162, -0.0030,  0.0083],
        ...,
        [ 0.0134,  0.0068,  0.0009,  ...,  0.1038, -0.0087,  0.0170],
        [-0.0024,  0.0306,  0.0065,  ..., -0.0191,  0.0857, -0.0277],
        [ 0.0067,  0.0167,  0.0159,  ...,  0.0179, -0.0037,  0.0934]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.2751,  0.1644,  3.5488,  ..., -1.1982, -2.7383, -1.2734]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 22:09:27 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of technology is technologies
The plural form of species is species
The plural form of story is stories
The plural form of army is armies
The plural form of variety is varieties
The plural form of authority is authorities
The plural form of duty is duties
The plural form of analysis is
2024-07-30 22:09:27 root INFO     [order_1_approx] starting weight calculation for The plural form of species is species
The plural form of analysis is analyses
The plural form of story is stories
The plural form of army is armies
The plural form of technology is technologies
The plural form of duty is duties
The plural form of authority is authorities
The plural form of variety is
2024-07-30 22:09:27 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-30 22:11:26 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3901,  0.4004, -0.4150,  ..., -0.0623, -0.4875,  0.3213],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.8755, -2.0957,  0.6426,  ..., -2.8262, -3.8555, -2.5078],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.1185,  0.0040,  0.0115,  ...,  0.0071,  0.0319,  0.0341],
        [-0.0117,  0.1091,  0.0105,  ...,  0.0112, -0.0024,  0.0178],
        [ 0.0194, -0.0029,  0.0631,  ..., -0.0319,  0.0022,  0.0287],
        ...,
        [ 0.0188,  0.0150,  0.0046,  ...,  0.1008, -0.0103,  0.0086],
        [-0.0035,  0.0163,  0.0217,  ..., -0.0253,  0.0847, -0.0267],
        [ 0.0024,  0.0447,  0.0073,  ...,  0.0063, -0.0195,  0.0825]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.2363, -2.2832,  0.8887,  ..., -2.7109, -3.4883, -1.7490]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 22:11:27 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of species is species
The plural form of analysis is analyses
The plural form of story is stories
The plural form of army is armies
The plural form of technology is technologies
The plural form of duty is duties
The plural form of authority is authorities
The plural form of variety is
2024-07-30 22:11:27 root INFO     [order_1_approx] starting weight calculation for The plural form of species is species
The plural form of technology is technologies
The plural form of story is stories
The plural form of army is armies
The plural form of authority is authorities
The plural form of variety is varieties
The plural form of analysis is analyses
The plural form of duty is
2024-07-30 22:11:27 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-30 22:13:18 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2529,  1.1758,  0.0891,  ..., -0.2925, -0.7539, -0.1390],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.1113, -1.5879,  2.6250,  ..., -1.3799, -2.1895, -2.8281],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0933,  0.0124,  0.0303,  ...,  0.0190,  0.0140,  0.0094],
        [-0.0243,  0.0760,  0.0079,  ...,  0.0106,  0.0098,  0.0035],
        [ 0.0206,  0.0054,  0.0665,  ..., -0.0028, -0.0134,  0.0017],
        ...,
        [ 0.0025,  0.0015, -0.0054,  ...,  0.0917, -0.0105,  0.0005],
        [-0.0036,  0.0375,  0.0118,  ..., -0.0230,  0.0707, -0.0060],
        [ 0.0172,  0.0021, -0.0008,  ..., -0.0122, -0.0012,  0.0928]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.4258, -1.6738,  2.4551,  ..., -1.3760, -2.2266, -2.2773]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 22:13:19 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of species is species
The plural form of technology is technologies
The plural form of story is stories
The plural form of army is armies
The plural form of authority is authorities
The plural form of variety is varieties
The plural form of analysis is analyses
The plural form of duty is
2024-07-30 22:13:19 root INFO     [order_1_approx] starting weight calculation for The plural form of duty is duties
The plural form of variety is varieties
The plural form of technology is technologies
The plural form of story is stories
The plural form of species is species
The plural form of analysis is analyses
The plural form of army is armies
The plural form of authority is
2024-07-30 22:13:20 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-30 22:15:17 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1361,  0.5908, -0.2162,  ..., -0.0328, -0.5425, -0.0809],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.0156, -2.8672,  1.1465,  ..., -0.9692, -1.4492, -2.4180],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0721,  0.0157,  0.0011,  ...,  0.0006,  0.0002,  0.0036],
        [-0.0077,  0.0708,  0.0155,  ...,  0.0108, -0.0074,  0.0125],
        [ 0.0208,  0.0015,  0.0369,  ..., -0.0079, -0.0015, -0.0035],
        ...,
        [ 0.0054,  0.0055,  0.0018,  ...,  0.0591, -0.0092, -0.0022],
        [-0.0206,  0.0205,  0.0127,  ..., -0.0113,  0.0570, -0.0056],
        [ 0.0329, -0.0129, -0.0015,  ...,  0.0192,  0.0018,  0.0474]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.0117, -2.6445,  1.3760,  ..., -1.0771, -1.4404, -2.1855]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 22:15:18 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of duty is duties
The plural form of variety is varieties
The plural form of technology is technologies
The plural form of story is stories
The plural form of species is species
The plural form of analysis is analyses
The plural form of army is armies
The plural form of authority is
2024-07-30 22:15:18 root INFO     [order_1_approx] starting weight calculation for The plural form of species is species
The plural form of variety is varieties
The plural form of technology is technologies
The plural form of authority is authorities
The plural form of duty is duties
The plural form of story is stories
The plural form of analysis is analyses
The plural form of army is
2024-07-30 22:15:18 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-30 22:17:18 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1270,  0.4016, -0.2141,  ..., -0.1315, -0.3560,  0.1461],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.6265, -5.5430,  2.4648,  ..., -1.5547, -0.7915, -2.4727],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0768,  0.0090,  0.0077,  ..., -0.0058, -0.0028, -0.0026],
        [ 0.0012,  0.0922,  0.0066,  ...,  0.0180,  0.0180, -0.0072],
        [ 0.0153, -0.0126,  0.0502,  ..., -0.0215,  0.0005,  0.0108],
        ...,
        [ 0.0170,  0.0109,  0.0206,  ...,  0.0713,  0.0052,  0.0023],
        [-0.0300,  0.0125, -0.0033,  ..., -0.0138,  0.0714, -0.0132],
        [-0.0040, -0.0043, -0.0060,  ...,  0.0076, -0.0047,  0.0700]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.6655, -5.4062,  2.6602,  ..., -1.7627, -0.2563, -1.7295]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 22:17:19 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of species is species
The plural form of variety is varieties
The plural form of technology is technologies
The plural form of authority is authorities
The plural form of duty is duties
The plural form of story is stories
The plural form of analysis is analyses
The plural form of army is
2024-07-30 22:17:19 root INFO     total operator prediction time: 946.386967420578 seconds
2024-07-30 22:17:19 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on meronyms - member
2024-07-30 22:17:19 root INFO     building operator meronyms - member
2024-07-30 22:17:20 root INFO     [order_1_approx] starting weight calculation for A fish is a member of a school
A spouse is a member of a couple
A shrub is a member of a shrubbery
A state is a member of a country
A christian is a member of a congregation
A member is a member of a club
A juror is a member of a jury
A listener is a member of a
2024-07-30 22:17:20 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-30 22:19:17 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4011, -0.0459, -0.3330,  ...,  0.3967, -0.0975, -0.1550],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.7188, -5.5156,  4.3828,  ...,  0.5664, -1.5146, -1.7422],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0659,  0.0081,  0.0214,  ...,  0.0217, -0.0029,  0.0126],
        [-0.0148,  0.0512,  0.0175,  ..., -0.0100,  0.0071, -0.0219],
        [ 0.0028, -0.0046,  0.0739,  ...,  0.0074,  0.0247,  0.0102],
        ...,
        [ 0.0241,  0.0012, -0.0056,  ...,  0.0761,  0.0047, -0.0190],
        [ 0.0063,  0.0164, -0.0039,  ...,  0.0076,  0.0719, -0.0114],
        [-0.0030, -0.0175, -0.0118,  ...,  0.0100, -0.0072,  0.0767]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.6650, -5.6094,  4.6367,  ...,  0.1504, -1.5029, -1.6982]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 22:19:18 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A fish is a member of a school
A spouse is a member of a couple
A shrub is a member of a shrubbery
A state is a member of a country
A christian is a member of a congregation
A member is a member of a club
A juror is a member of a jury
A listener is a member of a
2024-07-30 22:19:18 root INFO     [order_1_approx] starting weight calculation for A listener is a member of a audience
A juror is a member of a jury
A member is a member of a club
A spouse is a member of a couple
A shrub is a member of a shrubbery
A state is a member of a country
A christian is a member of a congregation
A fish is a member of a
2024-07-30 22:19:18 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-30 22:21:14 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2166,  0.4482, -0.3772,  ..., -0.6670, -0.0049,  0.2450],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 6.1133, -2.7461,  2.9688,  ..., -3.5352, -3.7930, -0.9834],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0424,  0.0110,  0.0096,  ...,  0.0166, -0.0027,  0.0038],
        [-0.0001,  0.0307, -0.0013,  ..., -0.0258,  0.0160, -0.0146],
        [-0.0009,  0.0070,  0.0458,  ...,  0.0038, -0.0112,  0.0110],
        ...,
        [-0.0053, -0.0131,  0.0083,  ...,  0.0691,  0.0029, -0.0029],
        [ 0.0120,  0.0057, -0.0061,  ..., -0.0043,  0.0408, -0.0144],
        [-0.0068, -0.0088, -0.0116,  ..., -0.0090, -0.0063,  0.0589]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 5.7656, -2.8027,  3.1562,  ..., -3.4453, -3.6992, -1.0664]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 22:21:15 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A listener is a member of a audience
A juror is a member of a jury
A member is a member of a club
A spouse is a member of a couple
A shrub is a member of a shrubbery
A state is a member of a country
A christian is a member of a congregation
A fish is a member of a
2024-07-30 22:21:15 root INFO     [order_1_approx] starting weight calculation for A listener is a member of a audience
A state is a member of a country
A shrub is a member of a shrubbery
A fish is a member of a school
A juror is a member of a jury
A christian is a member of a congregation
A spouse is a member of a couple
A member is a member of a
2024-07-30 22:21:15 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-30 22:23:13 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 1.1572, -0.1703, -0.1021,  ..., -0.2196,  0.5103, -0.2416],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.1992, -1.5850,  2.6328,  ..., -2.7246,  0.8516, -0.6353],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 1.2894e-02,  4.8256e-03,  4.8971e-04,  ..., -4.0359e-03,
         -1.2665e-03,  1.4744e-03],
        [-1.4563e-03,  9.8267e-03,  3.8300e-03,  ..., -7.4005e-03,
          1.5364e-03, -1.9073e-03],
        [ 1.7490e-03, -7.0477e-04,  1.0590e-02,  ...,  3.5405e-05,
          1.0748e-03, -1.8196e-03],
        ...,
        [ 1.6556e-03, -2.9297e-03,  2.0256e-03,  ...,  1.7731e-02,
         -6.9523e-04,  1.2398e-03],
        [ 1.4143e-03, -5.2404e-04,  4.4823e-04,  ...,  3.7766e-03,
          1.7410e-02,  9.8610e-04],
        [ 1.4448e-03, -5.9776e-03, -4.8876e-05,  ...,  3.8071e-03,
          1.1253e-04,  1.5182e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.2695, -1.6035,  2.6367,  ..., -2.7168,  0.8271, -0.6138]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 22:23:14 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A listener is a member of a audience
A state is a member of a country
A shrub is a member of a shrubbery
A fish is a member of a school
A juror is a member of a jury
A christian is a member of a congregation
A spouse is a member of a couple
A member is a member of a
2024-07-30 22:23:14 root INFO     [order_1_approx] starting weight calculation for A christian is a member of a congregation
A shrub is a member of a shrubbery
A state is a member of a country
A fish is a member of a school
A spouse is a member of a couple
A listener is a member of a audience
A member is a member of a club
A juror is a member of a
2024-07-30 22:23:15 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-30 22:25:10 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 1.1621, -0.2046, -0.1010,  ..., -0.1877, -0.6602, -0.2043],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.7734, -4.9922,  5.8281,  ..., -4.5859, -0.5088, -2.3047],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0428, -0.0030,  0.0111,  ..., -0.0026,  0.0023, -0.0081],
        [ 0.0079,  0.0314,  0.0122,  ..., -0.0055,  0.0057, -0.0069],
        [-0.0052,  0.0073,  0.0365,  ...,  0.0006, -0.0037,  0.0091],
        ...,
        [ 0.0091,  0.0051, -0.0021,  ...,  0.0374,  0.0029, -0.0033],
        [-0.0013,  0.0008, -0.0055,  ...,  0.0043,  0.0338,  0.0004],
        [ 0.0141, -0.0020, -0.0018,  ..., -0.0029, -0.0033,  0.0385]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.5859, -5.1172,  6.0625,  ..., -4.5508, -0.4517, -2.4629]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 22:25:11 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A christian is a member of a congregation
A shrub is a member of a shrubbery
A state is a member of a country
A fish is a member of a school
A spouse is a member of a couple
A listener is a member of a audience
A member is a member of a club
A juror is a member of a
2024-07-30 22:25:11 root INFO     [order_1_approx] starting weight calculation for A fish is a member of a school
A state is a member of a country
A listener is a member of a audience
A juror is a member of a jury
A christian is a member of a congregation
A member is a member of a club
A shrub is a member of a shrubbery
A spouse is a member of a
2024-07-30 22:25:11 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-30 22:27:07 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2234,  0.1897, -0.2097,  ...,  0.3706, -0.2896, -0.1495],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.9082, -3.2168,  2.5488,  ..., -2.7090, -1.1221,  2.3047],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0331, -0.0020,  0.0182,  ..., -0.0056,  0.0038,  0.0011],
        [ 0.0074,  0.0350,  0.0175,  ..., -0.0041,  0.0130, -0.0061],
        [-0.0086,  0.0013,  0.0522,  ..., -0.0016, -0.0008, -0.0010],
        ...,
        [ 0.0148, -0.0149, -0.0052,  ...,  0.0553, -0.0074, -0.0073],
        [-0.0024,  0.0090, -0.0065,  ...,  0.0156,  0.0372, -0.0156],
        [ 0.0135, -0.0116, -0.0095,  ..., -0.0017, -0.0262,  0.0530]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.1328, -3.3379,  2.9453,  ..., -2.7305, -1.3594,  1.9287]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 22:27:08 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A fish is a member of a school
A state is a member of a country
A listener is a member of a audience
A juror is a member of a jury
A christian is a member of a congregation
A member is a member of a club
A shrub is a member of a shrubbery
A spouse is a member of a
2024-07-30 22:27:09 root INFO     [order_1_approx] starting weight calculation for A shrub is a member of a shrubbery
A member is a member of a club
A christian is a member of a congregation
A juror is a member of a jury
A spouse is a member of a couple
A listener is a member of a audience
A fish is a member of a school
A state is a member of a
2024-07-30 22:27:09 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-30 22:29:04 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3708, -0.4688, -0.7080,  ...,  0.0174, -0.0658,  0.1340],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.2886, -3.3027,  3.7031,  ..., -4.2734,  1.6904, -3.7988],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 2.7679e-02, -2.6123e-02,  2.1255e-02,  ...,  1.7548e-04,
         -7.3128e-03,  9.3603e-04],
        [-4.4289e-03,  5.6702e-02,  9.6436e-03,  ..., -4.6539e-03,
         -4.0665e-03, -4.5242e-03],
        [ 3.1681e-03,  1.6464e-02,  3.9093e-02,  ...,  7.0190e-03,
         -6.8321e-03,  2.0752e-03],
        ...,
        [ 1.0185e-02,  8.6594e-03, -1.3832e-02,  ...,  3.8788e-02,
          5.7869e-03, -5.3635e-03],
        [ 3.8185e-03,  5.3406e-05, -5.1994e-03,  ...,  6.9046e-04,
          3.9856e-02, -7.3929e-03],
        [-4.4098e-03, -1.4442e-02,  2.5730e-03,  ..., -2.6817e-03,
         -2.7676e-03,  4.7913e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.7534, -3.2734,  3.6191,  ..., -4.0547,  1.5010, -3.7480]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 22:29:05 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A shrub is a member of a shrubbery
A member is a member of a club
A christian is a member of a congregation
A juror is a member of a jury
A spouse is a member of a couple
A listener is a member of a audience
A fish is a member of a school
A state is a member of a
2024-07-30 22:29:05 root INFO     [order_1_approx] starting weight calculation for A christian is a member of a congregation
A state is a member of a country
A fish is a member of a school
A listener is a member of a audience
A spouse is a member of a couple
A member is a member of a club
A juror is a member of a jury
A shrub is a member of a
2024-07-30 22:29:05 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-30 22:31:01 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.5015, -0.3921,  0.1653,  ..., -0.1455, -0.3328, -0.3501],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.0410, -3.5742,  1.3271,  ..., -4.5781, -2.0293, -2.2676],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0408, -0.0287,  0.0092,  ...,  0.0170,  0.0019,  0.0056],
        [ 0.0020,  0.0344,  0.0012,  ..., -0.0107,  0.0213, -0.0183],
        [-0.0187,  0.0024,  0.0710,  ..., -0.0013, -0.0034,  0.0001],
        ...,
        [-0.0038,  0.0038,  0.0087,  ...,  0.0676,  0.0170,  0.0078],
        [ 0.0122,  0.0069, -0.0153,  ...,  0.0087,  0.0417, -0.0045],
        [-0.0183, -0.0080,  0.0077,  ..., -0.0090, -0.0108,  0.0538]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.0723, -3.2988,  1.6650,  ..., -4.4414, -2.1250, -2.1289]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 22:31:03 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A christian is a member of a congregation
A state is a member of a country
A fish is a member of a school
A listener is a member of a audience
A spouse is a member of a couple
A member is a member of a club
A juror is a member of a jury
A shrub is a member of a
2024-07-30 22:31:03 root INFO     [order_1_approx] starting weight calculation for A shrub is a member of a shrubbery
A spouse is a member of a couple
A juror is a member of a jury
A state is a member of a country
A fish is a member of a school
A member is a member of a club
A listener is a member of a audience
A christian is a member of a
2024-07-30 22:31:03 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-30 22:32:56 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.5444,  0.0634, -0.1078,  ...,  0.1868, -0.6172,  0.0787],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 6.7266, -6.2969,  3.7090,  ..., -4.2891,  1.4453, -1.5400],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0559,  0.0014,  0.0141,  ...,  0.0096,  0.0064, -0.0085],
        [-0.0109,  0.0464,  0.0118,  ..., -0.0084,  0.0203, -0.0049],
        [-0.0001, -0.0071,  0.0337,  ..., -0.0021, -0.0048,  0.0095],
        ...,
        [-0.0067,  0.0065, -0.0010,  ...,  0.0515, -0.0030, -0.0188],
        [-0.0016,  0.0026, -0.0011,  ...,  0.0016,  0.0395,  0.0018],
        [-0.0126, -0.0084, -0.0051,  ...,  0.0068, -0.0122,  0.0546]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 6.1797, -5.8984,  3.9121,  ..., -4.0664,  1.1299, -1.5605]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 22:32:57 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A shrub is a member of a shrubbery
A spouse is a member of a couple
A juror is a member of a jury
A state is a member of a country
A fish is a member of a school
A member is a member of a club
A listener is a member of a audience
A christian is a member of a
2024-07-30 22:32:57 root INFO     total operator prediction time: 937.2571556568146 seconds
2024-07-30 22:32:57 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on antonyms - binary
2024-07-30 22:32:57 root INFO     building operator antonyms - binary
2024-07-30 22:32:57 root INFO     [order_1_approx] starting weight calculation for The opposite of proceed is retreat
The opposite of inverse is reverse
The opposite of dead is alive
The opposite of forget is remember
The opposite of below is above
The opposite of drop is lift
The opposite of in is out
The opposite of ahead is
2024-07-30 22:32:57 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-30 22:34:54 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1882,  0.3528, -0.7637,  ...,  0.0383,  0.5410,  0.1611],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.1816, -3.1855,  0.7847,  ..., -4.2266, -0.4863, -3.1445],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 5.3528e-02, -8.9188e-03, -1.8433e-02,  ...,  1.3008e-02,
          5.7220e-03, -4.0436e-03],
        [ 9.2316e-03,  4.7424e-02, -3.0136e-03,  ..., -7.6408e-03,
          1.2077e-02, -2.0771e-03],
        [ 3.8147e-06, -1.7014e-03,  2.2278e-02,  ..., -1.1131e-02,
         -2.6443e-02,  1.5930e-02],
        ...,
        [ 3.6049e-03, -5.6305e-03, -4.3488e-03,  ...,  2.6749e-02,
         -6.4659e-03, -1.8234e-02],
        [-1.6983e-02, -2.0828e-02,  3.6346e-02,  ..., -3.0136e-03,
          2.6627e-02,  1.5549e-02],
        [-1.7500e-03, -1.7807e-02,  9.1629e-03,  ...,  1.1467e-02,
         -7.0686e-03,  9.9945e-03]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.3799, -2.8965,  1.1377,  ..., -4.2461, -0.7178, -2.9785]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 22:34:55 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of proceed is retreat
The opposite of inverse is reverse
The opposite of dead is alive
The opposite of forget is remember
The opposite of below is above
The opposite of drop is lift
The opposite of in is out
The opposite of ahead is
2024-07-30 22:34:55 root INFO     [order_1_approx] starting weight calculation for The opposite of drop is lift
The opposite of ahead is behind
The opposite of in is out
The opposite of forget is remember
The opposite of proceed is retreat
The opposite of below is above
The opposite of inverse is reverse
The opposite of dead is
2024-07-30 22:34:55 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-30 22:36:51 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2388, -0.3477, -0.1132,  ..., -0.4766,  0.1104, -0.0186],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.9863, -2.6562,  0.7646,  ..., -3.0430, -3.0859, -2.9688],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0719, -0.0063,  0.0048,  ...,  0.0062,  0.0083,  0.0305],
        [ 0.0008,  0.0925, -0.0008,  ...,  0.0027, -0.0013,  0.0199],
        [ 0.0150,  0.0058,  0.0573,  ..., -0.0065, -0.0244,  0.0107],
        ...,
        [-0.0017,  0.0197, -0.0231,  ...,  0.0524, -0.0121, -0.0241],
        [-0.0183, -0.0019,  0.0128,  ..., -0.0090,  0.0725, -0.0055],
        [ 0.0105,  0.0080,  0.0158,  ..., -0.0288, -0.0046,  0.0690]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.4492, -2.3379,  0.2212,  ..., -2.4922, -2.8301, -2.8555]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 22:36:52 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of drop is lift
The opposite of ahead is behind
The opposite of in is out
The opposite of forget is remember
The opposite of proceed is retreat
The opposite of below is above
The opposite of inverse is reverse
The opposite of dead is
2024-07-30 22:36:52 root INFO     [order_1_approx] starting weight calculation for The opposite of dead is alive
The opposite of forget is remember
The opposite of in is out
The opposite of inverse is reverse
The opposite of below is above
The opposite of proceed is retreat
The opposite of ahead is behind
The opposite of drop is
2024-07-30 22:36:52 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-30 22:38:51 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.3159, -0.2737,  0.0450,  ..., -0.1688, -0.6328, -0.5913],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.5479, -1.7930, -3.2090,  ...,  0.9375, -2.9414, -3.0176],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 1.2878e-01, -9.7351e-03, -1.2230e-02,  ...,  2.3346e-02,
         -1.1482e-02,  2.2049e-02],
        [ 1.7899e-02,  1.3086e-01,  2.7847e-04,  ...,  6.2103e-03,
          2.5208e-02,  1.8631e-02],
        [-3.1395e-03,  1.3714e-03,  1.0571e-01,  ..., -1.8005e-02,
         -3.3569e-02, -3.6224e-02],
        ...,
        [-1.1063e-04, -1.4008e-02, -2.0432e-02,  ...,  1.1383e-01,
         -1.4572e-02, -1.7776e-02],
        [-1.3802e-02,  5.0392e-03,  2.7924e-03,  ...,  6.6185e-03,
          9.1492e-02, -1.1948e-02],
        [ 2.1667e-02, -4.0169e-03, -5.9547e-03,  ..., -4.1290e-02,
         -5.3406e-04,  1.2512e-01]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.1602, -1.8916, -2.5820,  ...,  1.2832, -3.3750, -2.5391]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 22:38:54 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of dead is alive
The opposite of forget is remember
The opposite of in is out
The opposite of inverse is reverse
The opposite of below is above
The opposite of proceed is retreat
The opposite of ahead is behind
The opposite of drop is
2024-07-30 22:38:57 root INFO     [order_1_approx] starting weight calculation for The opposite of inverse is reverse
The opposite of in is out
The opposite of drop is lift
The opposite of ahead is behind
The opposite of dead is alive
The opposite of proceed is retreat
The opposite of forget is remember
The opposite of below is
2024-07-30 22:38:57 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-30 22:40:53 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1532, -0.4290, -0.0591,  ..., -0.0393, -0.0431, -0.2893],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.8008, -2.1836,  0.8379,  ..., -0.2119,  2.2461, -1.2021],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0874, -0.0205,  0.0222,  ...,  0.0139, -0.0125,  0.0111],
        [ 0.0157,  0.1118,  0.0084,  ...,  0.0031,  0.0208,  0.0106],
        [ 0.0023, -0.0114,  0.0424,  ..., -0.0338, -0.0110,  0.0289],
        ...,
        [-0.0057,  0.0078, -0.0033,  ...,  0.0618,  0.0013, -0.0109],
        [-0.0095, -0.0215,  0.0041,  ..., -0.0114,  0.0461,  0.0170],
        [-0.0026,  0.0008,  0.0173,  ..., -0.0109,  0.0030,  0.0775]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.1660e+00, -2.3965e+00,  1.0166e+00,  ..., -1.4648e-03,
          1.7490e+00, -1.3086e+00]], device='cuda:1', dtype=torch.float16,
       grad_fn=<SubBackward0>) 

                    
2024-07-30 22:40:54 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of inverse is reverse
The opposite of in is out
The opposite of drop is lift
The opposite of ahead is behind
The opposite of dead is alive
The opposite of proceed is retreat
The opposite of forget is remember
The opposite of below is
2024-07-30 22:40:55 root INFO     [order_1_approx] starting weight calculation for The opposite of inverse is reverse
The opposite of forget is remember
The opposite of proceed is retreat
The opposite of ahead is behind
The opposite of below is above
The opposite of dead is alive
The opposite of drop is lift
The opposite of in is
2024-07-30 22:40:55 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-30 22:42:49 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0023,  0.5439, -0.4775,  ..., -0.0166, -0.1917, -0.5210],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.1309, -4.2031,  0.6465,  ..., -2.5488,  0.0462, -5.2461],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0244, -0.0063, -0.0036,  ...,  0.0139,  0.0016,  0.0057],
        [ 0.0035,  0.0417, -0.0028,  ...,  0.0083,  0.0094,  0.0076],
        [-0.0028, -0.0063, -0.0028,  ..., -0.0110, -0.0054,  0.0102],
        ...,
        [-0.0004,  0.0099,  0.0050,  ...,  0.0111,  0.0065, -0.0157],
        [-0.0082, -0.0142,  0.0057,  ..., -0.0065, -0.0006,  0.0028],
        [ 0.0181, -0.0025,  0.0160,  ..., -0.0154, -0.0018,  0.0091]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.0430, -4.0078,  0.3889,  ..., -2.3750, -0.0321, -5.2812]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 22:42:50 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of inverse is reverse
The opposite of forget is remember
The opposite of proceed is retreat
The opposite of ahead is behind
The opposite of below is above
The opposite of dead is alive
The opposite of drop is lift
The opposite of in is
2024-07-30 22:42:50 root INFO     [order_1_approx] starting weight calculation for The opposite of ahead is behind
The opposite of below is above
The opposite of drop is lift
The opposite of inverse is reverse
The opposite of in is out
The opposite of proceed is retreat
The opposite of dead is alive
The opposite of forget is
2024-07-30 22:42:50 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-30 22:44:40 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.6738,  0.6152,  0.0923,  ..., -0.5923, -0.2236, -0.1903],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.6836, -3.7188, -1.5703,  ..., -0.8691, -4.6250, -3.7461],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 8.1177e-02, -3.9787e-03,  6.4163e-03,  ...,  2.8801e-04,
          2.6436e-03,  1.5121e-02],
        [-3.9444e-03,  7.8552e-02,  9.9182e-05,  ...,  1.2131e-02,
         -3.2166e-02, -2.2751e-02],
        [ 2.7122e-03, -2.6031e-02,  4.7089e-02,  ..., -6.2637e-03,
         -2.0401e-02,  1.2253e-02],
        ...,
        [ 2.6627e-02,  9.7275e-04, -1.7578e-02,  ...,  5.6213e-02,
         -9.9564e-03, -9.0408e-03],
        [-1.7090e-02, -1.6113e-02,  8.3847e-03,  ...,  7.2861e-03,
          4.5227e-02,  3.3569e-04],
        [ 9.1705e-03,  1.3397e-02,  1.1234e-03,  ..., -3.9139e-03,
         -1.1383e-02,  4.2572e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.3652, -2.7461, -1.6172,  ..., -0.9971, -5.9062, -4.1133]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 22:44:41 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of ahead is behind
The opposite of below is above
The opposite of drop is lift
The opposite of inverse is reverse
The opposite of in is out
The opposite of proceed is retreat
The opposite of dead is alive
The opposite of forget is
2024-07-30 22:44:41 root INFO     [order_1_approx] starting weight calculation for The opposite of below is above
The opposite of drop is lift
The opposite of dead is alive
The opposite of inverse is reverse
The opposite of forget is remember
The opposite of in is out
The opposite of ahead is behind
The opposite of proceed is
2024-07-30 22:44:41 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-30 22:46:36 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0717, -0.3623, -0.8428,  ..., -0.3159, -0.9502,  0.5283],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.3887, -3.9180,  1.8789,  ...,  1.0645, -3.4023, -3.7871],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0789, -0.0045,  0.0076,  ...,  0.0244,  0.0185,  0.0266],
        [-0.0008,  0.0820, -0.0188,  ...,  0.0185, -0.0158, -0.0034],
        [ 0.0009,  0.0258,  0.0563,  ..., -0.0374, -0.0260, -0.0171],
        ...,
        [ 0.0180,  0.0069, -0.0339,  ...,  0.0620, -0.0120, -0.0306],
        [-0.0080,  0.0070,  0.0226,  ..., -0.0091,  0.0331,  0.0008],
        [ 0.0285,  0.0113, -0.0281,  ..., -0.0282, -0.0280,  0.0756]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.9102, -3.9883,  1.4971,  ...,  0.9531, -3.2344, -3.6855]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 22:46:37 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of below is above
The opposite of drop is lift
The opposite of dead is alive
The opposite of inverse is reverse
The opposite of forget is remember
The opposite of in is out
The opposite of ahead is behind
The opposite of proceed is
2024-07-30 22:46:37 root INFO     [order_1_approx] starting weight calculation for The opposite of below is above
The opposite of ahead is behind
The opposite of forget is remember
The opposite of dead is alive
The opposite of in is out
The opposite of proceed is retreat
The opposite of drop is lift
The opposite of inverse is
2024-07-30 22:46:37 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-30 22:48:35 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3103,  0.1663, -0.6670,  ...,  0.1225,  0.4880, -0.1548],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.9062, -0.6592,  1.0596,  ..., -1.9688, -2.9336, -1.7266],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.1191,  0.0169,  0.0108,  ...,  0.0225,  0.0036,  0.0018],
        [-0.0163,  0.1240,  0.0048,  ...,  0.0177,  0.0127, -0.0020],
        [ 0.0339, -0.0349,  0.0822,  ...,  0.0140,  0.0102,  0.0333],
        ...,
        [ 0.0190,  0.0219, -0.0213,  ...,  0.0837,  0.0004, -0.0155],
        [-0.0047, -0.0019,  0.0307,  ..., -0.0360,  0.1080,  0.0227],
        [ 0.0134,  0.0181,  0.0071,  ..., -0.0071, -0.0076,  0.1222]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.8145, -1.1094,  1.0850,  ..., -1.4834, -3.0137, -2.0430]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 22:48:35 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of below is above
The opposite of ahead is behind
The opposite of forget is remember
The opposite of dead is alive
The opposite of in is out
The opposite of proceed is retreat
The opposite of drop is lift
The opposite of inverse is
2024-07-30 22:48:35 root INFO     total operator prediction time: 938.712956905365 seconds
2024-07-30 22:48:35 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on hyponyms - misc
2024-07-30 22:48:35 root INFO     building operator hyponyms - misc
2024-07-30 22:48:36 root INFO     [order_1_approx] starting weight calculation for A more specific term for a shelf is bookshelf
A more specific term for a dress is gown
A more specific term for a cloud is thundercloud
A more specific term for a cup is teacup
A more specific term for a tool is rake
A more specific term for a guitar is ukulele
A more specific term for a burger is hamburger
A more specific term for a drum is
2024-07-30 22:48:36 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-30 22:50:34 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3003,  0.3369,  0.3203,  ..., -0.4897, -0.7061,  0.1401],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.1582, -6.2148, -1.3984,  ...,  1.7031, -0.1604,  0.9453],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.1122,  0.0002,  0.0043,  ...,  0.0093, -0.0190,  0.0014],
        [-0.0065,  0.0578, -0.0005,  ...,  0.0181,  0.0251, -0.0258],
        [ 0.0280,  0.0138,  0.0810,  ...,  0.0051, -0.0092,  0.0266],
        ...,
        [ 0.0238,  0.0096,  0.0071,  ...,  0.0853,  0.0057, -0.0028],
        [-0.0223, -0.0236,  0.0067,  ..., -0.0081,  0.0864, -0.0076],
        [-0.0204,  0.0094, -0.0056,  ..., -0.0137, -0.0108,  0.0734]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.3066, -5.8359, -1.3066,  ...,  1.6260, -0.1727,  1.1230]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 22:50:35 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more specific term for a shelf is bookshelf
A more specific term for a dress is gown
A more specific term for a cloud is thundercloud
A more specific term for a cup is teacup
A more specific term for a tool is rake
A more specific term for a guitar is ukulele
A more specific term for a burger is hamburger
A more specific term for a drum is
2024-07-30 22:50:35 root INFO     [order_1_approx] starting weight calculation for A more specific term for a burger is hamburger
A more specific term for a guitar is ukulele
A more specific term for a cloud is thundercloud
A more specific term for a drum is tambourine
A more specific term for a tool is rake
A more specific term for a dress is gown
A more specific term for a cup is teacup
A more specific term for a shelf is
2024-07-30 22:50:35 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-30 22:52:29 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1221, -0.4243, -0.4009,  ...,  0.3887, -0.5659, -0.2410],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.1562, -3.3125,  1.1426,  ...,  4.3633, -3.0391,  2.3945],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.1188,  0.0026, -0.0049,  ...,  0.0088, -0.0128,  0.0024],
        [-0.0047,  0.0963, -0.0102,  ...,  0.0168,  0.0161,  0.0017],
        [ 0.0069,  0.0103,  0.0987,  ...,  0.0061, -0.0052, -0.0101],
        ...,
        [ 0.0107,  0.0238, -0.0148,  ...,  0.1023, -0.0063,  0.0027],
        [-0.0166, -0.0024, -0.0258,  ..., -0.0016,  0.0850,  0.0092],
        [-0.0256,  0.0251, -0.0072,  ..., -0.0311, -0.0005,  0.0854]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.0938, -3.1895,  1.3027,  ...,  4.5859, -2.5566,  2.2227]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 22:52:29 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more specific term for a burger is hamburger
A more specific term for a guitar is ukulele
A more specific term for a cloud is thundercloud
A more specific term for a drum is tambourine
A more specific term for a tool is rake
A more specific term for a dress is gown
A more specific term for a cup is teacup
A more specific term for a shelf is
2024-07-30 22:52:30 root INFO     [order_1_approx] starting weight calculation for A more specific term for a drum is tambourine
A more specific term for a cup is teacup
A more specific term for a shelf is bookshelf
A more specific term for a cloud is thundercloud
A more specific term for a burger is hamburger
A more specific term for a dress is gown
A more specific term for a guitar is ukulele
A more specific term for a tool is
2024-07-30 22:52:30 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-30 22:54:29 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2307, -0.5781, -0.1621,  ...,  0.3813, -0.1223,  0.1002],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.2983, -3.9805,  0.0068,  ...,  2.1289, -4.0078,  1.8555],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 1.0107e-01,  5.0011e-03,  6.0883e-03,  ..., -1.2833e-02,
         -1.6861e-02,  2.2675e-02],
        [-6.5880e-03,  7.8918e-02,  6.8321e-03,  ..., -1.1520e-02,
          1.7807e-02, -1.6083e-02],
        [-8.2550e-03, -2.4147e-03,  7.3486e-02,  ...,  5.2338e-03,
          7.4615e-03,  8.0338e-03],
        ...,
        [ 1.5808e-02,  1.6541e-02, -1.0841e-02,  ...,  9.0454e-02,
         -8.4991e-03,  1.2505e-02],
        [ 1.5015e-02, -1.0834e-03,  2.0790e-04,  ..., -1.8188e-02,
          7.8979e-02, -9.6893e-03],
        [-9.5940e-04,  3.0884e-02, -8.9645e-05,  ..., -1.1108e-02,
          2.1133e-02,  6.8237e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.0791, -4.0000,  0.0229,  ...,  2.3438, -3.7051,  1.7539]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 22:54:30 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more specific term for a drum is tambourine
A more specific term for a cup is teacup
A more specific term for a shelf is bookshelf
A more specific term for a cloud is thundercloud
A more specific term for a burger is hamburger
A more specific term for a dress is gown
A more specific term for a guitar is ukulele
A more specific term for a tool is
2024-07-30 22:54:30 root INFO     [order_1_approx] starting weight calculation for A more specific term for a tool is rake
A more specific term for a dress is gown
A more specific term for a guitar is ukulele
A more specific term for a shelf is bookshelf
A more specific term for a drum is tambourine
A more specific term for a cup is teacup
A more specific term for a burger is hamburger
A more specific term for a cloud is
2024-07-30 22:54:30 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-30 22:56:24 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0461, -0.0986, -0.2534,  ...,  0.0898, -0.1015,  0.1114],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-2.0000, -3.8867,  4.0352,  ..., -0.0205, -1.3926,  2.3652],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0997,  0.0092,  0.0005,  ...,  0.0172,  0.0028,  0.0143],
        [ 0.0088,  0.0994,  0.0123,  ..., -0.0027,  0.0163, -0.0237],
        [-0.0054, -0.0065,  0.1022,  ..., -0.0038, -0.0084,  0.0086],
        ...,
        [-0.0079,  0.0155, -0.0103,  ...,  0.0966, -0.0206,  0.0054],
        [-0.0129, -0.0105, -0.0074,  ..., -0.0011,  0.0952, -0.0145],
        [ 0.0172,  0.0081, -0.0032,  ..., -0.0101, -0.0110,  0.0717]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.7266, -3.9434,  3.8672,  ...,  0.0798, -1.3848,  2.7930]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 22:56:25 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more specific term for a tool is rake
A more specific term for a dress is gown
A more specific term for a guitar is ukulele
A more specific term for a shelf is bookshelf
A more specific term for a drum is tambourine
A more specific term for a cup is teacup
A more specific term for a burger is hamburger
A more specific term for a cloud is
2024-07-30 22:56:25 root INFO     [order_1_approx] starting weight calculation for A more specific term for a burger is hamburger
A more specific term for a tool is rake
A more specific term for a shelf is bookshelf
A more specific term for a cloud is thundercloud
A more specific term for a cup is teacup
A more specific term for a dress is gown
A more specific term for a drum is tambourine
A more specific term for a guitar is
2024-07-30 22:56:25 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-30 22:58:23 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.5024,  1.0830,  0.1238,  ..., -0.1207, -0.3020,  0.0520],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.2615, -4.5391, -0.5098,  ..., -0.3843,  0.1482, -4.0117],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0896,  0.0118, -0.0047,  ...,  0.0101, -0.0113,  0.0021],
        [-0.0140,  0.0688,  0.0006,  ...,  0.0105,  0.0105, -0.0271],
        [ 0.0181,  0.0022,  0.0812,  ..., -0.0033,  0.0068,  0.0115],
        ...,
        [ 0.0149,  0.0066, -0.0070,  ...,  0.0816,  0.0035,  0.0070],
        [ 0.0081, -0.0025,  0.0089,  ...,  0.0102,  0.0518, -0.0043],
        [-0.0013, -0.0015, -0.0133,  ...,  0.0036, -0.0130,  0.0665]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.9570, -4.2500, -0.3662,  ..., -0.4478,  0.3208, -3.9473]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 22:58:24 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more specific term for a burger is hamburger
A more specific term for a tool is rake
A more specific term for a shelf is bookshelf
A more specific term for a cloud is thundercloud
A more specific term for a cup is teacup
A more specific term for a dress is gown
A more specific term for a drum is tambourine
A more specific term for a guitar is
2024-07-30 22:58:24 root INFO     [order_1_approx] starting weight calculation for A more specific term for a tool is rake
A more specific term for a shelf is bookshelf
A more specific term for a burger is hamburger
A more specific term for a guitar is ukulele
A more specific term for a dress is gown
A more specific term for a cloud is thundercloud
A more specific term for a drum is tambourine
A more specific term for a cup is
2024-07-30 22:58:24 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-30 23:00:22 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1943, -0.7139,  0.7676,  ...,  0.0635, -0.6367, -0.5576],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.2305, -1.7734, -2.1934,  ..., -1.0635,  1.1543, -1.2939],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0947, -0.0207,  0.0155,  ...,  0.0069,  0.0117,  0.0084],
        [-0.0028,  0.0572, -0.0014,  ..., -0.0033,  0.0295, -0.0238],
        [-0.0041,  0.0141,  0.0729,  ..., -0.0030, -0.0128,  0.0002],
        ...,
        [ 0.0093, -0.0057,  0.0034,  ...,  0.0617,  0.0055, -0.0097],
        [-0.0343, -0.0069,  0.0011,  ..., -0.0169,  0.0649, -0.0054],
        [-0.0005,  0.0156, -0.0057,  ..., -0.0014,  0.0089,  0.0676]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.4082, -1.9346, -2.3203,  ..., -0.6577,  1.6064, -1.4268]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 23:00:23 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more specific term for a tool is rake
A more specific term for a shelf is bookshelf
A more specific term for a burger is hamburger
A more specific term for a guitar is ukulele
A more specific term for a dress is gown
A more specific term for a cloud is thundercloud
A more specific term for a drum is tambourine
A more specific term for a cup is
2024-07-30 23:00:24 root INFO     [order_1_approx] starting weight calculation for A more specific term for a guitar is ukulele
A more specific term for a tool is rake
A more specific term for a cloud is thundercloud
A more specific term for a cup is teacup
A more specific term for a drum is tambourine
A more specific term for a burger is hamburger
A more specific term for a shelf is bookshelf
A more specific term for a dress is
2024-07-30 23:00:24 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-30 23:02:22 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3159, -0.1431, -0.2310,  ...,  0.0771, -0.2302,  0.2168],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.0498, -3.5488, -1.1748,  ...,  1.8936, -1.5254,  1.3945],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0715,  0.0161, -0.0018,  ..., -0.0179,  0.0182, -0.0071],
        [-0.0176,  0.0706, -0.0059,  ..., -0.0142, -0.0042, -0.0143],
        [ 0.0236, -0.0151,  0.0784,  ...,  0.0112, -0.0060,  0.0038],
        ...,
        [-0.0152, -0.0167, -0.0181,  ...,  0.0523,  0.0128, -0.0085],
        [-0.0077,  0.0144, -0.0227,  ...,  0.0178,  0.0637, -0.0126],
        [-0.0067, -0.0158,  0.0091,  ..., -0.0338, -0.0057,  0.0489]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.5444, -3.7637, -1.0273,  ...,  2.2461, -1.4541,  1.3418]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 23:02:23 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more specific term for a guitar is ukulele
A more specific term for a tool is rake
A more specific term for a cloud is thundercloud
A more specific term for a cup is teacup
A more specific term for a drum is tambourine
A more specific term for a burger is hamburger
A more specific term for a shelf is bookshelf
A more specific term for a dress is
2024-07-30 23:02:23 root INFO     [order_1_approx] starting weight calculation for A more specific term for a shelf is bookshelf
A more specific term for a cloud is thundercloud
A more specific term for a guitar is ukulele
A more specific term for a drum is tambourine
A more specific term for a tool is rake
A more specific term for a dress is gown
A more specific term for a cup is teacup
A more specific term for a burger is
2024-07-30 23:02:23 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-30 23:04:18 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0275,  0.7803, -0.0135,  ...,  0.0896, -0.0928, -0.3137],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.0693, -5.9648,  1.7207,  ..., -1.9629, -4.4805, -1.6348],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 9.6313e-02,  4.0131e-02,  3.4447e-03,  ...,  1.0437e-02,
         -1.8097e-02,  1.0185e-03],
        [ 9.3384e-03,  9.7290e-02,  1.2283e-02,  ..., -1.1032e-02,
          7.9880e-03, -1.7517e-02],
        [ 2.3163e-02, -2.0599e-04,  9.0332e-02,  ...,  1.5541e-02,
         -1.1642e-02,  3.3913e-03],
        ...,
        [ 2.2339e-02,  1.2131e-02,  1.9531e-03,  ...,  9.7961e-02,
         -1.2970e-02, -3.4065e-03],
        [-1.6190e-02, -2.1801e-03,  1.6842e-03,  ...,  2.3479e-03,
          8.7952e-02, -3.0807e-02],
        [ 8.6288e-03,  2.8900e-02,  7.2479e-05,  ..., -6.0577e-03,
          1.7242e-03,  8.9905e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.5557, -6.1719,  1.5869,  ..., -1.6729, -4.2148, -1.8359]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 23:04:22 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more specific term for a shelf is bookshelf
A more specific term for a cloud is thundercloud
A more specific term for a guitar is ukulele
A more specific term for a drum is tambourine
A more specific term for a tool is rake
A more specific term for a dress is gown
A more specific term for a cup is teacup
A more specific term for a burger is
2024-07-30 23:04:22 root INFO     total operator prediction time: 946.2046163082123 seconds
2024-07-30 23:04:22 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on hypernyms - animals
2024-07-30 23:04:22 root INFO     building operator hypernyms - animals
2024-07-30 23:04:24 root INFO     [order_1_approx] starting weight calculation for The lion falls into the category of feline
The tiger falls into the category of feline
The falcon falls into the category of raptor
The tyrannosaurus falls into the category of dinosaur
The fox falls into the category of canine
The cockroach falls into the category of insect
The ant falls into the category of insect
The goose falls into the category of
2024-07-30 23:04:24 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-30 23:06:18 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.7886, -0.4692, -0.1429,  ...,  0.0312, -0.4419, -0.1061],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.0938, -3.7246,  4.5742,  ..., -1.9258, -9.4609,  1.4883],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0389,  0.0070, -0.0114,  ..., -0.0141, -0.0040, -0.0094],
        [ 0.0046,  0.0383,  0.0150,  ...,  0.0020, -0.0012, -0.0316],
        [ 0.0009,  0.0012,  0.0430,  ...,  0.0042, -0.0057, -0.0040],
        ...,
        [ 0.0294, -0.0085,  0.0208,  ...,  0.0343, -0.0027,  0.0047],
        [-0.0098, -0.0021, -0.0087,  ..., -0.0061,  0.0582, -0.0046],
        [ 0.0018,  0.0092, -0.0193,  ...,  0.0089, -0.0134,  0.0401]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.3096, -3.8633,  4.2969,  ..., -1.7012, -9.2422,  1.4180]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 23:06:19 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The lion falls into the category of feline
The tiger falls into the category of feline
The falcon falls into the category of raptor
The tyrannosaurus falls into the category of dinosaur
The fox falls into the category of canine
The cockroach falls into the category of insect
The ant falls into the category of insect
The goose falls into the category of
2024-07-30 23:06:19 root INFO     [order_1_approx] starting weight calculation for The tiger falls into the category of feline
The falcon falls into the category of raptor
The ant falls into the category of insect
The cockroach falls into the category of insect
The lion falls into the category of feline
The goose falls into the category of fowl
The tyrannosaurus falls into the category of dinosaur
The fox falls into the category of
2024-07-30 23:06:19 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-30 23:08:13 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0601,  0.1498,  0.1255,  ...,  0.0588, -0.2462,  0.0838],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.2554, -5.7930,  1.8203,  ..., -3.6953, -6.1641,  1.1074],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0426,  0.0026, -0.0050,  ..., -0.0148, -0.0125,  0.0014],
        [ 0.0150,  0.0299,  0.0174,  ..., -0.0047,  0.0200, -0.0285],
        [ 0.0075, -0.0060,  0.0544,  ..., -0.0098,  0.0103, -0.0024],
        ...,
        [ 0.0111,  0.0021,  0.0089,  ...,  0.0237,  0.0161,  0.0001],
        [-0.0117, -0.0121, -0.0002,  ...,  0.0042,  0.0507, -0.0066],
        [ 0.0075,  0.0125, -0.0227,  ...,  0.0018, -0.0187,  0.0444]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.3950, -5.6250,  1.7051,  ..., -3.2949, -6.0977,  0.6445]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 23:08:14 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The tiger falls into the category of feline
The falcon falls into the category of raptor
The ant falls into the category of insect
The cockroach falls into the category of insect
The lion falls into the category of feline
The goose falls into the category of fowl
The tyrannosaurus falls into the category of dinosaur
The fox falls into the category of
2024-07-30 23:08:14 root INFO     [order_1_approx] starting weight calculation for The tiger falls into the category of feline
The cockroach falls into the category of insect
The fox falls into the category of canine
The lion falls into the category of feline
The goose falls into the category of fowl
The falcon falls into the category of raptor
The ant falls into the category of insect
The tyrannosaurus falls into the category of
2024-07-30 23:08:14 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-30 23:10:12 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.6426, -0.4326, -0.8496,  ..., -0.1765, -0.8774,  0.1257],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.2764, -5.1172,  2.0664,  ..., -2.3633, -6.7891, -1.6182],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 3.1052e-02, -9.4147e-03, -1.2436e-02,  ...,  1.3828e-04,
         -7.1335e-03, -6.8207e-03],
        [ 1.6279e-03,  3.8605e-02, -8.3847e-03,  ..., -1.5839e-02,
          9.6283e-03, -1.1688e-02],
        [ 4.6730e-03,  4.8676e-03,  3.2166e-02,  ..., -9.9850e-04,
         -1.0300e-03,  6.4392e-03],
        ...,
        [ 1.0063e-02, -2.8515e-03,  3.9902e-03,  ...,  4.4708e-02,
         -3.8223e-03,  5.8136e-03],
        [-1.0574e-02,  2.0905e-03, -1.5259e-05,  ..., -1.0712e-02,
          3.9001e-02,  1.1530e-03],
        [-2.9507e-03,  5.1231e-03, -1.3306e-02,  ..., -8.9493e-03,
         -4.2000e-03,  3.6407e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.0977, -4.9609,  2.0352,  ..., -2.4980, -6.6875, -1.8594]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 23:10:13 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The tiger falls into the category of feline
The cockroach falls into the category of insect
The fox falls into the category of canine
The lion falls into the category of feline
The goose falls into the category of fowl
The falcon falls into the category of raptor
The ant falls into the category of insect
The tyrannosaurus falls into the category of
2024-07-30 23:10:13 root INFO     [order_1_approx] starting weight calculation for The ant falls into the category of insect
The lion falls into the category of feline
The fox falls into the category of canine
The goose falls into the category of fowl
The cockroach falls into the category of insect
The tiger falls into the category of feline
The tyrannosaurus falls into the category of dinosaur
The falcon falls into the category of
2024-07-30 23:10:13 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-30 23:12:08 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1990,  0.0646, -0.1838,  ..., -0.0322, -0.3875,  0.0966],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.0000, -3.7422,  2.5273,  ..., -1.5225, -5.9219,  1.3604],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0569, -0.0072,  0.0010,  ..., -0.0008, -0.0159, -0.0017],
        [ 0.0160,  0.0323,  0.0175,  ...,  0.0076,  0.0043, -0.0216],
        [-0.0049, -0.0094,  0.0516,  ..., -0.0003,  0.0058,  0.0019],
        ...,
        [ 0.0216,  0.0092, -0.0050,  ...,  0.0467, -0.0195,  0.0052],
        [-0.0029, -0.0043,  0.0114,  ...,  0.0049,  0.0415, -0.0178],
        [ 0.0055, -0.0037, -0.0096,  ...,  0.0122, -0.0175,  0.0389]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.1797, -3.6211,  2.3711,  ..., -1.5146, -6.1094,  1.7568]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 23:12:09 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The ant falls into the category of insect
The lion falls into the category of feline
The fox falls into the category of canine
The goose falls into the category of fowl
The cockroach falls into the category of insect
The tiger falls into the category of feline
The tyrannosaurus falls into the category of dinosaur
The falcon falls into the category of
2024-07-30 23:12:09 root INFO     [order_1_approx] starting weight calculation for The falcon falls into the category of raptor
The tiger falls into the category of feline
The tyrannosaurus falls into the category of dinosaur
The goose falls into the category of fowl
The cockroach falls into the category of insect
The lion falls into the category of feline
The fox falls into the category of canine
The ant falls into the category of
2024-07-30 23:12:09 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-30 23:14:02 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.3206, -0.1201, -0.3560,  ..., -0.6025,  0.2324, -0.4995],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.2051, -3.8496,  2.3418,  ..., -3.0039, -4.0430, -1.4375],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 5.3619e-02,  7.5836e-03, -5.4207e-03,  ...,  1.9531e-03,
         -1.2321e-02, -5.2948e-03],
        [ 7.6294e-03,  2.8107e-02,  6.0425e-03,  ...,  1.1435e-03,
          1.8330e-03, -3.0396e-02],
        [-6.2943e-05, -6.6338e-03,  5.9052e-02,  ..., -3.7155e-03,
          4.5471e-03,  1.1452e-02],
        ...,
        [ 2.2049e-02,  1.1871e-02,  9.6283e-03,  ...,  5.1270e-02,
         -1.6144e-02, -6.7825e-03],
        [-1.8021e-02, -7.1411e-03,  3.7384e-04,  ..., -1.0117e-02,
          4.3121e-02,  1.2207e-04],
        [-1.4000e-03,  1.0406e-02, -2.1057e-02,  ..., -1.2817e-02,
         -2.0569e-02,  3.3173e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.1609, -4.0742,  2.2715,  ..., -2.4883, -3.8945, -1.5215]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 23:14:03 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The falcon falls into the category of raptor
The tiger falls into the category of feline
The tyrannosaurus falls into the category of dinosaur
The goose falls into the category of fowl
The cockroach falls into the category of insect
The lion falls into the category of feline
The fox falls into the category of canine
The ant falls into the category of
2024-07-30 23:14:04 root INFO     [order_1_approx] starting weight calculation for The cockroach falls into the category of insect
The ant falls into the category of insect
The falcon falls into the category of raptor
The tyrannosaurus falls into the category of dinosaur
The goose falls into the category of fowl
The tiger falls into the category of feline
The fox falls into the category of canine
The lion falls into the category of
2024-07-30 23:14:04 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-30 23:15:57 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.5674, -0.4043,  0.2177,  ..., -0.0852, -0.5757, -0.2947],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.0977, -7.4219,  0.4126,  ..., -3.8164, -7.5234, -0.6816],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 2.1164e-02,  2.4986e-03, -1.2939e-02,  ..., -5.1231e-03,
         -2.4399e-02, -1.2083e-03],
        [ 1.0101e-02,  2.7069e-02,  1.5976e-02,  ..., -1.1078e-02,
          1.4221e-02, -3.6316e-03],
        [-6.4316e-03, -7.8201e-05,  4.0863e-02,  ...,  1.4687e-04,
          6.4850e-03, -6.1836e-03],
        ...,
        [ 1.1993e-02,  3.5439e-03,  6.0081e-04,  ...,  2.2827e-02,
         -2.3460e-04, -1.8921e-03],
        [-5.2948e-03, -1.5869e-02,  5.1994e-03,  ..., -3.7632e-03,
          3.4821e-02, -8.4114e-04],
        [-1.3565e-02,  1.1711e-02, -1.4542e-02,  ...,  4.6158e-03,
         -1.0796e-02,  3.1128e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.2109, -7.3164,  0.9033,  ..., -3.5254, -7.3789, -0.6558]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 23:15:58 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The cockroach falls into the category of insect
The ant falls into the category of insect
The falcon falls into the category of raptor
The tyrannosaurus falls into the category of dinosaur
The goose falls into the category of fowl
The tiger falls into the category of feline
The fox falls into the category of canine
The lion falls into the category of
2024-07-30 23:15:58 root INFO     [order_1_approx] starting weight calculation for The lion falls into the category of feline
The cockroach falls into the category of insect
The goose falls into the category of fowl
The ant falls into the category of insect
The falcon falls into the category of raptor
The fox falls into the category of canine
The tyrannosaurus falls into the category of dinosaur
The tiger falls into the category of
2024-07-30 23:15:58 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-30 23:17:55 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0362, -0.1481,  0.0814,  ...,  0.3367, -0.1141, -0.2410],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.0308, -7.8828, -0.2168,  ..., -3.8516, -7.4844, -1.0957],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0354, -0.0018, -0.0137,  ..., -0.0006, -0.0089, -0.0074],
        [ 0.0085,  0.0363,  0.0184,  ..., -0.0187,  0.0070, -0.0153],
        [-0.0138,  0.0011,  0.0580,  ...,  0.0063, -0.0021, -0.0077],
        ...,
        [ 0.0031,  0.0006,  0.0095,  ...,  0.0407, -0.0070, -0.0002],
        [-0.0111, -0.0176, -0.0007,  ..., -0.0021,  0.0507, -0.0072],
        [-0.0222,  0.0320, -0.0092,  ...,  0.0098, -0.0160,  0.0374]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.1511, -7.4609,  0.2129,  ..., -3.5918, -7.4648, -0.9287]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 23:17:56 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The lion falls into the category of feline
The cockroach falls into the category of insect
The goose falls into the category of fowl
The ant falls into the category of insect
The falcon falls into the category of raptor
The fox falls into the category of canine
The tyrannosaurus falls into the category of dinosaur
The tiger falls into the category of
2024-07-30 23:17:57 root INFO     [order_1_approx] starting weight calculation for The tyrannosaurus falls into the category of dinosaur
The fox falls into the category of canine
The falcon falls into the category of raptor
The tiger falls into the category of feline
The goose falls into the category of fowl
The ant falls into the category of insect
The lion falls into the category of feline
The cockroach falls into the category of
2024-07-30 23:17:57 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-30 23:19:53 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1680, -0.2559, -0.5117,  ..., -0.4390, -0.6958,  0.1255],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.1318, -3.5703,  3.5898,  ..., -3.8379, -3.2500, -2.2891],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0345, -0.0070,  0.0002,  ..., -0.0046, -0.0062, -0.0015],
        [ 0.0023,  0.0175, -0.0013,  ...,  0.0017,  0.0046, -0.0056],
        [ 0.0008, -0.0017,  0.0233,  ...,  0.0013, -0.0017,  0.0071],
        ...,
        [ 0.0070,  0.0006, -0.0038,  ...,  0.0251,  0.0054, -0.0028],
        [ 0.0032, -0.0025, -0.0012,  ..., -0.0031,  0.0226, -0.0036],
        [-0.0080,  0.0140, -0.0018,  ..., -0.0095, -0.0089,  0.0310]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.9819, -3.6230,  3.5762,  ..., -3.8809, -3.4414, -2.0117]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 23:19:54 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The tyrannosaurus falls into the category of dinosaur
The fox falls into the category of canine
The falcon falls into the category of raptor
The tiger falls into the category of feline
The goose falls into the category of fowl
The ant falls into the category of insect
The lion falls into the category of feline
The cockroach falls into the category of
2024-07-30 23:19:54 root INFO     total operator prediction time: 932.3625044822693 seconds
2024-07-30 23:19:54 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on synonyms - intensity
2024-07-30 23:19:54 root INFO     building operator synonyms - intensity
2024-07-30 23:19:54 root INFO     [order_1_approx] starting weight calculation for A more intense word for cry is scream
A more intense word for house is palace
A more intense word for ask is beg
A more intense word for monkey is gorilla
A more intense word for strong is powerful
A more intense word for dinner is feast
A more intense word for happy is ecstatic
A more intense word for tasty is
2024-07-30 23:19:54 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-30 23:21:49 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3657, -0.4580, -0.5229,  ..., -0.4766, -0.5078, -0.0751],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.6016, -3.4512, -1.1162,  ..., -2.5293, -8.9375, -1.5342],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0732, -0.0026,  0.0021,  ..., -0.0045,  0.0062,  0.0218],
        [ 0.0216,  0.0906,  0.0116,  ..., -0.0017,  0.0077,  0.0067],
        [-0.0009, -0.0026,  0.0735,  ...,  0.0013, -0.0137, -0.0131],
        ...,
        [ 0.0240,  0.0018, -0.0153,  ...,  0.0583, -0.0088, -0.0007],
        [ 0.0113, -0.0113,  0.0172,  ..., -0.0037,  0.0493,  0.0002],
        [-0.0089, -0.0190, -0.0211,  ..., -0.0027, -0.0063,  0.0610]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.4531, -3.6699, -0.9209,  ..., -2.4141, -8.7734, -1.8389]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 23:21:50 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more intense word for cry is scream
A more intense word for house is palace
A more intense word for ask is beg
A more intense word for monkey is gorilla
A more intense word for strong is powerful
A more intense word for dinner is feast
A more intense word for happy is ecstatic
A more intense word for tasty is
2024-07-30 23:21:50 root INFO     [order_1_approx] starting weight calculation for A more intense word for cry is scream
A more intense word for ask is beg
A more intense word for dinner is feast
A more intense word for tasty is delicious
A more intense word for house is palace
A more intense word for monkey is gorilla
A more intense word for happy is ecstatic
A more intense word for strong is
2024-07-30 23:21:50 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-30 23:23:46 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1270, -0.3813, -0.2883,  ..., -0.1676, -0.0685, -0.0611],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.7900, -3.7539,  0.0371,  ..., -0.9316, -8.0312, -3.7969],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0724, -0.0115, -0.0038,  ..., -0.0230,  0.0074,  0.0091],
        [-0.0061,  0.0830,  0.0149,  ..., -0.0004,  0.0168,  0.0082],
        [ 0.0074, -0.0043,  0.0695,  ..., -0.0175, -0.0111,  0.0059],
        ...,
        [ 0.0077,  0.0058, -0.0129,  ...,  0.0879, -0.0032, -0.0011],
        [-0.0038, -0.0033, -0.0020,  ...,  0.0026,  0.0709,  0.0021],
        [-0.0014, -0.0036,  0.0099,  ...,  0.0157, -0.0021,  0.0682]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 8.9453e-01, -4.2539e+00, -2.2888e-03,  ..., -9.4678e-01,
         -8.4141e+00, -3.8281e+00]], device='cuda:1', dtype=torch.float16,
       grad_fn=<SubBackward0>) 

                    
2024-07-30 23:23:47 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more intense word for cry is scream
A more intense word for ask is beg
A more intense word for dinner is feast
A more intense word for tasty is delicious
A more intense word for house is palace
A more intense word for monkey is gorilla
A more intense word for happy is ecstatic
A more intense word for strong is
2024-07-30 23:23:47 root INFO     [order_1_approx] starting weight calculation for A more intense word for dinner is feast
A more intense word for strong is powerful
A more intense word for ask is beg
A more intense word for house is palace
A more intense word for tasty is delicious
A more intense word for happy is ecstatic
A more intense word for cry is scream
A more intense word for monkey is
2024-07-30 23:23:47 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-30 23:25:44 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2300, -0.2358, -0.3008,  ..., -0.2627, -0.7920,  0.1541],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.6992, -3.8867,  1.9043,  ...,  0.7695, -4.7305,  1.2676],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 8.0505e-02, -1.7414e-03,  7.2250e-03,  ..., -9.5367e-05,
          1.6266e-02, -1.7883e-02],
        [ 5.4054e-03,  5.8899e-02,  7.5035e-03,  ..., -1.5854e-02,
          2.8503e-02, -1.4854e-02],
        [-4.3182e-03,  1.5396e-02,  6.8848e-02,  ..., -1.5045e-02,
          1.6251e-02,  2.6245e-03],
        ...,
        [ 1.5518e-02,  1.5343e-02, -1.0567e-02,  ...,  9.2651e-02,
         -1.4709e-02,  3.2272e-03],
        [-3.5248e-03, -1.4847e-02,  1.3245e-02,  ...,  1.3237e-02,
          6.6772e-02, -8.9188e-03],
        [-3.8147e-03, -1.0429e-02, -1.2001e-02,  ..., -2.9526e-03,
          4.2725e-04,  7.9834e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.5615, -3.3613,  1.5586,  ...,  1.1348, -4.8047,  1.0654]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 23:25:45 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more intense word for dinner is feast
A more intense word for strong is powerful
A more intense word for ask is beg
A more intense word for house is palace
A more intense word for tasty is delicious
A more intense word for happy is ecstatic
A more intense word for cry is scream
A more intense word for monkey is
2024-07-30 23:25:45 root INFO     [order_1_approx] starting weight calculation for A more intense word for house is palace
A more intense word for tasty is delicious
A more intense word for cry is scream
A more intense word for monkey is gorilla
A more intense word for ask is beg
A more intense word for happy is ecstatic
A more intense word for strong is powerful
A more intense word for dinner is
2024-07-30 23:25:45 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-30 23:27:39 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.5869,  0.1427,  0.0234,  ..., -0.2744, -0.8599, -0.2391],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.5234, -2.4492,  0.3159,  ..., -2.1406, -1.9600, -2.7695],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.1118, -0.0066, -0.0264,  ...,  0.0195,  0.0245,  0.0018],
        [-0.0231,  0.1196,  0.0197,  ..., -0.0094, -0.0202, -0.0344],
        [-0.0047, -0.0295,  0.1040,  ...,  0.0165, -0.0025,  0.0122],
        ...,
        [-0.0008, -0.0073,  0.0084,  ...,  0.0955,  0.0049, -0.0006],
        [-0.0017, -0.0244, -0.0223,  ...,  0.0173,  0.1130,  0.0146],
        [-0.0047,  0.0146, -0.0126,  ..., -0.0184, -0.0168,  0.0792]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.5664, -1.9336,  0.8633,  ..., -1.9453, -2.9766, -2.3984]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 23:27:40 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more intense word for house is palace
A more intense word for tasty is delicious
A more intense word for cry is scream
A more intense word for monkey is gorilla
A more intense word for ask is beg
A more intense word for happy is ecstatic
A more intense word for strong is powerful
A more intense word for dinner is
2024-07-30 23:27:41 root INFO     [order_1_approx] starting weight calculation for A more intense word for ask is beg
A more intense word for tasty is delicious
A more intense word for strong is powerful
A more intense word for cry is scream
A more intense word for monkey is gorilla
A more intense word for house is palace
A more intense word for dinner is feast
A more intense word for happy is
2024-07-30 23:27:41 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-30 23:29:36 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1542, -0.2214,  0.1214,  ...,  0.1201, -0.3110, -0.1382],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.1133, -0.4241,  3.9609,  ...,  1.4072, -6.6758, -0.6504],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0845,  0.0027,  0.0143,  ...,  0.0016,  0.0205,  0.0300],
        [ 0.0009,  0.0607, -0.0045,  ..., -0.0001,  0.0117,  0.0085],
        [ 0.0186,  0.0094,  0.0723,  ...,  0.0073, -0.0069, -0.0089],
        ...,
        [ 0.0098,  0.0128, -0.0290,  ...,  0.0734, -0.0126, -0.0271],
        [ 0.0126, -0.0189,  0.0020,  ...,  0.0185,  0.0363, -0.0086],
        [-0.0007, -0.0208, -0.0027,  ..., -0.0030, -0.0183,  0.0654]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.2305, -0.5884,  3.7363,  ...,  1.7119, -6.3828, -0.7871]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 23:29:39 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more intense word for ask is beg
A more intense word for tasty is delicious
A more intense word for strong is powerful
A more intense word for cry is scream
A more intense word for monkey is gorilla
A more intense word for house is palace
A more intense word for dinner is feast
A more intense word for happy is
2024-07-30 23:29:40 root INFO     [order_1_approx] starting weight calculation for A more intense word for dinner is feast
A more intense word for tasty is delicious
A more intense word for monkey is gorilla
A more intense word for cry is scream
A more intense word for house is palace
A more intense word for happy is ecstatic
A more intense word for strong is powerful
A more intense word for ask is
2024-07-30 23:29:40 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-30 23:31:36 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3159, -0.3586, -0.6333,  ..., -0.5952, -0.5645, -0.4280],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.4043, -6.5664,  0.4521,  ..., -0.0214, -3.9629, -2.9883],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.1022, -0.0160,  0.0188,  ...,  0.0162, -0.0127,  0.0438],
        [-0.0076,  0.0939, -0.0171,  ..., -0.0075, -0.0061,  0.0168],
        [-0.0227,  0.0033,  0.0697,  ..., -0.0028, -0.0163, -0.0122],
        ...,
        [ 0.0161,  0.0128, -0.0224,  ...,  0.1193, -0.0206, -0.0361],
        [-0.0069, -0.0124,  0.0103,  ...,  0.0139,  0.0643, -0.0192],
        [ 0.0183, -0.0195, -0.0072,  ..., -0.0170, -0.0001,  0.0879]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.9785, -6.1133,  0.5918,  ..., -0.3521, -4.1875, -2.8164]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 23:31:37 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more intense word for dinner is feast
A more intense word for tasty is delicious
A more intense word for monkey is gorilla
A more intense word for cry is scream
A more intense word for house is palace
A more intense word for happy is ecstatic
A more intense word for strong is powerful
A more intense word for ask is
2024-07-30 23:31:37 root INFO     [order_1_approx] starting weight calculation for A more intense word for cry is scream
A more intense word for happy is ecstatic
A more intense word for dinner is feast
A more intense word for monkey is gorilla
A more intense word for ask is beg
A more intense word for tasty is delicious
A more intense word for strong is powerful
A more intense word for house is
2024-07-30 23:31:37 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-30 23:33:34 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1017,  0.3076, -0.4370,  ..., -0.0203, -0.3154, -0.4824],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-4.1250, -4.8281,  0.6455,  ..., -0.0229, -2.0820,  0.7158],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0986,  0.0110,  0.0179,  ...,  0.0013,  0.0061,  0.0156],
        [ 0.0061,  0.1012,  0.0205,  ..., -0.0242,  0.0204,  0.0060],
        [ 0.0140,  0.0179,  0.0787,  ..., -0.0164, -0.0085,  0.0154],
        ...,
        [ 0.0067, -0.0111, -0.0092,  ...,  0.0724, -0.0074, -0.0101],
        [-0.0008, -0.0168, -0.0005,  ..., -0.0021,  0.1011,  0.0009],
        [-0.0109, -0.0119, -0.0110,  ..., -0.0098, -0.0135,  0.0806]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-3.9629, -4.4453,  0.6108,  ..., -0.0380, -2.8926,  0.5410]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 23:33:35 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more intense word for cry is scream
A more intense word for happy is ecstatic
A more intense word for dinner is feast
A more intense word for monkey is gorilla
A more intense word for ask is beg
A more intense word for tasty is delicious
A more intense word for strong is powerful
A more intense word for house is
2024-07-30 23:33:35 root INFO     [order_1_approx] starting weight calculation for A more intense word for monkey is gorilla
A more intense word for house is palace
A more intense word for strong is powerful
A more intense word for ask is beg
A more intense word for tasty is delicious
A more intense word for dinner is feast
A more intense word for happy is ecstatic
A more intense word for cry is
2024-07-30 23:33:35 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-30 23:35:28 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0400, -0.2998, -0.5674,  ..., -0.6807, -0.4946,  0.1094],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 5.3672, -6.6211,  2.9883,  ...,  0.7202, -0.6514,  0.3584],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 1.1682e-01,  1.5526e-02, -7.0724e-03,  ..., -3.0174e-03,
         -4.5624e-03, -3.9577e-05],
        [-7.8583e-03,  7.2693e-02, -1.9119e-02,  ..., -1.3885e-02,
          1.9958e-02,  1.7380e-02],
        [ 6.2790e-03,  2.1454e-02,  7.4951e-02,  ...,  2.3361e-02,
         -1.0368e-02, -2.9266e-02],
        ...,
        [ 1.1803e-02, -4.4022e-03, -1.3275e-03,  ...,  3.9429e-02,
          3.0823e-03, -4.4899e-03],
        [-1.6296e-02, -6.4316e-03,  1.1444e-02,  ...,  3.3936e-02,
          5.3406e-02, -2.9480e-02],
        [-1.1444e-05, -1.6289e-03, -1.5106e-02,  ..., -1.3229e-02,
         -3.7003e-04,  7.1533e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.9844, -5.9258,  2.6855,  ...,  0.7280, -1.0898,  0.1334]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 23:35:28 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more intense word for monkey is gorilla
A more intense word for house is palace
A more intense word for strong is powerful
A more intense word for ask is beg
A more intense word for tasty is delicious
A more intense word for dinner is feast
A more intense word for happy is ecstatic
A more intense word for cry is
2024-07-30 23:35:28 root INFO     total operator prediction time: 934.414139509201 seconds
2024-07-30 23:35:28 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on meronyms - substance
2024-07-30 23:35:28 root INFO     building operator meronyms - substance
2024-07-30 23:35:29 root INFO     [order_1_approx] starting weight calculation for A concrete is made up of silicon
A atmosphere is made up of gas
A bronze is made up of copper
A steel is made up of iron
A house is made up of bricks
A ocean is made up of water
A lawn is made up of grass
A omelette is made up of
2024-07-30 23:35:29 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-30 23:37:27 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0698, -0.2905,  0.3640,  ..., -0.2700, -1.0029, -0.2192],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.3125, -4.0781,  2.5898,  ..., -1.8037, -0.8555,  0.4668],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0659, -0.0055,  0.0014,  ..., -0.0185, -0.0076,  0.0195],
        [ 0.0013,  0.0154,  0.0220,  ..., -0.0151,  0.0072, -0.0250],
        [ 0.0126, -0.0147,  0.0591,  ..., -0.0099,  0.0031, -0.0132],
        ...,
        [ 0.0223,  0.0163,  0.0186,  ...,  0.0685, -0.0136, -0.0065],
        [-0.0177, -0.0251, -0.0202,  ...,  0.0202,  0.0519, -0.0072],
        [-0.0094, -0.0139, -0.0175,  ..., -0.0042,  0.0109,  0.0739]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.5469, -4.4141,  2.2949,  ..., -1.7510, -1.1729,  0.0261]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 23:37:28 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A concrete is made up of silicon
A atmosphere is made up of gas
A bronze is made up of copper
A steel is made up of iron
A house is made up of bricks
A ocean is made up of water
A lawn is made up of grass
A omelette is made up of
2024-07-30 23:37:28 root INFO     [order_1_approx] starting weight calculation for A bronze is made up of copper
A house is made up of bricks
A atmosphere is made up of gas
A concrete is made up of silicon
A omelette is made up of eggs
A ocean is made up of water
A steel is made up of iron
A lawn is made up of
2024-07-30 23:37:28 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-30 23:39:28 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0352,  0.2197, -0.4470,  ..., -0.0571,  0.0190, -0.7939],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 6.2227, -7.2695, -3.0918,  ..., -2.1309,  3.4062, -2.7109],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0617, -0.0140,  0.0033,  ...,  0.0274, -0.0118, -0.0046],
        [ 0.0174,  0.0580, -0.0044,  ..., -0.0278,  0.0028, -0.0193],
        [ 0.0092, -0.0003,  0.0560,  ...,  0.0031,  0.0059,  0.0019],
        ...,
        [ 0.0125, -0.0015,  0.0193,  ...,  0.0649,  0.0029,  0.0005],
        [-0.0097, -0.0015, -0.0130,  ...,  0.0235,  0.0466,  0.0184],
        [-0.0048, -0.0203, -0.0048,  ..., -0.0106,  0.0005,  0.0462]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 5.8984, -7.3242, -2.9160,  ..., -2.1523,  3.3438, -2.5312]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 23:39:29 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A bronze is made up of copper
A house is made up of bricks
A atmosphere is made up of gas
A concrete is made up of silicon
A omelette is made up of eggs
A ocean is made up of water
A steel is made up of iron
A lawn is made up of
2024-07-30 23:39:29 root INFO     [order_1_approx] starting weight calculation for A omelette is made up of eggs
A lawn is made up of grass
A atmosphere is made up of gas
A house is made up of bricks
A concrete is made up of silicon
A ocean is made up of water
A bronze is made up of copper
A steel is made up of
2024-07-30 23:39:29 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-30 23:41:28 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0612, -0.0139, -0.2340,  ..., -0.0356,  0.0280, -0.3967],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.7910, -5.3984,  0.3721,  ..., -3.4180, -1.2324, -4.0703],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0499, -0.0145,  0.0051,  ..., -0.0175,  0.0124,  0.0006],
        [-0.0276,  0.0234, -0.0086,  ..., -0.0043,  0.0106, -0.0105],
        [ 0.0278,  0.0100,  0.0262,  ...,  0.0176,  0.0022, -0.0010],
        ...,
        [ 0.0138, -0.0138, -0.0058,  ...,  0.0196,  0.0019, -0.0143],
        [-0.0191,  0.0018, -0.0009,  ...,  0.0139,  0.0211, -0.0047],
        [-0.0205, -0.0199,  0.0033,  ..., -0.0073, -0.0042,  0.0226]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.8984, -5.3984,  0.2520,  ..., -3.0742, -1.0791, -4.1211]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 23:41:29 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A omelette is made up of eggs
A lawn is made up of grass
A atmosphere is made up of gas
A house is made up of bricks
A concrete is made up of silicon
A ocean is made up of water
A bronze is made up of copper
A steel is made up of
2024-07-30 23:41:30 root INFO     [order_1_approx] starting weight calculation for A lawn is made up of grass
A bronze is made up of copper
A ocean is made up of water
A steel is made up of iron
A atmosphere is made up of gas
A house is made up of bricks
A omelette is made up of eggs
A concrete is made up of
2024-07-30 23:41:30 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-30 23:43:28 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0097,  0.1887, -0.7090,  ...,  0.4187, -0.4990,  0.2476],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.4727, -7.6953, -1.5273,  ..., -1.4648,  1.0928, -0.7041],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0443, -0.0052,  0.0070,  ...,  0.0062, -0.0151,  0.0046],
        [-0.0038,  0.0394,  0.0039,  ..., -0.0308,  0.0071, -0.0146],
        [ 0.0147,  0.0069,  0.0331,  ...,  0.0073,  0.0041, -0.0114],
        ...,
        [ 0.0043,  0.0006,  0.0144,  ...,  0.0414, -0.0079, -0.0198],
        [-0.0208, -0.0103, -0.0219,  ...,  0.0348,  0.0308, -0.0045],
        [-0.0061, -0.0046, -0.0050,  ..., -0.0202,  0.0028,  0.0337]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.5195, -7.4648, -1.2822,  ..., -1.3545,  1.2725, -0.9331]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 23:43:29 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A lawn is made up of grass
A bronze is made up of copper
A ocean is made up of water
A steel is made up of iron
A atmosphere is made up of gas
A house is made up of bricks
A omelette is made up of eggs
A concrete is made up of
2024-07-30 23:43:29 root INFO     [order_1_approx] starting weight calculation for A omelette is made up of eggs
A ocean is made up of water
A bronze is made up of copper
A concrete is made up of silicon
A steel is made up of iron
A house is made up of bricks
A lawn is made up of grass
A atmosphere is made up of
2024-07-30 23:43:29 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-30 23:45:27 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3726, -0.0783, -0.6035,  ..., -0.5854, -0.6431, -0.6113],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.3438, -3.3789,  0.9087,  ..., -5.3945,  2.8789, -0.6807],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 4.4281e-02, -1.2398e-03, -2.9793e-03,  ...,  1.1475e-02,
          2.1305e-03, -8.7051e-03],
        [-1.8631e-02,  3.8635e-02, -1.5259e-05,  ..., -1.5732e-02,
          4.5128e-03, -1.9608e-02],
        [ 1.2238e-02,  5.4626e-03,  3.6316e-02,  ...,  1.8646e-02,
         -2.3079e-04, -5.8060e-03],
        ...,
        [-2.4147e-03,  1.0986e-02,  9.2316e-03,  ...,  4.2114e-02,
         -3.4428e-03,  1.8311e-03],
        [-3.0193e-03,  3.9597e-03, -9.9564e-04,  ...,  2.0569e-02,
          3.5431e-02, -3.1281e-03],
        [-8.5831e-05,  3.0479e-03, -1.1688e-02,  ..., -5.3253e-03,
         -8.2245e-03,  5.0140e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.5293, -3.6660,  1.0244,  ..., -5.1289,  2.7324, -0.5303]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 23:45:28 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A omelette is made up of eggs
A ocean is made up of water
A bronze is made up of copper
A concrete is made up of silicon
A steel is made up of iron
A house is made up of bricks
A lawn is made up of grass
A atmosphere is made up of
2024-07-30 23:45:28 root INFO     [order_1_approx] starting weight calculation for A house is made up of bricks
A lawn is made up of grass
A steel is made up of iron
A ocean is made up of water
A concrete is made up of silicon
A atmosphere is made up of gas
A omelette is made up of eggs
A bronze is made up of
2024-07-30 23:45:28 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-30 23:47:24 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2150,  0.8662, -0.1066,  ..., -0.0822, -0.1622, -0.1015],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 5.5898, -3.0273, -0.3699,  ..., -3.5859, -2.2734, -0.0361],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0587, -0.0240, -0.0053,  ..., -0.0072, -0.0219, -0.0165],
        [-0.0210,  0.0695, -0.0113,  ..., -0.0090, -0.0053, -0.0107],
        [ 0.0247, -0.0017,  0.0512,  ...,  0.0103, -0.0127, -0.0097],
        ...,
        [ 0.0342, -0.0112, -0.0052,  ...,  0.0676, -0.0046,  0.0017],
        [-0.0317,  0.0022, -0.0007,  ...,  0.0207,  0.0548, -0.0161],
        [-0.0015,  0.0033, -0.0059,  ..., -0.0235, -0.0006,  0.0439]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 5.5469, -2.8594, -0.7192,  ..., -3.5098, -2.1836,  0.5039]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 23:47:25 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A house is made up of bricks
A lawn is made up of grass
A steel is made up of iron
A ocean is made up of water
A concrete is made up of silicon
A atmosphere is made up of gas
A omelette is made up of eggs
A bronze is made up of
2024-07-30 23:47:25 root INFO     [order_1_approx] starting weight calculation for A house is made up of bricks
A atmosphere is made up of gas
A steel is made up of iron
A lawn is made up of grass
A omelette is made up of eggs
A bronze is made up of copper
A concrete is made up of silicon
A ocean is made up of
2024-07-30 23:47:25 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-30 23:49:25 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0343,  0.4324,  0.1770,  ..., -0.8032, -0.4990, -0.5298],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.2383, -3.9141,  1.8848,  ..., -4.8594,  2.7891, -1.8301],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0401,  0.0049,  0.0025,  ...,  0.0067, -0.0049,  0.0015],
        [-0.0030,  0.0374,  0.0041,  ..., -0.0183,  0.0083, -0.0191],
        [ 0.0099,  0.0192,  0.0331,  ...,  0.0101, -0.0054,  0.0142],
        ...,
        [ 0.0070, -0.0145,  0.0127,  ...,  0.0257,  0.0116,  0.0037],
        [-0.0132, -0.0007, -0.0055,  ...,  0.0165,  0.0323, -0.0003],
        [-0.0088, -0.0127, -0.0102,  ..., -0.0076, -0.0018,  0.0446]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.3516, -3.7676,  1.7744,  ..., -5.0000,  2.5293, -1.6748]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 23:49:26 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A house is made up of bricks
A atmosphere is made up of gas
A steel is made up of iron
A lawn is made up of grass
A omelette is made up of eggs
A bronze is made up of copper
A concrete is made up of silicon
A ocean is made up of
2024-07-30 23:49:26 root INFO     [order_1_approx] starting weight calculation for A steel is made up of iron
A omelette is made up of eggs
A lawn is made up of grass
A atmosphere is made up of gas
A bronze is made up of copper
A ocean is made up of water
A concrete is made up of silicon
A house is made up of
2024-07-30 23:49:26 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-30 23:51:24 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2323,  0.3831, -0.0783,  ...,  0.4272, -0.4121, -0.5396],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.1719, -8.3750,  1.3525,  ..., -1.7949, -0.0781, -1.8486],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0256, -0.0070,  0.0061,  ...,  0.0084, -0.0075, -0.0020],
        [-0.0059,  0.0389,  0.0006,  ..., -0.0206, -0.0008, -0.0119],
        [ 0.0199,  0.0090,  0.0227,  ...,  0.0051, -0.0009, -0.0062],
        ...,
        [ 0.0114,  0.0034,  0.0124,  ...,  0.0383, -0.0021, -0.0041],
        [-0.0129,  0.0053, -0.0057,  ...,  0.0201,  0.0278, -0.0124],
        [-0.0090, -0.0178,  0.0027,  ..., -0.0083,  0.0022,  0.0491]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.9824, -8.2812,  1.1543,  ..., -1.8252, -0.3320, -1.8398]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 23:51:26 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A steel is made up of iron
A omelette is made up of eggs
A lawn is made up of grass
A atmosphere is made up of gas
A bronze is made up of copper
A ocean is made up of water
A concrete is made up of silicon
A house is made up of
2024-07-30 23:51:26 root INFO     total operator prediction time: 957.1194179058075 seconds
2024-07-30 23:51:26 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on hypernyms - misc
2024-07-30 23:51:26 root INFO     building operator hypernyms - misc
2024-07-30 23:51:26 root INFO     [order_1_approx] starting weight calculation for The lotion falls into the category of toiletry
The tv falls into the category of device
The tub falls into the category of container
The sofa falls into the category of furniture
The photo falls into the category of picture
The stapler falls into the category of device
The cup falls into the category of tableware
The juicer falls into the category of
2024-07-30 23:51:26 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-30 23:53:22 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0891, -0.4001,  0.2983,  ..., -0.2443, -0.6431, -0.3838],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.4590, -4.0508,  1.0684,  ..., -2.4883, -1.6768,  0.2979],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 4.9835e-02,  3.1357e-03,  2.3251e-03,  ..., -1.5259e-03,
          6.9046e-03,  4.0436e-03],
        [ 7.2060e-03,  5.3741e-02,  2.5177e-04,  ..., -5.7144e-03,
          1.0910e-03, -5.9052e-03],
        [-4.9896e-03, -2.8038e-04,  4.7150e-02,  ..., -6.6109e-03,
         -5.3215e-03, -3.5667e-04],
        ...,
        [ 1.0864e-02,  2.3308e-03, -2.3670e-03,  ...,  4.4678e-02,
         -1.5135e-03, -3.6201e-03],
        [ 9.0599e-04, -8.7509e-03,  8.2016e-05,  ...,  4.2152e-03,
          4.9744e-02, -1.5045e-02],
        [-1.0193e-02, -4.0245e-04, -5.7983e-03,  ..., -6.8474e-03,
         -5.3406e-03,  4.6753e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.6621, -4.0039,  0.8652,  ..., -2.4590, -1.2754,  0.2477]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 23:53:24 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The lotion falls into the category of toiletry
The tv falls into the category of device
The tub falls into the category of container
The sofa falls into the category of furniture
The photo falls into the category of picture
The stapler falls into the category of device
The cup falls into the category of tableware
The juicer falls into the category of
2024-07-30 23:53:24 root INFO     [order_1_approx] starting weight calculation for The lotion falls into the category of toiletry
The juicer falls into the category of utensil
The tub falls into the category of container
The cup falls into the category of tableware
The tv falls into the category of device
The stapler falls into the category of device
The photo falls into the category of picture
The sofa falls into the category of
2024-07-30 23:53:24 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-30 23:55:23 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1400, -0.6357,  0.3208,  ...,  0.3213, -0.5527,  0.0602],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.9521, -5.8281,  3.2812,  ..., -2.1641, -3.6875, -0.2158],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0292,  0.0036, -0.0042,  ...,  0.0022,  0.0038,  0.0090],
        [ 0.0022,  0.0412,  0.0056,  ..., -0.0130,  0.0195, -0.0267],
        [-0.0166,  0.0025,  0.0435,  ...,  0.0075, -0.0066,  0.0056],
        ...,
        [ 0.0187, -0.0015,  0.0046,  ...,  0.0381,  0.0139, -0.0100],
        [ 0.0060,  0.0054, -0.0051,  ...,  0.0045,  0.0416, -0.0192],
        [-0.0052, -0.0103, -0.0138,  ..., -0.0097,  0.0060,  0.0272]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.8564, -5.2969,  3.0977,  ..., -2.0371, -3.5195,  0.0903]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 23:55:24 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The lotion falls into the category of toiletry
The juicer falls into the category of utensil
The tub falls into the category of container
The cup falls into the category of tableware
The tv falls into the category of device
The stapler falls into the category of device
The photo falls into the category of picture
The sofa falls into the category of
2024-07-30 23:55:24 root INFO     [order_1_approx] starting weight calculation for The lotion falls into the category of toiletry
The photo falls into the category of picture
The sofa falls into the category of furniture
The cup falls into the category of tableware
The tv falls into the category of device
The tub falls into the category of container
The juicer falls into the category of utensil
The stapler falls into the category of
2024-07-30 23:55:24 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-30 23:57:17 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1097, -0.4363, -0.3433,  ..., -0.0792, -0.2939, -0.5762],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.8203, -3.6211,  1.7822,  ..., -1.6709, -3.7656, -0.3389],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 7.5256e-02, -3.5286e-03, -6.0883e-03,  ..., -9.3536e-03,
          9.5367e-05,  1.3885e-02],
        [ 1.0529e-02,  4.6143e-02, -3.7766e-03,  ..., -3.2425e-03,
          5.7297e-03, -7.0496e-03],
        [-8.8272e-03, -3.2520e-03,  5.7678e-02,  ...,  1.1330e-03,
         -1.2878e-02,  5.7983e-03],
        ...,
        [ 1.3786e-02,  1.4221e-02, -4.7150e-03,  ...,  6.5430e-02,
          5.8670e-03,  4.1008e-03],
        [ 7.3929e-03, -5.9929e-03,  5.0774e-03,  ..., -1.0681e-03,
          5.1331e-02, -1.3634e-02],
        [-2.7580e-03, -1.1398e-02, -1.5015e-02,  ..., -4.3831e-03,
         -3.3646e-03,  5.8533e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.6313, -3.6270,  1.6992,  ..., -1.5742, -3.5371, -0.1683]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 23:57:18 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The lotion falls into the category of toiletry
The photo falls into the category of picture
The sofa falls into the category of furniture
The cup falls into the category of tableware
The tv falls into the category of device
The tub falls into the category of container
The juicer falls into the category of utensil
The stapler falls into the category of
2024-07-30 23:57:18 root INFO     [order_1_approx] starting weight calculation for The lotion falls into the category of toiletry
The stapler falls into the category of device
The tub falls into the category of container
The cup falls into the category of tableware
The sofa falls into the category of furniture
The juicer falls into the category of utensil
The photo falls into the category of picture
The tv falls into the category of
2024-07-30 23:57:18 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-30 23:59:12 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0674, -1.0176, -0.0860,  ...,  0.1884, -0.2266, -0.3853],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-2.4688, -2.9844,  2.3965,  ...,  0.0686, -4.3555, -1.0078],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 5.3284e-02, -2.2812e-03,  2.5711e-03,  ..., -6.6185e-03,
          5.3558e-03, -1.5755e-03],
        [-1.0162e-02,  4.8523e-02, -8.8043e-03,  ..., -6.2609e-04,
          1.2421e-02, -1.0162e-02],
        [-1.5244e-02,  4.4899e-03,  4.8340e-02,  ...,  7.3662e-03,
         -1.9493e-03,  1.5167e-02],
        ...,
        [ 1.0994e-02,  1.0521e-02, -5.3406e-05,  ...,  4.1199e-02,
         -8.8882e-04,  2.0924e-03],
        [-1.2197e-03, -7.4158e-03,  7.6981e-03,  ..., -2.5120e-03,
          4.1840e-02, -1.4786e-02],
        [-2.6741e-03,  4.3983e-03, -1.5747e-02,  ..., -5.5695e-03,
         -6.1512e-05,  3.6896e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-2.7383, -3.0254,  2.3125,  ...,  0.2178, -4.3750, -0.9136]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 23:59:13 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The lotion falls into the category of toiletry
The stapler falls into the category of device
The tub falls into the category of container
The cup falls into the category of tableware
The sofa falls into the category of furniture
The juicer falls into the category of utensil
The photo falls into the category of picture
The tv falls into the category of
2024-07-30 23:59:13 root INFO     [order_1_approx] starting weight calculation for The tv falls into the category of device
The lotion falls into the category of toiletry
The sofa falls into the category of furniture
The cup falls into the category of tableware
The juicer falls into the category of utensil
The photo falls into the category of picture
The stapler falls into the category of device
The tub falls into the category of
2024-07-30 23:59:13 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 00:01:11 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2747, -0.2311,  0.2356,  ..., -0.5508,  0.2937,  0.4729],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.0049, -1.8457,  2.9863,  ..., -1.2109, -2.4395,  1.5791],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0742, -0.0167, -0.0033,  ...,  0.0176,  0.0083, -0.0027],
        [ 0.0002,  0.0675, -0.0101,  ..., -0.0061,  0.0040, -0.0166],
        [-0.0021,  0.0088,  0.0636,  ...,  0.0198, -0.0138, -0.0010],
        ...,
        [ 0.0220,  0.0022, -0.0124,  ...,  0.0492, -0.0103, -0.0231],
        [-0.0039, -0.0136,  0.0036,  ..., -0.0098,  0.0604, -0.0201],
        [ 0.0053,  0.0002, -0.0142,  ..., -0.0156,  0.0063,  0.0578]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.3755, -1.7949,  2.4609,  ..., -1.3086, -2.5078,  1.0986]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 00:01:13 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The tv falls into the category of device
The lotion falls into the category of toiletry
The sofa falls into the category of furniture
The cup falls into the category of tableware
The juicer falls into the category of utensil
The photo falls into the category of picture
The stapler falls into the category of device
The tub falls into the category of
2024-07-31 00:01:13 root INFO     [order_1_approx] starting weight calculation for The tv falls into the category of device
The sofa falls into the category of furniture
The tub falls into the category of container
The juicer falls into the category of utensil
The stapler falls into the category of device
The lotion falls into the category of toiletry
The cup falls into the category of tableware
The photo falls into the category of
2024-07-31 00:01:13 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 00:03:09 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.5195, -0.2283,  0.0732,  ..., -0.3699, -0.2898,  0.0637],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.4087, -3.9648,  0.6982,  ..., -1.2988, -2.2871,  0.5264],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0615,  0.0044,  0.0060,  ..., -0.0116, -0.0020,  0.0089],
        [ 0.0041,  0.0468, -0.0185,  ..., -0.0027,  0.0073, -0.0106],
        [-0.0082, -0.0161,  0.0652,  ...,  0.0134, -0.0084,  0.0185],
        ...,
        [ 0.0065,  0.0128, -0.0069,  ...,  0.0477, -0.0107, -0.0030],
        [-0.0084,  0.0052,  0.0063,  ...,  0.0082,  0.0341, -0.0136],
        [ 0.0081,  0.0038, -0.0155,  ...,  0.0078, -0.0095,  0.0508]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.4243, -4.0703,  0.7227,  ..., -1.3311, -2.3418,  0.4771]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 00:03:10 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The tv falls into the category of device
The sofa falls into the category of furniture
The tub falls into the category of container
The juicer falls into the category of utensil
The stapler falls into the category of device
The lotion falls into the category of toiletry
The cup falls into the category of tableware
The photo falls into the category of
2024-07-31 00:03:11 root INFO     [order_1_approx] starting weight calculation for The stapler falls into the category of device
The lotion falls into the category of toiletry
The photo falls into the category of picture
The sofa falls into the category of furniture
The tub falls into the category of container
The juicer falls into the category of utensil
The tv falls into the category of device
The cup falls into the category of
2024-07-31 00:03:11 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 00:05:10 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1120, -0.8047,  0.7310,  ..., -0.0767, -0.7666, -0.8525],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.3887, -1.4717, -0.1675,  ..., -4.3984, -2.6055, -0.0254],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0523,  0.0001,  0.0058,  ..., -0.0038, -0.0105,  0.0052],
        [ 0.0100,  0.0574, -0.0084,  ..., -0.0080,  0.0115, -0.0093],
        [-0.0093, -0.0149,  0.0616,  ...,  0.0072,  0.0068, -0.0026],
        ...,
        [ 0.0142, -0.0064, -0.0046,  ...,  0.0410, -0.0002, -0.0143],
        [-0.0016, -0.0059, -0.0047,  ...,  0.0050,  0.0399, -0.0090],
        [-0.0011,  0.0060, -0.0204,  ..., -0.0056, -0.0081,  0.0521]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.2559, -1.6416,  0.1477,  ..., -4.1836, -2.7266, -0.2791]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 00:05:11 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The stapler falls into the category of device
The lotion falls into the category of toiletry
The photo falls into the category of picture
The sofa falls into the category of furniture
The tub falls into the category of container
The juicer falls into the category of utensil
The tv falls into the category of device
The cup falls into the category of
2024-07-31 00:05:11 root INFO     [order_1_approx] starting weight calculation for The cup falls into the category of tableware
The juicer falls into the category of utensil
The photo falls into the category of picture
The sofa falls into the category of furniture
The stapler falls into the category of device
The tv falls into the category of device
The tub falls into the category of container
The lotion falls into the category of
2024-07-31 00:05:11 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 00:07:09 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2175, -0.3164,  0.1079,  ..., -0.3911,  0.0750, -0.3796],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.8457, -1.4023,  1.9395,  ..., -3.1289, -2.9375,  0.6836],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0538,  0.0069, -0.0050,  ..., -0.0091,  0.0010,  0.0143],
        [-0.0045,  0.0279, -0.0040,  ..., -0.0035,  0.0018, -0.0071],
        [-0.0161,  0.0100,  0.0449,  ...,  0.0102, -0.0017,  0.0011],
        ...,
        [ 0.0214, -0.0008,  0.0075,  ...,  0.0443,  0.0010,  0.0046],
        [-0.0004,  0.0107, -0.0098,  ...,  0.0064,  0.0371, -0.0156],
        [-0.0132, -0.0020, -0.0042,  ..., -0.0065, -0.0145,  0.0486]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.5762, -1.4990,  1.7510,  ..., -2.9316, -2.8086,  0.5713]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 00:07:10 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The cup falls into the category of tableware
The juicer falls into the category of utensil
The photo falls into the category of picture
The sofa falls into the category of furniture
The stapler falls into the category of device
The tv falls into the category of device
The tub falls into the category of container
The lotion falls into the category of
2024-07-31 00:07:10 root INFO     total operator prediction time: 944.6304457187653 seconds
2024-07-31 00:07:10 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on synonyms - exact
2024-07-31 00:07:10 root INFO     building operator synonyms - exact
2024-07-31 00:07:10 root INFO     [order_1_approx] starting weight calculation for Another word for jewel is gem
Another word for honest is sincere
Another word for villain is scoundrel
Another word for identical is same
Another word for loyal is faithful
Another word for list is listing
Another word for lad is chap
Another word for spouse is
2024-07-31 00:07:11 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 00:09:02 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3687,  0.1088, -0.1982,  ...,  0.2793, -0.0444, -0.3435],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.6055, -1.7549,  1.5518,  ...,  0.5562, -1.0117,  1.7930],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0522, -0.0145,  0.0370,  ..., -0.0090,  0.0044,  0.0085],
        [ 0.0029,  0.0768,  0.0203,  ...,  0.0144,  0.0271,  0.0068],
        [ 0.0035,  0.0047,  0.0726,  ..., -0.0220, -0.0018,  0.0002],
        ...,
        [ 0.0055,  0.0037, -0.0090,  ...,  0.0618, -0.0051, -0.0014],
        [-0.0249,  0.0139,  0.0106,  ...,  0.0013,  0.0587, -0.0199],
        [-0.0096, -0.0169, -0.0116,  ..., -0.0148, -0.0191,  0.0715]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.3828, -1.8555,  1.1504,  ...,  0.6567, -1.4229,  1.5967]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 00:09:03 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Another word for jewel is gem
Another word for honest is sincere
Another word for villain is scoundrel
Another word for identical is same
Another word for loyal is faithful
Another word for list is listing
Another word for lad is chap
Another word for spouse is
2024-07-31 00:09:03 root INFO     [order_1_approx] starting weight calculation for Another word for identical is same
Another word for lad is chap
Another word for spouse is partner
Another word for list is listing
Another word for honest is sincere
Another word for loyal is faithful
Another word for villain is scoundrel
Another word for jewel is
2024-07-31 00:09:03 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 00:11:01 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1750, -0.1339, -0.5786,  ..., -0.1833, -0.2566, -0.4375],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.7959, -1.7422, -2.4590,  ..., -0.2236, -3.4082,  2.3301],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0678, -0.0020,  0.0229,  ..., -0.0152, -0.0320,  0.0185],
        [ 0.0046,  0.0659,  0.0003,  ...,  0.0133,  0.0287, -0.0132],
        [ 0.0013,  0.0092,  0.0586,  ...,  0.0044, -0.0101,  0.0069],
        ...,
        [-0.0196,  0.0145, -0.0090,  ...,  0.0817,  0.0220, -0.0116],
        [-0.0166,  0.0002,  0.0301,  ..., -0.0037,  0.0507, -0.0029],
        [-0.0002,  0.0009, -0.0226,  ..., -0.0330, -0.0098,  0.0414]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.2051, -1.4883, -2.4062,  ...,  0.1711, -3.8555,  2.2656]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 00:11:02 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Another word for identical is same
Another word for lad is chap
Another word for spouse is partner
Another word for list is listing
Another word for honest is sincere
Another word for loyal is faithful
Another word for villain is scoundrel
Another word for jewel is
2024-07-31 00:11:02 root INFO     [order_1_approx] starting weight calculation for Another word for lad is chap
Another word for jewel is gem
Another word for honest is sincere
Another word for identical is same
Another word for villain is scoundrel
Another word for list is listing
Another word for spouse is partner
Another word for loyal is
2024-07-31 00:11:02 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 00:13:00 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4258, -0.0994, -0.2888,  ..., -0.2593,  0.1331,  0.3386],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.7969, -5.0859,  0.0752,  ..., -1.3789, -7.0000, -0.9404],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0799,  0.0006,  0.0219,  ..., -0.0049,  0.0157,  0.0006],
        [ 0.0190,  0.0820,  0.0223,  ...,  0.0062,  0.0139,  0.0014],
        [ 0.0273, -0.0155,  0.0814,  ..., -0.0259, -0.0128, -0.0289],
        ...,
        [-0.0244,  0.0007, -0.0043,  ...,  0.0918,  0.0143,  0.0074],
        [-0.0061, -0.0030,  0.0054,  ..., -0.0151,  0.0643, -0.0152],
        [-0.0050, -0.0201, -0.0127,  ..., -0.0076, -0.0170,  0.0821]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.4004, -4.7891, -0.0599,  ..., -1.0215, -6.5820, -0.9868]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 00:13:01 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Another word for lad is chap
Another word for jewel is gem
Another word for honest is sincere
Another word for identical is same
Another word for villain is scoundrel
Another word for list is listing
Another word for spouse is partner
Another word for loyal is
2024-07-31 00:13:01 root INFO     [order_1_approx] starting weight calculation for Another word for lad is chap
Another word for jewel is gem
Another word for honest is sincere
Another word for identical is same
Another word for villain is scoundrel
Another word for loyal is faithful
Another word for spouse is partner
Another word for list is
2024-07-31 00:13:02 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 00:14:57 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0093, -0.0925, -0.8950,  ...,  0.4392, -0.4502, -0.0638],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-2.2500, -1.9414,  2.9766,  ..., -0.5264, -1.8213, -3.1504],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0878,  0.0007,  0.0357,  ...,  0.0086,  0.0008,  0.0253],
        [ 0.0096,  0.0693, -0.0024,  ...,  0.0167,  0.0171, -0.0156],
        [-0.0032, -0.0121,  0.0791,  ..., -0.0002,  0.0059, -0.0074],
        ...,
        [ 0.0080,  0.0096, -0.0174,  ...,  0.1003, -0.0048, -0.0223],
        [-0.0182,  0.0174,  0.0250,  ..., -0.0126,  0.0710, -0.0097],
        [ 0.0075, -0.0165,  0.0097,  ..., -0.0180, -0.0184,  0.0871]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.7051, -1.8691,  3.1035,  ..., -0.6211, -2.2559, -2.7637]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 00:14:58 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Another word for lad is chap
Another word for jewel is gem
Another word for honest is sincere
Another word for identical is same
Another word for villain is scoundrel
Another word for loyal is faithful
Another word for spouse is partner
Another word for list is
2024-07-31 00:14:59 root INFO     [order_1_approx] starting weight calculation for Another word for list is listing
Another word for jewel is gem
Another word for lad is chap
Another word for villain is scoundrel
Another word for loyal is faithful
Another word for honest is sincere
Another word for spouse is partner
Another word for identical is
2024-07-31 00:14:59 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 00:16:55 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0256, -0.3923, -0.2588,  ..., -0.0259,  0.0316,  0.1763],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.2261, -0.0784,  1.9912,  ..., -0.2939, -3.6562, -0.4805],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.1080, -0.0045,  0.0172,  ...,  0.0161, -0.0032,  0.0243],
        [-0.0088,  0.1007, -0.0018,  ..., -0.0084,  0.0415, -0.0098],
        [ 0.0062, -0.0008,  0.1143,  ..., -0.0151,  0.0075, -0.0289],
        ...,
        [ 0.0217,  0.0056, -0.0001,  ...,  0.1271, -0.0119, -0.0111],
        [-0.0036, -0.0147,  0.0037,  ..., -0.0222,  0.0739,  0.0312],
        [ 0.0039, -0.0071, -0.0234,  ..., -0.0110, -0.0085,  0.1090]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.1943,  0.0344,  1.8145,  ...,  0.3022, -4.2461, -0.4927]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 00:16:56 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Another word for list is listing
Another word for jewel is gem
Another word for lad is chap
Another word for villain is scoundrel
Another word for loyal is faithful
Another word for honest is sincere
Another word for spouse is partner
Another word for identical is
2024-07-31 00:16:56 root INFO     [order_1_approx] starting weight calculation for Another word for lad is chap
Another word for list is listing
Another word for jewel is gem
Another word for honest is sincere
Another word for loyal is faithful
Another word for spouse is partner
Another word for identical is same
Another word for villain is
2024-07-31 00:16:56 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 00:18:52 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.5991,  0.6382, -0.4575,  ...,  0.1692, -0.3672, -0.3040],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.3555, -3.0254,  1.0156,  ..., -0.6450, -3.2559,  0.2632],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0574, -0.0323,  0.0344,  ..., -0.0187,  0.0020,  0.0083],
        [ 0.0086,  0.0670,  0.0002,  ..., -0.0027,  0.0199, -0.0041],
        [ 0.0127, -0.0311,  0.0567,  ..., -0.0088, -0.0117,  0.0118],
        ...,
        [-0.0051,  0.0250, -0.0291,  ...,  0.0653,  0.0173, -0.0041],
        [-0.0159, -0.0021,  0.0156,  ...,  0.0064,  0.0715, -0.0055],
        [ 0.0174, -0.0022, -0.0267,  ..., -0.0131, -0.0165,  0.0500]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.2402, -2.6855,  0.6494,  ..., -0.4700, -3.2285,  0.3423]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 00:18:53 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Another word for lad is chap
Another word for list is listing
Another word for jewel is gem
Another word for honest is sincere
Another word for loyal is faithful
Another word for spouse is partner
Another word for identical is same
Another word for villain is
2024-07-31 00:18:53 root INFO     [order_1_approx] starting weight calculation for Another word for spouse is partner
Another word for honest is sincere
Another word for identical is same
Another word for loyal is faithful
Another word for list is listing
Another word for villain is scoundrel
Another word for jewel is gem
Another word for lad is
2024-07-31 00:18:53 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 00:20:51 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3091,  0.4172, -0.4253,  ...,  0.0989, -0.3247, -0.3584],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.8613, -1.6191, -4.0508,  ...,  2.9668, -0.5039, -1.4746],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0967, -0.0186,  0.0320,  ..., -0.0037, -0.0200, -0.0005],
        [ 0.0046,  0.0621, -0.0005,  ..., -0.0021,  0.0333, -0.0083],
        [ 0.0224,  0.0124,  0.0317,  ..., -0.0270,  0.0133, -0.0146],
        ...,
        [-0.0326,  0.0122, -0.0234,  ...,  0.0590, -0.0134, -0.0164],
        [-0.0109, -0.0204,  0.0094,  ..., -0.0180,  0.0473, -0.0192],
        [ 0.0005,  0.0107, -0.0105,  ..., -0.0155, -0.0123,  0.0409]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.6660, -1.5391, -3.9121,  ...,  3.3027, -1.3555, -1.6396]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 00:20:52 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Another word for spouse is partner
Another word for honest is sincere
Another word for identical is same
Another word for loyal is faithful
Another word for list is listing
Another word for villain is scoundrel
Another word for jewel is gem
Another word for lad is
2024-07-31 00:20:52 root INFO     [order_1_approx] starting weight calculation for Another word for jewel is gem
Another word for loyal is faithful
Another word for lad is chap
Another word for list is listing
Another word for spouse is partner
Another word for identical is same
Another word for villain is scoundrel
Another word for honest is
2024-07-31 00:20:52 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 00:22:52 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0087,  0.2783, -0.5508,  ...,  0.0173,  0.1863,  0.1858],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.5898, -2.8105, -0.9629,  ...,  0.2012, -9.4141,  2.6934],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.1132, -0.0103,  0.0317,  ..., -0.0141, -0.0068,  0.0208],
        [ 0.0062,  0.1038,  0.0049,  ..., -0.0038,  0.0342,  0.0059],
        [ 0.0191, -0.0074,  0.0989,  ..., -0.0283, -0.0215, -0.0158],
        ...,
        [-0.0022, -0.0017, -0.0015,  ...,  0.1359,  0.0163, -0.0123],
        [-0.0124,  0.0235,  0.0107,  ..., -0.0145,  0.0872, -0.0227],
        [-0.0029, -0.0193, -0.0029,  ..., -0.0209, -0.0234,  0.0951]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.4580, -2.0859, -1.0254,  ...,  0.0719, -9.3750,  2.8359]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 00:22:53 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Another word for jewel is gem
Another word for loyal is faithful
Another word for lad is chap
Another word for list is listing
Another word for spouse is partner
Another word for identical is same
Another word for villain is scoundrel
Another word for honest is
2024-07-31 00:22:53 root INFO     total operator prediction time: 942.4758765697479 seconds
2024-07-31 00:22:53 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on animal - youth
2024-07-31 00:22:53 root INFO     building operator animal - youth
2024-07-31 00:22:53 root INFO     [order_1_approx] starting weight calculation for The offspring of a duck is referred to as a duckling
The offspring of a muskrat is referred to as a kit
The offspring of a beetle is referred to as a larva
The offspring of a ox is referred to as a calf
The offspring of a gorilla is referred to as a infant
The offspring of a fox is referred to as a cub
The offspring of a cattle is referred to as a calf
The offspring of a skunk is referred to as a
2024-07-31 00:22:53 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 00:24:51 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1405,  0.0093,  0.0746,  ...,  0.0619, -0.7861,  0.2751],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.8887, -2.2852, -1.4980,  ...,  0.0928, -2.7812,  1.4199],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 5.8533e-02, -1.1612e-02, -1.4343e-02,  ...,  1.2337e-02,
         -1.2608e-03, -3.8605e-03],
        [ 8.6365e-03,  3.9154e-02, -6.7253e-03,  ..., -1.0529e-02,
          4.5242e-03, -2.0275e-03],
        [ 4.7150e-03,  1.3489e-02,  5.5023e-02,  ...,  1.7380e-02,
         -1.2009e-02, -1.9470e-02],
        ...,
        [-1.0586e-03,  1.7273e-02,  2.3621e-02,  ...,  6.2134e-02,
          2.8076e-02,  8.4457e-03],
        [-4.8065e-03,  5.0240e-03,  2.4048e-02,  ..., -7.7248e-03,
          1.8570e-02, -1.1429e-02],
        [-7.6294e-06,  2.1622e-02, -1.4221e-02,  ..., -2.6184e-02,
          2.1698e-02,  5.3619e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.9492, -2.0645, -1.2393,  ...,  0.4001, -2.8750,  1.4678]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 00:24:52 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The offspring of a duck is referred to as a duckling
The offspring of a muskrat is referred to as a kit
The offspring of a beetle is referred to as a larva
The offspring of a ox is referred to as a calf
The offspring of a gorilla is referred to as a infant
The offspring of a fox is referred to as a cub
The offspring of a cattle is referred to as a calf
The offspring of a skunk is referred to as a
2024-07-31 00:24:52 root INFO     [order_1_approx] starting weight calculation for The offspring of a ox is referred to as a calf
The offspring of a beetle is referred to as a larva
The offspring of a muskrat is referred to as a kit
The offspring of a duck is referred to as a duckling
The offspring of a cattle is referred to as a calf
The offspring of a fox is referred to as a cub
The offspring of a skunk is referred to as a kit
The offspring of a gorilla is referred to as a
2024-07-31 00:24:52 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 00:26:50 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3115, -0.1516,  0.6719,  ..., -0.3254, -0.9312,  0.6396],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.3730, -3.6309, -0.3618,  ...,  0.4336, -2.6387,  1.7178],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 2.0523e-02, -7.9422e-03,  6.6662e-04,  ...,  5.8594e-03,
          2.0409e-03,  8.9550e-04],
        [ 3.6144e-03,  2.1317e-02,  1.4505e-03,  ..., -3.4485e-03,
          7.6370e-03, -3.7918e-03],
        [ 5.9814e-03,  9.4452e-03,  1.8234e-02,  ..., -6.6757e-05,
          3.0804e-03, -4.4022e-03],
        ...,
        [ 1.8654e-03,  4.1008e-04, -8.1635e-03,  ...,  1.9287e-02,
          7.3128e-03,  3.6125e-03],
        [ 6.8817e-03, -1.6346e-03,  1.0529e-02,  ...,  6.8893e-03,
          1.9165e-02,  6.5231e-04],
        [-1.2985e-02, -6.9351e-03, -5.3902e-03,  ..., -1.5564e-02,
          1.1444e-05,  1.5808e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.4277, -3.5625, -0.1089,  ...,  0.6167, -2.7129,  1.6006]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 00:26:51 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The offspring of a ox is referred to as a calf
The offspring of a beetle is referred to as a larva
The offspring of a muskrat is referred to as a kit
The offspring of a duck is referred to as a duckling
The offspring of a cattle is referred to as a calf
The offspring of a fox is referred to as a cub
The offspring of a skunk is referred to as a kit
The offspring of a gorilla is referred to as a
2024-07-31 00:26:51 root INFO     [order_1_approx] starting weight calculation for The offspring of a fox is referred to as a cub
The offspring of a skunk is referred to as a kit
The offspring of a gorilla is referred to as a infant
The offspring of a duck is referred to as a duckling
The offspring of a cattle is referred to as a calf
The offspring of a ox is referred to as a calf
The offspring of a muskrat is referred to as a kit
The offspring of a beetle is referred to as a
2024-07-31 00:26:51 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 00:28:50 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1630,  0.2192,  0.1399,  ...,  0.0192, -0.3481, -0.1241],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.1094, -1.9492, -0.1074,  ...,  0.7856,  0.2393, -0.8408],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0361, -0.0109,  0.0014,  ...,  0.0074,  0.0064, -0.0070],
        [ 0.0124,  0.0181,  0.0066,  ...,  0.0056, -0.0029, -0.0159],
        [ 0.0026, -0.0013,  0.0278,  ...,  0.0105,  0.0008, -0.0002],
        ...,
        [ 0.0072,  0.0014, -0.0040,  ...,  0.0255,  0.0177, -0.0003],
        [ 0.0040, -0.0039,  0.0115,  ...,  0.0125,  0.0156, -0.0079],
        [ 0.0033, -0.0014, -0.0020,  ..., -0.0037, -0.0049,  0.0309]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.2773, -2.0938, -0.2306,  ...,  0.8779,  0.2454, -0.9644]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 00:28:51 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The offspring of a fox is referred to as a cub
The offspring of a skunk is referred to as a kit
The offspring of a gorilla is referred to as a infant
The offspring of a duck is referred to as a duckling
The offspring of a cattle is referred to as a calf
The offspring of a ox is referred to as a calf
The offspring of a muskrat is referred to as a kit
The offspring of a beetle is referred to as a
2024-07-31 00:28:51 root INFO     [order_1_approx] starting weight calculation for The offspring of a skunk is referred to as a kit
The offspring of a ox is referred to as a calf
The offspring of a muskrat is referred to as a kit
The offspring of a gorilla is referred to as a infant
The offspring of a fox is referred to as a cub
The offspring of a beetle is referred to as a larva
The offspring of a duck is referred to as a duckling
The offspring of a cattle is referred to as a
2024-07-31 00:28:51 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 00:30:48 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0503, -0.2517,  0.0928,  ...,  0.1300, -0.1078,  0.0531],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.8926, -3.5918, -0.6904,  ...,  0.6426,  0.1045, -1.1064],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0443, -0.0210,  0.0160,  ...,  0.0143,  0.0105, -0.0107],
        [ 0.0183,  0.0185,  0.0035,  ..., -0.0081, -0.0052,  0.0030],
        [ 0.0181, -0.0023,  0.0314,  ...,  0.0027,  0.0023, -0.0224],
        ...,
        [-0.0013,  0.0106, -0.0030,  ...,  0.0481,  0.0183,  0.0026],
        [ 0.0024,  0.0173,  0.0087,  ...,  0.0106,  0.0236, -0.0165],
        [-0.0086, -0.0017, -0.0078,  ..., -0.0195,  0.0052,  0.0281]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.4355, -3.6758, -0.3140,  ...,  0.7222, -0.7178, -0.9565]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 00:30:49 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The offspring of a skunk is referred to as a kit
The offspring of a ox is referred to as a calf
The offspring of a muskrat is referred to as a kit
The offspring of a gorilla is referred to as a infant
The offspring of a fox is referred to as a cub
The offspring of a beetle is referred to as a larva
The offspring of a duck is referred to as a duckling
The offspring of a cattle is referred to as a
2024-07-31 00:30:49 root INFO     [order_1_approx] starting weight calculation for The offspring of a fox is referred to as a cub
The offspring of a ox is referred to as a calf
The offspring of a skunk is referred to as a kit
The offspring of a duck is referred to as a duckling
The offspring of a beetle is referred to as a larva
The offspring of a gorilla is referred to as a infant
The offspring of a cattle is referred to as a calf
The offspring of a muskrat is referred to as a
2024-07-31 00:30:49 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 00:32:46 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1499, -0.0746,  0.1768,  ..., -0.9600, -1.0381,  0.3521],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.3281, -1.0088, -1.1250,  ..., -0.9629, -1.1670,  1.3623],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0452, -0.0011, -0.0015,  ...,  0.0091, -0.0063, -0.0029],
        [ 0.0214,  0.0242,  0.0088,  ...,  0.0113,  0.0038, -0.0121],
        [-0.0028,  0.0210,  0.0312,  ...,  0.0079, -0.0130, -0.0157],
        ...,
        [ 0.0070,  0.0014,  0.0080,  ...,  0.0363,  0.0020,  0.0099],
        [ 0.0056, -0.0037,  0.0061,  ...,  0.0087,  0.0199, -0.0041],
        [-0.0043,  0.0083,  0.0003,  ..., -0.0068,  0.0017,  0.0303]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.0312, -0.4111, -1.0088,  ..., -0.5723, -1.6523,  1.7197]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 00:32:47 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The offspring of a fox is referred to as a cub
The offspring of a ox is referred to as a calf
The offspring of a skunk is referred to as a kit
The offspring of a duck is referred to as a duckling
The offspring of a beetle is referred to as a larva
The offspring of a gorilla is referred to as a infant
The offspring of a cattle is referred to as a calf
The offspring of a muskrat is referred to as a
2024-07-31 00:32:47 root INFO     [order_1_approx] starting weight calculation for The offspring of a ox is referred to as a calf
The offspring of a beetle is referred to as a larva
The offspring of a muskrat is referred to as a kit
The offspring of a skunk is referred to as a kit
The offspring of a duck is referred to as a duckling
The offspring of a cattle is referred to as a calf
The offspring of a gorilla is referred to as a infant
The offspring of a fox is referred to as a
2024-07-31 00:32:47 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 00:34:43 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1833,  0.2900,  0.5117,  ..., -0.1218, -0.1102,  0.0944],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.7891, -4.6445, -1.8525,  ...,  0.9199, -2.2109,  2.6777],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0301, -0.0015,  0.0042,  ...,  0.0147,  0.0003,  0.0033],
        [ 0.0072,  0.0228,  0.0041,  ..., -0.0064,  0.0082, -0.0107],
        [ 0.0020, -0.0037,  0.0342,  ..., -0.0006,  0.0045, -0.0195],
        ...,
        [-0.0057,  0.0010,  0.0081,  ...,  0.0209,  0.0278,  0.0024],
        [ 0.0061, -0.0096,  0.0197,  ...,  0.0015,  0.0203, -0.0089],
        [ 0.0029, -0.0019, -0.0027,  ..., -0.0086, -0.0140,  0.0238]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.2070, -4.3789, -1.6758,  ...,  0.9839, -2.5879,  2.6289]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 00:34:44 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The offspring of a ox is referred to as a calf
The offspring of a beetle is referred to as a larva
The offspring of a muskrat is referred to as a kit
The offspring of a skunk is referred to as a kit
The offspring of a duck is referred to as a duckling
The offspring of a cattle is referred to as a calf
The offspring of a gorilla is referred to as a infant
The offspring of a fox is referred to as a
2024-07-31 00:34:45 root INFO     [order_1_approx] starting weight calculation for The offspring of a beetle is referred to as a larva
The offspring of a cattle is referred to as a calf
The offspring of a gorilla is referred to as a infant
The offspring of a muskrat is referred to as a kit
The offspring of a skunk is referred to as a kit
The offspring of a fox is referred to as a cub
The offspring of a ox is referred to as a calf
The offspring of a duck is referred to as a
2024-07-31 00:34:45 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 00:36:42 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.6660, -0.1510,  0.4658,  ..., -0.3428, -0.2974,  0.0569],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.0098, -1.2422, -1.7988,  ..., -0.4219, -5.1406,  2.1562],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 4.5105e-02, -5.1727e-03,  1.4019e-03,  ..., -6.1035e-05,
         -4.7684e-07,  2.4891e-03],
        [ 8.8730e-03,  1.9806e-02,  8.3923e-03,  ..., -2.7618e-03,
         -4.6463e-03, -8.4915e-03],
        [-3.1509e-03,  1.0132e-02,  3.3539e-02,  ..., -6.9885e-03,
         -9.6130e-03, -1.8402e-02],
        ...,
        [-7.0648e-03,  3.6621e-04, -1.0185e-02,  ...,  2.4734e-02,
          2.9068e-03,  1.5011e-03],
        [ 5.5771e-03, -7.7972e-03,  4.1199e-03,  ...,  7.8049e-03,
          2.8137e-02, -4.2114e-03],
        [-7.7209e-03, -8.4000e-03,  5.0926e-04,  ..., -7.0038e-03,
          1.6464e-02,  2.1545e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.8066, -1.1113, -1.8340,  ...,  0.0771, -5.2383,  2.1289]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 00:36:43 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The offspring of a beetle is referred to as a larva
The offspring of a cattle is referred to as a calf
The offspring of a gorilla is referred to as a infant
The offspring of a muskrat is referred to as a kit
The offspring of a skunk is referred to as a kit
The offspring of a fox is referred to as a cub
The offspring of a ox is referred to as a calf
The offspring of a duck is referred to as a
2024-07-31 00:36:44 root INFO     [order_1_approx] starting weight calculation for The offspring of a beetle is referred to as a larva
The offspring of a skunk is referred to as a kit
The offspring of a gorilla is referred to as a infant
The offspring of a cattle is referred to as a calf
The offspring of a duck is referred to as a duckling
The offspring of a muskrat is referred to as a kit
The offspring of a fox is referred to as a cub
The offspring of a ox is referred to as a
2024-07-31 00:36:44 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 00:38:39 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0656, -0.1978,  0.7432,  ..., -0.2458, -0.1377, -0.0264],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.4395, -2.5156, -1.9434,  ...,  1.2793, -0.3755, -0.0078],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0476, -0.0053,  0.0133,  ...,  0.0120, -0.0087, -0.0176],
        [ 0.0280,  0.0277,  0.0035,  ..., -0.0084,  0.0016, -0.0107],
        [ 0.0119,  0.0121,  0.0332,  ..., -0.0118, -0.0102, -0.0236],
        ...,
        [ 0.0104,  0.0022,  0.0001,  ...,  0.0490,  0.0212, -0.0034],
        [ 0.0011,  0.0121,  0.0136,  ..., -0.0095,  0.0465, -0.0061],
        [-0.0044,  0.0110, -0.0022,  ..., -0.0129,  0.0190,  0.0316]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.6855, -2.3359, -1.7324,  ...,  1.0586, -0.6016,  0.1990]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 00:38:40 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The offspring of a beetle is referred to as a larva
The offspring of a skunk is referred to as a kit
The offspring of a gorilla is referred to as a infant
The offspring of a cattle is referred to as a calf
The offspring of a duck is referred to as a duckling
The offspring of a muskrat is referred to as a kit
The offspring of a fox is referred to as a cub
The offspring of a ox is referred to as a
2024-07-31 00:38:40 root INFO     total operator prediction time: 947.2656607627869 seconds
2024-07-31 00:38:40 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on animal - sound
2024-07-31 00:38:40 root INFO     building operator animal - sound
2024-07-31 00:38:40 root INFO     [order_1_approx] starting weight calculation for The sound that a elk makes is called a bellow
The sound that a wasp makes is called a buzz
The sound that a chimpanzee makes is called a scream
The sound that a horse makes is called a neigh
The sound that a hornet makes is called a buzz
The sound that a mouse makes is called a squeak
The sound that a gorilla makes is called a grunt
The sound that a fox makes is called a
2024-07-31 00:38:40 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 00:40:36 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0855,  0.1764,  0.4924,  ...,  0.0640, -0.0070,  0.1697],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.4531, -6.4648, -0.0703,  ..., -2.8945, -0.4878,  4.0586],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 4.0466e-02,  9.9640e-03,  3.9253e-03,  ...,  4.8637e-05,
         -2.9755e-02,  3.6354e-03],
        [-2.8763e-02,  1.9547e-02,  2.5757e-02,  ...,  1.7365e-02,
          1.3611e-02, -9.7122e-03],
        [ 2.7039e-02,  7.7438e-03,  5.0293e-02,  ..., -1.8967e-02,
         -6.1111e-03, -1.1429e-02],
        ...,
        [-1.5793e-03, -1.4481e-02,  1.0452e-02,  ...,  4.4952e-02,
          1.7395e-02, -2.1896e-03],
        [-8.8959e-03, -1.5945e-02,  8.9264e-03,  ...,  1.9104e-02,
          4.1992e-02, -4.7607e-03],
        [ 1.4282e-02, -1.7944e-02, -3.3447e-02,  ..., -3.2997e-03,
         -1.7395e-02,  3.0334e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.2891, -5.7969,  0.6641,  ..., -3.3281, -0.7632,  3.6875]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 00:40:37 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The sound that a elk makes is called a bellow
The sound that a wasp makes is called a buzz
The sound that a chimpanzee makes is called a scream
The sound that a horse makes is called a neigh
The sound that a hornet makes is called a buzz
The sound that a mouse makes is called a squeak
The sound that a gorilla makes is called a grunt
The sound that a fox makes is called a
2024-07-31 00:40:37 root INFO     [order_1_approx] starting weight calculation for The sound that a chimpanzee makes is called a scream
The sound that a gorilla makes is called a grunt
The sound that a elk makes is called a bellow
The sound that a hornet makes is called a buzz
The sound that a horse makes is called a neigh
The sound that a fox makes is called a howl
The sound that a wasp makes is called a buzz
The sound that a mouse makes is called a
2024-07-31 00:40:37 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 00:42:35 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.3843, -0.2527,  0.4233,  ..., -0.2084, -0.4219,  0.2676],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.0137, -0.3855,  2.2520,  ..., -2.5488, -0.7451,  2.4297],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0504, -0.0029, -0.0017,  ...,  0.0033, -0.0232, -0.0007],
        [ 0.0033,  0.0332,  0.0050,  ..., -0.0118,  0.0194, -0.0014],
        [ 0.0077,  0.0174,  0.0604,  ..., -0.0026, -0.0028, -0.0188],
        ...,
        [ 0.0068,  0.0004,  0.0013,  ...,  0.0384,  0.0014, -0.0052],
        [-0.0046, -0.0033,  0.0005,  ...,  0.0051,  0.0319, -0.0044],
        [-0.0147,  0.0069, -0.0084,  ..., -0.0095, -0.0084,  0.0371]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.7949, -0.5273,  2.0000,  ..., -2.8965, -0.8760,  2.2773]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 00:42:36 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The sound that a chimpanzee makes is called a scream
The sound that a gorilla makes is called a grunt
The sound that a elk makes is called a bellow
The sound that a hornet makes is called a buzz
The sound that a horse makes is called a neigh
The sound that a fox makes is called a howl
The sound that a wasp makes is called a buzz
The sound that a mouse makes is called a
2024-07-31 00:42:36 root INFO     [order_1_approx] starting weight calculation for The sound that a hornet makes is called a buzz
The sound that a chimpanzee makes is called a scream
The sound that a fox makes is called a howl
The sound that a elk makes is called a bellow
The sound that a horse makes is called a neigh
The sound that a wasp makes is called a buzz
The sound that a mouse makes is called a squeak
The sound that a gorilla makes is called a
2024-07-31 00:42:36 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 00:44:36 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1056, -0.5859,  0.2198,  ..., -0.3574, -0.7666,  0.3984],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 5.2188, -5.0391,  1.2041,  ..., -0.2412, -0.7681,  0.2568],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0385, -0.0021,  0.0033,  ..., -0.0049,  0.0034, -0.0059],
        [ 0.0090,  0.0196, -0.0093,  ...,  0.0047, -0.0055, -0.0060],
        [ 0.0052,  0.0007,  0.0261,  ..., -0.0111,  0.0015, -0.0022],
        ...,
        [ 0.0207,  0.0070, -0.0164,  ...,  0.0407,  0.0032,  0.0018],
        [ 0.0020, -0.0062, -0.0020,  ...,  0.0141,  0.0360, -0.0104],
        [-0.0121, -0.0062, -0.0140,  ..., -0.0090, -0.0013,  0.0182]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 5.3633, -5.0156,  1.1387,  ..., -0.2910, -1.0039,  0.1277]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 00:44:36 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The sound that a hornet makes is called a buzz
The sound that a chimpanzee makes is called a scream
The sound that a fox makes is called a howl
The sound that a elk makes is called a bellow
The sound that a horse makes is called a neigh
The sound that a wasp makes is called a buzz
The sound that a mouse makes is called a squeak
The sound that a gorilla makes is called a
2024-07-31 00:44:37 root INFO     [order_1_approx] starting weight calculation for The sound that a mouse makes is called a squeak
The sound that a fox makes is called a howl
The sound that a horse makes is called a neigh
The sound that a chimpanzee makes is called a scream
The sound that a hornet makes is called a buzz
The sound that a gorilla makes is called a grunt
The sound that a wasp makes is called a buzz
The sound that a elk makes is called a
2024-07-31 00:44:37 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 00:46:35 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0973, -0.3347,  0.3091,  ...,  0.2288, -0.5698,  0.3279],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.5913, -3.6152,  1.0088,  ...,  1.7637, -1.0234,  0.5186],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0485, -0.0165,  0.0053,  ...,  0.0206, -0.0091,  0.0136],
        [-0.0161,  0.0437,  0.0047,  ...,  0.0291, -0.0148, -0.0173],
        [ 0.0302,  0.0147,  0.0589,  ..., -0.0181, -0.0139, -0.0114],
        ...,
        [-0.0054,  0.0011, -0.0088,  ...,  0.0776, -0.0110, -0.0073],
        [ 0.0190,  0.0053,  0.0029,  ...,  0.0153,  0.0405,  0.0009],
        [-0.0233, -0.0296, -0.0006,  ..., -0.0152, -0.0163,  0.0279]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.6548, -3.7109,  1.0107,  ...,  1.4580, -0.8330,  0.3123]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 00:46:36 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The sound that a mouse makes is called a squeak
The sound that a fox makes is called a howl
The sound that a horse makes is called a neigh
The sound that a chimpanzee makes is called a scream
The sound that a hornet makes is called a buzz
The sound that a gorilla makes is called a grunt
The sound that a wasp makes is called a buzz
The sound that a elk makes is called a
2024-07-31 00:46:36 root INFO     [order_1_approx] starting weight calculation for The sound that a wasp makes is called a buzz
The sound that a fox makes is called a howl
The sound that a mouse makes is called a squeak
The sound that a chimpanzee makes is called a scream
The sound that a elk makes is called a bellow
The sound that a gorilla makes is called a grunt
The sound that a hornet makes is called a buzz
The sound that a horse makes is called a
2024-07-31 00:46:36 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 00:48:30 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.4207, -0.3057,  0.9043,  ...,  0.0750,  0.3828, -0.0045],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.4717, -2.4609, -1.5449,  ...,  2.6055, -0.0752,  1.8711],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0458, -0.0016,  0.0051,  ...,  0.0002, -0.0001,  0.0062],
        [-0.0082,  0.0284, -0.0028,  ...,  0.0053,  0.0107,  0.0017],
        [-0.0061,  0.0059,  0.0526,  ..., -0.0065,  0.0064, -0.0033],
        ...,
        [ 0.0257,  0.0074, -0.0016,  ...,  0.0434,  0.0046, -0.0100],
        [-0.0066,  0.0099,  0.0058,  ...,  0.0196,  0.0247, -0.0159],
        [-0.0042, -0.0020,  0.0070,  ...,  0.0020, -0.0085,  0.0159]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.5078, -2.2305, -1.5254,  ...,  2.4512, -0.8516,  1.5547]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 00:48:31 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The sound that a wasp makes is called a buzz
The sound that a fox makes is called a howl
The sound that a mouse makes is called a squeak
The sound that a chimpanzee makes is called a scream
The sound that a elk makes is called a bellow
The sound that a gorilla makes is called a grunt
The sound that a hornet makes is called a buzz
The sound that a horse makes is called a
2024-07-31 00:48:32 root INFO     [order_1_approx] starting weight calculation for The sound that a horse makes is called a neigh
The sound that a mouse makes is called a squeak
The sound that a gorilla makes is called a grunt
The sound that a wasp makes is called a buzz
The sound that a chimpanzee makes is called a scream
The sound that a elk makes is called a bellow
The sound that a fox makes is called a howl
The sound that a hornet makes is called a
2024-07-31 00:48:32 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 00:50:25 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0860, -0.2499,  0.0507,  ..., -0.0379, -0.2407, -0.1653],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.1826, -2.1172,  2.8770,  ...,  0.0325, -1.0586,  2.0000],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0499, -0.0224, -0.0013,  ...,  0.0035, -0.0134, -0.0024],
        [-0.0208,  0.0244,  0.0114,  ...,  0.0292, -0.0139,  0.0021],
        [ 0.0033,  0.0233,  0.0504,  ..., -0.0005, -0.0063, -0.0019],
        ...,
        [-0.0015, -0.0129,  0.0174,  ...,  0.0565,  0.0003,  0.0036],
        [-0.0013,  0.0048, -0.0007,  ..., -0.0018,  0.0377, -0.0107],
        [-0.0163,  0.0052, -0.0073,  ..., -0.0127, -0.0051,  0.0379]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.1436, -2.2324,  2.9160,  ..., -0.0558, -0.9380,  1.9453]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 00:50:26 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The sound that a horse makes is called a neigh
The sound that a mouse makes is called a squeak
The sound that a gorilla makes is called a grunt
The sound that a wasp makes is called a buzz
The sound that a chimpanzee makes is called a scream
The sound that a elk makes is called a bellow
The sound that a fox makes is called a howl
The sound that a hornet makes is called a
2024-07-31 00:50:26 root INFO     [order_1_approx] starting weight calculation for The sound that a gorilla makes is called a grunt
The sound that a wasp makes is called a buzz
The sound that a elk makes is called a bellow
The sound that a horse makes is called a neigh
The sound that a mouse makes is called a squeak
The sound that a hornet makes is called a buzz
The sound that a fox makes is called a howl
The sound that a chimpanzee makes is called a
2024-07-31 00:50:26 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 00:52:21 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.4761, -0.5566,  0.2363,  ..., -0.2729, -0.5117,  0.3940],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.7812, -2.6738,  1.0947,  ..., -0.4102, -1.5449,  1.1309],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 7.0496e-03, -1.0281e-03, -8.1301e-04,  ..., -1.6308e-04,
          2.5678e-04, -5.3644e-05],
        [-1.7238e-04,  3.4695e-03,  1.3018e-04,  ..., -1.7300e-03,
         -6.1178e-04,  2.1815e-04],
        [-1.2910e-04,  7.6151e-04,  4.1924e-03,  ..., -1.6384e-03,
          1.8415e-03, -1.7519e-03],
        ...,
        [ 3.1776e-03,  1.4229e-03, -4.2915e-04,  ...,  4.4479e-03,
         -1.4811e-03,  1.2970e-03],
        [ 1.0562e-04, -9.8801e-04, -4.3011e-04,  ...,  2.4815e-03,
          5.5008e-03,  1.6708e-03],
        [-2.5711e-03, -1.5020e-03, -2.1935e-03,  ..., -8.8024e-04,
         -3.1948e-05,  1.5316e-03]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.7637, -2.6680,  1.0742,  ..., -0.4111, -1.5361,  1.0977]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 00:52:22 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The sound that a gorilla makes is called a grunt
The sound that a wasp makes is called a buzz
The sound that a elk makes is called a bellow
The sound that a horse makes is called a neigh
The sound that a mouse makes is called a squeak
The sound that a hornet makes is called a buzz
The sound that a fox makes is called a howl
The sound that a chimpanzee makes is called a
2024-07-31 00:52:22 root INFO     [order_1_approx] starting weight calculation for The sound that a gorilla makes is called a grunt
The sound that a mouse makes is called a squeak
The sound that a elk makes is called a bellow
The sound that a horse makes is called a neigh
The sound that a chimpanzee makes is called a scream
The sound that a fox makes is called a howl
The sound that a hornet makes is called a buzz
The sound that a wasp makes is called a
2024-07-31 00:52:22 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 00:54:19 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0861, -0.6147,  0.5923,  ..., -0.0370, -0.2505, -0.2705],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.6621, -1.5400,  2.5957,  ..., -0.6348, -0.0312,  2.2422],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 5.0995e-02, -5.6725e-03, -2.2869e-03,  ..., -1.4267e-03,
         -1.1261e-02,  4.2038e-03],
        [-1.3176e-02,  3.0365e-02,  5.1498e-04,  ...,  1.5625e-02,
         -5.5237e-03,  2.5291e-03],
        [ 1.3374e-02,  1.3565e-02,  4.2877e-02,  ...,  1.6623e-03,
         -9.7961e-03, -8.6136e-03],
        ...,
        [-7.2632e-03, -9.7036e-05,  5.5046e-03,  ...,  5.3955e-02,
         -5.4855e-03, -1.0262e-02],
        [-1.0956e-02,  4.9057e-03,  2.4643e-03,  ...,  3.2253e-03,
          2.4734e-02, -9.8495e-03],
        [-4.7340e-03,  1.0132e-02, -1.0803e-02,  ..., -1.2978e-02,
         -6.1264e-03,  3.9429e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.3867, -1.5576,  2.5176,  ..., -0.7031,  0.0557,  2.2051]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 00:54:20 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The sound that a gorilla makes is called a grunt
The sound that a mouse makes is called a squeak
The sound that a elk makes is called a bellow
The sound that a horse makes is called a neigh
The sound that a chimpanzee makes is called a scream
The sound that a fox makes is called a howl
The sound that a hornet makes is called a buzz
The sound that a wasp makes is called a
2024-07-31 00:54:20 root INFO     total operator prediction time: 940.4619266986847 seconds
2024-07-31 00:54:20 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on things - color
2024-07-31 00:54:20 root INFO     building operator things - color
2024-07-31 00:54:21 root INFO     [order_1_approx] starting weight calculation for The grapes is colored black
The crow is colored black
The cherry is colored red
The cream is colored white
The spinach is colored green
The ant is colored black
The potato is colored brown
The cabbage is colored
2024-07-31 00:54:21 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 00:56:19 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.5947,  0.2668, -0.1455,  ..., -0.5928, -0.5312, -0.6035],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.3203, -5.8203, -1.4434,  ...,  1.2998,  1.7109, -2.5430],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0723,  0.0013,  0.0011,  ...,  0.0042,  0.0041, -0.0007],
        [ 0.0159,  0.0492,  0.0226,  ..., -0.0102,  0.0114, -0.0105],
        [ 0.0092, -0.0115,  0.0652,  ...,  0.0025, -0.0018,  0.0002],
        ...,
        [ 0.0164, -0.0218, -0.0010,  ...,  0.0757, -0.0073,  0.0030],
        [-0.0106, -0.0093, -0.0166,  ...,  0.0198,  0.0577, -0.0131],
        [-0.0063,  0.0083, -0.0004,  ..., -0.0080,  0.0028,  0.0535]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.9824, -5.7461, -1.4297,  ...,  1.3584,  1.4580, -2.4609]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 00:56:20 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The grapes is colored black
The crow is colored black
The cherry is colored red
The cream is colored white
The spinach is colored green
The ant is colored black
The potato is colored brown
The cabbage is colored
2024-07-31 00:56:20 root INFO     [order_1_approx] starting weight calculation for The cabbage is colored green
The grapes is colored black
The cream is colored white
The ant is colored black
The spinach is colored green
The crow is colored black
The cherry is colored red
The potato is colored
2024-07-31 00:56:20 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 00:58:20 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3701, -0.1222, -0.2139,  ..., -0.0801, -0.9404, -0.5254],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.4248, -4.3672, -0.4097,  ..., -4.0703, -1.9219, -2.9453],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0705, -0.0040,  0.0051,  ..., -0.0054,  0.0104, -0.0069],
        [ 0.0422,  0.0542,  0.0305,  ..., -0.0085,  0.0044, -0.0130],
        [ 0.0176, -0.0029,  0.0609,  ...,  0.0135, -0.0066, -0.0144],
        ...,
        [-0.0033, -0.0171,  0.0077,  ...,  0.0708, -0.0013,  0.0235],
        [ 0.0011, -0.0031, -0.0130,  ...,  0.0286,  0.0482,  0.0001],
        [ 0.0087,  0.0021,  0.0107,  ..., -0.0017, -0.0084,  0.0668]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.2441, -4.5391, -0.6738,  ..., -3.6973, -1.8613, -2.4668]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 00:58:21 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The cabbage is colored green
The grapes is colored black
The cream is colored white
The ant is colored black
The spinach is colored green
The crow is colored black
The cherry is colored red
The potato is colored
2024-07-31 00:58:21 root INFO     [order_1_approx] starting weight calculation for The crow is colored black
The grapes is colored black
The potato is colored brown
The cabbage is colored green
The spinach is colored green
The cream is colored white
The cherry is colored red
The ant is colored
2024-07-31 00:58:21 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 01:00:20 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0469, -0.3491, -0.4331,  ..., -0.1520,  0.0525, -0.2705],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.0146, -4.2031,  0.1370,  ..., -0.5537, -0.8125, -1.4277],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0997, -0.0047,  0.0107,  ..., -0.0001,  0.0036, -0.0125],
        [ 0.0157,  0.0581,  0.0185,  ..., -0.0045,  0.0230, -0.0058],
        [ 0.0109,  0.0159,  0.0554,  ...,  0.0197, -0.0140,  0.0104],
        ...,
        [ 0.0264,  0.0012,  0.0072,  ...,  0.0861, -0.0098,  0.0030],
        [ 0.0046, -0.0004, -0.0097,  ...,  0.0192,  0.0591, -0.0040],
        [-0.0078,  0.0061, -0.0162,  ...,  0.0040, -0.0121,  0.0666]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.6011e-02, -4.5156e+00, -3.4180e-03,  ..., -6.2402e-01,
         -7.7344e-01, -1.3193e+00]], device='cuda:1', dtype=torch.float16,
       grad_fn=<SubBackward0>) 

                    
2024-07-31 01:00:21 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The crow is colored black
The grapes is colored black
The potato is colored brown
The cabbage is colored green
The spinach is colored green
The cream is colored white
The cherry is colored red
The ant is colored
2024-07-31 01:00:21 root INFO     [order_1_approx] starting weight calculation for The cream is colored white
The ant is colored black
The potato is colored brown
The cabbage is colored green
The spinach is colored green
The cherry is colored red
The crow is colored black
The grapes is colored
2024-07-31 01:00:21 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 01:02:19 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4077, -1.2910,  0.0410,  ..., -0.0283, -0.4409, -0.4133],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.0488, -7.8984, -1.9268,  ..., -1.8115,  0.4941, -2.7891],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0533,  0.0047,  0.0054,  ..., -0.0057, -0.0025, -0.0028],
        [ 0.0022,  0.0407,  0.0268,  ...,  0.0018,  0.0082, -0.0183],
        [ 0.0164, -0.0057,  0.0401,  ...,  0.0099,  0.0019, -0.0053],
        ...,
        [ 0.0016, -0.0044,  0.0042,  ...,  0.0585, -0.0021,  0.0043],
        [-0.0016, -0.0090, -0.0071,  ...,  0.0208,  0.0409, -0.0094],
        [-0.0051, -0.0072,  0.0016,  ..., -0.0040, -0.0095,  0.0453]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.0117, -7.9258, -2.0820,  ..., -1.9336,  0.5352, -2.7109]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 01:02:21 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The cream is colored white
The ant is colored black
The potato is colored brown
The cabbage is colored green
The spinach is colored green
The cherry is colored red
The crow is colored black
The grapes is colored
2024-07-31 01:02:21 root INFO     [order_1_approx] starting weight calculation for The grapes is colored black
The ant is colored black
The cabbage is colored green
The potato is colored brown
The cream is colored white
The crow is colored black
The cherry is colored red
The spinach is colored
2024-07-31 01:02:21 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 01:04:13 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2034, -0.2183, -0.1675,  ...,  0.0163, -0.8135, -0.3892],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.0020, -5.5039, -2.1504,  ..., -0.8267, -0.7983, -3.8516],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0706,  0.0202, -0.0083,  ..., -0.0039,  0.0103, -0.0004],
        [ 0.0106,  0.0468,  0.0268,  ...,  0.0072,  0.0118, -0.0069],
        [ 0.0084, -0.0173,  0.0577,  ...,  0.0089, -0.0190,  0.0018],
        ...,
        [ 0.0141, -0.0106, -0.0050,  ...,  0.0750, -0.0007,  0.0057],
        [-0.0074, -0.0081, -0.0074,  ...,  0.0136,  0.0615, -0.0072],
        [ 0.0011,  0.0066,  0.0033,  ..., -0.0105,  0.0019,  0.0618]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.8086, -5.5078, -2.3594,  ..., -0.8252, -0.8813, -3.5039]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 01:04:14 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The grapes is colored black
The ant is colored black
The cabbage is colored green
The potato is colored brown
The cream is colored white
The crow is colored black
The cherry is colored red
The spinach is colored
2024-07-31 01:04:14 root INFO     [order_1_approx] starting weight calculation for The spinach is colored green
The cabbage is colored green
The grapes is colored black
The cherry is colored red
The ant is colored black
The cream is colored white
The potato is colored brown
The crow is colored
2024-07-31 01:04:14 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 01:06:13 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1973, -0.6338, -0.1282,  ..., -0.1125, -0.5464,  0.1302],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.8184, -4.3359,  3.3828,  ..., -0.2373,  0.9365, -1.7793],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0757, -0.0144,  0.0079,  ..., -0.0134,  0.0140, -0.0070],
        [ 0.0089,  0.0771,  0.0180,  ...,  0.0073,  0.0007,  0.0062],
        [ 0.0194, -0.0006,  0.0597,  ...,  0.0112, -0.0034,  0.0157],
        ...,
        [ 0.0101,  0.0029,  0.0145,  ...,  0.0920, -0.0138,  0.0101],
        [ 0.0106,  0.0010, -0.0296,  ...,  0.0303,  0.0584, -0.0222],
        [ 0.0088,  0.0015, -0.0064,  ..., -0.0141, -0.0186,  0.0644]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.7627, -4.5352,  3.1836,  ..., -0.2223,  0.7891, -1.9336]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 01:06:13 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The spinach is colored green
The cabbage is colored green
The grapes is colored black
The cherry is colored red
The ant is colored black
The cream is colored white
The potato is colored brown
The crow is colored
2024-07-31 01:06:14 root INFO     [order_1_approx] starting weight calculation for The cabbage is colored green
The spinach is colored green
The crow is colored black
The cream is colored white
The grapes is colored black
The ant is colored black
The potato is colored brown
The cherry is colored
2024-07-31 01:06:14 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 01:08:10 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1603, -0.8975, -0.7217,  ..., -0.3213, -0.1763, -0.7178],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.0156, -7.6328, -2.5605,  ..., -2.2441,  1.3438, -2.5469],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0497,  0.0035,  0.0071,  ..., -0.0076,  0.0041, -0.0030],
        [-0.0015,  0.0425,  0.0231,  ...,  0.0054,  0.0097, -0.0007],
        [ 0.0124,  0.0049,  0.0372,  ...,  0.0043, -0.0036, -0.0091],
        ...,
        [ 0.0049, -0.0018, -0.0004,  ...,  0.0607, -0.0008,  0.0066],
        [-0.0096, -0.0214, -0.0094,  ...,  0.0251,  0.0402, -0.0103],
        [-0.0052, -0.0056, -0.0004,  ..., -0.0025, -0.0057,  0.0388]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.7441, -7.4336, -2.5488,  ..., -2.0332,  0.9941, -2.7832]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 01:08:11 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The cabbage is colored green
The spinach is colored green
The crow is colored black
The cream is colored white
The grapes is colored black
The ant is colored black
The potato is colored brown
The cherry is colored
2024-07-31 01:08:11 root INFO     [order_1_approx] starting weight calculation for The cherry is colored red
The potato is colored brown
The spinach is colored green
The grapes is colored black
The cabbage is colored green
The crow is colored black
The ant is colored black
The cream is colored
2024-07-31 01:08:11 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 01:10:10 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.3877, -0.3916,  0.1532,  ..., -0.3486, -0.3425, -0.0549],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.2275, -5.0586,  1.6348,  ..., -2.2852,  0.9087, -0.5146],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0887,  0.0110,  0.0071,  ...,  0.0059, -0.0066,  0.0078],
        [ 0.0010,  0.0581,  0.0148,  ...,  0.0092,  0.0165, -0.0031],
        [ 0.0008,  0.0083,  0.0573,  ...,  0.0093,  0.0019,  0.0018],
        ...,
        [ 0.0215, -0.0025, -0.0032,  ...,  0.0746, -0.0053,  0.0122],
        [-0.0087,  0.0019, -0.0004,  ...,  0.0270,  0.0630, -0.0099],
        [-0.0094,  0.0171,  0.0003,  ...,  0.0025,  0.0007,  0.0567]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.1631, -5.0312,  1.4658,  ..., -2.2559,  0.5449, -0.7007]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 01:10:11 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The cherry is colored red
The potato is colored brown
The spinach is colored green
The grapes is colored black
The cabbage is colored green
The crow is colored black
The ant is colored black
The cream is colored
2024-07-31 01:10:11 root INFO     total operator prediction time: 950.2792167663574 seconds
2024-07-31 01:10:11 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on country - capital
2024-07-31 01:10:11 root INFO     building operator country - capital
2024-07-31 01:10:11 root INFO     [order_1_approx] starting weight calculation for The country with manila as its capital is known as philippines
The country with lisbon as its capital is known as portugal
The country with baghdad as its capital is known as iraq
The country with havana as its capital is known as cuba
The country with tokyo as its capital is known as japan
The country with hanoi as its capital is known as vietnam
The country with madrid as its capital is known as spain
The country with ottawa as its capital is known as
2024-07-31 01:10:11 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 01:12:06 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0070,  0.1722, -0.3779,  ..., -0.2703, -0.1200,  0.1096],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.4175, -6.6250,  0.4243,  ..., -0.7314,  2.2715, -1.6309],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0392,  0.0006, -0.0005,  ...,  0.0209,  0.0003, -0.0086],
        [-0.0034,  0.0192,  0.0159,  ..., -0.0152, -0.0005, -0.0099],
        [ 0.0029, -0.0002,  0.0237,  ...,  0.0152, -0.0015,  0.0065],
        ...,
        [ 0.0063,  0.0018, -0.0067,  ...,  0.0356, -0.0031,  0.0030],
        [ 0.0025, -0.0078, -0.0119,  ..., -0.0019,  0.0205,  0.0003],
        [-0.0084, -0.0033,  0.0018,  ..., -0.0115, -0.0004,  0.0233]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.4646, -6.4609,  0.0679,  ..., -0.4387,  2.1758, -1.6875]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 01:12:07 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country with manila as its capital is known as philippines
The country with lisbon as its capital is known as portugal
The country with baghdad as its capital is known as iraq
The country with havana as its capital is known as cuba
The country with tokyo as its capital is known as japan
The country with hanoi as its capital is known as vietnam
The country with madrid as its capital is known as spain
The country with ottawa as its capital is known as
2024-07-31 01:12:07 root INFO     [order_1_approx] starting weight calculation for The country with manila as its capital is known as philippines
The country with tokyo as its capital is known as japan
The country with madrid as its capital is known as spain
The country with baghdad as its capital is known as iraq
The country with lisbon as its capital is known as portugal
The country with havana as its capital is known as cuba
The country with ottawa as its capital is known as canada
The country with hanoi as its capital is known as
2024-07-31 01:12:07 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 01:14:02 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0796, -0.1697,  0.0359,  ..., -0.1255, -0.3081,  0.3672],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.6665, -6.2188, -0.1082,  ..., -1.5508, -1.8799, -3.3633],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 1.6953e-02, -2.5868e-05, -1.2989e-03,  ...,  9.5062e-03,
         -7.3128e-03, -1.9512e-03],
        [-4.0436e-03,  1.6510e-02,  3.3092e-03,  ..., -2.8744e-03,
         -1.1578e-03, -1.6235e-02],
        [ 5.9128e-03, -2.8563e-04,  1.3702e-02,  ...,  3.1052e-03,
         -2.0695e-03,  2.4796e-04],
        ...,
        [ 7.5455e-03, -1.0939e-03, -8.6288e-03,  ...,  1.9974e-02,
          3.8605e-03, -7.9155e-05],
        [ 1.8177e-03, -3.8757e-03, -2.1057e-03,  ...,  2.5597e-03,
          1.1940e-02, -4.4346e-05],
        [-2.7561e-03, -1.5535e-03, -9.6130e-03,  ...,  7.4806e-03,
          6.6032e-03,  1.3107e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.6772, -6.0781, -0.2393,  ..., -1.4512, -1.7959, -3.3438]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 01:14:02 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country with manila as its capital is known as philippines
The country with tokyo as its capital is known as japan
The country with madrid as its capital is known as spain
The country with baghdad as its capital is known as iraq
The country with lisbon as its capital is known as portugal
The country with havana as its capital is known as cuba
The country with ottawa as its capital is known as canada
The country with hanoi as its capital is known as
2024-07-31 01:14:03 root INFO     [order_1_approx] starting weight calculation for The country with madrid as its capital is known as spain
The country with ottawa as its capital is known as canada
The country with hanoi as its capital is known as vietnam
The country with baghdad as its capital is known as iraq
The country with havana as its capital is known as cuba
The country with tokyo as its capital is known as japan
The country with lisbon as its capital is known as portugal
The country with manila as its capital is known as
2024-07-31 01:14:03 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 01:15:59 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.6040,  0.2681, -0.2184,  ..., -0.3645, -0.4539, -0.0083],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.4434, -5.9609, -0.3625,  ..., -1.9873, -1.3330, -4.5898],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0315,  0.0046, -0.0081,  ...,  0.0118, -0.0081,  0.0014],
        [ 0.0018,  0.0220,  0.0044,  ..., -0.0092,  0.0062, -0.0203],
        [-0.0002,  0.0018,  0.0402,  ...,  0.0053, -0.0153, -0.0067],
        ...,
        [-0.0009, -0.0062,  0.0067,  ...,  0.0238,  0.0087, -0.0012],
        [-0.0007, -0.0062, -0.0064,  ..., -0.0032,  0.0200, -0.0074],
        [-0.0017, -0.0092,  0.0003,  ...,  0.0042,  0.0029,  0.0165]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.7012, -5.6758, -0.8281,  ..., -2.1758, -1.5918, -4.4805]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 01:16:00 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country with madrid as its capital is known as spain
The country with ottawa as its capital is known as canada
The country with hanoi as its capital is known as vietnam
The country with baghdad as its capital is known as iraq
The country with havana as its capital is known as cuba
The country with tokyo as its capital is known as japan
The country with lisbon as its capital is known as portugal
The country with manila as its capital is known as
2024-07-31 01:16:00 root INFO     [order_1_approx] starting weight calculation for The country with ottawa as its capital is known as canada
The country with baghdad as its capital is known as iraq
The country with hanoi as its capital is known as vietnam
The country with madrid as its capital is known as spain
The country with manila as its capital is known as philippines
The country with lisbon as its capital is known as portugal
The country with havana as its capital is known as cuba
The country with tokyo as its capital is known as
2024-07-31 01:16:00 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 01:17:58 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2830, -0.1556,  0.3000,  ...,  0.0735,  0.1982,  0.4312],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.4316, -4.9180, -0.3857,  ...,  0.5977,  1.2188, -2.6719],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0154,  0.0028,  0.0026,  ...,  0.0052, -0.0039, -0.0010],
        [ 0.0035,  0.0117,  0.0020,  ..., -0.0038,  0.0059, -0.0071],
        [-0.0025,  0.0020,  0.0164,  ...,  0.0069,  0.0014, -0.0046],
        ...,
        [ 0.0038,  0.0015,  0.0023,  ...,  0.0160,  0.0005, -0.0027],
        [ 0.0006,  0.0009, -0.0058,  ..., -0.0020,  0.0076,  0.0015],
        [-0.0070, -0.0049, -0.0037,  ..., -0.0004, -0.0026,  0.0112]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.4336, -4.8711, -0.5942,  ...,  0.4612,  1.1758, -2.7031]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 01:17:59 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country with ottawa as its capital is known as canada
The country with baghdad as its capital is known as iraq
The country with hanoi as its capital is known as vietnam
The country with madrid as its capital is known as spain
The country with manila as its capital is known as philippines
The country with lisbon as its capital is known as portugal
The country with havana as its capital is known as cuba
The country with tokyo as its capital is known as
2024-07-31 01:18:00 root INFO     [order_1_approx] starting weight calculation for The country with tokyo as its capital is known as japan
The country with baghdad as its capital is known as iraq
The country with havana as its capital is known as cuba
The country with hanoi as its capital is known as vietnam
The country with ottawa as its capital is known as canada
The country with manila as its capital is known as philippines
The country with madrid as its capital is known as spain
The country with lisbon as its capital is known as
2024-07-31 01:18:00 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 01:19:59 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.5293, -0.0602, -0.4854,  ..., -0.0553,  0.1556, -0.2356],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.8203, -6.1953, -3.1309,  ...,  0.2208,  2.0938, -4.3906],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 3.4515e-02,  8.0643e-03,  8.4829e-04,  ...,  1.0590e-02,
         -7.2517e-03, -1.3876e-04],
        [-2.4490e-03,  1.7792e-02,  9.7961e-03,  ..., -1.2115e-02,
         -1.0700e-03, -1.6571e-02],
        [ 4.9095e-03,  3.0365e-03,  2.7740e-02,  ...,  1.0986e-02,
          9.9640e-03,  1.9388e-03],
        ...,
        [ 2.5940e-04,  7.2556e-03, -9.7198e-03,  ...,  2.8564e-02,
          8.6823e-03,  2.7504e-03],
        [-1.0452e-03,  4.4727e-04, -1.1253e-02,  ...,  4.2381e-03,
          2.0248e-02,  2.3460e-03],
        [-1.6068e-02,  8.0109e-05, -1.5602e-02,  ...,  5.1727e-03,
          5.3062e-03,  1.4107e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.8691, -6.0859, -3.0000,  ...,  0.3086,  2.1465, -4.4219]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 01:20:00 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country with tokyo as its capital is known as japan
The country with baghdad as its capital is known as iraq
The country with havana as its capital is known as cuba
The country with hanoi as its capital is known as vietnam
The country with ottawa as its capital is known as canada
The country with manila as its capital is known as philippines
The country with madrid as its capital is known as spain
The country with lisbon as its capital is known as
2024-07-31 01:20:00 root INFO     [order_1_approx] starting weight calculation for The country with ottawa as its capital is known as canada
The country with manila as its capital is known as philippines
The country with hanoi as its capital is known as vietnam
The country with havana as its capital is known as cuba
The country with tokyo as its capital is known as japan
The country with lisbon as its capital is known as portugal
The country with baghdad as its capital is known as iraq
The country with madrid as its capital is known as
2024-07-31 01:20:00 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 01:21:57 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.5479, -0.1403, -0.4683,  ...,  0.5088,  0.8052,  0.0304],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.3418, -4.7773, -2.1484,  ...,  0.8672,  1.1709, -5.3594],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 2.4323e-02,  1.9646e-03, -8.4457e-03,  ...,  6.5575e-03,
         -1.2085e-02, -3.3302e-03],
        [ 5.2490e-03,  9.1400e-03,  1.5312e-02,  ..., -9.1324e-03,
         -6.3248e-03, -1.5045e-02],
        [ 1.3628e-03,  1.1269e-02,  2.6489e-02,  ...,  1.6373e-02,
          1.2054e-02, -7.7744e-03],
        ...,
        [ 4.9667e-03,  1.2939e-02, -7.8125e-03,  ...,  2.7969e-02,
          6.2027e-03, -9.0485e-03],
        [ 5.1880e-03, -7.1640e-03, -1.4191e-02,  ..., -3.0060e-03,
          8.8120e-03, -1.1444e-05],
        [-1.3664e-02, -1.2405e-02, -3.9101e-04,  ...,  1.6022e-02,
         -4.9210e-04,  1.4763e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.3457, -4.2773, -2.5859,  ...,  0.4507,  1.3604, -5.1133]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 01:21:58 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country with ottawa as its capital is known as canada
The country with manila as its capital is known as philippines
The country with hanoi as its capital is known as vietnam
The country with havana as its capital is known as cuba
The country with tokyo as its capital is known as japan
The country with lisbon as its capital is known as portugal
The country with baghdad as its capital is known as iraq
The country with madrid as its capital is known as
2024-07-31 01:21:58 root INFO     [order_1_approx] starting weight calculation for The country with manila as its capital is known as philippines
The country with madrid as its capital is known as spain
The country with lisbon as its capital is known as portugal
The country with ottawa as its capital is known as canada
The country with havana as its capital is known as cuba
The country with hanoi as its capital is known as vietnam
The country with tokyo as its capital is known as japan
The country with baghdad as its capital is known as
2024-07-31 01:21:58 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 01:23:55 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0173, -0.0341, -0.3718,  ..., -0.0110, -0.0590,  0.1647],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.6025, -2.3906, -1.2275,  ..., -0.4067,  0.3909, -4.6758],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 1.3443e-02, -3.6354e-03, -2.0676e-03,  ...,  1.8682e-03,
         -3.3569e-03, -5.1880e-03],
        [-7.1106e-03,  1.6556e-02,  1.8005e-03,  ..., -9.3918e-03,
          5.6686e-03, -9.0942e-03],
        [ 2.7657e-03,  2.7027e-03,  2.1042e-02,  ...,  1.7853e-03,
          2.7466e-03, -2.1553e-04],
        ...,
        [ 7.0000e-04,  5.6572e-03, -6.5231e-03,  ...,  1.9363e-02,
          1.5202e-03, -1.3008e-03],
        [-5.4359e-04, -4.2038e-03,  3.6430e-04,  ..., -4.7684e-03,
          1.0872e-02,  6.7711e-05],
        [-2.4223e-03, -9.6893e-03, -1.0887e-02,  ...,  9.8515e-04,
          3.1586e-03,  9.9564e-03]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.5747, -2.3379, -1.1963,  ..., -0.4124,  0.4043, -4.7539]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 01:23:56 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country with manila as its capital is known as philippines
The country with madrid as its capital is known as spain
The country with lisbon as its capital is known as portugal
The country with ottawa as its capital is known as canada
The country with havana as its capital is known as cuba
The country with hanoi as its capital is known as vietnam
The country with tokyo as its capital is known as japan
The country with baghdad as its capital is known as
2024-07-31 01:23:56 root INFO     [order_1_approx] starting weight calculation for The country with baghdad as its capital is known as iraq
The country with ottawa as its capital is known as canada
The country with tokyo as its capital is known as japan
The country with manila as its capital is known as philippines
The country with lisbon as its capital is known as portugal
The country with madrid as its capital is known as spain
The country with hanoi as its capital is known as vietnam
The country with havana as its capital is known as
2024-07-31 01:23:56 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 01:25:55 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0166, -0.1201,  0.0133,  ..., -0.3977,  0.3181, -0.4978],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.4199, -4.3047, -1.2207,  ...,  1.4023,  2.1055, -2.0742],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0305, -0.0007,  0.0007,  ...,  0.0156, -0.0065, -0.0049],
        [-0.0009,  0.0205,  0.0269,  ..., -0.0246, -0.0048, -0.0220],
        [-0.0086,  0.0109,  0.0235,  ...,  0.0211, -0.0052,  0.0034],
        ...,
        [ 0.0082,  0.0046, -0.0132,  ...,  0.0394, -0.0006, -0.0052],
        [-0.0026, -0.0121, -0.0109,  ..., -0.0016,  0.0211, -0.0046],
        [-0.0037, -0.0030, -0.0102,  ...,  0.0141,  0.0040,  0.0140]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.3398, -4.1406, -1.8359,  ...,  0.8560,  1.6758, -2.4727]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 01:25:56 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country with baghdad as its capital is known as iraq
The country with ottawa as its capital is known as canada
The country with tokyo as its capital is known as japan
The country with manila as its capital is known as philippines
The country with lisbon as its capital is known as portugal
The country with madrid as its capital is known as spain
The country with hanoi as its capital is known as vietnam
The country with havana as its capital is known as
2024-07-31 01:25:56 root INFO     total operator prediction time: 944.8358449935913 seconds
2024-07-31 01:25:56 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on name - occupation
2024-07-31 01:25:56 root INFO     building operator name - occupation
2024-07-31 01:25:56 root INFO     [order_1_approx] starting weight calculation for edison was known for their work as a  inventor
columbus was known for their work as a  explorer
hegel was known for their work as a  philosopher
hitler was known for their work as a  dictator
plato was known for their work as a  philosopher
newton was known for their work as a  scientist
raphael was known for their work as a  painter
dickens was known for their work as a 
2024-07-31 01:25:56 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 01:27:53 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1947,  0.0485,  0.0652,  ...,  0.2029, -0.2925,  0.0085],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.5352, -5.2070,  4.6641,  ..., -5.0781,  0.0159, -1.3291],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0452,  0.0010,  0.0089,  ...,  0.0011, -0.0141,  0.0001],
        [ 0.0067,  0.0302,  0.0024,  ...,  0.0008,  0.0085, -0.0055],
        [ 0.0204, -0.0034,  0.0480,  ..., -0.0004, -0.0013,  0.0103],
        ...,
        [ 0.0173, -0.0001, -0.0030,  ...,  0.0583,  0.0094, -0.0005],
        [-0.0051,  0.0075, -0.0005,  ...,  0.0083,  0.0352,  0.0085],
        [-0.0094,  0.0034, -0.0083,  ..., -0.0021, -0.0054,  0.0479]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.6172, -5.4336,  4.5117,  ..., -5.0078,  0.0124, -1.5225]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 01:27:54 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for edison was known for their work as a  inventor
columbus was known for their work as a  explorer
hegel was known for their work as a  philosopher
hitler was known for their work as a  dictator
plato was known for their work as a  philosopher
newton was known for their work as a  scientist
raphael was known for their work as a  painter
dickens was known for their work as a 
2024-07-31 01:27:54 root INFO     [order_1_approx] starting weight calculation for edison was known for their work as a  inventor
dickens was known for their work as a  novelist
plato was known for their work as a  philosopher
hitler was known for their work as a  dictator
columbus was known for their work as a  explorer
newton was known for their work as a  scientist
hegel was known for their work as a  philosopher
raphael was known for their work as a 
2024-07-31 01:27:54 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 01:29:53 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.5542, -0.1262,  0.1748,  ..., -0.3516, -0.4197,  0.1646],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.1250, -6.9922,  2.5195,  ..., -7.3672, -0.4136, -2.5840],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0743,  0.0071,  0.0037,  ...,  0.0032, -0.0130,  0.0009],
        [ 0.0132,  0.0548, -0.0034,  ..., -0.0041,  0.0064, -0.0066],
        [ 0.0195, -0.0009,  0.0650,  ..., -0.0106, -0.0097,  0.0110],
        ...,
        [ 0.0041,  0.0131, -0.0161,  ...,  0.0702,  0.0154,  0.0028],
        [-0.0071, -0.0065, -0.0010,  ...,  0.0067,  0.0449,  0.0104],
        [-0.0040,  0.0155, -0.0059,  ..., -0.0102, -0.0085,  0.0525]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.9609, -6.6562,  2.5566,  ..., -7.3320, -0.2622, -2.0879]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 01:29:54 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for edison was known for their work as a  inventor
dickens was known for their work as a  novelist
plato was known for their work as a  philosopher
hitler was known for their work as a  dictator
columbus was known for their work as a  explorer
newton was known for their work as a  scientist
hegel was known for their work as a  philosopher
raphael was known for their work as a 
2024-07-31 01:29:54 root INFO     [order_1_approx] starting weight calculation for plato was known for their work as a  philosopher
hegel was known for their work as a  philosopher
hitler was known for their work as a  dictator
columbus was known for their work as a  explorer
dickens was known for their work as a  novelist
raphael was known for their work as a  painter
edison was known for their work as a  inventor
newton was known for their work as a 
2024-07-31 01:29:54 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 01:31:51 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.4680, -0.2937, -0.1639,  ..., -0.3655, -0.0280,  0.5781],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.8086, -3.9180,  1.4180,  ..., -7.7070,  0.7129, -1.9688],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0305,  0.0087,  0.0133,  ...,  0.0030, -0.0186, -0.0033],
        [-0.0012,  0.0492, -0.0091,  ..., -0.0021,  0.0171, -0.0047],
        [ 0.0161, -0.0013,  0.0538,  ..., -0.0030, -0.0019,  0.0157],
        ...,
        [ 0.0077,  0.0121, -0.0096,  ...,  0.0479,  0.0010, -0.0002],
        [-0.0091,  0.0016, -0.0064,  ...,  0.0156,  0.0399, -0.0043],
        [-0.0163,  0.0098, -0.0062,  ..., -0.0038, -0.0064,  0.0541]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.2305, -4.0781,  1.4814,  ..., -7.4844,  0.6191, -1.9482]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 01:31:52 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for plato was known for their work as a  philosopher
hegel was known for their work as a  philosopher
hitler was known for their work as a  dictator
columbus was known for their work as a  explorer
dickens was known for their work as a  novelist
raphael was known for their work as a  painter
edison was known for their work as a  inventor
newton was known for their work as a 
2024-07-31 01:31:52 root INFO     [order_1_approx] starting weight calculation for hegel was known for their work as a  philosopher
plato was known for their work as a  philosopher
dickens was known for their work as a  novelist
edison was known for their work as a  inventor
newton was known for their work as a  scientist
raphael was known for their work as a  painter
columbus was known for their work as a  explorer
hitler was known for their work as a 
2024-07-31 01:31:52 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 01:33:50 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3994, -0.2410, -0.3503,  ...,  0.6792, -0.3838,  0.4800],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.4473, -7.5234,  3.9766,  ..., -4.5859, -0.4102, -1.7607],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 5.4749e-02, -1.5831e-04, -1.2407e-03,  ..., -1.2589e-03,
         -1.1726e-02,  1.6966e-03],
        [-4.3602e-03,  3.4729e-02,  1.8396e-03,  ..., -5.6305e-03,
          5.4169e-04, -1.1337e-02],
        [ 9.0332e-03, -1.0246e-02,  4.7882e-02,  ..., -9.7466e-04,
          7.0381e-03,  1.7441e-02],
        ...,
        [ 2.9354e-03, -2.4414e-03, -1.0368e-02,  ...,  5.1697e-02,
         -7.4425e-03, -5.9814e-03],
        [-1.1200e-02,  2.6512e-03,  6.3553e-03,  ..., -3.7766e-03,
          3.3752e-02, -3.6430e-03],
        [-8.1482e-03, -1.1091e-03,  3.3646e-03,  ...,  4.9629e-03,
          1.1444e-05,  4.4800e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.5410, -7.2422,  3.5605,  ..., -4.5703, -0.3535, -1.6240]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 01:33:51 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for hegel was known for their work as a  philosopher
plato was known for their work as a  philosopher
dickens was known for their work as a  novelist
edison was known for their work as a  inventor
newton was known for their work as a  scientist
raphael was known for their work as a  painter
columbus was known for their work as a  explorer
hitler was known for their work as a 
2024-07-31 01:33:51 root INFO     [order_1_approx] starting weight calculation for hitler was known for their work as a  dictator
raphael was known for their work as a  painter
edison was known for their work as a  inventor
hegel was known for their work as a  philosopher
dickens was known for their work as a  novelist
columbus was known for their work as a  explorer
newton was known for their work as a  scientist
plato was known for their work as a 
2024-07-31 01:33:51 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 01:35:47 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.5273, -0.3467, -0.4487,  ...,  0.3616,  0.1017,  0.3225],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.5576, -5.1250,  2.7656,  ..., -7.6914, -0.1548, -1.1299],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0626,  0.0020,  0.0065,  ..., -0.0051, -0.0119,  0.0078],
        [-0.0012,  0.0416,  0.0065,  ...,  0.0027,  0.0028, -0.0123],
        [ 0.0150, -0.0023,  0.0504,  ..., -0.0041,  0.0006,  0.0233],
        ...,
        [ 0.0132, -0.0035, -0.0055,  ...,  0.0624,  0.0004, -0.0172],
        [ 0.0066,  0.0275, -0.0121,  ...,  0.0112,  0.0427,  0.0111],
        [-0.0076,  0.0217, -0.0117,  ...,  0.0093, -0.0034,  0.0508]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.4385, -5.0469,  2.7930,  ..., -7.4219, -0.1644, -1.0557]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 01:35:48 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for hitler was known for their work as a  dictator
raphael was known for their work as a  painter
edison was known for their work as a  inventor
hegel was known for their work as a  philosopher
dickens was known for their work as a  novelist
columbus was known for their work as a  explorer
newton was known for their work as a  scientist
plato was known for their work as a 
2024-07-31 01:35:49 root INFO     [order_1_approx] starting weight calculation for edison was known for their work as a  inventor
hitler was known for their work as a  dictator
newton was known for their work as a  scientist
dickens was known for their work as a  novelist
plato was known for their work as a  philosopher
raphael was known for their work as a  painter
hegel was known for their work as a  philosopher
columbus was known for their work as a 
2024-07-31 01:35:49 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 01:37:41 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3589, -0.0939, -0.5586,  ..., -0.0350,  0.0413,  0.2612],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.7070, -3.7539, -2.1113,  ..., -3.3359,  0.9385, -0.2275],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0377,  0.0015,  0.0045,  ...,  0.0018, -0.0012,  0.0032],
        [ 0.0034,  0.0255,  0.0015,  ...,  0.0024, -0.0003, -0.0068],
        [ 0.0057,  0.0017,  0.0257,  ..., -0.0053,  0.0008,  0.0121],
        ...,
        [ 0.0106,  0.0054, -0.0070,  ...,  0.0352, -0.0007, -0.0030],
        [-0.0030,  0.0133, -0.0021,  ...,  0.0097,  0.0222,  0.0027],
        [-0.0094,  0.0020, -0.0035,  ...,  0.0032, -0.0110,  0.0233]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.5703, -3.8965, -1.8262,  ..., -3.3652,  0.9199, -0.3567]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 01:37:42 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for edison was known for their work as a  inventor
hitler was known for their work as a  dictator
newton was known for their work as a  scientist
dickens was known for their work as a  novelist
plato was known for their work as a  philosopher
raphael was known for their work as a  painter
hegel was known for their work as a  philosopher
columbus was known for their work as a 
2024-07-31 01:37:42 root INFO     [order_1_approx] starting weight calculation for newton was known for their work as a  scientist
columbus was known for their work as a  explorer
edison was known for their work as a  inventor
hitler was known for their work as a  dictator
dickens was known for their work as a  novelist
plato was known for their work as a  philosopher
raphael was known for their work as a  painter
hegel was known for their work as a 
2024-07-31 01:37:42 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 01:39:37 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 3.2446e-01, -1.4587e-02, -1.2207e-04,  ...,  2.1863e-01,
         2.4512e-01, -9.1064e-02], device='cuda:1', dtype=torch.float16,
       grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.3037, -6.4727,  3.8438,  ..., -5.5859, -0.7314, -1.9414],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0316,  0.0078,  0.0094,  ..., -0.0019,  0.0016,  0.0036],
        [-0.0097,  0.0275,  0.0022,  ...,  0.0075, -0.0132, -0.0209],
        [ 0.0041,  0.0054,  0.0342,  ..., -0.0112, -0.0028,  0.0076],
        ...,
        [ 0.0166,  0.0056, -0.0104,  ...,  0.0447,  0.0015,  0.0074],
        [ 0.0034,  0.0049, -0.0072,  ...,  0.0095,  0.0262,  0.0062],
        [-0.0111,  0.0068, -0.0034,  ...,  0.0057, -0.0005,  0.0323]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.1426, -6.1367,  3.5977,  ..., -5.7578, -0.6431, -1.8643]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 01:39:38 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for newton was known for their work as a  scientist
columbus was known for their work as a  explorer
edison was known for their work as a  inventor
hitler was known for their work as a  dictator
dickens was known for their work as a  novelist
plato was known for their work as a  philosopher
raphael was known for their work as a  painter
hegel was known for their work as a 
2024-07-31 01:39:38 root INFO     [order_1_approx] starting weight calculation for raphael was known for their work as a  painter
hitler was known for their work as a  dictator
dickens was known for their work as a  novelist
newton was known for their work as a  scientist
columbus was known for their work as a  explorer
plato was known for their work as a  philosopher
hegel was known for their work as a  philosopher
edison was known for their work as a 
2024-07-31 01:39:38 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 01:41:32 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0696,  0.1938, -0.2427,  ..., -0.6128,  0.2888,  0.2230],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.0215, -3.7500,  1.7754,  ..., -2.1387,  0.3252, -1.6162],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0446, -0.0003, -0.0023,  ...,  0.0015, -0.0090, -0.0007],
        [-0.0039,  0.0410,  0.0020,  ..., -0.0028,  0.0070, -0.0080],
        [ 0.0087,  0.0053,  0.0386,  ...,  0.0049, -0.0035,  0.0131],
        ...,
        [ 0.0093,  0.0020, -0.0118,  ...,  0.0426, -0.0005, -0.0034],
        [-0.0043,  0.0095, -0.0082,  ...,  0.0081,  0.0252, -0.0070],
        [-0.0014,  0.0033,  0.0010,  ..., -0.0064, -0.0019,  0.0346]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.8750, -3.7129,  1.9180,  ..., -2.3418,  0.3096, -1.4072]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 01:41:33 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for raphael was known for their work as a  painter
hitler was known for their work as a  dictator
dickens was known for their work as a  novelist
newton was known for their work as a  scientist
columbus was known for their work as a  explorer
plato was known for their work as a  philosopher
hegel was known for their work as a  philosopher
edison was known for their work as a 
2024-07-31 01:41:33 root INFO     total operator prediction time: 937.6485817432404 seconds
2024-07-31 01:41:33 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on male - female
2024-07-31 01:41:33 root INFO     building operator male - female
2024-07-31 01:41:34 root INFO     [order_1_approx] starting weight calculation for A female rooster is known as a hen
A female batman is known as a batwoman
A female stallion is known as a mare
A female policeman is known as a policewoman
A female bull is known as a cow
A female ram is known as a ewe
A female lion is known as a lioness
A female grandpa is known as a
2024-07-31 01:41:34 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 01:43:32 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4111,  0.1497, -0.1247,  ..., -0.7686, -0.7720, -0.1199],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.0547, -2.8809, -1.6797,  ...,  0.4587, -3.6699, -2.9629],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0716, -0.0067,  0.0204,  ..., -0.0034, -0.0066, -0.0034],
        [-0.0042,  0.0471, -0.0004,  ...,  0.0172,  0.0146, -0.0059],
        [ 0.0060,  0.0061,  0.0546,  ...,  0.0097,  0.0085,  0.0035],
        ...,
        [ 0.0010,  0.0022, -0.0081,  ...,  0.0731, -0.0010, -0.0127],
        [ 0.0074, -0.0159, -0.0126,  ..., -0.0052,  0.0454, -0.0005],
        [-0.0025,  0.0103,  0.0002,  ...,  0.0119,  0.0194,  0.0460]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.8945, -2.8008, -1.7773,  ...,  0.6772, -3.7812, -2.8574]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 01:43:33 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A female rooster is known as a hen
A female batman is known as a batwoman
A female stallion is known as a mare
A female policeman is known as a policewoman
A female bull is known as a cow
A female ram is known as a ewe
A female lion is known as a lioness
A female grandpa is known as a
2024-07-31 01:43:33 root INFO     [order_1_approx] starting weight calculation for A female bull is known as a cow
A female ram is known as a ewe
A female stallion is known as a mare
A female rooster is known as a hen
A female lion is known as a lioness
A female grandpa is known as a grandma
A female batman is known as a batwoman
A female policeman is known as a
2024-07-31 01:43:33 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 01:45:31 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.7412,  0.2661, -0.4541,  ..., -0.7490, -0.6777, -0.1881],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.8320, -6.3516,  3.2109,  ..., -0.1260,  0.2217,  0.2305],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0401, -0.0068,  0.0093,  ...,  0.0020,  0.0001, -0.0078],
        [-0.0048,  0.0298,  0.0081,  ..., -0.0017,  0.0123, -0.0044],
        [ 0.0094,  0.0018,  0.0245,  ..., -0.0003, -0.0024,  0.0054],
        ...,
        [-0.0028,  0.0043,  0.0009,  ...,  0.0282, -0.0067, -0.0035],
        [ 0.0036,  0.0113,  0.0016,  ...,  0.0060,  0.0313, -0.0017],
        [-0.0035, -0.0068, -0.0041,  ..., -0.0081, -0.0078,  0.0269]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.7441, -6.2852,  3.2148,  ..., -0.0867,  0.0516,  0.2998]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 01:45:31 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A female bull is known as a cow
A female ram is known as a ewe
A female stallion is known as a mare
A female rooster is known as a hen
A female lion is known as a lioness
A female grandpa is known as a grandma
A female batman is known as a batwoman
A female policeman is known as a
2024-07-31 01:45:32 root INFO     [order_1_approx] starting weight calculation for A female rooster is known as a hen
A female ram is known as a ewe
A female grandpa is known as a grandma
A female stallion is known as a mare
A female batman is known as a batwoman
A female policeman is known as a policewoman
A female lion is known as a lioness
A female bull is known as a
2024-07-31 01:45:32 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 01:47:25 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4951, -0.7402,  0.4612,  ...,  0.0270, -0.7393,  0.6514],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.8789, -3.6387, -0.5186,  ...,  0.2944, -0.1267,  0.6484],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0701,  0.0200, -0.0148,  ...,  0.0022,  0.0065, -0.0244],
        [-0.0152,  0.0641,  0.0056,  ...,  0.0143,  0.0191, -0.0010],
        [ 0.0077,  0.0056,  0.0581,  ..., -0.0164, -0.0031, -0.0119],
        ...,
        [ 0.0025, -0.0055, -0.0112,  ...,  0.0704,  0.0016, -0.0222],
        [-0.0057, -0.0004,  0.0033,  ...,  0.0051,  0.0690, -0.0044],
        [ 0.0066, -0.0058, -0.0032,  ..., -0.0040,  0.0015,  0.0414]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.1094, -3.4141, -0.3955,  ...,  0.6426, -1.0918,  0.5688]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 01:47:26 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A female rooster is known as a hen
A female ram is known as a ewe
A female grandpa is known as a grandma
A female stallion is known as a mare
A female batman is known as a batwoman
A female policeman is known as a policewoman
A female lion is known as a lioness
A female bull is known as a
2024-07-31 01:47:26 root INFO     [order_1_approx] starting weight calculation for A female bull is known as a cow
A female batman is known as a batwoman
A female lion is known as a lioness
A female stallion is known as a mare
A female rooster is known as a hen
A female policeman is known as a policewoman
A female grandpa is known as a grandma
A female ram is known as a
2024-07-31 01:47:27 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 01:49:23 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.3000, -0.2316, -0.0735,  ..., -0.0351, -0.4351,  0.5020],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.6211, -1.5430,  0.9438,  ...,  2.2305, -2.7305, -1.3975],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0824,  0.0088,  0.0024,  ...,  0.0121, -0.0063,  0.0002],
        [ 0.0193,  0.0240,  0.0030,  ...,  0.0117,  0.0183, -0.0133],
        [ 0.0141,  0.0013,  0.0528,  ..., -0.0174, -0.0131, -0.0161],
        ...,
        [-0.0260,  0.0069, -0.0155,  ...,  0.0604, -0.0028, -0.0284],
        [ 0.0225,  0.0039, -0.0077,  ..., -0.0091,  0.0466, -0.0140],
        [ 0.0036,  0.0078, -0.0016,  ..., -0.0207, -0.0013,  0.0164]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.8789, -1.5400,  0.8574,  ...,  2.5332, -3.2480, -1.5977]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 01:49:24 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A female bull is known as a cow
A female batman is known as a batwoman
A female lion is known as a lioness
A female stallion is known as a mare
A female rooster is known as a hen
A female policeman is known as a policewoman
A female grandpa is known as a grandma
A female ram is known as a
2024-07-31 01:49:24 root INFO     [order_1_approx] starting weight calculation for A female ram is known as a ewe
A female stallion is known as a mare
A female lion is known as a lioness
A female policeman is known as a policewoman
A female batman is known as a batwoman
A female grandpa is known as a grandma
A female bull is known as a cow
A female rooster is known as a
2024-07-31 01:49:24 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 01:51:18 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4851,  0.2930, -0.0042,  ..., -0.1649, -0.6953,  0.5688],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.6421, -3.6191,  0.4121,  ..., -0.0181, -2.2617,  1.8926],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 7.0618e-02,  3.0556e-03,  9.9182e-05,  ..., -1.6079e-03,
         -3.6449e-03, -3.8338e-03],
        [-6.2103e-03,  4.3060e-02,  1.1902e-02,  ..., -3.8185e-03,
          2.0081e-02, -1.4015e-02],
        [ 8.2321e-03, -1.2413e-02,  6.0974e-02,  ...,  1.6251e-03,
         -2.0340e-02, -8.2245e-03],
        ...,
        [-1.2188e-03, -1.9089e-02, -6.7749e-03,  ...,  6.7505e-02,
         -2.3880e-03, -7.2479e-03],
        [ 9.0561e-03,  1.3191e-02,  3.3951e-04,  ...,  1.5007e-02,
          4.9561e-02, -3.1921e-02],
        [ 1.5808e-02, -1.2077e-02, -3.1948e-03,  ..., -1.2192e-02,
          3.9673e-04,  3.9734e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.5923, -3.5371,  0.3643,  ..., -0.1490, -2.5918,  1.4756]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 01:51:19 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A female ram is known as a ewe
A female stallion is known as a mare
A female lion is known as a lioness
A female policeman is known as a policewoman
A female batman is known as a batwoman
A female grandpa is known as a grandma
A female bull is known as a cow
A female rooster is known as a
2024-07-31 01:51:20 root INFO     [order_1_approx] starting weight calculation for A female policeman is known as a policewoman
A female bull is known as a cow
A female rooster is known as a hen
A female grandpa is known as a grandma
A female stallion is known as a mare
A female batman is known as a batwoman
A female ram is known as a ewe
A female lion is known as a
2024-07-31 01:51:20 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 01:53:13 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 1.0781, -0.1433,  0.1466,  ..., -0.2079, -0.6836,  0.0601],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.0469, -5.7461, -0.5317,  ...,  0.5732, -2.6562,  0.0352],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0485,  0.0114, -0.0030,  ...,  0.0087, -0.0159, -0.0045],
        [-0.0081,  0.0227, -0.0127,  ..., -0.0014,  0.0175, -0.0063],
        [ 0.0021,  0.0142,  0.0355,  ..., -0.0237, -0.0048, -0.0089],
        ...,
        [-0.0009,  0.0201, -0.0113,  ...,  0.0349, -0.0038, -0.0039],
        [ 0.0119, -0.0006,  0.0080,  ...,  0.0082,  0.0356, -0.0081],
        [-0.0053,  0.0044, -0.0085,  ..., -0.0027,  0.0008,  0.0209]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.8428, -5.6914, -0.0566,  ...,  0.9648, -2.9375,  0.2018]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 01:53:14 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A female policeman is known as a policewoman
A female bull is known as a cow
A female rooster is known as a hen
A female grandpa is known as a grandma
A female stallion is known as a mare
A female batman is known as a batwoman
A female ram is known as a ewe
A female lion is known as a
2024-07-31 01:53:14 root INFO     [order_1_approx] starting weight calculation for A female grandpa is known as a grandma
A female bull is known as a cow
A female policeman is known as a policewoman
A female lion is known as a lioness
A female stallion is known as a mare
A female rooster is known as a hen
A female ram is known as a ewe
A female batman is known as a
2024-07-31 01:53:14 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 01:55:10 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.5576,  0.5874, -0.7607,  ..., -0.1699, -0.4639, -0.0557],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.7383, -4.8516,  3.4453,  ..., -1.0469, -1.0391, -0.1533],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0631, -0.0263,  0.0252,  ...,  0.0093, -0.0230,  0.0002],
        [-0.0063,  0.0526,  0.0140,  ..., -0.0059,  0.0115,  0.0081],
        [ 0.0042,  0.0111,  0.0510,  ..., -0.0040, -0.0027,  0.0004],
        ...,
        [-0.0057,  0.0220, -0.0145,  ...,  0.0605, -0.0045,  0.0033],
        [-0.0085, -0.0022,  0.0022,  ...,  0.0124,  0.0500,  0.0167],
        [-0.0102, -0.0087, -0.0053,  ...,  0.0020, -0.0042,  0.0334]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.8652, -4.6055,  3.3301,  ..., -1.0039, -0.8926, -0.4048]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 01:55:11 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A female grandpa is known as a grandma
A female bull is known as a cow
A female policeman is known as a policewoman
A female lion is known as a lioness
A female stallion is known as a mare
A female rooster is known as a hen
A female ram is known as a ewe
A female batman is known as a
2024-07-31 01:55:11 root INFO     [order_1_approx] starting weight calculation for A female batman is known as a batwoman
A female grandpa is known as a grandma
A female policeman is known as a policewoman
A female rooster is known as a hen
A female ram is known as a ewe
A female bull is known as a cow
A female lion is known as a lioness
A female stallion is known as a
2024-07-31 01:55:11 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 01:57:09 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4976,  0.2451,  0.4390,  ..., -0.1619, -0.4688,  0.9243],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.7715, -4.1875, -2.7344,  ..., -0.1948, -2.1406,  1.9658],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0620,  0.0106, -0.0016,  ...,  0.0054, -0.0055,  0.0055],
        [-0.0135,  0.0289,  0.0061,  ...,  0.0152,  0.0334, -0.0040],
        [ 0.0096, -0.0013,  0.0457,  ..., -0.0007, -0.0006, -0.0123],
        ...,
        [-0.0019, -0.0081, -0.0154,  ...,  0.0451, -0.0062, -0.0045],
        [-0.0162,  0.0193, -0.0064,  ...,  0.0050,  0.0365,  0.0029],
        [ 0.0073, -0.0157,  0.0091,  ..., -0.0036, -0.0076,  0.0254]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.8906, -3.8770, -2.8809,  ..., -0.1169, -2.2812,  1.8418]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 01:57:09 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A female batman is known as a batwoman
A female grandpa is known as a grandma
A female policeman is known as a policewoman
A female rooster is known as a hen
A female ram is known as a ewe
A female bull is known as a cow
A female lion is known as a lioness
A female stallion is known as a
2024-07-31 01:57:09 root INFO     total operator prediction time: 936.1698317527771 seconds
2024-07-31 01:57:09 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on animal - shelter
2024-07-31 01:57:09 root INFO     building operator animal - shelter
2024-07-31 01:57:10 root INFO     [order_1_approx] starting weight calculation for The place hippopotamus lives in is called river
The place locust lives in is called nest
The place baboon lives in is called grove
The place woodchuck lives in is called hole
The place cattle lives in is called barn
The place bee lives in is called hive
The place fox lives in is called den
The place mole lives in is called
2024-07-31 01:57:10 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 01:58:59 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4556, -0.2646,  0.3508,  ..., -0.3599, -0.5576, -0.0485],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.3359, -0.5698,  2.2969,  ..., -1.5566,  0.3970,  0.8848],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0770, -0.0099, -0.0020,  ...,  0.0325,  0.0173,  0.0033],
        [ 0.0105,  0.0443,  0.0076,  ...,  0.0104,  0.0167, -0.0052],
        [ 0.0182,  0.0195,  0.0569,  ...,  0.0186, -0.0070,  0.0053],
        ...,
        [ 0.0090,  0.0077, -0.0044,  ...,  0.0876,  0.0112, -0.0138],
        [ 0.0020,  0.0043,  0.0016,  ...,  0.0201,  0.0461, -0.0028],
        [ 0.0080,  0.0081, -0.0054,  ..., -0.0149, -0.0174,  0.0753]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.9561, -0.8359,  1.9365,  ..., -1.4736,  0.2839,  0.5156]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 01:59:00 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The place hippopotamus lives in is called river
The place locust lives in is called nest
The place baboon lives in is called grove
The place woodchuck lives in is called hole
The place cattle lives in is called barn
The place bee lives in is called hive
The place fox lives in is called den
The place mole lives in is called
2024-07-31 01:59:00 root INFO     [order_1_approx] starting weight calculation for The place mole lives in is called hole
The place hippopotamus lives in is called river
The place woodchuck lives in is called hole
The place bee lives in is called hive
The place fox lives in is called den
The place baboon lives in is called grove
The place cattle lives in is called barn
The place locust lives in is called
2024-07-31 01:59:00 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 02:00:53 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2542, -0.9238, -0.0380,  ...,  0.4253, -0.0764, -0.3936],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.1523, -4.2891,  1.4824,  ..., -0.5078,  0.3123, -3.4336],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 6.4941e-02, -2.7771e-02,  3.1128e-03,  ...,  1.9043e-02,
          1.6327e-02,  5.8098e-03],
        [ 7.9422e-03,  7.0923e-02,  6.4850e-04,  ...,  1.4038e-02,
         -6.3553e-03, -2.1454e-02],
        [ 5.6305e-03,  2.3514e-02,  7.7576e-02,  ...,  2.1774e-02,
         -3.4119e-02,  8.0261e-03],
        ...,
        [ 2.0142e-02, -1.5762e-02,  4.8828e-04,  ...,  8.8806e-02,
         -1.0918e-02,  2.6627e-03],
        [-1.6327e-03,  1.1902e-03, -6.6757e-05,  ...,  2.7191e-02,
          4.5135e-02, -1.4374e-02],
        [-9.2316e-03,  9.1095e-03,  1.0849e-02,  ..., -7.0000e-03,
         -1.9806e-02,  7.0862e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.9512, -4.4414,  1.3301,  ..., -1.0273,  0.0554, -3.9277]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 02:00:54 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The place mole lives in is called hole
The place hippopotamus lives in is called river
The place woodchuck lives in is called hole
The place bee lives in is called hive
The place fox lives in is called den
The place baboon lives in is called grove
The place cattle lives in is called barn
The place locust lives in is called
2024-07-31 02:00:54 root INFO     [order_1_approx] starting weight calculation for The place hippopotamus lives in is called river
The place mole lives in is called hole
The place bee lives in is called hive
The place woodchuck lives in is called hole
The place locust lives in is called nest
The place fox lives in is called den
The place baboon lives in is called grove
The place cattle lives in is called
2024-07-31 02:00:54 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 02:02:47 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0528, -0.5757,  0.3533,  ...,  0.3760,  0.2017,  0.1007],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.7344, -4.2891,  1.6582,  ..., -3.2656,  1.9912, -2.1914],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0404, -0.0156,  0.0012,  ...,  0.0096, -0.0004, -0.0110],
        [ 0.0038,  0.0413,  0.0155,  ..., -0.0052,  0.0032, -0.0068],
        [-0.0007, -0.0088,  0.0295,  ...,  0.0104,  0.0006,  0.0010],
        ...,
        [-0.0028, -0.0131, -0.0012,  ...,  0.0627,  0.0080,  0.0056],
        [ 0.0160,  0.0132, -0.0075,  ..., -0.0067,  0.0341, -0.0255],
        [ 0.0021, -0.0173,  0.0007,  ..., -0.0095, -0.0097,  0.0407]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.9551, -4.2734,  1.7969,  ..., -3.2832,  1.6562, -2.0332]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 02:02:48 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The place hippopotamus lives in is called river
The place mole lives in is called hole
The place bee lives in is called hive
The place woodchuck lives in is called hole
The place locust lives in is called nest
The place fox lives in is called den
The place baboon lives in is called grove
The place cattle lives in is called
2024-07-31 02:02:48 root INFO     [order_1_approx] starting weight calculation for The place hippopotamus lives in is called river
The place mole lives in is called hole
The place cattle lives in is called barn
The place fox lives in is called den
The place locust lives in is called nest
The place woodchuck lives in is called hole
The place bee lives in is called hive
The place baboon lives in is called
2024-07-31 02:02:48 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 02:04:45 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.7271, -0.7217,  0.6890,  ...,  0.3271, -1.2686,  0.2935],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.8008, -3.7930, -0.1260,  ..., -0.3982, -1.6113, -0.0693],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 3.2318e-02, -9.5749e-04, -2.2247e-02,  ...,  1.0361e-02,
          1.4946e-02, -8.4763e-03],
        [-2.1851e-02,  3.6407e-02, -4.1084e-03,  ...,  1.1826e-02,
          6.5155e-03, -2.4323e-02],
        [-2.3880e-03,  1.7319e-03,  4.2725e-02,  ...,  1.7822e-02,
         -6.7635e-03,  3.4561e-03],
        ...,
        [ 2.4673e-02,  2.6207e-03,  6.5079e-03,  ...,  6.2500e-02,
         -9.6893e-03,  1.5717e-02],
        [ 8.0872e-03,  7.7248e-05,  6.9809e-03,  ...,  1.4221e-02,
          3.3508e-02, -1.5984e-03],
        [-1.0002e-02,  1.8188e-02, -4.1199e-03,  ..., -3.1738e-02,
          9.8572e-03,  4.3213e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 5.0664, -3.7559, -0.2852,  ..., -0.3447, -1.7217, -0.0977]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 02:04:46 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The place hippopotamus lives in is called river
The place mole lives in is called hole
The place cattle lives in is called barn
The place fox lives in is called den
The place locust lives in is called nest
The place woodchuck lives in is called hole
The place bee lives in is called hive
The place baboon lives in is called
2024-07-31 02:04:47 root INFO     [order_1_approx] starting weight calculation for The place hippopotamus lives in is called river
The place locust lives in is called nest
The place cattle lives in is called barn
The place mole lives in is called hole
The place baboon lives in is called grove
The place fox lives in is called den
The place bee lives in is called hive
The place woodchuck lives in is called
2024-07-31 02:04:47 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 02:06:46 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1267, -0.4116,  0.3218,  ..., -0.1925, -0.9546, -0.1733],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.7246, -3.8008,  1.9902,  ..., -2.7246, -0.8799,  0.0586],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0671, -0.0036, -0.0175,  ...,  0.0297,  0.0132, -0.0122],
        [ 0.0064,  0.0413, -0.0002,  ...,  0.0303,  0.0297, -0.0229],
        [ 0.0127,  0.0327,  0.0427,  ...,  0.0233, -0.0265,  0.0007],
        ...,
        [ 0.0022,  0.0133, -0.0028,  ...,  0.0749,  0.0006, -0.0147],
        [-0.0059,  0.0187, -0.0047,  ...,  0.0087,  0.0403,  0.0076],
        [ 0.0122,  0.0008, -0.0187,  ..., -0.0110, -0.0005,  0.0576]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.7031, -3.7227,  1.8779,  ..., -2.7461, -0.9238, -0.3640]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 02:06:48 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The place hippopotamus lives in is called river
The place locust lives in is called nest
The place cattle lives in is called barn
The place mole lives in is called hole
The place baboon lives in is called grove
The place fox lives in is called den
The place bee lives in is called hive
The place woodchuck lives in is called
2024-07-31 02:06:48 root INFO     [order_1_approx] starting weight calculation for The place woodchuck lives in is called hole
The place fox lives in is called den
The place cattle lives in is called barn
The place mole lives in is called hole
The place locust lives in is called nest
The place hippopotamus lives in is called river
The place baboon lives in is called grove
The place bee lives in is called
2024-07-31 02:06:48 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 02:08:46 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2773, -0.4878,  0.2378,  ...,  0.0646,  0.2754, -0.2642],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.9219, -5.8164,  1.8398,  ..., -3.3789,  0.5078, -0.9277],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0320,  0.0018,  0.0008,  ...,  0.0132,  0.0039,  0.0092],
        [ 0.0006,  0.0323,  0.0113,  ...,  0.0031, -0.0083, -0.0083],
        [ 0.0164,  0.0401,  0.0385,  ...,  0.0300, -0.0264,  0.0145],
        ...,
        [-0.0018, -0.0057, -0.0058,  ...,  0.0432,  0.0066, -0.0001],
        [ 0.0003,  0.0082,  0.0086,  ...,  0.0100,  0.0176, -0.0078],
        [-0.0190,  0.0045, -0.0108,  ..., -0.0095, -0.0140,  0.0367]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.0840, -5.9961,  1.5967,  ..., -3.4141,  0.4761, -0.8916]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 02:08:47 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The place woodchuck lives in is called hole
The place fox lives in is called den
The place cattle lives in is called barn
The place mole lives in is called hole
The place locust lives in is called nest
The place hippopotamus lives in is called river
The place baboon lives in is called grove
The place bee lives in is called
2024-07-31 02:08:47 root INFO     [order_1_approx] starting weight calculation for The place woodchuck lives in is called hole
The place fox lives in is called den
The place mole lives in is called hole
The place bee lives in is called hive
The place locust lives in is called nest
The place cattle lives in is called barn
The place baboon lives in is called grove
The place hippopotamus lives in is called
2024-07-31 02:08:47 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 02:10:41 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3735, -0.7412,  0.9307,  ...,  0.0658, -0.2856,  0.0252],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.2070, -3.7891, -0.4365,  ..., -2.2949, -0.2363,  0.6768],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 1.0468e-02,  2.0599e-03, -3.4828e-03,  ...,  1.0910e-02,
         -6.6090e-04, -2.2774e-03],
        [-2.2697e-03,  1.0239e-02, -3.2425e-04,  ..., -4.5433e-03,
          1.2875e-03, -2.2907e-03],
        [ 4.9829e-04,  3.4714e-03,  9.3842e-03,  ...,  2.0943e-03,
         -4.2343e-04,  2.9488e-03],
        ...,
        [ 1.3752e-03, -2.1496e-03,  2.3155e-03,  ...,  6.5384e-03,
          3.5152e-03,  1.3227e-03],
        [ 4.4632e-03,  2.9583e-03,  4.4441e-03,  ...,  9.0361e-04,
          1.1070e-02, -4.2191e-03],
        [-1.6603e-03, -2.3918e-03, -1.8387e-03,  ..., -3.2663e-05,
          3.3264e-03,  8.9111e-03]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.1758, -3.8066, -0.4338,  ..., -2.2617, -0.3149,  0.6289]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 02:10:42 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The place woodchuck lives in is called hole
The place fox lives in is called den
The place mole lives in is called hole
The place bee lives in is called hive
The place locust lives in is called nest
The place cattle lives in is called barn
The place baboon lives in is called grove
The place hippopotamus lives in is called
2024-07-31 02:10:42 root INFO     [order_1_approx] starting weight calculation for The place hippopotamus lives in is called river
The place woodchuck lives in is called hole
The place baboon lives in is called grove
The place cattle lives in is called barn
The place locust lives in is called nest
The place mole lives in is called hole
The place bee lives in is called hive
The place fox lives in is called
2024-07-31 02:10:42 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 02:12:42 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1447,  0.1205,  0.4976,  ...,  0.1646,  0.0137, -0.0515],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.8242, -6.9453, -0.3633,  ..., -0.6377, -1.4775,  2.4258],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 4.1382e-02,  1.2573e-02,  3.1853e-03,  ...,  1.0475e-02,
          6.0844e-03,  1.8265e-02],
        [-1.5320e-02,  4.3488e-02,  1.1314e-02,  ...,  6.6185e-04,
          6.0959e-03, -2.1179e-02],
        [ 1.2154e-02,  8.9417e-03,  5.9814e-02,  ...,  5.6207e-05,
         -1.2520e-02, -4.0398e-03],
        ...,
        [ 5.7983e-03, -1.7609e-02,  9.1934e-03,  ...,  5.0934e-02,
          1.3718e-02,  5.1594e-04],
        [ 6.8359e-03,  2.4796e-05,  1.1871e-02,  ...,  9.8724e-03,
          2.8046e-02, -8.8806e-03],
        [ 7.6828e-03,  3.4943e-03, -1.7883e-02,  ..., -8.7433e-03,
         -9.5444e-03,  4.0649e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.8516, -6.5742, -0.2059,  ..., -1.0439, -1.1650,  2.3047]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 02:12:43 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The place hippopotamus lives in is called river
The place woodchuck lives in is called hole
The place baboon lives in is called grove
The place cattle lives in is called barn
The place locust lives in is called nest
The place mole lives in is called hole
The place bee lives in is called hive
The place fox lives in is called
2024-07-31 02:12:43 root INFO     total operator prediction time: 933.1756663322449 seconds
2024-07-31 02:12:43 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on country - language
2024-07-31 02:12:43 root INFO     building operator country - language
2024-07-31 02:12:43 root INFO     [order_1_approx] starting weight calculation for The country of moldova primarily speaks the language of moldovan
The country of norway primarily speaks the language of norwegian
The country of guam primarily speaks the language of english
The country of kazakhstan primarily speaks the language of kazak
The country of barbados primarily speaks the language of english
The country of mexico primarily speaks the language of spanish
The country of fiji primarily speaks the language of english
The country of australia primarily speaks the language of
2024-07-31 02:12:43 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 02:14:41 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3862,  0.0333,  0.0775,  ...,  0.3845, -0.0276,  0.2170],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.4355, -2.1602,  2.3633,  ..., -0.0151, -1.5820, -1.9199],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0156, -0.0017,  0.0038,  ...,  0.0026, -0.0030, -0.0024],
        [-0.0032,  0.0105,  0.0034,  ...,  0.0014, -0.0014, -0.0014],
        [-0.0015,  0.0045,  0.0130,  ...,  0.0091,  0.0014, -0.0062],
        ...,
        [ 0.0005,  0.0028, -0.0019,  ...,  0.0107, -0.0016, -0.0062],
        [-0.0033, -0.0001, -0.0060,  ..., -0.0046,  0.0136, -0.0022],
        [-0.0028, -0.0025, -0.0031,  ..., -0.0007, -0.0003,  0.0116]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.4199, -2.1172,  2.2832,  ..., -0.0039, -1.5586, -1.9043]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 02:14:42 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country of moldova primarily speaks the language of moldovan
The country of norway primarily speaks the language of norwegian
The country of guam primarily speaks the language of english
The country of kazakhstan primarily speaks the language of kazak
The country of barbados primarily speaks the language of english
The country of mexico primarily speaks the language of spanish
The country of fiji primarily speaks the language of english
The country of australia primarily speaks the language of
2024-07-31 02:14:42 root INFO     [order_1_approx] starting weight calculation for The country of guam primarily speaks the language of english
The country of moldova primarily speaks the language of moldovan
The country of kazakhstan primarily speaks the language of kazak
The country of norway primarily speaks the language of norwegian
The country of mexico primarily speaks the language of spanish
The country of barbados primarily speaks the language of english
The country of australia primarily speaks the language of english
The country of fiji primarily speaks the language of
2024-07-31 02:14:42 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 02:16:41 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.9673, -0.2076, -0.3164,  ...,  0.1198,  0.0021,  0.0565],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.0688,  0.0806,  3.6113,  ...,  0.8677, -3.5527, -0.5166],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0373,  0.0077, -0.0030,  ...,  0.0057,  0.0006, -0.0036],
        [ 0.0077,  0.0437,  0.0092,  ..., -0.0089, -0.0093, -0.0184],
        [ 0.0020,  0.0065,  0.0482,  ...,  0.0180,  0.0059,  0.0075],
        ...,
        [-0.0170,  0.0012, -0.0042,  ...,  0.0499,  0.0176,  0.0095],
        [ 0.0132, -0.0114,  0.0010,  ..., -0.0033,  0.0602,  0.0004],
        [-0.0064,  0.0084,  0.0093,  ...,  0.0133,  0.0028,  0.0518]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.0813e-02, -1.4648e-03,  3.0938e+00,  ...,  7.3291e-01,
         -3.3457e+00, -3.8818e-01]], device='cuda:1', dtype=torch.float16,
       grad_fn=<SubBackward0>) 

                    
2024-07-31 02:16:42 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country of guam primarily speaks the language of english
The country of moldova primarily speaks the language of moldovan
The country of kazakhstan primarily speaks the language of kazak
The country of norway primarily speaks the language of norwegian
The country of mexico primarily speaks the language of spanish
The country of barbados primarily speaks the language of english
The country of australia primarily speaks the language of english
The country of fiji primarily speaks the language of
2024-07-31 02:16:42 root INFO     [order_1_approx] starting weight calculation for The country of norway primarily speaks the language of norwegian
The country of australia primarily speaks the language of english
The country of barbados primarily speaks the language of english
The country of moldova primarily speaks the language of moldovan
The country of kazakhstan primarily speaks the language of kazak
The country of guam primarily speaks the language of english
The country of fiji primarily speaks the language of english
The country of mexico primarily speaks the language of
2024-07-31 02:16:42 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 02:18:40 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2014,  0.4458,  0.2971,  ...,  0.4260, -0.1045,  0.0515],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.9170, -2.8027,  1.2461,  ...,  0.5586, -0.3496, -3.4219],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0190, -0.0029,  0.0019,  ..., -0.0057,  0.0007, -0.0035],
        [ 0.0012,  0.0211,  0.0069,  ..., -0.0033, -0.0051, -0.0062],
        [ 0.0051,  0.0023,  0.0148,  ...,  0.0107,  0.0068, -0.0053],
        ...,
        [ 0.0010, -0.0068, -0.0018,  ...,  0.0142,  0.0006, -0.0022],
        [-0.0054, -0.0070, -0.0036,  ..., -0.0014,  0.0172,  0.0008],
        [-0.0129, -0.0042,  0.0076,  ..., -0.0029,  0.0013,  0.0170]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.9004, -2.6484,  1.1123,  ...,  0.3101, -0.4680, -3.1836]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 02:18:41 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country of norway primarily speaks the language of norwegian
The country of australia primarily speaks the language of english
The country of barbados primarily speaks the language of english
The country of moldova primarily speaks the language of moldovan
The country of kazakhstan primarily speaks the language of kazak
The country of guam primarily speaks the language of english
The country of fiji primarily speaks the language of english
The country of mexico primarily speaks the language of
2024-07-31 02:18:41 root INFO     [order_1_approx] starting weight calculation for The country of mexico primarily speaks the language of spanish
The country of moldova primarily speaks the language of moldovan
The country of guam primarily speaks the language of english
The country of fiji primarily speaks the language of english
The country of norway primarily speaks the language of norwegian
The country of kazakhstan primarily speaks the language of kazak
The country of australia primarily speaks the language of english
The country of barbados primarily speaks the language of
2024-07-31 02:18:41 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 02:20:39 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2456,  0.4351, -0.1334,  ...,  0.5718, -0.0637,  0.1837],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.4668, -1.2617,  1.4023,  ...,  0.6763,  0.6221, -3.5273],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0280,  0.0011,  0.0008,  ...,  0.0101, -0.0028, -0.0039],
        [ 0.0003,  0.0195,  0.0047,  ..., -0.0029, -0.0017, -0.0091],
        [-0.0022, -0.0055,  0.0229,  ...,  0.0046,  0.0034,  0.0001],
        ...,
        [-0.0048,  0.0023, -0.0053,  ...,  0.0307,  0.0058, -0.0012],
        [-0.0004, -0.0081, -0.0022,  ...,  0.0072,  0.0201, -0.0009],
        [-0.0072, -0.0034, -0.0004,  ..., -0.0042,  0.0042,  0.0237]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.3887, -1.2168,  1.2520,  ...,  0.6074,  0.5903, -3.4844]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 02:20:40 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country of mexico primarily speaks the language of spanish
The country of moldova primarily speaks the language of moldovan
The country of guam primarily speaks the language of english
The country of fiji primarily speaks the language of english
The country of norway primarily speaks the language of norwegian
The country of kazakhstan primarily speaks the language of kazak
The country of australia primarily speaks the language of english
The country of barbados primarily speaks the language of
2024-07-31 02:20:40 root INFO     [order_1_approx] starting weight calculation for The country of moldova primarily speaks the language of moldovan
The country of australia primarily speaks the language of english
The country of barbados primarily speaks the language of english
The country of mexico primarily speaks the language of spanish
The country of guam primarily speaks the language of english
The country of norway primarily speaks the language of norwegian
The country of fiji primarily speaks the language of english
The country of kazakhstan primarily speaks the language of
2024-07-31 02:20:41 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 02:22:38 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2019, -0.2874,  0.0328,  ...,  0.1455, -0.5371,  0.2583],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.4766, -3.8730, -0.4771,  ..., -2.0879, -2.3496, -1.4727],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 4.4289e-03,  6.6161e-06, -4.1485e-04,  ...,  5.6915e-03,
          2.1791e-04,  1.0662e-03],
        [-7.8106e-04,  8.4763e-03, -1.0338e-03,  ..., -6.5517e-04,
         -1.8711e-03, -4.4289e-03],
        [ 1.5020e-04,  1.7061e-03,  6.3782e-03,  ...,  5.3101e-03,
          7.3719e-04, -2.5272e-04],
        ...,
        [-2.0714e-03,  2.0370e-03, -3.4714e-03,  ...,  1.4374e-02,
          2.6875e-03,  6.1035e-05],
        [-8.9931e-04,  8.9765e-05,  1.6098e-03,  ..., -2.1324e-03,
          9.0408e-03, -2.3532e-04],
        [-1.3599e-03, -2.1534e-03, -2.2507e-03,  ...,  5.3291e-03,
         -4.1747e-04,  1.0513e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.4102, -3.9023, -0.4446,  ..., -2.0293, -2.3535, -1.4453]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 02:22:39 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country of moldova primarily speaks the language of moldovan
The country of australia primarily speaks the language of english
The country of barbados primarily speaks the language of english
The country of mexico primarily speaks the language of spanish
The country of guam primarily speaks the language of english
The country of norway primarily speaks the language of norwegian
The country of fiji primarily speaks the language of english
The country of kazakhstan primarily speaks the language of
2024-07-31 02:22:40 root INFO     [order_1_approx] starting weight calculation for The country of barbados primarily speaks the language of english
The country of kazakhstan primarily speaks the language of kazak
The country of norway primarily speaks the language of norwegian
The country of moldova primarily speaks the language of moldovan
The country of mexico primarily speaks the language of spanish
The country of australia primarily speaks the language of english
The country of fiji primarily speaks the language of english
The country of guam primarily speaks the language of
2024-07-31 02:22:40 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 02:24:35 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1016,  0.0723, -0.1841,  ...,  0.5537, -0.7134,  0.2705],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.8232,  1.1357,  2.6250,  ...,  0.0552, -1.5781, -2.6543],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0237, -0.0003, -0.0002,  ..., -0.0094, -0.0052, -0.0071],
        [ 0.0205,  0.0486,  0.0030,  ...,  0.0121,  0.0075, -0.0039],
        [ 0.0006, -0.0152,  0.0309,  ...,  0.0104,  0.0042, -0.0134],
        ...,
        [ 0.0053,  0.0111, -0.0094,  ...,  0.0601,  0.0014, -0.0092],
        [-0.0033, -0.0056, -0.0118,  ..., -0.0033,  0.0386,  0.0020],
        [-0.0028, -0.0027, -0.0038,  ...,  0.0254,  0.0042,  0.0611]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.8291,  1.3594,  2.2910,  ..., -0.0049, -1.5869, -2.4082]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 02:24:36 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country of barbados primarily speaks the language of english
The country of kazakhstan primarily speaks the language of kazak
The country of norway primarily speaks the language of norwegian
The country of moldova primarily speaks the language of moldovan
The country of mexico primarily speaks the language of spanish
The country of australia primarily speaks the language of english
The country of fiji primarily speaks the language of english
The country of guam primarily speaks the language of
2024-07-31 02:24:37 root INFO     [order_1_approx] starting weight calculation for The country of norway primarily speaks the language of norwegian
The country of australia primarily speaks the language of english
The country of fiji primarily speaks the language of english
The country of mexico primarily speaks the language of spanish
The country of barbados primarily speaks the language of english
The country of guam primarily speaks the language of english
The country of kazakhstan primarily speaks the language of kazak
The country of moldova primarily speaks the language of
2024-07-31 02:24:37 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 02:26:35 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.5811, -0.3105, -0.2671,  ...,  0.2683, -0.2629, -0.0673],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.9219, -5.2305, -0.5234,  ..., -4.6172, -0.0664, -1.4668],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0133,  0.0014,  0.0007,  ...,  0.0083, -0.0070, -0.0005],
        [-0.0021,  0.0244,  0.0003,  ...,  0.0060, -0.0005, -0.0066],
        [ 0.0025, -0.0049,  0.0110,  ...,  0.0081, -0.0037, -0.0067],
        ...,
        [-0.0027,  0.0047, -0.0160,  ...,  0.0193,  0.0081,  0.0087],
        [-0.0042, -0.0094,  0.0043,  ..., -0.0009,  0.0108, -0.0087],
        [-0.0067, -0.0034, -0.0062,  ...,  0.0042,  0.0002,  0.0151]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.9043, -5.2344, -0.5078,  ..., -4.4961, -0.1092, -1.5088]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 02:26:36 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country of norway primarily speaks the language of norwegian
The country of australia primarily speaks the language of english
The country of fiji primarily speaks the language of english
The country of mexico primarily speaks the language of spanish
The country of barbados primarily speaks the language of english
The country of guam primarily speaks the language of english
The country of kazakhstan primarily speaks the language of kazak
The country of moldova primarily speaks the language of
2024-07-31 02:26:37 root INFO     [order_1_approx] starting weight calculation for The country of barbados primarily speaks the language of english
The country of mexico primarily speaks the language of spanish
The country of moldova primarily speaks the language of moldovan
The country of fiji primarily speaks the language of english
The country of australia primarily speaks the language of english
The country of kazakhstan primarily speaks the language of kazak
The country of guam primarily speaks the language of english
The country of norway primarily speaks the language of
2024-07-31 02:26:37 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 02:28:34 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0237,  0.1530, -0.4897,  ...,  0.0215,  0.2947,  0.1541],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.6377, -2.2930, -1.5215,  ..., -2.0293,  0.0537, -1.7812],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0243, -0.0002,  0.0030,  ..., -0.0022,  0.0084, -0.0175],
        [ 0.0005,  0.0167,  0.0006,  ...,  0.0021,  0.0117, -0.0068],
        [-0.0005,  0.0032,  0.0128,  ..., -0.0003,  0.0022, -0.0044],
        ...,
        [-0.0035,  0.0017, -0.0052,  ...,  0.0278,  0.0006,  0.0019],
        [ 0.0002,  0.0020, -0.0102,  ..., -0.0004,  0.0315,  0.0038],
        [-0.0089, -0.0113,  0.0012,  ...,  0.0068,  0.0006,  0.0220]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.4580, -2.3398, -1.3613,  ..., -2.3203,  0.0360, -1.4814]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 02:28:35 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country of barbados primarily speaks the language of english
The country of mexico primarily speaks the language of spanish
The country of moldova primarily speaks the language of moldovan
The country of fiji primarily speaks the language of english
The country of australia primarily speaks the language of english
The country of kazakhstan primarily speaks the language of kazak
The country of guam primarily speaks the language of english
The country of norway primarily speaks the language of
2024-07-31 02:28:35 root INFO     total operator prediction time: 952.7794816493988 seconds
2024-07-31 02:28:35 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on name - nationality
2024-07-31 02:28:35 root INFO     building operator name - nationality
2024-07-31 02:28:36 root INFO     [order_1_approx] starting weight calculation for pascal was french
spinoza was dutch
fermi was italian
rousseau was french
newton was english
copernicus was polish
dostoyevsky was russian
napoleon was
2024-07-31 02:28:36 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 02:30:36 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4583,  0.3560, -0.4175,  ...,  0.2991, -0.1340,  0.2026],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.7910, -4.3594,  0.1514,  ..., -0.7158, -0.2334, -0.3740],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0701, -0.0023, -0.0084,  ..., -0.0051, -0.0058, -0.0065],
        [-0.0017,  0.0699,  0.0202,  ..., -0.0045, -0.0077, -0.0206],
        [ 0.0177, -0.0158,  0.0655,  ..., -0.0002, -0.0060,  0.0195],
        ...,
        [ 0.0195,  0.0062, -0.0026,  ...,  0.0815, -0.0127,  0.0062],
        [ 0.0038,  0.0027,  0.0008,  ...,  0.0028,  0.0586, -0.0013],
        [-0.0155,  0.0081, -0.0168,  ...,  0.0072,  0.0001,  0.0578]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.7832, -4.4453, -0.1660,  ..., -0.8291, -0.2866, -0.4392]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 02:30:37 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for pascal was french
spinoza was dutch
fermi was italian
rousseau was french
newton was english
copernicus was polish
dostoyevsky was russian
napoleon was
2024-07-31 02:30:37 root INFO     [order_1_approx] starting weight calculation for pascal was french
copernicus was polish
newton was english
rousseau was french
napoleon was french
dostoyevsky was russian
spinoza was dutch
fermi was
2024-07-31 02:30:37 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 02:32:37 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4014,  0.1037, -0.4058,  ...,  0.2693, -0.1473,  0.8926],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.7871, -3.4570,  0.1343,  ..., -1.3330, -1.1992,  0.1401],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0717,  0.0099, -0.0147,  ..., -0.0273, -0.0256, -0.0239],
        [ 0.0544,  0.0819,  0.0215,  ...,  0.0327,  0.0447, -0.0021],
        [-0.0115, -0.0013,  0.0789,  ...,  0.0075, -0.0026,  0.0048],
        ...,
        [ 0.0128,  0.0176, -0.0166,  ...,  0.0994,  0.0024,  0.0013],
        [ 0.0167,  0.0091, -0.0059,  ..., -0.0026,  0.0695, -0.0121],
        [ 0.0095, -0.0024, -0.0043,  ..., -0.0007,  0.0070,  0.1210]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.3223, -3.8340,  0.2134,  ..., -1.6504, -1.0000, -0.1445]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 02:32:38 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for pascal was french
copernicus was polish
newton was english
rousseau was french
napoleon was french
dostoyevsky was russian
spinoza was dutch
fermi was
2024-07-31 02:32:38 root INFO     [order_1_approx] starting weight calculation for spinoza was dutch
copernicus was polish
pascal was french
rousseau was french
fermi was italian
napoleon was french
newton was english
dostoyevsky was
2024-07-31 02:32:39 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 02:34:38 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3450, -0.4026, -0.3040,  ..., -0.0709, -0.4907,  0.1189],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.2871, -3.2812,  1.1230,  ..., -5.9922, -0.0791, -1.2168],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0684, -0.0050,  0.0059,  ..., -0.0197,  0.0079, -0.0111],
        [ 0.0056,  0.0675,  0.0081,  ...,  0.0175,  0.0014, -0.0077],
        [ 0.0067, -0.0128,  0.0568,  ...,  0.0036, -0.0084,  0.0092],
        ...,
        [ 0.0111,  0.0050, -0.0086,  ...,  0.0721,  0.0050, -0.0088],
        [ 0.0077,  0.0068, -0.0073,  ...,  0.0032,  0.0493,  0.0058],
        [-0.0097,  0.0115, -0.0102,  ...,  0.0189, -0.0097,  0.0696]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.7168, -3.2344,  1.0771,  ..., -5.8516, -0.0864, -1.2725]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 02:34:39 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for spinoza was dutch
copernicus was polish
pascal was french
rousseau was french
fermi was italian
napoleon was french
newton was english
dostoyevsky was
2024-07-31 02:34:39 root INFO     [order_1_approx] starting weight calculation for spinoza was dutch
fermi was italian
rousseau was french
pascal was french
newton was english
dostoyevsky was russian
napoleon was french
copernicus was
2024-07-31 02:34:39 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 02:36:40 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2620, -0.0581, -0.4824,  ...,  0.0140, -0.1483,  0.3926],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.3340, -5.7695,  0.5332,  ..., -4.9570, -1.9023, -0.5068],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.1017,  0.0037,  0.0071,  ..., -0.0169,  0.0164, -0.0030],
        [ 0.0099,  0.0815, -0.0032,  ..., -0.0001, -0.0038, -0.0166],
        [ 0.0020, -0.0173,  0.0762,  ...,  0.0198, -0.0049,  0.0112],
        ...,
        [ 0.0078,  0.0088, -0.0219,  ...,  0.0858,  0.0014, -0.0057],
        [ 0.0159,  0.0102,  0.0014,  ..., -0.0006,  0.0612, -0.0036],
        [-0.0089,  0.0102, -0.0202,  ...,  0.0215, -0.0078,  0.0953]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.2246, -5.6992,  0.2993,  ..., -4.6523, -1.6670, -0.5952]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 02:36:41 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for spinoza was dutch
fermi was italian
rousseau was french
pascal was french
newton was english
dostoyevsky was russian
napoleon was french
copernicus was
2024-07-31 02:36:41 root INFO     [order_1_approx] starting weight calculation for rousseau was french
dostoyevsky was russian
copernicus was polish
fermi was italian
newton was english
napoleon was french
spinoza was dutch
pascal was
2024-07-31 02:36:41 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 02:38:40 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2961, -0.4026,  0.1156,  ..., -0.1720,  0.1065,  0.7783],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.5508, -0.1548,  2.7637,  ..., -3.8789, -1.2998,  2.7109],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.1010, -0.0324,  0.0074,  ..., -0.0112, -0.0135, -0.0079],
        [ 0.0131,  0.1165,  0.0069,  ...,  0.0136,  0.0046, -0.0161],
        [ 0.0037, -0.0308,  0.0927,  ...,  0.0048, -0.0021,  0.0088],
        ...,
        [ 0.0217,  0.0247, -0.0223,  ...,  0.0937,  0.0199, -0.0126],
        [ 0.0089,  0.0023,  0.0152,  ...,  0.0081,  0.0609, -0.0018],
        [ 0.0006,  0.0157, -0.0140,  ...,  0.0211, -0.0147,  0.1039]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.4375, -0.9019,  2.3848,  ..., -3.7129, -0.7993,  1.8418]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 02:38:41 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for rousseau was french
dostoyevsky was russian
copernicus was polish
fermi was italian
newton was english
napoleon was french
spinoza was dutch
pascal was
2024-07-31 02:38:41 root INFO     [order_1_approx] starting weight calculation for copernicus was polish
dostoyevsky was russian
napoleon was french
pascal was french
rousseau was french
fermi was italian
newton was english
spinoza was
2024-07-31 02:38:41 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 02:40:32 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1975, -0.1808, -0.0453,  ..., -0.1068, -0.1643,  0.1470],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.5254, -0.6035,  3.1289,  ..., -6.0938, -0.5684, -2.3828],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.1027,  0.0069, -0.0026,  ..., -0.0054,  0.0185,  0.0157],
        [ 0.0074,  0.0515,  0.0034,  ..., -0.0111, -0.0045, -0.0263],
        [-0.0018, -0.0119,  0.0722,  ...,  0.0210,  0.0050,  0.0195],
        ...,
        [ 0.0076,  0.0215,  0.0009,  ...,  0.0642, -0.0043, -0.0121],
        [-0.0031,  0.0119, -0.0030,  ...,  0.0148,  0.0522, -0.0017],
        [-0.0015,  0.0169, -0.0176,  ...,  0.0109, -0.0149,  0.0765]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.4453, -0.5933,  2.5410,  ..., -5.6250, -0.4719, -2.3594]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 02:40:33 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for copernicus was polish
dostoyevsky was russian
napoleon was french
pascal was french
rousseau was french
fermi was italian
newton was english
spinoza was
2024-07-31 02:40:34 root INFO     [order_1_approx] starting weight calculation for newton was english
fermi was italian
spinoza was dutch
copernicus was polish
pascal was french
dostoyevsky was russian
napoleon was french
rousseau was
2024-07-31 02:40:34 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 02:42:31 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3340,  0.0865, -0.4250,  ...,  0.0621, -0.7979,  0.1318],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.1172, -4.8125,  0.5293,  ..., -4.4766, -0.9912,  2.4043],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.1054, -0.0008, -0.0112,  ..., -0.0024,  0.0047, -0.0017],
        [ 0.0005,  0.0882,  0.0169,  ..., -0.0042, -0.0007, -0.0159],
        [ 0.0006,  0.0059,  0.0665,  ...,  0.0017,  0.0051,  0.0162],
        ...,
        [ 0.0027,  0.0065, -0.0114,  ...,  0.0796,  0.0041, -0.0047],
        [-0.0088, -0.0048,  0.0101,  ...,  0.0056,  0.0599, -0.0003],
        [-0.0033,  0.0054, -0.0040,  ...,  0.0140, -0.0156,  0.0851]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.8379, -4.7148,  0.4414,  ..., -4.2734, -0.8315,  2.1738]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 02:42:32 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for newton was english
fermi was italian
spinoza was dutch
copernicus was polish
pascal was french
dostoyevsky was russian
napoleon was french
rousseau was
2024-07-31 02:42:32 root INFO     [order_1_approx] starting weight calculation for rousseau was french
pascal was french
dostoyevsky was russian
napoleon was french
copernicus was polish
spinoza was dutch
fermi was italian
newton was
2024-07-31 02:42:32 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 02:44:31 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.4512, -0.2039, -0.0125,  ..., -0.1643, -0.0543,  0.3345],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.2656, -0.6191, -0.5605,  ..., -4.5078, -1.5498, -3.0938],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0840, -0.0060,  0.0002,  ..., -0.0109, -0.0137, -0.0275],
        [ 0.0009,  0.1083,  0.0149,  ..., -0.0010,  0.0283, -0.0005],
        [ 0.0135, -0.0124,  0.0686,  ...,  0.0261,  0.0013,  0.0074],
        ...,
        [-0.0087,  0.0194, -0.0117,  ...,  0.0636,  0.0186,  0.0066],
        [-0.0005,  0.0065,  0.0061,  ...,  0.0082,  0.0671, -0.0179],
        [-0.0011,  0.0183, -0.0085,  ..., -0.0098, -0.0062,  0.1193]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.7559, -1.0312, -0.5464,  ..., -4.0312, -1.5557, -3.0410]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 02:44:32 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for rousseau was french
pascal was french
dostoyevsky was russian
napoleon was french
copernicus was polish
spinoza was dutch
fermi was italian
newton was
2024-07-31 02:44:32 root INFO     total operator prediction time: 956.249183177948 seconds
2024-07-31 02:44:32 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on UK_city - county
2024-07-31 02:44:32 root INFO     building operator UK_city - county
2024-07-31 02:44:32 root INFO     [order_1_approx] starting weight calculation for In the United Kingdom, the city of stirling is in the county of stirlingshire
In the United Kingdom, the city of lincoln is in the county of lincolnshire
In the United Kingdom, the city of edinburgh is in the county of lowlands
In the United Kingdom, the city of southampton is in the county of hampshire
In the United Kingdom, the city of newport is in the county of gwent
In the United Kingdom, the city of canterbury is in the county of kent
In the United Kingdom, the city of brighton is in the county of sussex
In the United Kingdom, the city of liverpool is in the county of
2024-07-31 02:44:32 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 02:47:03 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3540, -0.0159, -0.2634,  ...,  0.1704, -0.5234,  0.3232],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.6289, -7.2148,  1.1211,  ..., -5.3828,  0.0732, -2.9727],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0196,  0.0059,  0.0048,  ...,  0.0082, -0.0017, -0.0071],
        [-0.0041,  0.0027,  0.0100,  ..., -0.0067,  0.0001,  0.0026],
        [-0.0087,  0.0077,  0.0116,  ...,  0.0179,  0.0076, -0.0138],
        ...,
        [-0.0020, -0.0105, -0.0095,  ...,  0.0268,  0.0105,  0.0043],
        [-0.0074, -0.0037,  0.0028,  ...,  0.0069,  0.0231, -0.0027],
        [ 0.0071, -0.0098, -0.0061,  ..., -0.0033, -0.0112,  0.0163]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.6699, -7.0742,  0.9233,  ..., -5.3320,  0.1404, -2.9531]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 02:47:04 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for In the United Kingdom, the city of stirling is in the county of stirlingshire
In the United Kingdom, the city of lincoln is in the county of lincolnshire
In the United Kingdom, the city of edinburgh is in the county of lowlands
In the United Kingdom, the city of southampton is in the county of hampshire
In the United Kingdom, the city of newport is in the county of gwent
In the United Kingdom, the city of canterbury is in the county of kent
In the United Kingdom, the city of brighton is in the county of sussex
In the United Kingdom, the city of liverpool is in the county of
2024-07-31 02:47:05 root INFO     [order_1_approx] starting weight calculation for In the United Kingdom, the city of liverpool is in the county of lancashire
In the United Kingdom, the city of southampton is in the county of hampshire
In the United Kingdom, the city of stirling is in the county of stirlingshire
In the United Kingdom, the city of canterbury is in the county of kent
In the United Kingdom, the city of brighton is in the county of sussex
In the United Kingdom, the city of edinburgh is in the county of lowlands
In the United Kingdom, the city of newport is in the county of gwent
In the United Kingdom, the city of lincoln is in the county of
2024-07-31 02:47:05 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 02:49:38 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0779,  0.0454, -0.1169,  ..., -0.2666, -0.0420, -0.2054],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.7285, -3.1934,  1.1641,  ..., -6.9375, -3.3750,  0.5850],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0098,  0.0027, -0.0178,  ..., -0.0160, -0.0305, -0.0093],
        [-0.0093,  0.0158,  0.0186,  ..., -0.0115, -0.0010, -0.0033],
        [-0.0108,  0.0004,  0.0301,  ...,  0.0103, -0.0024, -0.0109],
        ...,
        [ 0.0259, -0.0151, -0.0144,  ...,  0.0406,  0.0010,  0.0115],
        [-0.0041, -0.0138,  0.0090,  ...,  0.0112,  0.0189, -0.0075],
        [-0.0060, -0.0117, -0.0113,  ..., -0.0051, -0.0101,  0.0217]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.6309, -3.4141,  0.8315,  ..., -6.5859, -3.1152,  0.6357]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 02:49:39 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for In the United Kingdom, the city of liverpool is in the county of lancashire
In the United Kingdom, the city of southampton is in the county of hampshire
In the United Kingdom, the city of stirling is in the county of stirlingshire
In the United Kingdom, the city of canterbury is in the county of kent
In the United Kingdom, the city of brighton is in the county of sussex
In the United Kingdom, the city of edinburgh is in the county of lowlands
In the United Kingdom, the city of newport is in the county of gwent
In the United Kingdom, the city of lincoln is in the county of
2024-07-31 02:49:40 root INFO     [order_1_approx] starting weight calculation for In the United Kingdom, the city of lincoln is in the county of lincolnshire
In the United Kingdom, the city of brighton is in the county of sussex
In the United Kingdom, the city of newport is in the county of gwent
In the United Kingdom, the city of stirling is in the county of stirlingshire
In the United Kingdom, the city of southampton is in the county of hampshire
In the United Kingdom, the city of edinburgh is in the county of lowlands
In the United Kingdom, the city of liverpool is in the county of lancashire
In the United Kingdom, the city of canterbury is in the county of
2024-07-31 02:49:40 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 02:52:15 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 8.5156e-01, -1.2207e-04, -5.0195e-01,  ...,  1.8738e-02,
        -1.6284e-01,  4.2065e-01], device='cuda:1', dtype=torch.float16,
       grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.0742, -5.0898, -1.1641,  ..., -3.3379,  1.0684, -2.3750],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0125, -0.0029, -0.0066,  ..., -0.0048, -0.0062, -0.0114],
        [ 0.0056,  0.0109,  0.0060,  ..., -0.0039,  0.0071, -0.0069],
        [-0.0064,  0.0015,  0.0168,  ...,  0.0103,  0.0042, -0.0067],
        ...,
        [-0.0020, -0.0155, -0.0094,  ...,  0.0183,  0.0015,  0.0032],
        [-0.0084, -0.0055, -0.0074,  ...,  0.0106,  0.0163,  0.0031],
        [ 0.0002, -0.0078, -0.0072,  ..., -0.0037, -0.0002,  0.0127]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.9414, -4.9922, -1.2178,  ..., -3.3574,  1.0693, -2.3691]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 02:52:16 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for In the United Kingdom, the city of lincoln is in the county of lincolnshire
In the United Kingdom, the city of brighton is in the county of sussex
In the United Kingdom, the city of newport is in the county of gwent
In the United Kingdom, the city of stirling is in the county of stirlingshire
In the United Kingdom, the city of southampton is in the county of hampshire
In the United Kingdom, the city of edinburgh is in the county of lowlands
In the United Kingdom, the city of liverpool is in the county of lancashire
In the United Kingdom, the city of canterbury is in the county of
2024-07-31 02:52:16 root INFO     [order_1_approx] starting weight calculation for In the United Kingdom, the city of canterbury is in the county of kent
In the United Kingdom, the city of newport is in the county of gwent
In the United Kingdom, the city of liverpool is in the county of lancashire
In the United Kingdom, the city of southampton is in the county of hampshire
In the United Kingdom, the city of lincoln is in the county of lincolnshire
In the United Kingdom, the city of edinburgh is in the county of lowlands
In the United Kingdom, the city of brighton is in the county of sussex
In the United Kingdom, the city of stirling is in the county of
2024-07-31 02:52:16 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 02:54:50 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.6689,  0.4866, -0.7935,  ...,  0.2500, -0.1429,  0.0970],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.3125, -6.6328,  1.3379,  ..., -5.0859, -2.7051, -3.3555],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0169, -0.0028,  0.0014,  ...,  0.0054, -0.0011, -0.0105],
        [ 0.0061,  0.0068,  0.0199,  ...,  0.0026,  0.0040,  0.0042],
        [ 0.0042, -0.0013,  0.0318,  ...,  0.0300, -0.0112, -0.0019],
        ...,
        [ 0.0131, -0.0211, -0.0019,  ...,  0.0638,  0.0142,  0.0189],
        [-0.0191, -0.0136,  0.0033,  ...,  0.0215,  0.0251,  0.0006],
        [-0.0075, -0.0129, -0.0044,  ..., -0.0058, -0.0025,  0.0369]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.4141, -6.5469,  1.2568,  ..., -4.7695, -2.4199, -3.3418]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 02:54:51 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for In the United Kingdom, the city of canterbury is in the county of kent
In the United Kingdom, the city of newport is in the county of gwent
In the United Kingdom, the city of liverpool is in the county of lancashire
In the United Kingdom, the city of southampton is in the county of hampshire
In the United Kingdom, the city of lincoln is in the county of lincolnshire
In the United Kingdom, the city of edinburgh is in the county of lowlands
In the United Kingdom, the city of brighton is in the county of sussex
In the United Kingdom, the city of stirling is in the county of
2024-07-31 02:54:51 root INFO     [order_1_approx] starting weight calculation for In the United Kingdom, the city of southampton is in the county of hampshire
In the United Kingdom, the city of liverpool is in the county of lancashire
In the United Kingdom, the city of stirling is in the county of stirlingshire
In the United Kingdom, the city of canterbury is in the county of kent
In the United Kingdom, the city of newport is in the county of gwent
In the United Kingdom, the city of lincoln is in the county of lincolnshire
In the United Kingdom, the city of edinburgh is in the county of lowlands
In the United Kingdom, the city of brighton is in the county of
2024-07-31 02:54:51 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 02:57:26 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4639,  0.1083,  0.3479,  ...,  0.9058, -0.0557, -0.3926],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.9629, -5.7578, -0.0918,  ..., -3.7305,  1.2725, -0.6777],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0313,  0.0214, -0.0017,  ..., -0.0038, -0.0079, -0.0176],
        [-0.0101,  0.0150,  0.0204,  ..., -0.0071,  0.0041, -0.0127],
        [-0.0148, -0.0110,  0.0256,  ...,  0.0085,  0.0055,  0.0062],
        ...,
        [ 0.0015, -0.0233, -0.0034,  ...,  0.0298,  0.0079,  0.0074],
        [-0.0060,  0.0072, -0.0078,  ...,  0.0217,  0.0346,  0.0047],
        [-0.0003,  0.0031, -0.0177,  ..., -0.0010, -0.0122,  0.0287]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.8418, -5.7930, -0.1584,  ..., -3.7676,  1.2158, -0.8081]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 02:57:26 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for In the United Kingdom, the city of southampton is in the county of hampshire
In the United Kingdom, the city of liverpool is in the county of lancashire
In the United Kingdom, the city of stirling is in the county of stirlingshire
In the United Kingdom, the city of canterbury is in the county of kent
In the United Kingdom, the city of newport is in the county of gwent
In the United Kingdom, the city of lincoln is in the county of lincolnshire
In the United Kingdom, the city of edinburgh is in the county of lowlands
In the United Kingdom, the city of brighton is in the county of
2024-07-31 02:57:27 root INFO     [order_1_approx] starting weight calculation for In the United Kingdom, the city of stirling is in the county of stirlingshire
In the United Kingdom, the city of liverpool is in the county of lancashire
In the United Kingdom, the city of edinburgh is in the county of lowlands
In the United Kingdom, the city of brighton is in the county of sussex
In the United Kingdom, the city of southampton is in the county of hampshire
In the United Kingdom, the city of canterbury is in the county of kent
In the United Kingdom, the city of lincoln is in the county of lincolnshire
In the United Kingdom, the city of newport is in the county of
2024-07-31 02:57:27 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 03:00:02 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.5952, -0.0352,  0.1085,  ...,  0.0775, -0.2742, -0.2747],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 5.2422, -4.7695,  2.5723,  ..., -2.4062,  0.3403,  0.8652],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0485,  0.0038,  0.0073,  ...,  0.0002, -0.0051, -0.0145],
        [ 0.0094,  0.0277,  0.0222,  ..., -0.0181,  0.0155,  0.0018],
        [ 0.0132, -0.0161,  0.0480,  ...,  0.0103,  0.0082, -0.0106],
        ...,
        [ 0.0086, -0.0304,  0.0061,  ...,  0.0515,  0.0165,  0.0049],
        [-0.0024,  0.0140, -0.0039,  ...,  0.0447,  0.0404, -0.0084],
        [ 0.0313, -0.0176, -0.0107,  ..., -0.0357, -0.0015,  0.0251]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 5.1680, -5.1367,  2.1289,  ..., -2.8555,  0.6621,  0.5547]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 03:00:03 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for In the United Kingdom, the city of stirling is in the county of stirlingshire
In the United Kingdom, the city of liverpool is in the county of lancashire
In the United Kingdom, the city of edinburgh is in the county of lowlands
In the United Kingdom, the city of brighton is in the county of sussex
In the United Kingdom, the city of southampton is in the county of hampshire
In the United Kingdom, the city of canterbury is in the county of kent
In the United Kingdom, the city of lincoln is in the county of lincolnshire
In the United Kingdom, the city of newport is in the county of
2024-07-31 03:00:03 root INFO     [order_1_approx] starting weight calculation for In the United Kingdom, the city of newport is in the county of gwent
In the United Kingdom, the city of canterbury is in the county of kent
In the United Kingdom, the city of stirling is in the county of stirlingshire
In the United Kingdom, the city of liverpool is in the county of lancashire
In the United Kingdom, the city of brighton is in the county of sussex
In the United Kingdom, the city of lincoln is in the county of lincolnshire
In the United Kingdom, the city of edinburgh is in the county of lowlands
In the United Kingdom, the city of southampton is in the county of
2024-07-31 03:00:03 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 03:02:39 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.6279,  0.1190, -0.6387,  ...,  0.3013, -0.2751, -0.3987],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.6797, -7.0430,  1.5020,  ..., -4.9727,  0.0586, -2.1016],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 1.1139e-02,  7.7095e-03, -7.8201e-05,  ..., -2.4338e-03,
          7.6485e-04, -1.4694e-02],
        [-1.6296e-02,  1.5274e-02,  9.6664e-03,  ..., -7.7629e-04,
          2.6169e-03, -4.0894e-03],
        [ 2.2278e-03,  1.0281e-03,  1.7136e-02,  ...,  3.8891e-03,
          3.4561e-03, -5.7259e-03],
        ...,
        [-3.8757e-03, -5.2681e-03, -8.0109e-03,  ...,  2.0508e-02,
          6.1913e-03,  2.1572e-03],
        [-2.1973e-03, -1.3596e-02,  1.0300e-04,  ...,  1.7212e-02,
          1.8860e-02, -3.2692e-03],
        [-1.6594e-03, -6.1684e-03,  3.1471e-05,  ..., -8.4381e-03,
         -7.6447e-03,  1.0765e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.6523, -6.9180,  1.3877,  ..., -4.9648,  0.0928, -2.1172]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 03:02:40 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for In the United Kingdom, the city of newport is in the county of gwent
In the United Kingdom, the city of canterbury is in the county of kent
In the United Kingdom, the city of stirling is in the county of stirlingshire
In the United Kingdom, the city of liverpool is in the county of lancashire
In the United Kingdom, the city of brighton is in the county of sussex
In the United Kingdom, the city of lincoln is in the county of lincolnshire
In the United Kingdom, the city of edinburgh is in the county of lowlands
In the United Kingdom, the city of southampton is in the county of
2024-07-31 03:02:40 root INFO     [order_1_approx] starting weight calculation for In the United Kingdom, the city of canterbury is in the county of kent
In the United Kingdom, the city of brighton is in the county of sussex
In the United Kingdom, the city of lincoln is in the county of lincolnshire
In the United Kingdom, the city of southampton is in the county of hampshire
In the United Kingdom, the city of stirling is in the county of stirlingshire
In the United Kingdom, the city of liverpool is in the county of lancashire
In the United Kingdom, the city of newport is in the county of gwent
In the United Kingdom, the city of edinburgh is in the county of
2024-07-31 03:02:40 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 03:05:15 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4087,  0.5820, -0.5610,  ...,  0.2117,  0.0745,  0.5000],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.2598, -3.9883,  1.3691,  ..., -1.5654, -1.1035, -1.2354],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0027, -0.0067,  0.0073,  ...,  0.0151, -0.0031, -0.0113],
        [-0.0114,  0.0108,  0.0182,  ..., -0.0043,  0.0044,  0.0004],
        [ 0.0013,  0.0188,  0.0337,  ...,  0.0147, -0.0058, -0.0089],
        ...,
        [ 0.0061, -0.0141, -0.0001,  ...,  0.0425,  0.0063,  0.0113],
        [-0.0056, -0.0066, -0.0016,  ...,  0.0229,  0.0250, -0.0010],
        [-0.0116, -0.0023, -0.0059,  ..., -0.0011, -0.0034,  0.0285]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.8955, -3.5293,  1.1963,  ..., -1.7217, -0.8564, -1.4580]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 03:05:16 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for In the United Kingdom, the city of canterbury is in the county of kent
In the United Kingdom, the city of brighton is in the county of sussex
In the United Kingdom, the city of lincoln is in the county of lincolnshire
In the United Kingdom, the city of southampton is in the county of hampshire
In the United Kingdom, the city of stirling is in the county of stirlingshire
In the United Kingdom, the city of liverpool is in the county of lancashire
In the United Kingdom, the city of newport is in the county of gwent
In the United Kingdom, the city of edinburgh is in the county of
2024-07-31 03:05:16 root INFO     total operator prediction time: 1244.5730707645416 seconds
2024-07-31 03:05:16 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on verb+ment_irreg
2024-07-31 03:05:16 root INFO     building operator verb+ment_irreg
2024-07-31 03:05:16 root INFO     [order_1_approx] starting weight calculation for To replace results in a replacement
To require results in a requirement
To enhance results in a enhancement
To engage results in a engagement
To punish results in a punishment
To excite results in a excitement
To equip results in a equipment
To amend results in a
2024-07-31 03:05:17 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 03:07:15 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0049, -0.0477, -0.9561,  ..., -0.4099, -0.3706,  0.2301],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.1406, -1.3418,  0.0625,  ...,  2.0938, -2.1855, -1.6514],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0939, -0.0119, -0.0156,  ..., -0.0176, -0.0097, -0.0087],
        [ 0.0049,  0.0913,  0.0171,  ...,  0.0271,  0.0080,  0.0171],
        [-0.0056, -0.0009,  0.0748,  ..., -0.0097,  0.0014, -0.0195],
        ...,
        [ 0.0089,  0.0150, -0.0008,  ...,  0.1085, -0.0015,  0.0061],
        [-0.0035,  0.0133,  0.0054,  ...,  0.0096,  0.0717, -0.0064],
        [ 0.0202, -0.0106, -0.0029,  ..., -0.0002, -0.0086,  0.0990]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.8945, -1.2588,  0.2056,  ...,  2.3145, -2.1113, -1.9941]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 03:07:16 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To replace results in a replacement
To require results in a requirement
To enhance results in a enhancement
To engage results in a engagement
To punish results in a punishment
To excite results in a excitement
To equip results in a equipment
To amend results in a
2024-07-31 03:07:16 root INFO     [order_1_approx] starting weight calculation for To excite results in a excitement
To equip results in a equipment
To replace results in a replacement
To require results in a requirement
To amend results in a amendment
To engage results in a engagement
To punish results in a punishment
To enhance results in a
2024-07-31 03:07:16 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 03:09:14 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.3931, -0.6440, -0.2188,  ...,  0.0107,  0.0342, -0.0830],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.5176, -1.4043,  0.7451,  ...,  3.9219, -5.0820, -2.6230],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 9.1797e-02,  4.5624e-03,  1.9264e-04,  ..., -1.8738e-02,
         -1.6432e-03,  6.6376e-04],
        [ 8.4686e-04,  9.5276e-02,  7.6904e-03,  ...,  2.8870e-02,
          3.1853e-03,  1.0979e-02],
        [-2.5177e-03, -1.5289e-02,  7.0251e-02,  ..., -2.8458e-03,
          2.9335e-03, -1.5625e-02],
        ...,
        [-5.2452e-03, -1.8005e-03, -1.2115e-02,  ...,  1.0791e-01,
          1.1024e-03,  1.3933e-03],
        [-1.1902e-02,  1.5137e-02,  1.9485e-02,  ...,  1.8167e-03,
          9.1797e-02, -1.4931e-02],
        [-6.4850e-05, -1.1818e-02, -7.1106e-03,  ...,  1.1845e-03,
         -7.2594e-03,  8.7708e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.4980, -1.2402,  0.9175,  ...,  3.8945, -5.0352, -2.8066]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 03:09:15 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To excite results in a excitement
To equip results in a equipment
To replace results in a replacement
To require results in a requirement
To amend results in a amendment
To engage results in a engagement
To punish results in a punishment
To enhance results in a
2024-07-31 03:09:15 root INFO     [order_1_approx] starting weight calculation for To amend results in a amendment
To punish results in a punishment
To require results in a requirement
To excite results in a excitement
To equip results in a equipment
To enhance results in a enhancement
To replace results in a replacement
To engage results in a
2024-07-31 03:09:15 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 03:11:11 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0836,  0.6108,  0.1416,  ...,  0.2876, -0.1016, -0.3655],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.2285, -3.9883,  0.7534,  ...,  2.1738, -0.4480, -4.6523],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.1044,  0.0219,  0.0102,  ..., -0.0203,  0.0080,  0.0087],
        [-0.0037,  0.1014,  0.0068,  ...,  0.0186,  0.0040,  0.0037],
        [-0.0054, -0.0148,  0.0834,  ..., -0.0081, -0.0032, -0.0065],
        ...,
        [ 0.0013,  0.0050, -0.0068,  ...,  0.1035, -0.0053, -0.0128],
        [-0.0062,  0.0156,  0.0179,  ...,  0.0068,  0.0950, -0.0078],
        [ 0.0030,  0.0078, -0.0157,  ...,  0.0085, -0.0085,  0.0930]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.2656, -3.4238,  0.8716,  ...,  2.4375, -0.7061, -4.3008]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 03:11:12 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To amend results in a amendment
To punish results in a punishment
To require results in a requirement
To excite results in a excitement
To equip results in a equipment
To enhance results in a enhancement
To replace results in a replacement
To engage results in a
2024-07-31 03:11:12 root INFO     [order_1_approx] starting weight calculation for To amend results in a amendment
To excite results in a excitement
To require results in a requirement
To equip results in a equipment
To enhance results in a enhancement
To punish results in a punishment
To engage results in a engagement
To replace results in a
2024-07-31 03:11:12 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 03:13:11 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0806, -0.1105, -0.7368,  ...,  0.0349,  0.0156, -0.3386],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.9312, -4.2266, -0.2842,  ...,  2.4199, -0.3779, -1.1885],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.1143, -0.0050,  0.0019,  ..., -0.0143, -0.0072, -0.0030],
        [-0.0093,  0.0979,  0.0084,  ...,  0.0264,  0.0054,  0.0285],
        [ 0.0007, -0.0096,  0.0735,  ..., -0.0184,  0.0028, -0.0173],
        ...,
        [ 0.0064,  0.0094, -0.0092,  ...,  0.1071,  0.0004,  0.0051],
        [-0.0056,  0.0260,  0.0108,  ..., -0.0025,  0.0843, -0.0179],
        [ 0.0279,  0.0057,  0.0049,  ..., -0.0026, -0.0203,  0.1193]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.4741, -3.3984,  0.0786,  ...,  2.5215, -0.5889, -1.3115]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 03:13:12 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To amend results in a amendment
To excite results in a excitement
To require results in a requirement
To equip results in a equipment
To enhance results in a enhancement
To punish results in a punishment
To engage results in a engagement
To replace results in a
2024-07-31 03:13:12 root INFO     [order_1_approx] starting weight calculation for To replace results in a replacement
To excite results in a excitement
To amend results in a amendment
To require results in a requirement
To enhance results in a enhancement
To equip results in a equipment
To engage results in a engagement
To punish results in a
2024-07-31 03:13:12 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 03:15:11 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2646, -0.0212, -0.7949,  ..., -0.0114, -0.3789,  0.0856],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.8379, -4.1094,  0.7891,  ...,  0.5469,  0.4026, -0.3770],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0628, -0.0010,  0.0059,  ..., -0.0138, -0.0095, -0.0019],
        [ 0.0074,  0.0708, -0.0014,  ...,  0.0127,  0.0114,  0.0151],
        [ 0.0039,  0.0004,  0.0599,  ..., -0.0123, -0.0039, -0.0017],
        ...,
        [ 0.0027,  0.0065, -0.0073,  ...,  0.0701,  0.0012,  0.0048],
        [-0.0066,  0.0012,  0.0158,  ..., -0.0004,  0.0573, -0.0227],
        [ 0.0083,  0.0073, -0.0033,  ...,  0.0038, -0.0113,  0.0696]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.6328, -3.8984,  0.8120,  ...,  0.6255,  0.2607, -0.6602]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 03:15:12 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To replace results in a replacement
To excite results in a excitement
To amend results in a amendment
To require results in a requirement
To enhance results in a enhancement
To equip results in a equipment
To engage results in a engagement
To punish results in a
2024-07-31 03:15:12 root INFO     [order_1_approx] starting weight calculation for To excite results in a excitement
To enhance results in a enhancement
To punish results in a punishment
To equip results in a equipment
To replace results in a replacement
To amend results in a amendment
To engage results in a engagement
To require results in a
2024-07-31 03:15:12 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 03:17:09 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.8096,  0.1746, -0.6323,  ..., -0.3682, -0.6382, -0.4897],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.5332, -3.7695,  0.1128,  ...,  0.5674, -1.1016, -2.4512],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0700, -0.0137, -0.0008,  ..., -0.0259, -0.0178, -0.0085],
        [-0.0050,  0.0824,  0.0092,  ...,  0.0328,  0.0131,  0.0270],
        [ 0.0054, -0.0155,  0.0568,  ..., -0.0324, -0.0007, -0.0163],
        ...,
        [-0.0040,  0.0286,  0.0008,  ...,  0.1002,  0.0036,  0.0137],
        [-0.0123,  0.0091,  0.0202,  ..., -0.0017,  0.0714, -0.0305],
        [ 0.0028, -0.0035,  0.0089,  ..., -0.0051, -0.0112,  0.0911]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.2964, -3.4062,  0.1257,  ...,  0.7095, -0.7329, -2.4453]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 03:17:10 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To excite results in a excitement
To enhance results in a enhancement
To punish results in a punishment
To equip results in a equipment
To replace results in a replacement
To amend results in a amendment
To engage results in a engagement
To require results in a
2024-07-31 03:17:10 root INFO     [order_1_approx] starting weight calculation for To excite results in a excitement
To punish results in a punishment
To enhance results in a enhancement
To require results in a requirement
To amend results in a amendment
To engage results in a engagement
To replace results in a replacement
To equip results in a
2024-07-31 03:17:10 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 03:19:09 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2440,  0.3552, -0.1224,  ..., -0.4155, -0.2416,  0.1803],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.3823, -2.6191, -0.5786,  ...,  3.7344, -2.9824, -2.3535],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 7.5317e-02,  6.4812e-03,  1.2924e-02,  ..., -8.1635e-03,
          3.0060e-03, -7.2556e-03],
        [ 9.8267e-03,  7.2571e-02, -8.3923e-05,  ...,  1.4069e-02,
          8.3389e-03,  1.3428e-02],
        [ 1.1856e-02,  5.6572e-03,  6.9397e-02,  ..., -1.6403e-02,
         -3.8605e-03, -7.1869e-03],
        ...,
        [-9.2392e-03,  1.1726e-02,  1.1505e-02,  ...,  8.9478e-02,
         -7.9041e-03,  8.1635e-04],
        [-7.3891e-03,  2.0279e-02,  9.6741e-03,  ..., -6.2637e-03,
          8.5205e-02, -1.7456e-02],
        [ 6.7596e-03, -6.5994e-03, -1.4877e-02,  ..., -1.2115e-02,
         -4.9133e-03,  8.3679e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.2859, -2.1875, -0.6719,  ...,  3.9434, -2.8848, -2.2305]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 03:19:10 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To excite results in a excitement
To punish results in a punishment
To enhance results in a enhancement
To require results in a requirement
To amend results in a amendment
To engage results in a engagement
To replace results in a replacement
To equip results in a
2024-07-31 03:19:10 root INFO     [order_1_approx] starting weight calculation for To enhance results in a enhancement
To require results in a requirement
To punish results in a punishment
To equip results in a equipment
To amend results in a amendment
To engage results in a engagement
To replace results in a replacement
To excite results in a
2024-07-31 03:19:10 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 03:21:07 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0605, -0.5073, -1.1211,  ...,  0.1648, -0.2045,  0.4229],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.5508, -2.7383,  0.4363,  ...,  2.2676,  0.1289, -2.1426],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0942, -0.0036,  0.0032,  ..., -0.0083,  0.0086, -0.0056],
        [ 0.0083,  0.1016,  0.0116,  ...,  0.0204,  0.0013, -0.0020],
        [ 0.0096, -0.0078,  0.0856,  ..., -0.0101, -0.0032, -0.0141],
        ...,
        [ 0.0044,  0.0084, -0.0025,  ...,  0.1107, -0.0012, -0.0018],
        [ 0.0086,  0.0199,  0.0187,  ..., -0.0025,  0.0923, -0.0097],
        [ 0.0110, -0.0046, -0.0085,  ...,  0.0096, -0.0083,  0.1008]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.3477, -2.7129,  0.3540,  ...,  2.3652,  0.3596, -2.4062]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 03:21:07 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To enhance results in a enhancement
To require results in a requirement
To punish results in a punishment
To equip results in a equipment
To amend results in a amendment
To engage results in a engagement
To replace results in a replacement
To excite results in a
2024-07-31 03:21:07 root INFO     total operator prediction time: 951.1701865196228 seconds
2024-07-31 03:21:07 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on noun+less_reg
2024-07-31 03:21:07 root INFO     building operator noun+less_reg
2024-07-31 03:21:08 root INFO     [order_1_approx] starting weight calculation for Something without soul is soulless
Something without speech is speechless
Something without friend is friendless
Something without death is deathless
Something without tact is tactless
Something without friction is frictionless
Something without gender is genderless
Something without path is
2024-07-31 03:21:08 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 03:23:07 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1006, -0.4653,  0.2764,  ..., -0.6567, -0.1077,  0.0405],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.9082, -4.8750, -3.2480,  ..., -0.7295, -5.8555, -1.4746],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0339, -0.0339, -0.0018,  ..., -0.0040,  0.0140,  0.0111],
        [-0.0036,  0.0692, -0.0086,  ...,  0.0137,  0.0144, -0.0009],
        [ 0.0148, -0.0196,  0.0373,  ..., -0.0026,  0.0053,  0.0043],
        ...,
        [ 0.0034,  0.0299, -0.0120,  ...,  0.0390, -0.0178,  0.0046],
        [-0.0055,  0.0073,  0.0046,  ..., -0.0096,  0.0490, -0.0059],
        [ 0.0074,  0.0226, -0.0065,  ..., -0.0026, -0.0152,  0.0345]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.0391, -4.7461, -3.4922,  ..., -0.9707, -5.5391, -1.4551]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 03:23:07 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Something without soul is soulless
Something without speech is speechless
Something without friend is friendless
Something without death is deathless
Something without tact is tactless
Something without friction is frictionless
Something without gender is genderless
Something without path is
2024-07-31 03:23:08 root INFO     [order_1_approx] starting weight calculation for Something without speech is speechless
Something without friction is frictionless
Something without death is deathless
Something without tact is tactless
Something without gender is genderless
Something without friend is friendless
Something without path is pathless
Something without soul is
2024-07-31 03:23:08 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 03:25:08 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1643, -0.4907,  0.2043,  ..., -0.3013, -0.0688,  0.6934],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.9414, -0.8770,  0.8003,  ..., -4.3086, -4.3672,  0.3047],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 2.2034e-02, -1.8677e-02,  8.6212e-03,  ..., -6.4163e-03,
          1.9821e-02,  1.5129e-02],
        [ 5.0163e-04,  3.9429e-02, -2.1439e-03,  ...,  4.4174e-03,
         -9.0561e-03, -1.1238e-02],
        [ 1.1894e-02,  2.3155e-03,  2.4078e-02,  ...,  6.4278e-04,
         -2.0279e-02,  7.9117e-03],
        ...,
        [ 4.4098e-03,  1.3817e-02,  7.7744e-03,  ...,  2.2598e-02,
         -1.7700e-02,  8.8806e-03],
        [-1.3161e-03,  1.0056e-02,  1.0582e-02,  ...,  6.4850e-05,
          4.6906e-02, -1.5762e-02],
        [ 1.0567e-02,  7.6065e-03, -3.2425e-03,  ..., -5.9128e-03,
         -1.3489e-02,  2.4124e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.8867, -0.6245,  0.3259,  ..., -3.6191, -4.2773,  0.6396]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 03:25:09 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Something without speech is speechless
Something without friction is frictionless
Something without death is deathless
Something without tact is tactless
Something without gender is genderless
Something without friend is friendless
Something without path is pathless
Something without soul is
2024-07-31 03:25:09 root INFO     [order_1_approx] starting weight calculation for Something without gender is genderless
Something without tact is tactless
Something without speech is speechless
Something without path is pathless
Something without friend is friendless
Something without soul is soulless
Something without death is deathless
Something without friction is
2024-07-31 03:25:10 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 03:27:10 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.5742, -0.4788, -0.8716,  ..., -0.0693,  0.4780, -0.2693],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.5977, -0.9634,  1.6357,  ..., -2.2656, -3.1484, -0.5732],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0642, -0.0023,  0.0132,  ..., -0.0119,  0.0155, -0.0155],
        [-0.0148,  0.0671, -0.0009,  ..., -0.0011,  0.0005, -0.0089],
        [ 0.0232, -0.0005,  0.0503,  ..., -0.0064, -0.0087, -0.0056],
        ...,
        [-0.0007,  0.0077,  0.0026,  ...,  0.0611, -0.0241, -0.0088],
        [ 0.0032,  0.0153,  0.0004,  ..., -0.0019,  0.0709, -0.0084],
        [ 0.0165,  0.0148, -0.0211,  ..., -0.0025, -0.0051,  0.0421]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.6035, -1.1895,  1.5039,  ..., -2.0703, -3.1797, -0.6572]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 03:27:11 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Something without gender is genderless
Something without tact is tactless
Something without speech is speechless
Something without path is pathless
Something without friend is friendless
Something without soul is soulless
Something without death is deathless
Something without friction is
2024-07-31 03:27:11 root INFO     [order_1_approx] starting weight calculation for Something without death is deathless
Something without soul is soulless
Something without tact is tactless
Something without friction is frictionless
Something without gender is genderless
Something without friend is friendless
Something without path is pathless
Something without speech is
2024-07-31 03:27:11 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 03:29:10 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1963, -0.5688,  0.2185,  ..., -0.0135,  0.6191,  0.4165],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.0430, -1.9434, -0.0820,  ..., -0.0444, -2.0430, -0.9902],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0161,  0.0005,  0.0054,  ...,  0.0007,  0.0231,  0.0233],
        [ 0.0010,  0.0421,  0.0175,  ...,  0.0064,  0.0001,  0.0015],
        [ 0.0134, -0.0156,  0.0135,  ..., -0.0024, -0.0082,  0.0058],
        ...,
        [-0.0053,  0.0003, -0.0008,  ...,  0.0115, -0.0163,  0.0039],
        [-0.0052,  0.0093, -0.0007,  ..., -0.0203,  0.0139, -0.0120],
        [ 0.0027, -0.0030, -0.0030,  ..., -0.0029, -0.0001,  0.0186]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.7642, -1.8906, -0.4690,  ..., -0.0619, -2.2930, -1.0215]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 03:29:11 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Something without death is deathless
Something without soul is soulless
Something without tact is tactless
Something without friction is frictionless
Something without gender is genderless
Something without friend is friendless
Something without path is pathless
Something without speech is
2024-07-31 03:29:11 root INFO     [order_1_approx] starting weight calculation for Something without gender is genderless
Something without speech is speechless
Something without path is pathless
Something without death is deathless
Something without soul is soulless
Something without friend is friendless
Something without friction is frictionless
Something without tact is
2024-07-31 03:29:11 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 03:31:10 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([0.4614, 0.0416, 0.0530,  ..., 0.0343, 0.2637, 0.2856], device='cuda:1',
       dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.1289,  0.0574,  0.3770,  ..., -0.0352, -7.0156, -3.8086],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0337, -0.0194,  0.0015,  ..., -0.0059,  0.0051,  0.0078],
        [ 0.0013,  0.0411,  0.0089,  ...,  0.0112,  0.0113, -0.0159],
        [ 0.0014, -0.0058,  0.0281,  ...,  0.0148, -0.0150,  0.0153],
        ...,
        [ 0.0153,  0.0144,  0.0081,  ...,  0.0425, -0.0206, -0.0046],
        [ 0.0114, -0.0051, -0.0017,  ...,  0.0034,  0.0417, -0.0126],
        [ 0.0077,  0.0017,  0.0026,  ...,  0.0091, -0.0070,  0.0529]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.4766, -0.5049,  0.0688,  ..., -0.6147, -7.1055, -3.6797]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 03:31:11 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Something without gender is genderless
Something without speech is speechless
Something without path is pathless
Something without death is deathless
Something without soul is soulless
Something without friend is friendless
Something without friction is frictionless
Something without tact is
2024-07-31 03:31:11 root INFO     [order_1_approx] starting weight calculation for Something without path is pathless
Something without soul is soulless
Something without friction is frictionless
Something without speech is speechless
Something without tact is tactless
Something without friend is friendless
Something without gender is genderless
Something without death is
2024-07-31 03:31:11 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 03:33:11 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1100, -0.4189,  0.1383,  ..., -0.5220,  0.3113, -0.0835],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.5811, -3.4414,  0.7754,  ..., -1.7637, -3.2070, -2.0898],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0184, -0.0099,  0.0145,  ...,  0.0176,  0.0065,  0.0034],
        [-0.0060,  0.0318, -0.0042,  ...,  0.0078, -0.0011, -0.0065],
        [ 0.0173,  0.0077,  0.0260,  ..., -0.0102, -0.0042, -0.0009],
        ...,
        [ 0.0035,  0.0143, -0.0028,  ...,  0.0159, -0.0023, -0.0037],
        [-0.0021,  0.0024,  0.0093,  ..., -0.0150,  0.0345, -0.0056],
        [ 0.0083,  0.0050,  0.0008,  ...,  0.0048,  0.0027,  0.0291]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.9263, -3.0215,  0.6680,  ..., -1.6904, -3.3594, -1.5957]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 03:33:12 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Something without path is pathless
Something without soul is soulless
Something without friction is frictionless
Something without speech is speechless
Something without tact is tactless
Something without friend is friendless
Something without gender is genderless
Something without death is
2024-07-31 03:33:12 root INFO     [order_1_approx] starting weight calculation for Something without tact is tactless
Something without friend is friendless
Something without path is pathless
Something without speech is speechless
Something without death is deathless
Something without soul is soulless
Something without friction is frictionless
Something without gender is
2024-07-31 03:33:12 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 03:35:11 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.6768, -0.2852, -0.5576,  ...,  0.6523,  0.0209, -0.4417],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.3813, -2.2070, -1.4297,  ..., -2.1445, -3.8730, -2.3516],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0352, -0.0142,  0.0009,  ..., -0.0047,  0.0126, -0.0050],
        [ 0.0084,  0.0487, -0.0076,  ...,  0.0004,  0.0090,  0.0068],
        [-0.0062,  0.0028,  0.0373,  ..., -0.0053,  0.0083, -0.0012],
        ...,
        [-0.0073,  0.0072, -0.0028,  ...,  0.0380, -0.0096, -0.0165],
        [-0.0077, -0.0095,  0.0044,  ...,  0.0030,  0.0434,  0.0021],
        [ 0.0174,  0.0034, -0.0040,  ..., -0.0105, -0.0103,  0.0317]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.3821, -1.8750, -1.2500,  ..., -2.1191, -4.1758, -2.3145]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 03:35:12 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Something without tact is tactless
Something without friend is friendless
Something without path is pathless
Something without speech is speechless
Something without death is deathless
Something without soul is soulless
Something without friction is frictionless
Something without gender is
2024-07-31 03:35:12 root INFO     [order_1_approx] starting weight calculation for Something without friction is frictionless
Something without death is deathless
Something without gender is genderless
Something without soul is soulless
Something without path is pathless
Something without tact is tactless
Something without speech is speechless
Something without friend is
2024-07-31 03:35:12 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 03:37:06 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.5610, -0.3823, -0.5986,  ..., -0.6899,  0.0903, -0.1098],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.3008, -1.4424,  1.2168,  ..., -0.4077, -4.3242,  1.6895],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0303, -0.0023,  0.0130,  ..., -0.0005,  0.0129,  0.0189],
        [-0.0079,  0.0422, -0.0040,  ...,  0.0082,  0.0047, -0.0081],
        [ 0.0128, -0.0066,  0.0253,  ...,  0.0044,  0.0034,  0.0021],
        ...,
        [-0.0048,  0.0044, -0.0009,  ...,  0.0320, -0.0045, -0.0011],
        [-0.0036, -0.0036,  0.0066,  ..., -0.0055,  0.0331, -0.0064],
        [ 0.0091, -0.0035, -0.0131,  ..., -0.0010, -0.0057,  0.0328]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.1709, -1.2744,  1.3232,  ..., -0.2798, -4.3984,  1.5986]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 03:37:08 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Something without friction is frictionless
Something without death is deathless
Something without gender is genderless
Something without soul is soulless
Something without path is pathless
Something without tact is tactless
Something without speech is speechless
Something without friend is
2024-07-31 03:37:08 root INFO     total operator prediction time: 960.1777241230011 seconds
2024-07-31 03:37:08 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on adj+ness_reg
2024-07-31 03:37:08 root INFO     building operator adj+ness_reg
2024-07-31 03:37:08 root INFO     [order_1_approx] starting weight calculation for The state of being conscious is consciousness
The state of being serious is seriousness
The state of being hidden is hiddenness
The state of being massive is massiveness
The state of being connected is connectedness
The state of being reasonable is reasonableness
The state of being prepared is preparedness
The state of being related is
2024-07-31 03:37:08 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 03:39:08 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0497,  0.0026, -0.0314,  ..., -0.5215, -0.3438, -0.5156],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.2021, -2.0410, -1.9805,  ...,  0.9277, -2.4805, -1.5303],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0835,  0.0112,  0.0063,  ..., -0.0172, -0.0147,  0.0109],
        [-0.0090,  0.0689,  0.0027,  ...,  0.0464,  0.0255,  0.0106],
        [ 0.0188, -0.0070,  0.0693,  ..., -0.0102, -0.0130, -0.0131],
        ...,
        [ 0.0070,  0.0088, -0.0074,  ...,  0.0842,  0.0068, -0.0014],
        [-0.0037,  0.0222,  0.0315,  ..., -0.0103,  0.0679, -0.0165],
        [-0.0003, -0.0083, -0.0073,  ...,  0.0137, -0.0006,  0.0826]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.1816, -1.7441, -2.1797,  ...,  0.8794, -2.5508, -1.6875]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 03:39:10 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The state of being conscious is consciousness
The state of being serious is seriousness
The state of being hidden is hiddenness
The state of being massive is massiveness
The state of being connected is connectedness
The state of being reasonable is reasonableness
The state of being prepared is preparedness
The state of being related is
2024-07-31 03:39:10 root INFO     [order_1_approx] starting weight calculation for The state of being hidden is hiddenness
The state of being reasonable is reasonableness
The state of being connected is connectedness
The state of being serious is seriousness
The state of being related is relatedness
The state of being prepared is preparedness
The state of being conscious is consciousness
The state of being massive is
2024-07-31 03:39:10 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 03:41:00 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.6152,  0.1313, -0.1418,  ..., -0.5068, -0.1672, -0.0371],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.1562, -3.6836, -2.3242,  ..., -4.5078, -5.0586, -3.9121],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0977,  0.0046,  0.0014,  ...,  0.0107, -0.0008,  0.0054],
        [-0.0066,  0.0723,  0.0088,  ..., -0.0093,  0.0117, -0.0021],
        [ 0.0081,  0.0049,  0.0813,  ..., -0.0047,  0.0059,  0.0103],
        ...,
        [ 0.0169, -0.0046,  0.0257,  ...,  0.0867, -0.0145,  0.0081],
        [ 0.0084,  0.0073,  0.0014,  ..., -0.0095,  0.0889, -0.0139],
        [ 0.0121,  0.0119, -0.0025,  ..., -0.0060, -0.0190,  0.0764]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.8516, -3.3477, -2.1973,  ..., -4.4805, -5.0234, -3.7305]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 03:41:01 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The state of being hidden is hiddenness
The state of being reasonable is reasonableness
The state of being connected is connectedness
The state of being serious is seriousness
The state of being related is relatedness
The state of being prepared is preparedness
The state of being conscious is consciousness
The state of being massive is
2024-07-31 03:41:01 root INFO     [order_1_approx] starting weight calculation for The state of being related is relatedness
The state of being reasonable is reasonableness
The state of being massive is massiveness
The state of being prepared is preparedness
The state of being conscious is consciousness
The state of being hidden is hiddenness
The state of being connected is connectedness
The state of being serious is
2024-07-31 03:41:02 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 03:42:56 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2129, -0.1744, -0.2097,  ..., -0.3540, -1.0439,  0.6729],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.1992, -2.8301, -2.6543,  ..., -3.2930, -1.9609, -3.0742],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.1060, -0.0123,  0.0060,  ..., -0.0153, -0.0068,  0.0287],
        [ 0.0055,  0.0826,  0.0126,  ...,  0.0117, -0.0030,  0.0051],
        [ 0.0140, -0.0182,  0.0997,  ...,  0.0018,  0.0018, -0.0103],
        ...,
        [ 0.0159,  0.0148,  0.0056,  ...,  0.0798, -0.0229,  0.0257],
        [-0.0152,  0.0337, -0.0023,  ...,  0.0017,  0.0834, -0.0320],
        [ 0.0123, -0.0120, -0.0014,  ...,  0.0050, -0.0258,  0.0957]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.9272, -2.5117, -2.5352,  ..., -3.5391, -2.0879, -2.8848]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 03:42:57 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The state of being related is relatedness
The state of being reasonable is reasonableness
The state of being massive is massiveness
The state of being prepared is preparedness
The state of being conscious is consciousness
The state of being hidden is hiddenness
The state of being connected is connectedness
The state of being serious is
2024-07-31 03:42:57 root INFO     [order_1_approx] starting weight calculation for The state of being related is relatedness
The state of being conscious is consciousness
The state of being hidden is hiddenness
The state of being prepared is preparedness
The state of being massive is massiveness
The state of being connected is connectedness
The state of being serious is seriousness
The state of being reasonable is
2024-07-31 03:42:57 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 03:44:55 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0522, -0.4531,  0.0480,  ..., -0.5996, -0.1135, -0.0228],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.7637, -1.9375, -1.4062,  ..., -3.1328, -5.6406, -2.4551],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0711, -0.0040,  0.0018,  ..., -0.0048, -0.0073,  0.0312],
        [-0.0206,  0.0649,  0.0135,  ...,  0.0195,  0.0156, -0.0009],
        [ 0.0297, -0.0163,  0.0713,  ..., -0.0122, -0.0049, -0.0056],
        ...,
        [ 0.0040,  0.0031,  0.0295,  ...,  0.0765, -0.0080,  0.0124],
        [ 0.0186,  0.0168,  0.0343,  ...,  0.0066,  0.0603, -0.0146],
        [ 0.0032,  0.0096,  0.0011,  ..., -0.0002, -0.0121,  0.0687]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.2979, -2.2578, -1.3779,  ..., -3.2148, -5.3984, -2.6836]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 03:44:56 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The state of being related is relatedness
The state of being conscious is consciousness
The state of being hidden is hiddenness
The state of being prepared is preparedness
The state of being massive is massiveness
The state of being connected is connectedness
The state of being serious is seriousness
The state of being reasonable is
2024-07-31 03:44:57 root INFO     [order_1_approx] starting weight calculation for The state of being connected is connectedness
The state of being conscious is consciousness
The state of being massive is massiveness
The state of being reasonable is reasonableness
The state of being prepared is preparedness
The state of being serious is seriousness
The state of being related is relatedness
The state of being hidden is
2024-07-31 03:44:57 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 03:46:56 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2255, -0.1552, -0.2065,  ..., -0.4863,  0.3337,  0.1951],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.7969, -0.4561,  0.6025,  ..., -2.5410, -3.2617,  0.4072],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0852, -0.0003,  0.0060,  ...,  0.0010, -0.0100,  0.0136],
        [-0.0103,  0.0722,  0.0061,  ...,  0.0108,  0.0093, -0.0067],
        [ 0.0145, -0.0096,  0.0833,  ...,  0.0051, -0.0066, -0.0027],
        ...,
        [ 0.0060,  0.0192, -0.0031,  ...,  0.0827, -0.0190,  0.0024],
        [-0.0054,  0.0153,  0.0140,  ...,  0.0006,  0.0671, -0.0115],
        [ 0.0023, -0.0063, -0.0161,  ..., -0.0101, -0.0144,  0.0944]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.4785, -0.5620,  0.5044,  ..., -2.5137, -3.2109,  0.1643]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 03:46:57 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The state of being connected is connectedness
The state of being conscious is consciousness
The state of being massive is massiveness
The state of being reasonable is reasonableness
The state of being prepared is preparedness
The state of being serious is seriousness
The state of being related is relatedness
The state of being hidden is
2024-07-31 03:46:57 root INFO     [order_1_approx] starting weight calculation for The state of being connected is connectedness
The state of being massive is massiveness
The state of being hidden is hiddenness
The state of being prepared is preparedness
The state of being serious is seriousness
The state of being reasonable is reasonableness
The state of being related is relatedness
The state of being conscious is
2024-07-31 03:46:57 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 03:48:51 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1146,  0.1240, -0.1438,  ...,  0.1479, -0.0155,  0.6401],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.2339, -1.4814,  2.0234,  ..., -2.1016, -1.1426,  1.2852],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.1159,  0.0014,  0.0090,  ...,  0.0195, -0.0146,  0.0191],
        [-0.0076,  0.0795,  0.0123,  ...,  0.0225,  0.0066,  0.0044],
        [ 0.0195, -0.0047,  0.0886,  ..., -0.0182, -0.0073,  0.0033],
        ...,
        [ 0.0110,  0.0098,  0.0048,  ...,  0.0951, -0.0127,  0.0076],
        [ 0.0057,  0.0026,  0.0036,  ..., -0.0180,  0.0918, -0.0385],
        [ 0.0161,  0.0229, -0.0145,  ..., -0.0072, -0.0165,  0.0996]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.3726, -1.0547,  1.4844,  ..., -2.1465, -1.3242,  0.6392]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 03:48:52 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The state of being connected is connectedness
The state of being massive is massiveness
The state of being hidden is hiddenness
The state of being prepared is preparedness
The state of being serious is seriousness
The state of being reasonable is reasonableness
The state of being related is relatedness
The state of being conscious is
2024-07-31 03:48:52 root INFO     [order_1_approx] starting weight calculation for The state of being connected is connectedness
The state of being reasonable is reasonableness
The state of being massive is massiveness
The state of being hidden is hiddenness
The state of being related is relatedness
The state of being serious is seriousness
The state of being conscious is consciousness
The state of being prepared is
2024-07-31 03:48:52 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 03:50:51 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2842, -0.4077, -0.2480,  ..., -0.2910, -0.0154,  0.4414],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 5.0742, -5.2656, -1.3730,  ...,  0.3130, -2.4727, -2.0195],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0930, -0.0098,  0.0059,  ..., -0.0053, -0.0044,  0.0108],
        [-0.0057,  0.0773,  0.0021,  ...,  0.0189,  0.0041,  0.0088],
        [-0.0014, -0.0074,  0.0779,  ...,  0.0067, -0.0041,  0.0033],
        ...,
        [ 0.0083,  0.0058, -0.0211,  ...,  0.0885, -0.0137,  0.0055],
        [ 0.0093,  0.0102,  0.0096,  ..., -0.0016,  0.0811, -0.0231],
        [ 0.0047,  0.0031, -0.0088,  ..., -0.0096,  0.0028,  0.0878]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 5.2031, -5.3477, -1.2051,  ...,  0.0724, -2.6777, -1.7461]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 03:50:52 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The state of being connected is connectedness
The state of being reasonable is reasonableness
The state of being massive is massiveness
The state of being hidden is hiddenness
The state of being related is relatedness
The state of being serious is seriousness
The state of being conscious is consciousness
The state of being prepared is
2024-07-31 03:50:52 root INFO     [order_1_approx] starting weight calculation for The state of being prepared is preparedness
The state of being conscious is consciousness
The state of being hidden is hiddenness
The state of being massive is massiveness
The state of being reasonable is reasonableness
The state of being related is relatedness
The state of being serious is seriousness
The state of being connected is
2024-07-31 03:50:52 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 03:52:47 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3823, -0.1471,  0.1119,  ...,  0.4709, -0.7188,  0.3191],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.2417, -1.6914, -1.9453,  ...,  1.8867, -1.2852, -1.8789],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.1091, -0.0019,  0.0108,  ...,  0.0132,  0.0020,  0.0080],
        [-0.0149,  0.0671,  0.0258,  ...,  0.0250,  0.0018, -0.0009],
        [ 0.0163,  0.0033,  0.0793,  ..., -0.0254, -0.0155,  0.0012],
        ...,
        [ 0.0159,  0.0104,  0.0125,  ...,  0.0966, -0.0050, -0.0143],
        [ 0.0081,  0.0134, -0.0045,  ..., -0.0247,  0.0725, -0.0163],
        [ 0.0062,  0.0012, -0.0081,  ..., -0.0067, -0.0174,  0.0879]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.3979, -1.4473, -1.8779,  ...,  1.4531, -1.4893, -2.0059]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 03:52:48 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The state of being prepared is preparedness
The state of being conscious is consciousness
The state of being hidden is hiddenness
The state of being massive is massiveness
The state of being reasonable is reasonableness
The state of being related is relatedness
The state of being serious is seriousness
The state of being connected is
2024-07-31 03:52:48 root INFO     total operator prediction time: 940.0477447509766 seconds
2024-07-31 03:52:48 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on re+verb_reg
2024-07-31 03:52:48 root INFO     building operator re+verb_reg
2024-07-31 03:52:48 root INFO     [order_1_approx] starting weight calculation for To arrange again is to rearrange
To appear again is to reappear
To locate again is to relocate
To assess again is to reassess
To write again is to rewrite
To appoint again is to reappoint
To deem again is to redeem
To evaluate again is to
2024-07-31 03:52:48 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 03:54:48 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1682, -0.1785, -0.2993,  ..., -0.1724, -0.4656,  0.0305],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.2893, -1.5762,  0.9399,  ..., -0.6792, -3.3613, -4.6367],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0577, -0.0004,  0.0221,  ..., -0.0049,  0.0002,  0.0166],
        [ 0.0061,  0.0460, -0.0062,  ...,  0.0031,  0.0048,  0.0077],
        [ 0.0049,  0.0017,  0.0513,  ..., -0.0153,  0.0104, -0.0157],
        ...,
        [ 0.0144,  0.0030, -0.0061,  ...,  0.0746, -0.0057,  0.0023],
        [-0.0091,  0.0232,  0.0187,  ...,  0.0048,  0.0532, -0.0132],
        [-0.0077,  0.0064, -0.0005,  ..., -0.0026, -0.0162,  0.0491]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.2156, -1.6865,  0.8901,  ..., -0.6104, -3.5195, -4.3750]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 03:54:49 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To arrange again is to rearrange
To appear again is to reappear
To locate again is to relocate
To assess again is to reassess
To write again is to rewrite
To appoint again is to reappoint
To deem again is to redeem
To evaluate again is to
2024-07-31 03:54:49 root INFO     [order_1_approx] starting weight calculation for To deem again is to redeem
To arrange again is to rearrange
To appear again is to reappear
To write again is to rewrite
To appoint again is to reappoint
To assess again is to reassess
To evaluate again is to reevaluate
To locate again is to
2024-07-31 03:54:49 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 03:56:45 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1193,  0.6987, -0.8662,  ...,  0.1071, -0.2974,  0.0771],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.2998, -2.2715, -0.1133,  ...,  0.6104, -3.7188, -3.7227],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 9.0637e-02, -2.0294e-02,  2.3514e-02,  ...,  3.7766e-03,
          3.2291e-03,  2.3346e-02],
        [-1.3084e-03,  5.3131e-02, -2.9488e-03,  ...,  1.1009e-02,
         -5.8060e-03, -2.8992e-04],
        [ 6.2408e-03,  1.2505e-02,  5.6366e-02,  ..., -2.8259e-02,
         -3.0346e-03, -1.6113e-02],
        ...,
        [ 4.6921e-04, -7.6294e-06, -5.2948e-03,  ...,  6.7383e-02,
         -1.1597e-02, -4.2992e-03],
        [ 1.1536e-02,  2.1881e-02,  1.8494e-02,  ...,  5.6458e-04,
          4.8065e-02, -1.2604e-02],
        [-2.7504e-03,  1.1047e-02, -1.8417e-02,  ..., -5.7793e-03,
         -2.8534e-02,  6.6650e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.9248, -2.2227,  0.2158,  ...,  0.5381, -3.7090, -3.5781]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 03:56:46 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To deem again is to redeem
To arrange again is to rearrange
To appear again is to reappear
To write again is to rewrite
To appoint again is to reappoint
To assess again is to reassess
To evaluate again is to reevaluate
To locate again is to
2024-07-31 03:56:46 root INFO     [order_1_approx] starting weight calculation for To deem again is to redeem
To appear again is to reappear
To evaluate again is to reevaluate
To locate again is to relocate
To appoint again is to reappoint
To write again is to rewrite
To assess again is to reassess
To arrange again is to
2024-07-31 03:56:46 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 03:58:40 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.8140,  0.2837, -0.0720,  ..., -0.8408, -0.2311, -0.1965],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.6089, -2.5742, -0.8345,  ...,  2.6914, -3.2480, -4.5781],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0917, -0.0088,  0.0001,  ..., -0.0043,  0.0007,  0.0165],
        [-0.0099,  0.0730, -0.0074,  ...,  0.0154,  0.0109,  0.0077],
        [ 0.0104,  0.0110,  0.0759,  ..., -0.0265, -0.0021, -0.0170],
        ...,
        [ 0.0050, -0.0144, -0.0095,  ...,  0.0988, -0.0098, -0.0042],
        [-0.0117,  0.0292,  0.0162,  ..., -0.0014,  0.0898, -0.0163],
        [ 0.0048, -0.0014, -0.0247,  ..., -0.0098, -0.0255,  0.0856]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.4541, -2.8203, -0.6450,  ...,  2.7109, -3.2715, -4.4609]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 03:58:42 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To deem again is to redeem
To appear again is to reappear
To evaluate again is to reevaluate
To locate again is to relocate
To appoint again is to reappoint
To write again is to rewrite
To assess again is to reassess
To arrange again is to
2024-07-31 03:58:43 root INFO     [order_1_approx] starting weight calculation for To assess again is to reassess
To appoint again is to reappoint
To evaluate again is to reevaluate
To write again is to rewrite
To locate again is to relocate
To arrange again is to rearrange
To deem again is to redeem
To appear again is to
2024-07-31 03:58:43 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 04:00:40 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2759,  0.1945, -0.4634,  ..., -0.3345, -0.3181, -0.4827],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.2998, -1.4404, -0.6436,  ...,  3.6230, -5.0664, -3.1484],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0997,  0.0045,  0.0128,  ..., -0.0027,  0.0118,  0.0191],
        [-0.0151,  0.0543, -0.0058,  ...,  0.0138,  0.0017, -0.0003],
        [ 0.0090, -0.0031,  0.0869,  ..., -0.0006, -0.0090, -0.0189],
        ...,
        [-0.0108, -0.0095, -0.0046,  ...,  0.0820, -0.0264,  0.0022],
        [-0.0035,  0.0377,  0.0161,  ..., -0.0054,  0.0789, -0.0213],
        [ 0.0061, -0.0028, -0.0090,  ..., -0.0087, -0.0223,  0.0844]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.0564, -1.4307, -0.4607,  ...,  3.7715, -5.2109, -2.9688]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 04:00:41 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To assess again is to reassess
To appoint again is to reappoint
To evaluate again is to reevaluate
To write again is to rewrite
To locate again is to relocate
To arrange again is to rearrange
To deem again is to redeem
To appear again is to
2024-07-31 04:00:41 root INFO     [order_1_approx] starting weight calculation for To write again is to rewrite
To deem again is to redeem
To evaluate again is to reevaluate
To locate again is to relocate
To arrange again is to rearrange
To assess again is to reassess
To appear again is to reappear
To appoint again is to
2024-07-31 04:00:41 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 04:02:40 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2915,  0.2773, -0.7432,  ...,  0.1902, -0.8247, -0.1456],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.3633, -3.5996, -1.0898,  ...,  2.6016, -4.5234, -4.8516],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0540, -0.0079,  0.0083,  ..., -0.0079, -0.0093,  0.0105],
        [ 0.0089,  0.0388, -0.0010,  ...,  0.0157,  0.0044, -0.0027],
        [ 0.0111,  0.0070,  0.0333,  ..., -0.0133, -0.0074, -0.0038],
        ...,
        [ 0.0023, -0.0058, -0.0125,  ...,  0.0593, -0.0076,  0.0098],
        [-0.0095,  0.0155,  0.0095,  ..., -0.0074,  0.0380, -0.0207],
        [ 0.0186,  0.0052, -0.0161,  ..., -0.0079, -0.0223,  0.0566]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.0330, -3.3906, -1.1230,  ...,  2.6348, -4.5156, -4.7734]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 04:02:41 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To write again is to rewrite
To deem again is to redeem
To evaluate again is to reevaluate
To locate again is to relocate
To arrange again is to rearrange
To assess again is to reassess
To appear again is to reappear
To appoint again is to
2024-07-31 04:02:41 root INFO     [order_1_approx] starting weight calculation for To deem again is to redeem
To assess again is to reassess
To evaluate again is to reevaluate
To appear again is to reappear
To arrange again is to rearrange
To locate again is to relocate
To appoint again is to reappoint
To write again is to
2024-07-31 04:02:42 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 04:04:38 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.3774, -0.1390,  0.2207,  ..., -0.6812, -0.7769,  0.1150],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.5244, -2.5039,  0.1270,  ...,  1.8311, -4.8398, -3.1953],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 7.1106e-02, -3.8433e-03,  8.9569e-03,  ...,  9.7847e-04,
         -3.4866e-03,  1.5450e-02],
        [-2.7332e-03,  7.2998e-02, -5.2223e-03,  ..., -1.5049e-03,
          4.8752e-03,  1.3916e-02],
        [ 2.8458e-03, -1.7609e-02,  5.7648e-02,  ..., -1.7487e-02,
         -2.5711e-03, -1.5259e-05],
        ...,
        [ 1.5099e-02, -9.3918e-03,  1.1311e-03,  ...,  7.4097e-02,
         -9.2239e-03,  9.7885e-03],
        [ 3.2272e-03,  1.1406e-02,  1.2344e-02,  ..., -1.2711e-02,
          4.7028e-02, -9.4147e-03],
        [ 5.3329e-03,  4.7226e-03, -3.9043e-03,  ...,  2.4338e-03,
         -2.3636e-02,  7.0679e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.4619, -2.6641,  0.1929,  ...,  2.0039, -5.0352, -3.1797]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 04:04:39 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To deem again is to redeem
To assess again is to reassess
To evaluate again is to reevaluate
To appear again is to reappear
To arrange again is to rearrange
To locate again is to relocate
To appoint again is to reappoint
To write again is to
2024-07-31 04:04:39 root INFO     [order_1_approx] starting weight calculation for To assess again is to reassess
To write again is to rewrite
To locate again is to relocate
To evaluate again is to reevaluate
To appoint again is to reappoint
To appear again is to reappear
To arrange again is to rearrange
To deem again is to
2024-07-31 04:04:39 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 04:06:36 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3630, -0.0698, -0.1285,  ..., -0.0974, -0.9873,  0.7217],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.2461, -3.4375,  0.6948,  ...,  0.5527, -5.4219, -2.9082],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.1050, -0.0187,  0.0247,  ...,  0.0006,  0.0048,  0.0158],
        [ 0.0032,  0.0649, -0.0083,  ...,  0.0153,  0.0046,  0.0010],
        [ 0.0049, -0.0016,  0.0619,  ..., -0.0144, -0.0067, -0.0190],
        ...,
        [ 0.0205,  0.0211, -0.0067,  ...,  0.0911, -0.0106,  0.0023],
        [-0.0041,  0.0175,  0.0185,  ...,  0.0107,  0.0925, -0.0160],
        [-0.0013,  0.0187, -0.0154,  ..., -0.0129, -0.0145,  0.0966]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.3125, -3.2949,  0.6523,  ...,  0.7085, -5.2930, -3.1133]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 04:06:37 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To assess again is to reassess
To write again is to rewrite
To locate again is to relocate
To evaluate again is to reevaluate
To appoint again is to reappoint
To appear again is to reappear
To arrange again is to rearrange
To deem again is to
2024-07-31 04:06:37 root INFO     [order_1_approx] starting weight calculation for To appear again is to reappear
To appoint again is to reappoint
To locate again is to relocate
To write again is to rewrite
To evaluate again is to reevaluate
To deem again is to redeem
To arrange again is to rearrange
To assess again is to
2024-07-31 04:06:37 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 04:08:36 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2190, -0.0447, -0.1112,  ...,  0.0027, -0.4009, -0.2469],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.9902, -1.2275, -0.7964,  ...,  0.3789, -4.9648, -4.3281],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0763, -0.0019,  0.0197,  ..., -0.0123, -0.0036,  0.0087],
        [ 0.0083,  0.0563,  0.0034,  ...,  0.0080,  0.0049,  0.0033],
        [-0.0061,  0.0020,  0.0625,  ..., -0.0144,  0.0117, -0.0140],
        ...,
        [ 0.0200,  0.0047, -0.0096,  ...,  0.0901, -0.0054,  0.0029],
        [-0.0143,  0.0132,  0.0270,  ...,  0.0175,  0.0715, -0.0102],
        [-0.0045,  0.0221, -0.0106,  ..., -0.0168, -0.0137,  0.0630]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.7588, -1.2832, -0.3755,  ...,  0.4373, -4.7891, -4.4023]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 04:08:36 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To appear again is to reappear
To appoint again is to reappoint
To locate again is to relocate
To write again is to rewrite
To evaluate again is to reevaluate
To deem again is to redeem
To arrange again is to rearrange
To assess again is to
2024-07-31 04:08:36 root INFO     total operator prediction time: 948.6949234008789 seconds
2024-07-31 04:08:36 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on un+adj_reg
2024-07-31 04:08:36 root INFO     building operator un+adj_reg
2024-07-31 04:08:37 root INFO     [order_1_approx] starting weight calculation for The opposite of interrupted is uninterrupted
The opposite of biased is unbiased
The opposite of published is unpublished
The opposite of suitable is unsuitable
The opposite of related is unrelated
The opposite of conditional is unconditional
The opposite of used is unused
The opposite of forgettable is
2024-07-31 04:08:37 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 04:10:29 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.7202,  0.0461, -0.4771,  ..., -0.5625, -0.4661,  0.3682],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.5752, -0.4980, -2.1992,  ..., -0.4963, -5.5469, -4.1172],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0851,  0.0060,  0.0155,  ..., -0.0121,  0.0083,  0.0475],
        [-0.0131,  0.0956,  0.0013,  ...,  0.0276, -0.0065, -0.0087],
        [ 0.0162,  0.0132,  0.0712,  ..., -0.0312, -0.0156, -0.0159],
        ...,
        [-0.0051,  0.0107, -0.0019,  ...,  0.0795, -0.0104, -0.0330],
        [ 0.0130,  0.0173,  0.0204,  ..., -0.0208,  0.0671, -0.0118],
        [ 0.0031,  0.0041, -0.0183,  ..., -0.0077, -0.0008,  0.0673]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.8594, -0.3540, -1.9062,  ...,  0.1731, -5.5117, -3.9434]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 04:10:30 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of interrupted is uninterrupted
The opposite of biased is unbiased
The opposite of published is unpublished
The opposite of suitable is unsuitable
The opposite of related is unrelated
The opposite of conditional is unconditional
The opposite of used is unused
The opposite of forgettable is
2024-07-31 04:10:30 root INFO     [order_1_approx] starting weight calculation for The opposite of interrupted is uninterrupted
The opposite of biased is unbiased
The opposite of related is unrelated
The opposite of forgettable is unforgettable
The opposite of used is unused
The opposite of suitable is unsuitable
The opposite of published is unpublished
The opposite of conditional is
2024-07-31 04:10:30 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 04:12:28 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3945,  0.1929, -0.4255,  ..., -0.6680, -0.3447, -0.1887],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.8501, -1.6465,  0.9033,  ...,  0.9102, -1.1514, -1.7910],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0909,  0.0214, -0.0026,  ..., -0.0029,  0.0229,  0.0106],
        [-0.0229,  0.0822, -0.0243,  ...,  0.0008, -0.0226,  0.0034],
        [-0.0269, -0.0185,  0.0603,  ..., -0.0342,  0.0033,  0.0010],
        ...,
        [ 0.0186,  0.0459, -0.0149,  ...,  0.0865, -0.0211, -0.0267],
        [ 0.0114, -0.0030,  0.0205,  ..., -0.0047,  0.0692,  0.0103],
        [ 0.0005, -0.0062, -0.0116,  ..., -0.0226, -0.0106,  0.0981]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.5215, -0.8418,  0.9390,  ...,  1.5859, -1.5801, -1.7734]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 04:12:29 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of interrupted is uninterrupted
The opposite of biased is unbiased
The opposite of related is unrelated
The opposite of forgettable is unforgettable
The opposite of used is unused
The opposite of suitable is unsuitable
The opposite of published is unpublished
The opposite of conditional is
2024-07-31 04:12:29 root INFO     [order_1_approx] starting weight calculation for The opposite of related is unrelated
The opposite of interrupted is uninterrupted
The opposite of biased is unbiased
The opposite of used is unused
The opposite of forgettable is unforgettable
The opposite of suitable is unsuitable
The opposite of conditional is unconditional
The opposite of published is
2024-07-31 04:12:29 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 04:14:29 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1682,  0.2617, -0.2749,  ...,  0.2449, -0.0748,  0.5288],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.7612, -1.6113, -0.4561,  ..., -1.7412, -2.1191,  1.1982],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0844, -0.0183,  0.0078,  ...,  0.0010,  0.0067,  0.0316],
        [-0.0135,  0.0801, -0.0011,  ...,  0.0216,  0.0027, -0.0019],
        [-0.0121, -0.0134,  0.0765,  ..., -0.0131,  0.0033, -0.0207],
        ...,
        [-0.0037,  0.0114, -0.0193,  ...,  0.0601, -0.0056, -0.0108],
        [-0.0167,  0.0070,  0.0479,  ...,  0.0211,  0.0658, -0.0020],
        [ 0.0181,  0.0050, -0.0205,  ..., -0.0394, -0.0078,  0.0901]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.2158, -1.4609, -0.6597,  ..., -1.1367, -2.5840,  1.2949]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 04:14:30 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of related is unrelated
The opposite of interrupted is uninterrupted
The opposite of biased is unbiased
The opposite of used is unused
The opposite of forgettable is unforgettable
The opposite of suitable is unsuitable
The opposite of conditional is unconditional
The opposite of published is
2024-07-31 04:14:30 root INFO     [order_1_approx] starting weight calculation for The opposite of related is unrelated
The opposite of used is unused
The opposite of interrupted is uninterrupted
The opposite of published is unpublished
The opposite of conditional is unconditional
The opposite of suitable is unsuitable
The opposite of forgettable is unforgettable
The opposite of biased is
2024-07-31 04:14:30 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 04:16:28 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4167, -0.6406, -0.7051,  ...,  1.0000, -0.3501,  0.4683],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.8984, -0.7988, -1.7520,  ..., -0.7939, -3.7031, -2.9824],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0702, -0.0191,  0.0101,  ...,  0.0115,  0.0169,  0.0193],
        [-0.0223,  0.0760,  0.0094,  ...,  0.0099, -0.0011,  0.0023],
        [ 0.0017, -0.0109,  0.0473,  ..., -0.0039,  0.0109,  0.0018],
        ...,
        [ 0.0188,  0.0331,  0.0138,  ...,  0.0646, -0.0023, -0.0044],
        [-0.0007,  0.0092,  0.0096,  ..., -0.0212,  0.0471,  0.0065],
        [-0.0022, -0.0025,  0.0349,  ..., -0.0092,  0.0114,  0.0598]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.8691, -0.4319, -1.6553,  ..., -0.3088, -3.9297, -3.0586]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 04:16:29 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of related is unrelated
The opposite of used is unused
The opposite of interrupted is uninterrupted
The opposite of published is unpublished
The opposite of conditional is unconditional
The opposite of suitable is unsuitable
The opposite of forgettable is unforgettable
The opposite of biased is
2024-07-31 04:16:29 root INFO     [order_1_approx] starting weight calculation for The opposite of biased is unbiased
The opposite of interrupted is uninterrupted
The opposite of conditional is unconditional
The opposite of published is unpublished
The opposite of forgettable is unforgettable
The opposite of related is unrelated
The opposite of suitable is unsuitable
The opposite of used is
2024-07-31 04:16:29 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 04:18:26 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0767, -0.0695, -0.1200,  ..., -0.4631, -0.6279,  0.1343],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.0439, -1.6250, -0.4160,  ..., -1.1533, -1.8643, -2.0527],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0665, -0.0357, -0.0049,  ..., -0.0114,  0.0080,  0.0269],
        [-0.0050,  0.0988,  0.0051,  ...,  0.0296,  0.0061,  0.0023],
        [-0.0096,  0.0055,  0.0764,  ..., -0.0245, -0.0070, -0.0112],
        ...,
        [-0.0020,  0.0048, -0.0038,  ...,  0.0630, -0.0372, -0.0315],
        [-0.0117, -0.0155,  0.0088,  ..., -0.0282,  0.0709,  0.0101],
        [ 0.0209,  0.0293, -0.0267,  ..., -0.0345,  0.0083,  0.0973]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.1182, -1.4463, -0.8379,  ..., -0.6758, -1.9492, -1.7910]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 04:18:27 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of biased is unbiased
The opposite of interrupted is uninterrupted
The opposite of conditional is unconditional
The opposite of published is unpublished
The opposite of forgettable is unforgettable
The opposite of related is unrelated
The opposite of suitable is unsuitable
The opposite of used is
2024-07-31 04:18:27 root INFO     [order_1_approx] starting weight calculation for The opposite of related is unrelated
The opposite of used is unused
The opposite of conditional is unconditional
The opposite of biased is unbiased
The opposite of forgettable is unforgettable
The opposite of published is unpublished
The opposite of suitable is unsuitable
The opposite of interrupted is
2024-07-31 04:18:27 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 04:20:24 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1086,  0.0687, -0.1841,  ...,  0.1515, -0.5107,  0.2279],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.6465,  0.6963, -0.6860,  ...,  0.3003, -2.2383, -0.9932],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0759, -0.0099,  0.0085,  ..., -0.0140,  0.0155,  0.0083],
        [-0.0035,  0.0743, -0.0205,  ...,  0.0467, -0.0071,  0.0139],
        [ 0.0007, -0.0341,  0.0684,  ..., -0.0099,  0.0077,  0.0057],
        ...,
        [ 0.0014,  0.0195, -0.0287,  ...,  0.0875, -0.0110, -0.0033],
        [ 0.0018, -0.0111,  0.0129,  ..., -0.0060,  0.0426,  0.0002],
        [ 0.0091,  0.0019, -0.0085,  ..., -0.0175,  0.0146,  0.0804]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.0273,  0.4592, -1.1992,  ...,  0.9097, -2.4434, -1.7607]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 04:20:25 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of related is unrelated
The opposite of used is unused
The opposite of conditional is unconditional
The opposite of biased is unbiased
The opposite of forgettable is unforgettable
The opposite of published is unpublished
The opposite of suitable is unsuitable
The opposite of interrupted is
2024-07-31 04:20:26 root INFO     [order_1_approx] starting weight calculation for The opposite of biased is unbiased
The opposite of conditional is unconditional
The opposite of related is unrelated
The opposite of forgettable is unforgettable
The opposite of interrupted is uninterrupted
The opposite of used is unused
The opposite of published is unpublished
The opposite of suitable is
2024-07-31 04:20:26 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 04:22:26 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.3376, -0.3181,  0.1304,  ..., -0.2979, -0.1528, -0.1403],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.2266, -0.7080, -0.0244,  ...,  0.7935, -3.5840,  0.4590],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0958, -0.0271,  0.0072,  ..., -0.0132,  0.0169,  0.0353],
        [-0.0145,  0.0655, -0.0133,  ...,  0.0088, -0.0005,  0.0019],
        [-0.0163,  0.0064,  0.0755,  ..., -0.0272, -0.0305, -0.0078],
        ...,
        [-0.0064,  0.0041, -0.0242,  ...,  0.0860,  0.0041, -0.0194],
        [-0.0230,  0.0044,  0.0207,  ..., -0.0033,  0.0588,  0.0015],
        [-0.0029, -0.0025, -0.0413,  ...,  0.0026, -0.0079,  0.0850]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.3828, -0.8149, -0.2124,  ...,  0.7944, -2.6797,  0.0938]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 04:22:27 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of biased is unbiased
The opposite of conditional is unconditional
The opposite of related is unrelated
The opposite of forgettable is unforgettable
The opposite of interrupted is uninterrupted
The opposite of used is unused
The opposite of published is unpublished
The opposite of suitable is
2024-07-31 04:22:27 root INFO     [order_1_approx] starting weight calculation for The opposite of forgettable is unforgettable
The opposite of suitable is unsuitable
The opposite of published is unpublished
The opposite of biased is unbiased
The opposite of used is unused
The opposite of conditional is unconditional
The opposite of interrupted is uninterrupted
The opposite of related is
2024-07-31 04:22:27 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 04:24:26 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1146, -0.0490, -0.4226,  ..., -0.5342, -0.1232, -0.5015],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.2031,  0.5269, -0.6387,  ..., -0.4631,  0.3301, -3.1094],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0637, -0.0089,  0.0290,  ...,  0.0002,  0.0303,  0.0219],
        [-0.0238,  0.0693, -0.0116,  ...,  0.0184, -0.0138, -0.0020],
        [-0.0081, -0.0159,  0.0662,  ...,  0.0043, -0.0015, -0.0122],
        ...,
        [ 0.0065,  0.0299, -0.0189,  ...,  0.0697, -0.0028, -0.0116],
        [ 0.0121, -0.0020,  0.0161,  ..., -0.0075,  0.0549,  0.0013],
        [ 0.0114, -0.0047, -0.0018,  ..., -0.0197, -0.0088,  0.0730]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.3496,  0.6099, -0.4341,  ..., -0.2400, -0.2236, -3.0840]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 04:24:27 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of forgettable is unforgettable
The opposite of suitable is unsuitable
The opposite of published is unpublished
The opposite of biased is unbiased
The opposite of used is unused
The opposite of conditional is unconditional
The opposite of interrupted is uninterrupted
The opposite of related is
2024-07-31 04:24:27 root INFO     total operator prediction time: 950.8628587722778 seconds
2024-07-31 04:24:27 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on verb+able_reg
2024-07-31 04:24:27 root INFO     building operator verb+able_reg
2024-07-31 04:24:27 root INFO     [order_1_approx] starting weight calculation for If you can execute something, that thing is executable
If you can maintain something, that thing is maintainable
If you can rely something, that thing is reliable
If you can recognize something, that thing is recognizable
If you can expand something, that thing is expandable
If you can accept something, that thing is acceptable
If you can adore something, that thing is adorable
If you can contain something, that thing is
2024-07-31 04:24:28 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 04:26:21 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0696, -0.4309, -0.6592,  ...,  0.3152,  0.5073, -0.0420],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.1836,  0.8418, -0.4033,  ..., -4.3477, -5.2383, -2.7695],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0627, -0.0012,  0.0047,  ..., -0.0123,  0.0074,  0.0372],
        [-0.0050,  0.0481, -0.0004,  ...,  0.0133, -0.0046, -0.0150],
        [-0.0050, -0.0100,  0.0558,  ..., -0.0086, -0.0170, -0.0270],
        ...,
        [ 0.0007,  0.0076,  0.0146,  ...,  0.0561,  0.0056,  0.0029],
        [ 0.0205,  0.0019,  0.0037,  ..., -0.0067,  0.0584,  0.0077],
        [-0.0065,  0.0025, -0.0070,  ..., -0.0198, -0.0133,  0.0439]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.2529,  0.9932,  0.0444,  ..., -4.1914, -5.1016, -2.7832]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 04:26:22 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you can execute something, that thing is executable
If you can maintain something, that thing is maintainable
If you can rely something, that thing is reliable
If you can recognize something, that thing is recognizable
If you can expand something, that thing is expandable
If you can accept something, that thing is acceptable
If you can adore something, that thing is adorable
If you can contain something, that thing is
2024-07-31 04:26:22 root INFO     [order_1_approx] starting weight calculation for If you can recognize something, that thing is recognizable
If you can expand something, that thing is expandable
If you can execute something, that thing is executable
If you can contain something, that thing is containable
If you can adore something, that thing is adorable
If you can rely something, that thing is reliable
If you can maintain something, that thing is maintainable
If you can accept something, that thing is
2024-07-31 04:26:22 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 04:28:15 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.3669,  0.2798, -0.4497,  ...,  0.3918, -0.4910,  0.2529],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.4316,  1.7461, -3.4668,  ..., -1.7295, -9.3438, -0.1621],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0624, -0.0040,  0.0043,  ..., -0.0053, -0.0034,  0.0199],
        [-0.0030,  0.0592, -0.0059,  ...,  0.0081,  0.0058, -0.0169],
        [ 0.0040, -0.0073,  0.0663,  ..., -0.0019, -0.0062, -0.0113],
        ...,
        [ 0.0119,  0.0116, -0.0079,  ...,  0.0627, -0.0083, -0.0143],
        [ 0.0054,  0.0118,  0.0124,  ..., -0.0172,  0.0597,  0.0036],
        [ 0.0047,  0.0091, -0.0141,  ..., -0.0174, -0.0122,  0.0485]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.1699,  1.5820, -3.5547,  ..., -1.9697, -9.0938, -0.6133]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 04:28:16 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you can recognize something, that thing is recognizable
If you can expand something, that thing is expandable
If you can execute something, that thing is executable
If you can contain something, that thing is containable
If you can adore something, that thing is adorable
If you can rely something, that thing is reliable
If you can maintain something, that thing is maintainable
If you can accept something, that thing is
2024-07-31 04:28:16 root INFO     [order_1_approx] starting weight calculation for If you can expand something, that thing is expandable
If you can adore something, that thing is adorable
If you can recognize something, that thing is recognizable
If you can contain something, that thing is containable
If you can maintain something, that thing is maintainable
If you can execute something, that thing is executable
If you can accept something, that thing is acceptable
If you can rely something, that thing is
2024-07-31 04:28:16 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 04:30:14 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.3650, -0.4021,  0.0782,  ..., -0.2437, -0.3862, -0.3857],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.6328,  0.3704, -1.8477,  ..., -2.6641, -6.4102, -2.0781],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0687, -0.0197,  0.0004,  ..., -0.0076,  0.0185,  0.0213],
        [ 0.0109,  0.0627, -0.0055,  ...,  0.0130,  0.0091, -0.0085],
        [-0.0011, -0.0106,  0.0595,  ..., -0.0001, -0.0079, -0.0195],
        ...,
        [ 0.0009,  0.0198,  0.0022,  ...,  0.0712, -0.0044, -0.0026],
        [ 0.0188,  0.0096,  0.0033,  ..., -0.0083,  0.0610, -0.0049],
        [-0.0041,  0.0028, -0.0244,  ..., -0.0143, -0.0024,  0.0471]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.8770,  0.5049, -2.0566,  ..., -3.0781, -6.5352, -2.7832]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 04:30:15 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you can expand something, that thing is expandable
If you can adore something, that thing is adorable
If you can recognize something, that thing is recognizable
If you can contain something, that thing is containable
If you can maintain something, that thing is maintainable
If you can execute something, that thing is executable
If you can accept something, that thing is acceptable
If you can rely something, that thing is
2024-07-31 04:30:15 root INFO     [order_1_approx] starting weight calculation for If you can contain something, that thing is containable
If you can accept something, that thing is acceptable
If you can execute something, that thing is executable
If you can maintain something, that thing is maintainable
If you can adore something, that thing is adorable
If you can recognize something, that thing is recognizable
If you can rely something, that thing is reliable
If you can expand something, that thing is
2024-07-31 04:30:15 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 04:32:11 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.5649, -0.2109, -0.2050,  ...,  0.0641, -0.3206,  0.2708],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.4883, -0.1660, -0.3306,  ..., -2.5781, -8.8906, -3.1250],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0699, -0.0058,  0.0052,  ...,  0.0107,  0.0111,  0.0296],
        [ 0.0096,  0.0659, -0.0013,  ...,  0.0071,  0.0082, -0.0045],
        [ 0.0044, -0.0162,  0.0728,  ..., -0.0050, -0.0023, -0.0165],
        ...,
        [ 0.0192,  0.0232, -0.0043,  ...,  0.0785,  0.0010, -0.0008],
        [ 0.0085,  0.0040,  0.0224,  ..., -0.0191,  0.0702,  0.0136],
        [-0.0005,  0.0070, -0.0259,  ..., -0.0247, -0.0068,  0.0686]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.5156, -0.0901, -0.1090,  ..., -2.7285, -8.7422, -3.2070]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 04:32:12 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you can contain something, that thing is containable
If you can accept something, that thing is acceptable
If you can execute something, that thing is executable
If you can maintain something, that thing is maintainable
If you can adore something, that thing is adorable
If you can recognize something, that thing is recognizable
If you can rely something, that thing is reliable
If you can expand something, that thing is
2024-07-31 04:32:12 root INFO     [order_1_approx] starting weight calculation for If you can maintain something, that thing is maintainable
If you can recognize something, that thing is recognizable
If you can expand something, that thing is expandable
If you can accept something, that thing is acceptable
If you can contain something, that thing is containable
If you can rely something, that thing is reliable
If you can adore something, that thing is adorable
If you can execute something, that thing is
2024-07-31 04:32:12 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 04:34:11 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0897,  0.0986,  0.2009,  ...,  0.2925, -0.2996, -0.2012],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.8125, -0.1445,  1.5615,  ..., -1.6396, -9.0781, -4.5820],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0651, -0.0029,  0.0058,  ...,  0.0051, -0.0034,  0.0288],
        [ 0.0031,  0.0713,  0.0003,  ...,  0.0108,  0.0070, -0.0017],
        [ 0.0050, -0.0117,  0.0503,  ..., -0.0069,  0.0118, -0.0155],
        ...,
        [-0.0027,  0.0173, -0.0090,  ...,  0.0768,  0.0021, -0.0097],
        [ 0.0029,  0.0143,  0.0184,  ..., -0.0083,  0.0536, -0.0094],
        [-0.0024, -0.0037, -0.0056,  ..., -0.0077, -0.0146,  0.0620]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.1855,  0.0493,  1.7109,  ..., -1.7646, -8.7422, -4.4297]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 04:34:11 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you can maintain something, that thing is maintainable
If you can recognize something, that thing is recognizable
If you can expand something, that thing is expandable
If you can accept something, that thing is acceptable
If you can contain something, that thing is containable
If you can rely something, that thing is reliable
If you can adore something, that thing is adorable
If you can execute something, that thing is
2024-07-31 04:34:12 root INFO     [order_1_approx] starting weight calculation for If you can contain something, that thing is containable
If you can execute something, that thing is executable
If you can accept something, that thing is acceptable
If you can expand something, that thing is expandable
If you can maintain something, that thing is maintainable
If you can rely something, that thing is reliable
If you can recognize something, that thing is recognizable
If you can adore something, that thing is
2024-07-31 04:34:12 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 04:36:11 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0251,  0.1774, -0.0487,  ...,  0.1819, -0.0335,  0.5298],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.4570,  0.8916, -5.2109,  ..., -2.7930, -6.9180, -0.7334],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0657,  0.0084,  0.0025,  ..., -0.0081, -0.0042,  0.0055],
        [ 0.0024,  0.0502, -0.0013,  ...,  0.0149,  0.0056,  0.0046],
        [ 0.0176,  0.0013,  0.0557,  ...,  0.0184, -0.0109, -0.0126],
        ...,
        [ 0.0198,  0.0194, -0.0138,  ...,  0.0531,  0.0047,  0.0009],
        [-0.0016, -0.0014,  0.0112,  ..., -0.0110,  0.0426,  0.0125],
        [-0.0058, -0.0050, -0.0139,  ..., -0.0052, -0.0128,  0.0389]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.0762,  0.7402, -5.0664,  ..., -2.5293, -7.0273, -0.4248]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 04:36:11 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you can contain something, that thing is containable
If you can execute something, that thing is executable
If you can accept something, that thing is acceptable
If you can expand something, that thing is expandable
If you can maintain something, that thing is maintainable
If you can rely something, that thing is reliable
If you can recognize something, that thing is recognizable
If you can adore something, that thing is
2024-07-31 04:36:12 root INFO     [order_1_approx] starting weight calculation for If you can adore something, that thing is adorable
If you can accept something, that thing is acceptable
If you can execute something, that thing is executable
If you can expand something, that thing is expandable
If you can contain something, that thing is containable
If you can rely something, that thing is reliable
If you can recognize something, that thing is recognizable
If you can maintain something, that thing is
2024-07-31 04:36:12 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 04:38:10 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1533, -0.3303, -0.0701,  ...,  0.4766, -0.6172,  0.2644],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.0654,  0.2441, -3.3672,  ..., -4.1328, -6.0625, -1.1289],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0805, -0.0066,  0.0018,  ...,  0.0116, -0.0047,  0.0205],
        [ 0.0067,  0.0683,  0.0045,  ...,  0.0055,  0.0124, -0.0047],
        [ 0.0134, -0.0061,  0.0759,  ..., -0.0094, -0.0087, -0.0246],
        ...,
        [ 0.0145,  0.0206,  0.0071,  ...,  0.0718, -0.0044,  0.0016],
        [ 0.0238,  0.0114,  0.0088,  ..., -0.0168,  0.0543, -0.0065],
        [-0.0114,  0.0063, -0.0141,  ..., -0.0098,  0.0009,  0.0508]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.1777,  0.3418, -3.2949,  ..., -4.2852, -6.1094, -1.4180]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 04:38:11 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you can adore something, that thing is adorable
If you can accept something, that thing is acceptable
If you can execute something, that thing is executable
If you can expand something, that thing is expandable
If you can contain something, that thing is containable
If you can rely something, that thing is reliable
If you can recognize something, that thing is recognizable
If you can maintain something, that thing is
2024-07-31 04:38:11 root INFO     [order_1_approx] starting weight calculation for If you can execute something, that thing is executable
If you can adore something, that thing is adorable
If you can expand something, that thing is expandable
If you can accept something, that thing is acceptable
If you can rely something, that thing is reliable
If you can contain something, that thing is containable
If you can maintain something, that thing is maintainable
If you can recognize something, that thing is
2024-07-31 04:38:11 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 04:40:06 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.6367,  0.2644,  0.1672,  ...,  0.2478, -0.3171, -0.2783],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-2.9473,  0.8672, -1.7158,  ..., -3.1250, -7.7812, -0.5225],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0880, -0.0080,  0.0125,  ..., -0.0016,  0.0054,  0.0161],
        [-0.0047,  0.0731,  0.0052,  ...,  0.0165,  0.0079, -0.0060],
        [-0.0060, -0.0165,  0.0914,  ..., -0.0047, -0.0020, -0.0102],
        ...,
        [ 0.0077,  0.0155,  0.0060,  ...,  0.1075, -0.0133,  0.0018],
        [ 0.0038,  0.0228,  0.0207,  ..., -0.0057,  0.0732, -0.0068],
        [-0.0011, -0.0009, -0.0101,  ...,  0.0060, -0.0178,  0.0750]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-3.0156,  0.7998, -1.4043,  ..., -3.0957, -7.3438, -0.5571]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 04:40:07 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you can execute something, that thing is executable
If you can adore something, that thing is adorable
If you can expand something, that thing is expandable
If you can accept something, that thing is acceptable
If you can rely something, that thing is reliable
If you can contain something, that thing is containable
If you can maintain something, that thing is maintainable
If you can recognize something, that thing is
2024-07-31 04:40:07 root INFO     total operator prediction time: 940.1114983558655 seconds
2024-07-31 04:40:07 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on verb+tion_irreg
2024-07-31 04:40:07 root INFO     building operator verb+tion_irreg
2024-07-31 04:40:08 root INFO     [order_1_approx] starting weight calculation for To minimize results in minimization
To maximize results in maximization
To declare results in declaration
To starve results in starvation
To stabilize results in stabilization
To optimize results in optimization
To aspire results in aspiration
To specialize results in
2024-07-31 04:40:08 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 04:42:04 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4224,  0.0115, -0.5547,  ..., -0.2698,  0.0225, -0.4844],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.6680, -1.8369,  0.8086,  ...,  2.1367, -3.1250, -3.8086],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.1080, -0.0028,  0.0039,  ..., -0.0089, -0.0024,  0.0014],
        [-0.0133,  0.1036,  0.0144,  ...,  0.0206,  0.0010,  0.0134],
        [-0.0093, -0.0171,  0.0959,  ...,  0.0013,  0.0177, -0.0076],
        ...,
        [ 0.0031,  0.0169, -0.0010,  ...,  0.1164, -0.0064,  0.0091],
        [-0.0021,  0.0042,  0.0187,  ...,  0.0154,  0.1010, -0.0204],
        [ 0.0039, -0.0042, -0.0055,  ..., -0.0047, -0.0224,  0.0984]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.6855, -1.4873,  0.7417,  ...,  2.0645, -3.2520, -3.7539]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 04:42:05 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To minimize results in minimization
To maximize results in maximization
To declare results in declaration
To starve results in starvation
To stabilize results in stabilization
To optimize results in optimization
To aspire results in aspiration
To specialize results in
2024-07-31 04:42:05 root INFO     [order_1_approx] starting weight calculation for To declare results in declaration
To stabilize results in stabilization
To optimize results in optimization
To specialize results in specialization
To maximize results in maximization
To aspire results in aspiration
To starve results in starvation
To minimize results in
2024-07-31 04:42:05 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 04:44:03 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3467, -0.3064, -0.9888,  ..., -0.7515, -0.2227, -0.4888],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.1475, -0.6514,  1.3232,  ..., -1.6787, -3.7266, -4.0156],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0347, -0.0021, -0.0090,  ...,  0.0015,  0.0025, -0.0083],
        [-0.0013,  0.0460,  0.0079,  ...,  0.0073,  0.0001,  0.0121],
        [-0.0021, -0.0151,  0.0371,  ..., -0.0051,  0.0042, -0.0016],
        ...,
        [ 0.0004,  0.0113, -0.0015,  ...,  0.0379, -0.0003,  0.0131],
        [-0.0003,  0.0048,  0.0021,  ...,  0.0039,  0.0426, -0.0030],
        [-0.0014,  0.0066, -0.0014,  ..., -0.0079, -0.0077,  0.0452]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.0500, -0.3796,  1.5986,  ..., -1.4238, -3.8594, -3.8105]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 04:44:04 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To declare results in declaration
To stabilize results in stabilization
To optimize results in optimization
To specialize results in specialization
To maximize results in maximization
To aspire results in aspiration
To starve results in starvation
To minimize results in
2024-07-31 04:44:04 root INFO     [order_1_approx] starting weight calculation for To starve results in starvation
To maximize results in maximization
To stabilize results in stabilization
To specialize results in specialization
To declare results in declaration
To minimize results in minimization
To aspire results in aspiration
To optimize results in
2024-07-31 04:44:04 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 04:46:02 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1636, -0.3276, -1.1240,  ..., -0.8711, -0.0972,  0.0441],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.3105, -1.7148, -0.2905,  ...,  0.8672, -2.1328, -1.8945],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 6.3416e-02,  5.1498e-04, -1.4114e-04,  ..., -2.3842e-03,
          2.2640e-03,  9.9487e-03],
        [-6.9542e-03,  6.6650e-02,  3.7766e-03,  ...,  2.3239e-02,
         -6.4087e-04,  2.0264e-02],
        [-2.7161e-03, -8.2169e-03,  4.0588e-02,  ..., -2.8477e-03,
         -3.9368e-03, -8.8501e-03],
        ...,
        [-9.1400e-03,  5.2261e-04, -3.8338e-04,  ...,  5.5786e-02,
          8.5449e-04,  1.4458e-03],
        [ 7.1335e-03,  1.0056e-02,  8.8806e-03,  ...,  3.4256e-03,
          6.8176e-02, -1.3535e-02],
        [ 1.9894e-03,  3.2425e-05, -4.8676e-03,  ..., -8.4686e-03,
         -1.5793e-02,  7.0068e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.4058, -1.3320, -0.0798,  ...,  0.7295, -2.5488, -1.6553]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 04:46:03 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To starve results in starvation
To maximize results in maximization
To stabilize results in stabilization
To specialize results in specialization
To declare results in declaration
To minimize results in minimization
To aspire results in aspiration
To optimize results in
2024-07-31 04:46:03 root INFO     [order_1_approx] starting weight calculation for To starve results in starvation
To specialize results in specialization
To optimize results in optimization
To stabilize results in stabilization
To declare results in declaration
To maximize results in maximization
To minimize results in minimization
To aspire results in
2024-07-31 04:46:03 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 04:48:02 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1343, -0.6470, -0.6992,  ..., -0.4443, -0.3315,  0.4219],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.9961, -2.8301,  1.6055,  ...,  2.1914, -3.9141, -0.9648],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0598, -0.0175, -0.0086,  ...,  0.0003,  0.0007, -0.0044],
        [ 0.0024,  0.0676,  0.0071,  ...,  0.0179, -0.0056,  0.0031],
        [-0.0022, -0.0120,  0.0446,  ..., -0.0093, -0.0095, -0.0029],
        ...,
        [-0.0011,  0.0145,  0.0001,  ...,  0.0742, -0.0045,  0.0049],
        [-0.0014,  0.0027,  0.0083,  ...,  0.0054,  0.0544, -0.0042],
        [ 0.0034, -0.0008,  0.0001,  ..., -0.0036, -0.0139,  0.0555]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.9141, -2.6660,  1.7832,  ...,  2.2461, -3.9961, -1.1221]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 04:48:03 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To starve results in starvation
To specialize results in specialization
To optimize results in optimization
To stabilize results in stabilization
To declare results in declaration
To maximize results in maximization
To minimize results in minimization
To aspire results in
2024-07-31 04:48:03 root INFO     [order_1_approx] starting weight calculation for To maximize results in maximization
To minimize results in minimization
To specialize results in specialization
To starve results in starvation
To optimize results in optimization
To stabilize results in stabilization
To aspire results in aspiration
To declare results in
2024-07-31 04:48:03 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 04:50:00 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2195, -0.4890,  0.0520,  ..., -0.0874, -0.2206,  0.1510],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.3379, -5.7227,  4.2031,  ...,  1.9004, -3.0039,  0.6152],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.1295, -0.0131,  0.0057,  ..., -0.0010, -0.0261, -0.0100],
        [ 0.0060,  0.1389,  0.0251,  ...,  0.0162, -0.0029,  0.0202],
        [ 0.0135, -0.0284,  0.0924,  ..., -0.0045, -0.0128, -0.0160],
        ...,
        [ 0.0090,  0.0249, -0.0078,  ...,  0.1210, -0.0092,  0.0108],
        [-0.0168,  0.0205,  0.0191,  ..., -0.0039,  0.1119, -0.0248],
        [ 0.0341, -0.0056, -0.0062,  ..., -0.0032, -0.0207,  0.1343]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.0645, -4.9336,  3.4082,  ...,  2.0840, -2.9570,  0.8618]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 04:50:01 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To maximize results in maximization
To minimize results in minimization
To specialize results in specialization
To starve results in starvation
To optimize results in optimization
To stabilize results in stabilization
To aspire results in aspiration
To declare results in
2024-07-31 04:50:01 root INFO     [order_1_approx] starting weight calculation for To aspire results in aspiration
To maximize results in maximization
To specialize results in specialization
To stabilize results in stabilization
To minimize results in minimization
To optimize results in optimization
To declare results in declaration
To starve results in
2024-07-31 04:50:01 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 04:51:59 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1328, -0.8359, -0.5928,  ..., -0.9673, -0.3574,  0.1316],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.2422, -3.9941,  2.7871,  ...,  1.2510, -2.3418, -1.2900],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0845, -0.0123,  0.0192,  ...,  0.0063, -0.0057,  0.0061],
        [-0.0051,  0.0930, -0.0012,  ...,  0.0255, -0.0116,  0.0075],
        [ 0.0094, -0.0257,  0.0803,  ..., -0.0212,  0.0005, -0.0134],
        ...,
        [ 0.0106,  0.0126, -0.0045,  ...,  0.1045, -0.0069,  0.0047],
        [-0.0002,  0.0172,  0.0222,  ...,  0.0076,  0.0823, -0.0105],
        [ 0.0109,  0.0064, -0.0033,  ..., -0.0036, -0.0233,  0.1057]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.8418, -3.5703,  2.7031,  ...,  1.6064, -2.2188, -1.1016]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 04:52:00 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To aspire results in aspiration
To maximize results in maximization
To specialize results in specialization
To stabilize results in stabilization
To minimize results in minimization
To optimize results in optimization
To declare results in declaration
To starve results in
2024-07-31 04:52:00 root INFO     [order_1_approx] starting weight calculation for To starve results in starvation
To minimize results in minimization
To aspire results in aspiration
To declare results in declaration
To specialize results in specialization
To optimize results in optimization
To maximize results in maximization
To stabilize results in
2024-07-31 04:52:00 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 04:53:53 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2000, -0.4180, -0.9990,  ..., -0.4062, -0.1774,  0.2013],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.2266, -4.3047,  0.8672,  ...,  0.3970, -3.1504, -3.4316],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0449,  0.0102,  0.0068,  ...,  0.0001, -0.0028,  0.0080],
        [ 0.0044,  0.0427,  0.0068,  ...,  0.0139, -0.0031,  0.0059],
        [-0.0091, -0.0106,  0.0290,  ..., -0.0017, -0.0016, -0.0081],
        ...,
        [ 0.0040,  0.0027, -0.0010,  ...,  0.0349, -0.0076,  0.0049],
        [-0.0075,  0.0088, -0.0040,  ..., -0.0012,  0.0426, -0.0095],
        [ 0.0056,  0.0047, -0.0012,  ..., -0.0066, -0.0075,  0.0438]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.1562, -4.2969,  0.9136,  ...,  0.3159, -3.3398, -3.4102]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 04:53:54 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To starve results in starvation
To minimize results in minimization
To aspire results in aspiration
To declare results in declaration
To specialize results in specialization
To optimize results in optimization
To maximize results in maximization
To stabilize results in
2024-07-31 04:53:54 root INFO     [order_1_approx] starting weight calculation for To optimize results in optimization
To aspire results in aspiration
To minimize results in minimization
To stabilize results in stabilization
To declare results in declaration
To specialize results in specialization
To starve results in starvation
To maximize results in
2024-07-31 04:53:54 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 04:55:53 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3545, -0.1991, -0.5850,  ..., -0.2302, -0.2576, -0.1884],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.4844, -2.3516,  0.2627,  ..., -1.4004, -4.4766, -2.6055],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0634, -0.0018, -0.0079,  ..., -0.0101,  0.0105, -0.0012],
        [ 0.0039,  0.0698,  0.0069,  ...,  0.0215, -0.0041,  0.0100],
        [-0.0066, -0.0124,  0.0513,  ..., -0.0028,  0.0102, -0.0052],
        ...,
        [-0.0030,  0.0036,  0.0018,  ...,  0.0654, -0.0082,  0.0073],
        [ 0.0082,  0.0130, -0.0020,  ...,  0.0034,  0.0646,  0.0008],
        [ 0.0053,  0.0071, -0.0050,  ..., -0.0091, -0.0151,  0.0587]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.2334, -1.9922,  0.5059,  ..., -1.2246, -4.4570, -2.4961]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 04:55:54 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To optimize results in optimization
To aspire results in aspiration
To minimize results in minimization
To stabilize results in stabilization
To declare results in declaration
To specialize results in specialization
To starve results in starvation
To maximize results in
2024-07-31 04:55:54 root INFO     total operator prediction time: 946.5298111438751 seconds
2024-07-31 04:55:54 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on adj+ly_reg
2024-07-31 04:55:54 root INFO     building operator adj+ly_reg
2024-07-31 04:55:54 root INFO     [order_1_approx] starting weight calculation for The adjective form of global is globally
The adjective form of rare is rarely
The adjective form of subsequent is subsequently
The adjective form of financial is financially
The adjective form of clinical is clinically
The adjective form of important is importantly
The adjective form of actual is actually
The adjective form of similar is
2024-07-31 04:55:54 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 04:57:52 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.3147, -0.2068, -0.0717,  ..., -0.3757,  0.3286, -0.0421],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.4189, -1.3096,  0.8052,  ..., -1.7500,  0.2480, -1.8379],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 1.0211e-01, -1.8097e-02,  1.4023e-02,  ..., -9.1705e-03,
          1.8585e-02,  1.9363e-02],
        [ 8.5526e-03,  8.6060e-02,  3.1830e-02,  ...,  3.1097e-02,
          6.6528e-03, -1.1436e-02],
        [ 3.5477e-04,  1.7578e-02,  7.2144e-02,  ..., -9.0942e-03,
         -1.6754e-02, -2.9144e-02],
        ...,
        [-4.2419e-03, -1.5259e-05, -2.4261e-03,  ...,  9.3445e-02,
         -1.1993e-02, -5.4245e-03],
        [-1.4038e-02,  1.9226e-02, -2.1866e-02,  ..., -1.8555e-02,
          6.1035e-02, -8.6517e-03],
        [ 1.6632e-02,  2.5558e-04, -1.3344e-02,  ...,  1.3245e-02,
         -2.8687e-02,  6.4453e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.6958, -1.0859,  1.2109,  ..., -1.9980, -0.2881, -2.0723]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 04:57:53 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The adjective form of global is globally
The adjective form of rare is rarely
The adjective form of subsequent is subsequently
The adjective form of financial is financially
The adjective form of clinical is clinically
The adjective form of important is importantly
The adjective form of actual is actually
The adjective form of similar is
2024-07-31 04:57:53 root INFO     [order_1_approx] starting weight calculation for The adjective form of clinical is clinically
The adjective form of financial is financially
The adjective form of important is importantly
The adjective form of actual is actually
The adjective form of similar is similarly
The adjective form of rare is rarely
The adjective form of subsequent is subsequently
The adjective form of global is
2024-07-31 04:57:53 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 04:59:39 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1051,  0.4436, -0.1119,  ..., -0.8555, -0.2222, -0.1158],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.7295, -2.1680,  0.0229,  ..., -2.2539, -1.8242,  0.2305],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0891, -0.0119,  0.0181,  ...,  0.0062,  0.0035, -0.0013],
        [ 0.0129,  0.1075,  0.0218,  ...,  0.0214, -0.0066, -0.0136],
        [ 0.0230,  0.0016,  0.0985,  ...,  0.0151, -0.0060, -0.0043],
        ...,
        [-0.0105,  0.0315,  0.0012,  ...,  0.0863, -0.0134,  0.0147],
        [-0.0024,  0.0121,  0.0155,  ..., -0.0219,  0.0815, -0.0172],
        [ 0.0327, -0.0183, -0.0085,  ..., -0.0255, -0.0175,  0.0684]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.0645, -2.2031,  0.3203,  ..., -1.6133, -1.9326,  0.1044]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 04:59:40 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The adjective form of clinical is clinically
The adjective form of financial is financially
The adjective form of important is importantly
The adjective form of actual is actually
The adjective form of similar is similarly
The adjective form of rare is rarely
The adjective form of subsequent is subsequently
The adjective form of global is
2024-07-31 04:59:40 root INFO     [order_1_approx] starting weight calculation for The adjective form of similar is similarly
The adjective form of clinical is clinically
The adjective form of subsequent is subsequently
The adjective form of global is globally
The adjective form of actual is actually
The adjective form of important is importantly
The adjective form of financial is financially
The adjective form of rare is
2024-07-31 04:59:40 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 05:01:26 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0601, -0.3545, -0.8179,  ..., -0.5454,  0.4651,  0.1375],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.8701, -3.8320, -0.6416,  ..., -3.5684, -3.9941, -4.0898],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.1052,  0.0001,  0.0329,  ..., -0.0077,  0.0060,  0.0209],
        [ 0.0447,  0.0970,  0.0223,  ...,  0.0405,  0.0148,  0.0017],
        [ 0.0208, -0.0081,  0.0799,  ..., -0.0042,  0.0005,  0.0178],
        ...,
        [ 0.0001,  0.0179, -0.0173,  ...,  0.0861, -0.0123, -0.0010],
        [-0.0141,  0.0330, -0.0012,  ..., -0.0106,  0.0542, -0.0084],
        [ 0.0295, -0.0118, -0.0154,  ..., -0.0172, -0.0274,  0.0829]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-2.0371, -3.7754, -0.2759,  ..., -3.5918, -4.0977, -4.3516]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 05:01:27 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The adjective form of similar is similarly
The adjective form of clinical is clinically
The adjective form of subsequent is subsequently
The adjective form of global is globally
The adjective form of actual is actually
The adjective form of important is importantly
The adjective form of financial is financially
The adjective form of rare is
2024-07-31 05:01:28 root INFO     [order_1_approx] starting weight calculation for The adjective form of important is importantly
The adjective form of similar is similarly
The adjective form of financial is financially
The adjective form of subsequent is subsequently
The adjective form of rare is rarely
The adjective form of global is globally
The adjective form of clinical is clinically
The adjective form of actual is
2024-07-31 05:01:28 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 05:03:17 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.7100, -0.1097, -0.4043,  ..., -0.9209, -0.2250, -0.0938],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.3125, -2.9785,  0.9531,  ..., -0.2393, -2.4414, -1.4316],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.1097, -0.0391,  0.0191,  ..., -0.0160,  0.0114,  0.0364],
        [ 0.0014,  0.1265,  0.0205,  ...,  0.0289,  0.0176, -0.0016],
        [ 0.0190, -0.0118,  0.1030,  ...,  0.0147, -0.0073, -0.0160],
        ...,
        [-0.0118,  0.0220, -0.0421,  ...,  0.1086, -0.0183, -0.0121],
        [ 0.0175,  0.0192,  0.0243,  ..., -0.0078,  0.0677, -0.0037],
        [ 0.0303, -0.0099, -0.0220,  ..., -0.0283, -0.0331,  0.0706]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.1230, -3.2891,  1.1416,  ...,  0.1802, -2.0879, -1.5664]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 05:03:18 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The adjective form of important is importantly
The adjective form of similar is similarly
The adjective form of financial is financially
The adjective form of subsequent is subsequently
The adjective form of rare is rarely
The adjective form of global is globally
The adjective form of clinical is clinically
The adjective form of actual is
2024-07-31 05:03:18 root INFO     [order_1_approx] starting weight calculation for The adjective form of important is importantly
The adjective form of clinical is clinically
The adjective form of global is globally
The adjective form of subsequent is subsequently
The adjective form of similar is similarly
The adjective form of actual is actually
The adjective form of rare is rarely
The adjective form of financial is
2024-07-31 05:03:19 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 05:05:15 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1932, -0.3264, -0.3530,  ..., -0.8975, -0.1057, -0.0587],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.1133, -0.6509,  1.9033,  ..., -2.2852, -2.3574, -0.8086],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0662, -0.0280,  0.0241,  ..., -0.0208,  0.0121,  0.0139],
        [-0.0277,  0.0977,  0.0285,  ...,  0.0028, -0.0219, -0.0210],
        [-0.0144, -0.0084,  0.0739,  ...,  0.0013, -0.0028, -0.0021],
        ...,
        [ 0.0007, -0.0003, -0.0225,  ...,  0.1133,  0.0152,  0.0015],
        [-0.0161,  0.0406, -0.0088,  ..., -0.0169,  0.1049, -0.0227],
        [ 0.0196, -0.0206, -0.0010,  ...,  0.0087, -0.0138,  0.0637]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.2441, -0.1902,  2.2031,  ..., -1.9834, -2.3086, -1.1523]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 05:05:16 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The adjective form of important is importantly
The adjective form of clinical is clinically
The adjective form of global is globally
The adjective form of subsequent is subsequently
The adjective form of similar is similarly
The adjective form of actual is actually
The adjective form of rare is rarely
The adjective form of financial is
2024-07-31 05:05:17 root INFO     [order_1_approx] starting weight calculation for The adjective form of actual is actually
The adjective form of rare is rarely
The adjective form of clinical is clinically
The adjective form of global is globally
The adjective form of similar is similarly
The adjective form of financial is financially
The adjective form of subsequent is subsequently
The adjective form of important is
2024-07-31 05:05:17 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 05:07:13 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.4458,  0.0400, -0.6128,  ..., -0.5942, -0.2573, -0.8911],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.9609, -0.2856, -0.2661,  ..., -3.6758, -1.3779, -3.1914],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0702, -0.0098,  0.0129,  ..., -0.0087,  0.0037,  0.0160],
        [ 0.0027,  0.0558,  0.0106,  ...,  0.0186, -0.0029, -0.0206],
        [ 0.0016,  0.0093,  0.0761,  ...,  0.0005, -0.0138, -0.0070],
        ...,
        [-0.0107,  0.0120, -0.0134,  ...,  0.0544, -0.0035,  0.0085],
        [-0.0007,  0.0191,  0.0010,  ..., -0.0066,  0.0528, -0.0117],
        [ 0.0270, -0.0045, -0.0058,  ..., -0.0029, -0.0308,  0.0500]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.9805,  0.0632, -0.1130,  ..., -3.4863, -1.4219, -3.2480]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 05:07:14 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The adjective form of actual is actually
The adjective form of rare is rarely
The adjective form of clinical is clinically
The adjective form of global is globally
The adjective form of similar is similarly
The adjective form of financial is financially
The adjective form of subsequent is subsequently
The adjective form of important is
2024-07-31 05:07:14 root INFO     [order_1_approx] starting weight calculation for The adjective form of rare is rarely
The adjective form of actual is actually
The adjective form of similar is similarly
The adjective form of important is importantly
The adjective form of clinical is clinically
The adjective form of global is globally
The adjective form of financial is financially
The adjective form of subsequent is
2024-07-31 05:07:14 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 05:09:13 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1022,  0.3096, -0.0092,  ..., -0.6470, -0.4622, -0.0847],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.0234,  0.2637,  1.5137,  ..., -0.3696,  1.3770, -3.2441],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0903, -0.0071,  0.0075,  ..., -0.0160,  0.0146,  0.0038],
        [ 0.0129,  0.1029,  0.0329,  ...,  0.0305, -0.0179, -0.0155],
        [ 0.0197, -0.0244,  0.0730,  ..., -0.0269, -0.0075, -0.0196],
        ...,
        [-0.0117,  0.0084, -0.0081,  ...,  0.0966,  0.0099,  0.0112],
        [-0.0010,  0.0057,  0.0320,  ..., -0.0143,  0.0523,  0.0020],
        [ 0.0171,  0.0028, -0.0135,  ..., -0.0064, -0.0159,  0.0801]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.6729, -0.0552,  1.7686,  ...,  0.1475,  1.3291, -3.5527]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 05:09:14 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The adjective form of rare is rarely
The adjective form of actual is actually
The adjective form of similar is similarly
The adjective form of important is importantly
The adjective form of clinical is clinically
The adjective form of global is globally
The adjective form of financial is financially
The adjective form of subsequent is
2024-07-31 05:09:15 root INFO     [order_1_approx] starting weight calculation for The adjective form of rare is rarely
The adjective form of subsequent is subsequently
The adjective form of global is globally
The adjective form of actual is actually
The adjective form of financial is financially
The adjective form of similar is similarly
The adjective form of important is importantly
The adjective form of clinical is
2024-07-31 05:09:15 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 05:11:09 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3635,  0.0170, -0.1628,  ..., -0.8496, -0.5127, -0.4092],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.2969, -0.4099, -0.6562,  ..., -1.4004,  1.7197, -0.3340],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0934, -0.0102,  0.0205,  ..., -0.0014, -0.0063,  0.0258],
        [-0.0217,  0.0776,  0.0022,  ...,  0.0340,  0.0074,  0.0090],
        [-0.0058, -0.0067,  0.0822,  ...,  0.0034,  0.0111,  0.0017],
        ...,
        [ 0.0063,  0.0321, -0.0199,  ...,  0.0780, -0.0186,  0.0076],
        [-0.0001,  0.0414,  0.0013,  ..., -0.0122,  0.0722, -0.0118],
        [ 0.0008, -0.0148, -0.0050,  ..., -0.0179, -0.0182,  0.0630]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.0225, -0.3401, -0.5132,  ..., -1.4746,  1.6816, -0.4678]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 05:11:10 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The adjective form of rare is rarely
The adjective form of subsequent is subsequently
The adjective form of global is globally
The adjective form of actual is actually
The adjective form of financial is financially
The adjective form of similar is similarly
The adjective form of important is importantly
The adjective form of clinical is
2024-07-31 05:11:10 root INFO     total operator prediction time: 916.1848974227905 seconds
2024-07-31 05:11:10 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on over+adj_reg
2024-07-31 05:11:10 root INFO     building operator over+adj_reg
2024-07-31 05:11:10 root INFO     [order_1_approx] starting weight calculation for If something is too filled, it is overfilled
If something is too simplified, it is oversimplified
If something is too laid, it is overlaid
If something is too cooked, it is overcooked
If something is too subscribed, it is oversubscribed
If something is too arching, it is overarching
If something is too populated, it is overpopulated
If something is too exposed, it is
2024-07-31 05:11:10 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 05:13:02 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1238, -0.0296, -0.7090,  ..., -0.4185, -0.3325,  0.8945],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.0596, -3.0352, -0.5063,  ...,  0.6953, -1.2715, -2.8555],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0879, -0.0020, -0.0009,  ..., -0.0081,  0.0196,  0.0194],
        [ 0.0045,  0.0796, -0.0075,  ...,  0.0165, -0.0018, -0.0070],
        [ 0.0268,  0.0066,  0.0770,  ..., -0.0007, -0.0030, -0.0066],
        ...,
        [ 0.0023,  0.0040,  0.0011,  ...,  0.0956,  0.0097,  0.0076],
        [ 0.0051,  0.0016, -0.0002,  ..., -0.0021,  0.0896, -0.0219],
        [ 0.0095, -0.0049, -0.0002,  ...,  0.0012, -0.0189,  0.0804]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.4985, -3.0449, -0.4517,  ...,  0.8799, -1.4170, -2.6875]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 05:13:02 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is too filled, it is overfilled
If something is too simplified, it is oversimplified
If something is too laid, it is overlaid
If something is too cooked, it is overcooked
If something is too subscribed, it is oversubscribed
If something is too arching, it is overarching
If something is too populated, it is overpopulated
If something is too exposed, it is
2024-07-31 05:13:03 root INFO     [order_1_approx] starting weight calculation for If something is too subscribed, it is oversubscribed
If something is too cooked, it is overcooked
If something is too laid, it is overlaid
If something is too exposed, it is overexposed
If something is too filled, it is overfilled
If something is too arching, it is overarching
If something is too populated, it is overpopulated
If something is too simplified, it is
2024-07-31 05:13:03 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 05:14:54 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2314, -0.0523, -0.7793,  ..., -0.5869, -0.2365,  0.5552],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.5156, -2.1719,  1.5859,  ..., -1.9062, -3.1016,  0.0117],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0796, -0.0004,  0.0204,  ..., -0.0157,  0.0003, -0.0063],
        [ 0.0036,  0.0712,  0.0094,  ...,  0.0091,  0.0151, -0.0077],
        [ 0.0119, -0.0079,  0.0679,  ...,  0.0014, -0.0117, -0.0159],
        ...,
        [ 0.0105,  0.0042,  0.0061,  ...,  0.0885,  0.0107, -0.0010],
        [-0.0017,  0.0097,  0.0023,  ...,  0.0058,  0.0524, -0.0202],
        [-0.0082,  0.0233, -0.0042,  ..., -0.0121, -0.0144,  0.0635]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.0723, -2.3887,  1.2363,  ..., -1.6562, -3.3828, -0.1965]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 05:14:55 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is too subscribed, it is oversubscribed
If something is too cooked, it is overcooked
If something is too laid, it is overlaid
If something is too exposed, it is overexposed
If something is too filled, it is overfilled
If something is too arching, it is overarching
If something is too populated, it is overpopulated
If something is too simplified, it is
2024-07-31 05:14:55 root INFO     [order_1_approx] starting weight calculation for If something is too filled, it is overfilled
If something is too arching, it is overarching
If something is too cooked, it is overcooked
If something is too simplified, it is oversimplified
If something is too exposed, it is overexposed
If something is too subscribed, it is oversubscribed
If something is too populated, it is overpopulated
If something is too laid, it is
2024-07-31 05:14:55 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 05:16:45 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1157,  0.2925, -0.6289,  ..., -0.7041, -0.6948, -0.0147],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.8506, -2.4199,  0.5693,  ...,  1.3926, -2.6797, -1.7979],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 1.4844e-01, -2.4658e-02,  3.4332e-02,  ..., -1.5701e-02,
          2.8191e-03,  1.9302e-02],
        [-2.4052e-03,  8.2397e-02, -8.0032e-03,  ...,  7.1678e-03,
          2.2011e-03, -1.2489e-02],
        [ 1.5869e-02, -1.4244e-02,  1.0803e-01,  ..., -1.9958e-02,
          4.6883e-03, -3.3783e-02],
        ...,
        [ 1.1444e-02,  1.2932e-02,  7.9422e-03,  ...,  1.2036e-01,
          1.3041e-04, -1.2726e-02],
        [-9.1858e-03, -6.8893e-03,  1.2878e-02,  ..., -4.3106e-03,
          1.1877e-01, -2.9480e-02],
        [-1.9272e-02,  1.4221e-02, -1.7719e-03,  ..., -1.6499e-04,
          9.7122e-03,  9.9670e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.9312, -2.4590,  0.3477,  ...,  1.6504, -2.5723, -1.7959]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 05:16:46 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is too filled, it is overfilled
If something is too arching, it is overarching
If something is too cooked, it is overcooked
If something is too simplified, it is oversimplified
If something is too exposed, it is overexposed
If something is too subscribed, it is oversubscribed
If something is too populated, it is overpopulated
If something is too laid, it is
2024-07-31 05:16:47 root INFO     [order_1_approx] starting weight calculation for If something is too exposed, it is overexposed
If something is too populated, it is overpopulated
If something is too laid, it is overlaid
If something is too subscribed, it is oversubscribed
If something is too filled, it is overfilled
If something is too cooked, it is overcooked
If something is too simplified, it is oversimplified
If something is too arching, it is
2024-07-31 05:16:47 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 05:18:44 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2407, -0.5039, -0.4268,  ..., -0.4373, -0.9629, -0.8438],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.4199, -3.2969,  2.7051,  ...,  0.7695, -1.4443, -2.7539],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0955, -0.0204,  0.0111,  ..., -0.0104,  0.0193,  0.0026],
        [-0.0065,  0.0734,  0.0002,  ...,  0.0200, -0.0004, -0.0082],
        [ 0.0147,  0.0072,  0.0698,  ..., -0.0125,  0.0137, -0.0083],
        ...,
        [ 0.0026,  0.0095,  0.0086,  ...,  0.0864,  0.0141,  0.0003],
        [ 0.0047, -0.0029,  0.0019,  ..., -0.0136,  0.0735, -0.0107],
        [-0.0073,  0.0052,  0.0002,  ...,  0.0044, -0.0102,  0.0695]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.6680, -3.2539,  2.4961,  ...,  0.8149, -1.5576, -2.7344]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 05:18:45 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is too exposed, it is overexposed
If something is too populated, it is overpopulated
If something is too laid, it is overlaid
If something is too subscribed, it is oversubscribed
If something is too filled, it is overfilled
If something is too cooked, it is overcooked
If something is too simplified, it is oversimplified
If something is too arching, it is
2024-07-31 05:18:45 root INFO     [order_1_approx] starting weight calculation for If something is too cooked, it is overcooked
If something is too subscribed, it is oversubscribed
If something is too exposed, it is overexposed
If something is too laid, it is overlaid
If something is too arching, it is overarching
If something is too filled, it is overfilled
If something is too simplified, it is oversimplified
If something is too populated, it is
2024-07-31 05:18:45 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 05:20:43 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.3320,  0.2979, -0.4058,  ...,  0.3469, -0.8711,  0.0829],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.5527, -2.5781,  1.0352,  ..., -0.5835, -1.2754, -1.0967],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0773, -0.0063,  0.0112,  ..., -0.0097,  0.0103,  0.0074],
        [ 0.0121,  0.0599, -0.0025,  ...,  0.0116,  0.0139, -0.0060],
        [ 0.0034,  0.0003,  0.0621,  ..., -0.0013,  0.0003,  0.0021],
        ...,
        [ 0.0040, -0.0046,  0.0082,  ...,  0.0712,  0.0057,  0.0093],
        [-0.0020,  0.0097,  0.0062,  ..., -0.0089,  0.0546, -0.0089],
        [-0.0015, -0.0053,  0.0053,  ..., -0.0091, -0.0192,  0.0549]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.7324, -2.5371,  1.3457,  ..., -0.4414, -1.1934, -1.0400]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 05:20:44 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is too cooked, it is overcooked
If something is too subscribed, it is oversubscribed
If something is too exposed, it is overexposed
If something is too laid, it is overlaid
If something is too arching, it is overarching
If something is too filled, it is overfilled
If something is too simplified, it is oversimplified
If something is too populated, it is
2024-07-31 05:20:44 root INFO     [order_1_approx] starting weight calculation for If something is too laid, it is overlaid
If something is too populated, it is overpopulated
If something is too simplified, it is oversimplified
If something is too subscribed, it is oversubscribed
If something is too exposed, it is overexposed
If something is too arching, it is overarching
If something is too filled, it is overfilled
If something is too cooked, it is
2024-07-31 05:20:44 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 05:22:42 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4966, -0.0704, -0.4751,  ..., -0.6128, -1.2373,  0.3210],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.1445, -2.1191,  0.5430,  ..., -0.3340, -1.6982, -0.6562],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 7.6538e-02, -3.0518e-05,  3.4142e-03,  ..., -7.8964e-03,
         -1.0300e-03,  5.4665e-03],
        [ 2.8763e-03,  6.3354e-02,  2.4414e-04,  ...,  5.4550e-03,
         -3.2043e-04, -1.6495e-02],
        [ 1.0384e-02, -2.6779e-03,  6.1768e-02,  ..., -6.1264e-03,
          1.8063e-03,  3.0861e-03],
        ...,
        [ 1.1032e-02, -4.7836e-03,  2.9831e-03,  ...,  6.1218e-02,
          2.7871e-04,  7.6599e-03],
        [-2.5711e-03,  1.2093e-02, -7.1869e-03,  ..., -3.9387e-04,
          6.5308e-02, -4.9248e-03],
        [-3.3417e-03,  1.9493e-03, -4.1084e-03,  ..., -1.0437e-02,
         -3.6621e-04,  6.6528e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.0820, -2.0781,  0.8335,  ..., -0.0940, -1.5908, -0.7031]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 05:22:43 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is too laid, it is overlaid
If something is too populated, it is overpopulated
If something is too simplified, it is oversimplified
If something is too subscribed, it is oversubscribed
If something is too exposed, it is overexposed
If something is too arching, it is overarching
If something is too filled, it is overfilled
If something is too cooked, it is
2024-07-31 05:22:43 root INFO     [order_1_approx] starting weight calculation for If something is too arching, it is overarching
If something is too exposed, it is overexposed
If something is too laid, it is overlaid
If something is too filled, it is overfilled
If something is too cooked, it is overcooked
If something is too simplified, it is oversimplified
If something is too populated, it is overpopulated
If something is too subscribed, it is
2024-07-31 05:22:43 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 05:24:41 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1307, -0.3604, -0.5112,  ..., -0.1191, -0.3662, -0.0416],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.9106, -2.8789,  1.5449,  ..., -0.1522, -2.5898, -1.8076],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 8.9722e-02, -3.1464e-02,  1.6739e-02,  ..., -1.0178e-02,
          1.0757e-02, -4.3945e-03],
        [-3.9520e-03,  6.4453e-02, -2.6855e-03,  ...,  1.3023e-02,
          2.2316e-03, -1.1833e-02],
        [-3.9902e-03,  4.0054e-04,  5.3955e-02,  ..., -7.7057e-03,
         -5.0812e-03,  1.4286e-03],
        ...,
        [ 1.7900e-03,  4.4403e-03, -1.4923e-02,  ...,  8.5876e-02,
         -1.1559e-03, -5.9891e-03],
        [-6.6109e-03,  1.0750e-02,  4.7684e-05,  ..., -8.2932e-03,
          6.1829e-02, -5.0850e-03],
        [ 6.8436e-03, -1.2608e-03, -6.6185e-03,  ..., -9.3994e-03,
         -5.3253e-03,  7.7759e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.8608, -2.8223,  1.5127,  ..., -0.1423, -2.5762, -1.6445]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 05:24:42 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is too arching, it is overarching
If something is too exposed, it is overexposed
If something is too laid, it is overlaid
If something is too filled, it is overfilled
If something is too cooked, it is overcooked
If something is too simplified, it is oversimplified
If something is too populated, it is overpopulated
If something is too subscribed, it is
2024-07-31 05:24:42 root INFO     [order_1_approx] starting weight calculation for If something is too subscribed, it is oversubscribed
If something is too simplified, it is oversimplified
If something is too arching, it is overarching
If something is too populated, it is overpopulated
If something is too cooked, it is overcooked
If something is too exposed, it is overexposed
If something is too laid, it is overlaid
If something is too filled, it is
2024-07-31 05:24:42 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 05:26:42 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1316, -0.4597, -0.6162,  ..., -0.1302, -0.6050,  0.1014],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.3105, -2.5742,  2.7227,  ...,  1.2305, -3.1270, -1.4561],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 7.1411e-02, -1.6006e-02,  1.0132e-02,  ..., -8.4763e-03,
          2.7206e-02,  3.1376e-03],
        [ 8.6517e-03,  6.1707e-02, -1.7881e-06,  ...,  1.7654e-02,
          5.1003e-03,  5.8060e-03],
        [ 2.1393e-02,  7.8888e-03,  6.0516e-02,  ...,  4.6921e-03,
         -1.0033e-02, -1.1383e-02],
        ...,
        [ 7.3090e-03, -1.3649e-02,  2.1782e-03,  ...,  6.7688e-02,
          5.2948e-03,  2.2755e-03],
        [-2.1706e-03,  8.1940e-03,  6.9351e-03,  ..., -3.2806e-03,
          5.5176e-02, -1.1711e-02],
        [-6.5155e-03,  8.8806e-03,  8.2703e-03,  ..., -1.4862e-02,
         -2.1912e-02,  5.9204e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.5840, -2.4434,  2.3535,  ...,  0.8403, -2.9414, -1.4775]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 05:26:43 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is too subscribed, it is oversubscribed
If something is too simplified, it is oversimplified
If something is too arching, it is overarching
If something is too populated, it is overpopulated
If something is too cooked, it is overcooked
If something is too exposed, it is overexposed
If something is too laid, it is overlaid
If something is too filled, it is
2024-07-31 05:26:43 root INFO     total operator prediction time: 932.6990163326263 seconds
2024-07-31 05:26:43 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on verb+er_irreg
2024-07-31 05:26:43 root INFO     building operator verb+er_irreg
2024-07-31 05:26:43 root INFO     [order_1_approx] starting weight calculation for If you offend something, you are a offender
If you compose something, you are a composer
If you believe something, you are a believer
If you write something, you are a writer
If you molest something, you are a molester
If you interpret something, you are a interpreter
If you develop something, you are a developer
If you receive something, you are a
2024-07-31 05:26:43 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 05:28:40 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0140,  0.5850,  0.3655,  ..., -0.1449, -0.7656,  0.0467],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.8594, -0.9473, -0.9341,  ..., -2.0586, -3.8672, -2.3477],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0533, -0.0002,  0.0187,  ...,  0.0110,  0.0057,  0.0290],
        [-0.0325,  0.0508, -0.0002,  ...,  0.0179,  0.0214, -0.0146],
        [ 0.0138, -0.0095,  0.0344,  ..., -0.0124, -0.0081,  0.0056],
        ...,
        [ 0.0096,  0.0007, -0.0006,  ...,  0.0545, -0.0070, -0.0095],
        [ 0.0130,  0.0128,  0.0084,  ..., -0.0276,  0.0502, -0.0091],
        [ 0.0035,  0.0021, -0.0120,  ..., -0.0133, -0.0073,  0.0523]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.2812, -0.9150, -0.7568,  ..., -2.0918, -3.9395, -2.2344]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 05:28:41 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you offend something, you are a offender
If you compose something, you are a composer
If you believe something, you are a believer
If you write something, you are a writer
If you molest something, you are a molester
If you interpret something, you are a interpreter
If you develop something, you are a developer
If you receive something, you are a
2024-07-31 05:28:41 root INFO     [order_1_approx] starting weight calculation for If you receive something, you are a receiver
If you develop something, you are a developer
If you write something, you are a writer
If you molest something, you are a molester
If you believe something, you are a believer
If you offend something, you are a offender
If you compose something, you are a composer
If you interpret something, you are a
2024-07-31 05:28:41 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 05:30:37 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0024, -0.1328,  0.3977,  ...,  0.0834, -0.4861,  0.5874],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.9355, -4.4414,  3.5664,  ..., -2.5293, -4.2305, -3.5137],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 5.2826e-02, -7.2365e-03,  1.2093e-02,  ...,  7.2479e-03,
         -1.5442e-02,  1.2466e-02],
        [-1.4038e-02,  6.1737e-02,  1.7452e-03,  ...,  1.0468e-02,
          1.3756e-02, -1.0735e-02],
        [ 3.9787e-03, -7.5150e-03,  4.9133e-02,  ...,  6.5308e-03,
         -8.4229e-03, -1.4336e-02],
        ...,
        [ 1.3718e-02, -4.7569e-03,  6.5842e-03,  ...,  4.7119e-02,
         -4.2267e-03, -1.2283e-02],
        [ 2.8610e-05,  1.0452e-02,  1.0223e-02,  ..., -1.3382e-02,
          3.7445e-02, -2.1820e-02],
        [ 3.4752e-03,  6.1111e-03,  2.6894e-03,  ..., -1.2787e-02,
         -3.7918e-03,  6.0913e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.7520, -4.3906,  3.7852,  ..., -2.5078, -4.1523, -3.7793]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 05:30:38 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you receive something, you are a receiver
If you develop something, you are a developer
If you write something, you are a writer
If you molest something, you are a molester
If you believe something, you are a believer
If you offend something, you are a offender
If you compose something, you are a composer
If you interpret something, you are a
2024-07-31 05:30:38 root INFO     [order_1_approx] starting weight calculation for If you compose something, you are a composer
If you molest something, you are a molester
If you offend something, you are a offender
If you interpret something, you are a interpreter
If you receive something, you are a receiver
If you write something, you are a writer
If you believe something, you are a believer
If you develop something, you are a
2024-07-31 05:30:38 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 05:32:31 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.9253,  0.4702, -0.1919,  ...,  0.0500, -0.4006, -0.1538],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 5.7500, -4.6875,  3.5781,  ...,  1.4043, -4.1445, -2.3672],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0797,  0.0075,  0.0166,  ...,  0.0044, -0.0190,  0.0065],
        [-0.0158,  0.0793,  0.0041,  ...,  0.0160,  0.0141,  0.0011],
        [ 0.0028, -0.0148,  0.0668,  ..., -0.0044, -0.0071, -0.0190],
        ...,
        [ 0.0207,  0.0006,  0.0082,  ...,  0.0840, -0.0204,  0.0057],
        [ 0.0006, -0.0031,  0.0004,  ..., -0.0127,  0.0546, -0.0174],
        [-0.0055,  0.0046, -0.0179,  ..., -0.0116, -0.0228,  0.0754]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 5.6016, -4.6758,  3.9492,  ...,  1.5664, -4.0039, -2.2422]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 05:32:32 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you compose something, you are a composer
If you molest something, you are a molester
If you offend something, you are a offender
If you interpret something, you are a interpreter
If you receive something, you are a receiver
If you write something, you are a writer
If you believe something, you are a believer
If you develop something, you are a
2024-07-31 05:32:32 root INFO     [order_1_approx] starting weight calculation for If you molest something, you are a molester
If you write something, you are a writer
If you receive something, you are a receiver
If you develop something, you are a developer
If you offend something, you are a offender
If you compose something, you are a composer
If you interpret something, you are a interpreter
If you believe something, you are a
2024-07-31 05:32:32 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 05:34:25 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1006,  0.1110,  0.2600,  ..., -0.1123, -0.7769,  0.4209],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 6.8477, -5.2109,  2.8770,  ..., -0.8169, -4.6562, -1.5059],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 3.1616e-02,  5.2071e-03,  2.7008e-03,  ...,  1.5610e-02,
         -9.0561e-03,  1.6556e-02],
        [-4.1504e-03,  3.6194e-02,  1.7059e-02,  ...,  2.8427e-02,
          9.3994e-03, -4.9057e-03],
        [ 8.4686e-03, -1.3748e-02,  3.5767e-02,  ..., -6.0043e-03,
         -1.0010e-02,  8.5602e-03],
        ...,
        [ 3.4180e-03, -3.4981e-03, -1.0139e-02,  ...,  2.9083e-02,
         -7.7553e-03, -7.0114e-03],
        [ 1.9484e-03,  4.8485e-03,  9.6130e-03,  ..., -6.4430e-03,
          3.2471e-02, -8.7204e-03],
        [ 5.9929e-03,  3.7975e-03, -3.5782e-03,  ..., -9.0122e-05,
         -2.3804e-03,  2.8549e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 6.7539, -5.0977,  3.0176,  ..., -0.5269, -4.5312, -1.6230]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 05:34:26 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you molest something, you are a molester
If you write something, you are a writer
If you receive something, you are a receiver
If you develop something, you are a developer
If you offend something, you are a offender
If you compose something, you are a composer
If you interpret something, you are a interpreter
If you believe something, you are a
2024-07-31 05:34:26 root INFO     [order_1_approx] starting weight calculation for If you molest something, you are a molester
If you receive something, you are a receiver
If you develop something, you are a developer
If you compose something, you are a composer
If you believe something, you are a believer
If you interpret something, you are a interpreter
If you offend something, you are a offender
If you write something, you are a
2024-07-31 05:34:26 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 05:36:24 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.4624, -0.4622,  0.3931,  ..., -0.9624, -0.5181, -0.4570],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.5273, -4.9375,  0.9771,  ...,  0.1504, -4.4531, -0.3496],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0463, -0.0036,  0.0025,  ...,  0.0063, -0.0128,  0.0157],
        [-0.0094,  0.0410,  0.0047,  ...,  0.0113,  0.0200, -0.0112],
        [ 0.0153, -0.0111,  0.0438,  ..., -0.0057, -0.0173,  0.0161],
        ...,
        [ 0.0196,  0.0106,  0.0042,  ...,  0.0349, -0.0081, -0.0110],
        [ 0.0029,  0.0135,  0.0020,  ..., -0.0062,  0.0394,  0.0005],
        [ 0.0017,  0.0122, -0.0041,  ..., -0.0099, -0.0102,  0.0403]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.7031, -4.9414,  1.0283,  ...,  0.4187, -4.3711, -0.3447]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 05:36:25 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you molest something, you are a molester
If you receive something, you are a receiver
If you develop something, you are a developer
If you compose something, you are a composer
If you believe something, you are a believer
If you interpret something, you are a interpreter
If you offend something, you are a offender
If you write something, you are a
2024-07-31 05:36:25 root INFO     [order_1_approx] starting weight calculation for If you molest something, you are a molester
If you believe something, you are a believer
If you receive something, you are a receiver
If you compose something, you are a composer
If you write something, you are a writer
If you develop something, you are a developer
If you interpret something, you are a interpreter
If you offend something, you are a
2024-07-31 05:36:25 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 05:38:23 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0612, -0.4216, -0.3328,  ..., -0.3525, -0.4192, -0.3513],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.7188, -2.8398,  1.5303,  ..., -2.6875, -3.6641,  0.9424],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0750,  0.0037,  0.0263,  ...,  0.0037, -0.0066,  0.0268],
        [-0.0007,  0.0621, -0.0031,  ...,  0.0133,  0.0156, -0.0077],
        [ 0.0162, -0.0099,  0.0577,  ..., -0.0020, -0.0086, -0.0003],
        ...,
        [ 0.0141, -0.0037,  0.0024,  ...,  0.0714,  0.0094, -0.0017],
        [-0.0020,  0.0192,  0.0137,  ..., -0.0159,  0.0770, -0.0097],
        [ 0.0066,  0.0041, -0.0039,  ..., -0.0032, -0.0079,  0.0782]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.4023, -3.0938,  1.9297,  ..., -2.3574, -3.6836,  1.4668]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 05:38:24 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you molest something, you are a molester
If you believe something, you are a believer
If you receive something, you are a receiver
If you compose something, you are a composer
If you write something, you are a writer
If you develop something, you are a developer
If you interpret something, you are a interpreter
If you offend something, you are a
2024-07-31 05:38:24 root INFO     [order_1_approx] starting weight calculation for If you interpret something, you are a interpreter
If you believe something, you are a believer
If you write something, you are a writer
If you develop something, you are a developer
If you offend something, you are a offender
If you receive something, you are a receiver
If you molest something, you are a molester
If you compose something, you are a
2024-07-31 05:38:24 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 05:40:22 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2661,  0.1678, -0.0347,  ..., -0.9370, -0.6152,  0.4902],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.1777, -3.1484,  0.5767,  ..., -0.1875, -2.3145, -0.2080],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0612, -0.0018,  0.0150,  ...,  0.0035, -0.0116,  0.0162],
        [ 0.0037,  0.0564,  0.0002,  ...,  0.0125,  0.0237, -0.0131],
        [ 0.0114, -0.0013,  0.0598,  ...,  0.0005, -0.0088,  0.0026],
        ...,
        [ 0.0183,  0.0083,  0.0029,  ...,  0.0675, -0.0054, -0.0246],
        [ 0.0194,  0.0157,  0.0017,  ..., -0.0179,  0.0551, -0.0124],
        [-0.0038,  0.0007, -0.0007,  ..., -0.0040, -0.0141,  0.0522]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.2246, -3.3496,  0.5742,  ...,  0.0740, -2.1094, -0.4424]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 05:40:23 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you interpret something, you are a interpreter
If you believe something, you are a believer
If you write something, you are a writer
If you develop something, you are a developer
If you offend something, you are a offender
If you receive something, you are a receiver
If you molest something, you are a molester
If you compose something, you are a
2024-07-31 05:40:23 root INFO     [order_1_approx] starting weight calculation for If you believe something, you are a believer
If you interpret something, you are a interpreter
If you compose something, you are a composer
If you write something, you are a writer
If you offend something, you are a offender
If you receive something, you are a receiver
If you develop something, you are a developer
If you molest something, you are a
2024-07-31 05:40:23 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 05:42:22 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2664, -0.1109, -0.0970,  ..., -0.7539, -0.7500,  0.3594],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 5.1445, -2.2266, -0.4805,  ..., -2.1953, -3.6113,  0.4590],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0665, -0.0063,  0.0219,  ...,  0.0104, -0.0027,  0.0011],
        [-0.0031,  0.0511, -0.0232,  ...,  0.0317,  0.0146, -0.0069],
        [ 0.0158, -0.0142,  0.0599,  ...,  0.0102, -0.0005, -0.0080],
        ...,
        [-0.0060, -0.0057,  0.0072,  ...,  0.1014,  0.0012,  0.0161],
        [ 0.0070,  0.0051,  0.0229,  ..., -0.0171,  0.0568, -0.0161],
        [ 0.0095,  0.0147, -0.0029,  ..., -0.0162, -0.0073,  0.0810]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 5.1133, -2.0234,  0.0100,  ..., -2.0156, -3.3926,  0.4426]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 05:42:23 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you believe something, you are a believer
If you interpret something, you are a interpreter
If you compose something, you are a composer
If you write something, you are a writer
If you offend something, you are a offender
If you receive something, you are a receiver
If you develop something, you are a developer
If you molest something, you are a
2024-07-31 05:42:23 root INFO     total operator prediction time: 939.9185366630554 seconds
2024-07-31 05:42:23 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on adj - superlative
2024-07-31 05:42:23 root INFO     building operator adj - superlative
2024-07-31 05:42:23 root INFO     [order_1_approx] starting weight calculation for If something is the most happy, it is happiest
If something is the most rude, it is rudest
If something is the most merry, it is merriest
If something is the most hot, it is hottest
If something is the most shiny, it is shiniest
If something is the most noisy, it is noisiest
If something is the most dumb, it is dumbest
If something is the most cute, it is
2024-07-31 05:42:23 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 05:44:19 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2698,  0.2035,  0.6362,  ..., -0.6919, -0.7329,  0.2163],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-2.8047, -1.6836, -1.3457,  ..., -0.8804, -0.1621,  1.3584],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0525, -0.0027,  0.0143,  ..., -0.0179,  0.0004,  0.0071],
        [-0.0035,  0.0629,  0.0024,  ...,  0.0084,  0.0196,  0.0068],
        [ 0.0076,  0.0094,  0.0558,  ..., -0.0100, -0.0114, -0.0076],
        ...,
        [ 0.0100,  0.0116,  0.0011,  ...,  0.0551,  0.0050, -0.0134],
        [ 0.0172,  0.0097,  0.0153,  ..., -0.0150,  0.0355, -0.0088],
        [-0.0059, -0.0022, -0.0037,  ..., -0.0178, -0.0085,  0.0461]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-2.8418, -1.5986, -1.7031,  ..., -1.0146, -0.1719,  1.4111]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 05:44:19 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is the most happy, it is happiest
If something is the most rude, it is rudest
If something is the most merry, it is merriest
If something is the most hot, it is hottest
If something is the most shiny, it is shiniest
If something is the most noisy, it is noisiest
If something is the most dumb, it is dumbest
If something is the most cute, it is
2024-07-31 05:44:19 root INFO     [order_1_approx] starting weight calculation for If something is the most noisy, it is noisiest
If something is the most cute, it is cutest
If something is the most rude, it is rudest
If something is the most merry, it is merriest
If something is the most hot, it is hottest
If something is the most happy, it is happiest
If something is the most dumb, it is dumbest
If something is the most shiny, it is
2024-07-31 05:44:20 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 05:46:14 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.3208,  0.0092, -0.3928,  ...,  0.3210,  0.1622, -0.3103],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-2.9258, -1.3770, -2.9453,  ...,  0.7617, -1.4697,  0.8291],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0844, -0.0103,  0.0119,  ...,  0.0006,  0.0064,  0.0062],
        [-0.0092,  0.0747,  0.0204,  ..., -0.0161,  0.0152,  0.0036],
        [ 0.0053,  0.0011,  0.0585,  ..., -0.0051, -0.0033, -0.0129],
        ...,
        [ 0.0031,  0.0177,  0.0065,  ...,  0.0586, -0.0109, -0.0060],
        [ 0.0030,  0.0146,  0.0062,  ...,  0.0129,  0.0538, -0.0097],
        [-0.0021, -0.0023, -0.0137,  ..., -0.0255, -0.0091,  0.0501]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-2.7109, -1.2725, -3.0176,  ...,  0.9448, -1.4141,  0.8662]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 05:46:15 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is the most noisy, it is noisiest
If something is the most cute, it is cutest
If something is the most rude, it is rudest
If something is the most merry, it is merriest
If something is the most hot, it is hottest
If something is the most happy, it is happiest
If something is the most dumb, it is dumbest
If something is the most shiny, it is
2024-07-31 05:46:15 root INFO     [order_1_approx] starting weight calculation for If something is the most noisy, it is noisiest
If something is the most happy, it is happiest
If something is the most shiny, it is shiniest
If something is the most cute, it is cutest
If something is the most rude, it is rudest
If something is the most merry, it is merriest
If something is the most hot, it is hottest
If something is the most dumb, it is
2024-07-31 05:46:15 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 05:48:11 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2179,  0.0334, -0.1829,  ..., -0.7178, -0.6953,  0.4893],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.4717, -2.5391,  2.4160,  ..., -3.6699, -1.2578, -1.0459],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0490, -0.0073,  0.0161,  ..., -0.0040,  0.0173, -0.0018],
        [-0.0087,  0.0511,  0.0160,  ...,  0.0084,  0.0104, -0.0036],
        [ 0.0298,  0.0052,  0.0507,  ..., -0.0105, -0.0068, -0.0159],
        ...,
        [ 0.0200,  0.0125,  0.0041,  ...,  0.0617, -0.0080, -0.0057],
        [ 0.0176,  0.0133,  0.0150,  ...,  0.0074,  0.0427, -0.0220],
        [ 0.0079,  0.0146,  0.0005,  ..., -0.0248,  0.0020,  0.0612]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.2031, -2.5059,  1.5586,  ..., -3.9609, -1.2646, -1.1641]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 05:48:12 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is the most noisy, it is noisiest
If something is the most happy, it is happiest
If something is the most shiny, it is shiniest
If something is the most cute, it is cutest
If something is the most rude, it is rudest
If something is the most merry, it is merriest
If something is the most hot, it is hottest
If something is the most dumb, it is
2024-07-31 05:48:13 root INFO     [order_1_approx] starting weight calculation for If something is the most shiny, it is shiniest
If something is the most dumb, it is dumbest
If something is the most hot, it is hottest
If something is the most merry, it is merriest
If something is the most noisy, it is noisiest
If something is the most cute, it is cutest
If something is the most rude, it is rudest
If something is the most happy, it is
2024-07-31 05:48:13 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 05:50:09 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1442, -0.3086,  0.0938,  ..., -0.2666, -0.6274, -0.4324],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.2617, -3.4531, -0.1426,  ...,  1.0479, -2.2266, -0.8672],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0446, -0.0011,  0.0065,  ...,  0.0001,  0.0077,  0.0165],
        [-0.0043,  0.0371,  0.0119,  ...,  0.0024,  0.0068,  0.0031],
        [ 0.0105, -0.0029,  0.0347,  ..., -0.0064, -0.0115, -0.0114],
        ...,
        [-0.0040,  0.0127, -0.0105,  ...,  0.0420, -0.0015, -0.0056],
        [ 0.0064,  0.0050,  0.0133,  ..., -0.0014,  0.0333, -0.0158],
        [ 0.0053, -0.0075, -0.0007,  ..., -0.0078,  0.0047,  0.0468]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.0046, -3.0547, -0.3198,  ...,  1.4707, -2.2832, -0.9570]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 05:50:10 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is the most shiny, it is shiniest
If something is the most dumb, it is dumbest
If something is the most hot, it is hottest
If something is the most merry, it is merriest
If something is the most noisy, it is noisiest
If something is the most cute, it is cutest
If something is the most rude, it is rudest
If something is the most happy, it is
2024-07-31 05:50:10 root INFO     [order_1_approx] starting weight calculation for If something is the most happy, it is happiest
If something is the most noisy, it is noisiest
If something is the most rude, it is rudest
If something is the most dumb, it is dumbest
If something is the most shiny, it is shiniest
If something is the most hot, it is hottest
If something is the most cute, it is cutest
If something is the most merry, it is
2024-07-31 05:50:10 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 05:52:10 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.3242,  0.4722, -0.2261,  ..., -0.1492, -1.4189, -0.4067],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-2.1367, -3.7617, -2.4062,  ...,  1.0068, -1.9902, -1.6572],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0718, -0.0106,  0.0160,  ..., -0.0117,  0.0201,  0.0325],
        [-0.0024,  0.0356,  0.0151,  ...,  0.0037,  0.0142,  0.0142],
        [ 0.0009, -0.0086,  0.0515,  ...,  0.0045, -0.0128, -0.0122],
        ...,
        [-0.0052,  0.0019, -0.0116,  ...,  0.0546, -0.0018, -0.0146],
        [ 0.0090,  0.0047, -0.0085,  ...,  0.0036,  0.0507, -0.0112],
        [ 0.0046, -0.0023, -0.0043,  ..., -0.0114,  0.0069,  0.0562]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-2.2246, -3.4785, -2.5547,  ...,  1.1904, -2.1816, -1.6211]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 05:52:11 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is the most happy, it is happiest
If something is the most noisy, it is noisiest
If something is the most rude, it is rudest
If something is the most dumb, it is dumbest
If something is the most shiny, it is shiniest
If something is the most hot, it is hottest
If something is the most cute, it is cutest
If something is the most merry, it is
2024-07-31 05:52:11 root INFO     [order_1_approx] starting weight calculation for If something is the most cute, it is cutest
If something is the most merry, it is merriest
If something is the most happy, it is happiest
If something is the most shiny, it is shiniest
If something is the most dumb, it is dumbest
If something is the most rude, it is rudest
If something is the most noisy, it is noisiest
If something is the most hot, it is
2024-07-31 05:52:11 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 05:54:10 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1442, -0.2064, -0.1009,  ...,  0.0714, -0.6226, -0.5645],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.5850, -4.3516, -3.3945,  ..., -2.0312, -2.9473,  0.4141],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0415, -0.0026, -0.0009,  ..., -0.0124, -0.0110,  0.0130],
        [ 0.0047,  0.0480,  0.0161,  ...,  0.0025,  0.0129, -0.0092],
        [ 0.0022, -0.0021,  0.0350,  ...,  0.0008, -0.0037,  0.0002],
        ...,
        [-0.0036,  0.0133,  0.0095,  ...,  0.0347,  0.0031, -0.0103],
        [ 0.0106,  0.0054,  0.0055,  ..., -0.0002,  0.0482, -0.0211],
        [ 0.0019, -0.0017, -0.0066,  ..., -0.0120,  0.0072,  0.0428]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.7070, -4.0195, -3.6172,  ..., -1.7070, -3.1094,  0.5225]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 05:54:11 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is the most cute, it is cutest
If something is the most merry, it is merriest
If something is the most happy, it is happiest
If something is the most shiny, it is shiniest
If something is the most dumb, it is dumbest
If something is the most rude, it is rudest
If something is the most noisy, it is noisiest
If something is the most hot, it is
2024-07-31 05:54:11 root INFO     [order_1_approx] starting weight calculation for If something is the most happy, it is happiest
If something is the most hot, it is hottest
If something is the most noisy, it is noisiest
If something is the most merry, it is merriest
If something is the most cute, it is cutest
If something is the most shiny, it is shiniest
If something is the most dumb, it is dumbest
If something is the most rude, it is
2024-07-31 05:54:12 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 05:56:09 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1096,  0.0405,  0.0923,  ..., -0.6240, -0.0034, -0.1058],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-2.7129, -4.3828,  0.4561,  ..., -2.2207, -1.8965, -1.9883],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0575, -0.0114,  0.0218,  ..., -0.0149,  0.0080,  0.0080],
        [ 0.0046,  0.0540,  0.0251,  ..., -0.0179,  0.0173,  0.0103],
        [ 0.0080,  0.0113,  0.0555,  ..., -0.0070, -0.0127, -0.0103],
        ...,
        [ 0.0171,  0.0280,  0.0021,  ...,  0.0385, -0.0037, -0.0116],
        [ 0.0041,  0.0041,  0.0111,  ...,  0.0039,  0.0506, -0.0192],
        [-0.0079, -0.0061, -0.0036,  ..., -0.0017,  0.0016,  0.0336]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-2.8105, -4.6406,  0.2299,  ..., -2.6309, -1.5273, -1.9199]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 05:56:10 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is the most happy, it is happiest
If something is the most hot, it is hottest
If something is the most noisy, it is noisiest
If something is the most merry, it is merriest
If something is the most cute, it is cutest
If something is the most shiny, it is shiniest
If something is the most dumb, it is dumbest
If something is the most rude, it is
2024-07-31 05:56:10 root INFO     [order_1_approx] starting weight calculation for If something is the most rude, it is rudest
If something is the most cute, it is cutest
If something is the most hot, it is hottest
If something is the most merry, it is merriest
If something is the most shiny, it is shiniest
If something is the most dumb, it is dumbest
If something is the most happy, it is happiest
If something is the most noisy, it is
2024-07-31 05:56:11 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 05:58:08 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.3640,  0.2651,  0.1204,  ..., -0.1726, -0.4275, -0.0288],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-4.7422, -4.1836, -0.9658,  ..., -1.5605, -1.8438,  0.0977],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 5.3345e-02, -9.5367e-06,  1.7151e-02,  ...,  1.2901e-02,
          5.1880e-04,  2.2308e-02],
        [-1.1330e-02,  4.7363e-02,  1.7365e-02,  ...,  1.1223e-02,
          1.0254e-02,  3.8261e-03],
        [ 8.2550e-03, -4.7340e-03,  3.7689e-02,  ..., -1.0345e-02,
          9.3613e-03, -1.5320e-02],
        ...,
        [ 7.8201e-03,  1.8860e-02,  1.0246e-02,  ...,  3.8605e-02,
         -8.6975e-03, -5.7793e-04],
        [ 5.7755e-03,  3.4180e-03,  1.8272e-03,  ...,  1.1597e-02,
          4.0070e-02, -6.3477e-03],
        [ 7.6294e-03,  4.4060e-03, -1.5305e-02,  ..., -1.5823e-02,
         -7.2098e-04,  3.6499e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-4.8711, -4.0859, -1.2178,  ..., -1.4639, -1.8867,  0.1531]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 05:58:09 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is the most rude, it is rudest
If something is the most cute, it is cutest
If something is the most hot, it is hottest
If something is the most merry, it is merriest
If something is the most shiny, it is shiniest
If something is the most dumb, it is dumbest
If something is the most happy, it is happiest
If something is the most noisy, it is
2024-07-31 05:58:09 root INFO     total operator prediction time: 946.0581238269806 seconds
2024-07-31 05:58:09 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on verb_3pSg - Ved
2024-07-31 05:58:09 root INFO     building operator verb_3pSg - Ved
2024-07-31 05:58:09 root INFO     [order_1_approx] starting weight calculation for When he appoints something, something has been appointed
When he suggests something, something has been suggested
When he happens something, something has been happened
When he operates something, something has been operated
When he loses something, something has been lost
When he decides something, something has been decided
When he represents something, something has been represented
When he proposes something, something has been
2024-07-31 05:58:09 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 06:00:06 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3621, -0.4888,  0.2263,  ..., -0.0561, -0.1578,  0.0765],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.2891, -1.3682,  1.7188,  ..., -0.0767, -1.3398,  0.7559],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0334, -0.0016,  0.0103,  ..., -0.0085, -0.0117,  0.0129],
        [-0.0079,  0.0062,  0.0132,  ...,  0.0134, -0.0096,  0.0117],
        [ 0.0009, -0.0055,  0.0216,  ..., -0.0071, -0.0071, -0.0129],
        ...,
        [-0.0058,  0.0049,  0.0030,  ...,  0.0257,  0.0023,  0.0051],
        [ 0.0079,  0.0031,  0.0051,  ..., -0.0053,  0.0290, -0.0249],
        [-0.0041,  0.0050,  0.0039,  ...,  0.0030, -0.0015,  0.0065]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.6016, -1.4512,  1.8584,  ..., -0.1907, -1.2324,  0.4573]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 06:00:07 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When he appoints something, something has been appointed
When he suggests something, something has been suggested
When he happens something, something has been happened
When he operates something, something has been operated
When he loses something, something has been lost
When he decides something, something has been decided
When he represents something, something has been represented
When he proposes something, something has been
2024-07-31 06:00:08 root INFO     [order_1_approx] starting weight calculation for When he suggests something, something has been suggested
When he happens something, something has been happened
When he operates something, something has been operated
When he proposes something, something has been proposed
When he loses something, something has been lost
When he represents something, something has been represented
When he decides something, something has been decided
When he appoints something, something has been
2024-07-31 06:00:08 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 06:02:03 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2019, -0.7495, -0.0564,  ...,  0.2520, -0.6899,  0.0986],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.2031, -0.3542,  1.7148,  ...,  1.0928, -2.0332,  0.2207],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0170, -0.0018,  0.0242,  ..., -0.0007, -0.0075,  0.0126],
        [-0.0081,  0.0111, -0.0027,  ...,  0.0159,  0.0028, -0.0057],
        [ 0.0035, -0.0030,  0.0086,  ...,  0.0005,  0.0016, -0.0104],
        ...,
        [ 0.0028,  0.0052, -0.0013,  ...,  0.0171, -0.0069,  0.0092],
        [ 0.0072,  0.0060,  0.0134,  ...,  0.0132,  0.0171, -0.0242],
        [ 0.0008,  0.0013,  0.0054,  ..., -0.0043, -0.0026,  0.0023]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.2266, -0.2964,  1.8975,  ...,  1.0977, -1.5781, -0.1401]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 06:02:04 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When he suggests something, something has been suggested
When he happens something, something has been happened
When he operates something, something has been operated
When he proposes something, something has been proposed
When he loses something, something has been lost
When he represents something, something has been represented
When he decides something, something has been decided
When he appoints something, something has been
2024-07-31 06:02:04 root INFO     [order_1_approx] starting weight calculation for When he loses something, something has been lost
When he appoints something, something has been appointed
When he decides something, something has been decided
When he suggests something, something has been suggested
When he proposes something, something has been proposed
When he represents something, something has been represented
When he operates something, something has been operated
When he happens something, something has been
2024-07-31 06:02:04 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 06:03:57 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.9644, -0.2312,  0.3062,  ..., -0.3281, -0.4561, -0.5210],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.7461,  1.6162,  3.6523,  ...,  0.1106, -3.9883,  0.8682],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 2.3376e-02, -1.9653e-02,  7.5874e-03,  ...,  1.8482e-03,
         -1.0658e-02,  6.3705e-04],
        [-1.9897e-02,  2.3285e-02, -9.6440e-05,  ...,  1.7380e-02,
          5.1575e-03, -1.7822e-02],
        [ 1.1482e-03,  6.0539e-03,  3.6530e-02,  ..., -1.8723e-02,
          5.6839e-03, -1.5549e-02],
        ...,
        [-8.2169e-03,  1.3611e-02, -2.3071e-02,  ...,  2.9648e-02,
          5.8212e-03, -1.0986e-03],
        [ 1.2505e-02,  3.7079e-02,  1.9951e-03,  ..., -1.1726e-02,
          4.0771e-02, -1.6342e-02],
        [-1.9970e-03, -1.1307e-02,  7.9651e-03,  ..., -1.5087e-03,
          6.6185e-04,  2.5452e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.0039,  1.7676,  3.9023,  ...,  0.4080, -3.8984,  0.6348]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 06:03:58 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When he loses something, something has been lost
When he appoints something, something has been appointed
When he decides something, something has been decided
When he suggests something, something has been suggested
When he proposes something, something has been proposed
When he represents something, something has been represented
When he operates something, something has been operated
When he happens something, something has been
2024-07-31 06:03:59 root INFO     [order_1_approx] starting weight calculation for When he operates something, something has been operated
When he happens something, something has been happened
When he proposes something, something has been proposed
When he appoints something, something has been appointed
When he represents something, something has been represented
When he decides something, something has been decided
When he loses something, something has been lost
When he suggests something, something has been
2024-07-31 06:03:59 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 06:05:56 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0391, -0.6816,  0.4854,  ..., -0.1147, -0.4995, -0.3154],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 5.1758, -0.2874, -0.3989,  ...,  1.4961,  0.6587,  0.5273],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0609,  0.0053,  0.0077,  ..., -0.0175, -0.0121,  0.0058],
        [-0.0131,  0.0357,  0.0012,  ...,  0.0253, -0.0089,  0.0018],
        [ 0.0090, -0.0048,  0.0391,  ..., -0.0082, -0.0012, -0.0192],
        ...,
        [-0.0127,  0.0068,  0.0047,  ...,  0.0388,  0.0029,  0.0108],
        [ 0.0039,  0.0058, -0.0006,  ...,  0.0032,  0.0390, -0.0277],
        [ 0.0004,  0.0044,  0.0061,  ..., -0.0113, -0.0073,  0.0146]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.7891, -0.1790, -0.3267,  ...,  1.4131,  0.3962,  0.4778]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 06:05:57 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When he operates something, something has been operated
When he happens something, something has been happened
When he proposes something, something has been proposed
When he appoints something, something has been appointed
When he represents something, something has been represented
When he decides something, something has been decided
When he loses something, something has been lost
When he suggests something, something has been
2024-07-31 06:05:57 root INFO     [order_1_approx] starting weight calculation for When he operates something, something has been operated
When he proposes something, something has been proposed
When he loses something, something has been lost
When he represents something, something has been represented
When he appoints something, something has been appointed
When he suggests something, something has been suggested
When he happens something, something has been happened
When he decides something, something has been
2024-07-31 06:05:57 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 06:07:56 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0270, -0.0999,  0.0457,  ..., -0.0408, -0.9932,  0.2021],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.8750, -1.8164,  2.7930,  ..., -0.0728, -2.1914,  0.3984],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 1.9409e-02, -1.2337e-02,  2.1759e-02,  ...,  8.3084e-03,
         -2.3327e-03,  7.4997e-03],
        [-2.2141e-02,  1.9211e-02,  7.3738e-03,  ...,  1.4420e-02,
         -1.9073e-05, -7.4005e-04],
        [ 1.4259e-02,  6.2866e-03,  1.9806e-02,  ..., -3.9101e-03,
         -4.7836e-03, -1.9226e-02],
        ...,
        [ 1.2512e-03,  8.8196e-03, -2.3270e-03,  ...,  3.1372e-02,
         -4.6120e-03,  6.3400e-03],
        [ 1.0033e-02,  2.7351e-03,  9.2506e-04,  ..., -5.9814e-03,
          2.8000e-02, -1.5869e-02],
        [ 2.5330e-03, -9.5062e-03,  4.0321e-03,  ..., -1.0849e-02,
          2.4796e-05,  1.0941e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.9277, -1.4980,  2.8438,  ...,  0.0443, -2.0039,  0.3804]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 06:07:57 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When he operates something, something has been operated
When he proposes something, something has been proposed
When he loses something, something has been lost
When he represents something, something has been represented
When he appoints something, something has been appointed
When he suggests something, something has been suggested
When he happens something, something has been happened
When he decides something, something has been
2024-07-31 06:07:57 root INFO     [order_1_approx] starting weight calculation for When he loses something, something has been lost
When he suggests something, something has been suggested
When he appoints something, something has been appointed
When he decides something, something has been decided
When he happens something, something has been happened
When he operates something, something has been operated
When he proposes something, something has been proposed
When he represents something, something has been
2024-07-31 06:07:57 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 06:09:55 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0239,  0.4277, -0.0717,  ..., -0.2231, -0.1318,  0.1400],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.2793,  1.2764,  2.3965,  ...,  0.3916, -1.9941, -0.8457],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0535, -0.0019,  0.0147,  ...,  0.0023, -0.0026,  0.0020],
        [-0.0259,  0.0428, -0.0004,  ...,  0.0115,  0.0062, -0.0055],
        [ 0.0010, -0.0066,  0.0536,  ..., -0.0121,  0.0047, -0.0211],
        ...,
        [-0.0027, -0.0012, -0.0078,  ...,  0.0639, -0.0005,  0.0095],
        [ 0.0089, -0.0006,  0.0118,  ..., -0.0053,  0.0558, -0.0227],
        [-0.0018,  0.0025,  0.0061,  ..., -0.0080, -0.0016,  0.0500]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.2312,  1.3506,  2.5508,  ...,  0.2407, -2.0488, -0.8691]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 06:09:56 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When he loses something, something has been lost
When he suggests something, something has been suggested
When he appoints something, something has been appointed
When he decides something, something has been decided
When he happens something, something has been happened
When he operates something, something has been operated
When he proposes something, something has been proposed
When he represents something, something has been
2024-07-31 06:09:56 root INFO     [order_1_approx] starting weight calculation for When he appoints something, something has been appointed
When he decides something, something has been decided
When he represents something, something has been represented
When he happens something, something has been happened
When he proposes something, something has been proposed
When he suggests something, something has been suggested
When he loses something, something has been lost
When he operates something, something has been
2024-07-31 06:09:56 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 06:11:54 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2827, -0.6655, -0.5615,  ..., -0.1580, -0.8828, -0.1083],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.0938, -0.7910,  2.9297,  ..., -1.5508, -0.1145, -1.0264],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0368,  0.0030,  0.0137,  ...,  0.0076, -0.0094,  0.0154],
        [-0.0149,  0.0297,  0.0064,  ...,  0.0134,  0.0108, -0.0025],
        [ 0.0097,  0.0028,  0.0319,  ..., -0.0121,  0.0105, -0.0094],
        ...,
        [-0.0084,  0.0154, -0.0069,  ...,  0.0469,  0.0022, -0.0053],
        [ 0.0094,  0.0014, -0.0080,  ...,  0.0006,  0.0364, -0.0321],
        [ 0.0041, -0.0068, -0.0009,  ..., -0.0154, -0.0095,  0.0235]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.2500, -0.8730,  3.0938,  ..., -1.3984, -0.0654, -0.7559]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 06:11:55 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When he appoints something, something has been appointed
When he decides something, something has been decided
When he represents something, something has been represented
When he happens something, something has been happened
When he proposes something, something has been proposed
When he suggests something, something has been suggested
When he loses something, something has been lost
When he operates something, something has been
2024-07-31 06:11:55 root INFO     [order_1_approx] starting weight calculation for When he represents something, something has been represented
When he suggests something, something has been suggested
When he operates something, something has been operated
When he happens something, something has been happened
When he decides something, something has been decided
When he appoints something, something has been appointed
When he proposes something, something has been proposed
When he loses something, something has been
2024-07-31 06:11:55 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 06:13:54 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1615,  0.1729,  0.2104,  ..., -0.4424, -0.0088,  0.0420],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.0430, -0.6963,  1.1768,  ..., -0.5889, -0.0693, -1.7568],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0483, -0.0092,  0.0247,  ...,  0.0022, -0.0082,  0.0038],
        [-0.0038,  0.0269, -0.0016,  ...,  0.0094,  0.0046, -0.0092],
        [ 0.0119, -0.0079,  0.0357,  ..., -0.0101,  0.0041, -0.0177],
        ...,
        [ 0.0056,  0.0302, -0.0052,  ...,  0.0444, -0.0131,  0.0089],
        [ 0.0093,  0.0102, -0.0110,  ..., -0.0132,  0.0380, -0.0312],
        [-0.0095, -0.0017,  0.0113,  ..., -0.0173, -0.0052,  0.0233]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.9863, -0.8271,  1.4492,  ..., -0.6045, -0.2346, -1.5957]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 06:13:55 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When he represents something, something has been represented
When he suggests something, something has been suggested
When he operates something, something has been operated
When he happens something, something has been happened
When he decides something, something has been decided
When he appoints something, something has been appointed
When he proposes something, something has been proposed
When he loses something, something has been
2024-07-31 06:13:55 root INFO     total operator prediction time: 946.0490272045135 seconds
2024-07-31 06:13:55 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on noun - plural_reg
2024-07-31 06:13:55 root INFO     building operator noun - plural_reg
2024-07-31 06:13:55 root INFO     [order_1_approx] starting weight calculation for The plural form of year is years
The plural form of student is students
The plural form of system is systems
The plural form of week is weeks
The plural form of office is offices
The plural form of river is rivers
The plural form of member is members
The plural form of problem is
2024-07-31 06:13:55 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 06:15:50 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0684, -0.0463,  0.2729,  ..., -0.5581, -0.5391, -0.1243],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.8281, -3.0859,  0.7559,  ..., -0.2588,  0.0547, -0.3320],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0706, -0.0600, -0.0057,  ...,  0.0003,  0.0197, -0.0256],
        [ 0.0062,  0.1023,  0.0065,  ...,  0.0179, -0.0141,  0.0267],
        [-0.0043, -0.0172,  0.0767,  ..., -0.0035,  0.0044,  0.0018],
        ...,
        [ 0.0097,  0.0452,  0.0093,  ...,  0.0874, -0.0248,  0.0334],
        [-0.0174,  0.0028,  0.0082,  ...,  0.0019,  0.0617, -0.0051],
        [ 0.0075,  0.0272, -0.0034,  ...,  0.0023, -0.0172,  0.0800]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.5645, -2.9824,  0.7549,  ...,  0.1440,  0.1218, -0.4412]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 06:15:51 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of year is years
The plural form of student is students
The plural form of system is systems
The plural form of week is weeks
The plural form of office is offices
The plural form of river is rivers
The plural form of member is members
The plural form of problem is
2024-07-31 06:15:52 root INFO     [order_1_approx] starting weight calculation for The plural form of student is students
The plural form of year is years
The plural form of member is members
The plural form of office is offices
The plural form of system is systems
The plural form of problem is problems
The plural form of river is rivers
The plural form of week is
2024-07-31 06:15:52 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 06:17:50 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1794,  0.1548, -0.1169,  ...,  0.0105, -0.1591, -0.2262],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.0371, -4.3398,  0.1201,  ..., -0.1982,  0.7432, -1.5156],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0883, -0.0047,  0.0103,  ...,  0.0020,  0.0075,  0.0175],
        [-0.0050,  0.0927,  0.0001,  ...,  0.0196,  0.0077,  0.0081],
        [ 0.0019,  0.0111,  0.0760,  ...,  0.0021, -0.0195,  0.0270],
        ...,
        [-0.0009,  0.0182,  0.0080,  ...,  0.0842, -0.0202,  0.0152],
        [-0.0248,  0.0013,  0.0021,  ..., -0.0030,  0.0686, -0.0107],
        [-0.0097,  0.0161, -0.0224,  ..., -0.0039, -0.0138,  0.0947]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.9399, -4.4453,  0.6143,  ...,  0.0416,  0.7842, -1.2051]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 06:17:51 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of student is students
The plural form of year is years
The plural form of member is members
The plural form of office is offices
The plural form of system is systems
The plural form of problem is problems
The plural form of river is rivers
The plural form of week is
2024-07-31 06:17:51 root INFO     [order_1_approx] starting weight calculation for The plural form of office is offices
The plural form of problem is problems
The plural form of river is rivers
The plural form of student is students
The plural form of week is weeks
The plural form of member is members
The plural form of system is systems
The plural form of year is
2024-07-31 06:17:51 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 06:19:45 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3169,  0.3191, -0.1602,  ..., -0.3701, -0.2491,  0.2932],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.2969, -4.9375,  2.2520,  ..., -1.3457, -0.3408, -4.2969],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 5.5176e-02,  7.4692e-03,  3.7689e-03,  ...,  6.4735e-03,
         -3.4504e-03,  1.2672e-02],
        [-1.4641e-02,  8.1116e-02,  1.2497e-02,  ...,  1.5945e-02,
         -3.0403e-03,  1.0574e-02],
        [ 8.7128e-03, -1.0757e-03,  5.1849e-02,  ..., -6.2027e-03,
         -1.5572e-02,  4.9820e-03],
        ...,
        [-8.3084e-03,  8.9417e-03, -3.4332e-05,  ...,  4.9530e-02,
         -3.2349e-02,  1.1711e-02],
        [-1.2589e-02,  2.1851e-02,  3.2787e-03,  ...,  2.0081e-02,
          3.0762e-02, -6.9771e-03],
        [-2.2812e-02,  1.4374e-02, -5.1231e-03,  ...,  4.3793e-03,
         -1.3580e-02,  6.1279e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.1621, -4.5547,  2.4551,  ..., -1.2402, -0.0447, -4.0781]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 06:19:46 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of office is offices
The plural form of problem is problems
The plural form of river is rivers
The plural form of student is students
The plural form of week is weeks
The plural form of member is members
The plural form of system is systems
The plural form of year is
2024-07-31 06:19:46 root INFO     [order_1_approx] starting weight calculation for The plural form of week is weeks
The plural form of river is rivers
The plural form of problem is problems
The plural form of member is members
The plural form of system is systems
The plural form of student is students
The plural form of year is years
The plural form of office is
2024-07-31 06:19:47 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 06:21:46 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0066,  0.5215, -0.5161,  ..., -0.0810, -0.5449, -0.8647],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.0117, -2.9668,  1.4297,  ..., -0.3760,  0.4121, -0.9868],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0701, -0.0006,  0.0065,  ...,  0.0014, -0.0018,  0.0249],
        [-0.0107,  0.0678,  0.0144,  ...,  0.0120,  0.0049, -0.0031],
        [ 0.0197,  0.0182,  0.0922,  ..., -0.0165, -0.0105, -0.0056],
        ...,
        [ 0.0137,  0.0188, -0.0012,  ...,  0.0654, -0.0133,  0.0162],
        [-0.0273,  0.0279,  0.0100,  ..., -0.0013,  0.0600, -0.0051],
        [ 0.0048, -0.0061, -0.0218,  ...,  0.0154, -0.0087,  0.0659]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.0039, -2.7676,  1.8438,  ..., -0.4910,  0.5596, -0.7959]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 06:21:47 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of week is weeks
The plural form of river is rivers
The plural form of problem is problems
The plural form of member is members
The plural form of system is systems
The plural form of student is students
The plural form of year is years
The plural form of office is
2024-07-31 06:21:47 root INFO     [order_1_approx] starting weight calculation for The plural form of student is students
The plural form of office is offices
The plural form of problem is problems
The plural form of year is years
The plural form of river is rivers
The plural form of member is members
The plural form of week is weeks
The plural form of system is
2024-07-31 06:21:47 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 06:23:48 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.5752,  0.5337, -0.0334,  ..., -0.3755, -0.5859, -0.0742],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.8398, -2.4219,  0.1218,  ..., -1.0586, -0.4297, -1.5938],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0822,  0.0193,  0.0164,  ..., -0.0110,  0.0109,  0.0085],
        [-0.0144,  0.0745,  0.0134,  ..., -0.0019,  0.0060,  0.0108],
        [ 0.0056, -0.0011,  0.0828,  ...,  0.0063, -0.0139,  0.0064],
        ...,
        [ 0.0014,  0.0030,  0.0039,  ...,  0.0876, -0.0211,  0.0108],
        [-0.0231,  0.0141,  0.0092,  ..., -0.0159,  0.0559, -0.0222],
        [ 0.0042,  0.0109, -0.0120,  ...,  0.0023, -0.0152,  0.0667]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.1426, -1.9150,  0.3447,  ..., -0.9810,  0.0957, -1.0605]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 06:23:49 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of student is students
The plural form of office is offices
The plural form of problem is problems
The plural form of year is years
The plural form of river is rivers
The plural form of member is members
The plural form of week is weeks
The plural form of system is
2024-07-31 06:23:50 root INFO     [order_1_approx] starting weight calculation for The plural form of problem is problems
The plural form of student is students
The plural form of office is offices
The plural form of system is systems
The plural form of member is members
The plural form of year is years
The plural form of week is weeks
The plural form of river is
2024-07-31 06:23:50 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 06:25:44 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 2.9102e-01,  4.5654e-01, -2.4414e-04,  ..., -5.1074e-01,
        -2.5439e-01, -1.4124e-01], device='cuda:1', dtype=torch.float16,
       grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-3.0781, -6.3047,  2.2812,  ..., -1.9824,  2.0547, -2.0332],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0858, -0.0021,  0.0105,  ..., -0.0174,  0.0156, -0.0153],
        [ 0.0101,  0.0702,  0.0031,  ..., -0.0087,  0.0196,  0.0017],
        [-0.0020,  0.0148,  0.0684,  ...,  0.0071, -0.0005, -0.0043],
        ...,
        [-0.0049, -0.0028,  0.0032,  ...,  0.0872,  0.0089, -0.0070],
        [-0.0012,  0.0079, -0.0126,  ..., -0.0138,  0.0657, -0.0023],
        [-0.0037, -0.0040, -0.0114,  ..., -0.0064, -0.0075,  0.0555]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-2.8770, -6.1562,  2.3770,  ..., -1.8633,  2.1387, -1.8711]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 06:25:45 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of problem is problems
The plural form of student is students
The plural form of office is offices
The plural form of system is systems
The plural form of member is members
The plural form of year is years
The plural form of week is weeks
The plural form of river is
2024-07-31 06:25:46 root INFO     [order_1_approx] starting weight calculation for The plural form of week is weeks
The plural form of office is offices
The plural form of river is rivers
The plural form of student is students
The plural form of system is systems
The plural form of year is years
The plural form of problem is problems
The plural form of member is
2024-07-31 06:25:46 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 06:27:42 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.9697,  0.0569, -0.4509,  ..., -0.2812,  0.1432, -0.4570],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.5151, -1.4082,  1.2129,  ..., -1.3301,  0.9473, -3.4375],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 9.3262e-02, -2.1240e-02,  2.7588e-02,  ...,  9.5749e-04,
         -2.4963e-02, -1.8326e-02],
        [-1.7868e-02,  1.1157e-01,  4.3869e-03,  ...,  4.2572e-03,
          8.6975e-04,  2.7298e-02],
        [ 1.5366e-02,  5.3406e-05,  7.8979e-02,  ..., -1.6083e-02,
         -3.1281e-03,  1.1757e-02],
        ...,
        [ 9.4452e-03,  3.0579e-02,  3.2806e-03,  ...,  1.0938e-01,
         -6.0616e-03,  1.9058e-02],
        [-1.3687e-02,  1.4984e-02, -1.6747e-03,  ..., -4.1046e-03,
          6.0516e-02, -2.7428e-03],
        [ 6.8512e-03,  1.2772e-02, -1.0162e-02,  ...,  6.1531e-03,
          3.9902e-03,  9.3018e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.0718, -0.5610,  1.3311,  ..., -0.6050,  1.3242, -2.6621]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 06:27:43 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of week is weeks
The plural form of office is offices
The plural form of river is rivers
The plural form of student is students
The plural form of system is systems
The plural form of year is years
The plural form of problem is problems
The plural form of member is
2024-07-31 06:27:43 root INFO     [order_1_approx] starting weight calculation for The plural form of year is years
The plural form of member is members
The plural form of office is offices
The plural form of river is rivers
The plural form of system is systems
The plural form of problem is problems
The plural form of week is weeks
The plural form of student is
2024-07-31 06:27:44 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 06:29:40 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2739,  0.2651, -0.4106,  ..., -0.1980, -0.3540, -0.0031],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.0176, -1.3828,  2.7871,  ...,  0.0872,  0.4541, -1.6631],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0678, -0.0082,  0.0148,  ..., -0.0151, -0.0177, -0.0039],
        [-0.0045,  0.0809, -0.0004,  ...,  0.0077,  0.0138,  0.0131],
        [ 0.0043,  0.0048,  0.0684,  ..., -0.0155, -0.0072,  0.0014],
        ...,
        [ 0.0041,  0.0235, -0.0081,  ...,  0.0849, -0.0020,  0.0055],
        [-0.0157,  0.0103,  0.0141,  ..., -0.0382,  0.0379, -0.0086],
        [ 0.0022,  0.0141, -0.0333,  ...,  0.0149, -0.0135,  0.0694]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.1738, -1.4570,  2.8184,  ..., -0.1260,  0.8740, -1.6201]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 06:29:41 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of year is years
The plural form of member is members
The plural form of office is offices
The plural form of river is rivers
The plural form of system is systems
The plural form of problem is problems
The plural form of week is weeks
The plural form of student is
2024-07-31 06:29:41 root INFO     total operator prediction time: 945.7164433002472 seconds
2024-07-31 06:29:41 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on verb_Ving - 3pSg
2024-07-31 06:29:41 root INFO     building operator verb_Ving - 3pSg
2024-07-31 06:29:41 root INFO     [order_1_approx] starting weight calculation for When something is depending, it depends
When something is existing, it exists
When something is suggesting, it suggests
When something is appearing, it appears
When something is spending, it spends
When something is continuing, it continues
When something is discovering, it discovers
When something is happening, it
2024-07-31 06:29:41 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 06:31:37 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.3711, -0.7144,  0.1702,  ..., -0.1377,  0.1501, -0.8530],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.9258, -2.6426, -0.0742,  ...,  0.2554, -5.8047, -0.5957],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 5.1392e-02, -3.7842e-03,  6.3248e-03,  ..., -7.0953e-04,
         -4.9057e-03,  4.1046e-03],
        [-1.4435e-02,  4.7058e-02,  4.3526e-03,  ...,  6.2828e-03,
         -7.6141e-03,  6.1798e-04],
        [ 7.7133e-03,  1.6037e-02,  3.9124e-02,  ..., -1.3458e-02,
          1.0201e-02, -1.1299e-02],
        ...,
        [ 9.1095e-03,  1.1902e-02,  2.2888e-04,  ...,  5.3406e-02,
         -2.0844e-02, -5.8670e-03],
        [ 3.8147e-06,  1.3878e-02,  1.7052e-03,  ..., -8.7814e-03,
          5.7526e-02, -3.0365e-02],
        [ 8.3923e-04,  3.7098e-03,  3.5858e-03,  ..., -1.2016e-04,
         -1.3130e-02,  6.6406e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.1309, -2.6797, -0.2495,  ...,  0.7832, -5.3672, -0.6768]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 06:31:38 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When something is depending, it depends
When something is existing, it exists
When something is suggesting, it suggests
When something is appearing, it appears
When something is spending, it spends
When something is continuing, it continues
When something is discovering, it discovers
When something is happening, it
2024-07-31 06:31:38 root INFO     [order_1_approx] starting weight calculation for When something is suggesting, it suggests
When something is happening, it happens
When something is depending, it depends
When something is continuing, it continues
When something is existing, it exists
When something is spending, it spends
When something is discovering, it discovers
When something is appearing, it
2024-07-31 06:31:38 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 06:33:37 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4946, -0.3738, -0.4219,  ..., -0.1821,  0.4656, -0.6045],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.1660, -3.9746, -2.0156,  ...,  2.0000, -5.3516,  1.3633],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0693,  0.0076,  0.0301,  ...,  0.0057, -0.0029,  0.0133],
        [-0.0048,  0.0602,  0.0052,  ...,  0.0274, -0.0069, -0.0159],
        [ 0.0016,  0.0049,  0.0618,  ..., -0.0289,  0.0114, -0.0193],
        ...,
        [-0.0022,  0.0038,  0.0035,  ...,  0.0694, -0.0182,  0.0004],
        [ 0.0006, -0.0009,  0.0114,  ..., -0.0242,  0.0704, -0.0199],
        [ 0.0064, -0.0019,  0.0021,  ..., -0.0147, -0.0111,  0.0737]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.5127, -3.7734, -2.0039,  ...,  2.5957, -5.5859,  1.3125]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 06:33:38 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When something is suggesting, it suggests
When something is happening, it happens
When something is depending, it depends
When something is continuing, it continues
When something is existing, it exists
When something is spending, it spends
When something is discovering, it discovers
When something is appearing, it
2024-07-31 06:33:39 root INFO     [order_1_approx] starting weight calculation for When something is discovering, it discovers
When something is continuing, it continues
When something is existing, it exists
When something is appearing, it appears
When something is depending, it depends
When something is happening, it happens
When something is suggesting, it suggests
When something is spending, it
2024-07-31 06:33:39 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 06:35:34 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0639, -0.0262,  0.1389,  ..., -0.1726, -0.1519, -0.2051],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.5742, -1.5908, -3.9141,  ..., -0.4795, -4.6406, -2.8555],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0621, -0.0052,  0.0107,  ..., -0.0121, -0.0012,  0.0081],
        [-0.0176,  0.0478, -0.0059,  ...,  0.0110,  0.0125,  0.0038],
        [ 0.0092,  0.0026,  0.0460,  ..., -0.0161, -0.0099, -0.0212],
        ...,
        [ 0.0015, -0.0011,  0.0290,  ...,  0.0596, -0.0117, -0.0078],
        [ 0.0037,  0.0082,  0.0064,  ..., -0.0022,  0.0658, -0.0279],
        [-0.0159, -0.0031, -0.0022,  ..., -0.0056, -0.0135,  0.0637]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.6328, -1.4531, -4.0156,  ..., -0.2976, -4.7148, -2.9316]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 06:35:35 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When something is discovering, it discovers
When something is continuing, it continues
When something is existing, it exists
When something is appearing, it appears
When something is depending, it depends
When something is happening, it happens
When something is suggesting, it suggests
When something is spending, it
2024-07-31 06:35:35 root INFO     [order_1_approx] starting weight calculation for When something is existing, it exists
When something is continuing, it continues
When something is appearing, it appears
When something is spending, it spends
When something is discovering, it discovers
When something is happening, it happens
When something is suggesting, it suggests
When something is depending, it
2024-07-31 06:35:35 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 06:37:33 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0048,  0.1797, -0.6846,  ..., -0.8579, -0.2788, -0.6724],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.9531, -0.3831,  0.8398,  ..., -1.5908, -4.9258,  0.3008],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0740, -0.0113,  0.0077,  ..., -0.0009,  0.0092,  0.0024],
        [-0.0058,  0.0724,  0.0007,  ...,  0.0200, -0.0032,  0.0001],
        [ 0.0163,  0.0199,  0.0422,  ..., -0.0289, -0.0053, -0.0097],
        ...,
        [ 0.0070,  0.0041,  0.0236,  ...,  0.0713,  0.0057, -0.0015],
        [-0.0132,  0.0066,  0.0075,  ..., -0.0120,  0.0731, -0.0298],
        [ 0.0020,  0.0014,  0.0013,  ..., -0.0154, -0.0136,  0.0790]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.7617, -0.1111,  0.4375,  ..., -1.2705, -4.5430,  0.1790]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 06:37:33 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When something is existing, it exists
When something is continuing, it continues
When something is appearing, it appears
When something is spending, it spends
When something is discovering, it discovers
When something is happening, it happens
When something is suggesting, it suggests
When something is depending, it
2024-07-31 06:37:34 root INFO     [order_1_approx] starting weight calculation for When something is existing, it exists
When something is continuing, it continues
When something is appearing, it appears
When something is depending, it depends
When something is spending, it spends
When something is suggesting, it suggests
When something is happening, it happens
When something is discovering, it
2024-07-31 06:37:34 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 06:39:26 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3086, -0.2496, -0.1477,  ..., -0.2566, -0.9688,  0.2734],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.1250, -4.0820,  1.5996,  ...,  0.1348, -4.9375,  1.0176],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0455,  0.0011,  0.0255,  ...,  0.0117, -0.0100,  0.0018],
        [-0.0041,  0.0350,  0.0058,  ...,  0.0125, -0.0078,  0.0061],
        [ 0.0015,  0.0018,  0.0284,  ..., -0.0187,  0.0063, -0.0250],
        ...,
        [ 0.0073,  0.0006,  0.0035,  ...,  0.0383, -0.0068,  0.0026],
        [ 0.0011,  0.0057, -0.0137,  ..., -0.0145,  0.0422, -0.0154],
        [ 0.0044, -0.0023,  0.0062,  ..., -0.0117, -0.0052,  0.0357]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.2246, -3.7871,  1.6816,  ...,  0.4890, -5.0078,  0.7886]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 06:39:27 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When something is existing, it exists
When something is continuing, it continues
When something is appearing, it appears
When something is depending, it depends
When something is spending, it spends
When something is suggesting, it suggests
When something is happening, it happens
When something is discovering, it
2024-07-31 06:39:27 root INFO     [order_1_approx] starting weight calculation for When something is depending, it depends
When something is happening, it happens
When something is appearing, it appears
When something is spending, it spends
When something is suggesting, it suggests
When something is existing, it exists
When something is discovering, it discovers
When something is continuing, it
2024-07-31 06:39:27 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 06:41:22 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.7705, -0.5322, -0.3394,  ..., -0.5298, -0.4363,  0.5576],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.2422, -3.7305, -0.3008,  ..., -1.1826, -1.7910, -0.4648],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0620, -0.0049,  0.0022,  ...,  0.0005,  0.0073,  0.0238],
        [ 0.0041,  0.0503,  0.0017,  ...,  0.0158,  0.0049,  0.0080],
        [ 0.0032,  0.0185,  0.0411,  ..., -0.0144,  0.0016, -0.0175],
        ...,
        [ 0.0045,  0.0024,  0.0104,  ...,  0.0527, -0.0014, -0.0068],
        [-0.0024,  0.0210, -0.0024,  ..., -0.0137,  0.0457, -0.0361],
        [-0.0089,  0.0010,  0.0076,  ..., -0.0197, -0.0107,  0.0357]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.4531, -3.4531, -0.3848,  ..., -0.9873, -1.8252, -0.6895]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 06:41:23 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When something is depending, it depends
When something is happening, it happens
When something is appearing, it appears
When something is spending, it spends
When something is suggesting, it suggests
When something is existing, it exists
When something is discovering, it discovers
When something is continuing, it
2024-07-31 06:41:23 root INFO     [order_1_approx] starting weight calculation for When something is discovering, it discovers
When something is spending, it spends
When something is existing, it exists
When something is happening, it happens
When something is appearing, it appears
When something is depending, it depends
When something is continuing, it continues
When something is suggesting, it
2024-07-31 06:41:23 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 06:43:23 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4197, -0.3264,  0.2318,  ..., -0.1807, -0.2323, -0.3799],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 5.8242, -2.9707, -1.7500,  ...,  2.4258, -3.5508,  1.5098],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0920, -0.0039,  0.0064,  ..., -0.0131,  0.0030,  0.0147],
        [-0.0307,  0.0573,  0.0038,  ...,  0.0209, -0.0082,  0.0076],
        [-0.0023, -0.0144,  0.0535,  ..., -0.0219,  0.0087, -0.0173],
        ...,
        [-0.0154, -0.0046,  0.0134,  ...,  0.0693, -0.0007,  0.0049],
        [ 0.0020,  0.0097, -0.0068,  ..., -0.0112,  0.0583, -0.0310],
        [ 0.0093,  0.0168, -0.0032,  ..., -0.0092, -0.0144,  0.0493]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 5.5508, -3.0859, -1.3418,  ...,  2.3633, -3.4277,  1.4170]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 06:43:24 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When something is discovering, it discovers
When something is spending, it spends
When something is existing, it exists
When something is happening, it happens
When something is appearing, it appears
When something is depending, it depends
When something is continuing, it continues
When something is suggesting, it
2024-07-31 06:43:24 root INFO     [order_1_approx] starting weight calculation for When something is continuing, it continues
When something is discovering, it discovers
When something is happening, it happens
When something is appearing, it appears
When something is spending, it spends
When something is depending, it depends
When something is suggesting, it suggests
When something is existing, it
2024-07-31 06:43:24 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 06:45:20 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0473, -0.3086, -1.0869,  ..., -0.4363, -0.4734, -0.4600],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.1250, -3.3555, -1.2949,  ..., -0.8535, -3.9980, -0.2354],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0558, -0.0069,  0.0138,  ...,  0.0019, -0.0097,  0.0057],
        [-0.0079,  0.0569, -0.0079,  ...,  0.0250,  0.0026, -0.0119],
        [ 0.0062,  0.0019,  0.0528,  ..., -0.0191,  0.0020, -0.0113],
        ...,
        [-0.0083,  0.0128,  0.0024,  ...,  0.0739, -0.0079,  0.0135],
        [-0.0205,  0.0154,  0.0062,  ..., -0.0160,  0.0575, -0.0195],
        [ 0.0076, -0.0028, -0.0032,  ..., -0.0074, -0.0135,  0.0692]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.0605, -3.3535, -1.2197,  ..., -0.2524, -3.7324, -0.4375]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 06:45:21 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When something is continuing, it continues
When something is discovering, it discovers
When something is happening, it happens
When something is appearing, it appears
When something is spending, it spends
When something is depending, it depends
When something is suggesting, it suggests
When something is existing, it
2024-07-31 06:45:21 root INFO     total operator prediction time: 940.3555212020874 seconds
2024-07-31 06:45:21 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on verb_inf - 3pSg
2024-07-31 06:45:21 root INFO     building operator verb_inf - 3pSg
2024-07-31 06:45:21 root INFO     [order_1_approx] starting weight calculation for I protect, he protects
I remain, he remains
I explain, he explains
I suggest, he suggests
I remember, he remembers
I reduce, he reduces
I become, he becomes
I include, he
2024-07-31 06:45:21 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 06:47:18 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.4043,  0.4292,  0.1792,  ...,  0.0071,  0.1222, -0.3477],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.2227, -1.8418,  0.0312,  ..., -0.7695, -6.1484, -1.0654],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 4.3274e-02, -2.8381e-03,  6.5346e-03,  ..., -3.0518e-04,
          1.4877e-04,  1.4091e-02],
        [-5.7220e-03,  5.0873e-02, -1.0666e-02,  ..., -5.1498e-03,
         -7.1030e-03, -2.3766e-03],
        [-9.1267e-04, -3.1319e-03,  3.2257e-02,  ..., -1.3878e-02,
         -1.2741e-03,  2.9945e-03],
        ...,
        [ 7.6294e-05, -7.7744e-03,  2.2240e-03,  ...,  5.9418e-02,
         -1.0292e-02,  1.1002e-02],
        [-7.2708e-03, -6.8665e-03,  1.7914e-02,  ..., -6.7329e-03,
          3.6530e-02, -1.5068e-02],
        [-2.3766e-03,  2.2125e-04, -2.7809e-03,  ..., -8.4381e-03,
         -1.4198e-02,  4.9011e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.8340, -1.7393,  0.5049,  ..., -0.7573, -5.8711, -0.5571]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 06:47:19 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for I protect, he protects
I remain, he remains
I explain, he explains
I suggest, he suggests
I remember, he remembers
I reduce, he reduces
I become, he becomes
I include, he
2024-07-31 06:47:19 root INFO     [order_1_approx] starting weight calculation for I suggest, he suggests
I include, he includes
I reduce, he reduces
I protect, he protects
I remember, he remembers
I remain, he remains
I explain, he explains
I become, he
2024-07-31 06:47:19 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 06:49:17 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3223,  0.2646, -0.0948,  ..., -0.2391, -0.2166,  0.7412],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.5273, -2.9492,  0.2012,  ...,  0.0142, -2.4395, -0.8828],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0705, -0.0074,  0.0141,  ...,  0.0028, -0.0093,  0.0259],
        [-0.0075,  0.0440, -0.0107,  ...,  0.0124, -0.0012, -0.0094],
        [ 0.0039,  0.0016,  0.0423,  ..., -0.0169,  0.0071, -0.0142],
        ...,
        [-0.0024, -0.0093,  0.0035,  ...,  0.0643, -0.0091,  0.0018],
        [ 0.0065,  0.0018, -0.0083,  ..., -0.0225,  0.0369,  0.0008],
        [-0.0072, -0.0048,  0.0076,  ..., -0.0082, -0.0137,  0.0431]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.2695, -2.9023,  0.2603,  ...,  0.0373, -2.7227, -0.7178]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 06:49:18 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for I suggest, he suggests
I include, he includes
I reduce, he reduces
I protect, he protects
I remember, he remembers
I remain, he remains
I explain, he explains
I become, he
2024-07-31 06:49:18 root INFO     [order_1_approx] starting weight calculation for I protect, he protects
I suggest, he suggests
I explain, he explains
I remember, he remembers
I become, he becomes
I include, he includes
I remain, he remains
I reduce, he
2024-07-31 06:49:18 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 06:51:13 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2783,  0.2561, -0.3855,  ..., -0.5039,  0.1968,  0.0400],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.2500, -2.3281, -0.2383,  ..., -3.0488, -7.7344, -3.8105],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0540, -0.0009,  0.0212,  ..., -0.0046,  0.0019,  0.0230],
        [-0.0061,  0.0450, -0.0040,  ...,  0.0034,  0.0037,  0.0022],
        [-0.0009,  0.0034,  0.0523,  ..., -0.0064, -0.0090, -0.0055],
        ...,
        [ 0.0046,  0.0049,  0.0103,  ...,  0.0710, -0.0160,  0.0042],
        [-0.0092, -0.0035,  0.0028,  ..., -0.0008,  0.0463, -0.0151],
        [-0.0087,  0.0023,  0.0061,  ..., -0.0096, -0.0069,  0.0537]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.1646, -2.3906, -0.0946,  ..., -2.7246, -7.3125, -3.5586]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 06:51:14 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for I protect, he protects
I suggest, he suggests
I explain, he explains
I remember, he remembers
I become, he becomes
I include, he includes
I remain, he remains
I reduce, he
2024-07-31 06:51:14 root INFO     [order_1_approx] starting weight calculation for I remain, he remains
I explain, he explains
I reduce, he reduces
I include, he includes
I suggest, he suggests
I become, he becomes
I protect, he protects
I remember, he
2024-07-31 06:51:14 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 06:53:07 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.9888, -0.1022,  0.0798,  ..., -0.8931, -0.1820,  0.0063],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.2324, -3.1523, -2.3203,  ..., -1.5068, -7.3594, -1.3965],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0273,  0.0034,  0.0159,  ..., -0.0011,  0.0021,  0.0188],
        [-0.0087,  0.0365,  0.0004,  ...,  0.0030,  0.0020, -0.0080],
        [-0.0012, -0.0011,  0.0227,  ..., -0.0165, -0.0135, -0.0089],
        ...,
        [-0.0002,  0.0047,  0.0084,  ...,  0.0328, -0.0119,  0.0017],
        [ 0.0010, -0.0140, -0.0094,  ..., -0.0146,  0.0228, -0.0123],
        [-0.0011, -0.0028, -0.0038,  ..., -0.0144, -0.0084,  0.0334]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.2332, -3.1895, -2.0215,  ..., -1.3916, -7.6055, -1.5283]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 06:53:08 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for I remain, he remains
I explain, he explains
I reduce, he reduces
I include, he includes
I suggest, he suggests
I become, he becomes
I protect, he protects
I remember, he
2024-07-31 06:53:09 root INFO     [order_1_approx] starting weight calculation for I suggest, he suggests
I protect, he protects
I become, he becomes
I remain, he remains
I reduce, he reduces
I remember, he remembers
I include, he includes
I explain, he
2024-07-31 06:53:09 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 06:55:05 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0281, -0.2927,  0.1605,  ..., -0.7373, -0.1144, -0.0515],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.5449, -3.3145,  1.3164,  ...,  0.5566, -6.4922,  1.6504],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0154,  0.0035,  0.0145,  ..., -0.0048,  0.0068,  0.0227],
        [-0.0049,  0.0260, -0.0009,  ...,  0.0014,  0.0002,  0.0039],
        [-0.0028,  0.0022,  0.0195,  ..., -0.0185,  0.0056, -0.0055],
        ...,
        [-0.0033,  0.0021,  0.0128,  ...,  0.0316, -0.0050, -0.0021],
        [-0.0005,  0.0023,  0.0024,  ..., -0.0006,  0.0196, -0.0096],
        [ 0.0021,  0.0047,  0.0177,  ..., -0.0054, -0.0062,  0.0207]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.5449, -3.2832,  1.2539,  ...,  0.4583, -6.3984,  1.5928]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 06:55:06 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for I suggest, he suggests
I protect, he protects
I become, he becomes
I remain, he remains
I reduce, he reduces
I remember, he remembers
I include, he includes
I explain, he
2024-07-31 06:55:06 root INFO     [order_1_approx] starting weight calculation for I explain, he explains
I remember, he remembers
I remain, he remains
I include, he includes
I become, he becomes
I reduce, he reduces
I suggest, he suggests
I protect, he
2024-07-31 06:55:07 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 06:57:04 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0537, -0.0457, -0.3159,  ..., -0.2419, -0.2186,  0.3394],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.8350, -4.9141, -0.8926,  ..., -1.3955, -6.9805,  0.4258],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0282, -0.0011,  0.0085,  ..., -0.0078,  0.0074,  0.0243],
        [-0.0191,  0.0252, -0.0004,  ...,  0.0061,  0.0086, -0.0007],
        [ 0.0038,  0.0164,  0.0255,  ..., -0.0131, -0.0074, -0.0142],
        ...,
        [-0.0029, -0.0043,  0.0096,  ...,  0.0496,  0.0060, -0.0036],
        [ 0.0028, -0.0051, -0.0020,  ..., -0.0073,  0.0203, -0.0303],
        [-0.0013, -0.0071,  0.0032,  ..., -0.0118, -0.0147,  0.0450]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.8955, -4.6797, -0.6709,  ..., -1.1143, -6.9258,  0.4661]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 06:57:05 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for I explain, he explains
I remember, he remembers
I remain, he remains
I include, he includes
I become, he becomes
I reduce, he reduces
I suggest, he suggests
I protect, he
2024-07-31 06:57:05 root INFO     [order_1_approx] starting weight calculation for I become, he becomes
I protect, he protects
I suggest, he suggests
I remember, he remembers
I reduce, he reduces
I explain, he explains
I include, he includes
I remain, he
2024-07-31 06:57:05 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 06:59:04 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0958, -0.2241,  0.3088,  ..., -0.7153,  0.2764,  0.0450],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.1719, -3.0117, -2.0566,  ..., -3.1758, -4.7578, -0.6875],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 2.7344e-02, -1.5274e-02,  1.1459e-02,  ...,  5.3749e-03,
         -5.1117e-03,  1.7181e-02],
        [-5.7297e-03,  3.3356e-02, -3.2120e-03,  ..., -9.4223e-04,
          2.6741e-03, -6.6223e-03],
        [-2.8782e-03,  3.8548e-03,  2.8748e-02,  ..., -1.7609e-02,
         -5.3368e-03, -3.2806e-03],
        ...,
        [-3.9673e-03,  1.5366e-02,  1.0872e-02,  ...,  2.9739e-02,
         -1.2291e-02,  5.8174e-05],
        [ 2.6894e-03, -1.1414e-02, -6.0196e-03,  ..., -1.4000e-02,
          1.8234e-02, -2.0706e-02],
        [ 3.3498e-04,  8.3160e-03,  1.0490e-03,  ..., -6.9656e-03,
         -8.9569e-03,  3.3722e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.8633, -2.7266, -2.0625,  ..., -2.9805, -4.7266, -0.4285]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 06:59:05 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for I become, he becomes
I protect, he protects
I suggest, he suggests
I remember, he remembers
I reduce, he reduces
I explain, he explains
I include, he includes
I remain, he
2024-07-31 06:59:06 root INFO     [order_1_approx] starting weight calculation for I protect, he protects
I become, he becomes
I remain, he remains
I include, he includes
I reduce, he reduces
I remember, he remembers
I explain, he explains
I suggest, he
2024-07-31 06:59:06 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 07:01:05 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2256, -0.2551,  0.5996,  ..., -0.5327,  0.0124,  0.0178],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 5.8594, -2.3105, -1.5557,  ...,  1.3223, -6.0859,  2.0527],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 5.1575e-02,  4.7112e-03,  4.1733e-03,  ..., -1.0757e-02,
         -1.8291e-03,  1.9836e-02],
        [-1.6678e-02,  3.5400e-02,  4.6539e-03,  ...,  1.2035e-03,
         -2.0237e-03,  3.5858e-03],
        [-1.0620e-02,  4.4632e-04,  1.5717e-02,  ..., -7.9422e-03,
          3.8147e-06, -1.0567e-02],
        ...,
        [-1.2360e-02, -5.4893e-03,  1.7288e-02,  ...,  4.4800e-02,
          1.6689e-03,  2.2507e-03],
        [-1.3153e-02, -6.8550e-03,  3.8929e-03,  ..., -1.2527e-02,
          1.7944e-02, -7.6218e-03],
        [ 1.0071e-02,  3.4084e-03,  1.6998e-02,  ..., -1.8555e-02,
         -1.2321e-02,  2.2156e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 5.0938, -2.1719, -1.2139,  ...,  1.4668, -6.3203,  1.8584]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 07:01:06 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for I protect, he protects
I become, he becomes
I remain, he remains
I include, he includes
I reduce, he reduces
I remember, he remembers
I explain, he explains
I suggest, he
2024-07-31 07:01:06 root INFO     total operator prediction time: 945.4545905590057 seconds
2024-07-31 07:01:06 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on verb_inf - Ved
2024-07-31 07:01:06 root INFO     building operator verb_inf - Ved
2024-07-31 07:01:07 root INFO     [order_1_approx] starting weight calculation for If the present form is refer, the past form is referred
If the present form is consider, the past form is considered
If the present form is apply, the past form is applied
If the present form is achieve, the past form is achieved
If the present form is replace, the past form is replaced
If the present form is identify, the past form is identified
If the present form is spend, the past form is spent
If the present form is develop, the past form is
2024-07-31 07:01:07 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 07:03:06 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.6104,  0.3506, -0.1052,  ..., -0.6807, -0.5850, -0.1484],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.9326, -1.0684,  3.4609,  ..., -1.9814, -0.8105, -1.9805],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0710, -0.0073, -0.0020,  ..., -0.0067, -0.0112,  0.0164],
        [-0.0269,  0.0732,  0.0078,  ...,  0.0102,  0.0020, -0.0056],
        [ 0.0282, -0.0059,  0.0488,  ..., -0.0060,  0.0014,  0.0012],
        ...,
        [ 0.0156, -0.0103, -0.0049,  ...,  0.0816, -0.0079,  0.0103],
        [ 0.0154,  0.0096,  0.0057,  ...,  0.0027,  0.0493, -0.0094],
        [-0.0229, -0.0133, -0.0060,  ..., -0.0196, -0.0097,  0.0548]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.6431, -1.0576,  3.2324,  ..., -1.9248, -0.7461, -1.7314]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 07:03:07 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If the present form is refer, the past form is referred
If the present form is consider, the past form is considered
If the present form is apply, the past form is applied
If the present form is achieve, the past form is achieved
If the present form is replace, the past form is replaced
If the present form is identify, the past form is identified
If the present form is spend, the past form is spent
If the present form is develop, the past form is
2024-07-31 07:03:07 root INFO     [order_1_approx] starting weight calculation for If the present form is achieve, the past form is achieved
If the present form is refer, the past form is referred
If the present form is identify, the past form is identified
If the present form is apply, the past form is applied
If the present form is develop, the past form is developed
If the present form is consider, the past form is considered
If the present form is replace, the past form is replaced
If the present form is spend, the past form is
2024-07-31 07:03:07 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 07:05:06 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2678, -0.1196,  0.4761,  ..., -0.5537, -0.1826, -0.0114],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.4658, -0.7988, -1.4238,  ..., -2.2969, -2.9043, -1.4424],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0854, -0.0090,  0.0098,  ..., -0.0174,  0.0088,  0.0237],
        [-0.0134,  0.0559, -0.0056,  ...,  0.0065,  0.0069, -0.0032],
        [ 0.0109, -0.0121,  0.0490,  ..., -0.0269, -0.0173, -0.0050],
        ...,
        [ 0.0174,  0.0032, -0.0017,  ...,  0.0726, -0.0039, -0.0006],
        [ 0.0063,  0.0143, -0.0057,  ...,  0.0060,  0.0575, -0.0223],
        [-0.0088, -0.0011, -0.0061,  ..., -0.0165, -0.0091,  0.0581]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.5850, -0.5557, -1.4570,  ..., -2.3320, -2.6523, -1.3789]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 07:05:07 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If the present form is achieve, the past form is achieved
If the present form is refer, the past form is referred
If the present form is identify, the past form is identified
If the present form is apply, the past form is applied
If the present form is develop, the past form is developed
If the present form is consider, the past form is considered
If the present form is replace, the past form is replaced
If the present form is spend, the past form is
2024-07-31 07:05:07 root INFO     [order_1_approx] starting weight calculation for If the present form is spend, the past form is spent
If the present form is develop, the past form is developed
If the present form is replace, the past form is replaced
If the present form is refer, the past form is referred
If the present form is apply, the past form is applied
If the present form is achieve, the past form is achieved
If the present form is consider, the past form is considered
If the present form is identify, the past form is
2024-07-31 07:05:07 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 07:07:07 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.3623,  0.0201, -0.1636,  ..., -0.1577, -0.7236, -0.3833],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.0723,  1.3916,  2.1836,  ..., -1.5293, -1.3105, -0.3438],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0991, -0.0077,  0.0140,  ...,  0.0101, -0.0078,  0.0206],
        [-0.0333,  0.0746,  0.0025,  ...,  0.0057, -0.0024, -0.0033],
        [ 0.0224, -0.0076,  0.0551,  ..., -0.0296, -0.0106,  0.0090],
        ...,
        [ 0.0098, -0.0050, -0.0002,  ...,  0.0937, -0.0037,  0.0094],
        [-0.0010,  0.0173,  0.0105,  ..., -0.0062,  0.0630, -0.0282],
        [-0.0231,  0.0051,  0.0158,  ..., -0.0101, -0.0127,  0.0597]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.5957,  1.1592,  1.7109,  ..., -1.4102, -1.3232, -0.2130]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 07:07:08 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If the present form is spend, the past form is spent
If the present form is develop, the past form is developed
If the present form is replace, the past form is replaced
If the present form is refer, the past form is referred
If the present form is apply, the past form is applied
If the present form is achieve, the past form is achieved
If the present form is consider, the past form is considered
If the present form is identify, the past form is
2024-07-31 07:07:08 root INFO     [order_1_approx] starting weight calculation for If the present form is consider, the past form is considered
If the present form is spend, the past form is spent
If the present form is refer, the past form is referred
If the present form is identify, the past form is identified
If the present form is develop, the past form is developed
If the present form is replace, the past form is replaced
If the present form is achieve, the past form is achieved
If the present form is apply, the past form is
2024-07-31 07:07:08 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 07:09:03 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2810, -0.2352,  0.4424,  ..., -0.2932, -0.6401, -0.3735],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.4688, -0.1731, -0.3154,  ..., -0.3445, -2.4824, -0.8691],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 7.8430e-02, -8.2855e-03,  2.2995e-02,  ...,  3.3951e-03,
          6.5327e-04,  2.1561e-02],
        [-1.0719e-02,  7.1472e-02, -5.9662e-03,  ..., -5.1880e-04,
         -8.9264e-03, -9.7580e-03],
        [ 2.2110e-02, -4.6196e-03,  4.6997e-02,  ..., -2.1744e-02,
         -1.2405e-02, -3.4561e-03],
        ...,
        [-8.9264e-04, -1.3618e-02, -1.9882e-02,  ...,  8.6121e-02,
         -8.4534e-03,  3.8147e-05],
        [ 2.1988e-02,  4.1389e-03,  5.3406e-03,  ..., -1.2360e-02,
          5.4230e-02, -1.7441e-02],
        [-4.7150e-03, -4.6692e-03, -8.9722e-03,  ..., -2.0920e-02,
         -1.9730e-02,  5.0079e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.2739, -0.2388, -0.6528,  ..., -0.3586, -2.4863, -0.8706]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 07:09:04 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If the present form is consider, the past form is considered
If the present form is spend, the past form is spent
If the present form is refer, the past form is referred
If the present form is identify, the past form is identified
If the present form is develop, the past form is developed
If the present form is replace, the past form is replaced
If the present form is achieve, the past form is achieved
If the present form is apply, the past form is
2024-07-31 07:09:04 root INFO     [order_1_approx] starting weight calculation for If the present form is achieve, the past form is achieved
If the present form is spend, the past form is spent
If the present form is develop, the past form is developed
If the present form is identify, the past form is identified
If the present form is consider, the past form is considered
If the present form is apply, the past form is applied
If the present form is replace, the past form is replaced
If the present form is refer, the past form is
2024-07-31 07:09:04 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 07:10:57 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.4365, -0.6392, -0.1509,  ..., -0.7051, -0.1152, -0.2029],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.1152, -0.9360,  0.4580,  ...,  1.1309, -2.3398, -2.5781],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0984, -0.0164,  0.0192,  ..., -0.0027,  0.0122,  0.0306],
        [-0.0445,  0.0964, -0.0215,  ...,  0.0003,  0.0002,  0.0029],
        [ 0.0359, -0.0025,  0.0710,  ..., -0.0288, -0.0071,  0.0091],
        ...,
        [ 0.0084,  0.0121, -0.0173,  ...,  0.0980, -0.0071,  0.0180],
        [ 0.0200, -0.0008,  0.0068,  ..., -0.0070,  0.0591, -0.0237],
        [-0.0242, -0.0026,  0.0117,  ..., -0.0119, -0.0062,  0.0621]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.0605, -0.9160, -0.0688,  ...,  1.0146, -2.1836, -2.4688]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 07:10:58 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If the present form is achieve, the past form is achieved
If the present form is spend, the past form is spent
If the present form is develop, the past form is developed
If the present form is identify, the past form is identified
If the present form is consider, the past form is considered
If the present form is apply, the past form is applied
If the present form is replace, the past form is replaced
If the present form is refer, the past form is
2024-07-31 07:10:59 root INFO     [order_1_approx] starting weight calculation for If the present form is apply, the past form is applied
If the present form is refer, the past form is referred
If the present form is spend, the past form is spent
If the present form is develop, the past form is developed
If the present form is consider, the past form is considered
If the present form is identify, the past form is identified
If the present form is achieve, the past form is achieved
If the present form is replace, the past form is
2024-07-31 07:10:59 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 07:12:48 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0815, -0.3455, -0.4358,  ..., -0.4146, -0.2019, -0.2026],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.3672,  0.5073,  0.0850,  ..., -2.3398,  0.4607,  0.7324],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.1032, -0.0316,  0.0183,  ..., -0.0131,  0.0102,  0.0224],
        [-0.0300,  0.0660, -0.0009,  ...,  0.0246,  0.0027, -0.0001],
        [ 0.0292, -0.0151,  0.0383,  ..., -0.0231, -0.0089, -0.0115],
        ...,
        [-0.0010, -0.0028, -0.0300,  ...,  0.0954,  0.0019,  0.0076],
        [ 0.0224,  0.0181, -0.0023,  ..., -0.0084,  0.0795, -0.0137],
        [-0.0192, -0.0060, -0.0126,  ..., -0.0267, -0.0089,  0.0484]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.2871,  0.8643, -0.0042,  ..., -2.1250,  0.5239,  0.7656]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 07:12:48 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If the present form is apply, the past form is applied
If the present form is refer, the past form is referred
If the present form is spend, the past form is spent
If the present form is develop, the past form is developed
If the present form is consider, the past form is considered
If the present form is identify, the past form is identified
If the present form is achieve, the past form is achieved
If the present form is replace, the past form is
2024-07-31 07:12:49 root INFO     [order_1_approx] starting weight calculation for If the present form is identify, the past form is identified
If the present form is replace, the past form is replaced
If the present form is apply, the past form is applied
If the present form is refer, the past form is referred
If the present form is develop, the past form is developed
If the present form is spend, the past form is spent
If the present form is achieve, the past form is achieved
If the present form is consider, the past form is
2024-07-31 07:12:49 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 07:14:39 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3748, -0.1398,  0.0941,  ..., -0.1201,  0.1892, -0.2251],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.0586,  0.1321,  2.0664,  ..., -2.4414, -0.1494,  0.0527],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 9.3384e-02, -2.0966e-02,  8.1787e-03,  ..., -7.9575e-03,
          6.9427e-03,  3.3173e-02],
        [-2.8244e-02,  5.7434e-02,  1.1047e-02,  ...,  1.6098e-02,
         -5.7793e-03, -5.2032e-03],
        [-5.7030e-03,  1.4305e-06,  6.1462e-02,  ..., -2.2873e-02,
         -9.4757e-03, -2.6367e-02],
        ...,
        [ 3.2711e-03, -2.3254e-02,  1.6632e-03,  ...,  8.2825e-02,
         -1.0124e-02,  6.5079e-03],
        [ 1.8204e-02,  1.1047e-02, -4.8065e-03,  ..., -1.4633e-02,
          5.2246e-02, -3.5217e-02],
        [-1.6373e-02,  1.5228e-02, -4.7493e-04,  ..., -1.9516e-02,
         -2.5665e-02,  4.1748e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.2480,  0.4788,  1.6309,  ..., -2.3926, -0.4343,  0.3647]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 07:14:40 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If the present form is identify, the past form is identified
If the present form is replace, the past form is replaced
If the present form is apply, the past form is applied
If the present form is refer, the past form is referred
If the present form is develop, the past form is developed
If the present form is spend, the past form is spent
If the present form is achieve, the past form is achieved
If the present form is consider, the past form is
2024-07-31 07:14:40 root INFO     [order_1_approx] starting weight calculation for If the present form is consider, the past form is considered
If the present form is apply, the past form is applied
If the present form is spend, the past form is spent
If the present form is replace, the past form is replaced
If the present form is refer, the past form is referred
If the present form is develop, the past form is developed
If the present form is identify, the past form is identified
If the present form is achieve, the past form is
2024-07-31 07:14:40 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 07:16:27 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 5.7812e-01,  7.9346e-04, -2.8174e-01,  ..., -4.7705e-01,
        -8.4180e-01,  4.5215e-01], device='cuda:1', dtype=torch.float16,
       grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.3262,  1.3867, -0.6455,  ..., -2.6660, -1.6738, -0.7637],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0707,  0.0083,  0.0057,  ...,  0.0085,  0.0020,  0.0323],
        [-0.0185,  0.0595, -0.0072,  ...,  0.0044, -0.0050, -0.0143],
        [ 0.0169, -0.0133,  0.0507,  ..., -0.0193, -0.0007,  0.0038],
        ...,
        [-0.0092, -0.0005, -0.0261,  ...,  0.0677,  0.0045,  0.0090],
        [ 0.0127,  0.0058,  0.0085,  ..., -0.0073,  0.0293, -0.0044],
        [-0.0095, -0.0140, -0.0131,  ..., -0.0079, -0.0041,  0.0390]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.3994,  1.5996, -1.1865,  ..., -2.6309, -1.6406, -0.5825]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 07:16:28 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If the present form is consider, the past form is considered
If the present form is apply, the past form is applied
If the present form is spend, the past form is spent
If the present form is replace, the past form is replaced
If the present form is refer, the past form is referred
If the present form is develop, the past form is developed
If the present form is identify, the past form is identified
If the present form is achieve, the past form is
2024-07-31 07:16:28 root INFO     total operator prediction time: 921.4485001564026 seconds
2024-07-31 07:16:28 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on verb_Ving - Ved
2024-07-31 07:16:28 root INFO     building operator verb_Ving - Ved
2024-07-31 07:16:28 root INFO     [order_1_approx] starting weight calculation for After something is reducing, it has reduced
After something is performing, it has performed
After something is representing, it has represented
After something is relating, it has related
After something is requiring, it has required
After something is suffering, it has suffered
After something is replacing, it has replaced
After something is operating, it has
2024-07-31 07:16:28 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 07:18:26 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1110, -0.1940, -0.9468,  ..., -0.5840, -0.3833, -0.6572],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.6934,  0.2959,  1.6680,  ..., -3.1191, -1.6807,  0.3652],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0713,  0.0031,  0.0148,  ..., -0.0066, -0.0127,  0.0142],
        [-0.0268,  0.0529, -0.0055,  ...,  0.0196,  0.0130,  0.0013],
        [ 0.0087,  0.0133,  0.0638,  ..., -0.0037,  0.0094, -0.0180],
        ...,
        [-0.0112,  0.0131, -0.0088,  ...,  0.0773,  0.0014, -0.0036],
        [ 0.0080,  0.0111, -0.0081,  ...,  0.0031,  0.0676, -0.0268],
        [ 0.0043, -0.0041, -0.0064,  ..., -0.0023, -0.0144,  0.0430]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.7896,  0.6387,  2.0859,  ..., -2.5977, -1.4512,  0.5635]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 07:18:27 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for After something is reducing, it has reduced
After something is performing, it has performed
After something is representing, it has represented
After something is relating, it has related
After something is requiring, it has required
After something is suffering, it has suffered
After something is replacing, it has replaced
After something is operating, it has
2024-07-31 07:18:28 root INFO     [order_1_approx] starting weight calculation for After something is relating, it has related
After something is representing, it has represented
After something is performing, it has performed
After something is replacing, it has replaced
After something is suffering, it has suffered
After something is requiring, it has required
After something is operating, it has operated
After something is reducing, it has
2024-07-31 07:18:28 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 07:20:26 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0592, -0.0870, -0.2786,  ..., -0.3052,  0.1528, -0.3408],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.9023,  0.3618,  1.2070,  ..., -4.9141, -0.7539, -4.6016],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0746, -0.0012,  0.0197,  ..., -0.0051,  0.0099,  0.0122],
        [-0.0220,  0.0637, -0.0050,  ...,  0.0157,  0.0206,  0.0123],
        [ 0.0020, -0.0042,  0.0695,  ..., -0.0036,  0.0029, -0.0261],
        ...,
        [ 0.0129, -0.0017, -0.0048,  ...,  0.0927,  0.0140,  0.0186],
        [-0.0007,  0.0122, -0.0165,  ...,  0.0019,  0.0873, -0.0159],
        [-0.0173, -0.0029, -0.0078,  ..., -0.0129,  0.0026,  0.0687]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.9160,  0.3401,  1.1396,  ..., -4.7109, -0.5327, -4.5039]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 07:20:27 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for After something is relating, it has related
After something is representing, it has represented
After something is performing, it has performed
After something is replacing, it has replaced
After something is suffering, it has suffered
After something is requiring, it has required
After something is operating, it has operated
After something is reducing, it has
2024-07-31 07:20:27 root INFO     [order_1_approx] starting weight calculation for After something is reducing, it has reduced
After something is replacing, it has replaced
After something is requiring, it has required
After something is representing, it has represented
After something is operating, it has operated
After something is relating, it has related
After something is suffering, it has suffered
After something is performing, it has
2024-07-31 07:20:27 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 07:22:25 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.8037, -0.3062, -0.2131,  ..., -0.5698, -0.3003, -0.8696],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.5107, -0.0146,  4.2578,  ..., -2.6738, -2.0078, -0.8721],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 6.0242e-02,  1.1444e-05,  2.3788e-02,  ...,  2.3804e-03,
          2.8114e-03,  1.5671e-02],
        [-3.2379e-02,  5.2612e-02,  5.5237e-03,  ...,  1.9440e-02,
          1.1482e-03, -4.3221e-03],
        [ 1.9669e-02,  2.1095e-03,  4.5044e-02,  ..., -9.1171e-04,
          1.3153e-02, -9.7809e-03],
        ...,
        [-6.3477e-03,  1.2436e-03, -4.4060e-03,  ...,  6.1035e-02,
          3.4599e-03,  9.7504e-03],
        [ 1.3641e-02, -5.0468e-03,  4.0512e-03,  ..., -1.0201e-02,
          5.8197e-02, -1.1826e-02],
        [ 2.2736e-03,  1.2665e-02,  7.2250e-03,  ..., -8.3923e-03,
          3.9749e-03,  3.9856e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.6592,  0.1814,  4.5820,  ..., -2.3691, -1.4199, -0.7402]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 07:22:26 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for After something is reducing, it has reduced
After something is replacing, it has replaced
After something is requiring, it has required
After something is representing, it has represented
After something is operating, it has operated
After something is relating, it has related
After something is suffering, it has suffered
After something is performing, it has
2024-07-31 07:22:26 root INFO     [order_1_approx] starting weight calculation for After something is reducing, it has reduced
After something is requiring, it has required
After something is relating, it has related
After something is representing, it has represented
After something is operating, it has operated
After something is performing, it has performed
After something is replacing, it has replaced
After something is suffering, it has
2024-07-31 07:22:27 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 07:24:26 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2021, -0.2100,  0.2971,  ..., -0.9370, -0.0734, -0.0775],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.9219, -1.7979,  1.1855,  ..., -2.9727,  1.9951,  0.9062],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 7.7637e-02, -1.0315e-02,  2.3407e-02,  ..., -1.5228e-02,
          1.1307e-02,  3.1471e-05],
        [-1.5366e-02,  5.3680e-02,  7.0648e-03,  ...,  1.7303e-02,
          9.3384e-03,  1.1971e-02],
        [ 4.6387e-03,  7.8812e-03,  4.9072e-02,  ..., -2.4300e-03,
          6.6795e-03, -2.2675e-02],
        ...,
        [-8.6737e-04, -3.0365e-03,  1.3748e-02,  ...,  6.6772e-02,
         -1.9073e-03,  5.7182e-03],
        [ 1.3313e-02,  1.6754e-02, -1.1505e-02,  ..., -6.7711e-03,
          5.6488e-02, -3.0487e-02],
        [ 3.8700e-03,  1.3847e-02,  4.9820e-03,  ..., -1.1749e-02,
         -2.1576e-02,  4.7729e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.7168, -1.4023,  0.9268,  ..., -2.6055,  2.0293,  0.9092]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 07:24:27 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for After something is reducing, it has reduced
After something is requiring, it has required
After something is relating, it has related
After something is representing, it has represented
After something is operating, it has operated
After something is performing, it has performed
After something is replacing, it has replaced
After something is suffering, it has
2024-07-31 07:24:27 root INFO     [order_1_approx] starting weight calculation for After something is requiring, it has required
After something is reducing, it has reduced
After something is relating, it has related
After something is suffering, it has suffered
After something is replacing, it has replaced
After something is operating, it has operated
After something is performing, it has performed
After something is representing, it has
2024-07-31 07:24:27 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 07:26:27 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0702,  0.1442, -0.3198,  ..., -0.3508, -0.0459, -0.2734],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.3691,  1.7773,  2.1504,  ..., -0.9277, -0.7510, -0.7012],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0822,  0.0031,  0.0250,  ...,  0.0018,  0.0090,  0.0032],
        [-0.0363,  0.0790, -0.0092,  ...,  0.0064,  0.0048, -0.0171],
        [ 0.0131, -0.0026,  0.0757,  ..., -0.0126,  0.0075, -0.0317],
        ...,
        [-0.0025,  0.0128, -0.0043,  ...,  0.0947, -0.0047,  0.0113],
        [ 0.0167,  0.0064, -0.0008,  ..., -0.0083,  0.0740, -0.0141],
        [-0.0168,  0.0074,  0.0033,  ...,  0.0010, -0.0109,  0.0690]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.4658,  1.8916,  2.4395,  ..., -0.8462, -0.4438, -0.8545]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 07:26:28 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for After something is requiring, it has required
After something is reducing, it has reduced
After something is relating, it has related
After something is suffering, it has suffered
After something is replacing, it has replaced
After something is operating, it has operated
After something is performing, it has performed
After something is representing, it has
2024-07-31 07:26:28 root INFO     [order_1_approx] starting weight calculation for After something is reducing, it has reduced
After something is representing, it has represented
After something is replacing, it has replaced
After something is operating, it has operated
After something is relating, it has related
After something is suffering, it has suffered
After something is performing, it has performed
After something is requiring, it has
2024-07-31 07:26:28 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 07:28:22 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.5288, -0.1115, -0.5259,  ..., -0.3884, -0.6611, -0.6787],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.6826,  0.9019,  1.7676,  ..., -2.2012, -2.3438, -1.1934],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0668, -0.0016,  0.0334,  ..., -0.0112, -0.0004,  0.0031],
        [-0.0248,  0.0560, -0.0278,  ..., -0.0014,  0.0100, -0.0016],
        [ 0.0023, -0.0058,  0.0571,  ..., -0.0213,  0.0019, -0.0180],
        ...,
        [-0.0070,  0.0144,  0.0145,  ...,  0.0766, -0.0108,  0.0009],
        [-0.0011, -0.0007,  0.0143,  ..., -0.0146,  0.0660, -0.0323],
        [-0.0112,  0.0139,  0.0038,  ..., -0.0105,  0.0077,  0.0653]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.6182,  0.8789,  2.0020,  ..., -2.1484, -2.2129, -1.2598]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 07:28:23 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for After something is reducing, it has reduced
After something is representing, it has represented
After something is replacing, it has replaced
After something is operating, it has operated
After something is relating, it has related
After something is suffering, it has suffered
After something is performing, it has performed
After something is requiring, it has
2024-07-31 07:28:23 root INFO     [order_1_approx] starting weight calculation for After something is operating, it has operated
After something is performing, it has performed
After something is replacing, it has replaced
After something is representing, it has represented
After something is reducing, it has reduced
After something is requiring, it has required
After something is suffering, it has suffered
After something is relating, it has
2024-07-31 07:28:23 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 07:30:21 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4678,  0.0634, -0.4102,  ..., -0.4265, -0.4822, -0.7388],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.1978,  0.8203,  1.9102,  ...,  0.2009, -2.9980, -0.9980],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 7.8003e-02, -8.6060e-03,  1.9562e-02,  ...,  1.5259e-05,
          1.6891e-02,  1.0925e-02],
        [-2.7557e-02,  6.4331e-02,  2.7275e-03,  ...,  1.1703e-02,
         -2.2984e-03, -4.0054e-03],
        [ 1.2817e-02, -7.0038e-03,  6.8909e-02,  ..., -1.0033e-02,
          1.2779e-02, -1.6678e-02],
        ...,
        [-1.6193e-03,  1.6937e-02, -6.6872e-03,  ...,  8.2764e-02,
          6.3438e-03,  1.1688e-02],
        [ 7.4310e-03,  1.3931e-02, -3.7270e-03,  ...,  4.6616e-03,
          6.6162e-02, -2.0020e-02],
        [-1.5549e-02,  1.6159e-02,  7.3051e-03,  ...,  1.3565e-02,
         -1.1826e-02,  5.5817e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.2854,  0.7964,  2.2363,  ...,  0.2969, -2.5430, -1.3076]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 07:30:22 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for After something is operating, it has operated
After something is performing, it has performed
After something is replacing, it has replaced
After something is representing, it has represented
After something is reducing, it has reduced
After something is requiring, it has required
After something is suffering, it has suffered
After something is relating, it has
2024-07-31 07:30:22 root INFO     [order_1_approx] starting weight calculation for After something is performing, it has performed
After something is suffering, it has suffered
After something is reducing, it has reduced
After something is requiring, it has required
After something is operating, it has operated
After something is representing, it has represented
After something is relating, it has related
After something is replacing, it has
2024-07-31 07:30:22 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 07:32:22 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0322, -0.4878, -0.6509,  ..., -0.3823,  0.2959, -0.2771],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.7393,  0.6885,  0.3950,  ..., -1.6680, -0.0386,  1.2754],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0867, -0.0013,  0.0307,  ..., -0.0127,  0.0051,  0.0108],
        [-0.0528,  0.0569, -0.0258,  ...,  0.0290,  0.0039, -0.0120],
        [ 0.0193, -0.0105,  0.0488,  ..., -0.0221,  0.0093, -0.0313],
        ...,
        [ 0.0160,  0.0265, -0.0009,  ...,  0.1010, -0.0065,  0.0076],
        [ 0.0344,  0.0169,  0.0033,  ..., -0.0127,  0.0963, -0.0002],
        [ 0.0104,  0.0247, -0.0021,  ..., -0.0083, -0.0028,  0.0726]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.9141,  1.1279,  0.6689,  ..., -1.5410, -0.0302,  0.9941]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 07:32:23 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for After something is performing, it has performed
After something is suffering, it has suffered
After something is reducing, it has reduced
After something is requiring, it has required
After something is operating, it has operated
After something is representing, it has represented
After something is relating, it has related
After something is replacing, it has
2024-07-31 07:32:23 root INFO     total operator prediction time: 954.7653906345367 seconds
2024-07-31 07:32:23 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on Ving - verb_inf
2024-07-31 07:32:23 root INFO     building operator Ving - verb_inf
2024-07-31 07:32:23 root INFO     [order_1_approx] starting weight calculation for creating is the active form of create
adding is the active form of add
including is the active form of include
losing is the active form of lose
protecting is the active form of protect
understanding is the active form of understand
encouraging is the active form of encourage
preventing is the active form of
2024-07-31 07:32:23 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 07:34:20 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0845, -0.8359,  0.0542,  ..., -0.4036, -0.0512, -0.2915],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.0908, -3.4531, -1.8203,  ...,  2.6914, -1.2539, -2.2500],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 2.7679e-02, -6.8588e-03,  1.5045e-02,  ...,  5.7983e-03,
         -3.3150e-03,  1.3451e-02],
        [-8.3771e-03,  2.9205e-02, -8.6784e-05,  ...,  1.5831e-04,
         -1.1654e-03, -4.0131e-03],
        [ 1.1742e-02, -6.9809e-03,  1.2512e-02,  ..., -1.0429e-02,
         -1.7586e-03, -3.9558e-03],
        ...,
        [ 1.1124e-02, -4.6501e-03, -4.4785e-03,  ...,  3.1433e-02,
         -1.0017e-02, -2.3499e-03],
        [ 5.9509e-04,  6.8588e-03, -1.1768e-03,  ...,  4.0665e-03,
          2.9617e-02, -8.4915e-03],
        [ 4.0779e-03, -2.1706e-03, -3.4389e-03,  ..., -6.9046e-03,
         -2.1935e-03,  3.4637e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.2080, -3.4844, -1.8691,  ...,  2.7695, -1.2656, -2.2480]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 07:34:22 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for creating is the active form of create
adding is the active form of add
including is the active form of include
losing is the active form of lose
protecting is the active form of protect
understanding is the active form of understand
encouraging is the active form of encourage
preventing is the active form of
2024-07-31 07:34:22 root INFO     [order_1_approx] starting weight calculation for adding is the active form of add
understanding is the active form of understand
preventing is the active form of prevent
protecting is the active form of protect
encouraging is the active form of encourage
creating is the active form of create
including is the active form of include
losing is the active form of
2024-07-31 07:34:22 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 07:36:21 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0990,  0.1515,  0.0068,  ..., -0.7026,  0.4165,  0.3000],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.0977, -3.3398, -0.6758,  ...,  0.7559,  1.0684, -1.5752],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0857, -0.0085,  0.0094,  ..., -0.0157, -0.0030,  0.0270],
        [-0.0080,  0.0814,  0.0148,  ...,  0.0191,  0.0107, -0.0023],
        [ 0.0105, -0.0201,  0.0568,  ...,  0.0002, -0.0003, -0.0047],
        ...,
        [ 0.0107,  0.0004, -0.0169,  ...,  0.0751, -0.0168, -0.0094],
        [-0.0023,  0.0240,  0.0122,  ...,  0.0195,  0.0563, -0.0183],
        [-0.0048,  0.0022, -0.0051,  ..., -0.0218, -0.0106,  0.0620]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.0000, -2.9043, -0.6797,  ...,  1.0615,  1.0078, -1.4531]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 07:36:22 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for adding is the active form of add
understanding is the active form of understand
preventing is the active form of prevent
protecting is the active form of protect
encouraging is the active form of encourage
creating is the active form of create
including is the active form of include
losing is the active form of
2024-07-31 07:36:22 root INFO     [order_1_approx] starting weight calculation for preventing is the active form of prevent
encouraging is the active form of encourage
including is the active form of include
creating is the active form of create
understanding is the active form of understand
adding is the active form of add
losing is the active form of lose
protecting is the active form of
2024-07-31 07:36:22 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 07:38:19 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2078, -0.4939, -0.4485,  ..., -0.4370, -0.4033,  0.1442],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.2930, -5.4766, -0.9951,  ...,  1.9492, -1.0020, -2.2188],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 4.7913e-02, -6.7215e-03,  6.6376e-03,  ..., -6.3286e-03,
         -4.2534e-03,  1.2970e-02],
        [-1.3199e-02,  3.8269e-02,  7.5645e-03,  ...,  3.0651e-03,
          3.6163e-03, -3.6430e-03],
        [ 1.8097e-02, -3.0994e-03,  2.3697e-02,  ..., -1.2833e-02,
         -7.6294e-03, -1.6956e-03],
        ...,
        [ 8.2703e-03, -3.8986e-03, -7.4997e-03,  ...,  3.7354e-02,
         -4.4212e-03,  6.1989e-04],
        [ 4.2686e-03,  1.3168e-02,  5.3406e-05,  ...,  9.9335e-03,
          3.4363e-02, -1.5594e-02],
        [-9.9945e-04, -1.6975e-04, -4.3182e-03,  ..., -4.6577e-03,
         -2.4033e-03,  4.1199e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.3215, -5.3789, -1.0459,  ...,  2.0469, -1.1641, -2.1680]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 07:38:20 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for preventing is the active form of prevent
encouraging is the active form of encourage
including is the active form of include
creating is the active form of create
understanding is the active form of understand
adding is the active form of add
losing is the active form of lose
protecting is the active form of
2024-07-31 07:38:20 root INFO     [order_1_approx] starting weight calculation for encouraging is the active form of encourage
losing is the active form of lose
understanding is the active form of understand
protecting is the active form of protect
preventing is the active form of prevent
adding is the active form of add
including is the active form of include
creating is the active form of
2024-07-31 07:38:20 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 07:40:10 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0507,  0.4539,  0.4792,  ..., -0.0078, -0.7969,  0.2123],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.5635, -4.2227,  1.0342,  ...,  2.7832, -2.1133, -0.8940],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 6.1523e-02, -1.1642e-02,  9.9640e-03,  ...,  1.0056e-02,
         -1.1734e-02,  2.0905e-02],
        [-5.9929e-03,  5.3314e-02,  4.0283e-03,  ...,  1.2604e-02,
          4.6997e-03,  1.1444e-05],
        [ 1.8448e-02, -7.5760e-03,  5.2734e-02,  ..., -2.0065e-03,
          1.3145e-02, -9.4986e-04],
        ...,
        [ 1.0292e-02,  1.2901e-02, -6.8359e-03,  ...,  5.9143e-02,
         -1.6678e-02, -1.3443e-02],
        [ 2.2554e-04,  2.1576e-02, -4.6921e-04,  ..., -5.4703e-03,
          5.0201e-02, -1.7624e-02],
        [ 8.6451e-04, -1.0315e-02, -1.5793e-02,  ..., -8.0261e-03,
         -8.4763e-03,  6.1401e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.2117, -3.9727,  0.8052,  ...,  2.8848, -2.2559, -0.8618]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 07:40:11 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for encouraging is the active form of encourage
losing is the active form of lose
understanding is the active form of understand
protecting is the active form of protect
preventing is the active form of prevent
adding is the active form of add
including is the active form of include
creating is the active form of
2024-07-31 07:40:12 root INFO     [order_1_approx] starting weight calculation for preventing is the active form of prevent
understanding is the active form of understand
including is the active form of include
creating is the active form of create
protecting is the active form of protect
encouraging is the active form of encourage
losing is the active form of lose
adding is the active form of
2024-07-31 07:40:12 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 07:42:01 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0229, -0.6924,  0.3013,  ..., -0.4519, -0.3225, -0.3818],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.3213, -1.5117, -1.2109,  ...,  3.4609, -3.4160, -1.4600],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.1057, -0.0097,  0.0208,  ..., -0.0119, -0.0013,  0.0259],
        [-0.0103,  0.0884,  0.0059,  ...,  0.0079,  0.0077, -0.0080],
        [ 0.0211, -0.0143,  0.0615,  ...,  0.0004,  0.0035,  0.0124],
        ...,
        [ 0.0276,  0.0092, -0.0222,  ...,  0.1033, -0.0072, -0.0014],
        [-0.0045,  0.0100,  0.0147,  ...,  0.0161,  0.0771, -0.0201],
        [-0.0070,  0.0140, -0.0086,  ..., -0.0189, -0.0245,  0.1021]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.6230, -1.5400, -1.4297,  ...,  3.1016, -3.3730, -1.3848]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 07:42:02 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for preventing is the active form of prevent
understanding is the active form of understand
including is the active form of include
creating is the active form of create
protecting is the active form of protect
encouraging is the active form of encourage
losing is the active form of lose
adding is the active form of
2024-07-31 07:42:02 root INFO     [order_1_approx] starting weight calculation for protecting is the active form of protect
adding is the active form of add
losing is the active form of lose
encouraging is the active form of encourage
understanding is the active form of understand
preventing is the active form of prevent
creating is the active form of create
including is the active form of
2024-07-31 07:42:02 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 07:44:00 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.3623, -0.0609,  0.1250,  ..., -0.1065,  0.1088, -0.9829],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.3379, -1.6270,  0.6001,  ...,  1.1348, -2.0098, -3.6055],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0665, -0.0084,  0.0206,  ..., -0.0061,  0.0044,  0.0189],
        [-0.0098,  0.0621,  0.0036,  ...,  0.0066, -0.0093, -0.0070],
        [ 0.0075, -0.0068,  0.0379,  ..., -0.0113, -0.0052,  0.0023],
        ...,
        [ 0.0174,  0.0063, -0.0163,  ...,  0.0689, -0.0073,  0.0043],
        [-0.0009,  0.0183,  0.0091,  ...,  0.0022,  0.0429, -0.0177],
        [-0.0031,  0.0015, -0.0041,  ..., -0.0038, -0.0098,  0.0648]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.6221, -1.5547,  0.7783,  ...,  1.1377, -2.2832, -3.3691]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 07:44:01 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for protecting is the active form of protect
adding is the active form of add
losing is the active form of lose
encouraging is the active form of encourage
understanding is the active form of understand
preventing is the active form of prevent
creating is the active form of create
including is the active form of
2024-07-31 07:44:01 root INFO     [order_1_approx] starting weight calculation for losing is the active form of lose
preventing is the active form of prevent
creating is the active form of create
adding is the active form of add
protecting is the active form of protect
encouraging is the active form of encourage
including is the active form of include
understanding is the active form of
2024-07-31 07:44:01 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 07:45:53 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0720,  0.0662,  0.0552,  ..., -0.3318, -0.3096, -0.3281],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.2480, -1.9951,  0.2014,  ...,  0.8555, -1.2051, -0.3936],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0768, -0.0099,  0.0099,  ...,  0.0008,  0.0011,  0.0123],
        [-0.0007,  0.0678, -0.0073,  ...,  0.0067, -0.0056,  0.0009],
        [-0.0115, -0.0194,  0.0593,  ..., -0.0110,  0.0051,  0.0064],
        ...,
        [ 0.0106,  0.0056, -0.0153,  ...,  0.0750,  0.0027,  0.0086],
        [-0.0005,  0.0058,  0.0110,  ...,  0.0057,  0.0617, -0.0138],
        [ 0.0070,  0.0053, -0.0020,  ..., -0.0079, -0.0161,  0.0648]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.0938, -2.1016,  0.1090,  ...,  0.8120, -1.2256, -0.6260]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 07:45:54 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for losing is the active form of lose
preventing is the active form of prevent
creating is the active form of create
adding is the active form of add
protecting is the active form of protect
encouraging is the active form of encourage
including is the active form of include
understanding is the active form of
2024-07-31 07:45:54 root INFO     [order_1_approx] starting weight calculation for adding is the active form of add
creating is the active form of create
including is the active form of include
losing is the active form of lose
understanding is the active form of understand
preventing is the active form of prevent
protecting is the active form of protect
encouraging is the active form of
2024-07-31 07:45:54 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 07:47:50 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0740, -0.1127, -0.6460,  ..., -0.0731, -0.2222, -0.0963],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.8145, -2.9570, -1.1035,  ...,  4.3633, -2.0898, -3.3438],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 4.6295e-02, -8.3160e-03,  8.4114e-04,  ...,  2.3289e-03,
          2.4967e-03,  1.8173e-02],
        [-1.1490e-02,  5.5511e-02,  1.1349e-04,  ...,  1.6113e-02,
         -3.1877e-04,  4.6730e-05],
        [ 1.8234e-02, -7.8011e-04,  3.6774e-02,  ..., -9.0942e-03,
         -4.7493e-03, -5.2795e-03],
        ...,
        [ 8.5602e-03, -5.5695e-03, -2.3270e-03,  ...,  5.7007e-02,
         -9.9030e-03, -6.1646e-03],
        [ 2.5635e-03,  1.3161e-02,  4.0359e-03,  ...,  6.0692e-03,
          4.7058e-02, -1.0147e-02],
        [ 3.0117e-03, -2.4757e-03, -1.0742e-02,  ..., -2.7599e-03,
         -9.9411e-03,  4.8889e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.0000, -3.0156, -1.1963,  ...,  4.4570, -2.0684, -3.0977]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 07:47:51 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for adding is the active form of add
creating is the active form of create
including is the active form of include
losing is the active form of lose
understanding is the active form of understand
preventing is the active form of prevent
protecting is the active form of protect
encouraging is the active form of
2024-07-31 07:47:51 root INFO     total operator prediction time: 928.5140655040741 seconds
2024-07-31 07:47:51 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on noun - plural_irreg
2024-07-31 07:47:51 root INFO     building operator noun - plural_irreg
2024-07-31 07:47:51 root INFO     [order_1_approx] starting weight calculation for The plural form of safety is safeties
The plural form of library is libraries
The plural form of city is cities
The plural form of category is categories
The plural form of security is securities
The plural form of history is histories
The plural form of majority is majorities
The plural form of theory is
2024-07-31 07:47:51 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 07:49:43 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1709, -0.0488, -0.1436,  ..., -0.5898, -0.2462, -0.0427],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.4844, -2.2949,  2.1855,  ..., -0.4880, -2.5195, -3.1465],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 8.6243e-02, -4.5166e-03,  1.7233e-03,  ..., -2.1191e-03,
          8.9035e-03,  1.9501e-02],
        [-9.0103e-03,  9.8206e-02,  2.0248e-02,  ...,  4.4441e-03,
         -1.1772e-02,  1.2627e-02],
        [ 1.8234e-03, -2.2736e-03,  4.7485e-02,  ..., -2.2995e-02,
         -4.4518e-03,  4.6272e-03],
        ...,
        [ 2.1591e-03,  1.0849e-02, -1.5450e-03,  ...,  6.6589e-02,
         -1.1459e-02,  1.3718e-02],
        [ 1.9073e-05,  4.8065e-03,  1.4511e-02,  ..., -5.4121e-04,
          5.9326e-02, -2.0935e-02],
        [ 1.3313e-02,  1.3802e-02, -9.1553e-05,  ..., -8.7585e-03,
         -8.6060e-03,  7.4219e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.9814, -2.3125,  1.8193,  ..., -0.5957, -2.2637, -3.0840]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 07:49:44 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of safety is safeties
The plural form of library is libraries
The plural form of city is cities
The plural form of category is categories
The plural form of security is securities
The plural form of history is histories
The plural form of majority is majorities
The plural form of theory is
2024-07-31 07:49:44 root INFO     [order_1_approx] starting weight calculation for The plural form of library is libraries
The plural form of category is categories
The plural form of city is cities
The plural form of history is histories
The plural form of majority is majorities
The plural form of theory is theories
The plural form of security is securities
The plural form of safety is
2024-07-31 07:49:44 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 07:51:42 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1924,  0.1775, -0.4653,  ..., -0.2371, -0.0288, -0.1923],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.4648, -0.3228, -0.9971,  ..., -0.4395, -3.5664, -1.9912],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0838, -0.0178,  0.0123,  ..., -0.0055,  0.0076,  0.0132],
        [-0.0117,  0.0903,  0.0153,  ...,  0.0109,  0.0115, -0.0090],
        [ 0.0220,  0.0066,  0.0826,  ..., -0.0018, -0.0229, -0.0181],
        ...,
        [ 0.0019,  0.0239, -0.0101,  ...,  0.0914, -0.0327, -0.0148],
        [ 0.0101,  0.0202,  0.0141,  ...,  0.0149,  0.0609,  0.0080],
        [-0.0060, -0.0006, -0.0175,  ...,  0.0037, -0.0067,  0.0782]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.9355, -0.3945, -0.5342,  ..., -0.5469, -3.3359, -1.7998]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 07:51:43 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of library is libraries
The plural form of category is categories
The plural form of city is cities
The plural form of history is histories
The plural form of majority is majorities
The plural form of theory is theories
The plural form of security is securities
The plural form of safety is
2024-07-31 07:51:43 root INFO     [order_1_approx] starting weight calculation for The plural form of library is libraries
The plural form of theory is theories
The plural form of safety is safeties
The plural form of security is securities
The plural form of history is histories
The plural form of majority is majorities
The plural form of category is categories
The plural form of city is
2024-07-31 07:51:44 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 07:53:38 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3188,  0.3711, -0.3845,  ..., -0.5298, -0.1855, -0.0506],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-2.1211, -6.2383,  1.8438,  ..., -1.6318,  1.8018, -1.4590],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 7.0190e-02, -7.5226e-03,  1.6022e-02,  ..., -3.1223e-03,
          2.7771e-03,  1.4954e-02],
        [ 5.4131e-03,  6.9763e-02, -7.8735e-03,  ...,  1.8372e-02,
          2.3621e-02,  9.2697e-04],
        [ 8.9493e-03,  9.7275e-03,  6.5918e-02,  ..., -4.9591e-05,
         -2.2415e-02,  1.6800e-02],
        ...,
        [ 2.2095e-02,  5.5199e-03,  2.0943e-03,  ...,  6.7505e-02,
         -1.3832e-02,  3.2043e-03],
        [-2.7069e-02,  1.4854e-02, -7.6447e-03,  ..., -1.9760e-02,
          6.3660e-02, -1.4130e-02],
        [ 1.0643e-02,  8.1444e-04, -3.1006e-02,  ..., -2.1423e-02,
         -1.3412e-02,  6.1829e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.9756, -6.4844,  1.9629,  ..., -2.1309,  2.3672, -1.8330]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 07:53:39 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of library is libraries
The plural form of theory is theories
The plural form of safety is safeties
The plural form of security is securities
The plural form of history is histories
The plural form of majority is majorities
The plural form of category is categories
The plural form of city is
2024-07-31 07:53:39 root INFO     [order_1_approx] starting weight calculation for The plural form of category is categories
The plural form of safety is safeties
The plural form of library is libraries
The plural form of theory is theories
The plural form of city is cities
The plural form of history is histories
The plural form of majority is majorities
The plural form of security is
2024-07-31 07:53:39 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 07:55:39 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.5464,  0.2283, -0.5513,  ...,  0.1277, -0.0502, -0.3264],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.0576, -1.1836,  1.1104,  ...,  0.4114, -2.3066, -5.1406],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.1168, -0.0051,  0.0233,  ...,  0.0037, -0.0055,  0.0275],
        [-0.0284,  0.1024,  0.0262,  ...,  0.0015,  0.0078,  0.0057],
        [ 0.0336,  0.0228,  0.0935,  ..., -0.0034, -0.0212,  0.0007],
        ...,
        [-0.0148,  0.0099, -0.0093,  ...,  0.0993, -0.0181, -0.0078],
        [ 0.0169,  0.0227,  0.0250,  ...,  0.0063,  0.0853, -0.0120],
        [-0.0075,  0.0062, -0.0208,  ...,  0.0099,  0.0055,  0.0984]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.1019, -1.2129,  1.4707,  ...,  0.4854, -2.2480, -4.8516]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 07:55:40 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of category is categories
The plural form of safety is safeties
The plural form of library is libraries
The plural form of theory is theories
The plural form of city is cities
The plural form of history is histories
The plural form of majority is majorities
The plural form of security is
2024-07-31 07:55:40 root INFO     [order_1_approx] starting weight calculation for The plural form of majority is majorities
The plural form of category is categories
The plural form of theory is theories
The plural form of safety is safeties
The plural form of city is cities
The plural form of security is securities
The plural form of library is libraries
The plural form of history is
2024-07-31 07:55:40 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 07:57:38 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0848, -0.1152, -0.0601,  ..., -0.0690, -0.1814, -0.0580],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.2258, -1.7188,  0.9883,  ..., -2.0352, -3.6387, -2.7227],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0775,  0.0108,  0.0106,  ..., -0.0158,  0.0016,  0.0077],
        [-0.0035,  0.0875,  0.0033,  ...,  0.0140, -0.0122,  0.0029],
        [ 0.0155, -0.0015,  0.0529,  ..., -0.0016, -0.0069,  0.0207],
        ...,
        [ 0.0063,  0.0244, -0.0077,  ...,  0.0799, -0.0185,  0.0044],
        [-0.0169,  0.0182,  0.0178,  ..., -0.0047,  0.0636, -0.0091],
        [ 0.0106,  0.0130, -0.0113,  ...,  0.0011, -0.0178,  0.0673]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.1809, -1.7383,  1.2090,  ..., -1.7910, -3.8340, -2.3398]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 07:57:39 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of majority is majorities
The plural form of category is categories
The plural form of theory is theories
The plural form of safety is safeties
The plural form of city is cities
The plural form of security is securities
The plural form of library is libraries
The plural form of history is
2024-07-31 07:57:39 root INFO     [order_1_approx] starting weight calculation for The plural form of safety is safeties
The plural form of category is categories
The plural form of security is securities
The plural form of city is cities
The plural form of library is libraries
The plural form of theory is theories
The plural form of history is histories
The plural form of majority is
2024-07-31 07:57:39 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 07:59:37 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.6929,  0.9463, -0.8711,  ...,  0.1653, -0.1527, -0.2019],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.6719, -0.3872, -1.2256,  ..., -5.7031, -0.9053, -2.3594],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0945, -0.0060,  0.0104,  ...,  0.0097,  0.0072, -0.0108],
        [ 0.0087,  0.0780, -0.0069,  ...,  0.0283, -0.0158,  0.0083],
        [ 0.0272,  0.0031,  0.0931,  ..., -0.0115,  0.0018,  0.0092],
        ...,
        [ 0.0224,  0.0342,  0.0391,  ...,  0.0952, -0.0202,  0.0252],
        [-0.0161,  0.0140, -0.0122,  ...,  0.0050,  0.0604, -0.0208],
        [-0.0025,  0.0118, -0.0163,  ...,  0.0036, -0.0152,  0.0979]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.4336, -0.4231, -0.8994,  ..., -5.3828, -1.1230, -2.3379]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 07:59:38 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of safety is safeties
The plural form of category is categories
The plural form of security is securities
The plural form of city is cities
The plural form of library is libraries
The plural form of theory is theories
The plural form of history is histories
The plural form of majority is
2024-07-31 07:59:39 root INFO     [order_1_approx] starting weight calculation for The plural form of theory is theories
The plural form of history is histories
The plural form of security is securities
The plural form of safety is safeties
The plural form of city is cities
The plural form of majority is majorities
The plural form of category is categories
The plural form of library is
2024-07-31 07:59:39 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 08:01:38 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.5225, -0.4556, -0.8853,  ...,  0.1780, -0.6182,  0.1053],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.4180, -4.7500,  1.1836,  ..., -0.0898, -1.3818, -3.7344],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0718, -0.0100, -0.0042,  ..., -0.0003,  0.0131, -0.0198],
        [ 0.0111,  0.0702, -0.0053,  ...,  0.0186, -0.0020, -0.0033],
        [-0.0052,  0.0007,  0.0540,  ..., -0.0246,  0.0004,  0.0089],
        ...,
        [ 0.0056,  0.0042,  0.0016,  ...,  0.0869, -0.0136,  0.0041],
        [-0.0070,  0.0309,  0.0160,  ...,  0.0045,  0.0688,  0.0101],
        [-0.0055, -0.0148, -0.0070,  ..., -0.0052, -0.0139,  0.0619]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.4395, -4.6797,  1.0654,  ..., -0.4543, -1.0918, -3.3438]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 08:01:39 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of theory is theories
The plural form of history is histories
The plural form of security is securities
The plural form of safety is safeties
The plural form of city is cities
The plural form of majority is majorities
The plural form of category is categories
The plural form of library is
2024-07-31 08:01:39 root INFO     [order_1_approx] starting weight calculation for The plural form of history is histories
The plural form of majority is majorities
The plural form of library is libraries
The plural form of city is cities
The plural form of safety is safeties
The plural form of security is securities
The plural form of theory is theories
The plural form of category is
2024-07-31 08:01:39 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 08:03:31 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.7090,  0.2549,  0.1034,  ...,  0.1583, -0.2930, -0.0519],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.4624, -2.6719,  1.5166,  ..., -0.8877,  0.0098, -2.4824],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0819, -0.0231,  0.0195,  ..., -0.0245,  0.0305, -0.0347],
        [ 0.0105,  0.1232,  0.0192,  ...,  0.0153,  0.0017,  0.0279],
        [ 0.0066, -0.0044,  0.0834,  ..., -0.0150,  0.0059,  0.0045],
        ...,
        [ 0.0170,  0.0261,  0.0060,  ...,  0.1209, -0.0167,  0.0337],
        [-0.0276,  0.0221, -0.0083,  ..., -0.0199,  0.0914,  0.0047],
        [ 0.0187,  0.0171, -0.0127,  ...,  0.0053, -0.0132,  0.1128]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.3105, -2.2188,  1.8223,  ..., -0.5400, -0.2649, -2.4375]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 08:03:32 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of history is histories
The plural form of majority is majorities
The plural form of library is libraries
The plural form of city is cities
The plural form of safety is safeties
The plural form of security is securities
The plural form of theory is theories
The plural form of category is
2024-07-31 08:03:32 root INFO     total operator prediction time: 940.586377620697 seconds
2024-07-31 08:03:32 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on meronyms - member
2024-07-31 08:03:32 root INFO     building operator meronyms - member
2024-07-31 08:03:32 root INFO     [order_1_approx] starting weight calculation for A fish is a member of a school
A cattle is a member of a herd
A song is a member of a album
A cow is a member of a herd
A division is a member of a company
A sheep is a member of a flock
A singer is a member of a choir
A page is a member of a
2024-07-31 08:03:32 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 08:05:28 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0856,  1.1309,  0.0398,  ..., -0.4570, -0.8164,  0.0229],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.0781, -1.6846,  2.0039,  ..., -2.2285, -1.6387, -1.8242],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0985,  0.0040, -0.0008,  ...,  0.0005,  0.0043, -0.0127],
        [-0.0094,  0.1058,  0.0044,  ..., -0.0315,  0.0110, -0.0228],
        [ 0.0037,  0.0149,  0.1105,  ...,  0.0154, -0.0211,  0.0110],
        ...,
        [ 0.0153, -0.0175, -0.0443,  ...,  0.1087,  0.0005, -0.0287],
        [ 0.0074, -0.0072,  0.0055,  ...,  0.0120,  0.0996,  0.0028],
        [-0.0216,  0.0049, -0.0066,  ..., -0.0154, -0.0003,  0.1147]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.8457, -2.0059,  2.3027,  ..., -2.0781, -1.2842, -1.8574]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 08:05:29 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A fish is a member of a school
A cattle is a member of a herd
A song is a member of a album
A cow is a member of a herd
A division is a member of a company
A sheep is a member of a flock
A singer is a member of a choir
A page is a member of a
2024-07-31 08:05:29 root INFO     [order_1_approx] starting weight calculation for A song is a member of a album
A cow is a member of a herd
A cattle is a member of a herd
A singer is a member of a choir
A page is a member of a book
A sheep is a member of a flock
A fish is a member of a school
A division is a member of a
2024-07-31 08:05:29 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 08:07:25 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([0.8413, 0.2279, 0.1205,  ..., 0.6724, 0.2412, 0.3008], device='cuda:1',
       dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.0840, -4.7344,  2.5410,  ..., -2.7422,  0.3618, -4.9531],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 6.2225e-02, -2.5330e-03,  2.8152e-03,  ..., -1.8829e-02,
          9.6512e-03, -7.5912e-03],
        [ 3.2310e-03,  4.9744e-02,  7.7248e-03,  ..., -2.6733e-02,
          6.6376e-03, -4.1504e-03],
        [ 2.6608e-03,  1.2688e-02,  5.3284e-02,  ...,  3.4714e-04,
         -3.1605e-03, -7.9727e-03],
        ...,
        [ 4.3640e-03,  1.1284e-02,  1.2810e-02,  ...,  5.5603e-02,
         -1.5259e-04, -1.5129e-02],
        [-3.8528e-04,  2.3499e-02, -2.3727e-03,  ...,  2.3239e-02,
          6.8420e-02, -2.6550e-02],
        [-9.3651e-04, -1.2993e-02, -3.8147e-06,  ..., -4.8370e-03,
         -1.2573e-02,  7.3486e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.2441, -4.7773,  2.8730,  ..., -2.6250,  0.3684, -4.3906]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 08:07:26 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A song is a member of a album
A cow is a member of a herd
A cattle is a member of a herd
A singer is a member of a choir
A page is a member of a book
A sheep is a member of a flock
A fish is a member of a school
A division is a member of a
2024-07-31 08:07:26 root INFO     [order_1_approx] starting weight calculation for A sheep is a member of a flock
A song is a member of a album
A division is a member of a company
A page is a member of a book
A fish is a member of a school
A singer is a member of a choir
A cattle is a member of a herd
A cow is a member of a
2024-07-31 08:07:26 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 08:09:25 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4175,  0.0113,  0.0684,  ...,  0.2573, -0.2871, -0.0159],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.9570, -3.9668,  3.8789,  ..., -3.7305, -0.9580, -2.1836],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 4.4189e-02,  7.0267e-03,  5.0049e-03,  ..., -5.7144e-03,
         -1.0651e-02, -6.6299e-03],
        [ 1.5419e-02,  3.9917e-02, -5.2261e-04,  ..., -2.8152e-03,
         -4.6349e-03,  2.2888e-03],
        [-9.2163e-03, -5.6801e-03,  4.0466e-02,  ...,  4.9591e-03,
         -4.6730e-03, -8.5068e-03],
        ...,
        [ 2.1210e-03, -4.0131e-03, -2.3842e-05,  ...,  4.6570e-02,
          6.6338e-03,  8.6212e-04],
        [ 4.1962e-04,  6.1226e-03, -1.3222e-02,  ...,  1.3428e-02,
          3.1082e-02, -8.2169e-03],
        [-1.2817e-02, -1.7700e-03,  3.3188e-03,  ..., -5.6152e-03,
          1.5488e-03,  3.7354e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.8164, -4.1914,  4.2031,  ..., -3.5391, -1.2422, -1.9707]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 08:09:26 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A sheep is a member of a flock
A song is a member of a album
A division is a member of a company
A page is a member of a book
A fish is a member of a school
A singer is a member of a choir
A cattle is a member of a herd
A cow is a member of a
2024-07-31 08:09:26 root INFO     [order_1_approx] starting weight calculation for A division is a member of a company
A cattle is a member of a herd
A cow is a member of a herd
A page is a member of a book
A sheep is a member of a flock
A singer is a member of a choir
A song is a member of a album
A fish is a member of a
2024-07-31 08:09:26 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 08:11:23 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2737,  0.3643, -0.3784,  ..., -0.4382, -0.0882,  0.3608],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 5.0898, -3.7441,  1.3545,  ..., -2.2539, -2.9082, -1.9219],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0482, -0.0017,  0.0107,  ...,  0.0303, -0.0093,  0.0012],
        [ 0.0013,  0.0435, -0.0135,  ..., -0.0302,  0.0221, -0.0086],
        [-0.0019,  0.0118,  0.0541,  ...,  0.0008, -0.0137,  0.0111],
        ...,
        [-0.0040, -0.0075,  0.0127,  ...,  0.0710,  0.0005, -0.0011],
        [-0.0005,  0.0126, -0.0095,  ..., -0.0025,  0.0428, -0.0108],
        [-0.0048, -0.0177, -0.0155,  ..., -0.0097, -0.0027,  0.0647]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.7461, -3.6250,  1.3047,  ..., -2.1367, -2.9629, -1.9248]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 08:11:24 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A division is a member of a company
A cattle is a member of a herd
A cow is a member of a herd
A page is a member of a book
A sheep is a member of a flock
A singer is a member of a choir
A song is a member of a album
A fish is a member of a
2024-07-31 08:11:24 root INFO     [order_1_approx] starting weight calculation for A cattle is a member of a herd
A page is a member of a book
A cow is a member of a herd
A singer is a member of a choir
A song is a member of a album
A fish is a member of a school
A division is a member of a company
A sheep is a member of a
2024-07-31 08:11:24 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 08:13:22 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2993,  0.0458,  0.0797,  ..., -0.0630, -0.3721,  0.6592],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.4102, -1.9434,  3.8379,  ..., -1.7988, -2.0664, -1.0957],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0516,  0.0050,  0.0167,  ...,  0.0135, -0.0146, -0.0002],
        [ 0.0128,  0.0519, -0.0048,  ..., -0.0101,  0.0005, -0.0139],
        [-0.0058,  0.0145,  0.0536,  ...,  0.0087, -0.0128, -0.0041],
        ...,
        [ 0.0103, -0.0049, -0.0014,  ...,  0.0582, -0.0144, -0.0107],
        [-0.0026,  0.0063, -0.0018,  ...,  0.0031,  0.0471, -0.0111],
        [-0.0126, -0.0078, -0.0089,  ..., -0.0241, -0.0010,  0.0478]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.3867, -2.3594,  3.6797,  ..., -1.7598, -2.5898, -1.4023]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 08:13:23 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A cattle is a member of a herd
A page is a member of a book
A cow is a member of a herd
A singer is a member of a choir
A song is a member of a album
A fish is a member of a school
A division is a member of a company
A sheep is a member of a
2024-07-31 08:13:23 root INFO     [order_1_approx] starting weight calculation for A cattle is a member of a herd
A division is a member of a company
A page is a member of a book
A sheep is a member of a flock
A cow is a member of a herd
A fish is a member of a school
A song is a member of a album
A singer is a member of a
2024-07-31 08:13:23 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 08:15:19 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3716,  0.2986, -0.0921,  ...,  0.2842, -0.2798, -0.1956],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.5996, -6.2539,  5.0742,  ..., -1.4355,  0.6919, -2.7207],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0367,  0.0049,  0.0025,  ...,  0.0073, -0.0024, -0.0088],
        [-0.0022,  0.0349,  0.0156,  ..., -0.0112,  0.0144, -0.0079],
        [ 0.0029,  0.0088,  0.0399,  ...,  0.0075,  0.0035,  0.0107],
        ...,
        [ 0.0232, -0.0006,  0.0044,  ...,  0.0472,  0.0091, -0.0119],
        [-0.0066,  0.0020, -0.0084,  ...,  0.0193,  0.0300, -0.0096],
        [-0.0014, -0.0139, -0.0109,  ..., -0.0006, -0.0066,  0.0435]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.6641, -6.1406,  5.0508,  ..., -1.4688,  0.5195, -2.5996]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 08:15:20 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A cattle is a member of a herd
A division is a member of a company
A page is a member of a book
A sheep is a member of a flock
A cow is a member of a herd
A fish is a member of a school
A song is a member of a album
A singer is a member of a
2024-07-31 08:15:20 root INFO     [order_1_approx] starting weight calculation for A division is a member of a company
A sheep is a member of a flock
A singer is a member of a choir
A fish is a member of a school
A page is a member of a book
A song is a member of a album
A cow is a member of a herd
A cattle is a member of a
2024-07-31 08:15:20 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 08:17:20 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3589,  0.1019, -0.1164,  ..., -0.4287, -0.2864,  0.0345],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.5898, -4.5703,  3.4219,  ..., -3.6953, -0.1548, -2.4941],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 5.3558e-02, -5.2643e-03,  5.6915e-03,  ..., -1.2817e-03,
          6.7062e-03, -7.5302e-03],
        [ 1.0635e-02,  4.9438e-02,  4.0894e-03,  ..., -6.7902e-04,
         -7.2479e-04, -8.8959e-03],
        [-1.3466e-03, -6.4774e-03,  4.2816e-02,  ..., -3.2787e-03,
          1.0574e-02, -4.7150e-03],
        ...,
        [ 8.3351e-04, -3.6373e-03,  4.0131e-03,  ...,  5.2429e-02,
          9.1553e-05, -5.1270e-03],
        [-7.8201e-04,  9.7885e-03, -6.5384e-03,  ...,  1.0780e-02,
          3.5095e-02, -3.9520e-03],
        [ 4.1199e-04, -1.2421e-02, -1.9245e-03,  ..., -9.2010e-03,
         -2.3823e-03,  5.3955e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.5391, -4.6797,  3.7012,  ..., -3.4473, -0.5068, -2.4219]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 08:17:21 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A division is a member of a company
A sheep is a member of a flock
A singer is a member of a choir
A fish is a member of a school
A page is a member of a book
A song is a member of a album
A cow is a member of a herd
A cattle is a member of a
2024-07-31 08:17:21 root INFO     [order_1_approx] starting weight calculation for A singer is a member of a choir
A cow is a member of a herd
A page is a member of a book
A sheep is a member of a flock
A division is a member of a company
A fish is a member of a school
A cattle is a member of a herd
A song is a member of a
2024-07-31 08:17:21 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 08:19:19 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.4509,  0.1692,  0.2292,  ...,  0.0345, -0.6641, -0.7026],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.2241, -6.8281,  2.8652,  ..., -0.0840, -0.7070, -1.3564],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0464,  0.0070,  0.0157,  ...,  0.0069, -0.0085,  0.0020],
        [ 0.0088,  0.0442,  0.0051,  ..., -0.0109,  0.0094, -0.0099],
        [ 0.0216,  0.0172,  0.0542,  ...,  0.0057,  0.0041,  0.0138],
        ...,
        [ 0.0039, -0.0040,  0.0067,  ...,  0.0564,  0.0024, -0.0126],
        [-0.0086,  0.0044, -0.0020,  ...,  0.0100,  0.0492, -0.0086],
        [-0.0061, -0.0154, -0.0069,  ..., -0.0097, -0.0035,  0.0497]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.0094, -6.6953,  3.2168,  ..., -0.4485, -0.5371, -1.0947]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 08:19:20 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A singer is a member of a choir
A cow is a member of a herd
A page is a member of a book
A sheep is a member of a flock
A division is a member of a company
A fish is a member of a school
A cattle is a member of a herd
A song is a member of a
2024-07-31 08:19:20 root INFO     total operator prediction time: 948.1325387954712 seconds
2024-07-31 08:19:20 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on antonyms - binary
2024-07-31 08:19:20 root INFO     building operator antonyms - binary
2024-07-31 08:19:20 root INFO     [order_1_approx] starting weight calculation for The opposite of under is over
The opposite of backward is forward
The opposite of forward is backward
The opposite of exit is entrance
The opposite of over is under
The opposite of south is north
The opposite of climb is descend
The opposite of beginning is
2024-07-31 08:19:20 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 08:21:17 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4944,  0.4531, -0.4858,  ...,  0.0861, -0.5796, -0.7446],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.4766, -3.2949, -0.8760,  ...,  1.4160, -1.9160, -2.6250],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 5.3345e-02,  5.4092e-03, -8.0261e-03,  ...,  6.0120e-03,
         -4.6463e-03, -1.3542e-03],
        [ 1.1124e-02,  1.0101e-01, -1.6937e-03,  ..., -4.4250e-03,
          2.7122e-03,  1.1612e-02],
        [-7.8812e-03, -1.6754e-02,  3.5583e-02,  ..., -3.6278e-03,
         -8.5754e-03, -1.6205e-02],
        ...,
        [ 2.1820e-02,  1.4870e-02,  7.2136e-03,  ...,  6.5552e-02,
         -2.3392e-02, -2.2888e-05],
        [-1.0056e-02,  1.9226e-03,  4.1931e-02,  ..., -2.7130e-02,
          3.9520e-02, -9.7733e-03],
        [ 9.9182e-03, -6.0883e-03, -1.1711e-02,  ..., -1.4282e-02,
          1.0178e-02,  6.0333e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.7207, -3.5059, -0.3340,  ...,  1.5928, -2.0723, -2.1660]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 08:21:18 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of under is over
The opposite of backward is forward
The opposite of forward is backward
The opposite of exit is entrance
The opposite of over is under
The opposite of south is north
The opposite of climb is descend
The opposite of beginning is
2024-07-31 08:21:18 root INFO     [order_1_approx] starting weight calculation for The opposite of over is under
The opposite of under is over
The opposite of beginning is end
The opposite of backward is forward
The opposite of climb is descend
The opposite of exit is entrance
The opposite of south is north
The opposite of forward is
2024-07-31 08:21:19 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 08:23:15 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1476,  0.4082, -0.5801,  ..., -0.6040,  0.4822,  0.7241],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.8281, -3.9238,  1.2812,  ..., -0.8877, -3.2754, -2.1992],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0945, -0.0009,  0.0125,  ...,  0.0080, -0.0022, -0.0026],
        [ 0.0048,  0.0807,  0.0087,  ..., -0.0086,  0.0063,  0.0012],
        [ 0.0124, -0.0136,  0.0689,  ..., -0.0031, -0.0249,  0.0068],
        ...,
        [ 0.0053,  0.0013, -0.0161,  ...,  0.0950, -0.0086, -0.0209],
        [-0.0471, -0.0080,  0.0065,  ..., -0.0053,  0.0828, -0.0104],
        [ 0.0154, -0.0097,  0.0052,  ...,  0.0008, -0.0055,  0.0478]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.3105, -3.7695,  1.4541,  ..., -0.9087, -3.2637, -2.1816]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 08:23:16 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of over is under
The opposite of under is over
The opposite of beginning is end
The opposite of backward is forward
The opposite of climb is descend
The opposite of exit is entrance
The opposite of south is north
The opposite of forward is
2024-07-31 08:23:16 root INFO     [order_1_approx] starting weight calculation for The opposite of climb is descend
The opposite of beginning is end
The opposite of forward is backward
The opposite of backward is forward
The opposite of south is north
The opposite of exit is entrance
The opposite of over is under
The opposite of under is
2024-07-31 08:23:16 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 08:25:14 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0828,  0.1716,  0.2482,  ..., -0.7974,  0.0159, -0.6367],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.3086, -5.1953,  1.6680,  ..., -0.9570,  0.6899, -1.6934],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0410,  0.0117,  0.0065,  ...,  0.0083,  0.0085,  0.0121],
        [ 0.0016,  0.0739, -0.0024,  ...,  0.0026, -0.0096,  0.0103],
        [ 0.0074, -0.0117,  0.0293,  ..., -0.0140,  0.0016,  0.0219],
        ...,
        [-0.0089,  0.0068, -0.0018,  ...,  0.0403, -0.0079, -0.0067],
        [-0.0021, -0.0041,  0.0133,  ...,  0.0068,  0.0420,  0.0083],
        [ 0.0052,  0.0040, -0.0062,  ..., -0.0063, -0.0087,  0.0412]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.4883, -5.0742,  1.5762,  ..., -0.6064,  0.3259, -1.5732]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 08:25:15 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of climb is descend
The opposite of beginning is end
The opposite of forward is backward
The opposite of backward is forward
The opposite of south is north
The opposite of exit is entrance
The opposite of over is under
The opposite of under is
2024-07-31 08:25:15 root INFO     [order_1_approx] starting weight calculation for The opposite of exit is entrance
The opposite of climb is descend
The opposite of over is under
The opposite of under is over
The opposite of beginning is end
The opposite of backward is forward
The opposite of forward is backward
The opposite of south is
2024-07-31 08:25:15 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 08:27:06 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0662,  0.2688, -0.1710,  ...,  0.2854,  0.3032, -0.4272],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.0508, -4.3203,  1.0088,  ..., -1.0205,  0.8242, -4.1328],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0473, -0.0269, -0.0078,  ..., -0.0071,  0.0154,  0.0097],
        [ 0.0109,  0.0355,  0.0007,  ...,  0.0060,  0.0229,  0.0264],
        [-0.0269,  0.0003,  0.0356,  ..., -0.0059,  0.0007,  0.0386],
        ...,
        [ 0.0087, -0.0174,  0.0128,  ...,  0.0507,  0.0075, -0.0113],
        [-0.0222, -0.0274,  0.0125,  ...,  0.0093,  0.0595,  0.0033],
        [-0.0082, -0.0097, -0.0007,  ...,  0.0032, -0.0078,  0.0473]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.5254, -4.4141,  1.4238,  ..., -0.5488,  0.8794, -4.0273]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 08:27:07 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of exit is entrance
The opposite of climb is descend
The opposite of over is under
The opposite of under is over
The opposite of beginning is end
The opposite of backward is forward
The opposite of forward is backward
The opposite of south is
2024-07-31 08:27:07 root INFO     [order_1_approx] starting weight calculation for The opposite of over is under
The opposite of south is north
The opposite of forward is backward
The opposite of beginning is end
The opposite of exit is entrance
The opposite of under is over
The opposite of climb is descend
The opposite of backward is
2024-07-31 08:27:08 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 08:28:57 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2820, -0.1985, -0.7314,  ..., -0.4902,  0.0103, -0.2458],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.7500, -3.4258,  0.4604,  ...,  0.4966, -3.5430, -1.3145],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0748,  0.0099,  0.0062,  ...,  0.0153,  0.0175,  0.0208],
        [-0.0124,  0.0736,  0.0182,  ..., -0.0085,  0.0056, -0.0256],
        [-0.0046, -0.0232,  0.0369,  ...,  0.0128, -0.0153,  0.0040],
        ...,
        [-0.0021,  0.0100,  0.0043,  ...,  0.0333,  0.0039, -0.0134],
        [-0.0118, -0.0189,  0.0194,  ..., -0.0048,  0.0334, -0.0119],
        [-0.0014,  0.0138,  0.0075,  ..., -0.0076,  0.0040,  0.0436]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 5.3242, -3.3242, -0.0474,  ...,  0.7593, -3.7051, -1.3760]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 08:28:57 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of over is under
The opposite of south is north
The opposite of forward is backward
The opposite of beginning is end
The opposite of exit is entrance
The opposite of under is over
The opposite of climb is descend
The opposite of backward is
2024-07-31 08:28:58 root INFO     [order_1_approx] starting weight calculation for The opposite of south is north
The opposite of forward is backward
The opposite of under is over
The opposite of beginning is end
The opposite of climb is descend
The opposite of exit is entrance
The opposite of backward is forward
The opposite of over is
2024-07-31 08:28:58 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 08:30:58 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3540, -0.1089, -0.7100,  ..., -0.6245,  0.2000, -0.1359],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.5195, -1.9814,  0.7354,  ..., -1.9814,  1.7705, -1.6143],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 5.4626e-02, -5.6763e-03,  7.1259e-03,  ..., -2.1420e-03,
          8.6517e-03, -5.7220e-05],
        [ 2.7885e-03,  6.7810e-02, -3.0411e-02,  ..., -1.0956e-02,
          1.4160e-02,  1.7502e-02],
        [ 2.8954e-03, -8.4610e-03,  4.5929e-02,  ..., -2.5391e-02,
         -1.7609e-02,  3.5248e-03],
        ...,
        [-7.9651e-03,  1.0422e-02, -1.8845e-02,  ...,  6.7383e-02,
          1.1337e-02, -3.3081e-02],
        [ 1.0681e-04, -9.3231e-03,  2.1576e-02,  ..., -5.6229e-03,
          4.3121e-02,  1.0368e-02],
        [ 7.1030e-03, -1.6937e-02, -1.1063e-02,  ...,  6.1035e-05,
         -2.0599e-03,  4.4800e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 5.0859, -2.7109,  0.2427,  ..., -1.6250,  0.9741, -1.8184]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 08:30:59 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of south is north
The opposite of forward is backward
The opposite of under is over
The opposite of beginning is end
The opposite of climb is descend
The opposite of exit is entrance
The opposite of backward is forward
The opposite of over is
2024-07-31 08:30:59 root INFO     [order_1_approx] starting weight calculation for The opposite of backward is forward
The opposite of exit is entrance
The opposite of forward is backward
The opposite of south is north
The opposite of beginning is end
The opposite of under is over
The opposite of over is under
The opposite of climb is
2024-07-31 08:30:59 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 08:32:58 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2002, -0.0137, -0.1619,  ..., -0.9414, -0.4202,  0.2573],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.3320, -1.7930,  3.2051,  ..., -0.4458, -3.2832, -1.4102],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 7.8857e-02,  4.3983e-03,  2.6703e-05,  ...,  2.0416e-02,
          6.2485e-03, -3.1548e-03],
        [-1.2924e-02,  5.9998e-02,  6.4697e-03,  ..., -9.1553e-05,
          3.1548e-03, -1.7059e-02],
        [-7.3967e-03, -2.2202e-03,  1.6907e-02,  ..., -7.5455e-03,
         -2.3270e-02,  9.5520e-03],
        ...,
        [-9.1400e-03,  1.2405e-02,  3.7422e-03,  ...,  4.3854e-02,
         -1.8036e-02, -1.6281e-02],
        [-3.2501e-03,  1.6212e-03,  6.9351e-03,  ...,  1.0437e-02,
          4.0833e-02,  1.5160e-02],
        [-1.1673e-02,  1.4008e-02,  3.7384e-03,  ..., -1.2833e-02,
          1.2291e-02,  3.3875e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.6250, -1.7324,  3.1250,  ..., -0.4968, -3.4453, -1.4414]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 08:32:59 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of backward is forward
The opposite of exit is entrance
The opposite of forward is backward
The opposite of south is north
The opposite of beginning is end
The opposite of under is over
The opposite of over is under
The opposite of climb is
2024-07-31 08:33:00 root INFO     [order_1_approx] starting weight calculation for The opposite of beginning is end
The opposite of south is north
The opposite of under is over
The opposite of backward is forward
The opposite of forward is backward
The opposite of climb is descend
The opposite of over is under
The opposite of exit is
2024-07-31 08:33:00 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 08:34:58 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.4419,  0.0906, -1.3809,  ..., -0.0125, -0.1212, -0.5684],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.6123, -3.8789, -2.2734,  ...,  1.7773, -3.4707, -4.2578],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0651,  0.0231,  0.0083,  ...,  0.0066,  0.0115,  0.0153],
        [-0.0158,  0.0869, -0.0125,  ..., -0.0007,  0.0066,  0.0026],
        [-0.0084,  0.0236,  0.0409,  ..., -0.0174, -0.0281,  0.0126],
        ...,
        [ 0.0123, -0.0020, -0.0285,  ...,  0.0590, -0.0198, -0.0244],
        [-0.0141, -0.0111,  0.0121,  ...,  0.0154,  0.0478,  0.0206],
        [ 0.0189,  0.0278, -0.0158,  ..., -0.0128,  0.0010,  0.0721]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.6631, -3.7500, -2.2793,  ...,  1.8213, -3.1680, -3.9551]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 08:34:59 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of beginning is end
The opposite of south is north
The opposite of under is over
The opposite of backward is forward
The opposite of forward is backward
The opposite of climb is descend
The opposite of over is under
The opposite of exit is
2024-07-31 08:34:59 root INFO     total operator prediction time: 939.4846050739288 seconds
2024-07-31 08:34:59 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on hyponyms - misc
2024-07-31 08:34:59 root INFO     building operator hyponyms - misc
2024-07-31 08:35:00 root INFO     [order_1_approx] starting weight calculation for A more specific term for a mixer is blender
A more specific term for a shoes is sneakers
A more specific term for a collar is choker
A more specific term for a song is lullaby
A more specific term for a camera is camcorder
A more specific term for a bag is pouch
A more specific term for a dessert is cake
A more specific term for a oven is
2024-07-31 08:35:00 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 08:36:55 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0865, -0.1285, -0.0254,  ...,  0.5469, -0.3928, -0.4988],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.3672, -4.1680,  3.4277,  ..., -3.0508, -3.3281,  2.2637],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0875,  0.0079, -0.0118,  ...,  0.0132,  0.0013,  0.0039],
        [ 0.0056,  0.0574,  0.0193,  ..., -0.0158,  0.0089, -0.0110],
        [-0.0045,  0.0044,  0.0874,  ..., -0.0006,  0.0129,  0.0023],
        ...,
        [-0.0053,  0.0147,  0.0013,  ...,  0.0825, -0.0083,  0.0044],
        [-0.0154, -0.0060, -0.0071,  ...,  0.0122,  0.0942, -0.0142],
        [-0.0163, -0.0031,  0.0084,  ..., -0.0286, -0.0203,  0.0540]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.1113, -4.3906,  3.1035,  ..., -2.9316, -2.7266,  2.3555]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 08:36:56 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more specific term for a mixer is blender
A more specific term for a shoes is sneakers
A more specific term for a collar is choker
A more specific term for a song is lullaby
A more specific term for a camera is camcorder
A more specific term for a bag is pouch
A more specific term for a dessert is cake
A more specific term for a oven is
2024-07-31 08:36:56 root INFO     [order_1_approx] starting weight calculation for A more specific term for a bag is pouch
A more specific term for a shoes is sneakers
A more specific term for a camera is camcorder
A more specific term for a oven is broiler
A more specific term for a mixer is blender
A more specific term for a song is lullaby
A more specific term for a dessert is cake
A more specific term for a collar is
2024-07-31 08:36:56 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 08:38:49 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3843, -0.3030, -0.3179,  ...,  0.1865, -0.1049,  0.0075],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.2266, -5.3750, -0.8862,  ...,  4.2031,  4.5000,  1.3936],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 9.9060e-02,  9.7275e-03,  1.9531e-02,  ...,  9.9182e-03,
          3.2440e-02, -2.0599e-02],
        [-1.9958e-02,  9.0576e-02,  1.0788e-02,  ...,  4.1199e-03,
          3.4058e-02, -2.5070e-02],
        [ 8.6212e-03, -1.9775e-02,  9.4727e-02,  ...,  1.2589e-04,
         -3.3447e-02,  5.7831e-03],
        ...,
        [-1.6190e-02,  1.5686e-02,  4.7684e-03,  ...,  1.0303e-01,
         -2.3666e-02,  4.5929e-03],
        [-8.6288e-03, -1.0071e-02, -5.6839e-03,  ..., -9.7580e-03,
          1.3989e-01, -9.2087e-03],
        [-1.1292e-02,  3.4790e-02,  3.3951e-04,  ..., -3.6255e-02,
         -7.5455e-03,  8.4839e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.3535, -5.4180, -1.0010,  ...,  4.4648,  4.3125,  1.2217]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 08:38:50 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more specific term for a bag is pouch
A more specific term for a shoes is sneakers
A more specific term for a camera is camcorder
A more specific term for a oven is broiler
A more specific term for a mixer is blender
A more specific term for a song is lullaby
A more specific term for a dessert is cake
A more specific term for a collar is
2024-07-31 08:38:50 root INFO     [order_1_approx] starting weight calculation for A more specific term for a song is lullaby
A more specific term for a shoes is sneakers
A more specific term for a collar is choker
A more specific term for a camera is camcorder
A more specific term for a oven is broiler
A more specific term for a dessert is cake
A more specific term for a mixer is blender
A more specific term for a bag is
2024-07-31 08:38:50 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 08:40:44 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3206,  0.0412, -0.2068,  ...,  0.3884, -0.5337, -0.6816],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 5.4062, -4.0273, -3.3125,  ...,  0.6572,  1.9326,  1.4248],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0818,  0.0013, -0.0149,  ...,  0.0206, -0.0116,  0.0105],
        [-0.0256,  0.0786,  0.0022,  ..., -0.0169,  0.0045, -0.0221],
        [ 0.0324, -0.0002,  0.0797,  ...,  0.0340, -0.0091,  0.0006],
        ...,
        [-0.0016,  0.0045, -0.0276,  ...,  0.0703, -0.0233, -0.0212],
        [-0.0228,  0.0015, -0.0081,  ..., -0.0112,  0.0784,  0.0027],
        [-0.0238, -0.0020, -0.0111,  ..., -0.0189, -0.0037,  0.0860]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 5.6484, -4.1523, -3.2793,  ...,  0.7681,  1.9482,  1.0342]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 08:40:45 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more specific term for a song is lullaby
A more specific term for a shoes is sneakers
A more specific term for a collar is choker
A more specific term for a camera is camcorder
A more specific term for a oven is broiler
A more specific term for a dessert is cake
A more specific term for a mixer is blender
A more specific term for a bag is
2024-07-31 08:40:45 root INFO     [order_1_approx] starting weight calculation for A more specific term for a collar is choker
A more specific term for a mixer is blender
A more specific term for a camera is camcorder
A more specific term for a bag is pouch
A more specific term for a song is lullaby
A more specific term for a oven is broiler
A more specific term for a shoes is sneakers
A more specific term for a dessert is
2024-07-31 08:40:46 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 08:42:44 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1854, -0.2423,  0.3022,  ..., -0.2363, -0.8301, -0.5894],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([  3.0703, -11.4297,  -0.1450,  ...,  -1.0195,  -0.3789,   2.5156],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0558, -0.0043,  0.0110,  ...,  0.0100, -0.0086,  0.0013],
        [ 0.0052,  0.0507,  0.0169,  ..., -0.0112,  0.0075, -0.0119],
        [-0.0134, -0.0132,  0.0453,  ...,  0.0063, -0.0109,  0.0006],
        ...,
        [ 0.0014, -0.0049, -0.0107,  ...,  0.0459,  0.0005, -0.0047],
        [-0.0068,  0.0043, -0.0036,  ..., -0.0121,  0.0437,  0.0015],
        [ 0.0058,  0.0047,  0.0008,  ..., -0.0150,  0.0177,  0.0463]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[  2.8926, -11.4922,  -0.0752,  ...,  -0.8652,  -0.3301,   2.6055]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 08:42:44 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more specific term for a collar is choker
A more specific term for a mixer is blender
A more specific term for a camera is camcorder
A more specific term for a bag is pouch
A more specific term for a song is lullaby
A more specific term for a oven is broiler
A more specific term for a shoes is sneakers
A more specific term for a dessert is
2024-07-31 08:42:45 root INFO     [order_1_approx] starting weight calculation for A more specific term for a dessert is cake
A more specific term for a collar is choker
A more specific term for a oven is broiler
A more specific term for a shoes is sneakers
A more specific term for a song is lullaby
A more specific term for a camera is camcorder
A more specific term for a bag is pouch
A more specific term for a mixer is
2024-07-31 08:42:45 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 08:44:42 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0320,  0.4229, -0.2666,  ...,  0.8569, -0.4351,  0.0284],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.4900, -4.8008, -2.0195,  ...,  0.2964, -3.0371,  0.4277],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.1155, -0.0039, -0.0041,  ...,  0.0073, -0.0273, -0.0112],
        [ 0.0106,  0.1055,  0.0208,  ...,  0.0032,  0.0128, -0.0042],
        [ 0.0057, -0.0014,  0.0991,  ...,  0.0016, -0.0027,  0.0194],
        ...,
        [-0.0008,  0.0154, -0.0243,  ...,  0.1287, -0.0140,  0.0160],
        [-0.0377, -0.0243, -0.0087,  ...,  0.0034,  0.1338, -0.0173],
        [ 0.0124,  0.0222,  0.0022,  ..., -0.0157, -0.0139,  0.0958]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.1582, -5.1172, -1.7256,  ...,  0.3689, -2.4883,  0.2067]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 08:44:43 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more specific term for a dessert is cake
A more specific term for a collar is choker
A more specific term for a oven is broiler
A more specific term for a shoes is sneakers
A more specific term for a song is lullaby
A more specific term for a camera is camcorder
A more specific term for a bag is pouch
A more specific term for a mixer is
2024-07-31 08:44:43 root INFO     [order_1_approx] starting weight calculation for A more specific term for a mixer is blender
A more specific term for a oven is broiler
A more specific term for a bag is pouch
A more specific term for a camera is camcorder
A more specific term for a collar is choker
A more specific term for a shoes is sneakers
A more specific term for a dessert is cake
A more specific term for a song is
2024-07-31 08:44:43 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 08:46:35 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1501,  0.0721,  0.2047,  ...,  0.1946, -0.3286, -0.6436],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.5449e+00, -8.4219e+00,  2.5977e+00,  ...,  1.5137e-01,
        -1.3066e+00, -9.7656e-04], device='cuda:1', dtype=torch.float16,
       grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0781,  0.0036,  0.0163,  ...,  0.0183, -0.0079,  0.0100],
        [ 0.0049,  0.0858,  0.0054,  ...,  0.0108,  0.0265, -0.0218],
        [-0.0059, -0.0049,  0.1060,  ..., -0.0032, -0.0075,  0.0219],
        ...,
        [ 0.0101,  0.0179, -0.0184,  ...,  0.0931, -0.0142,  0.0018],
        [-0.0206,  0.0109, -0.0084,  ...,  0.0068,  0.0812, -0.0084],
        [ 0.0153, -0.0040, -0.0254,  ..., -0.0124,  0.0047,  0.0717]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.4570, -8.0000,  2.3418,  ..., -0.0948, -1.3926,  0.3311]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 08:46:36 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more specific term for a mixer is blender
A more specific term for a oven is broiler
A more specific term for a bag is pouch
A more specific term for a camera is camcorder
A more specific term for a collar is choker
A more specific term for a shoes is sneakers
A more specific term for a dessert is cake
A more specific term for a song is
2024-07-31 08:46:36 root INFO     [order_1_approx] starting weight calculation for A more specific term for a song is lullaby
A more specific term for a oven is broiler
A more specific term for a collar is choker
A more specific term for a shoes is sneakers
A more specific term for a bag is pouch
A more specific term for a mixer is blender
A more specific term for a dessert is cake
A more specific term for a camera is
2024-07-31 08:46:36 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 08:48:35 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2629, -0.2427, -0.3296,  ..., -0.4248,  0.0365, -0.6719],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-2.1133, -3.4570, -0.0503,  ...,  0.0902,  0.6079, -2.0059],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.1105,  0.0007,  0.0068,  ...,  0.0143, -0.0373,  0.0011],
        [ 0.0033,  0.0952, -0.0055,  ...,  0.0016,  0.0199, -0.0167],
        [ 0.0019, -0.0037,  0.0878,  ..., -0.0083, -0.0016,  0.0124],
        ...,
        [ 0.0036, -0.0004, -0.0155,  ...,  0.0955,  0.0091, -0.0165],
        [-0.0184,  0.0151, -0.0038,  ..., -0.0023,  0.0754, -0.0311],
        [-0.0023,  0.0025, -0.0112,  ...,  0.0042, -0.0169,  0.0780]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.6729, -3.5879,  0.3052,  ...,  0.2258,  0.6182, -1.7607]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 08:48:36 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more specific term for a song is lullaby
A more specific term for a oven is broiler
A more specific term for a collar is choker
A more specific term for a shoes is sneakers
A more specific term for a bag is pouch
A more specific term for a mixer is blender
A more specific term for a dessert is cake
A more specific term for a camera is
2024-07-31 08:48:36 root INFO     [order_1_approx] starting weight calculation for A more specific term for a oven is broiler
A more specific term for a dessert is cake
A more specific term for a song is lullaby
A more specific term for a bag is pouch
A more specific term for a mixer is blender
A more specific term for a collar is choker
A more specific term for a camera is camcorder
A more specific term for a shoes is
2024-07-31 08:48:36 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 08:50:34 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0659, -0.4199, -0.1967,  ...,  0.4622, -0.2267, -0.3354],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 5.9844, -6.2969, -1.1270,  ...,  1.3330, -0.0098,  2.0391],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0801, -0.0080, -0.0044,  ...,  0.0014,  0.0008, -0.0103],
        [-0.0157,  0.0719,  0.0038,  ...,  0.0036, -0.0073, -0.0054],
        [-0.0068, -0.0108,  0.0602,  ..., -0.0069, -0.0206, -0.0030],
        ...,
        [-0.0051,  0.0060, -0.0060,  ...,  0.0651, -0.0094, -0.0008],
        [-0.0168,  0.0021, -0.0010,  ...,  0.0012,  0.0436, -0.0076],
        [ 0.0157,  0.0092,  0.0007,  ..., -0.0383,  0.0008,  0.0606]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 5.9883, -6.1719, -1.5986,  ...,  1.5938, -0.0389,  2.1602]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 08:50:35 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more specific term for a oven is broiler
A more specific term for a dessert is cake
A more specific term for a song is lullaby
A more specific term for a bag is pouch
A more specific term for a mixer is blender
A more specific term for a collar is choker
A more specific term for a camera is camcorder
A more specific term for a shoes is
2024-07-31 08:50:35 root INFO     total operator prediction time: 935.3658173084259 seconds
2024-07-31 08:50:35 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on hypernyms - animals
2024-07-31 08:50:35 root INFO     building operator hypernyms - animals
2024-07-31 08:50:35 root INFO     [order_1_approx] starting weight calculation for The cockroach falls into the category of insect
The fox falls into the category of canine
The cow falls into the category of bovid
The lion falls into the category of feline
The gibbon falls into the category of primate
The beetle falls into the category of insect
The porcupine falls into the category of rodent
The deer falls into the category of
2024-07-31 08:50:35 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 08:52:31 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1793, -0.2029,  0.2368,  ...,  0.4009, -0.4863,  0.2876],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.6611, -4.0352,  0.1865,  ..., -0.8208, -9.4453, -1.0488],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0284,  0.0008, -0.0064,  ..., -0.0014, -0.0062, -0.0011],
        [-0.0031,  0.0145,  0.0124,  ..., -0.0018,  0.0062, -0.0038],
        [ 0.0033,  0.0138,  0.0278,  ..., -0.0053,  0.0167, -0.0014],
        ...,
        [ 0.0029,  0.0022,  0.0005,  ...,  0.0423, -0.0051,  0.0009],
        [ 0.0005, -0.0117, -0.0084,  ..., -0.0076,  0.0453, -0.0032],
        [-0.0069,  0.0047, -0.0115,  ..., -0.0082, -0.0007,  0.0295]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.5337, -3.6875,  0.2827,  ..., -0.9404, -9.2266, -1.1758]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 08:52:32 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The cockroach falls into the category of insect
The fox falls into the category of canine
The cow falls into the category of bovid
The lion falls into the category of feline
The gibbon falls into the category of primate
The beetle falls into the category of insect
The porcupine falls into the category of rodent
The deer falls into the category of
2024-07-31 08:52:32 root INFO     [order_1_approx] starting weight calculation for The beetle falls into the category of insect
The porcupine falls into the category of rodent
The cockroach falls into the category of insect
The cow falls into the category of bovid
The lion falls into the category of feline
The deer falls into the category of bovid
The fox falls into the category of canine
The gibbon falls into the category of
2024-07-31 08:52:32 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 08:54:30 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.6748, -0.5928,  0.9482,  ...,  0.3049, -1.1045,  0.4521],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.3303, -3.5156,  1.7109,  ..., -3.5605, -6.4219,  0.7183],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0413, -0.0074, -0.0093,  ..., -0.0038, -0.0149, -0.0074],
        [-0.0034,  0.0050, -0.0125,  ...,  0.0064,  0.0145, -0.0060],
        [-0.0025,  0.0122,  0.0248,  ...,  0.0040,  0.0115, -0.0056],
        ...,
        [ 0.0148,  0.0127, -0.0113,  ...,  0.0333, -0.0072,  0.0011],
        [-0.0090, -0.0239,  0.0012,  ...,  0.0045,  0.0367, -0.0204],
        [-0.0057,  0.0019, -0.0195,  ...,  0.0103, -0.0049,  0.0244]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.2482, -3.7871,  1.6279,  ..., -3.6836, -6.5273,  0.4717]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 08:54:31 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The beetle falls into the category of insect
The porcupine falls into the category of rodent
The cockroach falls into the category of insect
The cow falls into the category of bovid
The lion falls into the category of feline
The deer falls into the category of bovid
The fox falls into the category of canine
The gibbon falls into the category of
2024-07-31 08:54:32 root INFO     [order_1_approx] starting weight calculation for The fox falls into the category of canine
The deer falls into the category of bovid
The lion falls into the category of feline
The gibbon falls into the category of primate
The cow falls into the category of bovid
The porcupine falls into the category of rodent
The cockroach falls into the category of insect
The beetle falls into the category of
2024-07-31 08:54:32 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 08:56:30 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1213, -0.2573,  0.0748,  ..., -0.1027, -0.6396, -0.4431],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.7368, -2.2969,  2.6992,  ..., -1.8652, -2.7422, -2.7598],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 4.7546e-02, -1.5211e-03, -6.5308e-03,  ..., -1.3985e-02,
         -6.4468e-04,  2.0580e-03],
        [ 6.8130e-03,  1.3504e-02,  4.7569e-03,  ...,  1.5244e-02,
          6.8855e-04, -1.7090e-02],
        [ 3.7804e-03,  3.4599e-03,  4.3457e-02,  ..., -3.7460e-03,
         -5.4398e-03,  1.9424e-02],
        ...,
        [ 1.1726e-02, -1.3351e-04, -7.2479e-03,  ...,  4.8004e-02,
          9.6741e-03,  4.5929e-03],
        [-1.3866e-03, -9.3307e-03, -4.1046e-03,  ..., -9.0599e-05,
          3.7781e-02, -1.9836e-03],
        [-1.3893e-02,  3.1586e-03, -5.0125e-03,  ..., -7.8659e-03,
         -1.1787e-02,  2.7206e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.8887, -2.5449,  2.7891,  ..., -1.9756, -2.9512, -2.6836]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 08:56:31 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The fox falls into the category of canine
The deer falls into the category of bovid
The lion falls into the category of feline
The gibbon falls into the category of primate
The cow falls into the category of bovid
The porcupine falls into the category of rodent
The cockroach falls into the category of insect
The beetle falls into the category of
2024-07-31 08:56:32 root INFO     [order_1_approx] starting weight calculation for The lion falls into the category of feline
The beetle falls into the category of insect
The gibbon falls into the category of primate
The porcupine falls into the category of rodent
The deer falls into the category of bovid
The fox falls into the category of canine
The cockroach falls into the category of insect
The cow falls into the category of
2024-07-31 08:56:32 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
2024-07-31 08:58:27 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2759, -0.4922,  0.0330,  ...,  0.4656, -0.4143, -0.1383],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.3083, -5.4844,  2.1641,  ..., -0.9819, -7.6641, -1.1133],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0338, -0.0053,  0.0034,  ..., -0.0100, -0.0124, -0.0043],
        [-0.0028,  0.0258,  0.0200,  ..., -0.0180,  0.0076, -0.0253],
        [ 0.0108,  0.0127,  0.0186,  ...,  0.0024,  0.0107,  0.0188],
        ...,
        [ 0.0061, -0.0011, -0.0006,  ...,  0.0408, -0.0015, -0.0031],
        [ 0.0024, -0.0072, -0.0116,  ..., -0.0076,  0.0374, -0.0081],
        [-0.0133,  0.0107, -0.0043,  ..., -0.0093, -0.0071,  0.0413]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.2505, -5.2344,  1.9316,  ..., -0.9004, -7.5938, -0.9160]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 08:58:28 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The lion falls into the category of feline
The beetle falls into the category of insect
The gibbon falls into the category of primate
The porcupine falls into the category of rodent
The deer falls into the category of bovid
The fox falls into the category of canine
The cockroach falls into the category of insect
The cow falls into the category of
2024-07-31 08:58:28 root INFO     [order_1_approx] starting weight calculation for The beetle falls into the category of insect
The gibbon falls into the category of primate
The fox falls into the category of canine
The lion falls into the category of feline
The cockroach falls into the category of insect
The deer falls into the category of bovid
The cow falls into the category of bovid
The porcupine falls into the category of
2024-07-31 08:58:28 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.15
