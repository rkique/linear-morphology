2024-07-30 17:15:03 root INFO     loading model + tokenizer
2024-07-30 17:17:02 root INFO     model + tokenizer loaded
2024-07-30 17:17:02 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on verb+ment_irreg
2024-07-30 17:17:02 root INFO     building operator verb+ment_irreg
2024-07-30 17:17:03 root INFO     [order_1_approx] starting weight calculation for To enhance results in a enhancement
To detach results in a detachment
To reinforce results in a reinforcement
To replace results in a replacement
To adjust results in a adjustment
To reimburse results in a reimbursement
To amend results in a amendment
To engage results in a
2024-07-30 17:17:03 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-30 17:19:10 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0107,  0.2271,  0.0183,  ...,  0.1909, -0.0610, -0.1694],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.0244, -3.0234,  1.3838,  ...,  1.0781, -0.9805, -2.9961],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0842,  0.0126, -0.0032,  ..., -0.0078,  0.0074,  0.0128],
        [-0.0076,  0.0789, -0.0007,  ...,  0.0153, -0.0022,  0.0011],
        [ 0.0078, -0.0208,  0.0599,  ..., -0.0096, -0.0113,  0.0013],
        ...,
        [-0.0003,  0.0149,  0.0070,  ...,  0.0779,  0.0022,  0.0011],
        [ 0.0012,  0.0196,  0.0093,  ...,  0.0023,  0.0739, -0.0104],
        [ 0.0131, -0.0038, -0.0111,  ..., -0.0080, -0.0210,  0.0780]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.3271, -2.7637,  1.5527,  ...,  0.9116, -1.1777, -2.9355]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 17:19:11 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To enhance results in a enhancement
To detach results in a detachment
To reinforce results in a reinforcement
To replace results in a replacement
To adjust results in a adjustment
To reimburse results in a reimbursement
To amend results in a amendment
To engage results in a
2024-07-30 17:19:11 root INFO     [order_1_approx] starting weight calculation for To adjust results in a adjustment
To detach results in a detachment
To replace results in a replacement
To engage results in a engagement
To enhance results in a enhancement
To reinforce results in a reinforcement
To reimburse results in a reimbursement
To amend results in a
2024-07-30 17:19:12 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-30 17:21:14 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3462, -0.3088, -0.6025,  ..., -0.1306, -0.4717, -0.2000],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.4844, -1.3975, -0.5000,  ...,  0.4834, -1.9941, -1.4307],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0837,  0.0011, -0.0041,  ..., -0.0077,  0.0024,  0.0036],
        [ 0.0068,  0.0744,  0.0122,  ...,  0.0188, -0.0109,  0.0115],
        [-0.0006, -0.0064,  0.0519,  ..., -0.0071, -0.0008, -0.0092],
        ...,
        [ 0.0113,  0.0084,  0.0009,  ...,  0.0956, -0.0038, -0.0058],
        [-0.0062,  0.0040, -0.0103,  ...,  0.0088,  0.0671, -0.0144],
        [ 0.0130, -0.0120,  0.0079,  ...,  0.0017, -0.0168,  0.0917]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.4141, -1.1914, -0.3486,  ...,  0.7090, -1.9033, -1.7246]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 17:21:15 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To adjust results in a adjustment
To detach results in a detachment
To replace results in a replacement
To engage results in a engagement
To enhance results in a enhancement
To reinforce results in a reinforcement
To reimburse results in a reimbursement
To amend results in a
2024-07-30 17:21:15 root INFO     [order_1_approx] starting weight calculation for To engage results in a engagement
To reimburse results in a reimbursement
To enhance results in a enhancement
To amend results in a amendment
To replace results in a replacement
To detach results in a detachment
To reinforce results in a reinforcement
To adjust results in a
2024-07-30 17:21:15 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-30 17:23:20 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1812,  0.0027, -0.4150,  ...,  0.0361, -0.0614, -0.4270],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.2891, -2.1016, -0.7471,  ...,  1.9209, -2.3438, -1.7168],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0620,  0.0156,  0.0041,  ..., -0.0058,  0.0115,  0.0089],
        [ 0.0130,  0.0550,  0.0079,  ...,  0.0307,  0.0013,  0.0181],
        [-0.0033, -0.0017,  0.0329,  ..., -0.0026,  0.0015, -0.0244],
        ...,
        [ 0.0167,  0.0122,  0.0039,  ...,  0.0743, -0.0035,  0.0030],
        [-0.0200,  0.0117,  0.0143,  ..., -0.0126,  0.0522, -0.0385],
        [ 0.0175,  0.0026,  0.0032,  ..., -0.0082, -0.0195,  0.0548]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.8125, -1.5928, -0.5630,  ...,  2.0605, -2.4785, -1.8438]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 17:23:21 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To engage results in a engagement
To reimburse results in a reimbursement
To enhance results in a enhancement
To amend results in a amendment
To replace results in a replacement
To detach results in a detachment
To reinforce results in a reinforcement
To adjust results in a
2024-07-30 17:23:21 root INFO     [order_1_approx] starting weight calculation for To engage results in a engagement
To reinforce results in a reinforcement
To detach results in a detachment
To adjust results in a adjustment
To amend results in a amendment
To enhance results in a enhancement
To replace results in a replacement
To reimburse results in a
2024-07-30 17:23:21 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-30 17:25:27 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0085, -0.2739, -0.4895,  ...,  0.0950,  0.0167,  0.0056],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.8477, -2.3340, -0.6494,  ..., -0.3628, -0.4727, -2.2402],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0668,  0.0026,  0.0092,  ..., -0.0049,  0.0021,  0.0101],
        [-0.0034,  0.0634,  0.0005,  ...,  0.0127,  0.0068,  0.0092],
        [-0.0006,  0.0072,  0.0506,  ..., -0.0160,  0.0019, -0.0170],
        ...,
        [-0.0066,  0.0079, -0.0073,  ...,  0.0765,  0.0018,  0.0023],
        [ 0.0032, -0.0003,  0.0066,  ...,  0.0058,  0.0661, -0.0264],
        [-0.0061, -0.0128, -0.0102,  ...,  0.0024, -0.0136,  0.0731]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.6982, -2.0449, -0.8516,  ..., -0.2529, -0.2537, -2.3887]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 17:25:28 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To engage results in a engagement
To reinforce results in a reinforcement
To detach results in a detachment
To adjust results in a adjustment
To amend results in a amendment
To enhance results in a enhancement
To replace results in a replacement
To reimburse results in a
2024-07-30 17:25:29 root INFO     [order_1_approx] starting weight calculation for To reimburse results in a reimbursement
To engage results in a engagement
To adjust results in a adjustment
To reinforce results in a reinforcement
To replace results in a replacement
To amend results in a amendment
To enhance results in a enhancement
To detach results in a
2024-07-30 17:25:29 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-30 17:27:35 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.5200, -0.0948, -0.1207,  ...,  0.2007,  0.0240, -0.2925],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.0781, -2.9668,  0.4507,  ...,  2.4531, -1.7676, -1.6250],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0587,  0.0189, -0.0105,  ..., -0.0111,  0.0089, -0.0113],
        [ 0.0211,  0.0723,  0.0074,  ...,  0.0402,  0.0108,  0.0229],
        [-0.0032, -0.0091,  0.0623,  ..., -0.0080, -0.0060, -0.0185],
        ...,
        [ 0.0104,  0.0175,  0.0029,  ...,  0.0962,  0.0094,  0.0200],
        [-0.0027, -0.0080, -0.0003,  ...,  0.0025,  0.0735, -0.0148],
        [ 0.0071,  0.0098,  0.0006,  ..., -0.0066, -0.0196,  0.1043]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.2354, -3.0020,  0.5615,  ...,  2.0156, -1.8496, -1.6641]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 17:27:36 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To reimburse results in a reimbursement
To engage results in a engagement
To adjust results in a adjustment
To reinforce results in a reinforcement
To replace results in a replacement
To amend results in a amendment
To enhance results in a enhancement
To detach results in a
2024-07-30 17:27:36 root INFO     [order_1_approx] starting weight calculation for To detach results in a detachment
To adjust results in a adjustment
To engage results in a engagement
To reinforce results in a reinforcement
To replace results in a replacement
To reimburse results in a reimbursement
To amend results in a amendment
To enhance results in a
2024-07-30 17:27:36 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-30 17:29:42 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2881, -0.6323,  0.1196,  ...,  0.0547, -0.1973, -0.2629],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.8584, -0.5107,  0.1987,  ...,  2.7168, -4.3867, -2.0703],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0699,  0.0115, -0.0035,  ..., -0.0106,  0.0059,  0.0005],
        [-0.0021,  0.0606,  0.0057,  ...,  0.0201,  0.0056, -0.0026],
        [-0.0026, -0.0146,  0.0377,  ..., -0.0015, -0.0020, -0.0115],
        ...,
        [-0.0044,  0.0029,  0.0023,  ...,  0.0640,  0.0091,  0.0020],
        [-0.0101,  0.0046,  0.0039,  ...,  0.0083,  0.0653, -0.0125],
        [-0.0053, -0.0146, -0.0008,  ..., -0.0150, -0.0152,  0.0537]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.4258, -0.4937,  0.3208,  ...,  2.7285, -4.3398, -2.2656]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 17:29:43 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To detach results in a detachment
To adjust results in a adjustment
To engage results in a engagement
To reinforce results in a reinforcement
To replace results in a replacement
To reimburse results in a reimbursement
To amend results in a amendment
To enhance results in a
2024-07-30 17:29:43 root INFO     [order_1_approx] starting weight calculation for To engage results in a engagement
To reimburse results in a reimbursement
To enhance results in a enhancement
To adjust results in a adjustment
To detach results in a detachment
To amend results in a amendment
To reinforce results in a reinforcement
To replace results in a
2024-07-30 17:29:43 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-30 17:31:48 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0580,  0.0236, -0.3831,  ...,  0.4163,  0.0250, -0.1619],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.0020, -3.5762, -0.6460,  ...,  2.6738, -0.4744, -0.0342],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0832, -0.0001,  0.0021,  ...,  0.0048, -0.0018,  0.0149],
        [-0.0065,  0.0598, -0.0150,  ...,  0.0391,  0.0121,  0.0103],
        [ 0.0139, -0.0098,  0.0267,  ..., -0.0145,  0.0055, -0.0215],
        ...,
        [ 0.0016,  0.0216, -0.0067,  ...,  0.0854, -0.0015,  0.0116],
        [-0.0079,  0.0246,  0.0017,  ..., -0.0162,  0.0619, -0.0162],
        [ 0.0067, -0.0011,  0.0085,  ..., -0.0095, -0.0307,  0.0973]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.9956, -2.9961, -0.1619,  ...,  2.3730, -0.6558, -0.4629]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 17:31:49 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To engage results in a engagement
To reimburse results in a reimbursement
To enhance results in a enhancement
To adjust results in a adjustment
To detach results in a detachment
To amend results in a amendment
To reinforce results in a reinforcement
To replace results in a
2024-07-30 17:31:49 root INFO     [order_1_approx] starting weight calculation for To engage results in a engagement
To enhance results in a enhancement
To amend results in a amendment
To detach results in a detachment
To replace results in a replacement
To adjust results in a adjustment
To reimburse results in a reimbursement
To reinforce results in a
2024-07-30 17:31:49 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-30 17:33:56 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1351, -0.2583, -0.0953,  ...,  0.1139, -0.2156, -0.0422],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.0977, -2.7363,  2.6816,  ...,  3.7070, -2.1250, -3.1055],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.1034, -0.0093,  0.0008,  ..., -0.0113,  0.0058,  0.0158],
        [-0.0118,  0.0997, -0.0027,  ...,  0.0163,  0.0157, -0.0107],
        [ 0.0008, -0.0130,  0.0707,  ..., -0.0185, -0.0044, -0.0111],
        ...,
        [-0.0103,  0.0135,  0.0057,  ...,  0.1025, -0.0042, -0.0045],
        [-0.0087,  0.0118,  0.0040,  ..., -0.0009,  0.0901, -0.0177],
        [-0.0101, -0.0072, -0.0034,  ..., -0.0027, -0.0254,  0.0743]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.1250, -2.5703,  2.6543,  ...,  3.1270, -1.9561, -3.1133]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 17:33:57 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To engage results in a engagement
To enhance results in a enhancement
To amend results in a amendment
To detach results in a detachment
To replace results in a replacement
To adjust results in a adjustment
To reimburse results in a reimbursement
To reinforce results in a
2024-07-30 17:33:57 root INFO     total operator prediction time: 1015.3912868499756 seconds
2024-07-30 17:33:57 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on noun+less_reg
2024-07-30 17:33:57 root INFO     building operator noun+less_reg
2024-07-30 17:33:57 root INFO     [order_1_approx] starting weight calculation for Something without talent is talentless
Something without luck is luckless
Something without speech is speechless
Something without arm is armless
Something without ego is egoless
Something without friction is frictionless
Something without mirth is mirthless
Something without odor is
2024-07-30 17:33:57 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-30 17:36:01 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3252, -0.5918, -0.1088,  ..., -0.9497,  0.0506, -0.2090],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.7568, -4.0547, -1.6152,  ..., -4.5000, -6.6992, -0.9668],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 3.7994e-02, -2.5101e-03,  4.4746e-03,  ..., -7.4005e-03,
         -2.0084e-03,  1.0498e-02],
        [ 1.4038e-02,  2.5681e-02, -1.6739e-02,  ..., -5.3329e-03,
          1.2489e-02, -2.0599e-03],
        [ 2.2736e-02,  7.2479e-04,  4.2297e-02,  ...,  1.4793e-02,
         -1.4374e-02,  3.7479e-03],
        ...,
        [ 7.6370e-03,  8.4152e-03,  3.4332e-04,  ...,  3.1677e-02,
          7.6828e-03,  4.7684e-05],
        [ 1.6403e-02,  2.8744e-03,  7.1564e-03,  ..., -2.2980e-02,
          4.2847e-02, -1.0292e-02],
        [ 1.5579e-02, -1.2421e-02,  3.3569e-03,  ...,  1.7395e-02,
         -2.2369e-02,  2.7145e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.7041, -4.0000, -1.7100,  ..., -4.2031, -6.4609, -0.7944]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 17:36:02 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Something without talent is talentless
Something without luck is luckless
Something without speech is speechless
Something without arm is armless
Something without ego is egoless
Something without friction is frictionless
Something without mirth is mirthless
Something without odor is
2024-07-30 17:36:03 root INFO     [order_1_approx] starting weight calculation for Something without odor is odorless
Something without luck is luckless
Something without friction is frictionless
Something without arm is armless
Something without ego is egoless
Something without mirth is mirthless
Something without speech is speechless
Something without talent is
2024-07-30 17:36:03 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-30 17:38:08 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.6226, -0.5273,  0.1155,  ..., -0.6152,  0.2432, -0.1256],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.6426, -1.1377,  0.6514,  ..., -3.5703, -4.6680, -1.8184],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0279, -0.0094,  0.0139,  ..., -0.0084,  0.0175,  0.0157],
        [ 0.0095,  0.0530, -0.0101,  ...,  0.0159,  0.0057,  0.0088],
        [ 0.0050, -0.0053,  0.0267,  ...,  0.0190, -0.0030, -0.0037],
        ...,
        [ 0.0023,  0.0276,  0.0035,  ...,  0.0250,  0.0029,  0.0039],
        [-0.0072,  0.0166,  0.0280,  ..., -0.0022,  0.0267, -0.0233],
        [ 0.0414, -0.0115, -0.0044,  ...,  0.0005, -0.0099,  0.0413]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.4043, -0.9961,  0.5498,  ..., -3.2246, -4.5820, -1.4316]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 17:38:09 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Something without odor is odorless
Something without luck is luckless
Something without friction is frictionless
Something without arm is armless
Something without ego is egoless
Something without mirth is mirthless
Something without speech is speechless
Something without talent is
2024-07-30 17:38:09 root INFO     [order_1_approx] starting weight calculation for Something without odor is odorless
Something without friction is frictionless
Something without talent is talentless
Something without luck is luckless
Something without arm is armless
Something without speech is speechless
Something without ego is egoless
Something without mirth is
2024-07-30 17:38:09 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-30 17:40:11 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2129,  0.0714,  0.6934,  ...,  0.1711, -0.6968,  0.0171],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.0439, -2.3164, -1.1543,  ..., -1.8516, -4.3828, -2.1406],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0392, -0.0111, -0.0069,  ..., -0.0144,  0.0144,  0.0078],
        [ 0.0146,  0.0301,  0.0009,  ...,  0.0201, -0.0068,  0.0176],
        [ 0.0188, -0.0110,  0.0569,  ...,  0.0173,  0.0063, -0.0167],
        ...,
        [ 0.0139,  0.0247,  0.0099,  ...,  0.0325,  0.0144,  0.0050],
        [-0.0011, -0.0052,  0.0026,  ..., -0.0150,  0.0457, -0.0390],
        [ 0.0316, -0.0110,  0.0109,  ...,  0.0214, -0.0030,  0.0350]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.0742, -2.1875, -1.7090,  ..., -1.7656, -4.3047, -2.5469]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 17:40:12 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Something without odor is odorless
Something without friction is frictionless
Something without talent is talentless
Something without luck is luckless
Something without arm is armless
Something without speech is speechless
Something without ego is egoless
Something without mirth is
2024-07-30 17:40:12 root INFO     [order_1_approx] starting weight calculation for Something without talent is talentless
Something without arm is armless
Something without speech is speechless
Something without mirth is mirthless
Something without odor is odorless
Something without friction is frictionless
Something without luck is luckless
Something without ego is
2024-07-30 17:40:12 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-30 17:42:16 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2859, -0.3005, -0.1671,  ...,  0.2729, -0.0283,  0.0712],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.3242, -2.9844,  0.4790,  ..., -3.5430, -3.5234, -3.7383],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0430, -0.0173, -0.0065,  ..., -0.0080, -0.0126,  0.0096],
        [-0.0064,  0.0612, -0.0115,  ...,  0.0174, -0.0007,  0.0132],
        [ 0.0224,  0.0162,  0.0495,  ...,  0.0074,  0.0168,  0.0287],
        ...,
        [-0.0057,  0.0178, -0.0041,  ...,  0.0602,  0.0236, -0.0048],
        [-0.0075,  0.0021,  0.0148,  ..., -0.0195,  0.0670,  0.0012],
        [ 0.0246, -0.0066,  0.0006,  ...,  0.0265, -0.0262,  0.0719]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.8882, -2.5410,  0.1409,  ..., -2.7715, -3.5996, -3.7227]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 17:42:17 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Something without talent is talentless
Something without arm is armless
Something without speech is speechless
Something without mirth is mirthless
Something without odor is odorless
Something without friction is frictionless
Something without luck is luckless
Something without ego is
2024-07-30 17:42:17 root INFO     [order_1_approx] starting weight calculation for Something without arm is armless
Something without ego is egoless
Something without talent is talentless
Something without friction is frictionless
Something without odor is odorless
Something without mirth is mirthless
Something without luck is luckless
Something without speech is
2024-07-30 17:42:17 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-30 17:44:21 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1687, -0.3857,  0.2554,  ...,  0.2208,  0.3657,  0.1094],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.6895, -3.1680,  0.3108,  ..., -0.1001, -1.6982,  0.0078],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 3.3051e-02,  6.3400e-03, -1.2077e-02,  ...,  7.9498e-03,
          2.7405e-02,  1.7853e-02],
        [ 9.0885e-04,  4.7424e-02,  1.3550e-02,  ...,  6.2704e-04,
         -1.3762e-03,  1.4359e-02],
        [ 1.4969e-02, -2.3590e-02,  2.1774e-02,  ...,  8.5449e-03,
         -1.5900e-02,  6.5041e-03],
        ...,
        [-8.2245e-03,  1.6144e-02,  1.3794e-02,  ...,  2.1347e-02,
         -1.1795e-02, -4.0131e-03],
        [-7.9956e-03, -2.2888e-05,  1.6928e-03,  ..., -2.1530e-02,
          2.7710e-02, -1.7014e-02],
        [ 1.0056e-02,  1.1253e-03,  1.3008e-02,  ..., -6.7291e-03,
         -4.8294e-03,  2.8595e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.3530, -3.1719, -0.1143,  ..., -0.1871, -1.8672, -0.1052]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 17:44:22 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Something without arm is armless
Something without ego is egoless
Something without talent is talentless
Something without friction is frictionless
Something without odor is odorless
Something without mirth is mirthless
Something without luck is luckless
Something without speech is
2024-07-30 17:44:22 root INFO     [order_1_approx] starting weight calculation for Something without odor is odorless
Something without mirth is mirthless
Something without ego is egoless
Something without friction is frictionless
Something without talent is talentless
Something without speech is speechless
Something without luck is luckless
Something without arm is
2024-07-30 17:44:22 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-30 17:46:27 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2827, -0.4431,  0.4087,  ..., -0.4866, -0.2020, -0.3074],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.5649, -4.6484, -1.0166,  ..., -0.2186, -3.3594, -2.7793],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0284, -0.0179, -0.0127,  ..., -0.0042, -0.0017, -0.0006],
        [ 0.0027,  0.0338, -0.0064,  ..., -0.0169,  0.0207, -0.0016],
        [ 0.0125,  0.0056,  0.0131,  ..., -0.0006,  0.0028,  0.0047],
        ...,
        [-0.0126,  0.0299,  0.0065,  ...,  0.0322,  0.0186, -0.0079],
        [-0.0042, -0.0140,  0.0032,  ...,  0.0098,  0.0087, -0.0164],
        [ 0.0097,  0.0101,  0.0171,  ...,  0.0100, -0.0004,  0.0248]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.5269, -4.2031, -1.0674,  ...,  0.1520, -3.5586, -2.9570]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 17:46:28 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Something without odor is odorless
Something without mirth is mirthless
Something without ego is egoless
Something without friction is frictionless
Something without talent is talentless
Something without speech is speechless
Something without luck is luckless
Something without arm is
2024-07-30 17:46:28 root INFO     [order_1_approx] starting weight calculation for Something without mirth is mirthless
Something without talent is talentless
Something without speech is speechless
Something without friction is frictionless
Something without arm is armless
Something without odor is odorless
Something without ego is egoless
Something without luck is
2024-07-30 17:46:28 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-30 17:48:28 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0395,  0.6587,  0.3262,  ...,  0.0029, -0.0037,  0.1747],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.1030, -3.2051, -0.5137,  ..., -1.8438, -1.4375, -1.7207],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0293, -0.0055,  0.0142,  ...,  0.0117,  0.0129,  0.0172],
        [ 0.0141,  0.0362, -0.0131,  ..., -0.0021, -0.0072,  0.0107],
        [ 0.0207,  0.0011,  0.0328,  ..., -0.0078, -0.0004,  0.0034],
        ...,
        [ 0.0028,  0.0097, -0.0021,  ...,  0.0333, -0.0010, -0.0132],
        [ 0.0021,  0.0099,  0.0237,  ...,  0.0027,  0.0479, -0.0219],
        [ 0.0151, -0.0106, -0.0061,  ..., -0.0034, -0.0192,  0.0261]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.6162, -2.8730, -0.6030,  ..., -1.6123, -1.5498, -1.6172]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 17:48:30 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Something without mirth is mirthless
Something without talent is talentless
Something without speech is speechless
Something without friction is frictionless
Something without arm is armless
Something without odor is odorless
Something without ego is egoless
Something without luck is
2024-07-30 17:48:30 root INFO     [order_1_approx] starting weight calculation for Something without ego is egoless
Something without odor is odorless
Something without arm is armless
Something without mirth is mirthless
Something without speech is speechless
Something without luck is luckless
Something without talent is talentless
Something without friction is
2024-07-30 17:48:30 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-30 17:50:37 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4023, -0.3345, -0.5684,  ...,  0.0869,  0.4941, -0.1760],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.2266, -0.9688,  1.5215,  ..., -2.0391, -3.2266, -0.0723],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0526, -0.0058,  0.0153,  ..., -0.0008,  0.0174, -0.0061],
        [-0.0098,  0.0565,  0.0038,  ...,  0.0010,  0.0017,  0.0038],
        [ 0.0067,  0.0070,  0.0255,  ..., -0.0106, -0.0164,  0.0030],
        ...,
        [-0.0032,  0.0178,  0.0072,  ...,  0.0633,  0.0049, -0.0044],
        [-0.0029,  0.0102, -0.0026,  ..., -0.0124,  0.0688, -0.0022],
        [ 0.0120,  0.0297, -0.0074,  ..., -0.0029, -0.0036,  0.0463]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.0977, -1.3457,  1.5527,  ..., -1.9248, -2.9512, -0.1254]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 17:50:42 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Something without ego is egoless
Something without odor is odorless
Something without arm is armless
Something without mirth is mirthless
Something without speech is speechless
Something without luck is luckless
Something without talent is talentless
Something without friction is
2024-07-30 17:50:42 root INFO     total operator prediction time: 1004.614926815033 seconds
2024-07-30 17:50:42 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on adj+ness_reg
2024-07-30 17:50:42 root INFO     building operator adj+ness_reg
2024-07-30 17:50:43 root INFO     [order_1_approx] starting weight calculation for The state of being hot is hotness
The state of being pure is pureness
The state of being same is sameness
The state of being broken is brokenness
The state of being directed is directedness
The state of being distinct is distinctness
The state of being devoted is devotedness
The state of being nice is
2024-07-30 17:50:43 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-30 17:52:46 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0770, -0.3965,  0.0635,  ..., -0.1069,  0.2888, -0.5688],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.7734, -1.2900, -3.7812,  ..., -2.0059, -7.1484, -2.1289],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0637, -0.0040, -0.0074,  ..., -0.0021, -0.0025,  0.0139],
        [ 0.0008,  0.0504,  0.0059,  ...,  0.0181,  0.0172,  0.0035],
        [ 0.0061, -0.0083,  0.0366,  ..., -0.0088, -0.0040,  0.0065],
        ...,
        [ 0.0109,  0.0087,  0.0040,  ...,  0.0464,  0.0113, -0.0021],
        [ 0.0007,  0.0107,  0.0213,  ...,  0.0152,  0.0395, -0.0211],
        [ 0.0001, -0.0036, -0.0040,  ...,  0.0027, -0.0240,  0.0519]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.1797, -1.3984, -4.0078,  ..., -1.9268, -7.1250, -1.7676]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 17:52:47 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The state of being hot is hotness
The state of being pure is pureness
The state of being same is sameness
The state of being broken is brokenness
The state of being directed is directedness
The state of being distinct is distinctness
The state of being devoted is devotedness
The state of being nice is
2024-07-30 17:52:47 root INFO     [order_1_approx] starting weight calculation for The state of being distinct is distinctness
The state of being directed is directedness
The state of being devoted is devotedness
The state of being same is sameness
The state of being pure is pureness
The state of being nice is niceness
The state of being broken is brokenness
The state of being hot is
2024-07-30 17:52:47 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-30 17:54:52 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.3025, -0.1135,  0.1599,  ...,  0.0941, -0.0587, -0.2590],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.7793, -2.2695, -1.5225,  ..., -3.4805, -5.9453, -0.4141],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0518,  0.0085,  0.0014,  ..., -0.0175, -0.0022,  0.0137],
        [ 0.0254,  0.0486,  0.0110,  ..., -0.0015,  0.0025,  0.0013],
        [-0.0034, -0.0026,  0.0388,  ...,  0.0027, -0.0010,  0.0012],
        ...,
        [ 0.0061,  0.0104,  0.0196,  ...,  0.0334, -0.0108, -0.0052],
        [ 0.0086,  0.0171, -0.0252,  ...,  0.0024,  0.0670, -0.0090],
        [-0.0037, -0.0048,  0.0072,  ...,  0.0024, -0.0069,  0.0490]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.4814, -2.1797, -1.9131,  ..., -3.0586, -5.9805, -0.1975]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 17:54:53 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The state of being distinct is distinctness
The state of being directed is directedness
The state of being devoted is devotedness
The state of being same is sameness
The state of being pure is pureness
The state of being nice is niceness
The state of being broken is brokenness
The state of being hot is
2024-07-30 17:54:53 root INFO     [order_1_approx] starting weight calculation for The state of being hot is hotness
The state of being distinct is distinctness
The state of being same is sameness
The state of being nice is niceness
The state of being directed is directedness
The state of being broken is brokenness
The state of being pure is pureness
The state of being devoted is
2024-07-30 17:54:53 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-30 17:56:59 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3521,  0.3521, -0.0190,  ...,  0.0815, -0.6807,  0.3508],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.1191, -4.0977, -0.7505,  ..., -1.9102, -2.6484, -2.1719],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0493, -0.0048, -0.0088,  ...,  0.0173,  0.0102, -0.0043],
        [ 0.0162,  0.0662, -0.0012,  ...,  0.0200,  0.0104, -0.0025],
        [-0.0003, -0.0179,  0.0373,  ..., -0.0042, -0.0063, -0.0085],
        ...,
        [ 0.0225,  0.0137,  0.0076,  ...,  0.0487, -0.0044,  0.0132],
        [-0.0026, -0.0020,  0.0152,  ...,  0.0031,  0.0397, -0.0163],
        [ 0.0299,  0.0104, -0.0040,  ..., -0.0077, -0.0197,  0.0640]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.0469, -3.4004, -0.8379,  ..., -1.6006, -2.7598, -1.6025]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 17:57:00 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The state of being hot is hotness
The state of being distinct is distinctness
The state of being same is sameness
The state of being nice is niceness
The state of being directed is directedness
The state of being broken is brokenness
The state of being pure is pureness
The state of being devoted is
2024-07-30 17:57:00 root INFO     [order_1_approx] starting weight calculation for The state of being broken is brokenness
The state of being same is sameness
The state of being pure is pureness
The state of being distinct is distinctness
The state of being nice is niceness
The state of being hot is hotness
The state of being devoted is devotedness
The state of being directed is
2024-07-30 17:57:00 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-30 17:59:05 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.3706, -0.0266, -0.3433,  ...,  0.0818, -0.0732,  0.1837],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.6914, -3.6719, -0.9121,  ...,  0.3777, -2.4785, -4.4375],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0594,  0.0121, -0.0205,  ...,  0.0071,  0.0017,  0.0177],
        [-0.0121,  0.0562,  0.0152,  ...,  0.0137,  0.0080, -0.0177],
        [ 0.0046, -0.0106,  0.0364,  ..., -0.0168, -0.0227,  0.0002],
        ...,
        [ 0.0057,  0.0144,  0.0130,  ...,  0.0441,  0.0071,  0.0030],
        [-0.0108,  0.0153,  0.0105,  ..., -0.0114,  0.0271, -0.0154],
        [ 0.0149, -0.0009,  0.0043,  ...,  0.0021, -0.0232,  0.0453]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.1836, -3.7930, -1.0303,  ...,  0.2357, -2.8691, -3.8379]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 17:59:06 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The state of being broken is brokenness
The state of being same is sameness
The state of being pure is pureness
The state of being distinct is distinctness
The state of being nice is niceness
The state of being hot is hotness
The state of being devoted is devotedness
The state of being directed is
2024-07-30 17:59:06 root INFO     [order_1_approx] starting weight calculation for The state of being devoted is devotedness
The state of being nice is niceness
The state of being distinct is distinctness
The state of being hot is hotness
The state of being same is sameness
The state of being broken is brokenness
The state of being directed is directedness
The state of being pure is
2024-07-30 17:59:07 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-30 18:01:09 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1942, -0.1526,  1.0186,  ..., -0.1848,  0.2390,  0.3318],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.3848, -1.5312, -2.7246,  ..., -2.9414, -3.2539, -2.7969],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0545, -0.0055, -0.0150,  ..., -0.0010, -0.0112,  0.0070],
        [ 0.0074,  0.0560,  0.0309,  ...,  0.0132,  0.0173, -0.0042],
        [ 0.0123, -0.0021,  0.0353,  ...,  0.0273, -0.0036,  0.0124],
        ...,
        [ 0.0113,  0.0204,  0.0161,  ...,  0.0274,  0.0017,  0.0039],
        [-0.0069,  0.0222, -0.0226,  ..., -0.0089,  0.0584, -0.0189],
        [ 0.0046,  0.0121,  0.0007,  ..., -0.0120, -0.0215,  0.0593]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.4102, -1.3203, -2.7344,  ..., -2.8242, -3.2363, -2.7266]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 18:01:09 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The state of being devoted is devotedness
The state of being nice is niceness
The state of being distinct is distinctness
The state of being hot is hotness
The state of being same is sameness
The state of being broken is brokenness
The state of being directed is directedness
The state of being pure is
2024-07-30 18:01:10 root INFO     [order_1_approx] starting weight calculation for The state of being same is sameness
The state of being pure is pureness
The state of being hot is hotness
The state of being directed is directedness
The state of being broken is brokenness
The state of being devoted is devotedness
The state of being nice is niceness
The state of being distinct is
2024-07-30 18:01:10 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-30 18:03:15 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2861, -0.0962,  0.0591,  ...,  0.4258, -0.0410,  0.1249],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.0312, -1.9707, -0.6206,  ..., -2.6816, -3.6797, -1.3721],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0455,  0.0154, -0.0111,  ...,  0.0130, -0.0015,  0.0009],
        [-0.0020,  0.0499,  0.0162,  ...,  0.0201,  0.0103,  0.0070],
        [ 0.0101, -0.0036,  0.0350,  ..., -0.0175, -0.0059,  0.0030],
        ...,
        [ 0.0103,  0.0147,  0.0099,  ...,  0.0370, -0.0145,  0.0001],
        [-0.0032, -0.0078,  0.0129,  ..., -0.0179,  0.0367, -0.0046],
        [ 0.0154,  0.0109,  0.0021,  ..., -0.0067, -0.0259,  0.0461]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.8711, -1.9336, -0.6104,  ..., -2.3184, -4.0859, -0.9805]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 18:03:16 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The state of being same is sameness
The state of being pure is pureness
The state of being hot is hotness
The state of being directed is directedness
The state of being broken is brokenness
The state of being devoted is devotedness
The state of being nice is niceness
The state of being distinct is
2024-07-30 18:03:17 root INFO     [order_1_approx] starting weight calculation for The state of being distinct is distinctness
The state of being hot is hotness
The state of being devoted is devotedness
The state of being nice is niceness
The state of being directed is directedness
The state of being pure is pureness
The state of being same is sameness
The state of being broken is
2024-07-30 18:03:17 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-30 18:05:23 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0121, -0.0004,  0.1056,  ..., -0.0437,  0.1085, -0.1902],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.2939, -4.0625, -0.8584,  ..., -1.5137,  1.3262, -0.5215],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0889,  0.0188, -0.0266,  ..., -0.0100,  0.0099,  0.0214],
        [ 0.0243,  0.0657,  0.0176,  ...,  0.0385,  0.0023,  0.0001],
        [ 0.0110, -0.0285,  0.0656,  ..., -0.0002, -0.0004, -0.0002],
        ...,
        [ 0.0067,  0.0258,  0.0144,  ...,  0.0721,  0.0014,  0.0079],
        [-0.0237,  0.0060, -0.0104,  ..., -0.0071,  0.0628, -0.0056],
        [-0.0112,  0.0181,  0.0044,  ..., -0.0098, -0.0115,  0.0577]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.6494, -3.9668, -0.4312,  ..., -1.2812,  1.1211, -0.3955]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 18:05:24 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The state of being distinct is distinctness
The state of being hot is hotness
The state of being devoted is devotedness
The state of being nice is niceness
The state of being directed is directedness
The state of being pure is pureness
The state of being same is sameness
The state of being broken is
2024-07-30 18:05:24 root INFO     [order_1_approx] starting weight calculation for The state of being pure is pureness
The state of being nice is niceness
The state of being distinct is distinctness
The state of being broken is brokenness
The state of being devoted is devotedness
The state of being hot is hotness
The state of being directed is directedness
The state of being same is
2024-07-30 18:05:24 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-30 18:07:28 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0784, -0.1494, -0.2625,  ..., -0.0400, -0.1885,  0.0623],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.5508, -3.5586, -3.2109,  ..., -4.5391, -5.7383, -0.5469],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0455,  0.0057,  0.0063,  ..., -0.0029,  0.0201,  0.0020],
        [ 0.0051,  0.0486,  0.0074,  ...,  0.0164,  0.0190,  0.0102],
        [-0.0114, -0.0061,  0.0208,  ...,  0.0007, -0.0168,  0.0079],
        ...,
        [ 0.0098,  0.0192,  0.0209,  ...,  0.0372,  0.0004,  0.0088],
        [-0.0045, -0.0055, -0.0022,  ..., -0.0071,  0.0256,  0.0043],
        [ 0.0054,  0.0089,  0.0230,  ..., -0.0041, -0.0223,  0.0486]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.3184, -3.4648, -3.0859,  ..., -3.9648, -5.6797, -0.1453]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 18:07:35 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The state of being pure is pureness
The state of being nice is niceness
The state of being distinct is distinctness
The state of being broken is brokenness
The state of being devoted is devotedness
The state of being hot is hotness
The state of being directed is directedness
The state of being same is
2024-07-30 18:07:35 root INFO     total operator prediction time: 1013.5678579807281 seconds
2024-07-30 18:07:35 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on re+verb_reg
2024-07-30 18:07:35 root INFO     building operator re+verb_reg
2024-07-30 18:07:36 root INFO     [order_1_approx] starting weight calculation for To appear again is to reappear
To develop again is to redevelop
To invest again is to reinvest
To consider again is to reconsider
To organize again is to reorganize
To write again is to rewrite
To assure again is to reassure
To calculate again is to
2024-07-30 18:07:36 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-30 18:09:40 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0706,  0.0059,  0.0269,  ..., -0.2388, -0.5815,  0.0536],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-2.1309, -0.5542,  2.3184,  ...,  1.2119, -2.1914, -1.0410],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 8.5205e-02,  6.4926e-03,  2.1515e-02,  ..., -7.9536e-04,
         -2.9736e-03,  2.2491e-02],
        [ 3.7155e-03,  5.8685e-02, -1.0483e-02,  ...,  1.9684e-02,
         -8.6880e-04, -8.8730e-03],
        [ 4.3774e-04,  7.2365e-03,  6.1981e-02,  ..., -3.7422e-03,
          1.6678e-02, -1.4526e-02],
        ...,
        [ 1.4664e-02,  4.9858e-03, -3.2749e-03,  ...,  6.8115e-02,
         -2.0508e-02,  8.7738e-05],
        [-9.0714e-03,  2.0035e-02,  8.2016e-04,  ..., -6.5765e-03,
          6.2866e-02, -2.3666e-02],
        [-9.3384e-03,  1.1795e-02,  6.0349e-03,  ..., -8.7738e-03,
         -1.9836e-02,  6.5369e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-2.1074, -0.6260,  2.2773,  ...,  1.5391, -2.3418, -0.9946]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 18:09:41 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To appear again is to reappear
To develop again is to redevelop
To invest again is to reinvest
To consider again is to reconsider
To organize again is to reorganize
To write again is to rewrite
To assure again is to reassure
To calculate again is to
2024-07-30 18:09:42 root INFO     [order_1_approx] starting weight calculation for To appear again is to reappear
To develop again is to redevelop
To organize again is to reorganize
To invest again is to reinvest
To calculate again is to recalculate
To write again is to rewrite
To assure again is to reassure
To consider again is to
2024-07-30 18:09:42 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-30 18:11:49 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1089,  0.0309,  0.0212,  ...,  0.0162, -0.3892, -0.0286],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.5479, -4.3672,  1.6094,  ...,  0.4131, -2.4180, -2.5527],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0730, -0.0096,  0.0249,  ...,  0.0060,  0.0006,  0.0285],
        [ 0.0129,  0.0426,  0.0037,  ...,  0.0186, -0.0057,  0.0009],
        [-0.0054, -0.0046,  0.0681,  ..., -0.0003,  0.0101, -0.0139],
        ...,
        [ 0.0095, -0.0096,  0.0088,  ...,  0.0931, -0.0015, -0.0071],
        [ 0.0060,  0.0299, -0.0003,  ..., -0.0246,  0.0650, -0.0168],
        [-0.0093, -0.0013,  0.0044,  ..., -0.0128, -0.0269,  0.0616]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.4382, -4.5664,  1.1719,  ...,  0.9927, -2.5566, -2.1914]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 18:11:50 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To appear again is to reappear
To develop again is to redevelop
To organize again is to reorganize
To invest again is to reinvest
To calculate again is to recalculate
To write again is to rewrite
To assure again is to reassure
To consider again is to
2024-07-30 18:11:50 root INFO     [order_1_approx] starting weight calculation for To calculate again is to recalculate
To write again is to rewrite
To invest again is to reinvest
To consider again is to reconsider
To organize again is to reorganize
To appear again is to reappear
To assure again is to reassure
To develop again is to
2024-07-30 18:11:50 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-30 18:13:59 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.5571,  0.4612, -0.3218,  ..., -0.0741, -0.1123, -0.2119],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.9766, -3.4082,  1.2305,  ...,  2.1836, -4.7188, -3.7656],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0721,  0.0033,  0.0107,  ...,  0.0031, -0.0022,  0.0285],
        [ 0.0038,  0.0805,  0.0126,  ...,  0.0126, -0.0005,  0.0135],
        [ 0.0137, -0.0129,  0.0600,  ...,  0.0016,  0.0040, -0.0222],
        ...,
        [ 0.0119, -0.0076,  0.0023,  ...,  0.0811, -0.0053,  0.0045],
        [-0.0065,  0.0035,  0.0070,  ..., -0.0069,  0.0608, -0.0111],
        [-0.0033, -0.0115, -0.0038,  ..., -0.0145, -0.0289,  0.0721]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.7500, -3.5371,  1.3643,  ...,  1.9971, -4.7656, -3.5664]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 18:14:00 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To calculate again is to recalculate
To write again is to rewrite
To invest again is to reinvest
To consider again is to reconsider
To organize again is to reorganize
To appear again is to reappear
To assure again is to reassure
To develop again is to
2024-07-30 18:14:00 root INFO     [order_1_approx] starting weight calculation for To appear again is to reappear
To organize again is to reorganize
To calculate again is to recalculate
To invest again is to reinvest
To assure again is to reassure
To consider again is to reconsider
To develop again is to redevelop
To write again is to
2024-07-30 18:14:00 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-30 18:16:07 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.3154, -0.1888,  0.2542,  ..., -0.5762, -0.3052,  0.1328],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.7212, -3.2207,  0.5498,  ...,  2.9961, -5.5781, -2.2461],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0624,  0.0050,  0.0143,  ...,  0.0092, -0.0076,  0.0185],
        [ 0.0129,  0.0596,  0.0039,  ...,  0.0082, -0.0166, -0.0013],
        [ 0.0164, -0.0163,  0.0695,  ..., -0.0014,  0.0060, -0.0116],
        ...,
        [ 0.0153, -0.0077,  0.0041,  ...,  0.0747, -0.0182,  0.0024],
        [-0.0012,  0.0106,  0.0144,  ..., -0.0145,  0.0422, -0.0113],
        [ 0.0058, -0.0031, -0.0007,  ...,  0.0047, -0.0277,  0.0602]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.7427, -3.3945,  0.5190,  ...,  2.9785, -5.7227, -2.0547]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 18:16:08 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To appear again is to reappear
To organize again is to reorganize
To calculate again is to recalculate
To invest again is to reinvest
To assure again is to reassure
To consider again is to reconsider
To develop again is to redevelop
To write again is to
2024-07-30 18:16:08 root INFO     [order_1_approx] starting weight calculation for To calculate again is to recalculate
To organize again is to reorganize
To consider again is to reconsider
To invest again is to reinvest
To appear again is to reappear
To develop again is to redevelop
To write again is to rewrite
To assure again is to
2024-07-30 18:16:08 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-30 18:18:13 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3049,  0.2886, -0.1965,  ...,  0.0247,  0.1272, -0.3240],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.0215, -3.3223, -0.7812,  ...,  2.3438, -4.9648, -2.4961],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0776, -0.0113,  0.0196,  ...,  0.0073, -0.0052,  0.0264],
        [ 0.0068,  0.0518,  0.0122,  ...,  0.0116, -0.0158,  0.0061],
        [ 0.0115, -0.0009,  0.0379,  ...,  0.0017,  0.0016, -0.0091],
        ...,
        [ 0.0007, -0.0088, -0.0159,  ...,  0.0695,  0.0060,  0.0014],
        [-0.0137,  0.0142,  0.0028,  ...,  0.0058,  0.0504, -0.0187],
        [ 0.0184, -0.0084,  0.0081,  ..., -0.0181, -0.0131,  0.0582]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.0280, -3.5684, -0.6064,  ...,  2.8047, -5.1797, -2.6953]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 18:18:14 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To calculate again is to recalculate
To organize again is to reorganize
To consider again is to reconsider
To invest again is to reinvest
To appear again is to reappear
To develop again is to redevelop
To write again is to rewrite
To assure again is to
2024-07-30 18:18:14 root INFO     [order_1_approx] starting weight calculation for To write again is to rewrite
To appear again is to reappear
To calculate again is to recalculate
To invest again is to reinvest
To develop again is to redevelop
To assure again is to reassure
To consider again is to reconsider
To organize again is to
2024-07-30 18:18:14 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-30 18:20:19 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2208,  0.5464,  0.1709,  ..., -0.3623, -0.0753, -0.0706],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.9419, -3.4414,  0.6772,  ...,  2.1055, -1.8330, -4.1562],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0643,  0.0163,  0.0175,  ...,  0.0024, -0.0046,  0.0129],
        [ 0.0043,  0.0602,  0.0061,  ...,  0.0076, -0.0010,  0.0034],
        [ 0.0049,  0.0112,  0.0343,  ..., -0.0015,  0.0062, -0.0109],
        ...,
        [-0.0002, -0.0037, -0.0059,  ...,  0.0471, -0.0063, -0.0126],
        [-0.0073,  0.0063, -0.0024,  ..., -0.0012,  0.0556, -0.0172],
        [ 0.0086, -0.0121, -0.0055,  ..., -0.0097, -0.0143,  0.0535]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.9399, -3.6328,  0.8179,  ...,  2.0684, -1.8867, -4.1250]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 18:20:20 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To write again is to rewrite
To appear again is to reappear
To calculate again is to recalculate
To invest again is to reinvest
To develop again is to redevelop
To assure again is to reassure
To consider again is to reconsider
To organize again is to
2024-07-30 18:20:20 root INFO     [order_1_approx] starting weight calculation for To calculate again is to recalculate
To write again is to rewrite
To assure again is to reassure
To appear again is to reappear
To develop again is to redevelop
To consider again is to reconsider
To organize again is to reorganize
To invest again is to
2024-07-30 18:20:21 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-30 18:22:25 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3628,  0.3582,  0.1411,  ..., -0.1660, -0.2253, -0.0265],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.5708, -2.4160,  0.3186,  ...,  1.0117, -2.8535, -3.3320],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0695, -0.0045,  0.0123,  ..., -0.0088, -0.0039,  0.0280],
        [ 0.0108,  0.0435, -0.0212,  ...,  0.0095, -0.0036, -0.0123],
        [ 0.0206,  0.0076,  0.0396,  ..., -0.0079, -0.0043, -0.0237],
        ...,
        [ 0.0004,  0.0084, -0.0004,  ...,  0.0636,  0.0018, -0.0174],
        [-0.0213,  0.0142,  0.0023,  ...,  0.0047,  0.0585, -0.0303],
        [-0.0161, -0.0038, -0.0018,  ...,  0.0066, -0.0164,  0.0462]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.3945, -2.2441,  0.2817,  ...,  1.1133, -2.9824, -3.4199]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 18:22:26 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To calculate again is to recalculate
To write again is to rewrite
To assure again is to reassure
To appear again is to reappear
To develop again is to redevelop
To consider again is to reconsider
To organize again is to reorganize
To invest again is to
2024-07-30 18:22:27 root INFO     [order_1_approx] starting weight calculation for To develop again is to redevelop
To invest again is to reinvest
To organize again is to reorganize
To calculate again is to recalculate
To consider again is to reconsider
To write again is to rewrite
To assure again is to reassure
To appear again is to
2024-07-30 18:22:27 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-30 18:24:28 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0786, -0.0281, -0.3850,  ..., -0.1047, -0.1570, -0.2166],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.8887, -1.9287, -0.0264,  ...,  4.1719, -5.5156, -2.2305],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.1031,  0.0005,  0.0152,  ...,  0.0080,  0.0027,  0.0274],
        [-0.0034,  0.0640,  0.0012,  ...,  0.0165,  0.0027, -0.0055],
        [ 0.0082, -0.0172,  0.0892,  ...,  0.0136,  0.0054, -0.0172],
        ...,
        [-0.0195, -0.0026,  0.0035,  ...,  0.0852, -0.0170, -0.0104],
        [ 0.0004,  0.0401,  0.0052,  ..., -0.0286,  0.0691, -0.0243],
        [-0.0057, -0.0127,  0.0004,  ..., -0.0119, -0.0215,  0.0857]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.5205, -2.2559, -0.0290,  ...,  4.3750, -5.4336, -1.9521]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 18:24:32 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To develop again is to redevelop
To invest again is to reinvest
To organize again is to reorganize
To calculate again is to recalculate
To consider again is to reconsider
To write again is to rewrite
To assure again is to reassure
To appear again is to
2024-07-30 18:24:32 root INFO     total operator prediction time: 1016.7259814739227 seconds
2024-07-30 18:24:32 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on un+adj_reg
2024-07-30 18:24:32 root INFO     building operator un+adj_reg
2024-07-30 18:24:35 root INFO     [order_1_approx] starting weight calculation for The opposite of wanted is unwanted
The opposite of satisfactory is unsatisfactory
The opposite of forgettable is unforgettable
The opposite of specified is unspecified
The opposite of employed is unemployed
The opposite of sustainable is unsustainable
The opposite of successful is unsuccessful
The opposite of conditional is
2024-07-30 18:24:35 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-30 18:26:39 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2964,  0.2172, -0.4409,  ..., -0.5488, -0.0880, -0.0439],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.7461, -1.7129,  1.4980,  ...,  1.1670, -1.7773, -1.9785],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0641,  0.0145, -0.0134,  ...,  0.0209,  0.0121, -0.0013],
        [ 0.0023,  0.0561, -0.0111,  ...,  0.0055, -0.0201, -0.0060],
        [-0.0415, -0.0164,  0.0384,  ..., -0.0292,  0.0113,  0.0073],
        ...,
        [ 0.0266,  0.0322,  0.0072,  ...,  0.0604, -0.0039, -0.0173],
        [ 0.0158, -0.0014,  0.0071,  ...,  0.0049,  0.0394,  0.0442],
        [-0.0089,  0.0018,  0.0068,  ..., -0.0410, -0.0220,  0.0934]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.6650, -1.2354,  1.8936,  ...,  1.4746, -2.1172, -1.8223]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 18:26:40 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of wanted is unwanted
The opposite of satisfactory is unsatisfactory
The opposite of forgettable is unforgettable
The opposite of specified is unspecified
The opposite of employed is unemployed
The opposite of sustainable is unsustainable
The opposite of successful is unsuccessful
The opposite of conditional is
2024-07-30 18:26:40 root INFO     [order_1_approx] starting weight calculation for The opposite of sustainable is unsustainable
The opposite of forgettable is unforgettable
The opposite of conditional is unconditional
The opposite of specified is unspecified
The opposite of successful is unsuccessful
The opposite of wanted is unwanted
The opposite of satisfactory is unsatisfactory
The opposite of employed is
2024-07-30 18:26:40 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-30 18:28:45 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4573,  0.1184, -0.0925,  ...,  0.1428, -0.2822, -0.0359],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.0371, -1.4688,  0.2871,  ..., -0.3716,  0.3169, -2.3359],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 4.7180e-02, -1.2009e-02,  7.8964e-03,  ...,  1.6876e-02,
         -5.2261e-03,  1.8768e-03],
        [-2.4185e-02,  3.7415e-02, -1.8631e-02,  ...,  4.9667e-03,
          2.2629e-02,  1.3580e-02],
        [ 9.9564e-04,  4.0588e-03,  2.3071e-02,  ..., -1.3092e-02,
          1.8356e-02, -1.0719e-02],
        ...,
        [ 4.5061e-05,  1.8402e-02, -4.2076e-03,  ...,  2.8717e-02,
         -6.3438e-03, -1.2222e-02],
        [-2.3117e-02, -7.3738e-03,  1.9623e-02,  ..., -1.7120e-02,
          2.3132e-02,  6.2561e-03],
        [-5.4054e-03,  4.3793e-03, -2.4734e-02,  ..., -1.0399e-02,
         -2.0390e-03,  4.6814e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.3018, -1.8066, -0.4370,  ..., -0.0830,  0.5098, -2.1055]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 18:28:46 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of sustainable is unsustainable
The opposite of forgettable is unforgettable
The opposite of conditional is unconditional
The opposite of specified is unspecified
The opposite of successful is unsuccessful
The opposite of wanted is unwanted
The opposite of satisfactory is unsatisfactory
The opposite of employed is
2024-07-30 18:28:46 root INFO     [order_1_approx] starting weight calculation for The opposite of conditional is unconditional
The opposite of specified is unspecified
The opposite of wanted is unwanted
The opposite of satisfactory is unsatisfactory
The opposite of forgettable is unforgettable
The opposite of successful is unsuccessful
The opposite of employed is unemployed
The opposite of sustainable is
2024-07-30 18:28:46 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-30 18:30:48 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0293,  0.1630, -0.6133,  ..., -0.0630, -0.1531,  0.1973],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.0117, -2.4766,  0.1074,  ..., -1.8691, -2.4297, -0.0264],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0527,  0.0287, -0.0116,  ...,  0.0079, -0.0034, -0.0077],
        [-0.0103,  0.0529,  0.0135,  ...,  0.0118,  0.0244,  0.0108],
        [ 0.0030, -0.0022,  0.0357,  ...,  0.0011, -0.0125, -0.0062],
        ...,
        [ 0.0116,  0.0177, -0.0232,  ...,  0.0180,  0.0061, -0.0054],
        [-0.0066,  0.0150,  0.0223,  ..., -0.0179,  0.0166,  0.0092],
        [-0.0206, -0.0066, -0.0106,  ..., -0.0136, -0.0027,  0.0291]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.4062, -2.4375,  0.6934,  ..., -1.4883, -1.8691,  0.0255]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 18:30:50 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of conditional is unconditional
The opposite of specified is unspecified
The opposite of wanted is unwanted
The opposite of satisfactory is unsatisfactory
The opposite of forgettable is unforgettable
The opposite of successful is unsuccessful
The opposite of employed is unemployed
The opposite of sustainable is
2024-07-30 18:30:50 root INFO     [order_1_approx] starting weight calculation for The opposite of sustainable is unsustainable
The opposite of conditional is unconditional
The opposite of forgettable is unforgettable
The opposite of specified is unspecified
The opposite of satisfactory is unsatisfactory
The opposite of wanted is unwanted
The opposite of employed is unemployed
The opposite of successful is
2024-07-30 18:30:50 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-30 18:32:57 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1591,  0.5508, -0.1130,  ...,  0.1353, -0.2732, -0.2361],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.3906, -0.3550,  0.3906,  ..., -0.6094,  0.2637, -0.9224],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0234,  0.0002, -0.0100,  ...,  0.0311,  0.0018, -0.0024],
        [-0.0216,  0.0557, -0.0123,  ...,  0.0301,  0.0267,  0.0013],
        [ 0.0038, -0.0091,  0.0191,  ..., -0.0120, -0.0274, -0.0149],
        ...,
        [ 0.0111,  0.0101, -0.0215,  ...,  0.0116,  0.0032,  0.0121],
        [-0.0039, -0.0066,  0.0075,  ...,  0.0037,  0.0024, -0.0060],
        [ 0.0058, -0.0110, -0.0115,  ..., -0.0120, -0.0107,  0.0300]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.5488, -0.5903,  0.6890,  ..., -0.2988,  0.3003, -0.8188]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 18:32:59 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of sustainable is unsustainable
The opposite of conditional is unconditional
The opposite of forgettable is unforgettable
The opposite of specified is unspecified
The opposite of satisfactory is unsatisfactory
The opposite of wanted is unwanted
The opposite of employed is unemployed
The opposite of successful is
2024-07-30 18:32:59 root INFO     [order_1_approx] starting weight calculation for The opposite of employed is unemployed
The opposite of specified is unspecified
The opposite of wanted is unwanted
The opposite of conditional is unconditional
The opposite of successful is unsuccessful
The opposite of sustainable is unsustainable
The opposite of satisfactory is unsatisfactory
The opposite of forgettable is
2024-07-30 18:32:59 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-30 18:35:08 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.5791, -0.2817, -0.4492,  ..., -0.4387, -0.3274,  0.1970],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.0840, -1.4023, -1.4131,  ..., -1.6484, -6.4375, -3.4648],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0546,  0.0253,  0.0036,  ..., -0.0011, -0.0086,  0.0303],
        [-0.0138,  0.0654, -0.0085,  ...,  0.0278,  0.0071, -0.0104],
        [ 0.0143,  0.0144,  0.0350,  ..., -0.0240, -0.0169, -0.0031],
        ...,
        [ 0.0028,  0.0188, -0.0010,  ...,  0.0400, -0.0036, -0.0304],
        [ 0.0177,  0.0315,  0.0248,  ..., -0.0016,  0.0378, -0.0118],
        [-0.0034,  0.0144, -0.0215,  ..., -0.0005, -0.0263,  0.0508]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.5312, -1.0010, -0.9307,  ..., -1.5068, -6.1562, -3.2695]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 18:35:09 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of employed is unemployed
The opposite of specified is unspecified
The opposite of wanted is unwanted
The opposite of conditional is unconditional
The opposite of successful is unsuccessful
The opposite of sustainable is unsustainable
The opposite of satisfactory is unsatisfactory
The opposite of forgettable is
2024-07-30 18:35:09 root INFO     [order_1_approx] starting weight calculation for The opposite of forgettable is unforgettable
The opposite of successful is unsuccessful
The opposite of wanted is unwanted
The opposite of conditional is unconditional
The opposite of sustainable is unsustainable
The opposite of employed is unemployed
The opposite of satisfactory is unsatisfactory
The opposite of specified is
2024-07-30 18:35:09 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-30 18:37:11 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0500, -0.2489, -0.4758,  ..., -0.0287, -0.0338, -0.5322],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.1113,  0.5381,  0.3320,  ...,  1.8828, -1.1582, -1.1455],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0616,  0.0102, -0.0074,  ...,  0.0032,  0.0009, -0.0061],
        [-0.0179,  0.0547, -0.0031,  ...,  0.0146,  0.0154,  0.0001],
        [-0.0143,  0.0053,  0.0535,  ...,  0.0071,  0.0186,  0.0176],
        ...,
        [-0.0009,  0.0199, -0.0067,  ...,  0.0491, -0.0126,  0.0106],
        [ 0.0162,  0.0242,  0.0232,  ..., -0.0167,  0.0502,  0.0431],
        [-0.0117,  0.0174, -0.0151,  ..., -0.0214, -0.0095,  0.0826]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.5879,  0.1658,  0.2305,  ...,  2.0430, -1.4902, -1.0635]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 18:37:12 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of forgettable is unforgettable
The opposite of successful is unsuccessful
The opposite of wanted is unwanted
The opposite of conditional is unconditional
The opposite of sustainable is unsustainable
The opposite of employed is unemployed
The opposite of satisfactory is unsatisfactory
The opposite of specified is
2024-07-30 18:37:12 root INFO     [order_1_approx] starting weight calculation for The opposite of conditional is unconditional
The opposite of forgettable is unforgettable
The opposite of successful is unsuccessful
The opposite of specified is unspecified
The opposite of satisfactory is unsatisfactory
The opposite of employed is unemployed
The opposite of sustainable is unsustainable
The opposite of wanted is
2024-07-30 18:37:12 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-30 18:39:10 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1161, -0.0032, -0.6704,  ..., -0.0133,  0.0450,  0.2198],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.8271, -2.3438, -1.5010,  ...,  0.3809, -2.6953, -1.6270],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0136, -0.0130, -0.0200,  ...,  0.0079, -0.0162, -0.0055],
        [-0.0345,  0.0581, -0.0480,  ...,  0.0316, -0.0125, -0.0201],
        [ 0.0100,  0.0242,  0.0403,  ..., -0.0070,  0.0054,  0.0085],
        ...,
        [ 0.0104,  0.0186,  0.0095,  ...,  0.0300, -0.0148, -0.0272],
        [ 0.0202, -0.0045,  0.0264,  ..., -0.0082,  0.0537,  0.0310],
        [ 0.0039,  0.0105, -0.0342,  ..., -0.0187,  0.0059,  0.0714]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.4766, -1.8848, -1.2402,  ...,  0.7695, -2.4551, -1.5449]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 18:39:11 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of conditional is unconditional
The opposite of forgettable is unforgettable
The opposite of successful is unsuccessful
The opposite of specified is unspecified
The opposite of satisfactory is unsatisfactory
The opposite of employed is unemployed
The opposite of sustainable is unsustainable
The opposite of wanted is
2024-07-30 18:39:11 root INFO     [order_1_approx] starting weight calculation for The opposite of successful is unsuccessful
The opposite of forgettable is unforgettable
The opposite of wanted is unwanted
The opposite of specified is unspecified
The opposite of conditional is unconditional
The opposite of sustainable is unsustainable
The opposite of employed is unemployed
The opposite of satisfactory is
2024-07-30 18:39:11 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-30 18:41:12 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0513, -0.0097, -0.3787,  ..., -0.3013, -0.3286, -0.1328],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.6602, -1.9736,  3.4629,  ..., -2.0605, -3.2930, -0.7231],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0414,  0.0181,  0.0037,  ...,  0.0146,  0.0076,  0.0126],
        [-0.0096,  0.0611, -0.0065,  ...,  0.0291,  0.0039, -0.0086],
        [ 0.0062, -0.0249,  0.0257,  ..., -0.0118, -0.0217, -0.0110],
        ...,
        [ 0.0023,  0.0221, -0.0068,  ...,  0.0247, -0.0036, -0.0084],
        [ 0.0043, -0.0075,  0.0312,  ..., -0.0145,  0.0243,  0.0151],
        [-0.0034, -0.0052, -0.0155,  ..., -0.0156, -0.0107,  0.0371]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.8398, -2.2539,  3.7422,  ..., -2.2871, -3.1582, -0.1812]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 18:41:15 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of successful is unsuccessful
The opposite of forgettable is unforgettable
The opposite of wanted is unwanted
The opposite of specified is unspecified
The opposite of conditional is unconditional
The opposite of sustainable is unsustainable
The opposite of employed is unemployed
The opposite of satisfactory is
2024-07-30 18:41:15 root INFO     total operator prediction time: 1002.9166913032532 seconds
2024-07-30 18:41:15 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on verb+able_reg
2024-07-30 18:41:15 root INFO     building operator verb+able_reg
2024-07-30 18:41:18 root INFO     [order_1_approx] starting weight calculation for If you can foresee something, that thing is foreseeable
If you can rely something, that thing is reliable
If you can improve something, that thing is improvable
If you can replace something, that thing is replaceable
If you can write something, that thing is writeable
If you can protect something, that thing is protectable
If you can discover something, that thing is discoverable
If you can achieve something, that thing is
2024-07-30 18:41:18 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-30 18:43:20 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1851,  0.0261, -0.1510,  ...,  0.0958, -0.5723,  0.0890],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.2109, -0.0869, -1.9785,  ..., -4.0195, -9.0391, -3.4551],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0399,  0.0080, -0.0025,  ..., -0.0023,  0.0104,  0.0201],
        [ 0.0027,  0.0516,  0.0064,  ...,  0.0075, -0.0126, -0.0173],
        [-0.0013, -0.0188,  0.0363,  ..., -0.0095, -0.0135, -0.0056],
        ...,
        [ 0.0112,  0.0263, -0.0099,  ...,  0.0477,  0.0028, -0.0177],
        [ 0.0035,  0.0056,  0.0093,  ..., -0.0292,  0.0316, -0.0119],
        [ 0.0051, -0.0009, -0.0096,  ..., -0.0068, -0.0083,  0.0405]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.2852, -0.1624, -2.2617,  ..., -3.7344, -9.0312, -3.5488]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 18:43:21 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you can foresee something, that thing is foreseeable
If you can rely something, that thing is reliable
If you can improve something, that thing is improvable
If you can replace something, that thing is replaceable
If you can write something, that thing is writeable
If you can protect something, that thing is protectable
If you can discover something, that thing is discoverable
If you can achieve something, that thing is
2024-07-30 18:43:21 root INFO     [order_1_approx] starting weight calculation for If you can discover something, that thing is discoverable
If you can rely something, that thing is reliable
If you can foresee something, that thing is foreseeable
If you can achieve something, that thing is achieveable
If you can write something, that thing is writeable
If you can protect something, that thing is protectable
If you can improve something, that thing is improvable
If you can replace something, that thing is
2024-07-30 18:43:21 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-30 18:45:27 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0502, -0.4854, -0.4468,  ..., -0.0447,  0.0338,  0.1791],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-2.1738, -0.7905, -1.8184,  ..., -3.2480, -5.8281, -0.7051],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 5.6519e-02, -9.4223e-03,  8.4839e-03,  ...,  6.4964e-03,
          5.5542e-03,  2.9938e-02],
        [-1.1597e-02,  3.8879e-02,  8.8806e-03,  ...,  8.0261e-03,
         -1.6251e-02, -2.2888e-05],
        [-8.7357e-04, -4.8523e-03,  4.3762e-02,  ..., -7.2212e-03,
          3.3340e-03, -9.2926e-03],
        ...,
        [ 1.8158e-02,  6.2408e-03,  1.5900e-02,  ...,  5.4901e-02,
          2.2173e-04, -6.2790e-03],
        [-6.7902e-03, -3.8986e-03, -8.8501e-04,  ..., -2.3117e-02,
          4.1077e-02, -1.2024e-02],
        [-2.3537e-03,  5.0774e-03,  9.8038e-03,  ..., -2.9297e-02,
         -6.2714e-03,  5.7007e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-2.3887, -1.0977, -1.6367,  ..., -3.2305, -5.6094, -0.8174]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 18:45:28 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you can discover something, that thing is discoverable
If you can rely something, that thing is reliable
If you can foresee something, that thing is foreseeable
If you can achieve something, that thing is achieveable
If you can write something, that thing is writeable
If you can protect something, that thing is protectable
If you can improve something, that thing is improvable
If you can replace something, that thing is
2024-07-30 18:45:28 root INFO     [order_1_approx] starting weight calculation for If you can rely something, that thing is reliable
If you can improve something, that thing is improvable
If you can protect something, that thing is protectable
If you can achieve something, that thing is achieveable
If you can foresee something, that thing is foreseeable
If you can replace something, that thing is replaceable
If you can write something, that thing is writeable
If you can discover something, that thing is
2024-07-30 18:45:28 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-30 18:47:30 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0181, -0.0504,  0.1960,  ..., -0.2781, -0.7378,  0.0662],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.2090, -3.5508,  0.7856,  ..., -1.2344, -6.6484,  0.6133],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0675,  0.0149,  0.0125,  ...,  0.0014,  0.0067,  0.0155],
        [-0.0139,  0.0493,  0.0091,  ...,  0.0110, -0.0107, -0.0043],
        [ 0.0079, -0.0085,  0.0536,  ...,  0.0113, -0.0020, -0.0202],
        ...,
        [ 0.0123,  0.0233,  0.0138,  ...,  0.0579,  0.0101, -0.0063],
        [-0.0009,  0.0106,  0.0011,  ..., -0.0223,  0.0612, -0.0018],
        [ 0.0157,  0.0044,  0.0213,  ..., -0.0066, -0.0213,  0.0614]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.1047, -3.6191,  0.9424,  ..., -1.0791, -6.7734,  0.1597]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 18:47:31 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you can rely something, that thing is reliable
If you can improve something, that thing is improvable
If you can protect something, that thing is protectable
If you can achieve something, that thing is achieveable
If you can foresee something, that thing is foreseeable
If you can replace something, that thing is replaceable
If you can write something, that thing is writeable
If you can discover something, that thing is
2024-07-30 18:47:31 root INFO     [order_1_approx] starting weight calculation for If you can replace something, that thing is replaceable
If you can rely something, that thing is reliable
If you can foresee something, that thing is foreseeable
If you can write something, that thing is writeable
If you can improve something, that thing is improvable
If you can discover something, that thing is discoverable
If you can achieve something, that thing is achieveable
If you can protect something, that thing is
2024-07-30 18:47:31 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-30 18:49:33 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0938, -0.5537,  0.2083,  ...,  0.0370, -0.1604,  0.1519],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.0811, -3.4160, -1.4619,  ..., -2.2734, -6.3125, -1.7764],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0441,  0.0062,  0.0073,  ...,  0.0002,  0.0136,  0.0323],
        [-0.0188,  0.0432,  0.0009,  ...,  0.0114, -0.0015, -0.0088],
        [ 0.0116, -0.0082,  0.0461,  ..., -0.0141, -0.0013, -0.0211],
        ...,
        [-0.0041,  0.0212,  0.0092,  ...,  0.0439,  0.0153, -0.0045],
        [-0.0080,  0.0037,  0.0085,  ..., -0.0181,  0.0466, -0.0312],
        [ 0.0047,  0.0122,  0.0110,  ..., -0.0139, -0.0182,  0.0427]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.2070, -3.4277, -1.1377,  ..., -1.9971, -6.4023, -2.0371]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 18:49:34 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you can replace something, that thing is replaceable
If you can rely something, that thing is reliable
If you can foresee something, that thing is foreseeable
If you can write something, that thing is writeable
If you can improve something, that thing is improvable
If you can discover something, that thing is discoverable
If you can achieve something, that thing is achieveable
If you can protect something, that thing is
2024-07-30 18:49:35 root INFO     [order_1_approx] starting weight calculation for If you can achieve something, that thing is achieveable
If you can rely something, that thing is reliable
If you can protect something, that thing is protectable
If you can discover something, that thing is discoverable
If you can foresee something, that thing is foreseeable
If you can improve something, that thing is improvable
If you can replace something, that thing is replaceable
If you can write something, that thing is
2024-07-30 18:49:35 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-30 18:51:36 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.4958, -0.1625,  0.5977,  ..., -0.5791, -0.1279,  0.2229],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.5527, -1.4688, -0.3047,  ..., -2.7363, -8.0469, -0.7422],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0630,  0.0059, -0.0089,  ..., -0.0149, -0.0097,  0.0209],
        [-0.0060,  0.0620,  0.0138,  ...,  0.0238, -0.0084, -0.0072],
        [-0.0009, -0.0223,  0.0842,  ...,  0.0050, -0.0116,  0.0005],
        ...,
        [ 0.0152,  0.0106,  0.0118,  ...,  0.0564,  0.0029, -0.0100],
        [ 0.0041, -0.0019, -0.0014,  ..., -0.0184,  0.0519, -0.0002],
        [ 0.0240,  0.0155,  0.0059,  ..., -0.0176, -0.0180,  0.0644]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.4141, -1.3242, -0.2991,  ..., -2.4160, -7.6953, -0.8374]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 18:51:37 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you can achieve something, that thing is achieveable
If you can rely something, that thing is reliable
If you can protect something, that thing is protectable
If you can discover something, that thing is discoverable
If you can foresee something, that thing is foreseeable
If you can improve something, that thing is improvable
If you can replace something, that thing is replaceable
If you can write something, that thing is
2024-07-30 18:51:37 root INFO     [order_1_approx] starting weight calculation for If you can achieve something, that thing is achieveable
If you can foresee something, that thing is foreseeable
If you can replace something, that thing is replaceable
If you can discover something, that thing is discoverable
If you can protect something, that thing is protectable
If you can improve something, that thing is improvable
If you can write something, that thing is writeable
If you can rely something, that thing is
2024-07-30 18:51:37 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-30 18:53:38 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0853, -0.2297,  0.2007,  ..., -0.2859, -0.3962, -0.1672],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.0947, -1.0010, -1.4824,  ..., -1.2168, -5.9766, -2.6582],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0773, -0.0043, -0.0057,  ..., -0.0028,  0.0095,  0.0272],
        [-0.0036,  0.0641,  0.0132,  ...,  0.0207,  0.0043, -0.0009],
        [ 0.0006, -0.0020,  0.0406,  ...,  0.0003, -0.0066, -0.0121],
        ...,
        [ 0.0193,  0.0502,  0.0035,  ...,  0.0562,  0.0079,  0.0150],
        [ 0.0106,  0.0051, -0.0128,  ..., -0.0227,  0.0515, -0.0216],
        [ 0.0023,  0.0026,  0.0007,  ..., -0.0287, -0.0078,  0.0384]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.4199, -1.1641, -1.8408,  ..., -1.2891, -6.0391, -2.6426]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 18:53:40 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you can achieve something, that thing is achieveable
If you can foresee something, that thing is foreseeable
If you can replace something, that thing is replaceable
If you can discover something, that thing is discoverable
If you can protect something, that thing is protectable
If you can improve something, that thing is improvable
If you can write something, that thing is writeable
If you can rely something, that thing is
2024-07-30 18:53:40 root INFO     [order_1_approx] starting weight calculation for If you can write something, that thing is writeable
If you can achieve something, that thing is achieveable
If you can replace something, that thing is replaceable
If you can protect something, that thing is protectable
If you can rely something, that thing is reliable
If you can improve something, that thing is improvable
If you can discover something, that thing is discoverable
If you can foresee something, that thing is
2024-07-30 18:53:40 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-30 18:55:39 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2495,  0.3347,  0.3337,  ..., -0.3452,  0.0739, -0.0652],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.6328,  0.7842, -1.8105,  ..., -2.9434, -7.4648, -1.9492],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0281,  0.0058, -0.0031,  ...,  0.0017,  0.0037,  0.0051],
        [-0.0102,  0.0316,  0.0030,  ...,  0.0099, -0.0071, -0.0077],
        [-0.0017, -0.0072,  0.0278,  ..., -0.0019,  0.0014, -0.0084],
        ...,
        [ 0.0057,  0.0047, -0.0035,  ...,  0.0338,  0.0026, -0.0007],
        [ 0.0010, -0.0013,  0.0027,  ..., -0.0130,  0.0339, -0.0068],
        [ 0.0053,  0.0014,  0.0014,  ..., -0.0045, -0.0054,  0.0285]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.7451,  0.7466, -1.7490,  ..., -2.8672, -7.3633, -1.9277]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 18:55:40 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you can write something, that thing is writeable
If you can achieve something, that thing is achieveable
If you can replace something, that thing is replaceable
If you can protect something, that thing is protectable
If you can rely something, that thing is reliable
If you can improve something, that thing is improvable
If you can discover something, that thing is discoverable
If you can foresee something, that thing is
2024-07-30 18:55:40 root INFO     [order_1_approx] starting weight calculation for If you can discover something, that thing is discoverable
If you can foresee something, that thing is foreseeable
If you can write something, that thing is writeable
If you can protect something, that thing is protectable
If you can achieve something, that thing is achieveable
If you can replace something, that thing is replaceable
If you can rely something, that thing is reliable
If you can improve something, that thing is
2024-07-30 18:55:40 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-30 18:57:42 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0335, -0.4932, -0.0212,  ..., -0.2234, -0.1827,  0.1573],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.4609, -1.2363,  0.1777,  ..., -2.1406, -8.3906, -3.0977],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0427, -0.0020,  0.0108,  ..., -0.0006, -0.0150,  0.0154],
        [ 0.0005,  0.0383,  0.0027,  ...,  0.0019, -0.0059,  0.0029],
        [-0.0002, -0.0037,  0.0399,  ...,  0.0057, -0.0004, -0.0129],
        ...,
        [ 0.0137,  0.0116,  0.0003,  ...,  0.0388, -0.0025, -0.0088],
        [ 0.0006,  0.0049,  0.0048,  ..., -0.0195,  0.0311, -0.0100],
        [-0.0056, -0.0017,  0.0019,  ..., -0.0141, -0.0237,  0.0244]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.2910, -1.4854,  0.2395,  ..., -2.0605, -7.8672, -3.4727]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 18:57:43 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you can discover something, that thing is discoverable
If you can foresee something, that thing is foreseeable
If you can write something, that thing is writeable
If you can protect something, that thing is protectable
If you can achieve something, that thing is achieveable
If you can replace something, that thing is replaceable
If you can rely something, that thing is reliable
If you can improve something, that thing is
2024-07-30 18:57:43 root INFO     total operator prediction time: 988.1852700710297 seconds
2024-07-30 18:57:43 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on verb+tion_irreg
2024-07-30 18:57:43 root INFO     building operator verb+tion_irreg
2024-07-30 18:57:43 root INFO     [order_1_approx] starting weight calculation for To reorganize results in reorganization
To customize results in customization
To consult results in consulation
To deprive results in deprivation
To explore results in exploration
To compile results in compilation
To observe results in observation
To oblige results in
2024-07-30 18:57:44 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-30 18:59:50 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1029,  1.0586, -0.8037,  ..., -0.3579, -0.0593, -0.4189],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.9697, -6.1172,  1.8340,  ...,  3.0176, -2.0059, -1.4785],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 6.7810e-02, -3.5820e-03,  1.5297e-02,  ...,  1.8454e-03,
         -1.4778e-02, -4.6310e-03],
        [ 6.7291e-03,  5.9875e-02, -7.7972e-03,  ...,  2.5894e-02,
         -1.1765e-02,  1.6953e-02],
        [-1.5511e-02, -1.2619e-02,  3.3905e-02,  ..., -2.3422e-03,
          9.1553e-05,  7.0076e-03],
        ...,
        [ 1.3809e-02,  1.9012e-02,  1.5915e-02,  ...,  6.9031e-02,
          4.4632e-04,  1.3390e-02],
        [-4.4060e-04,  2.4643e-03, -4.2229e-03,  ...,  2.1591e-03,
          6.0577e-02, -3.4302e-02],
        [ 1.1110e-03,  3.2520e-03, -4.9591e-04,  ..., -4.7035e-03,
         -1.2741e-02,  7.5623e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.6611, -5.9336,  2.2812,  ...,  2.4316, -1.7451, -1.6016]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 18:59:50 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To reorganize results in reorganization
To customize results in customization
To consult results in consulation
To deprive results in deprivation
To explore results in exploration
To compile results in compilation
To observe results in observation
To oblige results in
2024-07-30 18:59:51 root INFO     [order_1_approx] starting weight calculation for To observe results in observation
To deprive results in deprivation
To reorganize results in reorganization
To consult results in consulation
To oblige results in obligation
To compile results in compilation
To explore results in exploration
To customize results in
2024-07-30 18:59:51 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-30 19:01:53 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1562, -0.5054, -0.6289,  ..., -0.2349, -0.5386,  0.1207],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.8135, -3.8984,  1.6943,  ...,  1.0596, -2.8633, -0.1533],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0690,  0.0061,  0.0098,  ..., -0.0138,  0.0185, -0.0033],
        [ 0.0031,  0.0745, -0.0034,  ...,  0.0420, -0.0039,  0.0153],
        [-0.0076, -0.0063,  0.0486,  ..., -0.0086,  0.0158, -0.0064],
        ...,
        [ 0.0074, -0.0048, -0.0094,  ...,  0.1025, -0.0129,  0.0055],
        [ 0.0003,  0.0110,  0.0029,  ...,  0.0117,  0.0629, -0.0081],
        [ 0.0062, -0.0062,  0.0060,  ...,  0.0121, -0.0327,  0.0807]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.6279, -3.5195,  1.7656,  ...,  1.6133, -2.5859, -0.0122]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 19:01:54 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To observe results in observation
To deprive results in deprivation
To reorganize results in reorganization
To consult results in consulation
To oblige results in obligation
To compile results in compilation
To explore results in exploration
To customize results in
2024-07-30 19:01:54 root INFO     [order_1_approx] starting weight calculation for To oblige results in obligation
To explore results in exploration
To observe results in observation
To customize results in customization
To compile results in compilation
To consult results in consulation
To deprive results in deprivation
To reorganize results in
2024-07-30 19:01:54 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-30 19:03:56 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2769,  0.1785, -1.0049,  ...,  0.0562, -0.1252, -0.2976],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.9624, -4.2148,  2.4922,  ...,  0.5864, -0.6855, -5.0625],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0388,  0.0049,  0.0033,  ..., -0.0056,  0.0061, -0.0016],
        [ 0.0053,  0.0454,  0.0048,  ...,  0.0094, -0.0061,  0.0039],
        [-0.0061, -0.0055,  0.0343,  ...,  0.0018,  0.0092, -0.0045],
        ...,
        [ 0.0068,  0.0024, -0.0003,  ...,  0.0442, -0.0178,  0.0033],
        [ 0.0003,  0.0016,  0.0030,  ...,  0.0047,  0.0408, -0.0056],
        [ 0.0047, -0.0056, -0.0043,  ..., -0.0038, -0.0107,  0.0403]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.1475, -4.2148,  2.6387,  ...,  0.5405, -0.7544, -5.0859]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 19:03:57 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To oblige results in obligation
To explore results in exploration
To observe results in observation
To customize results in customization
To compile results in compilation
To consult results in consulation
To deprive results in deprivation
To reorganize results in
2024-07-30 19:03:57 root INFO     [order_1_approx] starting weight calculation for To compile results in compilation
To consult results in consulation
To reorganize results in reorganization
To customize results in customization
To oblige results in obligation
To observe results in observation
To explore results in exploration
To deprive results in
2024-07-30 19:03:57 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-30 19:05:55 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.6357,  0.0779, -0.4902,  ..., -0.0691,  0.1970,  0.0862],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.3984, -5.3906,  2.4512,  ...,  0.9409, -3.2070, -2.5918],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 7.7148e-02, -4.8065e-04, -7.6523e-03,  ..., -1.0323e-02,
          1.8377e-03, -4.1962e-05],
        [ 1.0101e-02,  7.4829e-02,  6.3477e-03,  ...,  2.2461e-02,
         -3.9940e-03,  5.2071e-03],
        [-3.5210e-03, -1.1078e-02,  4.9500e-02,  ..., -4.8828e-04,
          1.5335e-03, -2.8038e-03],
        ...,
        [ 4.2419e-03, -3.5725e-03,  1.1383e-02,  ...,  8.9050e-02,
         -1.2886e-02, -1.9741e-03],
        [-3.4657e-03,  3.0804e-03,  5.5084e-03,  ...,  1.3420e-02,
          7.5134e-02, -1.1749e-02],
        [ 1.4114e-02, -9.1553e-03,  2.8000e-03,  ..., -1.1864e-02,
         -2.4017e-02,  8.8196e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.5293, -5.2969,  2.7500,  ...,  0.6855, -3.1426, -2.7598]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 19:05:56 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To compile results in compilation
To consult results in consulation
To reorganize results in reorganization
To customize results in customization
To oblige results in obligation
To observe results in observation
To explore results in exploration
To deprive results in
2024-07-30 19:05:56 root INFO     [order_1_approx] starting weight calculation for To oblige results in obligation
To compile results in compilation
To customize results in customization
To reorganize results in reorganization
To consult results in consulation
To deprive results in deprivation
To explore results in exploration
To observe results in
2024-07-30 19:05:56 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-30 19:08:01 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0535,  0.4287, -0.0987,  ..., -0.0442, -0.0778, -0.1558],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.9082, -5.8594,  2.9961,  ..., -0.6255, -0.7432, -0.9375],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 8.6548e-02,  7.6447e-03,  1.3229e-02,  ...,  2.2831e-03,
         -1.9485e-02,  1.9714e-02],
        [ 8.6365e-03,  7.5806e-02, -6.3553e-03,  ...,  3.2684e-02,
         -1.1444e-05,  9.2163e-03],
        [-1.2703e-03, -1.1314e-02,  6.7383e-02,  ...,  6.0387e-03,
         -1.1017e-02,  7.2746e-03],
        ...,
        [-7.4692e-03, -3.6659e-03,  8.5449e-04,  ...,  7.9102e-02,
         -9.6130e-04,  1.9312e-05],
        [-1.5564e-03,  2.7893e-02,  1.0796e-02,  ..., -7.0000e-03,
          7.3547e-02, -3.1403e-02],
        [ 1.6541e-02,  4.1428e-03, -1.6708e-02,  ...,  1.2455e-03,
         -2.5864e-02,  7.6904e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.1709, -5.5977,  3.3867,  ..., -0.6060, -1.1377, -0.9868]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 19:08:02 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To oblige results in obligation
To compile results in compilation
To customize results in customization
To reorganize results in reorganization
To consult results in consulation
To deprive results in deprivation
To explore results in exploration
To observe results in
2024-07-30 19:08:02 root INFO     [order_1_approx] starting weight calculation for To explore results in exploration
To oblige results in obligation
To customize results in customization
To observe results in observation
To compile results in compilation
To reorganize results in reorganization
To deprive results in deprivation
To consult results in
2024-07-30 19:08:03 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-30 19:10:00 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1039, -0.2317, -0.5469,  ...,  0.0939, -0.5537, -0.3206],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.2305, -3.3223,  3.0430,  ...,  1.3848, -0.5176, -2.2031],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0579,  0.0193,  0.0164,  ..., -0.0074,  0.0016,  0.0253],
        [ 0.0070,  0.0507,  0.0012,  ...,  0.0339, -0.0110, -0.0033],
        [-0.0018, -0.0152,  0.0740,  ..., -0.0024,  0.0023, -0.0073],
        ...,
        [ 0.0096,  0.0006, -0.0026,  ...,  0.0880, -0.0003, -0.0128],
        [-0.0109, -0.0055,  0.0202,  ...,  0.0112,  0.0611, -0.0043],
        [ 0.0187, -0.0149, -0.0084,  ...,  0.0082, -0.0103,  0.0609]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.2477, -3.0371,  3.0352,  ...,  1.5117, -0.6406, -2.3281]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 19:10:01 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To explore results in exploration
To oblige results in obligation
To customize results in customization
To observe results in observation
To compile results in compilation
To reorganize results in reorganization
To deprive results in deprivation
To consult results in
2024-07-30 19:10:01 root INFO     [order_1_approx] starting weight calculation for To consult results in consulation
To compile results in compilation
To oblige results in obligation
To customize results in customization
To deprive results in deprivation
To observe results in observation
To reorganize results in reorganization
To explore results in
2024-07-30 19:10:02 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-30 19:12:02 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2290,  0.0246,  0.0540,  ..., -0.1797, -0.1129, -0.5244],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.5889, -2.8457,  4.0586,  ...,  2.3574, -0.2074, -2.7539],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0820,  0.0084,  0.0054,  ...,  0.0030, -0.0058, -0.0072],
        [-0.0089,  0.0931,  0.0202,  ...,  0.0276,  0.0024,  0.0091],
        [ 0.0188, -0.0129,  0.0603,  ..., -0.0042, -0.0035, -0.0182],
        ...,
        [-0.0028,  0.0052,  0.0117,  ...,  0.0890,  0.0030,  0.0001],
        [ 0.0056,  0.0190,  0.0038,  ...,  0.0161,  0.0959, -0.0177],
        [ 0.0171, -0.0122, -0.0109,  ..., -0.0032, -0.0199,  0.0867]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.4685, -2.4141,  4.0117,  ...,  2.4082, -0.2915, -2.8105]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 19:12:03 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To consult results in consulation
To compile results in compilation
To oblige results in obligation
To customize results in customization
To deprive results in deprivation
To observe results in observation
To reorganize results in reorganization
To explore results in
2024-07-30 19:12:03 root INFO     [order_1_approx] starting weight calculation for To oblige results in obligation
To deprive results in deprivation
To customize results in customization
To observe results in observation
To explore results in exploration
To consult results in consulation
To reorganize results in reorganization
To compile results in
2024-07-30 19:12:03 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-30 19:14:00 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2827, -0.1564, -0.3374,  ..., -0.4590, -0.5044,  0.2410],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.2002, -4.3828,  4.0391,  ...,  1.4766, -1.4922,  0.3506],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.1075,  0.0199,  0.0181,  ...,  0.0082,  0.0073,  0.0031],
        [-0.0111,  0.0869,  0.0030,  ...,  0.0405, -0.0078,  0.0166],
        [-0.0115, -0.0266,  0.0576,  ..., -0.0028,  0.0091, -0.0180],
        ...,
        [ 0.0151,  0.0056,  0.0017,  ...,  0.0974, -0.0170, -0.0143],
        [ 0.0035,  0.0176,  0.0210,  ..., -0.0071,  0.0897, -0.0115],
        [ 0.0015,  0.0023,  0.0019,  ...,  0.0140, -0.0114,  0.0885]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.2832, -3.8320,  3.9473,  ...,  1.5264, -1.7422, -0.0522]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 19:14:01 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To oblige results in obligation
To deprive results in deprivation
To customize results in customization
To observe results in observation
To explore results in exploration
To consult results in consulation
To reorganize results in reorganization
To compile results in
2024-07-30 19:14:01 root INFO     total operator prediction time: 978.1945567131042 seconds
2024-07-30 19:14:01 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on adj+ly_reg
2024-07-30 19:14:01 root INFO     building operator adj+ly_reg
2024-07-30 19:14:02 root INFO     [order_1_approx] starting weight calculation for The adjective form of increasing is increasingly
The adjective form of virtual is virtually
The adjective form of federal is federally
The adjective form of physical is physically
The adjective form of additional is additionally
The adjective form of internal is internally
The adjective form of international is internationally
The adjective form of actual is
2024-07-30 19:14:02 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-30 19:16:07 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2295, -0.1677, -0.3669,  ..., -0.6777, -0.3838, -0.1484],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.7461, -2.6172,  1.9658,  ..., -0.3242, -1.4678, -1.2070],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.1005, -0.0260,  0.0034,  ...,  0.0011,  0.0143,  0.0302],
        [ 0.0088,  0.0850,  0.0179,  ...,  0.0341,  0.0114,  0.0102],
        [ 0.0062, -0.0192,  0.0921,  ...,  0.0075, -0.0033, -0.0202],
        ...,
        [ 0.0089,  0.0435, -0.0182,  ...,  0.0768, -0.0063, -0.0027],
        [ 0.0022,  0.0192,  0.0222,  ..., -0.0089,  0.0618, -0.0044],
        [ 0.0273, -0.0150, -0.0091,  ..., -0.0037, -0.0378,  0.0767]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.6328, -2.7148,  1.9756,  ...,  0.1196, -1.1016, -1.1191]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 19:16:23 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The adjective form of increasing is increasingly
The adjective form of virtual is virtually
The adjective form of federal is federally
The adjective form of physical is physically
The adjective form of additional is additionally
The adjective form of internal is internally
The adjective form of international is internationally
The adjective form of actual is
2024-07-30 19:16:23 root INFO     [order_1_approx] starting weight calculation for The adjective form of additional is additionally
The adjective form of virtual is virtually
The adjective form of internal is internally
The adjective form of actual is actually
The adjective form of international is internationally
The adjective form of physical is physically
The adjective form of federal is federally
The adjective form of increasing is
2024-07-30 19:16:23 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-30 19:18:28 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0615, -0.1713, -0.4407,  ...,  0.1366, -0.2590, -0.5923],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.7690, -2.4629,  0.4932,  ..., -0.2871, -2.2695, -1.4053],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0708, -0.0096, -0.0034,  ..., -0.0058,  0.0164,  0.0191],
        [ 0.0229,  0.0457,  0.0031,  ...,  0.0232,  0.0109,  0.0080],
        [ 0.0245,  0.0067,  0.0275,  ...,  0.0007,  0.0139, -0.0103],
        ...,
        [-0.0050,  0.0177,  0.0183,  ...,  0.0681, -0.0106,  0.0195],
        [-0.0201,  0.0221, -0.0097,  ..., -0.0088,  0.0535, -0.0020],
        [ 0.0011, -0.0065, -0.0039,  ..., -0.0034, -0.0118,  0.0489]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.7300, -3.0859,  0.9990,  ..., -0.3186, -1.9092, -1.1914]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 19:18:28 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The adjective form of additional is additionally
The adjective form of virtual is virtually
The adjective form of internal is internally
The adjective form of actual is actually
The adjective form of international is internationally
The adjective form of physical is physically
The adjective form of federal is federally
The adjective form of increasing is
2024-07-30 19:18:29 root INFO     [order_1_approx] starting weight calculation for The adjective form of physical is physically
The adjective form of federal is federally
The adjective form of international is internationally
The adjective form of actual is actually
The adjective form of internal is internally
The adjective form of additional is additionally
The adjective form of increasing is increasingly
The adjective form of virtual is
2024-07-30 19:18:29 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-30 19:20:36 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.5000, -0.1445,  0.1948,  ..., -0.4580,  0.0574,  0.3916],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.0371, -3.1035,  0.4312,  ..., -2.9141, -0.1016, -0.0049],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.1257, -0.0126,  0.0111,  ..., -0.0040,  0.0139,  0.0108],
        [ 0.0273,  0.1063, -0.0005,  ...,  0.0334,  0.0103,  0.0068],
        [ 0.0320, -0.0273,  0.1221,  ...,  0.0026, -0.0124,  0.0136],
        ...,
        [ 0.0349,  0.0304,  0.0043,  ...,  0.1078,  0.0087,  0.0166],
        [ 0.0021,  0.0401, -0.0134,  ..., -0.0157,  0.0910, -0.0176],
        [ 0.0219,  0.0143, -0.0006,  ..., -0.0158, -0.0239,  0.0923]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.1378, -3.3340,  0.2888,  ..., -2.7617,  0.1567, -0.1862]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 19:20:37 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The adjective form of physical is physically
The adjective form of federal is federally
The adjective form of international is internationally
The adjective form of actual is actually
The adjective form of internal is internally
The adjective form of additional is additionally
The adjective form of increasing is increasingly
The adjective form of virtual is
2024-07-30 19:20:37 root INFO     [order_1_approx] starting weight calculation for The adjective form of international is internationally
The adjective form of increasing is increasingly
The adjective form of actual is actually
The adjective form of federal is federally
The adjective form of internal is internally
The adjective form of physical is physically
The adjective form of virtual is virtually
The adjective form of additional is
2024-07-30 19:20:37 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-30 19:22:41 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.6245, -0.3120, -0.4521,  ..., -0.3853, -0.4077, -0.1781],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.2236, -2.3242, -0.3794,  ...,  1.0938, -1.5850, -1.2207],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0831, -0.0017,  0.0166,  ..., -0.0103,  0.0196,  0.0173],
        [ 0.0177,  0.0370, -0.0116,  ...,  0.0361, -0.0161,  0.0159],
        [ 0.0050,  0.0002,  0.0601,  ...,  0.0183,  0.0038, -0.0115],
        ...,
        [ 0.0041,  0.0100,  0.0129,  ...,  0.0861,  0.0014,  0.0235],
        [ 0.0049,  0.0171, -0.0022,  ..., -0.0172,  0.0544, -0.0054],
        [ 0.0165, -0.0060, -0.0077,  ..., -0.0084, -0.0370,  0.0701]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.2651, -2.7734,  0.1096,  ...,  0.8701, -1.4766, -1.1016]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 19:22:42 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The adjective form of international is internationally
The adjective form of increasing is increasingly
The adjective form of actual is actually
The adjective form of federal is federally
The adjective form of internal is internally
The adjective form of physical is physically
The adjective form of virtual is virtually
The adjective form of additional is
2024-07-30 19:22:42 root INFO     [order_1_approx] starting weight calculation for The adjective form of international is internationally
The adjective form of federal is federally
The adjective form of additional is additionally
The adjective form of physical is physically
The adjective form of virtual is virtually
The adjective form of increasing is increasingly
The adjective form of actual is actually
The adjective form of internal is
2024-07-30 19:22:42 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-30 19:24:49 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2419, -0.2612,  0.3188,  ..., -0.7534, -0.0848,  0.1797],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.4526, -1.3506,  1.6094,  ..., -4.0664,  1.2178, -3.1699],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.1125, -0.0239, -0.0129,  ...,  0.0077,  0.0172,  0.0010],
        [ 0.0079,  0.0833,  0.0101,  ..., -0.0044,  0.0029, -0.0119],
        [ 0.0094, -0.0031,  0.1030,  ...,  0.0202,  0.0217, -0.0068],
        ...,
        [-0.0039,  0.0162, -0.0046,  ...,  0.0815,  0.0117,  0.0105],
        [ 0.0139,  0.0361, -0.0385,  ...,  0.0342,  0.0928, -0.0296],
        [ 0.0081, -0.0243, -0.0060,  ..., -0.0003, -0.0356,  0.0917]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.5938, -1.5527,  1.7705,  ..., -3.6016,  0.9990, -3.4551]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 19:24:55 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The adjective form of international is internationally
The adjective form of federal is federally
The adjective form of additional is additionally
The adjective form of physical is physically
The adjective form of virtual is virtually
The adjective form of increasing is increasingly
The adjective form of actual is actually
The adjective form of internal is
2024-07-30 19:24:58 root INFO     [order_1_approx] starting weight calculation for The adjective form of increasing is increasingly
The adjective form of physical is physically
The adjective form of international is internationally
The adjective form of virtual is virtually
The adjective form of internal is internally
The adjective form of actual is actually
The adjective form of additional is additionally
The adjective form of federal is
2024-07-30 19:24:58 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-30 19:27:06 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2930,  0.1537, -0.6816,  ..., -0.3521, -0.3657, -0.4023],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.2676, -1.5977,  4.1250,  ..., -1.7275, -0.4292, -0.8320],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0889, -0.0267, -0.0070,  ...,  0.0114,  0.0180,  0.0021],
        [ 0.0120,  0.0737,  0.0042,  ...,  0.0300,  0.0039, -0.0108],
        [ 0.0103,  0.0289,  0.0560,  ...,  0.0159,  0.0237, -0.0139],
        ...,
        [-0.0137,  0.0203, -0.0108,  ...,  0.0683,  0.0191, -0.0091],
        [-0.0003,  0.0148,  0.0137,  ...,  0.0178,  0.0566, -0.0111],
        [ 0.0144, -0.0144, -0.0206,  ...,  0.0036, -0.0335,  0.0781]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.4629, -1.3711,  4.2930,  ..., -1.5225,  0.0627, -1.4814]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 19:27:07 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The adjective form of increasing is increasingly
The adjective form of physical is physically
The adjective form of international is internationally
The adjective form of virtual is virtually
The adjective form of internal is internally
The adjective form of actual is actually
The adjective form of additional is additionally
The adjective form of federal is
2024-07-30 19:27:07 root INFO     [order_1_approx] starting weight calculation for The adjective form of increasing is increasingly
The adjective form of virtual is virtually
The adjective form of additional is additionally
The adjective form of actual is actually
The adjective form of internal is internally
The adjective form of physical is physically
The adjective form of federal is federally
The adjective form of international is
2024-07-30 19:27:07 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-30 19:29:11 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1528,  0.1519, -0.1633,  ..., -0.2817, -0.5859, -0.3110],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.3135, -2.1934,  0.4084,  ..., -2.4570,  0.4658, -0.9287],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0670, -0.0139, -0.0089,  ...,  0.0150,  0.0024, -0.0033],
        [ 0.0011,  0.0699,  0.0152,  ...,  0.0095,  0.0062,  0.0141],
        [ 0.0237,  0.0149,  0.0475,  ...,  0.0281,  0.0054, -0.0046],
        ...,
        [-0.0003,  0.0291, -0.0020,  ...,  0.0502,  0.0172,  0.0124],
        [ 0.0066,  0.0216,  0.0141,  ...,  0.0018,  0.0543,  0.0027],
        [ 0.0112, -0.0112,  0.0080,  ..., -0.0048, -0.0160,  0.0631]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.9355, -2.4180,  0.8242,  ..., -2.8008,  0.2382, -1.0713]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 19:29:13 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The adjective form of increasing is increasingly
The adjective form of virtual is virtually
The adjective form of additional is additionally
The adjective form of actual is actually
The adjective form of internal is internally
The adjective form of physical is physically
The adjective form of federal is federally
The adjective form of international is
2024-07-30 19:29:13 root INFO     [order_1_approx] starting weight calculation for The adjective form of international is internationally
The adjective form of increasing is increasingly
The adjective form of federal is federally
The adjective form of actual is actually
The adjective form of virtual is virtually
The adjective form of additional is additionally
The adjective form of internal is internally
The adjective form of physical is
2024-07-30 19:29:13 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-30 19:31:17 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0105, -0.0267, -0.3853,  ..., -0.7891, -0.6938, -0.0207],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.3105, -2.8145,  1.2539,  ..., -3.3125, -2.2266, -2.0840],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0933, -0.0201, -0.0078,  ..., -0.0084,  0.0068,  0.0047],
        [ 0.0079,  0.0840, -0.0072,  ..., -0.0027,  0.0429,  0.0007],
        [ 0.0107, -0.0251,  0.0731,  ...,  0.0095,  0.0050, -0.0089],
        ...,
        [ 0.0213,  0.0132, -0.0093,  ...,  0.0620,  0.0050, -0.0041],
        [ 0.0105,  0.0101,  0.0323,  ..., -0.0167,  0.0554, -0.0155],
        [-0.0010,  0.0057, -0.0185,  ..., -0.0071, -0.0124,  0.0819]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.8013, -2.3750,  1.2852,  ..., -2.9766, -1.9023, -2.3730]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 19:31:18 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The adjective form of international is internationally
The adjective form of increasing is increasingly
The adjective form of federal is federally
The adjective form of actual is actually
The adjective form of virtual is virtually
The adjective form of additional is additionally
The adjective form of internal is internally
The adjective form of physical is
2024-07-30 19:31:18 root INFO     total operator prediction time: 1036.271656513214 seconds
2024-07-30 19:31:18 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on over+adj_reg
2024-07-30 19:31:18 root INFO     building operator over+adj_reg
2024-07-30 19:31:18 root INFO     [order_1_approx] starting weight calculation for If something is too saturated, it is oversaturated
If something is too cooked, it is overcooked
If something is too stocked, it is overstocked
If something is too protected, it is overprotected
If something is too spent, it is overspent
If something is too excited, it is overexcited
If something is too sized, it is oversized
If something is too turned, it is
2024-07-30 19:31:18 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-30 19:33:24 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1566, -0.0583, -0.3159,  ...,  0.3013, -0.1022, -0.0360],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.5840, -3.7891,  1.6475,  ..., -0.4243, -0.9668, -0.8779],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.1016,  0.0186, -0.0016,  ...,  0.0017,  0.0109,  0.0192],
        [ 0.0043,  0.0912, -0.0163,  ...,  0.0189, -0.0043, -0.0195],
        [ 0.0536, -0.0328,  0.0967,  ...,  0.0142,  0.0065,  0.0155],
        ...,
        [ 0.0219,  0.0230,  0.0150,  ...,  0.1129,  0.0247, -0.0047],
        [-0.0156, -0.0007,  0.0156,  ..., -0.0003,  0.0894, -0.0414],
        [-0.0070,  0.0316,  0.0075,  ..., -0.0296, -0.0279,  0.1078]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.7559, -3.9805,  1.1768,  ..., -0.5947, -0.9688, -1.0938]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 19:33:31 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is too saturated, it is oversaturated
If something is too cooked, it is overcooked
If something is too stocked, it is overstocked
If something is too protected, it is overprotected
If something is too spent, it is overspent
If something is too excited, it is overexcited
If something is too sized, it is oversized
If something is too turned, it is
2024-07-30 19:33:32 root INFO     [order_1_approx] starting weight calculation for If something is too excited, it is overexcited
If something is too protected, it is overprotected
If something is too turned, it is overturned
If something is too cooked, it is overcooked
If something is too spent, it is overspent
If something is too saturated, it is oversaturated
If something is too sized, it is oversized
If something is too stocked, it is
2024-07-30 19:33:32 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-30 19:35:34 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1997,  0.2756, -0.6265,  ..., -0.1163, -0.1787,  0.3474],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.3643, -2.6465, -0.0210,  ..., -0.7559, -1.3447, -1.6504],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0713, -0.0097, -0.0011,  ..., -0.0024,  0.0119,  0.0111],
        [ 0.0009,  0.0620, -0.0044,  ...,  0.0130,  0.0110, -0.0045],
        [ 0.0075, -0.0038,  0.0465,  ..., -0.0003, -0.0047,  0.0089],
        ...,
        [-0.0040, -0.0024,  0.0068,  ...,  0.0790,  0.0142,  0.0009],
        [-0.0183,  0.0107,  0.0042,  ...,  0.0045,  0.0746, -0.0270],
        [-0.0025, -0.0159, -0.0069,  ..., -0.0150, -0.0161,  0.0589]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.5342, -2.6797,  0.0901,  ..., -0.8052, -0.8848, -1.4307]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 19:35:35 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is too excited, it is overexcited
If something is too protected, it is overprotected
If something is too turned, it is overturned
If something is too cooked, it is overcooked
If something is too spent, it is overspent
If something is too saturated, it is oversaturated
If something is too sized, it is oversized
If something is too stocked, it is
2024-07-30 19:35:35 root INFO     [order_1_approx] starting weight calculation for If something is too protected, it is overprotected
If something is too spent, it is overspent
If something is too saturated, it is oversaturated
If something is too excited, it is overexcited
If something is too turned, it is overturned
If something is too cooked, it is overcooked
If something is too stocked, it is overstocked
If something is too sized, it is
2024-07-30 19:35:36 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-30 19:37:41 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0776, -0.6016, -0.8169,  ..., -0.7480, -0.4326,  0.0891],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.3438, -3.0898, -1.4941,  ...,  0.5166, -2.6504,  0.3633],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.1011, -0.0057,  0.0011,  ..., -0.0091,  0.0148,  0.0005],
        [ 0.0240,  0.0944, -0.0026,  ...,  0.0099, -0.0019, -0.0026],
        [ 0.0136, -0.0178,  0.0757,  ..., -0.0136,  0.0027,  0.0080],
        ...,
        [-0.0002,  0.0006,  0.0125,  ...,  0.1163,  0.0055,  0.0126],
        [-0.0070,  0.0096,  0.0105,  ...,  0.0066,  0.0837, -0.0183],
        [-0.0071,  0.0151,  0.0070,  ..., -0.0163, -0.0273,  0.0952]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.7559, -3.2207, -1.3926,  ...,  0.8516, -2.3398,  0.2202]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 19:37:42 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is too protected, it is overprotected
If something is too spent, it is overspent
If something is too saturated, it is oversaturated
If something is too excited, it is overexcited
If something is too turned, it is overturned
If something is too cooked, it is overcooked
If something is too stocked, it is overstocked
If something is too sized, it is
2024-07-30 19:37:42 root INFO     [order_1_approx] starting weight calculation for If something is too protected, it is overprotected
If something is too saturated, it is oversaturated
If something is too sized, it is oversized
If something is too turned, it is overturned
If something is too excited, it is overexcited
If something is too spent, it is overspent
If something is too stocked, it is overstocked
If something is too cooked, it is
2024-07-30 19:37:42 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-30 19:39:44 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4688, -0.1599, -0.1405,  ..., -0.7256, -0.7827,  0.3516],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.9502, -2.6230,  0.3799,  ..., -0.8589, -1.5410, -0.7305],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0683, -0.0003, -0.0045,  ...,  0.0015,  0.0094,  0.0175],
        [-0.0046,  0.0576, -0.0039,  ...,  0.0063,  0.0015, -0.0308],
        [ 0.0130, -0.0138,  0.0462,  ..., -0.0027,  0.0037,  0.0103],
        ...,
        [ 0.0011, -0.0006,  0.0036,  ...,  0.0554, -0.0019,  0.0054],
        [-0.0041,  0.0084, -0.0026,  ...,  0.0047,  0.0485, -0.0196],
        [-0.0042,  0.0023,  0.0030,  ..., -0.0126, -0.0085,  0.0590]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.9170, -2.2910,  0.4849,  ..., -0.8613, -1.2314, -0.5972]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 19:39:45 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is too protected, it is overprotected
If something is too saturated, it is oversaturated
If something is too sized, it is oversized
If something is too turned, it is overturned
If something is too excited, it is overexcited
If something is too spent, it is overspent
If something is too stocked, it is overstocked
If something is too cooked, it is
2024-07-30 19:39:45 root INFO     [order_1_approx] starting weight calculation for If something is too spent, it is overspent
If something is too saturated, it is oversaturated
If something is too sized, it is oversized
If something is too cooked, it is overcooked
If something is too excited, it is overexcited
If something is too turned, it is overturned
If something is too stocked, it is overstocked
If something is too protected, it is
2024-07-30 19:39:45 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-30 19:41:52 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3782, -0.4050, -0.4219,  ..., -0.1858, -0.4119,  0.1550],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.8906, -3.7461,  1.4258,  ..., -0.0977, -1.2939, -2.9883],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0742, -0.0120, -0.0052,  ..., -0.0029,  0.0088,  0.0106],
        [-0.0139,  0.0777, -0.0014,  ...,  0.0088,  0.0093, -0.0074],
        [ 0.0152, -0.0074,  0.0724,  ...,  0.0161,  0.0139,  0.0098],
        ...,
        [-0.0085,  0.0173,  0.0042,  ...,  0.0861,  0.0032,  0.0055],
        [-0.0017,  0.0106, -0.0060,  ...,  0.0080,  0.0950, -0.0389],
        [ 0.0118,  0.0112, -0.0132,  ..., -0.0067, -0.0163,  0.0858]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.9688, -3.6270,  1.4590,  ...,  0.0734, -1.3604, -2.9766]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 19:41:55 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is too spent, it is overspent
If something is too saturated, it is oversaturated
If something is too sized, it is oversized
If something is too cooked, it is overcooked
If something is too excited, it is overexcited
If something is too turned, it is overturned
If something is too stocked, it is overstocked
If something is too protected, it is
2024-07-30 19:41:55 root INFO     [order_1_approx] starting weight calculation for If something is too excited, it is overexcited
If something is too protected, it is overprotected
If something is too cooked, it is overcooked
If something is too spent, it is overspent
If something is too sized, it is oversized
If something is too turned, it is overturned
If something is too stocked, it is overstocked
If something is too saturated, it is
2024-07-30 19:41:55 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-30 19:44:02 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0267,  0.0486, -0.4268,  ..., -0.0703, -0.4556, -0.0032],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.2305, -2.1016,  0.2944,  ..., -2.0176, -1.0645, -0.9277],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0843, -0.0107, -0.0015,  ..., -0.0120, -0.0062,  0.0070],
        [ 0.0066,  0.0833,  0.0121,  ...,  0.0025,  0.0097, -0.0036],
        [ 0.0109,  0.0019,  0.0461,  ..., -0.0139, -0.0017,  0.0032],
        ...,
        [ 0.0014,  0.0102,  0.0007,  ...,  0.0734,  0.0076,  0.0136],
        [-0.0075,  0.0007,  0.0041,  ...,  0.0043,  0.0700, -0.0095],
        [-0.0104, -0.0003, -0.0079,  ..., -0.0133, -0.0136,  0.0710]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.3047, -2.2539,  0.3269,  ..., -1.8496, -1.1025, -0.9785]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 19:44:03 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is too excited, it is overexcited
If something is too protected, it is overprotected
If something is too cooked, it is overcooked
If something is too spent, it is overspent
If something is too sized, it is oversized
If something is too turned, it is overturned
If something is too stocked, it is overstocked
If something is too saturated, it is
2024-07-30 19:44:03 root INFO     [order_1_approx] starting weight calculation for If something is too cooked, it is overcooked
If something is too saturated, it is oversaturated
If something is too turned, it is overturned
If something is too stocked, it is overstocked
If something is too sized, it is oversized
If something is too excited, it is overexcited
If something is too protected, it is overprotected
If something is too spent, it is
2024-07-30 19:44:04 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-30 19:46:09 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0719, -0.1621, -0.3152,  ..., -0.2756, -0.1660, -0.0677],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.0820, -3.7539, -0.9463,  ..., -2.1250, -1.0752, -2.4297],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 8.3435e-02,  8.9645e-04,  1.4114e-02,  ..., -6.9923e-03,
          1.2337e-02,  1.6876e-02],
        [-4.2114e-03,  6.6162e-02, -2.0645e-02,  ...,  3.3478e-02,
          1.8448e-02, -1.8787e-03],
        [ 4.0253e-02, -1.0849e-02,  8.0383e-02,  ..., -6.4850e-03,
         -2.5787e-03, -1.0284e-02],
        ...,
        [-3.1166e-03,  2.2217e-02, -9.4376e-03,  ...,  8.9417e-02,
          4.7073e-03,  3.9482e-04],
        [-8.4305e-03,  3.5896e-03,  4.7760e-03,  ...,  2.0981e-02,
          6.3843e-02, -2.1240e-02],
        [-4.4708e-03,  1.5366e-02,  1.9073e-05,  ..., -2.3079e-03,
         -9.0790e-03,  9.0210e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.4668, -3.4883, -1.3750,  ..., -1.8525, -0.9009, -2.3496]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 19:46:09 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is too cooked, it is overcooked
If something is too saturated, it is oversaturated
If something is too turned, it is overturned
If something is too stocked, it is overstocked
If something is too sized, it is oversized
If something is too excited, it is overexcited
If something is too protected, it is overprotected
If something is too spent, it is
2024-07-30 19:46:10 root INFO     [order_1_approx] starting weight calculation for If something is too cooked, it is overcooked
If something is too spent, it is overspent
If something is too saturated, it is oversaturated
If something is too turned, it is overturned
If something is too protected, it is overprotected
If something is too stocked, it is overstocked
If something is too sized, it is oversized
If something is too excited, it is
2024-07-30 19:46:10 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-30 19:48:14 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2026, -0.4343, -0.9146,  ...,  0.1284, -0.7080,  0.2413],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.6855, -4.0820,  0.2725,  ...,  0.2930, -0.6724, -1.5957],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0660,  0.0014, -0.0145,  ..., -0.0119,  0.0211,  0.0131],
        [ 0.0021,  0.0668, -0.0059,  ...,  0.0124,  0.0012, -0.0048],
        [ 0.0321, -0.0102,  0.0664,  ...,  0.0046,  0.0023,  0.0043],
        ...,
        [-0.0123,  0.0124,  0.0075,  ...,  0.0767,  0.0018,  0.0083],
        [-0.0026,  0.0158,  0.0038,  ...,  0.0052,  0.0829, -0.0482],
        [ 0.0034, -0.0147,  0.0115,  ..., -0.0011, -0.0251,  0.0663]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.5293, -4.0195,  0.2380,  ...,  0.4695, -0.7661, -1.4492]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 19:48:15 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is too cooked, it is overcooked
If something is too spent, it is overspent
If something is too saturated, it is oversaturated
If something is too turned, it is overturned
If something is too protected, it is overprotected
If something is too stocked, it is overstocked
If something is too sized, it is oversized
If something is too excited, it is
2024-07-30 19:48:15 root INFO     total operator prediction time: 1017.8192481994629 seconds
2024-07-30 19:48:15 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on verb+er_irreg
2024-07-30 19:48:15 root INFO     building operator verb+er_irreg
2024-07-30 19:48:16 root INFO     [order_1_approx] starting weight calculation for If you develop something, you are a developer
If you recommend something, you are a recommender
If you eat something, you are a eater
If you learn something, you are a learner
If you examine something, you are a examiner
If you molest something, you are a molester
If you perform something, you are a performer
If you advertise something, you are a
2024-07-30 19:48:16 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-30 19:50:18 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1136, -0.0631, -0.0574,  ...,  0.1390, -0.2898, -0.3345],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 5.6250, -2.5078, -0.2849,  ...,  1.8057, -6.3633, -2.6094],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0348, -0.0014,  0.0115,  ...,  0.0031, -0.0076,  0.0029],
        [-0.0167,  0.0387, -0.0012,  ...,  0.0177,  0.0049, -0.0099],
        [ 0.0074, -0.0072,  0.0358,  ..., -0.0119, -0.0104,  0.0055],
        ...,
        [ 0.0069,  0.0080,  0.0083,  ...,  0.0341,  0.0066,  0.0025],
        [-0.0075,  0.0051,  0.0018,  ..., -0.0036,  0.0260, -0.0115],
        [ 0.0096, -0.0002,  0.0012,  ..., -0.0031, -0.0106,  0.0251]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 5.5234, -2.5410, -0.2822,  ...,  1.8701, -6.1641, -2.7422]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 19:50:26 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you develop something, you are a developer
If you recommend something, you are a recommender
If you eat something, you are a eater
If you learn something, you are a learner
If you examine something, you are a examiner
If you molest something, you are a molester
If you perform something, you are a performer
If you advertise something, you are a
2024-07-30 19:50:26 root INFO     [order_1_approx] starting weight calculation for If you examine something, you are a examiner
If you molest something, you are a molester
If you perform something, you are a performer
If you eat something, you are a eater
If you advertise something, you are a advertiser
If you recommend something, you are a recommender
If you develop something, you are a developer
If you learn something, you are a
2024-07-30 19:50:26 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-30 19:52:29 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1731, -0.5469,  0.4351,  ..., -0.3777, -0.5601,  0.0765],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.7080, -2.4258,  2.1855,  ...,  1.7539, -4.8594, -5.4805],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0264,  0.0021, -0.0038,  ..., -0.0024,  0.0015,  0.0135],
        [-0.0092,  0.0373,  0.0055,  ...,  0.0121,  0.0007, -0.0079],
        [ 0.0065, -0.0156,  0.0359,  ..., -0.0049, -0.0057, -0.0005],
        ...,
        [ 0.0147,  0.0061,  0.0023,  ...,  0.0321, -0.0104, -0.0010],
        [-0.0039,  0.0098,  0.0080,  ..., -0.0114,  0.0273, -0.0117],
        [-0.0044,  0.0035,  0.0160,  ..., -0.0130, -0.0020,  0.0205]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.5991, -2.3184,  2.1055,  ...,  2.2344, -4.8867, -5.6211]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 19:52:30 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you examine something, you are a examiner
If you molest something, you are a molester
If you perform something, you are a performer
If you eat something, you are a eater
If you advertise something, you are a advertiser
If you recommend something, you are a recommender
If you develop something, you are a developer
If you learn something, you are a
2024-07-30 19:52:31 root INFO     [order_1_approx] starting weight calculation for If you examine something, you are a examiner
If you eat something, you are a eater
If you molest something, you are a molester
If you learn something, you are a learner
If you perform something, you are a performer
If you recommend something, you are a recommender
If you advertise something, you are a advertiser
If you develop something, you are a
2024-07-30 19:52:31 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-30 19:54:34 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3987,  0.1376, -0.0090,  ..., -0.0500, -0.1027, -0.5732],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.7969, -4.2812,  2.6172,  ...,  2.2773, -5.2656, -2.4375],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0624,  0.0096,  0.0036,  ...,  0.0045, -0.0053,  0.0129],
        [-0.0103,  0.0677, -0.0031,  ...,  0.0183,  0.0081, -0.0068],
        [ 0.0039, -0.0095,  0.0535,  ..., -0.0050, -0.0044, -0.0083],
        ...,
        [ 0.0222,  0.0046,  0.0114,  ...,  0.0661, -0.0131, -0.0090],
        [-0.0006, -0.0022,  0.0148,  ..., -0.0175,  0.0415, -0.0074],
        [ 0.0125, -0.0036, -0.0033,  ..., -0.0100, -0.0293,  0.0426]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.9492, -4.2578,  2.8438,  ...,  2.6094, -5.4023, -2.1348]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 19:54:35 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you examine something, you are a examiner
If you eat something, you are a eater
If you molest something, you are a molester
If you learn something, you are a learner
If you perform something, you are a performer
If you recommend something, you are a recommender
If you advertise something, you are a advertiser
If you develop something, you are a
2024-07-30 19:54:35 root INFO     [order_1_approx] starting weight calculation for If you advertise something, you are a advertiser
If you perform something, you are a performer
If you learn something, you are a learner
If you develop something, you are a developer
If you eat something, you are a eater
If you recommend something, you are a recommender
If you molest something, you are a molester
If you examine something, you are a
2024-07-30 19:54:35 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-30 19:56:41 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.3635, -0.2729,  0.1847,  ..., -0.3826, -0.1716, -0.1801],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.3457, -1.5605,  0.4575,  ..., -2.4219, -4.3242, -5.2891],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0592, -0.0031,  0.0040,  ...,  0.0182, -0.0110,  0.0177],
        [-0.0011,  0.0621, -0.0005,  ...,  0.0116,  0.0156, -0.0105],
        [ 0.0103, -0.0032,  0.0659,  ..., -0.0038, -0.0008, -0.0072],
        ...,
        [ 0.0100,  0.0127,  0.0008,  ...,  0.0678,  0.0023, -0.0154],
        [-0.0070, -0.0034,  0.0070,  ..., -0.0093,  0.0336, -0.0051],
        [ 0.0135,  0.0048,  0.0157,  ..., -0.0007, -0.0201,  0.0554]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.8125, -1.8379,  0.3635,  ..., -1.8027, -4.3945, -5.1211]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 19:56:42 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you advertise something, you are a advertiser
If you perform something, you are a performer
If you learn something, you are a learner
If you develop something, you are a developer
If you eat something, you are a eater
If you recommend something, you are a recommender
If you molest something, you are a molester
If you examine something, you are a
2024-07-30 19:56:42 root INFO     [order_1_approx] starting weight calculation for If you advertise something, you are a advertiser
If you molest something, you are a molester
If you examine something, you are a examiner
If you learn something, you are a learner
If you develop something, you are a developer
If you recommend something, you are a recommender
If you eat something, you are a eater
If you perform something, you are a
2024-07-30 19:56:42 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-30 19:58:48 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2056,  0.2339,  0.0560,  ..., -0.3110, -0.4409,  0.0348],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.9434, -3.0195,  2.4629,  ..., -0.3096, -3.3965, -3.1797],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0555,  0.0063, -0.0040,  ...,  0.0045,  0.0015,  0.0077],
        [-0.0042,  0.0437, -0.0053,  ...,  0.0260,  0.0204, -0.0096],
        [ 0.0129, -0.0012,  0.0420,  ...,  0.0121, -0.0073,  0.0135],
        ...,
        [ 0.0081,  0.0062, -0.0083,  ...,  0.0365,  0.0244, -0.0168],
        [-0.0033,  0.0182,  0.0108,  ..., -0.0182,  0.0399, -0.0052],
        [ 0.0176, -0.0019,  0.0156,  ..., -0.0076, -0.0217,  0.0425]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.1660, -2.9297,  2.4082,  ...,  0.4287, -3.2695, -3.2832]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 19:58:49 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you advertise something, you are a advertiser
If you molest something, you are a molester
If you examine something, you are a examiner
If you learn something, you are a learner
If you develop something, you are a developer
If you recommend something, you are a recommender
If you eat something, you are a eater
If you perform something, you are a
2024-07-30 19:58:49 root INFO     [order_1_approx] starting weight calculation for If you develop something, you are a developer
If you eat something, you are a eater
If you examine something, you are a examiner
If you advertise something, you are a advertiser
If you molest something, you are a molester
If you perform something, you are a performer
If you learn something, you are a learner
If you recommend something, you are a
2024-07-30 19:58:49 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-30 20:00:55 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.4236, -0.0834,  0.6875,  ...,  0.2426,  0.2050, -0.2852],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.6074, -1.6758,  1.8096,  ...,  1.2188, -6.4844, -3.9453],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0544,  0.0033,  0.0077,  ...,  0.0219, -0.0173,  0.0123],
        [-0.0236,  0.0549,  0.0013,  ...,  0.0268, -0.0009, -0.0130],
        [ 0.0176, -0.0146,  0.0410,  ..., -0.0027, -0.0245,  0.0187],
        ...,
        [ 0.0022,  0.0142,  0.0005,  ...,  0.0734,  0.0063, -0.0006],
        [-0.0069,  0.0028,  0.0133,  ..., -0.0166,  0.0479, -0.0223],
        [ 0.0144,  0.0082,  0.0066,  ..., -0.0284, -0.0224,  0.0212]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.6445, -1.9092,  1.7432,  ...,  1.7129, -6.2266, -4.4805]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 20:00:56 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you develop something, you are a developer
If you eat something, you are a eater
If you examine something, you are a examiner
If you advertise something, you are a advertiser
If you molest something, you are a molester
If you perform something, you are a performer
If you learn something, you are a learner
If you recommend something, you are a
2024-07-30 20:00:56 root INFO     [order_1_approx] starting weight calculation for If you examine something, you are a examiner
If you learn something, you are a learner
If you recommend something, you are a recommender
If you develop something, you are a developer
If you molest something, you are a molester
If you advertise something, you are a advertiser
If you perform something, you are a performer
If you eat something, you are a
2024-07-30 20:00:56 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-30 20:03:00 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.5962, -0.8354,  0.3137,  ..., -0.2502, -0.5347,  0.1256],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.9170, -0.5815,  0.2299,  ...,  0.6777, -7.5469, -3.9902],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0437,  0.0031, -0.0078,  ...,  0.0046, -0.0046,  0.0038],
        [-0.0043,  0.0480, -0.0074,  ...,  0.0084,  0.0123, -0.0109],
        [ 0.0085, -0.0148,  0.0378,  ..., -0.0012,  0.0003,  0.0005],
        ...,
        [ 0.0135,  0.0014,  0.0153,  ...,  0.0360, -0.0032, -0.0159],
        [-0.0067,  0.0229, -0.0057,  ..., -0.0183,  0.0289, -0.0029],
        [-0.0009, -0.0079,  0.0158,  ..., -0.0040, -0.0082,  0.0416]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.2480, -0.3748,  0.2598,  ...,  1.0391, -7.8984, -4.0039]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 20:03:01 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you examine something, you are a examiner
If you learn something, you are a learner
If you recommend something, you are a recommender
If you develop something, you are a developer
If you molest something, you are a molester
If you advertise something, you are a advertiser
If you perform something, you are a performer
If you eat something, you are a
2024-07-30 20:03:01 root INFO     [order_1_approx] starting weight calculation for If you eat something, you are a eater
If you recommend something, you are a recommender
If you develop something, you are a developer
If you examine something, you are a examiner
If you advertise something, you are a advertiser
If you perform something, you are a performer
If you learn something, you are a learner
If you molest something, you are a
2024-07-30 20:03:01 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-30 20:05:08 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2874, -0.1543,  0.0468,  ..., -0.4971, -0.4443,  0.2678],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.7617, -2.7969, -1.0088,  ..., -2.1035, -4.7656, -0.5010],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 6.0394e-02,  8.9722e-03,  2.7390e-02,  ...,  1.9012e-02,
          5.1546e-04, -2.6531e-03],
        [ 3.2272e-03,  3.8391e-02, -3.0655e-02,  ...,  3.9886e-02,
          9.4757e-03,  7.1335e-04],
        [ 2.3514e-02, -1.9791e-02,  5.3619e-02,  ...,  1.1261e-02,
          2.4529e-03, -5.3406e-05],
        ...,
        [ 1.1360e-02, -3.2349e-03,  6.8512e-03,  ...,  8.8623e-02,
          1.0803e-02,  1.6937e-02],
        [ 5.9319e-03,  9.8419e-03,  3.1769e-02,  ..., -1.4572e-02,
          5.6549e-02, -2.1713e-02],
        [ 1.0284e-02,  2.1851e-02,  5.1384e-03,  ..., -1.8341e-02,
         -1.9333e-02,  6.2042e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.8184, -2.4375, -0.3013,  ..., -1.7969, -4.4609, -0.8232]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 20:05:09 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you eat something, you are a eater
If you recommend something, you are a recommender
If you develop something, you are a developer
If you examine something, you are a examiner
If you advertise something, you are a advertiser
If you perform something, you are a performer
If you learn something, you are a learner
If you molest something, you are a
2024-07-30 20:05:09 root INFO     total operator prediction time: 1013.8941006660461 seconds
2024-07-30 20:05:09 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on adj - superlative
2024-07-30 20:05:09 root INFO     building operator adj - superlative
2024-07-30 20:05:10 root INFO     [order_1_approx] starting weight calculation for If something is the most rare, it is rarest
If something is the most lazy, it is laziest
If something is the most rude, it is rudest
If something is the most sad, it is saddest
If something is the most lucky, it is luckiest
If something is the most sunny, it is sunniest
If something is the most mild, it is mildest
If something is the most tricky, it is
2024-07-30 20:05:10 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-30 20:07:11 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0024, -0.0706, -0.1370,  ...,  0.0031, -0.1044,  0.1144],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.2732, -4.4805, -2.3125,  ..., -0.0613, -2.6934,  0.0840],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0701, -0.0027,  0.0186,  ...,  0.0124, -0.0023,  0.0188],
        [ 0.0011,  0.0576,  0.0303,  ...,  0.0050, -0.0022, -0.0034],
        [ 0.0381, -0.0033,  0.0647,  ...,  0.0098, -0.0037,  0.0107],
        ...,
        [ 0.0112,  0.0200,  0.0227,  ...,  0.0831, -0.0029, -0.0137],
        [ 0.0181, -0.0098,  0.0277,  ..., -0.0149,  0.0580, -0.0105],
        [ 0.0106, -0.0014,  0.0065,  ..., -0.0284, -0.0220,  0.0652]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.3745, -4.3125, -2.3965,  ...,  0.0786, -2.5488,  0.0468]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 20:07:13 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is the most rare, it is rarest
If something is the most lazy, it is laziest
If something is the most rude, it is rudest
If something is the most sad, it is saddest
If something is the most lucky, it is luckiest
If something is the most sunny, it is sunniest
If something is the most mild, it is mildest
If something is the most tricky, it is
2024-07-30 20:07:14 root INFO     [order_1_approx] starting weight calculation for If something is the most mild, it is mildest
If something is the most rude, it is rudest
If something is the most lazy, it is laziest
If something is the most sad, it is saddest
If something is the most rare, it is rarest
If something is the most lucky, it is luckiest
If something is the most tricky, it is trickiest
If something is the most sunny, it is
2024-07-30 20:07:14 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-30 20:09:18 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.3005,  0.2905, -0.6802,  ..., -0.4507, -0.1456, -0.6133],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.8018, -0.3965, -3.2363,  ...,  1.2529, -3.1680, -0.0596],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 6.7139e-02, -2.1698e-02,  5.6725e-03,  ..., -3.2616e-03,
          2.9335e-03,  1.5755e-03],
        [-1.4236e-02,  6.2744e-02,  3.0041e-03,  ..., -1.0345e-02,
          1.6159e-02,  2.8973e-03],
        [-7.0076e-03, -7.6294e-03,  5.7281e-02,  ..., -2.4681e-03,
         -1.1162e-02, -4.2114e-03],
        ...,
        [ 2.4124e-02,  1.6296e-02,  1.0216e-02,  ...,  6.0638e-02,
          2.8343e-03,  7.6294e-06],
        [-1.3199e-02, -2.2793e-03, -2.3308e-03,  ...,  3.1528e-03,
          4.6661e-02, -1.5427e-02],
        [-2.6703e-04,  5.6267e-05,  1.4816e-02,  ..., -1.7059e-02,
         -7.5340e-03,  4.6814e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.8242, -0.1609, -3.2363,  ...,  1.5645, -2.7305,  0.0387]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 20:09:19 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is the most mild, it is mildest
If something is the most rude, it is rudest
If something is the most lazy, it is laziest
If something is the most sad, it is saddest
If something is the most rare, it is rarest
If something is the most lucky, it is luckiest
If something is the most tricky, it is trickiest
If something is the most sunny, it is
2024-07-30 20:09:19 root INFO     [order_1_approx] starting weight calculation for If something is the most mild, it is mildest
If something is the most lucky, it is luckiest
If something is the most sad, it is saddest
If something is the most tricky, it is trickiest
If something is the most rare, it is rarest
If something is the most lazy, it is laziest
If something is the most sunny, it is sunniest
If something is the most rude, it is
2024-07-30 20:09:19 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-30 20:11:20 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0751,  0.0988, -0.0786,  ..., -0.2231,  0.2234, -0.0336],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-2.4648, -4.3633, -0.3901,  ..., -1.7725, -1.7324, -2.0176],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0646, -0.0089,  0.0172,  ..., -0.0112,  0.0169,  0.0060],
        [ 0.0114,  0.0536,  0.0146,  ..., -0.0328,  0.0052,  0.0027],
        [ 0.0083,  0.0061,  0.0721,  ..., -0.0046, -0.0168, -0.0059],
        ...,
        [ 0.0122,  0.0368,  0.0185,  ...,  0.0477, -0.0070, -0.0079],
        [-0.0165,  0.0049,  0.0084,  ..., -0.0006,  0.0450, -0.0177],
        [-0.0046, -0.0131,  0.0041,  ...,  0.0039,  0.0015,  0.0306]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-2.4395, -4.2930, -0.8223,  ..., -2.0469, -1.4697, -2.0391]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 20:11:21 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is the most mild, it is mildest
If something is the most lucky, it is luckiest
If something is the most sad, it is saddest
If something is the most tricky, it is trickiest
If something is the most rare, it is rarest
If something is the most lazy, it is laziest
If something is the most sunny, it is sunniest
If something is the most rude, it is
2024-07-30 20:11:21 root INFO     [order_1_approx] starting weight calculation for If something is the most sad, it is saddest
If something is the most rare, it is rarest
If something is the most tricky, it is trickiest
If something is the most mild, it is mildest
If something is the most rude, it is rudest
If something is the most sunny, it is sunniest
If something is the most lucky, it is luckiest
If something is the most lazy, it is
2024-07-30 20:11:21 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-30 20:13:19 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4026, -0.0555, -0.4500,  ..., -0.4141, -0.0757,  0.2162],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-2.9297, -4.9922, -1.9902,  ..., -1.9512, -0.9697, -2.5879],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0696, -0.0110,  0.0151,  ...,  0.0057,  0.0090,  0.0165],
        [-0.0018,  0.0323,  0.0131,  ...,  0.0020,  0.0080,  0.0059],
        [ 0.0092, -0.0188,  0.0547,  ...,  0.0022, -0.0076, -0.0049],
        ...,
        [ 0.0043,  0.0269, -0.0028,  ...,  0.0409, -0.0031, -0.0228],
        [-0.0092, -0.0034, -0.0167,  ..., -0.0111,  0.0424, -0.0188],
        [ 0.0085, -0.0122,  0.0159,  ..., -0.0249, -0.0181,  0.0381]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-3.2148, -4.7773, -2.2070,  ..., -1.4922, -0.6084, -2.4746]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 20:13:20 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is the most sad, it is saddest
If something is the most rare, it is rarest
If something is the most tricky, it is trickiest
If something is the most mild, it is mildest
If something is the most rude, it is rudest
If something is the most sunny, it is sunniest
If something is the most lucky, it is luckiest
If something is the most lazy, it is
2024-07-30 20:13:20 root INFO     [order_1_approx] starting weight calculation for If something is the most sad, it is saddest
If something is the most lazy, it is laziest
If something is the most lucky, it is luckiest
If something is the most rude, it is rudest
If something is the most tricky, it is trickiest
If something is the most mild, it is mildest
If something is the most sunny, it is sunniest
If something is the most rare, it is
2024-07-30 20:13:20 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-30 20:15:23 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2593, -0.3906, -0.8042,  ..., -0.6562,  0.6113, -0.0408],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-3.8867, -4.3047, -1.7412,  ..., -3.3848, -1.6113, -2.8672],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0559, -0.0099,  0.0237,  ..., -0.0143,  0.0071,  0.0224],
        [ 0.0122,  0.0667,  0.0212,  ...,  0.0045,  0.0049,  0.0091],
        [ 0.0157,  0.0029,  0.0499,  ..., -0.0059, -0.0198,  0.0193],
        ...,
        [ 0.0120,  0.0454,  0.0135,  ...,  0.0563, -0.0021,  0.0078],
        [-0.0115,  0.0051, -0.0004,  ...,  0.0114,  0.0374, -0.0349],
        [ 0.0138, -0.0072,  0.0105,  ..., -0.0222, -0.0022,  0.0567]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-3.8730, -4.2969, -1.9062,  ..., -3.9316, -1.6094, -3.0566]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 20:15:33 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is the most sad, it is saddest
If something is the most lazy, it is laziest
If something is the most lucky, it is luckiest
If something is the most rude, it is rudest
If something is the most tricky, it is trickiest
If something is the most mild, it is mildest
If something is the most sunny, it is sunniest
If something is the most rare, it is
2024-07-30 20:15:33 root INFO     [order_1_approx] starting weight calculation for If something is the most lucky, it is luckiest
If something is the most rude, it is rudest
If something is the most tricky, it is trickiest
If something is the most lazy, it is laziest
If something is the most sunny, it is sunniest
If something is the most mild, it is mildest
If something is the most rare, it is rarest
If something is the most sad, it is
2024-07-30 20:15:33 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-30 20:17:40 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1558, -0.1031, -0.3906,  ..., -0.1512, -0.5908,  0.3088],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.1660, -5.4609, -2.6914,  ..., -4.6289, -0.1777, -3.2031],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 3.6896e-02,  2.6932e-03,  8.4305e-03,  ...,  4.2725e-04,
          2.1629e-03,  1.6205e-02],
        [ 8.0948e-03,  1.6815e-02,  4.8714e-03,  ..., -2.5387e-03,
          1.6251e-03, -4.8447e-04],
        [-3.0251e-03, -1.1238e-02,  2.5482e-02,  ..., -4.4022e-03,
         -9.0332e-03, -5.6610e-03],
        ...,
        [-5.1117e-04,  1.9348e-02,  7.9117e-03,  ...,  3.3386e-02,
         -3.6926e-03,  1.1730e-03],
        [ 3.2730e-03, -1.0506e-02,  4.6425e-03,  ...,  1.2764e-02,
          2.5070e-02, -1.6907e-02],
        [ 7.0877e-03, -8.6784e-05,  5.5580e-03,  ..., -1.7349e-02,
         -6.4011e-03,  2.4384e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.0651, -5.0625, -2.8984,  ..., -4.5820,  0.0226, -2.8848]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 20:17:41 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is the most lucky, it is luckiest
If something is the most rude, it is rudest
If something is the most tricky, it is trickiest
If something is the most lazy, it is laziest
If something is the most sunny, it is sunniest
If something is the most mild, it is mildest
If something is the most rare, it is rarest
If something is the most sad, it is
2024-07-30 20:17:41 root INFO     [order_1_approx] starting weight calculation for If something is the most mild, it is mildest
If something is the most sad, it is saddest
If something is the most rare, it is rarest
If something is the most lazy, it is laziest
If something is the most sunny, it is sunniest
If something is the most rude, it is rudest
If something is the most tricky, it is trickiest
If something is the most lucky, it is
2024-07-30 20:17:41 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-30 20:19:41 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0193,  0.5137, -0.3987,  ..., -0.3364, -0.2744,  0.0325],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.0459, -3.2285, -3.5977,  ...,  0.1895, -0.9180, -1.5410],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0331, -0.0020,  0.0063,  ...,  0.0043, -0.0022,  0.0129],
        [ 0.0025,  0.0281,  0.0118,  ...,  0.0048, -0.0017, -0.0046],
        [ 0.0126, -0.0071,  0.0254,  ..., -0.0079, -0.0144, -0.0071],
        ...,
        [ 0.0101,  0.0112,  0.0012,  ...,  0.0334, -0.0028,  0.0067],
        [ 0.0013, -0.0031,  0.0068,  ..., -0.0135,  0.0140, -0.0135],
        [ 0.0078, -0.0088,  0.0076,  ..., -0.0130, -0.0071,  0.0183]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.1210, -3.2031, -3.6738,  ...,  0.3098, -0.9512, -1.6924]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 20:19:42 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is the most mild, it is mildest
If something is the most sad, it is saddest
If something is the most rare, it is rarest
If something is the most lazy, it is laziest
If something is the most sunny, it is sunniest
If something is the most rude, it is rudest
If something is the most tricky, it is trickiest
If something is the most lucky, it is
2024-07-30 20:19:42 root INFO     [order_1_approx] starting weight calculation for If something is the most lazy, it is laziest
If something is the most rare, it is rarest
If something is the most rude, it is rudest
If something is the most sad, it is saddest
If something is the most sunny, it is sunniest
If something is the most tricky, it is trickiest
If something is the most lucky, it is luckiest
If something is the most mild, it is
2024-07-30 20:19:42 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-30 20:21:43 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2249,  0.2385, -0.3271,  ..., -0.7217,  0.0149, -0.0867],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.7925, -3.6953, -1.0684,  ..., -1.7812, -1.6992, -1.9648],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0749, -0.0103, -0.0091,  ...,  0.0037, -0.0007,  0.0146],
        [ 0.0195,  0.0714,  0.0131,  ...,  0.0169,  0.0092, -0.0061],
        [ 0.0031, -0.0039,  0.0548,  ..., -0.0056, -0.0080,  0.0046],
        ...,
        [ 0.0082,  0.0400,  0.0044,  ...,  0.0953,  0.0199, -0.0153],
        [ 0.0134, -0.0009, -0.0100,  ..., -0.0092,  0.0657, -0.0208],
        [-0.0061,  0.0047,  0.0177,  ...,  0.0133, -0.0128,  0.0523]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.5571, -3.6309, -1.2227,  ..., -1.0020, -1.8555, -1.8330]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 20:21:44 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is the most lazy, it is laziest
If something is the most rare, it is rarest
If something is the most rude, it is rudest
If something is the most sad, it is saddest
If something is the most sunny, it is sunniest
If something is the most tricky, it is trickiest
If something is the most lucky, it is luckiest
If something is the most mild, it is
2024-07-30 20:21:44 root INFO     total operator prediction time: 994.3567571640015 seconds
2024-07-30 20:21:44 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on verb_3pSg - Ved
2024-07-30 20:21:44 root INFO     building operator verb_3pSg - Ved
2024-07-30 20:21:44 root INFO     [order_1_approx] starting weight calculation for When he publishes something, something has been published
When he includes something, something has been included
When he tells something, something has been told
When he describes something, something has been described
When he becomes something, something has been became
When he believes something, something has been believed
When he appoints something, something has been appointed
When he appears something, something has been
2024-07-30 20:21:44 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-30 20:23:47 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2351,  0.0834, -0.1792,  ...,  0.0201,  0.0460, -0.5405],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.2754, -0.0417,  1.2451,  ...,  1.1729, -1.9814,  1.1797],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0408, -0.0179,  0.0113,  ...,  0.0071,  0.0016,  0.0104],
        [ 0.0019,  0.0367,  0.0025,  ...,  0.0281, -0.0015, -0.0064],
        [-0.0035, -0.0050,  0.0494,  ..., -0.0089, -0.0035, -0.0107],
        ...,
        [-0.0109,  0.0018, -0.0029,  ...,  0.0607, -0.0045, -0.0019],
        [ 0.0145,  0.0047,  0.0106,  ..., -0.0032,  0.0539, -0.0263],
        [-0.0148, -0.0012,  0.0153,  ..., -0.0020, -0.0116,  0.0410]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.4697, -0.2510,  1.2725,  ...,  1.3896, -1.8682,  1.4355]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 20:24:02 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When he publishes something, something has been published
When he includes something, something has been included
When he tells something, something has been told
When he describes something, something has been described
When he becomes something, something has been became
When he believes something, something has been believed
When he appoints something, something has been appointed
When he appears something, something has been
2024-07-30 20:24:02 root INFO     [order_1_approx] starting weight calculation for When he appears something, something has been appeared
When he appoints something, something has been appointed
When he describes something, something has been described
When he becomes something, something has been became
When he includes something, something has been included
When he believes something, something has been believed
When he tells something, something has been told
When he publishes something, something has been
2024-07-30 20:24:02 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-30 20:26:00 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1726, -0.3259,  0.1835,  ...,  0.1005,  0.0314,  0.1400],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.3379, -2.3730,  2.4766,  ..., -2.3516, -2.1055,  0.4746],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0049,  0.0095,  0.0080,  ..., -0.0043, -0.0067,  0.0180],
        [-0.0088, -0.0006,  0.0035,  ...,  0.0131,  0.0077,  0.0070],
        [ 0.0166, -0.0012,  0.0047,  ..., -0.0076, -0.0083, -0.0055],
        ...,
        [-0.0067,  0.0052, -0.0037,  ...,  0.0084,  0.0021,  0.0018],
        [ 0.0095,  0.0030, -0.0034,  ...,  0.0005,  0.0185, -0.0209],
        [-0.0027,  0.0106,  0.0035,  ..., -0.0028,  0.0004,  0.0006]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.5020, -2.5918,  2.8047,  ..., -2.6738, -1.9873,  0.0244]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 20:26:00 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When he appears something, something has been appeared
When he appoints something, something has been appointed
When he describes something, something has been described
When he becomes something, something has been became
When he includes something, something has been included
When he believes something, something has been believed
When he tells something, something has been told
When he publishes something, something has been
2024-07-30 20:26:01 root INFO     [order_1_approx] starting weight calculation for When he becomes something, something has been became
When he publishes something, something has been published
When he appoints something, something has been appointed
When he tells something, something has been told
When he includes something, something has been included
When he believes something, something has been believed
When he appears something, something has been appeared
When he describes something, something has been
2024-07-30 20:26:01 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-30 20:27:59 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.4033, -0.6538,  0.7656,  ...,  0.1338, -0.0638, -0.7412],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.4238, -0.4976,  4.7578,  ...,  0.3774, -0.1768, -2.3496],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0461, -0.0099,  0.0019,  ...,  0.0000, -0.0018,  0.0127],
        [-0.0104,  0.0295,  0.0064,  ...,  0.0115,  0.0138,  0.0100],
        [ 0.0258, -0.0176,  0.0195,  ..., -0.0026, -0.0017, -0.0156],
        ...,
        [ 0.0144,  0.0058,  0.0115,  ...,  0.0458, -0.0012,  0.0108],
        [-0.0064, -0.0009, -0.0004,  ..., -0.0031,  0.0303, -0.0062],
        [ 0.0011,  0.0075,  0.0155,  ..., -0.0161, -0.0093,  0.0305]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.3711,  0.0107,  5.1875,  ...,  0.6245, -0.5479, -2.2129]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 20:28:00 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When he becomes something, something has been became
When he publishes something, something has been published
When he appoints something, something has been appointed
When he tells something, something has been told
When he includes something, something has been included
When he believes something, something has been believed
When he appears something, something has been appeared
When he describes something, something has been
2024-07-30 20:28:00 root INFO     [order_1_approx] starting weight calculation for When he appears something, something has been appeared
When he appoints something, something has been appointed
When he publishes something, something has been published
When he describes something, something has been described
When he tells something, something has been told
When he becomes something, something has been became
When he includes something, something has been included
When he believes something, something has been
2024-07-30 20:28:00 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-30 20:30:02 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2693,  0.3105,  0.0593,  ..., -0.2065, -0.6387,  0.4922],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.5352, -1.7812,  1.4268,  ...,  0.8691, -2.8262, -0.6465],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 1.4908e-02, -5.8250e-03,  7.1373e-03,  ...,  4.1199e-04,
         -7.9441e-04,  1.3771e-02],
        [-7.5798e-03,  2.1255e-02,  8.2397e-03,  ...,  2.6352e-02,
          1.4381e-03,  3.9520e-03],
        [-6.3400e-03, -1.0750e-02,  2.5116e-02,  ..., -2.4548e-03,
         -5.6152e-03, -1.2962e-02],
        ...,
        [-4.5471e-03,  8.7585e-03,  1.4553e-03,  ...,  2.2339e-02,
         -1.3180e-03, -5.1498e-05],
        [ 9.9335e-03, -1.2169e-03, -7.9060e-04,  ...,  6.6948e-04,
          1.8723e-02, -2.4780e-02],
        [-7.1526e-05, -2.1019e-03,  1.4908e-02,  ..., -9.6893e-03,
         -5.7259e-03,  1.1047e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.3438, -1.6318,  1.2539,  ...,  0.9307, -2.9414, -0.8188]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 20:30:02 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When he appears something, something has been appeared
When he appoints something, something has been appointed
When he publishes something, something has been published
When he describes something, something has been described
When he tells something, something has been told
When he becomes something, something has been became
When he includes something, something has been included
When he believes something, something has been
2024-07-30 20:30:03 root INFO     [order_1_approx] starting weight calculation for When he tells something, something has been told
When he includes something, something has been included
When he becomes something, something has been became
When he describes something, something has been described
When he believes something, something has been believed
When he publishes something, something has been published
When he appears something, something has been appeared
When he appoints something, something has been
2024-07-30 20:30:03 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-30 20:32:05 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0769, -0.4019,  0.2068,  ...,  0.3433, -0.0697, -0.2920],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.8496, -0.1172,  1.3809,  ...,  0.8574, -1.9395,  0.4219],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0154, -0.0129,  0.0159,  ..., -0.0040, -0.0093,  0.0122],
        [-0.0022,  0.0152, -0.0033,  ...,  0.0135, -0.0022, -0.0092],
        [ 0.0019, -0.0031,  0.0122,  ...,  0.0046, -0.0004, -0.0140],
        ...,
        [-0.0032,  0.0089,  0.0045,  ...,  0.0170, -0.0079,  0.0140],
        [-0.0040, -0.0002,  0.0039,  ...,  0.0176,  0.0118, -0.0329],
        [-0.0018,  0.0066,  0.0063,  ..., -0.0028, -0.0057,  0.0055]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.7363, -0.3748,  1.6172,  ...,  0.9336, -1.5098,  0.1260]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 20:32:31 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When he tells something, something has been told
When he includes something, something has been included
When he becomes something, something has been became
When he describes something, something has been described
When he believes something, something has been believed
When he publishes something, something has been published
When he appears something, something has been appeared
When he appoints something, something has been
2024-07-30 20:32:32 root INFO     [order_1_approx] starting weight calculation for When he publishes something, something has been published
When he describes something, something has been described
When he becomes something, something has been became
When he includes something, something has been included
When he believes something, something has been believed
When he appoints something, something has been appointed
When he appears something, something has been appeared
When he tells something, something has been
2024-07-30 20:32:32 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-30 20:34:37 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1242, -0.3486,  0.6025,  ...,  0.0260, -0.2673, -0.4102],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.5879,  0.6367,  3.9980,  ...,  2.4375, -4.5000, -1.7520],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0420, -0.0075,  0.0083,  ..., -0.0053,  0.0021,  0.0110],
        [-0.0196,  0.0258, -0.0028,  ...,  0.0159, -0.0039,  0.0020],
        [-0.0020, -0.0264,  0.0266,  ..., -0.0021, -0.0141, -0.0143],
        ...,
        [-0.0014,  0.0126,  0.0052,  ...,  0.0414, -0.0029,  0.0033],
        [-0.0018, -0.0086,  0.0139,  ..., -0.0081,  0.0374, -0.0154],
        [-0.0070,  0.0048,  0.0194,  ..., -0.0109,  0.0100,  0.0284]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.4453,  0.8628,  3.8320,  ...,  2.4727, -4.4141, -1.6660]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 20:34:38 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When he publishes something, something has been published
When he describes something, something has been described
When he becomes something, something has been became
When he includes something, something has been included
When he believes something, something has been believed
When he appoints something, something has been appointed
When he appears something, something has been appeared
When he tells something, something has been
2024-07-30 20:34:39 root INFO     [order_1_approx] starting weight calculation for When he describes something, something has been described
When he includes something, something has been included
When he appoints something, something has been appointed
When he tells something, something has been told
When he publishes something, something has been published
When he appears something, something has been appeared
When he believes something, something has been believed
When he becomes something, something has been
2024-07-30 20:34:39 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-30 20:36:38 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0806, -0.0906,  0.3979,  ...,  0.2163, -0.5508,  0.1670],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.3711,  1.1699,  2.1699,  ...,  0.2964,  0.0103, -1.2725],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 4.3823e-02, -4.6005e-03,  8.1329e-03,  ...,  4.9591e-05,
          7.4081e-03,  9.7198e-03],
        [-1.5350e-02,  3.0991e-02,  3.0746e-03,  ...,  2.2339e-02,
         -4.7073e-03, -1.1536e-02],
        [ 7.7667e-03, -1.7273e-02,  3.1281e-02,  ..., -3.1033e-03,
         -9.6893e-04, -1.1780e-02],
        ...,
        [-5.5122e-03,  4.1771e-03, -3.7193e-03,  ...,  3.9398e-02,
         -2.9163e-03,  2.1324e-03],
        [ 1.1185e-02,  1.2642e-02, -3.9406e-03,  ..., -3.3588e-03,
          3.8513e-02, -1.3748e-02],
        [-1.9165e-02, -6.6757e-04,  1.8646e-02,  ..., -1.2115e-02,
         -9.5444e-03,  4.2206e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.3340,  1.1504,  2.0781,  ...,  0.5957, -0.3000, -1.1699]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 20:36:39 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When he describes something, something has been described
When he includes something, something has been included
When he appoints something, something has been appointed
When he tells something, something has been told
When he publishes something, something has been published
When he appears something, something has been appeared
When he believes something, something has been believed
When he becomes something, something has been
2024-07-30 20:36:40 root INFO     [order_1_approx] starting weight calculation for When he appoints something, something has been appointed
When he describes something, something has been described
When he publishes something, something has been published
When he believes something, something has been believed
When he appears something, something has been appeared
When he tells something, something has been told
When he becomes something, something has been became
When he includes something, something has been
2024-07-30 20:36:40 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-30 20:38:38 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0614, -0.4277,  0.0974,  ...,  0.4644,  0.0356, -0.5005],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.2979,  0.2017,  0.4963,  ...,  0.2556, -0.4141, -2.6562],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 4.7272e-02, -2.8801e-03,  2.4475e-02,  ...,  5.9814e-03,
         -1.0918e-02,  1.1337e-02],
        [-1.7487e-02,  4.0283e-02, -4.1885e-03,  ...,  2.0370e-02,
         -1.1047e-02, -8.6975e-03],
        [-5.9128e-05, -3.3169e-03,  3.6835e-02,  ..., -1.0742e-02,
         -8.7662e-03, -2.5055e-02],
        ...,
        [ 1.7868e-02,  6.8741e-03,  4.8180e-03,  ...,  4.3396e-02,
         -4.6043e-03,  2.0401e-02],
        [ 1.8494e-02,  4.8294e-03, -2.6474e-03,  ..., -1.7252e-03,
          2.8015e-02, -1.9974e-02],
        [-1.6693e-02,  7.6180e-03,  1.4252e-02,  ...,  1.6022e-03,
         -9.5673e-03,  3.6133e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.4805,  0.7427,  0.8574,  ...,  0.2832, -0.5249, -2.0898]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 20:38:39 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When he appoints something, something has been appointed
When he describes something, something has been described
When he publishes something, something has been published
When he believes something, something has been believed
When he appears something, something has been appeared
When he tells something, something has been told
When he becomes something, something has been became
When he includes something, something has been
2024-07-30 20:38:39 root INFO     total operator prediction time: 1015.4023406505585 seconds
2024-07-30 20:38:39 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on noun - plural_reg
2024-07-30 20:38:39 root INFO     building operator noun - plural_reg
2024-07-30 20:38:39 root INFO     [order_1_approx] starting weight calculation for The plural form of week is weeks
The plural form of problem is problems
The plural form of role is roles
The plural form of idea is ideas
The plural form of product is products
The plural form of god is gods
The plural form of street is streets
The plural form of development is
2024-07-30 20:38:39 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-30 20:40:41 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.6104,  0.7461, -0.4915,  ...,  0.0839, -0.0417, -0.5635],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.8887, -2.5977,  0.6934,  ..., -1.8809, -2.6367, -2.4258],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0907, -0.0078, -0.0341,  ..., -0.0064,  0.0069, -0.0434],
        [-0.0055,  0.0815,  0.0193,  ...,  0.0215, -0.0043,  0.0334],
        [-0.0054, -0.0135,  0.0583,  ..., -0.0002, -0.0132,  0.0064],
        ...,
        [ 0.0180, -0.0061,  0.0017,  ...,  0.1006, -0.0322,  0.0300],
        [-0.0138,  0.0197,  0.0052,  ...,  0.0025,  0.0738,  0.0140],
        [-0.0105, -0.0023, -0.0069,  ...,  0.0007, -0.0356,  0.1010]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.1602, -3.1621,  0.8926,  ..., -2.0859, -2.4902, -2.0977]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 20:40:49 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of week is weeks
The plural form of problem is problems
The plural form of role is roles
The plural form of idea is ideas
The plural form of product is products
The plural form of god is gods
The plural form of street is streets
The plural form of development is
2024-07-30 20:40:51 root INFO     [order_1_approx] starting weight calculation for The plural form of idea is ideas
The plural form of role is roles
The plural form of week is weeks
The plural form of product is products
The plural form of development is developments
The plural form of problem is problems
The plural form of god is gods
The plural form of street is
2024-07-30 20:40:51 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-30 20:42:55 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.3618,  0.1194,  0.3442,  ..., -0.3369,  0.0341, -0.1855],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.0156, -4.3086, -0.1711,  ...,  0.8257, -0.0833, -2.6816],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0826,  0.0237, -0.0150,  ..., -0.0052, -0.0009,  0.0131],
        [ 0.0017,  0.0866, -0.0008,  ...,  0.0110,  0.0248, -0.0186],
        [-0.0103,  0.0307,  0.0875,  ...,  0.0057,  0.0158,  0.0375],
        ...,
        [-0.0012,  0.0045,  0.0334,  ...,  0.0704, -0.0196,  0.0119],
        [-0.0625,  0.0194, -0.0347,  ..., -0.0051,  0.0806,  0.0025],
        [ 0.0098,  0.0138,  0.0083,  ...,  0.0189,  0.0179,  0.0753]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.4414, -4.7891,  0.2310,  ...,  0.7769,  0.3689, -2.5156]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 20:42:56 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of idea is ideas
The plural form of role is roles
The plural form of week is weeks
The plural form of product is products
The plural form of development is developments
The plural form of problem is problems
The plural form of god is gods
The plural form of street is
2024-07-30 20:42:56 root INFO     [order_1_approx] starting weight calculation for The plural form of problem is problems
The plural form of street is streets
The plural form of god is gods
The plural form of development is developments
The plural form of week is weeks
The plural form of idea is ideas
The plural form of role is roles
The plural form of product is
2024-07-30 20:42:57 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-30 20:44:57 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1094,  0.3113, -0.0334,  ..., -0.1284, -0.0693, -0.2462],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.1104, -4.0938, -0.0464,  ..., -1.0371, -1.2803, -0.6748],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 1.0114e-01,  1.1566e-02, -1.2159e-03,  ...,  3.7479e-03,
          7.6294e-06,  5.7487e-03],
        [-1.0361e-02,  8.2397e-02,  9.9792e-03,  ...,  1.6266e-02,
          2.0767e-02, -6.1150e-03],
        [ 1.9943e-02,  1.5366e-02,  8.0261e-02,  ...,  3.4523e-03,
         -1.7059e-02,  2.2755e-03],
        ...,
        [ 3.1036e-02,  1.1002e-02, -1.5335e-03,  ...,  8.4961e-02,
          8.0414e-03,  1.0315e-02],
        [-2.4796e-02,  1.0391e-02, -7.4234e-03,  ..., -7.5226e-03,
          7.3242e-02, -1.8951e-02],
        [ 1.0040e-02,  2.9774e-03, -9.1934e-03,  ...,  2.9373e-02,
         -9.6207e-03,  1.0101e-01]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.9385, -3.8359,  0.1082,  ..., -0.5830, -1.0469, -0.7163]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 20:44:58 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of problem is problems
The plural form of street is streets
The plural form of god is gods
The plural form of development is developments
The plural form of week is weeks
The plural form of idea is ideas
The plural form of role is roles
The plural form of product is
2024-07-30 20:44:59 root INFO     [order_1_approx] starting weight calculation for The plural form of role is roles
The plural form of week is weeks
The plural form of street is streets
The plural form of god is gods
The plural form of development is developments
The plural form of product is products
The plural form of problem is problems
The plural form of idea is
2024-07-30 20:44:59 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-30 20:46:58 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1604,  0.0795,  0.1580,  ..., -0.3206, -0.0474, -0.3010],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.7617, -2.7070,  2.6133,  ..., -0.4299, -1.1738, -2.1562],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0746,  0.0049, -0.0066,  ...,  0.0077, -0.0097,  0.0267],
        [-0.0059,  0.0451,  0.0262,  ...,  0.0165, -0.0022, -0.0019],
        [-0.0050, -0.0118,  0.0708,  ..., -0.0129,  0.0090,  0.0149],
        ...,
        [ 0.0029,  0.0090,  0.0115,  ...,  0.0500,  0.0040, -0.0055],
        [-0.0170,  0.0135,  0.0060,  ..., -0.0005,  0.0583, -0.0158],
        [ 0.0152,  0.0004,  0.0028,  ..., -0.0080, -0.0117,  0.0649]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.8105, -3.0488,  2.7383,  ..., -0.4302, -0.8804, -1.8877]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 20:46:59 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of role is roles
The plural form of week is weeks
The plural form of street is streets
The plural form of god is gods
The plural form of development is developments
The plural form of product is products
The plural form of problem is problems
The plural form of idea is
2024-07-30 20:46:59 root INFO     [order_1_approx] starting weight calculation for The plural form of god is gods
The plural form of product is products
The plural form of idea is ideas
The plural form of street is streets
The plural form of problem is problems
The plural form of role is roles
The plural form of development is developments
The plural form of week is
2024-07-30 20:46:59 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-30 20:49:00 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.3755,  0.1859, -0.1565,  ...,  0.1460, -0.4189, -0.4780],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.5566, -4.0508,  0.3726,  ..., -0.6665,  0.2471, -1.6738],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 6.7993e-02,  1.6388e-02,  9.1248e-03,  ...,  1.3649e-02,
          2.5139e-03,  1.8097e-02],
        [-6.2847e-04,  7.1228e-02, -1.1299e-02,  ...,  1.4297e-02,
          2.0294e-02, -1.6953e-02],
        [-1.4477e-03,  7.7133e-03,  6.3965e-02,  ...,  6.1264e-03,
         -1.0971e-02,  2.4612e-02],
        ...,
        [ 2.3003e-03,  2.3315e-02, -6.3324e-03,  ...,  6.5613e-02,
         -2.7054e-02,  1.5045e-02],
        [-2.1973e-02,  3.3722e-03,  6.9618e-05,  ...,  2.7962e-03,
          6.2622e-02, -3.0003e-03],
        [-6.4926e-03,  1.3268e-02, -2.0172e-02,  ..., -7.1106e-03,
         -8.4000e-03,  7.4585e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.6719, -4.0586,  0.5576,  ..., -0.6548, -0.0576, -1.5928]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 20:49:01 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of god is gods
The plural form of product is products
The plural form of idea is ideas
The plural form of street is streets
The plural form of problem is problems
The plural form of role is roles
The plural form of development is developments
The plural form of week is
2024-07-30 20:49:01 root INFO     [order_1_approx] starting weight calculation for The plural form of problem is problems
The plural form of product is products
The plural form of street is streets
The plural form of development is developments
The plural form of week is weeks
The plural form of role is roles
The plural form of idea is ideas
The plural form of god is
2024-07-30 20:49:01 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-30 20:51:03 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0525,  0.2406, -0.1404,  ..., -0.4177, -0.3855, -0.2336],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 5.1523, -4.1562,  0.8271,  ..., -1.7871,  0.6797, -2.9121],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0464, -0.0042, -0.0101,  ...,  0.0115, -0.0215,  0.0056],
        [ 0.0228,  0.0664,  0.0163,  ...,  0.0009,  0.0171, -0.0084],
        [ 0.0133, -0.0206,  0.0430,  ...,  0.0182,  0.0003,  0.0071],
        ...,
        [ 0.0254, -0.0050, -0.0088,  ...,  0.0529, -0.0018,  0.0086],
        [ 0.0084,  0.0013, -0.0042,  ..., -0.0325,  0.0232, -0.0080],
        [-0.0157,  0.0229, -0.0080,  ..., -0.0071, -0.0101,  0.0570]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 5.1523, -3.7617,  0.7251,  ..., -1.5547,  0.6987, -2.8145]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 20:51:04 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of problem is problems
The plural form of product is products
The plural form of street is streets
The plural form of development is developments
The plural form of week is weeks
The plural form of role is roles
The plural form of idea is ideas
The plural form of god is
2024-07-30 20:51:04 root INFO     [order_1_approx] starting weight calculation for The plural form of product is products
The plural form of development is developments
The plural form of idea is ideas
The plural form of week is weeks
The plural form of problem is problems
The plural form of street is streets
The plural form of god is gods
The plural form of role is
2024-07-30 20:51:04 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-30 20:53:10 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0123,  0.1750, -0.2622,  ..., -0.1783, -0.0793, -0.4995],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.4268, -3.0625,  0.2080,  ..., -2.8672,  0.0820, -4.4062],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.1048,  0.0181,  0.0122,  ...,  0.0263,  0.0344, -0.0139],
        [-0.0119,  0.0752, -0.0034,  ...,  0.0259,  0.0120, -0.0196],
        [ 0.0164, -0.0063,  0.0963,  ...,  0.0072, -0.0007, -0.0151],
        ...,
        [ 0.0145,  0.0098, -0.0026,  ...,  0.1028, -0.0036,  0.0131],
        [-0.0299,  0.0078, -0.0116,  ..., -0.0119,  0.0768,  0.0091],
        [ 0.0160,  0.0171, -0.0108,  ..., -0.0096,  0.0072,  0.0853]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.7012, -2.9336,  0.4932,  ..., -2.6855,  0.0586, -4.2695]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 20:53:11 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of product is products
The plural form of development is developments
The plural form of idea is ideas
The plural form of week is weeks
The plural form of problem is problems
The plural form of street is streets
The plural form of god is gods
The plural form of role is
2024-07-30 20:53:11 root INFO     [order_1_approx] starting weight calculation for The plural form of idea is ideas
The plural form of god is gods
The plural form of role is roles
The plural form of week is weeks
The plural form of development is developments
The plural form of street is streets
The plural form of product is products
The plural form of problem is
2024-07-30 20:53:11 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-30 20:55:19 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2039, -0.0060,  0.1897,  ..., -0.3772, -0.4932, -0.2524],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.8232, -2.8516,  1.0381,  ..., -0.1250, -0.2471, -0.6982],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0690,  0.0036,  0.0100,  ...,  0.0139, -0.0032,  0.0193],
        [ 0.0063,  0.0637, -0.0090,  ...,  0.0308,  0.0012,  0.0021],
        [ 0.0037, -0.0019,  0.0726,  ...,  0.0048, -0.0047,  0.0130],
        ...,
        [ 0.0061,  0.0128,  0.0043,  ...,  0.0560, -0.0085,  0.0126],
        [-0.0117,  0.0003,  0.0009,  ..., -0.0033,  0.0482, -0.0117],
        [ 0.0044,  0.0105, -0.0036,  ...,  0.0116, -0.0240,  0.0672]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.6689, -2.9102,  0.9048,  ...,  0.0979, -0.1707, -1.0605]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 20:55:20 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of idea is ideas
The plural form of god is gods
The plural form of role is roles
The plural form of week is weeks
The plural form of development is developments
The plural form of street is streets
The plural form of product is products
The plural form of problem is
2024-07-30 20:55:20 root INFO     total operator prediction time: 1000.5167443752289 seconds
2024-07-30 20:55:20 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on verb_Ving - 3pSg
2024-07-30 20:55:20 root INFO     building operator verb_Ving - 3pSg
2024-07-30 20:55:20 root INFO     [order_1_approx] starting weight calculation for When something is allowing, it allows
When something is explaining, it explains
When something is requiring, it requires
When something is providing, it provides
When something is becoming, it becomes
When something is adding, it adds
When something is existing, it exists
When something is including, it
2024-07-30 20:55:20 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-30 20:57:22 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1721, -0.3706, -0.1853,  ..., -0.0451,  0.0016, -0.4790],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.8496, -2.3965,  1.4980,  ..., -1.3428, -5.2188, -2.0352],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0824,  0.0023,  0.0222,  ...,  0.0095, -0.0171,  0.0123],
        [-0.0053,  0.0890, -0.0056,  ...,  0.0162, -0.0126,  0.0128],
        [ 0.0049, -0.0105,  0.0425,  ..., -0.0246, -0.0168, -0.0219],
        ...,
        [ 0.0240,  0.0092,  0.0088,  ...,  0.0634, -0.0136,  0.0221],
        [-0.0168, -0.0034,  0.0035,  ..., -0.0063,  0.0782, -0.0470],
        [ 0.0001,  0.0097,  0.0015,  ..., -0.0111, -0.0189,  0.0601]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.9912, -2.3242,  1.8428,  ..., -1.3564, -5.4102, -1.9600]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 20:57:23 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When something is allowing, it allows
When something is explaining, it explains
When something is requiring, it requires
When something is providing, it provides
When something is becoming, it becomes
When something is adding, it adds
When something is existing, it exists
When something is including, it
2024-07-30 20:57:23 root INFO     [order_1_approx] starting weight calculation for When something is providing, it provides
When something is explaining, it explains
When something is existing, it exists
When something is including, it includes
When something is requiring, it requires
When something is becoming, it becomes
When something is allowing, it allows
When something is adding, it
2024-07-30 20:57:23 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-30 20:59:18 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2213, -0.6055,  0.0515,  ..., -0.2827,  0.1603, -0.3071],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.8555, -1.6436, -1.1113,  ...,  0.9492, -9.0469, -0.1992],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 7.6660e-02,  3.3875e-03,  9.9564e-03,  ...,  7.2479e-05,
         -6.9389e-03,  4.2305e-03],
        [ 5.1346e-03,  6.9336e-02, -8.1253e-03,  ...,  1.7380e-02,
         -6.2485e-03,  6.9199e-03],
        [-1.3641e-02, -1.4549e-02,  5.4810e-02,  ...,  1.1749e-03,
         -7.3433e-03, -1.0384e-02],
        ...,
        [ 2.6596e-02,  3.0853e-02,  4.4899e-03,  ...,  7.7148e-02,
          6.7749e-03,  1.3542e-03],
        [ 9.8419e-04, -3.5210e-03, -7.4158e-03,  ..., -1.0880e-02,
          8.0688e-02, -2.5574e-02],
        [-1.4389e-02,  5.2109e-03,  8.4991e-03,  ..., -2.2903e-02,
         -2.4429e-02,  5.3864e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.8311, -1.5645, -0.6274,  ...,  0.9248, -8.8359, -0.4365]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 20:59:19 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When something is providing, it provides
When something is explaining, it explains
When something is existing, it exists
When something is including, it includes
When something is requiring, it requires
When something is becoming, it becomes
When something is allowing, it allows
When something is adding, it
2024-07-30 20:59:19 root INFO     [order_1_approx] starting weight calculation for When something is allowing, it allows
When something is becoming, it becomes
When something is adding, it adds
When something is including, it includes
When something is existing, it exists
When something is explaining, it explains
When something is providing, it provides
When something is requiring, it
2024-07-30 20:59:20 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-30 21:01:13 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.4780,  0.0377, -0.1970,  ..., -0.4990, -0.1434, -0.5347],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.2778, -2.8965,  1.6621,  ..., -1.4551, -5.3008, -0.5762],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0568,  0.0026,  0.0214,  ...,  0.0019, -0.0071,  0.0214],
        [-0.0041,  0.0608, -0.0361,  ...,  0.0103,  0.0035,  0.0287],
        [ 0.0128, -0.0020,  0.0578,  ..., -0.0205, -0.0048, -0.0161],
        ...,
        [-0.0021, -0.0003,  0.0303,  ...,  0.0518, -0.0030,  0.0149],
        [-0.0288, -0.0240,  0.0291,  ..., -0.0164,  0.0528, -0.0591],
        [-0.0079,  0.0111,  0.0022,  ..., -0.0154,  0.0008,  0.0599]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.3931, -3.0078,  1.9424,  ..., -1.2490, -5.1094, -0.8711]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 21:01:14 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When something is allowing, it allows
When something is becoming, it becomes
When something is adding, it adds
When something is including, it includes
When something is existing, it exists
When something is explaining, it explains
When something is providing, it provides
When something is requiring, it
2024-07-30 21:01:14 root INFO     [order_1_approx] starting weight calculation for When something is allowing, it allows
When something is requiring, it requires
When something is becoming, it becomes
When something is providing, it provides
When something is including, it includes
When something is adding, it adds
When something is existing, it exists
When something is explaining, it
2024-07-30 21:01:14 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-30 21:03:09 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2076, -0.7354,  0.0249,  ..., -0.2006,  0.1405, -0.4978],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.1943, -3.4707,  3.2109,  ...,  0.5464, -6.1953,  0.7480],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0478,  0.0001,  0.0035,  ...,  0.0043,  0.0047,  0.0176],
        [-0.0179,  0.0559,  0.0014,  ...,  0.0166, -0.0079,  0.0053],
        [-0.0179, -0.0096,  0.0290,  ..., -0.0269,  0.0028, -0.0244],
        ...,
        [-0.0094,  0.0013,  0.0139,  ...,  0.0576, -0.0003,  0.0008],
        [-0.0156, -0.0025, -0.0089,  ..., -0.0013,  0.0461, -0.0289],
        [ 0.0147,  0.0056,  0.0251,  ...,  0.0033, -0.0068,  0.0520]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.0732, -3.2441,  3.2402,  ...,  0.8413, -6.0469,  0.5625]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 21:03:10 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When something is allowing, it allows
When something is requiring, it requires
When something is becoming, it becomes
When something is providing, it provides
When something is including, it includes
When something is adding, it adds
When something is existing, it exists
When something is explaining, it
2024-07-30 21:03:10 root INFO     [order_1_approx] starting weight calculation for When something is becoming, it becomes
When something is providing, it provides
When something is existing, it exists
When something is explaining, it explains
When something is requiring, it requires
When something is adding, it adds
When something is including, it includes
When something is allowing, it
2024-07-30 21:03:10 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-30 21:05:09 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.4377, -0.0891, -0.0714,  ..., -0.4961,  0.0613, -0.1116],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.1211, -4.6406,  0.0273,  ..., -1.3516, -6.4766,  1.4961],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0567,  0.0009, -0.0184,  ..., -0.0120,  0.0054,  0.0084],
        [ 0.0119,  0.0433, -0.0150,  ...,  0.0210,  0.0032,  0.0049],
        [-0.0276, -0.0134,  0.0500,  ..., -0.0243, -0.0062, -0.0358],
        ...,
        [ 0.0005, -0.0062,  0.0132,  ...,  0.0446, -0.0060,  0.0186],
        [-0.0167,  0.0123,  0.0082,  ...,  0.0023,  0.0490, -0.0347],
        [ 0.0035,  0.0132,  0.0023,  ..., -0.0150, -0.0084,  0.0433]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.0938, -4.3164,  0.3643,  ..., -1.0391, -6.9258,  1.2334]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 21:05:10 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When something is becoming, it becomes
When something is providing, it provides
When something is existing, it exists
When something is explaining, it explains
When something is requiring, it requires
When something is adding, it adds
When something is including, it includes
When something is allowing, it
2024-07-30 21:05:10 root INFO     [order_1_approx] starting weight calculation for When something is adding, it adds
When something is allowing, it allows
When something is including, it includes
When something is requiring, it requires
When something is providing, it provides
When something is explaining, it explains
When something is existing, it exists
When something is becoming, it
2024-07-30 21:05:10 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-30 21:07:12 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1569,  0.1476,  0.1389,  ..., -0.0532, -0.2969,  0.5083],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.7344, -2.2773,  0.1777,  ...,  0.5801, -3.3516, -1.3271],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 5.4108e-02,  2.0103e-03,  9.8228e-05,  ...,  4.8599e-03,
          3.1967e-03,  1.2802e-02],
        [ 1.3100e-02,  3.4943e-02, -7.5951e-03,  ...,  1.2161e-02,
         -6.5727e-03,  7.6942e-03],
        [-7.4158e-03, -6.0692e-03,  3.2257e-02,  ...,  4.3869e-05,
          2.2720e-02, -2.2720e-02],
        ...,
        [ 1.0895e-02, -1.6432e-03,  7.8888e-03,  ...,  4.7546e-02,
         -9.5978e-03, -4.0579e-04],
        [ 1.1292e-03,  2.2430e-02, -1.2955e-02,  ..., -3.2597e-03,
          5.0873e-02, -4.6082e-02],
        [-4.3869e-03,  3.5324e-03,  1.5747e-02,  ..., -8.6975e-03,
         -8.8272e-03,  4.6570e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.6406, -1.9922,  0.0596,  ...,  0.6816, -3.8906, -1.3418]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 21:07:13 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When something is adding, it adds
When something is allowing, it allows
When something is including, it includes
When something is requiring, it requires
When something is providing, it provides
When something is explaining, it explains
When something is existing, it exists
When something is becoming, it
2024-07-30 21:07:13 root INFO     [order_1_approx] starting weight calculation for When something is adding, it adds
When something is including, it includes
When something is becoming, it becomes
When something is requiring, it requires
When something is allowing, it allows
When something is explaining, it explains
When something is existing, it exists
When something is providing, it
2024-07-30 21:07:13 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-30 21:09:07 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0232, -0.5356, -0.1661,  ..., -0.3774, -0.0658, -0.2620],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.1094, -6.1953,  0.2656,  ..., -1.2148, -7.0234,  0.0957],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0878,  0.0060,  0.0172,  ...,  0.0030,  0.0038,  0.0094],
        [-0.0092,  0.0639,  0.0055,  ...,  0.0181,  0.0033,  0.0110],
        [-0.0093, -0.0214,  0.0517,  ..., -0.0114,  0.0051, -0.0243],
        ...,
        [-0.0057, -0.0030,  0.0101,  ...,  0.0717, -0.0082, -0.0050],
        [-0.0157, -0.0201, -0.0135,  ..., -0.0096,  0.0691, -0.0393],
        [-0.0067,  0.0077,  0.0013,  ..., -0.0232,  0.0026,  0.0657]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.0352, -5.5898,  0.8721,  ..., -0.9385, -7.0000,  0.0448]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 21:09:08 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When something is adding, it adds
When something is including, it includes
When something is becoming, it becomes
When something is requiring, it requires
When something is allowing, it allows
When something is explaining, it explains
When something is existing, it exists
When something is providing, it
2024-07-30 21:09:08 root INFO     [order_1_approx] starting weight calculation for When something is explaining, it explains
When something is adding, it adds
When something is providing, it provides
When something is requiring, it requires
When something is becoming, it becomes
When something is allowing, it allows
When something is including, it includes
When something is existing, it
2024-07-30 21:09:08 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-30 21:11:12 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.3640, -0.2209, -0.9893,  ..., -0.3831, -0.1863, -0.2211],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.4688, -3.4160,  0.0371,  ..., -1.1621, -4.4883, -0.0996],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0520, -0.0107, -0.0091,  ..., -0.0096, -0.0005,  0.0217],
        [-0.0002,  0.0597, -0.0171,  ...,  0.0271,  0.0040, -0.0140],
        [-0.0067, -0.0061,  0.0428,  ..., -0.0116,  0.0038, -0.0282],
        ...,
        [-0.0073,  0.0178, -0.0036,  ...,  0.0756, -0.0155,  0.0094],
        [-0.0239,  0.0110,  0.0129,  ..., -0.0127,  0.0570, -0.0227],
        [-0.0040, -0.0122,  0.0136,  ...,  0.0036, -0.0039,  0.0740]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.4805, -3.0801,  0.3296,  ..., -0.6284, -4.4219, -0.0854]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 21:11:13 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When something is explaining, it explains
When something is adding, it adds
When something is providing, it provides
When something is requiring, it requires
When something is becoming, it becomes
When something is allowing, it allows
When something is including, it includes
When something is existing, it
2024-07-30 21:11:13 root INFO     total operator prediction time: 953.3730652332306 seconds
2024-07-30 21:11:13 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on verb_inf - 3pSg
2024-07-30 21:11:13 root INFO     building operator verb_inf - 3pSg
2024-07-30 21:11:13 root INFO     [order_1_approx] starting weight calculation for I follow, he follows
I require, he requires
I accept, he accepts
I seem, he seems
I refer, he refers
I promote, he promotes
I avoid, he avoids
I reduce, he
2024-07-30 21:11:13 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-30 21:13:16 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2089,  0.0370, -0.2317,  ..., -0.4260,  0.0702, -0.2250],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.3037, -2.7090, -0.7832,  ..., -2.3340, -8.1250, -4.4414],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0635,  0.0105,  0.0098,  ...,  0.0052, -0.0120,  0.0256],
        [ 0.0034,  0.0455, -0.0018,  ...,  0.0026, -0.0021,  0.0042],
        [-0.0035,  0.0067,  0.0356,  ...,  0.0011, -0.0087,  0.0060],
        ...,
        [-0.0100, -0.0077, -0.0067,  ...,  0.0450, -0.0027, -0.0116],
        [-0.0204, -0.0121, -0.0038,  ..., -0.0148,  0.0516, -0.0174],
        [-0.0165,  0.0029,  0.0072,  ..., -0.0188, -0.0010,  0.0244]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.3679, -2.7598, -1.1064,  ..., -1.3008, -8.0156, -4.0469]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 21:13:17 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for I follow, he follows
I require, he requires
I accept, he accepts
I seem, he seems
I refer, he refers
I promote, he promotes
I avoid, he avoids
I reduce, he
2024-07-30 21:13:17 root INFO     [order_1_approx] starting weight calculation for I accept, he accepts
I seem, he seems
I avoid, he avoids
I follow, he follows
I require, he requires
I reduce, he reduces
I promote, he promotes
I refer, he
2024-07-30 21:13:17 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-30 21:15:17 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.3635, -0.3750, -0.0862,  ..., -0.4851, -0.0542,  0.1030],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.2637, -4.5859, -0.1113,  ...,  2.2695, -8.6328, -2.9609],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 4.5044e-02, -3.8109e-03,  5.9128e-04,  ...,  1.3031e-02,
         -2.9755e-03,  1.5373e-02],
        [-1.0834e-02,  6.4575e-02, -1.6251e-03,  ..., -1.2978e-02,
          6.5765e-03,  2.6112e-03],
        [-9.4910e-03,  2.1305e-03,  3.2410e-02,  ..., -1.5388e-02,
         -2.8553e-03, -6.9542e-03],
        ...,
        [-3.5229e-03,  1.0742e-02,  7.4043e-03,  ...,  5.9998e-02,
         -4.8294e-03,  3.8147e-05],
        [ 2.0828e-03, -6.1569e-03, -4.4212e-03,  ..., -1.3641e-02,
          2.9510e-02, -1.8082e-02],
        [ 8.8196e-03,  2.8210e-03,  3.6774e-03,  ..., -1.1497e-02,
         -1.5869e-02,  4.0955e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.0332, -4.5703,  0.1075,  ...,  2.4922, -8.9219, -2.8262]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 21:15:18 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for I accept, he accepts
I seem, he seems
I avoid, he avoids
I follow, he follows
I require, he requires
I reduce, he reduces
I promote, he promotes
I refer, he
2024-07-30 21:15:18 root INFO     [order_1_approx] starting weight calculation for I follow, he follows
I require, he requires
I reduce, he reduces
I refer, he refers
I accept, he accepts
I promote, he promotes
I seem, he seems
I avoid, he
2024-07-30 21:15:18 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-30 21:17:25 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3560, -0.2673, -0.1588,  ..., -0.3569,  0.2323,  0.0581],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.4023, -3.3535, -2.7461,  ...,  1.9658, -6.2344, -0.4922],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0626,  0.0102, -0.0061,  ...,  0.0082, -0.0167,  0.0427],
        [-0.0037,  0.0590, -0.0144,  ...,  0.0015, -0.0112, -0.0159],
        [ 0.0063, -0.0010,  0.0371,  ..., -0.0086, -0.0091,  0.0155],
        ...,
        [-0.0027, -0.0060,  0.0123,  ...,  0.0478, -0.0038, -0.0132],
        [-0.0133, -0.0132,  0.0159,  ..., -0.0136,  0.0431, -0.0413],
        [-0.0029, -0.0074,  0.0072,  ..., -0.0208, -0.0179,  0.0409]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.2168, -3.2129, -3.0645,  ...,  2.4453, -6.3906, -0.3616]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 21:17:26 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for I follow, he follows
I require, he requires
I reduce, he reduces
I refer, he refers
I accept, he accepts
I promote, he promotes
I seem, he seems
I avoid, he
2024-07-30 21:17:26 root INFO     [order_1_approx] starting weight calculation for I seem, he seems
I promote, he promotes
I reduce, he reduces
I accept, he accepts
I avoid, he avoids
I refer, he refers
I require, he requires
I follow, he
2024-07-30 21:17:26 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-30 21:19:27 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0109, -0.3608,  0.0287,  ...,  0.0309, -0.0244,  0.3928],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.7031, -3.7324,  0.7988,  ..., -0.0923, -7.9297, -1.2852],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0542,  0.0026, -0.0080,  ...,  0.0127,  0.0144,  0.0344],
        [ 0.0044,  0.0620, -0.0093,  ..., -0.0001, -0.0038, -0.0172],
        [-0.0238,  0.0021,  0.0256,  ..., -0.0208, -0.0096, -0.0209],
        ...,
        [-0.0191,  0.0012,  0.0044,  ...,  0.0339,  0.0028, -0.0063],
        [-0.0092, -0.0092,  0.0121,  ..., -0.0157,  0.0206, -0.0180],
        [ 0.0004,  0.0107,  0.0140,  ..., -0.0114, -0.0115,  0.0215]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.3867, -3.7207,  0.6504,  ...,  0.0743, -7.9648, -1.0869]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 21:19:28 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for I seem, he seems
I promote, he promotes
I reduce, he reduces
I accept, he accepts
I avoid, he avoids
I refer, he refers
I require, he requires
I follow, he
2024-07-30 21:19:28 root INFO     [order_1_approx] starting weight calculation for I refer, he refers
I reduce, he reduces
I avoid, he avoids
I require, he requires
I accept, he accepts
I follow, he follows
I seem, he seems
I promote, he
2024-07-30 21:19:28 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-30 21:21:36 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1860, -0.3022, -0.0284,  ...,  0.0702,  0.0220,  0.3555],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.7695, -4.6367, -0.1836,  ..., -0.3809, -8.3828, -0.0430],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0458, -0.0040,  0.0040,  ...,  0.0078, -0.0108,  0.0261],
        [-0.0141,  0.0311, -0.0008,  ...,  0.0014,  0.0008, -0.0052],
        [ 0.0100,  0.0117,  0.0205,  ..., -0.0093, -0.0145,  0.0068],
        ...,
        [-0.0155,  0.0069,  0.0063,  ...,  0.0397,  0.0129, -0.0192],
        [-0.0166, -0.0104, -0.0099,  ..., -0.0058,  0.0377, -0.0300],
        [-0.0116, -0.0033,  0.0004,  ..., -0.0268, -0.0099,  0.0156]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.6992, -4.3008, -0.3289,  ...,  0.4438, -8.4062,  0.0601]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 21:21:37 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for I refer, he refers
I reduce, he reduces
I avoid, he avoids
I require, he requires
I accept, he accepts
I follow, he follows
I seem, he seems
I promote, he
2024-07-30 21:21:37 root INFO     [order_1_approx] starting weight calculation for I accept, he accepts
I avoid, he avoids
I require, he requires
I refer, he refers
I reduce, he reduces
I promote, he promotes
I follow, he follows
I seem, he
2024-07-30 21:21:37 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-30 21:23:40 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2983,  0.1499, -0.1497,  ...,  0.1193, -0.3213,  0.3186],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.6094, -2.8516, -2.0156,  ...,  1.1016, -6.0234, -2.3672],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 4.9042e-02, -4.0665e-03,  1.1360e-02,  ...,  2.7561e-03,
         -5.7678e-03,  2.3605e-02],
        [-4.3259e-03,  5.2216e-02, -1.2604e-02,  ...,  2.7790e-03,
         -5.1308e-04, -1.3016e-02],
        [-9.1629e-03, -1.9806e-02,  3.7933e-02,  ..., -1.8845e-02,
         -7.6408e-03,  1.8749e-03],
        ...,
        [ 7.2174e-03, -1.1444e-05,  2.7275e-03,  ...,  5.7800e-02,
         -1.4030e-02, -8.2245e-03],
        [-2.2064e-02,  7.2861e-04, -1.0567e-03,  ..., -1.8860e-02,
          3.5553e-02, -7.5798e-03],
        [ 2.4872e-03, -1.0994e-02,  6.8855e-03,  ..., -2.3708e-03,
         -1.0651e-02,  2.3193e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.8809, -2.6387, -1.4854,  ...,  1.3506, -5.6719, -1.9531]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 21:23:41 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for I accept, he accepts
I avoid, he avoids
I require, he requires
I refer, he refers
I reduce, he reduces
I promote, he promotes
I follow, he follows
I seem, he
2024-07-30 21:23:41 root INFO     [order_1_approx] starting weight calculation for I seem, he seems
I avoid, he avoids
I accept, he accepts
I promote, he promotes
I reduce, he reduces
I refer, he refers
I follow, he follows
I require, he
2024-07-30 21:23:41 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-30 21:25:45 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.3726, -0.1377, -0.1619,  ..., -0.2427, -0.6182, -0.3767],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.7773, -3.0508,  0.7891,  ..., -0.7397, -8.2500, -1.0879],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0346,  0.0043,  0.0129,  ...,  0.0207, -0.0017,  0.0149],
        [-0.0170,  0.0411, -0.0063,  ..., -0.0050,  0.0082,  0.0035],
        [-0.0020,  0.0119,  0.0295,  ..., -0.0240,  0.0011,  0.0034],
        ...,
        [-0.0004,  0.0007,  0.0048,  ...,  0.0293, -0.0173,  0.0013],
        [-0.0194, -0.0115,  0.0154,  ..., -0.0268,  0.0340, -0.0109],
        [-0.0122,  0.0006,  0.0040,  ..., -0.0296, -0.0068,  0.0248]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.7471, -3.0371,  0.8315,  ..., -0.3049, -8.5547, -1.2451]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 21:25:46 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for I seem, he seems
I avoid, he avoids
I accept, he accepts
I promote, he promotes
I reduce, he reduces
I refer, he refers
I follow, he follows
I require, he
2024-07-30 21:25:46 root INFO     [order_1_approx] starting weight calculation for I require, he requires
I refer, he refers
I reduce, he reduces
I follow, he follows
I promote, he promotes
I avoid, he avoids
I seem, he seems
I accept, he
2024-07-30 21:25:46 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-30 21:27:52 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0947,  0.3364, -0.3308,  ..., -0.1560, -0.2676,  0.1848],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.2344, -3.6211, -2.0137,  ...,  0.7031, -7.2227, -0.2812],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0606, -0.0010,  0.0084,  ...,  0.0111, -0.0051,  0.0239],
        [ 0.0023,  0.0526, -0.0078,  ...,  0.0027, -0.0107, -0.0168],
        [ 0.0048,  0.0049,  0.0191,  ..., -0.0132, -0.0111, -0.0149],
        ...,
        [-0.0111,  0.0040,  0.0004,  ...,  0.0455,  0.0052, -0.0246],
        [-0.0248, -0.0045, -0.0074,  ..., -0.0234,  0.0412,  0.0010],
        [-0.0038,  0.0022,  0.0057,  ..., -0.0183, -0.0146,  0.0407]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.8516, -3.4277, -1.9834,  ...,  1.0781, -7.0781, -0.1357]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 21:27:53 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for I require, he requires
I refer, he refers
I reduce, he reduces
I follow, he follows
I promote, he promotes
I avoid, he avoids
I seem, he seems
I accept, he
2024-07-30 21:27:53 root INFO     total operator prediction time: 1000.003785610199 seconds
2024-07-30 21:27:53 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on verb_inf - Ved
2024-07-30 21:27:53 root INFO     building operator verb_inf - Ved
2024-07-30 21:27:53 root INFO     [order_1_approx] starting weight calculation for If the present form is agree, the past form is agreed
If the present form is create, the past form is created
If the present form is enjoy, the past form is enjoyed
If the present form is believe, the past form is believed
If the present form is introduce, the past form is introduced
If the present form is establish, the past form is established
If the present form is relate, the past form is related
If the present form is marry, the past form is
2024-07-30 21:27:53 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-30 21:29:56 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1613, -0.1176,  0.1282,  ..., -0.4150, -1.0869,  0.3945],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.2324, -1.8271,  2.2246,  ..., -0.9106, -2.4980, -0.6104],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0404, -0.0013, -0.0016,  ...,  0.0096, -0.0003,  0.0108],
        [-0.0182,  0.0343,  0.0065,  ...,  0.0082,  0.0038, -0.0095],
        [-0.0138, -0.0055,  0.0182,  ..., -0.0116, -0.0116, -0.0128],
        ...,
        [-0.0133, -0.0125,  0.0125,  ...,  0.0492, -0.0063, -0.0103],
        [-0.0024,  0.0032, -0.0130,  ..., -0.0239,  0.0309, -0.0010],
        [-0.0100,  0.0062,  0.0098,  ..., -0.0265, -0.0029,  0.0274]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.2637, -1.7686,  2.2695,  ..., -0.4583, -2.0352, -0.7812]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 21:29:57 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If the present form is agree, the past form is agreed
If the present form is create, the past form is created
If the present form is enjoy, the past form is enjoyed
If the present form is believe, the past form is believed
If the present form is introduce, the past form is introduced
If the present form is establish, the past form is established
If the present form is relate, the past form is related
If the present form is marry, the past form is
2024-07-30 21:29:58 root INFO     [order_1_approx] starting weight calculation for If the present form is relate, the past form is related
If the present form is enjoy, the past form is enjoyed
If the present form is introduce, the past form is introduced
If the present form is marry, the past form is married
If the present form is create, the past form is created
If the present form is agree, the past form is agreed
If the present form is believe, the past form is believed
If the present form is establish, the past form is
2024-07-30 21:29:58 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-30 21:32:05 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0936, -0.1211, -0.2815,  ..., -0.2363, -0.4507,  0.1083],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.3184,  0.0647,  0.6792,  ..., -0.6704, -1.0039, -2.1328],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 6.2286e-02, -1.6144e-02,  1.8524e-02,  ..., -5.8403e-03,
         -5.1270e-03,  2.4261e-02],
        [-2.6306e-02,  7.9834e-02, -8.0109e-04,  ...,  1.0513e-02,
         -3.7975e-03, -7.2212e-03],
        [ 1.8555e-02,  3.1090e-03,  3.1311e-02,  ..., -9.6893e-03,
         -2.8610e-05,  7.4883e-03],
        ...,
        [ 2.1324e-03, -7.8583e-03, -1.7120e-02,  ...,  6.9214e-02,
         -8.2932e-03,  1.0132e-02],
        [-1.3145e-02, -3.2196e-03,  1.2009e-02,  ..., -9.1019e-03,
          4.3488e-02, -1.8967e-02],
        [-3.0762e-02, -5.7755e-03,  9.1400e-03,  ..., -7.0190e-03,
         -2.7191e-02,  3.7506e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.5601,  0.2688,  0.5156,  ..., -0.3938, -0.5098, -2.0430]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 21:32:06 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If the present form is relate, the past form is related
If the present form is enjoy, the past form is enjoyed
If the present form is introduce, the past form is introduced
If the present form is marry, the past form is married
If the present form is create, the past form is created
If the present form is agree, the past form is agreed
If the present form is believe, the past form is believed
If the present form is establish, the past form is
2024-07-30 21:32:06 root INFO     [order_1_approx] starting weight calculation for If the present form is enjoy, the past form is enjoyed
If the present form is establish, the past form is established
If the present form is introduce, the past form is introduced
If the present form is agree, the past form is agreed
If the present form is relate, the past form is related
If the present form is create, the past form is created
If the present form is marry, the past form is married
If the present form is believe, the past form is
2024-07-30 21:32:06 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-30 21:34:11 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1379,  0.2302, -0.0776,  ..., -0.4739, -0.4246,  0.2175],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.1914, -2.8828,  1.0625,  ..., -0.4380, -2.4492, -1.7197],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 5.2856e-02, -3.2013e-02,  1.2794e-02,  ...,  1.6832e-03,
          2.1801e-03,  3.4637e-02],
        [-9.4452e-03,  5.1422e-02,  7.2441e-03,  ...,  2.0554e-02,
         -1.0864e-02,  3.8986e-03],
        [ 3.7613e-03,  1.0925e-02,  3.8483e-02,  ..., -9.0179e-03,
         -2.2602e-03,  1.2024e-02],
        ...,
        [-8.4839e-03,  3.8834e-03, -1.6510e-02,  ...,  6.1707e-02,
          1.7624e-03,  9.1553e-05],
        [-2.7695e-03, -8.7738e-03, -1.2955e-02,  ..., -8.2245e-03,
          2.0538e-02, -3.5645e-02],
        [-9.3918e-03,  1.3145e-02,  8.8501e-03,  ..., -1.4297e-02,
         -1.4244e-02,  2.1866e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.0352, -2.9922,  0.6182,  ..., -0.3433, -2.2969, -1.6875]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 21:34:12 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If the present form is enjoy, the past form is enjoyed
If the present form is establish, the past form is established
If the present form is introduce, the past form is introduced
If the present form is agree, the past form is agreed
If the present form is relate, the past form is related
If the present form is create, the past form is created
If the present form is marry, the past form is married
If the present form is believe, the past form is
2024-07-30 21:34:12 root INFO     [order_1_approx] starting weight calculation for If the present form is establish, the past form is established
If the present form is relate, the past form is related
If the present form is believe, the past form is believed
If the present form is marry, the past form is married
If the present form is introduce, the past form is introduced
If the present form is enjoy, the past form is enjoyed
If the present form is agree, the past form is agreed
If the present form is create, the past form is
2024-07-30 21:34:12 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-30 21:36:20 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2122, -0.2086,  0.2529,  ..., -0.3262, -0.2190, -0.1005],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.1074, -1.2305,  1.8594,  ..., -1.6064, -1.9170,  0.5488],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0800, -0.0187,  0.0118,  ...,  0.0043, -0.0139,  0.0051],
        [-0.0147,  0.0874,  0.0093,  ...,  0.0111,  0.0033, -0.0104],
        [ 0.0388,  0.0038,  0.0637,  ..., -0.0057,  0.0044,  0.0089],
        ...,
        [ 0.0024,  0.0105, -0.0027,  ...,  0.0715, -0.0053, -0.0140],
        [ 0.0043,  0.0090, -0.0003,  ..., -0.0212,  0.0438, -0.0124],
        [-0.0311, -0.0017, -0.0094,  ..., -0.0180, -0.0143,  0.0516]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.0371, -1.0752,  1.2900,  ..., -1.4688, -1.7754,  0.9277]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 21:36:21 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If the present form is establish, the past form is established
If the present form is relate, the past form is related
If the present form is believe, the past form is believed
If the present form is marry, the past form is married
If the present form is introduce, the past form is introduced
If the present form is enjoy, the past form is enjoyed
If the present form is agree, the past form is agreed
If the present form is create, the past form is
2024-07-30 21:36:21 root INFO     [order_1_approx] starting weight calculation for If the present form is agree, the past form is agreed
If the present form is believe, the past form is believed
If the present form is introduce, the past form is introduced
If the present form is relate, the past form is related
If the present form is establish, the past form is established
If the present form is marry, the past form is married
If the present form is create, the past form is created
If the present form is enjoy, the past form is
2024-07-30 21:36:21 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-30 21:38:25 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1519, -0.2432,  0.1232,  ..., -0.7480, -0.2671, -0.1898],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.0820, -0.4099,  1.3213,  ..., -2.6094, -4.2695, -0.6748],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0494, -0.0053,  0.0109,  ..., -0.0150,  0.0053,  0.0390],
        [-0.0135,  0.0502, -0.0110,  ...,  0.0053, -0.0036,  0.0003],
        [-0.0002, -0.0134,  0.0405,  ..., -0.0045, -0.0133,  0.0112],
        ...,
        [-0.0232,  0.0019,  0.0033,  ...,  0.0539, -0.0029, -0.0264],
        [ 0.0115, -0.0001, -0.0041,  ..., -0.0117,  0.0169, -0.0093],
        [-0.0121,  0.0064, -0.0056,  ..., -0.0177, -0.0083,  0.0330]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.0781, -0.5244,  1.0010,  ..., -2.1367, -4.2695, -0.7109]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 21:38:26 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If the present form is agree, the past form is agreed
If the present form is believe, the past form is believed
If the present form is introduce, the past form is introduced
If the present form is relate, the past form is related
If the present form is establish, the past form is established
If the present form is marry, the past form is married
If the present form is create, the past form is created
If the present form is enjoy, the past form is
2024-07-30 21:38:26 root INFO     [order_1_approx] starting weight calculation for If the present form is create, the past form is created
If the present form is relate, the past form is related
If the present form is agree, the past form is agreed
If the present form is believe, the past form is believed
If the present form is establish, the past form is established
If the present form is marry, the past form is married
If the present form is enjoy, the past form is enjoyed
If the present form is introduce, the past form is
2024-07-30 21:38:26 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-30 21:40:32 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.7373, -0.2068,  0.1285,  ...,  0.0251, -0.3364,  0.0162],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.2676,  1.2695,  2.8477,  ...,  0.6372, -2.7832, -0.6992],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.1021, -0.0067,  0.0114,  ..., -0.0003, -0.0006,  0.0138],
        [-0.0196,  0.0725, -0.0096,  ...,  0.0199, -0.0188, -0.0206],
        [ 0.0227, -0.0042,  0.0383,  ..., -0.0129, -0.0117,  0.0109],
        ...,
        [-0.0038, -0.0153, -0.0137,  ...,  0.0824, -0.0084,  0.0145],
        [-0.0042, -0.0134,  0.0109,  ..., -0.0148,  0.0385, -0.0183],
        [-0.0257, -0.0124,  0.0142,  ..., -0.0090, -0.0211,  0.0466]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.2212,  1.3271,  2.7773,  ...,  0.2578, -2.2949, -0.3032]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 21:40:33 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If the present form is create, the past form is created
If the present form is relate, the past form is related
If the present form is agree, the past form is agreed
If the present form is believe, the past form is believed
If the present form is establish, the past form is established
If the present form is marry, the past form is married
If the present form is enjoy, the past form is enjoyed
If the present form is introduce, the past form is
2024-07-30 21:40:33 root INFO     [order_1_approx] starting weight calculation for If the present form is believe, the past form is believed
If the present form is enjoy, the past form is enjoyed
If the present form is create, the past form is created
If the present form is relate, the past form is related
If the present form is introduce, the past form is introduced
If the present form is establish, the past form is established
If the present form is marry, the past form is married
If the present form is agree, the past form is
2024-07-30 21:40:33 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-30 21:42:36 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2166, -0.3003, -0.2074,  ..., -0.2053, -0.3108, -0.2861],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.2725, -1.9365,  0.7822,  ..., -0.9180, -3.0332,  0.7891],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 6.8542e-02, -1.4481e-02,  4.0627e-04,  ..., -1.0880e-02,
          9.1782e-03,  2.8488e-02],
        [-2.3895e-02,  5.4291e-02, -1.0729e-04,  ...,  1.4679e-02,
         -1.3107e-02, -1.3077e-02],
        [-1.9684e-03, -1.6190e-02,  3.3234e-02,  ..., -6.0272e-04,
          4.5471e-03, -1.0262e-03],
        ...,
        [ 9.0790e-04,  1.2970e-03, -6.2866e-03,  ...,  6.2012e-02,
         -9.2773e-03, -1.3382e-02],
        [-2.0950e-02,  6.2027e-03, -2.4109e-02,  ..., -1.6556e-02,
          3.6804e-02, -1.9363e-02],
        [ 4.1962e-05, -9.4147e-03,  1.0574e-02,  ..., -2.0126e-02,
         -1.4359e-02,  4.8370e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.5400, -2.0273,  0.7183,  ..., -1.1221, -3.1875,  0.9482]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 21:42:37 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If the present form is believe, the past form is believed
If the present form is enjoy, the past form is enjoyed
If the present form is create, the past form is created
If the present form is relate, the past form is related
If the present form is introduce, the past form is introduced
If the present form is establish, the past form is established
If the present form is marry, the past form is married
If the present form is agree, the past form is
2024-07-30 21:42:37 root INFO     [order_1_approx] starting weight calculation for If the present form is believe, the past form is believed
If the present form is enjoy, the past form is enjoyed
If the present form is establish, the past form is established
If the present form is marry, the past form is married
If the present form is create, the past form is created
If the present form is agree, the past form is agreed
If the present form is introduce, the past form is introduced
If the present form is relate, the past form is
2024-07-30 21:42:37 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-30 21:44:38 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0704, -0.1040, -0.1754,  ..., -0.6089, -0.4121, -0.1838],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.4062,  0.5723,  1.4219,  ..., -0.0454, -2.4961, -1.3086],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 9.1614e-02, -3.1036e-02, -3.2539e-03,  ...,  4.6921e-03,
          3.3283e-03,  1.5236e-02],
        [-2.2614e-02,  9.0820e-02, -7.8354e-03,  ..., -1.6212e-05,
         -8.6670e-03, -8.3313e-03],
        [ 1.0803e-02, -8.6746e-03,  4.3182e-02,  ..., -1.6266e-02,
          1.3580e-02, -1.2421e-02],
        ...,
        [-5.3635e-03,  1.4503e-02, -1.2741e-02,  ...,  7.9102e-02,
         -2.8687e-03,  7.5378e-03],
        [ 3.4904e-03,  5.0354e-04, -2.4300e-03,  ...,  5.2643e-04,
          5.9265e-02, -1.6937e-02],
        [-2.9663e-02,  4.6921e-04,  6.7024e-03,  ..., -9.2468e-03,
         -1.0063e-02,  4.5990e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.1299,  0.5557,  1.1670,  ..., -0.1487, -2.1543, -1.2285]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 21:44:39 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If the present form is believe, the past form is believed
If the present form is enjoy, the past form is enjoyed
If the present form is establish, the past form is established
If the present form is marry, the past form is married
If the present form is create, the past form is created
If the present form is agree, the past form is agreed
If the present form is introduce, the past form is introduced
If the present form is relate, the past form is
2024-07-30 21:44:39 root INFO     total operator prediction time: 1005.785519361496 seconds
2024-07-30 21:44:39 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on verb_Ving - Ved
2024-07-30 21:44:39 root INFO     building operator verb_Ving - Ved
2024-07-30 21:44:39 root INFO     [order_1_approx] starting weight calculation for After something is representing, it has represented
After something is introducing, it has introduced
After something is managing, it has managed
After something is understanding, it has understood
After something is considering, it has considered
After something is losing, it has lost
After something is attending, it has attended
After something is proposing, it has
2024-07-30 21:44:39 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-30 21:46:40 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0715, -0.1732,  0.3208,  ..., -0.1360,  0.2147, -0.2483],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.1289, -2.5312,  2.0801,  ..., -1.1836, -1.7129,  0.9277],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0616, -0.0033,  0.0123,  ...,  0.0066, -0.0083,  0.0140],
        [-0.0207,  0.0247,  0.0082,  ...,  0.0096, -0.0148,  0.0008],
        [ 0.0046, -0.0085,  0.0284,  ..., -0.0107,  0.0009, -0.0060],
        ...,
        [-0.0155,  0.0024,  0.0034,  ...,  0.0453,  0.0086,  0.0060],
        [ 0.0055,  0.0156, -0.0033,  ..., -0.0098,  0.0386, -0.0199],
        [-0.0011,  0.0083,  0.0020,  ..., -0.0057, -0.0205,  0.0282]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.1328, -2.8086,  2.1777,  ..., -1.0625, -1.6104,  0.7441]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 21:46:41 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for After something is representing, it has represented
After something is introducing, it has introduced
After something is managing, it has managed
After something is understanding, it has understood
After something is considering, it has considered
After something is losing, it has lost
After something is attending, it has attended
After something is proposing, it has
2024-07-30 21:46:41 root INFO     [order_1_approx] starting weight calculation for After something is understanding, it has understood
After something is proposing, it has proposed
After something is considering, it has considered
After something is introducing, it has introduced
After something is representing, it has represented
After something is managing, it has managed
After something is losing, it has lost
After something is attending, it has
2024-07-30 21:46:41 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-30 21:48:47 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1473,  0.2205, -0.6792,  ..., -0.5449, -0.3965, -0.3838],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.6270,  1.7139,  0.6934,  ..., -0.9077, -4.7500, -1.1660],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0562,  0.0023,  0.0063,  ...,  0.0083,  0.0175,  0.0048],
        [-0.0182,  0.1080, -0.0092,  ...,  0.0033, -0.0014, -0.0243],
        [ 0.0128,  0.0141,  0.0618,  ...,  0.0085,  0.0005, -0.0043],
        ...,
        [-0.0172,  0.0006,  0.0085,  ...,  0.0867, -0.0133,  0.0019],
        [ 0.0074,  0.0010, -0.0031,  ..., -0.0043,  0.0660, -0.0107],
        [ 0.0057,  0.0165,  0.0009,  ..., -0.0099, -0.0100,  0.0630]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.4434,  1.7754,  0.3994,  ..., -0.2842, -4.2422, -1.0586]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 21:48:54 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for After something is understanding, it has understood
After something is proposing, it has proposed
After something is considering, it has considered
After something is introducing, it has introduced
After something is representing, it has represented
After something is managing, it has managed
After something is losing, it has lost
After something is attending, it has
2024-07-30 21:48:54 root INFO     [order_1_approx] starting weight calculation for After something is attending, it has attended
After something is introducing, it has introduced
After something is losing, it has lost
After something is representing, it has represented
After something is proposing, it has proposed
After something is managing, it has managed
After something is understanding, it has understood
After something is considering, it has
2024-07-30 21:48:54 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-30 21:50:58 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0750, -0.4829,  0.1249,  ..., -0.1257,  0.1455, -0.3657],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.4531, -0.7061,  3.3438,  ..., -2.2539, -0.2939, -0.1777],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0692, -0.0118,  0.0102,  ...,  0.0075,  0.0040,  0.0285],
        [-0.0113,  0.0463,  0.0058,  ...,  0.0123, -0.0111,  0.0017],
        [-0.0004,  0.0038,  0.0481,  ..., -0.0108, -0.0036, -0.0274],
        ...,
        [-0.0041,  0.0082,  0.0135,  ...,  0.0566, -0.0009,  0.0233],
        [ 0.0096,  0.0222,  0.0044,  ..., -0.0249,  0.0507, -0.0289],
        [-0.0010,  0.0217,  0.0143,  ..., -0.0061, -0.0111,  0.0204]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.6289, -0.6904,  2.9199,  ..., -1.6074, -0.6816, -0.0560]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 21:50:58 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for After something is attending, it has attended
After something is introducing, it has introduced
After something is losing, it has lost
After something is representing, it has represented
After something is proposing, it has proposed
After something is managing, it has managed
After something is understanding, it has understood
After something is considering, it has
2024-07-30 21:50:59 root INFO     [order_1_approx] starting weight calculation for After something is representing, it has represented
After something is considering, it has considered
After something is losing, it has lost
After something is introducing, it has introduced
After something is attending, it has attended
After something is managing, it has managed
After something is proposing, it has proposed
After something is understanding, it has
2024-07-30 21:50:59 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-30 21:53:04 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.3984, -0.0844,  0.1852,  ..., -0.5093,  0.0934, -0.6597],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.3398,  1.9053,  1.5459,  ..., -1.3164, -1.7207,  1.4277],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0600,  0.0061,  0.0018,  ..., -0.0006,  0.0011,  0.0208],
        [-0.0247,  0.0491, -0.0033,  ...,  0.0041, -0.0059,  0.0026],
        [-0.0088, -0.0249,  0.0576,  ..., -0.0101,  0.0104, -0.0198],
        ...,
        [ 0.0069,  0.0131, -0.0010,  ...,  0.0636,  0.0085,  0.0006],
        [-0.0056, -0.0012,  0.0018,  ..., -0.0167,  0.0481, -0.0075],
        [-0.0051,  0.0093,  0.0216,  ..., -0.0094, -0.0120,  0.0176]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.3047,  1.8125,  1.4814,  ..., -1.1357, -1.7061,  1.3662]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 21:53:06 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for After something is representing, it has represented
After something is considering, it has considered
After something is losing, it has lost
After something is introducing, it has introduced
After something is attending, it has attended
After something is managing, it has managed
After something is proposing, it has proposed
After something is understanding, it has
2024-07-30 21:53:06 root INFO     [order_1_approx] starting weight calculation for After something is managing, it has managed
After something is understanding, it has understood
After something is considering, it has considered
After something is attending, it has attended
After something is losing, it has lost
After something is proposing, it has proposed
After something is representing, it has represented
After something is introducing, it has
2024-07-30 21:53:06 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-30 21:55:12 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.6523, -0.4773,  0.0684,  ...,  0.0708, -0.2617, -0.1030],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.8818,  0.2294,  2.7637,  ...,  0.1699, -2.7109, -0.9277],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0607, -0.0052,  0.0173,  ...,  0.0040, -0.0032,  0.0133],
        [-0.0219,  0.0478, -0.0099,  ...,  0.0287, -0.0075, -0.0122],
        [ 0.0136, -0.0136,  0.0379,  ..., -0.0014,  0.0055, -0.0031],
        ...,
        [ 0.0060, -0.0063,  0.0044,  ...,  0.0652, -0.0044,  0.0166],
        [ 0.0114,  0.0068, -0.0062,  ..., -0.0224,  0.0482, -0.0055],
        [-0.0215,  0.0182,  0.0075,  ..., -0.0116, -0.0142,  0.0365]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.0020,  0.1270,  3.1035,  ...,  0.2262, -2.8027, -1.0615]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 21:55:13 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for After something is managing, it has managed
After something is understanding, it has understood
After something is considering, it has considered
After something is attending, it has attended
After something is losing, it has lost
After something is proposing, it has proposed
After something is representing, it has represented
After something is introducing, it has
2024-07-30 21:55:13 root INFO     [order_1_approx] starting weight calculation for After something is attending, it has attended
After something is representing, it has represented
After something is understanding, it has understood
After something is managing, it has managed
After something is proposing, it has proposed
After something is introducing, it has introduced
After something is considering, it has considered
After something is losing, it has
2024-07-30 21:55:13 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-30 21:57:18 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0546, -0.2988,  0.3096,  ..., -0.5273,  0.5029, -0.2394],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.3398, -0.7617,  0.4556,  ..., -1.9941, -0.7002, -1.3076],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0863,  0.0132,  0.0077,  ...,  0.0099, -0.0031,  0.0201],
        [-0.0357,  0.0612, -0.0096,  ...,  0.0115, -0.0097, -0.0076],
        [ 0.0243,  0.0033,  0.0476,  ...,  0.0010,  0.0037, -0.0128],
        ...,
        [-0.0135,  0.0313, -0.0133,  ...,  0.0546, -0.0046,  0.0118],
        [ 0.0070,  0.0118, -0.0063,  ..., -0.0101,  0.0589, -0.0318],
        [-0.0114,  0.0202,  0.0398,  ..., -0.0412,  0.0020,  0.0475]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.3711, -0.7974,  0.4985,  ..., -1.4834, -0.8242, -1.5859]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 21:57:28 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for After something is attending, it has attended
After something is representing, it has represented
After something is understanding, it has understood
After something is managing, it has managed
After something is proposing, it has proposed
After something is introducing, it has introduced
After something is considering, it has considered
After something is losing, it has
2024-07-30 21:57:28 root INFO     [order_1_approx] starting weight calculation for After something is introducing, it has introduced
After something is understanding, it has understood
After something is attending, it has attended
After something is losing, it has lost
After something is considering, it has considered
After something is representing, it has represented
After something is proposing, it has proposed
After something is managing, it has
2024-07-30 21:57:28 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-30 21:59:33 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1014,  0.4009,  0.0070,  ..., -0.1968, -0.3037, -0.2566],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.1660, -1.6816,  1.7422,  ..., -1.8711, -1.9824, -2.2012],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0549,  0.0199,  0.0097,  ..., -0.0073,  0.0005,  0.0094],
        [-0.0096,  0.0553, -0.0149,  ...,  0.0105, -0.0026,  0.0015],
        [-0.0046,  0.0054,  0.0541,  ..., -0.0010,  0.0095, -0.0149],
        ...,
        [-0.0060,  0.0074,  0.0090,  ...,  0.0677, -0.0005,  0.0105],
        [-0.0099,  0.0132, -0.0025,  ...,  0.0010,  0.0537, -0.0255],
        [-0.0048,  0.0038,  0.0107,  ..., -0.0219, -0.0163,  0.0364]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.2148, -1.7656,  1.4521,  ..., -1.4102, -1.9814, -2.2031]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 21:59:34 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for After something is introducing, it has introduced
After something is understanding, it has understood
After something is attending, it has attended
After something is losing, it has lost
After something is considering, it has considered
After something is representing, it has represented
After something is proposing, it has proposed
After something is managing, it has
2024-07-30 21:59:34 root INFO     [order_1_approx] starting weight calculation for After something is understanding, it has understood
After something is introducing, it has introduced
After something is managing, it has managed
After something is losing, it has lost
After something is proposing, it has proposed
After something is attending, it has attended
After something is considering, it has considered
After something is representing, it has
2024-07-30 21:59:34 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-30 22:01:35 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1113,  0.0652, -0.3718,  ..., -0.3833,  0.3345, -0.3606],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.4014, -0.1445,  2.2383,  ..., -1.3311, -1.4375, -0.8008],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0797,  0.0015,  0.0166,  ...,  0.0158,  0.0122,  0.0126],
        [-0.0350,  0.0741, -0.0139,  ...,  0.0054,  0.0025, -0.0291],
        [ 0.0145,  0.0022,  0.0723,  ..., -0.0023,  0.0038, -0.0093],
        ...,
        [-0.0029,  0.0157, -0.0137,  ...,  0.0945,  0.0043,  0.0153],
        [ 0.0030,  0.0003,  0.0050,  ..., -0.0103,  0.0621, -0.0107],
        [-0.0142,  0.0009,  0.0060,  ..., -0.0127, -0.0202,  0.0647]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.1252, -0.1396,  2.3008,  ..., -1.0918, -1.4082, -0.8901]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 22:01:36 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for After something is understanding, it has understood
After something is introducing, it has introduced
After something is managing, it has managed
After something is losing, it has lost
After something is proposing, it has proposed
After something is attending, it has attended
After something is considering, it has considered
After something is representing, it has
2024-07-30 22:01:36 root INFO     total operator prediction time: 1016.9488332271576 seconds
2024-07-30 22:01:36 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on Ving - verb_inf
2024-07-30 22:01:36 root INFO     building operator Ving - verb_inf
2024-07-30 22:01:36 root INFO     [order_1_approx] starting weight calculation for operating is the active form of operate
becoming is the active form of become
achieving is the active form of achieve
reducing is the active form of reduce
allowing is the active form of allow
enjoying is the active form of enjoy
protecting is the active form of protect
referring is the active form of
2024-07-30 22:01:36 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-30 22:03:37 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0857, -0.3838,  0.1982,  ..., -0.2418,  0.1506, -0.2781],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.8428, -5.2266,  0.4976,  ...,  3.4316, -0.7397, -3.8281],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0589,  0.0015,  0.0079,  ...,  0.0140,  0.0014,  0.0041],
        [-0.0075,  0.0600,  0.0039,  ...,  0.0066, -0.0048, -0.0050],
        [ 0.0079, -0.0044,  0.0355,  ...,  0.0028, -0.0063,  0.0049],
        ...,
        [ 0.0067,  0.0133,  0.0004,  ...,  0.0613, -0.0104,  0.0041],
        [-0.0063,  0.0043,  0.0017,  ..., -0.0011,  0.0350, -0.0073],
        [ 0.0042,  0.0098, -0.0004,  ..., -0.0093, -0.0037,  0.0476]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.8218, -5.3711,  0.4287,  ...,  3.5957, -0.7944, -3.7480]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 22:03:38 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for operating is the active form of operate
becoming is the active form of become
achieving is the active form of achieve
reducing is the active form of reduce
allowing is the active form of allow
enjoying is the active form of enjoy
protecting is the active form of protect
referring is the active form of
2024-07-30 22:03:38 root INFO     [order_1_approx] starting weight calculation for achieving is the active form of achieve
referring is the active form of refer
allowing is the active form of allow
becoming is the active form of become
enjoying is the active form of enjoy
reducing is the active form of reduce
protecting is the active form of protect
operating is the active form of
2024-07-30 22:03:38 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-30 22:05:37 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1677, -0.0134, -0.5322,  ..., -0.3464, -0.3418, -0.1161],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.1826, -4.5078,  0.7788,  ...,  1.6602, -0.1475, -1.5713],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0770,  0.0109, -0.0016,  ...,  0.0024,  0.0001,  0.0103],
        [-0.0035,  0.0542,  0.0081,  ...,  0.0069,  0.0006, -0.0071],
        [ 0.0235,  0.0105,  0.0509,  ..., -0.0019, -0.0010,  0.0094],
        ...,
        [-0.0005,  0.0056, -0.0112,  ...,  0.0645, -0.0123, -0.0016],
        [ 0.0137,  0.0166, -0.0052,  ..., -0.0166,  0.0413, -0.0070],
        [ 0.0021,  0.0017,  0.0017,  ..., -0.0013, -0.0171,  0.0597]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.0391, -4.2383,  0.6479,  ...,  1.8135, -0.1010, -1.4775]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 22:05:49 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for achieving is the active form of achieve
referring is the active form of refer
allowing is the active form of allow
becoming is the active form of become
enjoying is the active form of enjoy
reducing is the active form of reduce
protecting is the active form of protect
operating is the active form of
2024-07-30 22:05:52 root INFO     [order_1_approx] starting weight calculation for achieving is the active form of achieve
enjoying is the active form of enjoy
referring is the active form of refer
allowing is the active form of allow
reducing is the active form of reduce
protecting is the active form of protect
operating is the active form of operate
becoming is the active form of
2024-07-30 22:05:52 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-30 22:07:54 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0372,  0.3384,  0.1353,  ...,  0.0181, -0.3857,  0.1592],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.3828, -2.7383, -0.2114,  ...,  3.4258,  0.4810, -2.8613],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.1010, -0.0215,  0.0056,  ...,  0.0073, -0.0055,  0.0325],
        [ 0.0031,  0.0860, -0.0127,  ...,  0.0023, -0.0044, -0.0135],
        [ 0.0121, -0.0035,  0.0691,  ..., -0.0082,  0.0117, -0.0175],
        ...,
        [ 0.0158,  0.0178, -0.0043,  ...,  0.0917, -0.0027, -0.0016],
        [-0.0183,  0.0370, -0.0042,  ..., -0.0118,  0.0725, -0.0054],
        [ 0.0095, -0.0186, -0.0075,  ..., -0.0126, -0.0211,  0.0880]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.1309, -2.9551, -0.3066,  ...,  3.4512,  0.3645, -2.9082]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 22:07:55 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for achieving is the active form of achieve
enjoying is the active form of enjoy
referring is the active form of refer
allowing is the active form of allow
reducing is the active form of reduce
protecting is the active form of protect
operating is the active form of operate
becoming is the active form of
2024-07-30 22:07:55 root INFO     [order_1_approx] starting weight calculation for operating is the active form of operate
achieving is the active form of achieve
protecting is the active form of protect
allowing is the active form of allow
becoming is the active form of become
referring is the active form of refer
enjoying is the active form of enjoy
reducing is the active form of
2024-07-30 22:07:55 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-30 22:09:55 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0580, -0.4028, -0.1270,  ..., -0.1790,  0.2773, -0.5347],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.0439, -3.2461, -1.2773,  ..., -1.2744, -1.4277, -4.4102],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0554, -0.0109,  0.0088,  ..., -0.0012,  0.0007,  0.0110],
        [-0.0022,  0.0534,  0.0005,  ...,  0.0077,  0.0064,  0.0016],
        [ 0.0133, -0.0093,  0.0382,  ..., -0.0022, -0.0054,  0.0032],
        ...,
        [-0.0033,  0.0068, -0.0036,  ...,  0.0395,  0.0018, -0.0014],
        [-0.0093,  0.0117, -0.0007,  ...,  0.0052,  0.0372, -0.0155],
        [-0.0117, -0.0020, -0.0070,  ..., -0.0099,  0.0014,  0.0422]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.0186, -3.2617, -1.4785,  ..., -1.0430, -1.7471, -3.9434]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 22:09:56 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for operating is the active form of operate
achieving is the active form of achieve
protecting is the active form of protect
allowing is the active form of allow
becoming is the active form of become
referring is the active form of refer
enjoying is the active form of enjoy
reducing is the active form of
2024-07-30 22:09:56 root INFO     [order_1_approx] starting weight calculation for becoming is the active form of become
reducing is the active form of reduce
operating is the active form of operate
allowing is the active form of allow
achieving is the active form of achieve
referring is the active form of refer
protecting is the active form of protect
enjoying is the active form of
2024-07-30 22:09:56 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-30 22:11:57 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0187, -0.2773, -0.0417,  ..., -0.6255, -0.0423,  0.0918],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.2734, -3.1211, -0.9175,  ...,  1.2510, -2.3516, -2.9707],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.1091, -0.0093,  0.0073,  ...,  0.0030,  0.0004,  0.0302],
        [ 0.0052,  0.0756, -0.0030,  ...,  0.0076, -0.0161,  0.0053],
        [ 0.0265, -0.0005,  0.0545,  ..., -0.0059,  0.0021, -0.0094],
        ...,
        [-0.0144, -0.0013,  0.0025,  ...,  0.0751, -0.0064, -0.0216],
        [-0.0008,  0.0106,  0.0053,  ...,  0.0102,  0.0616, -0.0151],
        [-0.0055,  0.0121, -0.0091,  ..., -0.0149, -0.0211,  0.0760]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.1373, -3.3145, -1.3359,  ...,  1.8184, -2.1992, -2.9141]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 22:11:58 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for becoming is the active form of become
reducing is the active form of reduce
operating is the active form of operate
allowing is the active form of allow
achieving is the active form of achieve
referring is the active form of refer
protecting is the active form of protect
enjoying is the active form of
2024-07-30 22:11:58 root INFO     [order_1_approx] starting weight calculation for enjoying is the active form of enjoy
referring is the active form of refer
protecting is the active form of protect
operating is the active form of operate
becoming is the active form of become
reducing is the active form of reduce
allowing is the active form of allow
achieving is the active form of
2024-07-30 22:11:58 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-30 22:14:03 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3340, -0.0414, -0.2290,  ..., -0.2976, -0.2939,  0.2180],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.7783, -1.7988, -0.4766,  ...,  0.5288, -2.8438, -2.5078],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0701, -0.0072,  0.0116,  ...,  0.0147, -0.0033,  0.0166],
        [ 0.0043,  0.0569,  0.0022,  ...,  0.0099, -0.0118, -0.0077],
        [ 0.0115, -0.0150,  0.0460,  ..., -0.0011,  0.0047, -0.0017],
        ...,
        [ 0.0064, -0.0011, -0.0078,  ...,  0.0600, -0.0091, -0.0097],
        [-0.0094,  0.0034,  0.0055,  ..., -0.0043,  0.0390, -0.0057],
        [ 0.0045, -0.0038,  0.0022,  ..., -0.0032, -0.0037,  0.0494]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.6631, -1.9873, -0.7461,  ...,  0.7871, -2.8340, -2.4492]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 22:14:04 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for enjoying is the active form of enjoy
referring is the active form of refer
protecting is the active form of protect
operating is the active form of operate
becoming is the active form of become
reducing is the active form of reduce
allowing is the active form of allow
achieving is the active form of
2024-07-30 22:14:04 root INFO     [order_1_approx] starting weight calculation for becoming is the active form of become
operating is the active form of operate
reducing is the active form of reduce
referring is the active form of refer
achieving is the active form of achieve
enjoying is the active form of enjoy
allowing is the active form of allow
protecting is the active form of
2024-07-30 22:14:04 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-30 22:16:09 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0464, -0.5776,  0.0779,  ..., -0.1592, -0.0538, -0.3118],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.1797, -5.5117, -1.0068,  ...,  1.6602, -1.0625, -2.3379],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0502, -0.0079,  0.0017,  ..., -0.0031, -0.0053,  0.0246],
        [-0.0119,  0.0358,  0.0101,  ..., -0.0034,  0.0032,  0.0037],
        [ 0.0244,  0.0011,  0.0184,  ..., -0.0035, -0.0110, -0.0046],
        ...,
        [ 0.0147,  0.0070, -0.0040,  ...,  0.0374,  0.0003,  0.0111],
        [-0.0002,  0.0067, -0.0066,  ...,  0.0021,  0.0323, -0.0248],
        [ 0.0008,  0.0059, -0.0026,  ..., -0.0047, -0.0073,  0.0461]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.2925, -5.4453, -1.0029,  ...,  1.7842, -1.1484, -2.1914]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 22:16:10 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for becoming is the active form of become
operating is the active form of operate
reducing is the active form of reduce
referring is the active form of refer
achieving is the active form of achieve
enjoying is the active form of enjoy
allowing is the active form of allow
protecting is the active form of
2024-07-30 22:16:10 root INFO     [order_1_approx] starting weight calculation for operating is the active form of operate
achieving is the active form of achieve
enjoying is the active form of enjoy
becoming is the active form of become
reducing is the active form of reduce
protecting is the active form of protect
referring is the active form of refer
allowing is the active form of
2024-07-30 22:16:10 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-30 22:18:16 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1501, -0.2281,  0.1218,  ..., -0.6235,  0.4050,  0.0361],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.1602, -5.5469, -1.7734,  ...,  1.6836, -2.4902, -0.8315],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0679, -0.0060, -0.0024,  ...,  0.0022, -0.0022,  0.0073],
        [-0.0017,  0.0358, -0.0160,  ...,  0.0040, -0.0093, -0.0011],
        [ 0.0077, -0.0065,  0.0257,  ..., -0.0064, -0.0021, -0.0132],
        ...,
        [ 0.0109, -0.0012, -0.0056,  ...,  0.0385, -0.0047, -0.0010],
        [ 0.0017,  0.0159, -0.0006,  ..., -0.0021,  0.0315, -0.0109],
        [ 0.0115,  0.0132, -0.0054,  ..., -0.0053, -0.0107,  0.0430]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.2236, -5.3828, -1.9922,  ...,  2.0742, -2.7461, -0.8540]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 22:18:17 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for operating is the active form of operate
achieving is the active form of achieve
enjoying is the active form of enjoy
becoming is the active form of become
reducing is the active form of reduce
protecting is the active form of protect
referring is the active form of refer
allowing is the active form of
2024-07-30 22:18:17 root INFO     total operator prediction time: 1000.8608417510986 seconds
2024-07-30 22:18:17 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on noun - plural_irreg
2024-07-30 22:18:17 root INFO     building operator noun - plural_irreg
2024-07-30 22:18:17 root INFO     [order_1_approx] starting weight calculation for The plural form of energy is energies
The plural form of datum is data
The plural form of child is children
The plural form of ability is abilities
The plural form of history is histories
The plural form of entry is entries
The plural form of responsibility is responsibilities
The plural form of property is
2024-07-30 22:18:17 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-30 22:20:23 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2336,  0.1006,  0.0390,  ..., -0.2886, -0.2372, -0.1985],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.8594, -2.7129,  0.8296,  ..., -1.1211, -2.6348, -1.7314],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0953,  0.0085, -0.0149,  ...,  0.0164, -0.0080,  0.0186],
        [-0.0141,  0.0670,  0.0069,  ...,  0.0363,  0.0059, -0.0130],
        [ 0.0105,  0.0083,  0.0714,  ...,  0.0014, -0.0015,  0.0026],
        ...,
        [ 0.0311,  0.0069,  0.0016,  ...,  0.0652,  0.0071, -0.0025],
        [-0.0303,  0.0335, -0.0248,  ..., -0.0220,  0.0742, -0.0205],
        [ 0.0244, -0.0066,  0.0152,  ..., -0.0179, -0.0184,  0.0862]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.7764, -2.2969,  0.7715,  ..., -1.0723, -2.2734, -1.5996]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 22:20:24 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of energy is energies
The plural form of datum is data
The plural form of child is children
The plural form of ability is abilities
The plural form of history is histories
The plural form of entry is entries
The plural form of responsibility is responsibilities
The plural form of property is
2024-07-30 22:20:24 root INFO     [order_1_approx] starting weight calculation for The plural form of property is properties
The plural form of datum is data
The plural form of entry is entries
The plural form of energy is energies
The plural form of history is histories
The plural form of responsibility is responsibilities
The plural form of child is children
The plural form of ability is
2024-07-30 22:20:24 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-30 22:22:28 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3613,  0.4048,  0.4263,  ..., -0.6270, -0.3057,  0.0074],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.1035, -1.2695,  0.8735,  ..., -0.9688, -2.7480, -1.3057],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 9.0576e-02,  6.2447e-03, -6.3438e-03,  ..., -9.6207e-03,
          1.3054e-02,  7.3662e-03],
        [ 2.0752e-03,  9.7778e-02, -6.7902e-04,  ...,  4.7943e-02,
          7.1106e-03, -2.4109e-02],
        [-9.6893e-04, -2.3842e-05,  6.6162e-02,  ..., -7.7515e-03,
         -2.3518e-03,  2.8885e-02],
        ...,
        [ 1.2383e-02,  3.7048e-02, -4.3411e-03,  ...,  7.2205e-02,
         -5.3215e-03,  1.5930e-02],
        [-2.2964e-02,  2.1317e-02,  2.3239e-02,  ..., -1.4832e-02,
          4.2175e-02, -3.3760e-03],
        [-5.1422e-03,  2.4586e-03,  1.0376e-02,  ..., -2.3365e-03,
         -7.1449e-03,  8.0811e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.1055, -0.7969,  0.7051,  ..., -0.8496, -2.6895, -1.4111]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 22:22:29 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of property is properties
The plural form of datum is data
The plural form of entry is entries
The plural form of energy is energies
The plural form of history is histories
The plural form of responsibility is responsibilities
The plural form of child is children
The plural form of ability is
2024-07-30 22:22:29 root INFO     [order_1_approx] starting weight calculation for The plural form of history is histories
The plural form of datum is data
The plural form of property is properties
The plural form of child is children
The plural form of entry is entries
The plural form of responsibility is responsibilities
The plural form of ability is abilities
The plural form of energy is
2024-07-30 22:22:29 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-30 22:24:33 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0350,  0.2366, -0.2693,  ..., -0.1267, -0.1017,  0.0345],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.5986,  0.8081,  1.3281,  ..., -2.9082, -2.9531, -3.1895],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0673,  0.0199, -0.0062,  ...,  0.0048, -0.0144,  0.0146],
        [ 0.0046,  0.0698, -0.0106,  ...,  0.0282,  0.0274,  0.0217],
        [-0.0039,  0.0063,  0.0675,  ...,  0.0074, -0.0008,  0.0166],
        ...,
        [ 0.0131,  0.0004,  0.0041,  ...,  0.0620,  0.0084, -0.0111],
        [-0.0055,  0.0192, -0.0082,  ..., -0.0218,  0.0482, -0.0060],
        [ 0.0125,  0.0049,  0.0085,  ...,  0.0011, -0.0209,  0.0536]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.7759,  0.4985,  1.1768,  ..., -2.4160, -2.6406, -3.1719]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 22:24:34 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of history is histories
The plural form of datum is data
The plural form of property is properties
The plural form of child is children
The plural form of entry is entries
The plural form of responsibility is responsibilities
The plural form of ability is abilities
The plural form of energy is
2024-07-30 22:24:34 root INFO     [order_1_approx] starting weight calculation for The plural form of property is properties
The plural form of child is children
The plural form of energy is energies
The plural form of history is histories
The plural form of datum is data
The plural form of responsibility is responsibilities
The plural form of ability is abilities
The plural form of entry is
2024-07-30 22:24:34 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-30 22:26:40 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0982,  0.1785, -0.2915,  ...,  0.1550, -0.0369,  0.0114],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.4834, -1.5254, -1.0986,  ..., -0.4966, -4.7578, -4.0156],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.1257, -0.0042,  0.0008,  ..., -0.0218,  0.0193, -0.0052],
        [-0.0257,  0.1273,  0.0008,  ...,  0.0151, -0.0015, -0.0039],
        [-0.0070,  0.0077,  0.1055,  ...,  0.0005, -0.0080,  0.0159],
        ...,
        [ 0.0401,  0.0135, -0.0194,  ...,  0.1187, -0.0277,  0.0349],
        [ 0.0104,  0.0086,  0.0132,  ...,  0.0014,  0.0740,  0.0040],
        [-0.0135,  0.0180,  0.0092,  ..., -0.0137, -0.0120,  0.0993]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.7939, -1.4062, -1.6953,  ..., -1.1494, -4.6797, -3.9473]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 22:26:41 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of property is properties
The plural form of child is children
The plural form of energy is energies
The plural form of history is histories
The plural form of datum is data
The plural form of responsibility is responsibilities
The plural form of ability is abilities
The plural form of entry is
2024-07-30 22:26:41 root INFO     [order_1_approx] starting weight calculation for The plural form of ability is abilities
The plural form of property is properties
The plural form of history is histories
The plural form of energy is energies
The plural form of datum is data
The plural form of responsibility is responsibilities
The plural form of entry is entries
The plural form of child is
2024-07-30 22:26:41 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-30 22:28:45 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0702, -0.0797,  0.1084,  ..., -0.2007, -0.9287, -0.1162],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.2500, -2.4297,  1.5508,  ..., -1.8682, -0.5571, -2.3926],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 6.5674e-02, -1.7761e-02, -8.1940e-03,  ...,  1.8616e-02,
          2.1606e-02, -7.0000e-03],
        [-1.1421e-02,  5.6885e-02,  6.0310e-03,  ...,  1.3542e-02,
         -6.3438e-03, -7.4863e-04],
        [ 7.9575e-03, -1.1034e-03,  5.3986e-02,  ..., -3.8643e-03,
          5.2528e-03,  6.7520e-03],
        ...,
        [-1.6983e-02,  1.2421e-02, -7.4387e-05,  ...,  6.1707e-02,
         -2.6306e-02,  9.4452e-03],
        [ 2.2621e-03,  1.2909e-02, -5.6381e-03,  ...,  5.1117e-03,
          4.7028e-02, -1.0910e-03],
        [ 4.2763e-03, -5.4359e-03, -1.2421e-02,  ..., -9.5444e-03,
         -1.1032e-02,  5.2887e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.5117, -2.3711,  1.2920,  ..., -2.0039, -0.6387, -2.6309]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 22:28:46 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of ability is abilities
The plural form of property is properties
The plural form of history is histories
The plural form of energy is energies
The plural form of datum is data
The plural form of responsibility is responsibilities
The plural form of entry is entries
The plural form of child is
2024-07-30 22:28:46 root INFO     [order_1_approx] starting weight calculation for The plural form of energy is energies
The plural form of child is children
The plural form of property is properties
The plural form of responsibility is responsibilities
The plural form of history is histories
The plural form of entry is entries
The plural form of ability is abilities
The plural form of datum is
2024-07-30 22:28:46 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-30 22:30:48 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.6016,  0.3748, -0.5850,  ...,  0.0738, -0.7246,  0.0985],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.6094, -2.1016,  2.3984,  ..., -1.1973, -4.0391, -1.9990],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.1129, -0.0264,  0.0248,  ..., -0.0290,  0.0193, -0.0026],
        [ 0.0187,  0.1240, -0.0006,  ...,  0.0452, -0.0091,  0.0183],
        [ 0.0075, -0.0037,  0.0952,  ..., -0.0123,  0.0068, -0.0233],
        ...,
        [ 0.0224,  0.0263,  0.0029,  ...,  0.1182, -0.0351,  0.0262],
        [-0.0072,  0.0224,  0.0082,  ..., -0.0225,  0.0901, -0.0209],
        [ 0.0046,  0.0423,  0.0006,  ..., -0.0139, -0.0117,  0.1065]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.7578, -3.1055,  2.8125,  ..., -1.6895, -3.7754, -2.0273]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 22:30:50 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of energy is energies
The plural form of child is children
The plural form of property is properties
The plural form of responsibility is responsibilities
The plural form of history is histories
The plural form of entry is entries
The plural form of ability is abilities
The plural form of datum is
2024-07-30 22:30:50 root INFO     [order_1_approx] starting weight calculation for The plural form of child is children
The plural form of entry is entries
The plural form of datum is data
The plural form of responsibility is responsibilities
The plural form of energy is energies
The plural form of property is properties
The plural form of ability is abilities
The plural form of history is
2024-07-30 22:30:50 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-30 22:32:52 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2668, -0.1538, -0.1210,  ...,  0.0120,  0.0453, -0.0955],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.6211, -1.7852,  1.5273,  ..., -2.1270, -3.6992, -3.1621],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0764,  0.0148,  0.0060,  ..., -0.0082, -0.0037,  0.0051],
        [-0.0145,  0.0754,  0.0102,  ...,  0.0114, -0.0065, -0.0018],
        [ 0.0229,  0.0013,  0.0469,  ...,  0.0116, -0.0040,  0.0224],
        ...,
        [ 0.0198,  0.0239,  0.0047,  ...,  0.0655, -0.0137,  0.0129],
        [-0.0194,  0.0240,  0.0097,  ...,  0.0051,  0.0586, -0.0078],
        [ 0.0197,  0.0193, -0.0052,  ...,  0.0006, -0.0196,  0.0742]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.4858, -1.5586,  1.4531,  ..., -1.9941, -3.9277, -2.8008]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 22:32:53 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of child is children
The plural form of entry is entries
The plural form of datum is data
The plural form of responsibility is responsibilities
The plural form of energy is energies
The plural form of property is properties
The plural form of ability is abilities
The plural form of history is
2024-07-30 22:32:53 root INFO     [order_1_approx] starting weight calculation for The plural form of child is children
The plural form of energy is energies
The plural form of datum is data
The plural form of ability is abilities
The plural form of property is properties
The plural form of history is histories
The plural form of entry is entries
The plural form of responsibility is
2024-07-30 22:32:53 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-30 22:34:57 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1340,  0.8691, -0.8457,  ...,  0.2549, -0.0271, -0.3760],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.4814, -1.2656,  1.1445,  ..., -2.6836, -1.4883, -2.7480],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 6.4819e-02, -7.0190e-04,  1.2634e-02,  ...,  2.7027e-03,
          1.7452e-03,  4.6806e-03],
        [-8.3618e-03,  7.6782e-02, -2.0428e-03,  ...,  1.6144e-02,
          3.8223e-03, -3.9940e-03],
        [ 5.2261e-04,  7.0229e-03,  5.8716e-02,  ..., -2.9278e-04,
         -2.8648e-03,  3.9978e-03],
        ...,
        [ 2.3895e-02,  2.2736e-02,  9.0408e-03,  ...,  8.5754e-02,
         -8.6212e-03,  8.8120e-04],
        [-5.5275e-03,  4.1428e-03,  4.1618e-03,  ..., -3.1757e-04,
          6.1707e-02,  6.4278e-03],
        [ 1.0738e-03, -7.5989e-03, -7.9956e-03,  ...,  5.7220e-05,
         -2.6123e-02,  6.4636e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.5542, -1.3115,  0.8447,  ..., -2.2402, -1.8262, -2.6777]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 22:34:57 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of child is children
The plural form of energy is energies
The plural form of datum is data
The plural form of ability is abilities
The plural form of property is properties
The plural form of history is histories
The plural form of entry is entries
The plural form of responsibility is
2024-07-30 22:34:57 root INFO     total operator prediction time: 1000.8387467861176 seconds
2024-07-30 22:34:58 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on meronyms - member
2024-07-30 22:34:58 root INFO     building operator meronyms - member
2024-07-30 22:34:58 root INFO     [order_1_approx] starting weight calculation for A college is a member of a university
A soldier is a member of a army
A lion is a member of a pride
A calf is a member of a cattle
A student is a member of a class
A musician is a member of a orchestra
A crow is a member of a murder
A player is a member of a
2024-07-30 22:34:58 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-30 22:37:01 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3499, -0.0155, -0.0602,  ..., -0.1046, -0.2583, -0.5254],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.1758, -7.3516,  0.5020,  ..., -1.2480,  1.1553, -5.6328],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0764, -0.0128, -0.0395,  ...,  0.0220,  0.0051, -0.0240],
        [-0.0257,  0.0477,  0.0261,  ..., -0.0135,  0.0227,  0.0069],
        [ 0.0142,  0.0108,  0.0452,  ..., -0.0127, -0.0013,  0.0152],
        ...,
        [-0.0142,  0.0201,  0.0357,  ...,  0.0676, -0.0010,  0.0018],
        [ 0.0068, -0.0041,  0.0067,  ..., -0.0143,  0.0759, -0.0071],
        [-0.0146, -0.0015, -0.0018,  ..., -0.0181, -0.0059,  0.0650]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.7305, -7.1406,  0.6699,  ..., -0.9092,  1.5098, -5.2227]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 22:37:02 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A college is a member of a university
A soldier is a member of a army
A lion is a member of a pride
A calf is a member of a cattle
A student is a member of a class
A musician is a member of a orchestra
A crow is a member of a murder
A player is a member of a
2024-07-30 22:37:02 root INFO     [order_1_approx] starting weight calculation for A soldier is a member of a army
A crow is a member of a murder
A player is a member of a team
A musician is a member of a orchestra
A calf is a member of a cattle
A lion is a member of a pride
A college is a member of a university
A student is a member of a
2024-07-30 22:37:02 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-30 22:39:09 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1541,  0.2153, -0.1793,  ...,  0.4800, -0.0327,  0.0026],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.3115, -4.6562,  3.1758,  ..., -0.8125,  1.5566, -2.6445],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0485,  0.0023, -0.0080,  ..., -0.0059,  0.0012,  0.0023],
        [-0.0304,  0.0383,  0.0165,  ...,  0.0065,  0.0035, -0.0114],
        [-0.0006, -0.0149,  0.0338,  ...,  0.0025,  0.0060,  0.0010],
        ...,
        [-0.0129, -0.0003,  0.0069,  ...,  0.0441, -0.0172, -0.0021],
        [ 0.0108,  0.0124, -0.0063,  ..., -0.0069,  0.0385,  0.0017],
        [-0.0099, -0.0041, -0.0016,  ...,  0.0050, -0.0040,  0.0406]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.2598, -4.6133,  3.2891,  ..., -0.6787,  1.6475, -2.3945]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 22:39:10 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A soldier is a member of a army
A crow is a member of a murder
A player is a member of a team
A musician is a member of a orchestra
A calf is a member of a cattle
A lion is a member of a pride
A college is a member of a university
A student is a member of a
2024-07-30 22:39:10 root INFO     [order_1_approx] starting weight calculation for A player is a member of a team
A student is a member of a class
A college is a member of a university
A musician is a member of a orchestra
A soldier is a member of a army
A calf is a member of a cattle
A crow is a member of a murder
A lion is a member of a
2024-07-30 22:39:10 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-30 22:41:16 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.5977, -0.1017,  0.1257,  ...,  0.1270, -0.3997, -0.0647],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 7.0117, -7.0430,  2.0000,  ..., -1.5898, -1.0996, -2.2188],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0471,  0.0119, -0.0307,  ...,  0.0201, -0.0012,  0.0239],
        [-0.0052,  0.0254,  0.0082,  ..., -0.0226, -0.0069, -0.0069],
        [-0.0023,  0.0106,  0.0487,  ..., -0.0084, -0.0185,  0.0046],
        ...,
        [ 0.0137, -0.0068,  0.0200,  ...,  0.0452,  0.0167, -0.0193],
        [ 0.0345, -0.0091, -0.0160,  ..., -0.0075,  0.0360, -0.0133],
        [-0.0161, -0.0167, -0.0008,  ..., -0.0070, -0.0098,  0.0376]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 7.0625, -7.1328,  2.0996,  ..., -1.5605, -1.3174, -2.0801]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 22:41:17 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A player is a member of a team
A student is a member of a class
A college is a member of a university
A musician is a member of a orchestra
A soldier is a member of a army
A calf is a member of a cattle
A crow is a member of a murder
A lion is a member of a
2024-07-30 22:41:17 root INFO     [order_1_approx] starting weight calculation for A soldier is a member of a army
A lion is a member of a pride
A crow is a member of a murder
A calf is a member of a cattle
A college is a member of a university
A player is a member of a team
A student is a member of a class
A musician is a member of a
2024-07-30 22:41:17 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-30 22:43:17 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4707,  0.4143,  0.2891,  ..., -0.4871, -0.3093, -0.3816],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.0391, -6.1797,  2.8301,  ..., -2.3359, -0.1787, -2.9629],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 2.6962e-02,  6.6185e-04, -2.5692e-03,  ...,  7.8659e-03,
         -6.5460e-03, -1.8234e-03],
        [-6.6376e-04,  2.6443e-02,  1.4435e-02,  ..., -1.7181e-02,
          1.1765e-02, -1.0696e-02],
        [ 1.5926e-03,  3.7231e-03,  2.8015e-02,  ..., -3.3665e-03,
          7.6675e-03,  4.9438e-03],
        ...,
        [ 7.8087e-03,  7.1754e-03,  6.2599e-03,  ...,  2.7069e-02,
          1.4086e-03, -8.3618e-03],
        [ 1.5076e-02,  9.1934e-03, -5.3024e-03,  ...,  7.4387e-04,
          2.8748e-02, -2.9736e-03],
        [ 3.4308e-04, -5.1346e-03, -1.0246e-02,  ..., -1.5869e-02,
         -9.9182e-05,  3.5187e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.9639, -6.1875,  2.8125,  ..., -2.1328, -0.3562, -2.9414]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 22:43:17 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A soldier is a member of a army
A lion is a member of a pride
A crow is a member of a murder
A calf is a member of a cattle
A college is a member of a university
A player is a member of a team
A student is a member of a class
A musician is a member of a
2024-07-30 22:43:18 root INFO     [order_1_approx] starting weight calculation for A player is a member of a team
A student is a member of a class
A college is a member of a university
A calf is a member of a cattle
A musician is a member of a orchestra
A lion is a member of a pride
A soldier is a member of a army
A crow is a member of a
2024-07-30 22:43:18 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-30 22:45:15 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1121, -0.2544,  0.1022,  ...,  0.0007, -0.1091, -0.2046],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 6.6797, -3.5586,  3.2852,  ..., -1.3896, -1.4531, -0.6953],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0533,  0.0294,  0.0045,  ...,  0.0153, -0.0041,  0.0147],
        [ 0.0004,  0.0319,  0.0117,  ..., -0.0033, -0.0045, -0.0255],
        [ 0.0111, -0.0175,  0.0854,  ...,  0.0048,  0.0080, -0.0017],
        ...,
        [ 0.0023, -0.0118,  0.0513,  ...,  0.0968, -0.0065, -0.0205],
        [ 0.0180,  0.0192, -0.0305,  ...,  0.0103,  0.0426, -0.0080],
        [-0.0139, -0.0188, -0.0055,  ..., -0.0118, -0.0134,  0.0667]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 6.8164, -3.8477,  2.7031,  ..., -1.4395, -1.7617, -0.5547]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 22:45:16 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A player is a member of a team
A student is a member of a class
A college is a member of a university
A calf is a member of a cattle
A musician is a member of a orchestra
A lion is a member of a pride
A soldier is a member of a army
A crow is a member of a
2024-07-30 22:45:16 root INFO     [order_1_approx] starting weight calculation for A player is a member of a team
A crow is a member of a murder
A calf is a member of a cattle
A musician is a member of a orchestra
A student is a member of a class
A lion is a member of a pride
A soldier is a member of a army
A college is a member of a
2024-07-30 22:45:16 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-30 22:47:20 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2499, -0.2852, -0.1843,  ...,  0.0857, -0.4004, -0.1633],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.0547, -6.2266,  3.6348,  ..., -2.1035,  3.0352, -2.5215],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0516, -0.0168,  0.0195,  ...,  0.0089,  0.0144, -0.0130],
        [-0.0051,  0.0451, -0.0030,  ..., -0.0025,  0.0081, -0.0089],
        [ 0.0014, -0.0100,  0.0397,  ..., -0.0085, -0.0063,  0.0069],
        ...,
        [ 0.0135,  0.0072,  0.0028,  ...,  0.0558, -0.0099, -0.0175],
        [ 0.0080,  0.0192, -0.0080,  ..., -0.0264,  0.0439,  0.0135],
        [-0.0143, -0.0042,  0.0008,  ...,  0.0004, -0.0041,  0.0514]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.1108, -6.3203,  3.6680,  ..., -1.8936,  3.1484, -2.7148]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 22:47:23 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A player is a member of a team
A crow is a member of a murder
A calf is a member of a cattle
A musician is a member of a orchestra
A student is a member of a class
A lion is a member of a pride
A soldier is a member of a army
A college is a member of a
2024-07-30 22:47:25 root INFO     [order_1_approx] starting weight calculation for A crow is a member of a murder
A student is a member of a class
A lion is a member of a pride
A soldier is a member of a army
A musician is a member of a orchestra
A player is a member of a team
A college is a member of a university
A calf is a member of a
2024-07-30 22:47:25 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-30 22:49:31 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.6484, -0.3103,  0.2949,  ...,  0.0254, -0.3499,  0.2622],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 5.0117, -2.6348,  1.8965,  ..., -1.8115,  1.2988, -1.4385],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 5.9509e-02,  5.1956e-03,  1.6495e-02,  ...,  3.0670e-03,
         -5.4169e-03, -1.7593e-02],
        [ 2.6337e-02,  5.5359e-02, -8.5907e-03,  ...,  2.2469e-03,
          1.4099e-02, -2.6337e-02],
        [-5.6458e-03, -1.0368e-02,  4.9774e-02,  ...,  9.4070e-03,
         -1.6876e-02, -2.0142e-03],
        ...,
        [ 3.1471e-05, -6.0387e-03,  2.2629e-02,  ...,  6.0699e-02,
          5.4169e-04, -7.9956e-03],
        [ 9.1400e-03,  1.9058e-02, -1.6403e-02,  ...,  9.4528e-03,
          5.4016e-02, -6.8932e-03],
        [-3.8719e-03, -4.4327e-03, -3.0184e-04,  ..., -2.7588e-02,
         -8.1253e-04,  6.6895e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.9922, -2.8613,  2.1016,  ..., -1.9043,  0.9282, -1.7969]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 22:49:32 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A crow is a member of a murder
A student is a member of a class
A lion is a member of a pride
A soldier is a member of a army
A musician is a member of a orchestra
A player is a member of a team
A college is a member of a university
A calf is a member of a
2024-07-30 22:49:32 root INFO     [order_1_approx] starting weight calculation for A student is a member of a class
A musician is a member of a orchestra
A crow is a member of a murder
A lion is a member of a pride
A player is a member of a team
A calf is a member of a cattle
A college is a member of a university
A soldier is a member of a
2024-07-30 22:49:32 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-30 22:51:36 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1737,  0.5337, -0.3445,  ...,  0.1503, -0.4041, -0.0051],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.1702, -6.8359,  2.9531,  ..., -2.7207,  2.5938, -4.7734],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0507,  0.0027, -0.0010,  ...,  0.0134, -0.0043, -0.0080],
        [-0.0021,  0.0493,  0.0005,  ..., -0.0135,  0.0015, -0.0047],
        [ 0.0032, -0.0030,  0.0375,  ..., -0.0020,  0.0051,  0.0061],
        ...,
        [-0.0026,  0.0103,  0.0048,  ...,  0.0374, -0.0019,  0.0010],
        [ 0.0035,  0.0076, -0.0076,  ...,  0.0014,  0.0443, -0.0005],
        [-0.0081, -0.0013, -0.0062,  ...,  0.0071,  0.0017,  0.0430]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.3831, -7.0820,  2.7969,  ..., -2.7695,  2.6543, -4.8398]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 22:51:37 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A student is a member of a class
A musician is a member of a orchestra
A crow is a member of a murder
A lion is a member of a pride
A player is a member of a team
A calf is a member of a cattle
A college is a member of a university
A soldier is a member of a
2024-07-30 22:51:37 root INFO     total operator prediction time: 999.7260067462921 seconds
2024-07-30 22:51:37 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on antonyms - binary
2024-07-30 22:51:37 root INFO     building operator antonyms - binary
2024-07-30 22:51:37 root INFO     [order_1_approx] starting weight calculation for The opposite of inside is outside
The opposite of first is last
The opposite of out is in
The opposite of after is before
The opposite of up is down
The opposite of true is false
The opposite of west is east
The opposite of ahead is
2024-07-30 22:51:37 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-30 22:53:43 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1138,  0.4243, -0.5464,  ..., -0.0076,  0.2700, -0.1731],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.5039, -2.7188,  0.4912,  ..., -4.4414, -0.1184, -2.8320],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0812, -0.0141, -0.0068,  ...,  0.0408,  0.0032,  0.0055],
        [-0.0041,  0.0710, -0.0119,  ..., -0.0039,  0.0188,  0.0039],
        [-0.0023, -0.0020,  0.0195,  ...,  0.0032, -0.0363,  0.0011],
        ...,
        [ 0.0039,  0.0195, -0.0043,  ...,  0.0306,  0.0123, -0.0202],
        [-0.0136, -0.0323,  0.0348,  ...,  0.0184,  0.0466,  0.0175],
        [ 0.0007, -0.0252,  0.0098,  ...,  0.0101,  0.0031,  0.0205]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.9062, -2.7090,  0.6685,  ..., -4.1602, -0.2737, -2.0820]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 22:53:44 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of inside is outside
The opposite of first is last
The opposite of out is in
The opposite of after is before
The opposite of up is down
The opposite of true is false
The opposite of west is east
The opposite of ahead is
2024-07-30 22:53:45 root INFO     [order_1_approx] starting weight calculation for The opposite of out is in
The opposite of west is east
The opposite of up is down
The opposite of inside is outside
The opposite of ahead is behind
The opposite of after is before
The opposite of first is last
The opposite of true is
2024-07-30 22:53:45 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-30 22:55:52 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1375,  0.0224,  0.1157,  ..., -0.6108,  0.0992,  0.0531],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.6777, -1.7227, -0.3320,  ...,  1.0684, -1.1113, -2.6016],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0416,  0.0185, -0.0141,  ...,  0.0122, -0.0066, -0.0002],
        [ 0.0067,  0.0417,  0.0022,  ...,  0.0095, -0.0197, -0.0063],
        [-0.0237, -0.0017,  0.0199,  ..., -0.0122, -0.0133, -0.0136],
        ...,
        [ 0.0054,  0.0165, -0.0174,  ...,  0.0293,  0.0164,  0.0119],
        [ 0.0031, -0.0279, -0.0068,  ...,  0.0078,  0.0339,  0.0191],
        [ 0.0027, -0.0201, -0.0151,  ..., -0.0043, -0.0249,  0.0449]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.1406, -1.9941,  0.0530,  ...,  1.0938, -1.4453, -2.4277]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 22:55:56 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of out is in
The opposite of west is east
The opposite of up is down
The opposite of inside is outside
The opposite of ahead is behind
The opposite of after is before
The opposite of first is last
The opposite of true is
2024-07-30 22:55:56 root INFO     [order_1_approx] starting weight calculation for The opposite of ahead is behind
The opposite of inside is outside
The opposite of first is last
The opposite of out is in
The opposite of true is false
The opposite of after is before
The opposite of up is down
The opposite of west is
2024-07-30 22:55:56 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-30 22:58:00 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.3296,  0.3210, -0.0827,  ..., -0.1230,  0.6572, -0.3350],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.9629, -3.0566, -1.5762,  ..., -0.5166,  1.1523, -1.4854],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0795, -0.0070, -0.0108,  ...,  0.0171,  0.0177,  0.0057],
        [ 0.0180,  0.0762,  0.0198,  ..., -0.0067,  0.0063,  0.0134],
        [ 0.0100, -0.0256,  0.0037,  ...,  0.0115, -0.0156,  0.0138],
        ...,
        [ 0.0089, -0.0186, -0.0053,  ...,  0.0625, -0.0038, -0.0080],
        [-0.0137, -0.0262,  0.0147,  ...,  0.0172,  0.0756,  0.0280],
        [ 0.0020, -0.0105,  0.0063,  ...,  0.0110, -0.0101,  0.0299]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.5273, -2.7012, -2.0234,  ..., -0.4390,  1.3047, -0.9233]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 22:58:01 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of ahead is behind
The opposite of inside is outside
The opposite of first is last
The opposite of out is in
The opposite of true is false
The opposite of after is before
The opposite of up is down
The opposite of west is
2024-07-30 22:58:02 root INFO     [order_1_approx] starting weight calculation for The opposite of ahead is behind
The opposite of true is false
The opposite of up is down
The opposite of west is east
The opposite of first is last
The opposite of after is before
The opposite of inside is outside
The opposite of out is
2024-07-30 22:58:02 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-30 23:00:07 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0451,  0.2335,  0.0306,  ..., -0.2588,  0.0925, -0.2401],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.3311, -4.0391,  0.4814,  ..., -1.0566, -0.5693, -3.7402],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0576,  0.0239, -0.0149,  ...,  0.0127, -0.0034,  0.0140],
        [ 0.0159,  0.0462, -0.0547,  ...,  0.0103,  0.0375,  0.0012],
        [-0.0178,  0.0048,  0.0421,  ..., -0.0053, -0.0297, -0.0127],
        ...,
        [-0.0075, -0.0216, -0.0196,  ...,  0.0922,  0.0168, -0.0381],
        [ 0.0100, -0.0176,  0.0198,  ...,  0.0283,  0.0350,  0.0060],
        [-0.0052,  0.0369,  0.0101,  ..., -0.0048,  0.0096,  0.0505]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.5693, -3.9824, -0.2031,  ..., -0.9468,  0.1479, -3.7969]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 23:00:08 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of ahead is behind
The opposite of true is false
The opposite of up is down
The opposite of west is east
The opposite of first is last
The opposite of after is before
The opposite of inside is outside
The opposite of out is
2024-07-30 23:00:08 root INFO     [order_1_approx] starting weight calculation for The opposite of after is before
The opposite of out is in
The opposite of true is false
The opposite of first is last
The opposite of ahead is behind
The opposite of west is east
The opposite of up is down
The opposite of inside is
2024-07-30 23:00:08 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-30 23:02:13 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0120, -0.0160, -0.2249,  ..., -0.3352,  0.4456, -0.2500],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.1016, -4.0859,  2.5020,  ..., -2.1211,  3.4766, -1.5957],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0620,  0.0196, -0.0202,  ...,  0.0323,  0.0140,  0.0043],
        [ 0.0045,  0.0754, -0.0206,  ...,  0.0123,  0.0122,  0.0226],
        [ 0.0145,  0.0010,  0.0354,  ..., -0.0356, -0.0108, -0.0080],
        ...,
        [ 0.0024,  0.0046, -0.0022,  ...,  0.0487,  0.0054,  0.0139],
        [-0.0082, -0.0031, -0.0062,  ...,  0.0202,  0.0466,  0.0126],
        [ 0.0020, -0.0265, -0.0050,  ...,  0.0101, -0.0239,  0.0575]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.7246, -3.9766,  1.9570,  ..., -2.2070,  3.0430, -1.9512]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 23:02:14 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of after is before
The opposite of out is in
The opposite of true is false
The opposite of first is last
The opposite of ahead is behind
The opposite of west is east
The opposite of up is down
The opposite of inside is
2024-07-30 23:02:14 root INFO     [order_1_approx] starting weight calculation for The opposite of out is in
The opposite of west is east
The opposite of true is false
The opposite of inside is outside
The opposite of first is last
The opposite of ahead is behind
The opposite of after is before
The opposite of up is
2024-07-30 23:02:14 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-30 23:04:17 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.4556, -0.1311, -0.0519,  ...,  0.0009, -0.0690, -0.4949],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.0469, -4.2812,  2.4883,  ..., -2.8711,  0.7676, -3.4609],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0583, -0.0056, -0.0054,  ..., -0.0110,  0.0073,  0.0054],
        [-0.0108,  0.0865, -0.0151,  ...,  0.0002, -0.0006,  0.0102],
        [-0.0081,  0.0050,  0.0300,  ...,  0.0007, -0.0270, -0.0230],
        ...,
        [ 0.0069,  0.0105, -0.0179,  ...,  0.0674,  0.0105, -0.0291],
        [-0.0071,  0.0090, -0.0049,  ..., -0.0157,  0.0453,  0.0070],
        [ 0.0059, -0.0165, -0.0064,  ...,  0.0017, -0.0153,  0.0490]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.4883, -4.3438,  2.3359,  ..., -2.4375,  0.7886, -3.4531]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 23:04:21 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of out is in
The opposite of west is east
The opposite of true is false
The opposite of inside is outside
The opposite of first is last
The opposite of ahead is behind
The opposite of after is before
The opposite of up is
2024-07-30 23:04:23 root INFO     [order_1_approx] starting weight calculation for The opposite of first is last
The opposite of true is false
The opposite of ahead is behind
The opposite of inside is outside
The opposite of up is down
The opposite of out is in
The opposite of west is east
The opposite of after is
2024-07-30 23:04:24 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-30 23:06:29 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.5840,  0.0432, -0.5430,  ..., -0.3916,  0.4072, -0.2524],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.0312, -2.1133, -1.3984,  ...,  1.7148, -0.6108, -4.2656],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0533, -0.0034,  0.0003,  ..., -0.0021,  0.0214,  0.0199],
        [-0.0110,  0.0674, -0.0139,  ...,  0.0103,  0.0098, -0.0300],
        [-0.0041,  0.0063,  0.0169,  ...,  0.0130, -0.0127, -0.0026],
        ...,
        [-0.0053, -0.0213,  0.0039,  ...,  0.0601,  0.0004, -0.0282],
        [ 0.0073, -0.0118, -0.0079,  ...,  0.0141, -0.0061,  0.0009],
        [-0.0106,  0.0021, -0.0186,  ...,  0.0157,  0.0068,  0.0207]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.9648, -1.9180, -1.2559,  ...,  1.6660, -0.7051, -3.2812]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 23:06:30 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of first is last
The opposite of true is false
The opposite of ahead is behind
The opposite of inside is outside
The opposite of up is down
The opposite of out is in
The opposite of west is east
The opposite of after is
2024-07-30 23:06:30 root INFO     [order_1_approx] starting weight calculation for The opposite of out is in
The opposite of west is east
The opposite of after is before
The opposite of inside is outside
The opposite of true is false
The opposite of ahead is behind
The opposite of up is down
The opposite of first is
2024-07-30 23:06:30 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-30 23:08:37 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1234,  0.4473, -0.4680,  ..., -0.1814,  0.0457,  0.1523],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.6602, -2.6562, -1.3320,  ...,  0.1121, -0.1655, -3.4922],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0586, -0.0254,  0.0215,  ...,  0.0033,  0.0127,  0.0047],
        [-0.0114,  0.0693, -0.0200,  ..., -0.0169, -0.0231, -0.0047],
        [ 0.0008, -0.0112,  0.0178,  ..., -0.0108, -0.0044, -0.0161],
        ...,
        [-0.0172, -0.0049, -0.0159,  ...,  0.0549, -0.0067,  0.0009],
        [ 0.0020, -0.0073, -0.0015,  ..., -0.0052,  0.0416,  0.0185],
        [ 0.0020,  0.0078,  0.0150,  ...,  0.0071, -0.0260,  0.0474]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.3750, -2.2031, -1.0156,  ...,  0.0359, -0.4565, -3.0039]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 23:08:38 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of out is in
The opposite of west is east
The opposite of after is before
The opposite of inside is outside
The opposite of true is false
The opposite of ahead is behind
The opposite of up is down
The opposite of first is
2024-07-30 23:08:38 root INFO     total operator prediction time: 1020.7869484424591 seconds
2024-07-30 23:08:38 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on hyponyms - misc
2024-07-30 23:08:38 root INFO     building operator hyponyms - misc
2024-07-30 23:08:38 root INFO     [order_1_approx] starting weight calculation for A more specific term for a cloud is thundercloud
A more specific term for a emotion is anger
A more specific term for a poem is haiku
A more specific term for a trousers is jeans
A more specific term for a dress is gown
A more specific term for a gun is rifle
A more specific term for a burger is hamburger
A more specific term for a flask is
2024-07-30 23:08:38 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-30 23:10:44 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2905, -0.3442, -0.6865,  ..., -0.1131,  0.1947,  0.1644],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.2520, -3.9258, -0.2949,  ...,  0.1475,  2.0898,  0.3125],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.1158, -0.0046, -0.0054,  ...,  0.0173, -0.0075,  0.0170],
        [-0.0296,  0.0648, -0.0176,  ...,  0.0043,  0.0015, -0.0190],
        [ 0.0151,  0.0196,  0.1140,  ...,  0.0331,  0.0024, -0.0050],
        ...,
        [ 0.0256,  0.0311,  0.0083,  ...,  0.0992,  0.0273,  0.0062],
        [-0.0684,  0.0113, -0.0504,  ...,  0.0014,  0.0615, -0.0418],
        [ 0.0128,  0.0178, -0.0345,  ..., -0.0126,  0.0058,  0.0901]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.4141, -3.7383,  0.1462,  ...,  0.3848,  2.5117,  0.5342]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 23:10:45 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more specific term for a cloud is thundercloud
A more specific term for a emotion is anger
A more specific term for a poem is haiku
A more specific term for a trousers is jeans
A more specific term for a dress is gown
A more specific term for a gun is rifle
A more specific term for a burger is hamburger
A more specific term for a flask is
2024-07-30 23:10:45 root INFO     [order_1_approx] starting weight calculation for A more specific term for a dress is gown
A more specific term for a burger is hamburger
A more specific term for a flask is thermos
A more specific term for a gun is rifle
A more specific term for a trousers is jeans
A more specific term for a poem is haiku
A more specific term for a cloud is thundercloud
A more specific term for a emotion is
2024-07-30 23:10:45 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-30 23:12:51 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2852, -0.2214, -0.0129,  ...,  0.0710, -0.3457, -0.1326],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.1562, -3.6172,  2.4258,  ...,  1.3291, -0.5332, -1.4336],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 7.0984e-02,  6.8893e-03, -6.2714e-03,  ..., -8.3923e-03,
          4.8599e-03,  1.0132e-02],
        [ 1.3227e-03,  8.5510e-02, -1.5778e-02,  ...,  4.1008e-03,
          1.2726e-02, -1.3290e-02],
        [-8.8425e-03, -1.4664e-02,  5.7465e-02,  ...,  2.5711e-03,
         -1.7517e-02, -3.0470e-04],
        ...,
        [ 9.9411e-03,  2.0523e-02, -3.4008e-03,  ...,  5.6610e-02,
          2.5940e-04, -6.0616e-03],
        [-1.7075e-02,  1.1978e-03, -1.8082e-03,  ..., -7.0724e-03,
          3.9093e-02,  8.5831e-05],
        [-5.0697e-03, -6.2103e-03, -1.2276e-02,  ...,  1.9440e-02,
         -5.1498e-03,  5.8136e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.8379, -3.4277,  2.2480,  ...,  1.3672, -0.6475, -1.4316]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 23:12:52 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more specific term for a dress is gown
A more specific term for a burger is hamburger
A more specific term for a flask is thermos
A more specific term for a gun is rifle
A more specific term for a trousers is jeans
A more specific term for a poem is haiku
A more specific term for a cloud is thundercloud
A more specific term for a emotion is
2024-07-30 23:12:52 root INFO     [order_1_approx] starting weight calculation for A more specific term for a flask is thermos
A more specific term for a gun is rifle
A more specific term for a dress is gown
A more specific term for a emotion is anger
A more specific term for a poem is haiku
A more specific term for a trousers is jeans
A more specific term for a cloud is thundercloud
A more specific term for a burger is
2024-07-30 23:12:52 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-30 23:14:59 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0596,  0.4058, -0.0291,  ...,  0.2047,  0.0616, -0.3616],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.1191, -4.5391,  2.2324,  ..., -2.4219, -4.7461, -1.9170],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0716,  0.0343,  0.0115,  ...,  0.0089,  0.0027, -0.0007],
        [ 0.0144,  0.0841,  0.0196,  ..., -0.0145,  0.0018, -0.0299],
        [ 0.0053,  0.0016,  0.0738,  ...,  0.0170, -0.0021, -0.0047],
        ...,
        [ 0.0330,  0.0025,  0.0062,  ...,  0.0775, -0.0104, -0.0111],
        [-0.0146,  0.0018, -0.0121,  ...,  0.0119,  0.0846, -0.0157],
        [ 0.0101,  0.0127,  0.0124,  ..., -0.0112, -0.0125,  0.0839]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.4878, -4.4219,  2.1562,  ..., -2.1191, -4.5039, -1.9023]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 23:15:00 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more specific term for a flask is thermos
A more specific term for a gun is rifle
A more specific term for a dress is gown
A more specific term for a emotion is anger
A more specific term for a poem is haiku
A more specific term for a trousers is jeans
A more specific term for a cloud is thundercloud
A more specific term for a burger is
2024-07-30 23:15:00 root INFO     [order_1_approx] starting weight calculation for A more specific term for a emotion is anger
A more specific term for a flask is thermos
A more specific term for a gun is rifle
A more specific term for a cloud is thundercloud
A more specific term for a trousers is jeans
A more specific term for a poem is haiku
A more specific term for a burger is hamburger
A more specific term for a dress is
2024-07-30 23:15:00 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-30 23:16:59 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1550, -0.1875, -0.1655,  ...,  0.1189, -0.3237,  0.0741],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.0166, -3.8555, -1.8662,  ...,  0.7324, -2.2715,  1.8174],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0662,  0.0199, -0.0047,  ..., -0.0255,  0.0372, -0.0008],
        [-0.0080,  0.0563, -0.0029,  ..., -0.0138, -0.0053, -0.0283],
        [ 0.0377, -0.0224,  0.0717,  ..., -0.0050,  0.0006, -0.0033],
        ...,
        [-0.0193, -0.0025, -0.0133,  ...,  0.0603,  0.0140, -0.0180],
        [-0.0100,  0.0115, -0.0213,  ...,  0.0180,  0.0577, -0.0073],
        [-0.0013,  0.0035,  0.0105,  ..., -0.0273, -0.0105,  0.0555]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.4863, -3.9824, -1.7334,  ...,  1.0723, -2.3496,  1.7549]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 23:17:00 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more specific term for a emotion is anger
A more specific term for a flask is thermos
A more specific term for a gun is rifle
A more specific term for a cloud is thundercloud
A more specific term for a trousers is jeans
A more specific term for a poem is haiku
A more specific term for a burger is hamburger
A more specific term for a dress is
2024-07-30 23:17:00 root INFO     [order_1_approx] starting weight calculation for A more specific term for a burger is hamburger
A more specific term for a flask is thermos
A more specific term for a cloud is thundercloud
A more specific term for a gun is rifle
A more specific term for a poem is haiku
A more specific term for a dress is gown
A more specific term for a emotion is anger
A more specific term for a trousers is
2024-07-30 23:17:00 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-30 23:19:00 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0153, -0.3936, -0.5474,  ...,  0.4905, -0.2837, -0.2180],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.8633, -6.7695,  0.5283,  ...,  0.6729,  0.5215,  1.7871],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0484, -0.0067,  0.0013,  ...,  0.0144,  0.0153, -0.0087],
        [-0.0127,  0.0338, -0.0110,  ..., -0.0028,  0.0029, -0.0021],
        [ 0.0096, -0.0126,  0.0317,  ..., -0.0034, -0.0055, -0.0045],
        ...,
        [-0.0024, -0.0083,  0.0031,  ...,  0.0536,  0.0135,  0.0019],
        [-0.0075, -0.0026, -0.0112,  ...,  0.0046,  0.0348, -0.0031],
        [-0.0059, -0.0030,  0.0044,  ..., -0.0039, -0.0039,  0.0291]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.7656, -6.6836,  0.4250,  ...,  0.7622,  0.4590,  1.7725]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 23:19:01 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more specific term for a burger is hamburger
A more specific term for a flask is thermos
A more specific term for a cloud is thundercloud
A more specific term for a gun is rifle
A more specific term for a poem is haiku
A more specific term for a dress is gown
A more specific term for a emotion is anger
A more specific term for a trousers is
2024-07-30 23:19:01 root INFO     [order_1_approx] starting weight calculation for A more specific term for a flask is thermos
A more specific term for a dress is gown
A more specific term for a gun is rifle
A more specific term for a emotion is anger
A more specific term for a trousers is jeans
A more specific term for a burger is hamburger
A more specific term for a poem is haiku
A more specific term for a cloud is
2024-07-30 23:19:01 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-30 23:21:05 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1302, -0.0128, -0.2727,  ..., -0.0718,  0.0717, -0.1742],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.5410, -4.0273,  4.2695,  ..., -0.7495, -0.4551,  1.8721],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.1115,  0.0217, -0.0131,  ...,  0.0165,  0.0042,  0.0090],
        [ 0.0265,  0.0853, -0.0138,  ...,  0.0065,  0.0024, -0.0394],
        [-0.0051,  0.0081,  0.1073,  ...,  0.0197, -0.0194,  0.0212],
        ...,
        [-0.0061,  0.0162,  0.0055,  ...,  0.0734,  0.0004, -0.0036],
        [-0.0169,  0.0043, -0.0026,  ...,  0.0037,  0.0941, -0.0052],
        [ 0.0074,  0.0035,  0.0027,  ..., -0.0159, -0.0134,  0.0718]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.3062, -4.3594,  4.0938,  ..., -0.6733, -0.3403,  1.8877]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 23:21:07 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more specific term for a flask is thermos
A more specific term for a dress is gown
A more specific term for a gun is rifle
A more specific term for a emotion is anger
A more specific term for a trousers is jeans
A more specific term for a burger is hamburger
A more specific term for a poem is haiku
A more specific term for a cloud is
2024-07-30 23:21:07 root INFO     [order_1_approx] starting weight calculation for A more specific term for a trousers is jeans
A more specific term for a burger is hamburger
A more specific term for a poem is haiku
A more specific term for a flask is thermos
A more specific term for a dress is gown
A more specific term for a cloud is thundercloud
A more specific term for a emotion is anger
A more specific term for a gun is
2024-07-30 23:21:07 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-30 23:23:09 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0022, -0.0922,  0.0030,  ...,  0.0300, -0.0774, -0.0980],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.1992, -5.3750,  0.2075,  ..., -0.8438, -2.0918, -0.2451],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0826, -0.0107,  0.0014,  ...,  0.0013, -0.0088, -0.0189],
        [-0.0026,  0.0517, -0.0047,  ..., -0.0046,  0.0097, -0.0502],
        [ 0.0127, -0.0170,  0.0818,  ...,  0.0107, -0.0010,  0.0049],
        ...,
        [ 0.0072,  0.0245,  0.0007,  ...,  0.0786,  0.0022,  0.0135],
        [-0.0185,  0.0027, -0.0222,  ..., -0.0018,  0.0613, -0.0109],
        [ 0.0176,  0.0102,  0.0191,  ..., -0.0172, -0.0279,  0.0479]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.1123, -5.3008,  0.3970,  ..., -0.6963, -2.1855, -0.1794]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 23:23:09 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more specific term for a trousers is jeans
A more specific term for a burger is hamburger
A more specific term for a poem is haiku
A more specific term for a flask is thermos
A more specific term for a dress is gown
A more specific term for a cloud is thundercloud
A more specific term for a emotion is anger
A more specific term for a gun is
2024-07-30 23:23:10 root INFO     [order_1_approx] starting weight calculation for A more specific term for a burger is hamburger
A more specific term for a flask is thermos
A more specific term for a emotion is anger
A more specific term for a trousers is jeans
A more specific term for a cloud is thundercloud
A more specific term for a dress is gown
A more specific term for a gun is rifle
A more specific term for a poem is
2024-07-30 23:23:10 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-30 23:25:10 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0059, -0.0548, -0.1052,  ..., -0.0734, -0.5991,  0.1871],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.6035, -6.5156,  5.7266,  ...,  0.9111, -0.3711, -1.6035],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0899, -0.0138,  0.0022,  ...,  0.0147, -0.0189,  0.0187],
        [-0.0090,  0.0920, -0.0036,  ...,  0.0034,  0.0206, -0.0063],
        [-0.0008, -0.0244,  0.1008,  ...,  0.0184, -0.0061,  0.0050],
        ...,
        [-0.0013,  0.0073, -0.0007,  ...,  0.1022,  0.0155, -0.0183],
        [-0.0135,  0.0165,  0.0004,  ...,  0.0237,  0.0860, -0.0059],
        [-0.0310,  0.0114,  0.0048,  ..., -0.0136,  0.0055,  0.0712]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.3633, -6.6211,  5.4883,  ...,  0.9438, -0.4944, -1.2959]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 23:25:11 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more specific term for a burger is hamburger
A more specific term for a flask is thermos
A more specific term for a emotion is anger
A more specific term for a trousers is jeans
A more specific term for a cloud is thundercloud
A more specific term for a dress is gown
A more specific term for a gun is rifle
A more specific term for a poem is
2024-07-30 23:25:11 root INFO     total operator prediction time: 993.169183254242 seconds
2024-07-30 23:25:11 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on hypernyms - animals
2024-07-30 23:25:11 root INFO     building operator hypernyms - animals
2024-07-30 23:25:11 root INFO     [order_1_approx] starting weight calculation for The lion falls into the category of feline
The goose falls into the category of fowl
The ant falls into the category of insect
The duck falls into the category of fowl
The cockroach falls into the category of insect
The quail falls into the category of fowl
The falcon falls into the category of raptor
The bee falls into the category of
2024-07-30 23:25:11 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-30 23:27:14 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3027, -0.2144,  0.1414,  ...,  0.3025, -0.4229,  0.2173],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.0264, -3.5508,  2.2148,  ..., -2.9980, -2.1543,  0.3438],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0345, -0.0117, -0.0079,  ...,  0.0072, -0.0039,  0.0059],
        [ 0.0220,  0.0210,  0.0057,  ..., -0.0089, -0.0032, -0.0246],
        [-0.0054,  0.0012,  0.0529,  ...,  0.0133, -0.0039,  0.0174],
        ...,
        [ 0.0063, -0.0033,  0.0111,  ...,  0.0256,  0.0108,  0.0100],
        [-0.0168,  0.0164, -0.0061,  ..., -0.0032,  0.0431, -0.0053],
        [-0.0119, -0.0115, -0.0179,  ..., -0.0116, -0.0110,  0.0555]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.1611, -3.4492,  1.8418,  ..., -2.8047, -2.0449,  0.4736]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 23:27:15 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The lion falls into the category of feline
The goose falls into the category of fowl
The ant falls into the category of insect
The duck falls into the category of fowl
The cockroach falls into the category of insect
The quail falls into the category of fowl
The falcon falls into the category of raptor
The bee falls into the category of
2024-07-30 23:27:16 root INFO     [order_1_approx] starting weight calculation for The lion falls into the category of feline
The goose falls into the category of fowl
The bee falls into the category of insect
The quail falls into the category of fowl
The duck falls into the category of fowl
The falcon falls into the category of raptor
The ant falls into the category of insect
The cockroach falls into the category of
2024-07-30 23:27:16 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-30 23:29:17 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1890, -0.2664, -0.2617,  ..., -0.4128, -0.7876,  0.0010],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.1152, -3.6445,  3.4629,  ..., -3.6250, -2.6172, -2.2188],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 2.7435e-02, -9.0485e-03,  1.3018e-03,  ...,  2.7771e-03,
         -4.2305e-03, -9.0885e-04],
        [ 5.4626e-03,  1.1620e-02, -2.0027e-03,  ...,  3.2005e-03,
          4.4823e-03, -7.8659e-03],
        [-1.6937e-03, -1.8082e-03,  1.5991e-02,  ...,  5.8212e-03,
         -2.2774e-03,  6.3400e-03],
        ...,
        [ 1.0590e-02, -4.0054e-05,  1.1444e-05,  ...,  1.5205e-02,
          5.3101e-03, -2.1400e-03],
        [ 6.9351e-03, -5.5923e-03, -6.9656e-03,  ..., -5.8899e-03,
          2.3270e-02,  2.2392e-03],
        [-1.4153e-02,  1.1543e-02,  1.3380e-03,  ..., -1.1108e-02,
         -6.1340e-03,  2.4002e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.0518, -3.6484,  3.4375,  ..., -3.6738, -2.6250, -2.0156]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 23:29:18 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The lion falls into the category of feline
The goose falls into the category of fowl
The bee falls into the category of insect
The quail falls into the category of fowl
The duck falls into the category of fowl
The falcon falls into the category of raptor
The ant falls into the category of insect
The cockroach falls into the category of
2024-07-30 23:29:19 root INFO     [order_1_approx] starting weight calculation for The goose falls into the category of fowl
The lion falls into the category of feline
The duck falls into the category of fowl
The cockroach falls into the category of insect
The bee falls into the category of insect
The quail falls into the category of fowl
The falcon falls into the category of raptor
The ant falls into the category of
2024-07-30 23:29:19 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-30 23:31:18 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2064, -0.1340, -0.1525,  ..., -0.3105,  0.1592, -0.5435],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.3872, -3.3750,  2.7246,  ..., -3.0625, -3.6543, -1.4053],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0456,  0.0056, -0.0045,  ...,  0.0070, -0.0042,  0.0011],
        [ 0.0204,  0.0243,  0.0079,  ..., -0.0021,  0.0107, -0.0274],
        [ 0.0033,  0.0011,  0.0507,  ...,  0.0047, -0.0121,  0.0211],
        ...,
        [ 0.0252,  0.0043,  0.0121,  ...,  0.0456, -0.0058, -0.0005],
        [-0.0124,  0.0046,  0.0026,  ..., -0.0071,  0.0363, -0.0004],
        [-0.0060, -0.0028, -0.0169,  ..., -0.0186, -0.0106,  0.0432]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.3513, -3.6348,  2.5586,  ..., -2.7715, -3.6367, -1.3291]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 23:31:19 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The goose falls into the category of fowl
The lion falls into the category of feline
The duck falls into the category of fowl
The cockroach falls into the category of insect
The bee falls into the category of insect
The quail falls into the category of fowl
The falcon falls into the category of raptor
The ant falls into the category of
2024-07-30 23:31:19 root INFO     [order_1_approx] starting weight calculation for The bee falls into the category of insect
The duck falls into the category of fowl
The lion falls into the category of feline
The ant falls into the category of insect
The goose falls into the category of fowl
The falcon falls into the category of raptor
The cockroach falls into the category of insect
The quail falls into the category of
2024-07-30 23:31:19 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-30 23:33:26 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1924, -0.6309, -0.1644,  ...,  0.4316, -0.7119,  0.0298],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.9492, -2.7441,  2.4590,  ..., -1.5303, -3.2480, -0.1113],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0631,  0.0047, -0.0208,  ...,  0.0112, -0.0289, -0.0122],
        [ 0.0242,  0.0462, -0.0007,  ...,  0.0156, -0.0038, -0.0195],
        [ 0.0020, -0.0166,  0.0901,  ..., -0.0058, -0.0044,  0.0192],
        ...,
        [ 0.0130, -0.0011,  0.0170,  ...,  0.0706, -0.0058, -0.0089],
        [ 0.0103, -0.0006, -0.0051,  ...,  0.0322,  0.0697, -0.0113],
        [-0.0251, -0.0142, -0.0075,  ..., -0.0106, -0.0351,  0.0626]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.3418, -2.4316,  2.0898,  ..., -1.8721, -3.1094, -0.2764]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 23:33:27 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The bee falls into the category of insect
The duck falls into the category of fowl
The lion falls into the category of feline
The ant falls into the category of insect
The goose falls into the category of fowl
The falcon falls into the category of raptor
The cockroach falls into the category of insect
The quail falls into the category of
2024-07-30 23:33:27 root INFO     [order_1_approx] starting weight calculation for The quail falls into the category of fowl
The ant falls into the category of insect
The goose falls into the category of fowl
The lion falls into the category of feline
The duck falls into the category of fowl
The cockroach falls into the category of insect
The bee falls into the category of insect
The falcon falls into the category of
2024-07-30 23:33:27 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-30 23:35:29 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3677, -0.1741, -0.3130,  ...,  0.1768, -0.5625,  0.1218],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.4297, -4.4414,  2.6836,  ..., -2.3770, -5.7578,  0.5000],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0670, -0.0029, -0.0033,  ..., -0.0001, -0.0082, -0.0035],
        [ 0.0195,  0.0327,  0.0101,  ..., -0.0013, -0.0032, -0.0235],
        [ 0.0048, -0.0140,  0.0530,  ...,  0.0112,  0.0112, -0.0055],
        ...,
        [ 0.0264,  0.0011,  0.0089,  ...,  0.0457, -0.0175,  0.0003],
        [ 0.0176, -0.0026,  0.0153,  ...,  0.0067,  0.0446, -0.0156],
        [ 0.0003, -0.0101, -0.0013,  ..., -0.0042, -0.0161,  0.0460]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.6875, -4.6328,  2.5352,  ..., -2.5254, -6.0156,  0.6689]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 23:35:30 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The quail falls into the category of fowl
The ant falls into the category of insect
The goose falls into the category of fowl
The lion falls into the category of feline
The duck falls into the category of fowl
The cockroach falls into the category of insect
The bee falls into the category of insect
The falcon falls into the category of
2024-07-30 23:35:30 root INFO     [order_1_approx] starting weight calculation for The cockroach falls into the category of insect
The duck falls into the category of fowl
The bee falls into the category of insect
The ant falls into the category of insect
The goose falls into the category of fowl
The quail falls into the category of fowl
The falcon falls into the category of raptor
The lion falls into the category of
2024-07-30 23:35:30 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-30 23:37:36 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4312, -0.3625,  0.1902,  ...,  0.3428, -0.5781, -0.0809],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.0913, -7.0938,  0.0679,  ..., -2.6523, -5.8438, -0.5996],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0191, -0.0069, -0.0189,  ..., -0.0102, -0.0194,  0.0090],
        [ 0.0026,  0.0255,  0.0077,  ..., -0.0237,  0.0075, -0.0105],
        [-0.0184,  0.0028,  0.0419,  ...,  0.0035,  0.0082, -0.0054],
        ...,
        [-0.0028,  0.0033,  0.0162,  ...,  0.0194,  0.0032,  0.0011],
        [ 0.0128, -0.0126,  0.0023,  ...,  0.0059,  0.0410, -0.0011],
        [-0.0159,  0.0009, -0.0065,  ..., -0.0162, -0.0042,  0.0368]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.0168, -6.7852,  0.2644,  ..., -2.2559, -5.8242, -0.5317]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 23:37:37 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The cockroach falls into the category of insect
The duck falls into the category of fowl
The bee falls into the category of insect
The ant falls into the category of insect
The goose falls into the category of fowl
The quail falls into the category of fowl
The falcon falls into the category of raptor
The lion falls into the category of
2024-07-30 23:37:37 root INFO     [order_1_approx] starting weight calculation for The falcon falls into the category of raptor
The ant falls into the category of insect
The bee falls into the category of insect
The cockroach falls into the category of insect
The quail falls into the category of fowl
The duck falls into the category of fowl
The lion falls into the category of feline
The goose falls into the category of
2024-07-30 23:37:37 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-30 23:39:43 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.6465, -0.2583,  0.0981,  ...,  0.2106, -0.4648, -0.1946],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.7148, -2.5859,  3.8340,  ..., -2.0742, -6.8125,  1.3203],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0339,  0.0126, -0.0174,  ..., -0.0079, -0.0178, -0.0209],
        [ 0.0138,  0.0397, -0.0049,  ...,  0.0145, -0.0039, -0.0255],
        [-0.0048, -0.0116,  0.0523,  ...,  0.0003, -0.0038,  0.0126],
        ...,
        [ 0.0251,  0.0032,  0.0119,  ...,  0.0281,  0.0052,  0.0042],
        [ 0.0009,  0.0089, -0.0003,  ...,  0.0092,  0.0474, -0.0124],
        [ 0.0033, -0.0106, -0.0039,  ..., -0.0192, -0.0143,  0.0452]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.0254, -2.7051,  3.7051,  ..., -2.1562, -6.8594,  1.2568]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 23:39:44 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The falcon falls into the category of raptor
The ant falls into the category of insect
The bee falls into the category of insect
The cockroach falls into the category of insect
The quail falls into the category of fowl
The duck falls into the category of fowl
The lion falls into the category of feline
The goose falls into the category of
2024-07-30 23:39:44 root INFO     [order_1_approx] starting weight calculation for The bee falls into the category of insect
The quail falls into the category of fowl
The lion falls into the category of feline
The cockroach falls into the category of insect
The goose falls into the category of fowl
The falcon falls into the category of raptor
The ant falls into the category of insect
The duck falls into the category of
2024-07-30 23:39:44 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-30 23:41:45 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1443, -0.4868,  0.3374,  ...,  0.2479, -0.7451,  0.0603],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.9780, -1.8721,  3.2812,  ..., -2.0957, -6.1484,  0.3701],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0374,  0.0014, -0.0102,  ...,  0.0089, -0.0140, -0.0092],
        [ 0.0119,  0.0287,  0.0031,  ...,  0.0005, -0.0002, -0.0262],
        [ 0.0014, -0.0147,  0.0397,  ...,  0.0008,  0.0022,  0.0050],
        ...,
        [ 0.0210, -0.0014,  0.0114,  ...,  0.0210, -0.0031, -0.0048],
        [ 0.0050,  0.0006, -0.0032,  ...,  0.0052,  0.0310, -0.0106],
        [-0.0035, -0.0103,  0.0100,  ..., -0.0186, -0.0107,  0.0349]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.2021, -1.7109,  3.0566,  ..., -2.0352, -6.0938,  0.4333]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 23:41:46 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The bee falls into the category of insect
The quail falls into the category of fowl
The lion falls into the category of feline
The cockroach falls into the category of insect
The goose falls into the category of fowl
The falcon falls into the category of raptor
The ant falls into the category of insect
The duck falls into the category of
2024-07-30 23:41:46 root INFO     total operator prediction time: 994.8975365161896 seconds
2024-07-30 23:41:46 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on synonyms - intensity
2024-07-30 23:41:46 root INFO     building operator synonyms - intensity
2024-07-30 23:41:46 root INFO     [order_1_approx] starting weight calculation for A more intense word for sad is desparate
A more intense word for guilty is remorseful
A more intense word for doze is sleep
A more intense word for indulge is pamper
A more intense word for dinner is feast
A more intense word for tired is exhausted
A more intense word for house is palace
A more intense word for faith is
2024-07-30 23:41:46 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-30 23:43:49 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1400,  0.0369, -0.2896,  ..., -0.0828,  0.0655,  0.5190],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.4219, -5.3516,  0.0830,  ..., -2.4238, -5.8750, -0.6162],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0682,  0.0093,  0.0242,  ...,  0.0121,  0.0082,  0.0146],
        [-0.0009,  0.0613, -0.0009,  ...,  0.0029, -0.0063, -0.0248],
        [ 0.0058, -0.0269,  0.0571,  ..., -0.0008, -0.0164, -0.0054],
        ...,
        [ 0.0075,  0.0071, -0.0035,  ...,  0.0731, -0.0217, -0.0019],
        [-0.0134, -0.0026,  0.0265,  ..., -0.0133,  0.0667,  0.0102],
        [ 0.0295,  0.0028, -0.0124,  ...,  0.0103, -0.0107,  0.0654]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.4023, -5.1211, -0.1427,  ..., -2.2852, -6.2578, -1.1504]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 23:43:50 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more intense word for sad is desparate
A more intense word for guilty is remorseful
A more intense word for doze is sleep
A more intense word for indulge is pamper
A more intense word for dinner is feast
A more intense word for tired is exhausted
A more intense word for house is palace
A more intense word for faith is
2024-07-30 23:43:50 root INFO     [order_1_approx] starting weight calculation for A more intense word for house is palace
A more intense word for dinner is feast
A more intense word for faith is fanatism
A more intense word for sad is desparate
A more intense word for guilty is remorseful
A more intense word for tired is exhausted
A more intense word for doze is sleep
A more intense word for indulge is
2024-07-30 23:43:50 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-30 23:45:53 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3723,  0.3640, -0.6328,  ..., -0.2812, -0.7642,  0.3596],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.6875, -2.3984, -2.4648,  ...,  1.6787, -3.7773,  1.9668],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0748, -0.0004,  0.0197,  ..., -0.0116, -0.0017,  0.0135],
        [ 0.0252,  0.0802, -0.0250,  ...,  0.0287, -0.0066, -0.0087],
        [-0.0243, -0.0216,  0.0482,  ..., -0.0125, -0.0079, -0.0180],
        ...,
        [ 0.0310, -0.0144,  0.0019,  ...,  0.0797, -0.0086, -0.0092],
        [-0.0176,  0.0134,  0.0034,  ..., -0.0048,  0.0493, -0.0030],
        [ 0.0018, -0.0113, -0.0099,  ..., -0.0059, -0.0169,  0.0559]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.4746, -1.9570, -2.2578,  ...,  1.9551, -3.8496,  1.9941]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 23:45:54 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more intense word for house is palace
A more intense word for dinner is feast
A more intense word for faith is fanatism
A more intense word for sad is desparate
A more intense word for guilty is remorseful
A more intense word for tired is exhausted
A more intense word for doze is sleep
A more intense word for indulge is
2024-07-30 23:45:54 root INFO     [order_1_approx] starting weight calculation for A more intense word for indulge is pamper
A more intense word for guilty is remorseful
A more intense word for faith is fanatism
A more intense word for house is palace
A more intense word for tired is exhausted
A more intense word for dinner is feast
A more intense word for doze is sleep
A more intense word for sad is
2024-07-30 23:45:54 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-30 23:48:00 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1414, -0.1425, -0.2006,  ...,  0.1204, -0.4526,  0.1503],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.9004, -3.3965,  2.9492,  ..., -0.6685, -1.6406, -2.7129],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 7.5317e-02,  3.5339e-02,  8.0109e-03,  ...,  1.6541e-02,
          5.1117e-03,  3.1738e-02],
        [-1.3374e-02,  4.3945e-02, -1.9897e-02,  ..., -1.3664e-02,
          2.6550e-02, -2.1851e-02],
        [ 1.1086e-02, -1.2741e-02,  8.1970e-02,  ...,  6.8359e-03,
         -2.6108e-02, -1.0094e-02],
        ...,
        [-7.0572e-05, -6.3362e-03, -7.3166e-03,  ...,  5.1697e-02,
          6.6147e-03, -5.2338e-03],
        [ 8.7738e-04, -3.6469e-03, -6.1951e-03,  ...,  2.7878e-02,
          4.2877e-02, -2.6794e-02],
        [-8.0872e-03, -2.9144e-02,  2.7199e-03,  ..., -1.3359e-02,
          4.3564e-03,  3.8666e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.7812, -3.1426,  2.9180,  ..., -0.6230, -1.3193, -3.0391]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 23:48:01 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more intense word for indulge is pamper
A more intense word for guilty is remorseful
A more intense word for faith is fanatism
A more intense word for house is palace
A more intense word for tired is exhausted
A more intense word for dinner is feast
A more intense word for doze is sleep
A more intense word for sad is
2024-07-30 23:48:02 root INFO     [order_1_approx] starting weight calculation for A more intense word for faith is fanatism
A more intense word for house is palace
A more intense word for doze is sleep
A more intense word for tired is exhausted
A more intense word for indulge is pamper
A more intense word for dinner is feast
A more intense word for sad is desparate
A more intense word for guilty is
2024-07-30 23:48:02 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-30 23:50:09 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0558,  0.0508, -0.5537,  ...,  0.2812,  0.0869,  0.2820],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.0674, -3.0508,  1.8301,  ..., -2.0723, -1.4795,  0.5732],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0935,  0.0036,  0.0348,  ..., -0.0135, -0.0046,  0.0301],
        [-0.0164,  0.0412, -0.0238,  ..., -0.0187, -0.0045, -0.0062],
        [ 0.0010, -0.0237,  0.0839,  ...,  0.0230, -0.0277,  0.0072],
        ...,
        [-0.0023,  0.0035, -0.0036,  ...,  0.0730,  0.0148, -0.0174],
        [-0.0197, -0.0005,  0.0012,  ...,  0.0118,  0.0461, -0.0239],
        [-0.0015, -0.0111,  0.0047,  ...,  0.0184, -0.0029,  0.0616]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.9229, -2.8008,  2.0020,  ..., -1.6904, -1.2773,  0.1890]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 23:50:10 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more intense word for faith is fanatism
A more intense word for house is palace
A more intense word for doze is sleep
A more intense word for tired is exhausted
A more intense word for indulge is pamper
A more intense word for dinner is feast
A more intense word for sad is desparate
A more intense word for guilty is
2024-07-30 23:50:10 root INFO     [order_1_approx] starting weight calculation for A more intense word for guilty is remorseful
A more intense word for dinner is feast
A more intense word for sad is desparate
A more intense word for indulge is pamper
A more intense word for faith is fanatism
A more intense word for house is palace
A more intense word for doze is sleep
A more intense word for tired is
2024-07-30 23:50:10 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-30 23:52:15 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.6548, -0.5298, -0.5547,  ...,  0.0091, -0.1333,  0.5273],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.1641, -5.9531,  3.4727,  ..., -2.4023, -1.1953, -0.0957],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0519,  0.0234,  0.0107,  ...,  0.0149,  0.0120,  0.0196],
        [-0.0039,  0.0452,  0.0017,  ...,  0.0010,  0.0213, -0.0058],
        [-0.0030, -0.0026,  0.0397,  ...,  0.0146, -0.0122,  0.0040],
        ...,
        [ 0.0102,  0.0060, -0.0044,  ...,  0.0370,  0.0170, -0.0134],
        [-0.0028,  0.0086, -0.0023,  ...,  0.0193,  0.0282,  0.0051],
        [-0.0162, -0.0112, -0.0112,  ...,  0.0039, -0.0108,  0.0438]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.0742, -5.9023,  3.7148,  ..., -2.2129, -1.1797, -0.1731]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 23:52:16 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more intense word for guilty is remorseful
A more intense word for dinner is feast
A more intense word for sad is desparate
A more intense word for indulge is pamper
A more intense word for faith is fanatism
A more intense word for house is palace
A more intense word for doze is sleep
A more intense word for tired is
2024-07-30 23:52:16 root INFO     [order_1_approx] starting weight calculation for A more intense word for indulge is pamper
A more intense word for tired is exhausted
A more intense word for house is palace
A more intense word for guilty is remorseful
A more intense word for sad is desparate
A more intense word for doze is sleep
A more intense word for faith is fanatism
A more intense word for dinner is
2024-07-30 23:52:16 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-30 23:54:23 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3245,  0.1614, -0.1083,  ..., -0.2705, -0.5762, -0.3167],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 5.6680, -3.0801,  1.3418,  ..., -2.1133, -2.6973, -2.2812],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 7.9651e-02,  1.4999e-02, -1.3878e-02,  ...,  1.9150e-02,
          2.7740e-02, -1.5427e-02],
        [-2.7939e-02,  8.9722e-02,  7.9727e-03,  ...,  1.2070e-02,
         -1.9394e-02, -2.2324e-02],
        [-7.7019e-03, -1.2344e-02,  8.2214e-02,  ...,  1.3199e-02,
         -4.0894e-03, -1.4481e-02],
        ...,
        [-4.8943e-03,  8.6823e-03,  8.9645e-03,  ...,  8.1909e-02,
          1.3733e-02, -9.0122e-05],
        [-2.1057e-03, -1.6190e-02, -7.5111e-03,  ...,  2.7847e-02,
          6.8787e-02,  4.8096e-02],
        [-1.4038e-02,  1.1932e-02,  7.3242e-04,  ..., -1.3329e-02,
         -1.5480e-02,  5.0293e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 5.6641, -2.8574,  2.1953,  ..., -1.6992, -3.7227, -1.7461]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 23:54:24 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more intense word for indulge is pamper
A more intense word for tired is exhausted
A more intense word for house is palace
A more intense word for guilty is remorseful
A more intense word for sad is desparate
A more intense word for doze is sleep
A more intense word for faith is fanatism
A more intense word for dinner is
2024-07-30 23:54:24 root INFO     [order_1_approx] starting weight calculation for A more intense word for indulge is pamper
A more intense word for house is palace
A more intense word for sad is desparate
A more intense word for tired is exhausted
A more intense word for dinner is feast
A more intense word for faith is fanatism
A more intense word for guilty is remorseful
A more intense word for doze is
2024-07-30 23:54:24 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-30 23:56:26 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4189, -0.1249, -0.2634,  ..., -0.3589, -0.7148,  0.0983],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.1953, -4.8516,  2.3828,  ...,  0.1885, -2.0703,  0.3301],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0880,  0.0148, -0.0047,  ...,  0.0225, -0.0341, -0.0079],
        [ 0.0085,  0.0766, -0.0042,  ..., -0.0045,  0.0115,  0.0006],
        [-0.0383, -0.0079,  0.0527,  ...,  0.0071, -0.0284, -0.0341],
        ...,
        [-0.0124,  0.0005,  0.0034,  ...,  0.0707,  0.0115, -0.0170],
        [-0.0013, -0.0153,  0.0022,  ...,  0.0214,  0.0313, -0.0307],
        [ 0.0056, -0.0182, -0.0114,  ..., -0.0023, -0.0329,  0.0457]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.5234, -4.7188,  2.6016,  ..., -0.0338, -2.0957,  0.2151]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 23:56:28 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more intense word for indulge is pamper
A more intense word for house is palace
A more intense word for sad is desparate
A more intense word for tired is exhausted
A more intense word for dinner is feast
A more intense word for faith is fanatism
A more intense word for guilty is remorseful
A more intense word for doze is
2024-07-30 23:56:28 root INFO     [order_1_approx] starting weight calculation for A more intense word for sad is desparate
A more intense word for faith is fanatism
A more intense word for indulge is pamper
A more intense word for guilty is remorseful
A more intense word for doze is sleep
A more intense word for tired is exhausted
A more intense word for dinner is feast
A more intense word for house is
2024-07-30 23:56:28 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-30 23:58:34 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1931,  0.2313, -0.3503,  ..., -0.0707,  0.0659, -0.4814],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-2.7578, -5.1367,  1.3145,  ..., -0.9771, -1.7803,  0.4795],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0902,  0.0284,  0.0104,  ..., -0.0113,  0.0254,  0.0166],
        [-0.0161,  0.0777,  0.0113,  ..., -0.0163,  0.0287, -0.0046],
        [ 0.0060,  0.0178,  0.0559,  ..., -0.0069, -0.0034,  0.0075],
        ...,
        [ 0.0003,  0.0137,  0.0120,  ...,  0.0638, -0.0053, -0.0193],
        [ 0.0026, -0.0097, -0.0009,  ..., -0.0031,  0.0713,  0.0038],
        [-0.0204,  0.0010, -0.0019,  ..., -0.0068, -0.0268,  0.0603]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-2.6641, -4.6094,  1.5576,  ..., -0.9468, -2.4414,  0.2499]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 23:58:35 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more intense word for sad is desparate
A more intense word for faith is fanatism
A more intense word for indulge is pamper
A more intense word for guilty is remorseful
A more intense word for doze is sleep
A more intense word for tired is exhausted
A more intense word for dinner is feast
A more intense word for house is
2024-07-30 23:58:35 root INFO     total operator prediction time: 1009.1960003376007 seconds
2024-07-30 23:58:35 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on meronyms - substance
2024-07-30 23:58:35 root INFO     building operator meronyms - substance
2024-07-30 23:58:36 root INFO     [order_1_approx] starting weight calculation for A pastry is made up of flour
A roof is made up of shingles
A cocktail is made up of alcohol
A sea is made up of water
A doorknob is made up of metal
A wine is made up of grapes
A wire is made up of metal
A glass is made up of
2024-07-30 23:58:36 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 00:00:40 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1732, -0.1078, -0.1306,  ...,  0.2061, -0.0729, -0.1497],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.8906, -4.8633,  0.2610,  ..., -3.9844, -0.3154,  0.2490],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0364, -0.0148,  0.0002,  ...,  0.0215, -0.0362, -0.0086],
        [-0.0047,  0.0630,  0.0090,  ...,  0.0031,  0.0117, -0.0197],
        [ 0.0391, -0.0077,  0.0319,  ...,  0.0122, -0.0080, -0.0198],
        ...,
        [ 0.0352,  0.0037,  0.0046,  ...,  0.0265,  0.0067, -0.0037],
        [-0.0084,  0.0172, -0.0175,  ..., -0.0104,  0.0279, -0.0112],
        [ 0.0032, -0.0075,  0.0055,  ..., -0.0043,  0.0122,  0.0409]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.9238, -4.8672,  0.1628,  ..., -3.8320, -0.2476,  0.1906]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 00:00:41 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A pastry is made up of flour
A roof is made up of shingles
A cocktail is made up of alcohol
A sea is made up of water
A doorknob is made up of metal
A wine is made up of grapes
A wire is made up of metal
A glass is made up of
2024-07-31 00:00:42 root INFO     [order_1_approx] starting weight calculation for A cocktail is made up of alcohol
A glass is made up of silicone
A wire is made up of metal
A roof is made up of shingles
A doorknob is made up of metal
A wine is made up of grapes
A pastry is made up of flour
A sea is made up of
2024-07-31 00:00:42 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 00:02:45 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.3232,  0.0936, -0.0576,  ..., -0.5137,  0.0746, -0.0125],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.1383, -3.9766,  0.3047,  ..., -5.2031,  2.6113,  0.3076],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0440,  0.0089,  0.0030,  ...,  0.0028, -0.0158,  0.0045],
        [-0.0018,  0.0221, -0.0094,  ..., -0.0012,  0.0030, -0.0262],
        [ 0.0149,  0.0045,  0.0359,  ...,  0.0020, -0.0069,  0.0066],
        ...,
        [-0.0034,  0.0148,  0.0181,  ...,  0.0391, -0.0073,  0.0016],
        [ 0.0056,  0.0135, -0.0191,  ...,  0.0103,  0.0445,  0.0126],
        [-0.0026, -0.0095,  0.0019,  ...,  0.0055, -0.0041,  0.0355]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.3645, -3.7500,  0.1046,  ..., -5.2461,  2.3867,  0.4202]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 00:02:46 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A cocktail is made up of alcohol
A glass is made up of silicone
A wire is made up of metal
A roof is made up of shingles
A doorknob is made up of metal
A wine is made up of grapes
A pastry is made up of flour
A sea is made up of
2024-07-31 00:02:47 root INFO     [order_1_approx] starting weight calculation for A cocktail is made up of alcohol
A sea is made up of water
A pastry is made up of flour
A roof is made up of shingles
A doorknob is made up of metal
A wire is made up of metal
A glass is made up of silicone
A wine is made up of
2024-07-31 00:02:47 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 00:04:52 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1843,  0.1804, -0.1533,  ..., -0.1758,  0.1320, -0.5137],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.0254, -6.5078, -0.3506,  ..., -4.8008,  1.2158, -3.5762],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 7.9422e-03, -9.2077e-04, -3.6049e-04,  ...,  6.7978e-03,
         -5.5313e-04, -5.6267e-03],
        [-2.6062e-02,  3.0045e-02,  1.1948e-02,  ...,  9.0942e-03,
          1.4244e-02, -3.0640e-02],
        [ 2.7191e-02, -3.8185e-03,  4.3945e-02,  ...,  1.5144e-03,
          5.3406e-03,  1.0042e-03],
        ...,
        [ 2.8610e-03,  6.0501e-03,  1.5930e-02,  ...,  3.7384e-02,
         -8.4639e-06,  1.5545e-03],
        [ 2.0874e-02,  1.4572e-02, -2.8259e-02,  ...,  1.1230e-02,
          2.4246e-02,  8.0566e-03],
        [-2.7130e-02, -8.6546e-05,  1.9348e-02,  ..., -2.0126e-02,
          6.7215e-03,  2.7664e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.6348, -6.7266, -0.6611,  ..., -4.7383,  1.3174, -3.6035]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 00:04:53 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A cocktail is made up of alcohol
A sea is made up of water
A pastry is made up of flour
A roof is made up of shingles
A doorknob is made up of metal
A wire is made up of metal
A glass is made up of silicone
A wine is made up of
2024-07-31 00:04:53 root INFO     [order_1_approx] starting weight calculation for A roof is made up of shingles
A glass is made up of silicone
A wire is made up of metal
A doorknob is made up of metal
A wine is made up of grapes
A pastry is made up of flour
A sea is made up of water
A cocktail is made up of
2024-07-31 00:04:53 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 00:06:59 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0248, -0.1349, -0.1971,  ...,  0.1161, -0.5879, -0.4929],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.8789, -7.1445, -3.7871,  ..., -3.0215, -0.9521, -4.3750],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 5.8716e-02, -1.6266e-02,  3.6697e-03,  ...,  1.2199e-02,
          1.0223e-03,  1.1917e-02],
        [ 6.4850e-05,  3.1235e-02,  1.0803e-02,  ..., -3.1223e-03,
          1.3657e-02, -1.7487e-02],
        [ 2.2812e-03,  2.0523e-03,  4.0161e-02,  ..., -2.7542e-03,
         -9.2850e-03, -2.7504e-03],
        ...,
        [-1.8448e-02,  1.3084e-02,  6.0387e-03,  ...,  4.0283e-02,
         -5.6458e-03, -1.8890e-02],
        [ 2.4071e-03,  2.5909e-02, -5.6152e-03,  ...,  2.0554e-02,
          3.7384e-02,  1.8677e-02],
        [ 2.0752e-03, -1.8341e-02, -5.7182e-03,  ..., -3.1921e-02,
          8.6517e-03,  3.2562e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.9229, -7.0430, -3.8984,  ..., -3.3262, -0.8306, -4.3398]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 00:07:00 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A roof is made up of shingles
A glass is made up of silicone
A wire is made up of metal
A doorknob is made up of metal
A wine is made up of grapes
A pastry is made up of flour
A sea is made up of water
A cocktail is made up of
2024-07-31 00:07:00 root INFO     [order_1_approx] starting weight calculation for A wire is made up of metal
A doorknob is made up of metal
A cocktail is made up of alcohol
A sea is made up of water
A glass is made up of silicone
A wine is made up of grapes
A roof is made up of shingles
A pastry is made up of
2024-07-31 00:07:01 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 00:09:08 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1036, -0.2271,  0.1694,  ..., -0.1575, -0.6089,  0.0876],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.4375, -5.8359,  0.5083,  ..., -1.4072, -4.3516,  3.8984],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0457, -0.0146,  0.0078,  ..., -0.0036, -0.0094,  0.0051],
        [-0.0057,  0.0201,  0.0139,  ...,  0.0066,  0.0020, -0.0244],
        [ 0.0207, -0.0090,  0.0361,  ...,  0.0117,  0.0043, -0.0018],
        ...,
        [ 0.0067,  0.0135,  0.0013,  ...,  0.0558, -0.0102, -0.0263],
        [-0.0159,  0.0089,  0.0015,  ...,  0.0177,  0.0427,  0.0068],
        [-0.0119, -0.0179,  0.0008,  ..., -0.0173,  0.0315,  0.0413]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.1611, -5.6602,  0.5669,  ..., -1.3828, -4.6211,  4.2188]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 00:09:09 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A wire is made up of metal
A doorknob is made up of metal
A cocktail is made up of alcohol
A sea is made up of water
A glass is made up of silicone
A wine is made up of grapes
A roof is made up of shingles
A pastry is made up of
2024-07-31 00:09:09 root INFO     [order_1_approx] starting weight calculation for A wine is made up of grapes
A glass is made up of silicone
A sea is made up of water
A cocktail is made up of alcohol
A doorknob is made up of metal
A wire is made up of metal
A pastry is made up of flour
A roof is made up of
2024-07-31 00:09:09 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 00:11:14 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0695, -0.0589,  0.2019,  ...,  0.0244, -0.2500, -0.5552],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.1406, -5.4766,  0.6914,  ..., -3.8867, -0.9790,  0.1406],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0497, -0.0029,  0.0133,  ..., -0.0010, -0.0233, -0.0117],
        [-0.0143,  0.0584,  0.0207,  ..., -0.0077, -0.0040, -0.0124],
        [ 0.0052,  0.0177,  0.0343,  ..., -0.0065, -0.0054, -0.0187],
        ...,
        [ 0.0133,  0.0015,  0.0250,  ...,  0.0495,  0.0004, -0.0024],
        [-0.0078,  0.0198, -0.0152,  ..., -0.0025,  0.0607,  0.0214],
        [-0.0024, -0.0115,  0.0142,  ...,  0.0113, -0.0080,  0.0184]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.9824, -5.1094,  0.4639,  ..., -4.0273, -0.9990,  0.2793]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 00:11:15 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A wine is made up of grapes
A glass is made up of silicone
A sea is made up of water
A cocktail is made up of alcohol
A doorknob is made up of metal
A wire is made up of metal
A pastry is made up of flour
A roof is made up of
2024-07-31 00:11:16 root INFO     [order_1_approx] starting weight calculation for A pastry is made up of flour
A wire is made up of metal
A cocktail is made up of alcohol
A wine is made up of grapes
A sea is made up of water
A glass is made up of silicone
A roof is made up of shingles
A doorknob is made up of
2024-07-31 00:11:16 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 00:13:18 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0956,  0.0652, -0.0079,  ...,  0.4521, -0.7734, -0.2600],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.6113, -2.5938, -1.8623,  ..., -2.7539, -0.4521, -0.3926],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0649, -0.0164, -0.0176,  ...,  0.0334, -0.0072, -0.0182],
        [ 0.0060,  0.0473,  0.0067,  ...,  0.0059,  0.0036, -0.0071],
        [ 0.0276,  0.0159,  0.0573,  ..., -0.0003,  0.0068,  0.0015],
        ...,
        [ 0.0284, -0.0004,  0.0046,  ...,  0.0493, -0.0102, -0.0036],
        [-0.0193,  0.0194, -0.0057,  ...,  0.0102,  0.0545,  0.0091],
        [-0.0035, -0.0008,  0.0201,  ..., -0.0138,  0.0013,  0.0357]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.6055, -2.1094, -1.7422,  ..., -2.8574, -0.4937, -0.3752]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 00:13:18 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A pastry is made up of flour
A wire is made up of metal
A cocktail is made up of alcohol
A wine is made up of grapes
A sea is made up of water
A glass is made up of silicone
A roof is made up of shingles
A doorknob is made up of
2024-07-31 00:13:19 root INFO     [order_1_approx] starting weight calculation for A sea is made up of water
A cocktail is made up of alcohol
A wine is made up of grapes
A roof is made up of shingles
A pastry is made up of flour
A glass is made up of silicone
A doorknob is made up of metal
A wire is made up of
2024-07-31 00:13:19 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 00:15:20 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2700,  0.4805, -0.6929,  ...,  0.2595,  0.3235,  0.0120],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.7539, -4.8125, -0.0596,  ..., -3.5898,  0.0522, -0.7344],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0475, -0.0275,  0.0064,  ...,  0.0156, -0.0024, -0.0235],
        [ 0.0095,  0.0274,  0.0121,  ...,  0.0058,  0.0156, -0.0184],
        [ 0.0260,  0.0106,  0.0236,  ...,  0.0099, -0.0088, -0.0224],
        ...,
        [ 0.0179,  0.0099,  0.0208,  ...,  0.0322,  0.0111,  0.0045],
        [-0.0196,  0.0199,  0.0100,  ..., -0.0013,  0.0318,  0.0088],
        [-0.0036,  0.0028, -0.0224,  ..., -0.0125,  0.0113,  0.0370]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.7246, -5.1133, -0.2593,  ..., -3.5254, -0.2627, -0.5752]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 00:15:21 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A sea is made up of water
A cocktail is made up of alcohol
A wine is made up of grapes
A roof is made up of shingles
A pastry is made up of flour
A glass is made up of silicone
A doorknob is made up of metal
A wire is made up of
2024-07-31 00:15:21 root INFO     total operator prediction time: 1005.8728199005127 seconds
2024-07-31 00:15:21 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on hypernyms - misc
2024-07-31 00:15:21 root INFO     building operator hypernyms - misc
2024-07-31 00:15:22 root INFO     [order_1_approx] starting weight calculation for The grapefruit falls into the category of citrus
The desk falls into the category of furniture
The deodorant falls into the category of toiletry
The blender falls into the category of appliance
The sunscreen falls into the category of cream
The toaster falls into the category of appliance
The lotion falls into the category of toiletry
The diary falls into the category of
2024-07-31 00:15:22 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 00:17:21 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.3354, -0.0772, -0.2385,  ..., -0.3020, -0.4185,  0.1631],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.3750, -4.2969,  0.7671,  ..., -2.9844, -1.3662, -0.4805],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0772, -0.0060,  0.0065,  ..., -0.0159, -0.0033,  0.0034],
        [-0.0127,  0.0564, -0.0086,  ..., -0.0094,  0.0228,  0.0156],
        [ 0.0162, -0.0129,  0.0770,  ...,  0.0276, -0.0175,  0.0099],
        ...,
        [ 0.0105,  0.0062,  0.0204,  ...,  0.0721,  0.0055, -0.0197],
        [-0.0163, -0.0092,  0.0222,  ...,  0.0155,  0.0540,  0.0004],
        [-0.0179,  0.0250,  0.0055,  ..., -0.0156, -0.0119,  0.0835]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.5210, -4.5742,  0.8330,  ..., -2.7578, -1.0645, -0.8721]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 00:17:22 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The grapefruit falls into the category of citrus
The desk falls into the category of furniture
The deodorant falls into the category of toiletry
The blender falls into the category of appliance
The sunscreen falls into the category of cream
The toaster falls into the category of appliance
The lotion falls into the category of toiletry
The diary falls into the category of
2024-07-31 00:17:22 root INFO     [order_1_approx] starting weight calculation for The deodorant falls into the category of toiletry
The toaster falls into the category of appliance
The lotion falls into the category of toiletry
The sunscreen falls into the category of cream
The blender falls into the category of appliance
The diary falls into the category of journal
The desk falls into the category of furniture
The grapefruit falls into the category of
2024-07-31 00:17:22 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 00:19:25 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2307, -0.3884, -0.1554,  ..., -0.1296, -0.4536, -0.4055],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.2852, -5.3711,  0.9517,  ..., -5.0352, -2.1562, -2.3398],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0549,  0.0119, -0.0150,  ...,  0.0294,  0.0005,  0.0088],
        [ 0.0235,  0.0527,  0.0131,  ...,  0.0080,  0.0119, -0.0113],
        [-0.0022, -0.0037,  0.0486,  ...,  0.0194, -0.0078,  0.0221],
        ...,
        [ 0.0175, -0.0034, -0.0015,  ...,  0.0398, -0.0036, -0.0112],
        [ 0.0171,  0.0018,  0.0123,  ...,  0.0093,  0.0325, -0.0144],
        [-0.0027, -0.0108,  0.0069,  ..., -0.0146, -0.0136,  0.0580]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.3047, -5.7266,  0.5654,  ..., -4.8516, -1.7754, -2.6738]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 00:19:26 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The deodorant falls into the category of toiletry
The toaster falls into the category of appliance
The lotion falls into the category of toiletry
The sunscreen falls into the category of cream
The blender falls into the category of appliance
The diary falls into the category of journal
The desk falls into the category of furniture
The grapefruit falls into the category of
2024-07-31 00:19:26 root INFO     [order_1_approx] starting weight calculation for The deodorant falls into the category of toiletry
The grapefruit falls into the category of citrus
The lotion falls into the category of toiletry
The blender falls into the category of appliance
The toaster falls into the category of appliance
The desk falls into the category of furniture
The diary falls into the category of journal
The sunscreen falls into the category of
2024-07-31 00:19:26 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 00:21:31 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.4587, -0.5845,  0.2275,  ..., -0.0388,  0.0133, -0.4724],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.8613, -1.1953,  2.6680,  ..., -2.1797,  0.2773, -0.6162],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 5.1819e-02, -1.1055e-02, -2.3193e-03,  ..., -5.5656e-03,
         -7.4501e-03,  3.2043e-03],
        [ 1.4305e-02,  6.3110e-02, -1.2558e-02,  ..., -4.1199e-04,
          2.1801e-03,  2.4368e-02],
        [-1.1078e-02,  1.0963e-02,  4.6356e-02,  ...,  1.1223e-02,
          2.5635e-03, -4.9591e-05],
        ...,
        [ 1.4267e-02, -2.8610e-03, -3.8509e-03,  ...,  5.8350e-02,
          4.1885e-03,  2.2858e-02],
        [-3.3245e-03,  1.4534e-03, -2.1095e-03,  ...,  3.2074e-02,
          5.5908e-02, -8.6288e-03],
        [ 6.1073e-03, -1.7426e-02,  1.4858e-03,  ...,  1.2589e-03,
         -1.2619e-02,  6.2561e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.7803, -1.7559,  2.6230,  ..., -2.0684,  0.1764, -0.7490]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 00:21:32 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The deodorant falls into the category of toiletry
The grapefruit falls into the category of citrus
The lotion falls into the category of toiletry
The blender falls into the category of appliance
The toaster falls into the category of appliance
The desk falls into the category of furniture
The diary falls into the category of journal
The sunscreen falls into the category of
2024-07-31 00:21:32 root INFO     [order_1_approx] starting weight calculation for The diary falls into the category of journal
The deodorant falls into the category of toiletry
The grapefruit falls into the category of citrus
The toaster falls into the category of appliance
The lotion falls into the category of toiletry
The sunscreen falls into the category of cream
The desk falls into the category of furniture
The blender falls into the category of
2024-07-31 00:21:32 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 00:23:36 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0887, -0.2720,  0.3362,  ...,  0.6787,  0.0085, -0.2004],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.7754, -4.2773, -0.1587,  ..., -2.4121, -2.6230, -0.1641],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0699,  0.0004, -0.0103,  ...,  0.0022,  0.0073,  0.0037],
        [ 0.0220,  0.0842, -0.0038,  ..., -0.0023, -0.0030,  0.0005],
        [-0.0152,  0.0064,  0.0728,  ...,  0.0047, -0.0051,  0.0104],
        ...,
        [ 0.0140,  0.0086,  0.0065,  ...,  0.0683,  0.0131,  0.0120],
        [-0.0151, -0.0039,  0.0045,  ...,  0.0078,  0.0773, -0.0303],
        [-0.0089,  0.0057, -0.0022,  ..., -0.0060, -0.0024,  0.0727]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.7261, -4.0195, -0.1836,  ..., -2.5488, -2.0898, -0.0804]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 00:23:37 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The diary falls into the category of journal
The deodorant falls into the category of toiletry
The grapefruit falls into the category of citrus
The toaster falls into the category of appliance
The lotion falls into the category of toiletry
The sunscreen falls into the category of cream
The desk falls into the category of furniture
The blender falls into the category of
2024-07-31 00:23:37 root INFO     [order_1_approx] starting weight calculation for The grapefruit falls into the category of citrus
The desk falls into the category of furniture
The toaster falls into the category of appliance
The diary falls into the category of journal
The sunscreen falls into the category of cream
The blender falls into the category of appliance
The lotion falls into the category of toiletry
The deodorant falls into the category of
2024-07-31 00:23:37 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 00:25:42 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0972, -0.7529,  0.2073,  ...,  0.0473, -0.3628, -0.5469],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.5742, -2.9297, -0.4814,  ..., -2.2480, -0.5430, -1.3125],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0300, -0.0071, -0.0022,  ...,  0.0071, -0.0049,  0.0038],
        [-0.0009,  0.0294, -0.0013,  ..., -0.0081,  0.0061, -0.0034],
        [-0.0034,  0.0039,  0.0355,  ..., -0.0050,  0.0009,  0.0005],
        ...,
        [ 0.0090,  0.0072,  0.0004,  ...,  0.0307,  0.0057,  0.0022],
        [-0.0079,  0.0048,  0.0058,  ..., -0.0074,  0.0311, -0.0032],
        [ 0.0021, -0.0025,  0.0013,  ..., -0.0021, -0.0125,  0.0322]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.5615, -3.0410, -0.3730,  ..., -2.2871, -0.6514, -1.3467]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 00:25:43 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The grapefruit falls into the category of citrus
The desk falls into the category of furniture
The toaster falls into the category of appliance
The diary falls into the category of journal
The sunscreen falls into the category of cream
The blender falls into the category of appliance
The lotion falls into the category of toiletry
The deodorant falls into the category of
2024-07-31 00:25:43 root INFO     [order_1_approx] starting weight calculation for The sunscreen falls into the category of cream
The blender falls into the category of appliance
The grapefruit falls into the category of citrus
The lotion falls into the category of toiletry
The desk falls into the category of furniture
The diary falls into the category of journal
The deodorant falls into the category of toiletry
The toaster falls into the category of
2024-07-31 00:25:43 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 00:27:39 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2415,  0.1367,  0.0772,  ..., -0.0117, -0.2812, -0.1405],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.4971, -2.8594,  0.7617,  ..., -0.7441, -2.6094,  2.0391],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0759, -0.0066,  0.0064,  ...,  0.0002, -0.0121, -0.0034],
        [ 0.0211,  0.0783,  0.0052,  ...,  0.0064,  0.0037, -0.0004],
        [ 0.0048, -0.0049,  0.0478,  ...,  0.0076, -0.0066, -0.0079],
        ...,
        [ 0.0321,  0.0153,  0.0034,  ...,  0.0773, -0.0071, -0.0014],
        [-0.0131, -0.0009,  0.0189,  ...,  0.0130,  0.0719, -0.0139],
        [ 0.0062,  0.0067, -0.0167,  ..., -0.0104, -0.0043,  0.0851]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.6274, -2.7227,  0.7559,  ..., -1.0371, -2.0449,  1.6895]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 00:27:40 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The sunscreen falls into the category of cream
The blender falls into the category of appliance
The grapefruit falls into the category of citrus
The lotion falls into the category of toiletry
The desk falls into the category of furniture
The diary falls into the category of journal
The deodorant falls into the category of toiletry
The toaster falls into the category of
2024-07-31 00:27:40 root INFO     [order_1_approx] starting weight calculation for The sunscreen falls into the category of cream
The toaster falls into the category of appliance
The deodorant falls into the category of toiletry
The diary falls into the category of journal
The grapefruit falls into the category of citrus
The desk falls into the category of furniture
The blender falls into the category of appliance
The lotion falls into the category of
2024-07-31 00:27:40 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 00:29:44 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0231, -0.6118,  0.0920,  ..., -0.3989, -0.1436, -0.2388],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.7217, -0.4888,  1.4580,  ..., -2.9199, -0.5635, -0.2480],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0740, -0.0233, -0.0041,  ..., -0.0118, -0.0117,  0.0087],
        [ 0.0080,  0.0687,  0.0040,  ...,  0.0123,  0.0039,  0.0027],
        [-0.0159,  0.0094,  0.0717,  ...,  0.0051,  0.0030,  0.0049],
        ...,
        [-0.0089,  0.0164,  0.0124,  ...,  0.0726,  0.0096, -0.0081],
        [ 0.0059,  0.0084,  0.0021,  ...,  0.0004,  0.0643, -0.0135],
        [-0.0110, -0.0075,  0.0038,  ...,  0.0022, -0.0213,  0.0847]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.6006, -0.7451,  1.2383,  ..., -2.8730, -0.6045, -0.3784]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 00:29:45 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The sunscreen falls into the category of cream
The toaster falls into the category of appliance
The deodorant falls into the category of toiletry
The diary falls into the category of journal
The grapefruit falls into the category of citrus
The desk falls into the category of furniture
The blender falls into the category of appliance
The lotion falls into the category of
2024-07-31 00:29:45 root INFO     [order_1_approx] starting weight calculation for The sunscreen falls into the category of cream
The diary falls into the category of journal
The lotion falls into the category of toiletry
The blender falls into the category of appliance
The toaster falls into the category of appliance
The deodorant falls into the category of toiletry
The grapefruit falls into the category of citrus
The desk falls into the category of
2024-07-31 00:29:45 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 00:31:50 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.3818, -0.0867, -0.3203,  ...,  0.2264, -0.6367, -0.2695],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.0605, -6.0078,  4.0039,  ..., -2.6484, -3.2031, -1.8438],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 4.0436e-02,  8.8043e-03,  2.6398e-03,  ...,  2.4185e-03,
          1.9226e-02,  9.8190e-03],
        [ 8.3923e-03,  3.1891e-02, -9.3460e-05,  ..., -7.1793e-03,
          1.1475e-02, -1.0414e-02],
        [-5.8899e-03, -7.4844e-03,  4.2664e-02,  ...,  1.0147e-02,
         -7.1259e-03,  1.9760e-02],
        ...,
        [ 1.5869e-03,  7.5684e-03,  1.9943e-02,  ...,  3.7750e-02,
          9.0790e-03, -1.2238e-02],
        [ 6.4621e-03,  1.7059e-02,  1.5755e-03,  ...,  8.2779e-03,
          4.6356e-02, -1.1185e-02],
        [-1.6718e-03, -7.7171e-03, -6.5689e-03,  ..., -5.8136e-03,
         -2.1164e-02,  3.7720e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.8403, -5.7266,  3.5996,  ..., -2.4375, -3.0273, -1.5977]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 00:31:51 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The sunscreen falls into the category of cream
The diary falls into the category of journal
The lotion falls into the category of toiletry
The blender falls into the category of appliance
The toaster falls into the category of appliance
The deodorant falls into the category of toiletry
The grapefruit falls into the category of citrus
The desk falls into the category of
2024-07-31 00:31:51 root INFO     total operator prediction time: 989.9971604347229 seconds
2024-07-31 00:31:51 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on synonyms - exact
2024-07-31 00:31:51 root INFO     building operator synonyms - exact
2024-07-31 00:31:51 root INFO     [order_1_approx] starting weight calculation for Another word for honest is sincere
Another word for flower is blossom
Another word for loyal is faithful
Another word for style is manner
Another word for bicycle is bike
Another word for intelligent is clever
Another word for jewel is gem
Another word for airplane is
2024-07-31 00:31:51 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 00:33:59 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1741, -0.3843, -0.4622,  ..., -0.1394, -0.5234, -0.4868],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.4507, -3.2031,  2.6387,  ..., -1.0430, -2.4082,  1.1875],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0921, -0.0062,  0.0064,  ...,  0.0146,  0.0173,  0.0068],
        [ 0.0398,  0.0649,  0.0089,  ...,  0.0156,  0.0164, -0.0271],
        [-0.0123,  0.0089,  0.0798,  ...,  0.0039, -0.0037,  0.0273],
        ...,
        [ 0.0175,  0.0158, -0.0096,  ...,  0.0800,  0.0113, -0.0074],
        [-0.0145,  0.0025,  0.0076,  ..., -0.0009,  0.0745,  0.0007],
        [-0.0048,  0.0036, -0.0154,  ..., -0.0263, -0.0027,  0.0646]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.5361, -2.8828,  2.2422,  ..., -0.9102, -2.3281,  1.1396]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 00:34:00 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Another word for honest is sincere
Another word for flower is blossom
Another word for loyal is faithful
Another word for style is manner
Another word for bicycle is bike
Another word for intelligent is clever
Another word for jewel is gem
Another word for airplane is
2024-07-31 00:34:00 root INFO     [order_1_approx] starting weight calculation for Another word for bicycle is bike
Another word for jewel is gem
Another word for loyal is faithful
Another word for flower is blossom
Another word for airplane is aeroplane
Another word for honest is sincere
Another word for intelligent is clever
Another word for style is
2024-07-31 00:34:00 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 00:36:05 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3525, -0.4746, -0.2002,  ..., -0.0571,  0.2725,  0.1731],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.0020, -1.9736,  0.2301,  ...,  2.3457, -5.7383, -0.8965],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0703,  0.0057, -0.0128,  ...,  0.0170, -0.0111, -0.0124],
        [ 0.0108,  0.0839,  0.0023,  ..., -0.0008,  0.0100, -0.0218],
        [-0.0122, -0.0048,  0.0956,  ...,  0.0053,  0.0167, -0.0012],
        ...,
        [-0.0044, -0.0056,  0.0001,  ...,  0.1229,  0.0236, -0.0159],
        [ 0.0157,  0.0006,  0.0189,  ...,  0.0126,  0.0913,  0.0130],
        [ 0.0047,  0.0133,  0.0056,  ..., -0.0081,  0.0086,  0.0866]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.1064, -1.3281, -0.2515,  ...,  2.7266, -5.8945, -0.9551]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 00:36:06 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Another word for bicycle is bike
Another word for jewel is gem
Another word for loyal is faithful
Another word for flower is blossom
Another word for airplane is aeroplane
Another word for honest is sincere
Another word for intelligent is clever
Another word for style is
2024-07-31 00:36:06 root INFO     [order_1_approx] starting weight calculation for Another word for flower is blossom
Another word for style is manner
Another word for intelligent is clever
Another word for bicycle is bike
Another word for loyal is faithful
Another word for airplane is aeroplane
Another word for jewel is gem
Another word for honest is
2024-07-31 00:36:06 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 00:38:11 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2069,  0.1898, -0.2805,  ...,  0.0743,  0.1416,  0.0877],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.9277, -3.1914, -0.9419,  ...,  0.2915, -8.3828,  2.5898],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0991, -0.0007,  0.0213,  ..., -0.0025, -0.0016,  0.0169],
        [ 0.0115,  0.1084, -0.0115,  ..., -0.0021,  0.0255,  0.0003],
        [ 0.0108, -0.0100,  0.0978,  ..., -0.0293, -0.0214, -0.0133],
        ...,
        [ 0.0154,  0.0042,  0.0300,  ...,  0.1144,  0.0066, -0.0213],
        [-0.0163,  0.0167, -0.0010,  ...,  0.0058,  0.0771, -0.0233],
        [ 0.0059, -0.0244,  0.0099,  ..., -0.0198, -0.0195,  0.0767]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.7568, -2.4141, -1.1670,  ...,  0.2610, -8.6797,  2.4004]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 00:38:12 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Another word for flower is blossom
Another word for style is manner
Another word for intelligent is clever
Another word for bicycle is bike
Another word for loyal is faithful
Another word for airplane is aeroplane
Another word for jewel is gem
Another word for honest is
2024-07-31 00:38:12 root INFO     [order_1_approx] starting weight calculation for Another word for jewel is gem
Another word for bicycle is bike
Another word for airplane is aeroplane
Another word for style is manner
Another word for intelligent is clever
Another word for honest is sincere
Another word for flower is blossom
Another word for loyal is
2024-07-31 00:38:12 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 00:40:19 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2646, -0.1423, -0.2225,  ..., -0.2213,  0.2837,  0.1907],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.4512, -4.8633,  0.0527,  ..., -0.8521, -6.4336, -0.6802],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0749, -0.0053,  0.0190,  ..., -0.0137,  0.0055, -0.0083],
        [ 0.0125,  0.0839,  0.0042,  ...,  0.0030,  0.0112, -0.0097],
        [ 0.0243, -0.0191,  0.0892,  ..., -0.0157, -0.0070, -0.0205],
        ...,
        [-0.0126,  0.0088,  0.0047,  ...,  0.0889,  0.0073,  0.0140],
        [ 0.0091, -0.0009, -0.0033,  ..., -0.0055,  0.0658, -0.0031],
        [-0.0018, -0.0130, -0.0026,  ..., -0.0092, -0.0229,  0.0830]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.3145, -4.9023,  0.0803,  ..., -0.6562, -6.3398, -1.0332]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 00:40:20 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Another word for jewel is gem
Another word for bicycle is bike
Another word for airplane is aeroplane
Another word for style is manner
Another word for intelligent is clever
Another word for honest is sincere
Another word for flower is blossom
Another word for loyal is
2024-07-31 00:40:20 root INFO     [order_1_approx] starting weight calculation for Another word for intelligent is clever
Another word for style is manner
Another word for loyal is faithful
Another word for bicycle is bike
Another word for honest is sincere
Another word for airplane is aeroplane
Another word for flower is blossom
Another word for jewel is
2024-07-31 00:40:20 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 00:42:25 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4878,  0.0255, -0.4783,  ..., -0.1244, -0.4451, -0.3938],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.0723, -1.7891, -2.8555,  ...,  0.1108, -3.4336,  2.3945],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0435, -0.0060,  0.0172,  ..., -0.0106, -0.0135,  0.0068],
        [-0.0026,  0.0482, -0.0020,  ...,  0.0111,  0.0183, -0.0140],
        [-0.0010, -0.0010,  0.0323,  ...,  0.0014, -0.0101,  0.0043],
        ...,
        [-0.0168,  0.0153, -0.0031,  ...,  0.0519,  0.0148, -0.0101],
        [-0.0063, -0.0039,  0.0160,  ...,  0.0008,  0.0299,  0.0004],
        [ 0.0017,  0.0042, -0.0154,  ..., -0.0181, -0.0008,  0.0304]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.2500, -1.6904, -3.0664,  ...,  0.4434, -3.9023,  2.4102]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 00:42:26 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Another word for intelligent is clever
Another word for style is manner
Another word for loyal is faithful
Another word for bicycle is bike
Another word for honest is sincere
Another word for airplane is aeroplane
Another word for flower is blossom
Another word for jewel is
2024-07-31 00:42:27 root INFO     [order_1_approx] starting weight calculation for Another word for intelligent is clever
Another word for airplane is aeroplane
Another word for loyal is faithful
Another word for flower is blossom
Another word for jewel is gem
Another word for honest is sincere
Another word for style is manner
Another word for bicycle is
2024-07-31 00:42:27 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 00:44:28 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2258, -0.5718, -0.5869,  ..., -0.0735, -0.2891, -0.2062],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.4548, -4.0703,  0.6367,  ...,  1.2871, -0.8633, -1.8477],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0358, -0.0133,  0.0093,  ...,  0.0129,  0.0055, -0.0123],
        [ 0.0021,  0.0365,  0.0023,  ...,  0.0017,  0.0146, -0.0223],
        [-0.0012, -0.0028,  0.0412,  ..., -0.0093,  0.0048,  0.0140],
        ...,
        [ 0.0097, -0.0017,  0.0026,  ...,  0.0467, -0.0002,  0.0057],
        [-0.0062, -0.0044,  0.0008,  ...,  0.0014,  0.0369, -0.0056],
        [ 0.0084, -0.0056, -0.0018,  ..., -0.0163, -0.0080,  0.0379]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.3633, -3.9609,  0.5518,  ...,  1.2871, -0.7974, -1.9570]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 00:44:28 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Another word for intelligent is clever
Another word for airplane is aeroplane
Another word for loyal is faithful
Another word for flower is blossom
Another word for jewel is gem
Another word for honest is sincere
Another word for style is manner
Another word for bicycle is
2024-07-31 00:44:29 root INFO     [order_1_approx] starting weight calculation for Another word for loyal is faithful
Another word for style is manner
Another word for intelligent is clever
Another word for airplane is aeroplane
Another word for jewel is gem
Another word for bicycle is bike
Another word for honest is sincere
Another word for flower is
2024-07-31 00:44:29 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 00:46:37 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0093, -0.3008, -0.3662,  ...,  0.0039,  0.0743, -0.0560],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.8721, -3.5605,  0.3530,  ...,  2.8438, -3.0371,  0.1543],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0870, -0.0029,  0.0238,  ...,  0.0072,  0.0020,  0.0054],
        [ 0.0057,  0.0966,  0.0240,  ...,  0.0224,  0.0057, -0.0182],
        [ 0.0047,  0.0019,  0.1072,  ...,  0.0057, -0.0281,  0.0043],
        ...,
        [-0.0319,  0.0142, -0.0007,  ...,  0.0955,  0.0043, -0.0113],
        [-0.0144, -0.0052,  0.0135,  ..., -0.0092,  0.0856,  0.0178],
        [-0.0223, -0.0092, -0.0151,  ..., -0.0007, -0.0230,  0.0756]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.8516, -2.7266,  0.2437,  ...,  2.9707, -3.5820,  0.9033]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 00:46:38 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Another word for loyal is faithful
Another word for style is manner
Another word for intelligent is clever
Another word for airplane is aeroplane
Another word for jewel is gem
Another word for bicycle is bike
Another word for honest is sincere
Another word for flower is
2024-07-31 00:46:38 root INFO     [order_1_approx] starting weight calculation for Another word for jewel is gem
Another word for flower is blossom
Another word for loyal is faithful
Another word for style is manner
Another word for honest is sincere
Another word for airplane is aeroplane
Another word for bicycle is bike
Another word for intelligent is
2024-07-31 00:46:38 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 00:48:46 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3342, -0.2791, -0.1899,  ...,  0.0281,  0.0052, -0.0247],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.2910, -0.3350,  0.6299,  ...,  1.8594, -4.1367,  0.3765],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0648,  0.0017,  0.0023,  ..., -0.0033,  0.0017,  0.0112],
        [-0.0102,  0.0397,  0.0101,  ...,  0.0203,  0.0115,  0.0027],
        [-0.0226, -0.0238,  0.0681,  ...,  0.0030,  0.0056, -0.0001],
        ...,
        [ 0.0115,  0.0082, -0.0041,  ...,  0.0891,  0.0188,  0.0054],
        [-0.0097, -0.0105, -0.0017,  ..., -0.0047,  0.0276, -0.0063],
        [ 0.0113, -0.0111,  0.0072,  ..., -0.0109,  0.0060,  0.0558]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.1553, -0.1699,  0.5884,  ...,  2.0195, -4.1914,  0.4250]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 00:48:47 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Another word for jewel is gem
Another word for flower is blossom
Another word for loyal is faithful
Another word for style is manner
Another word for honest is sincere
Another word for airplane is aeroplane
Another word for bicycle is bike
Another word for intelligent is
2024-07-31 00:48:47 root INFO     total operator prediction time: 1015.9873621463776 seconds
2024-07-31 00:48:47 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on animal - youth
2024-07-31 00:48:47 root INFO     building operator animal - youth
2024-07-31 00:48:47 root INFO     [order_1_approx] starting weight calculation for The offspring of a monkey is referred to as a infant
The offspring of a horse is referred to as a foal
The offspring of a cat is referred to as a kitten
The offspring of a fly is referred to as a grub
The offspring of a bear is referred to as a cub
The offspring of a chimpanzee is referred to as a baby
The offspring of a muskrat is referred to as a kit
The offspring of a beetle is referred to as a
2024-07-31 00:48:48 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 00:50:56 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0493,  0.0570,  0.0774,  ..., -0.0288, -0.2981, -0.3027],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.7471, -1.3037, -0.3447,  ...,  1.2227, -0.3711, -0.3984],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0374, -0.0100,  0.0040,  ...,  0.0163,  0.0030, -0.0099],
        [ 0.0118,  0.0111,  0.0002,  ...,  0.0036, -0.0055, -0.0178],
        [-0.0011, -0.0077,  0.0285,  ...,  0.0119,  0.0024, -0.0034],
        ...,
        [ 0.0108, -0.0079,  0.0011,  ...,  0.0235,  0.0110, -0.0052],
        [ 0.0041, -0.0003,  0.0143,  ...,  0.0073,  0.0066, -0.0055],
        [-0.0038, -0.0012, -0.0050,  ..., -0.0056, -0.0044,  0.0311]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.8828, -1.5068, -0.6123,  ...,  1.3789, -0.3359, -0.5308]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 00:50:57 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The offspring of a monkey is referred to as a infant
The offspring of a horse is referred to as a foal
The offspring of a cat is referred to as a kitten
The offspring of a fly is referred to as a grub
The offspring of a bear is referred to as a cub
The offspring of a chimpanzee is referred to as a baby
The offspring of a muskrat is referred to as a kit
The offspring of a beetle is referred to as a
2024-07-31 00:50:57 root INFO     [order_1_approx] starting weight calculation for The offspring of a bear is referred to as a cub
The offspring of a horse is referred to as a foal
The offspring of a muskrat is referred to as a kit
The offspring of a beetle is referred to as a larva
The offspring of a cat is referred to as a kitten
The offspring of a monkey is referred to as a infant
The offspring of a chimpanzee is referred to as a baby
The offspring of a fly is referred to as a
2024-07-31 00:50:57 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 00:53:02 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.5713, -0.1223,  0.1523,  ...,  0.3872, -0.1117,  0.3601],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.0137, -2.6289, -1.0859,  ...,  0.4419, -2.8477, -0.0088],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0508, -0.0162,  0.0060,  ...,  0.0152, -0.0143, -0.0101],
        [-0.0005,  0.0338,  0.0054,  ..., -0.0094,  0.0053, -0.0174],
        [-0.0016,  0.0059,  0.0468,  ...,  0.0072, -0.0027, -0.0034],
        ...,
        [-0.0102,  0.0047, -0.0057,  ...,  0.0388,  0.0105, -0.0021],
        [-0.0023,  0.0137,  0.0233,  ...,  0.0118,  0.0062, -0.0019],
        [ 0.0097, -0.0073, -0.0001,  ..., -0.0055,  0.0091,  0.0161]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.9688, -2.6387, -1.0234,  ...,  0.5654, -2.6895, -0.3479]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 00:53:03 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The offspring of a bear is referred to as a cub
The offspring of a horse is referred to as a foal
The offspring of a muskrat is referred to as a kit
The offspring of a beetle is referred to as a larva
The offspring of a cat is referred to as a kitten
The offspring of a monkey is referred to as a infant
The offspring of a chimpanzee is referred to as a baby
The offspring of a fly is referred to as a
2024-07-31 00:53:03 root INFO     [order_1_approx] starting weight calculation for The offspring of a cat is referred to as a kitten
The offspring of a muskrat is referred to as a kit
The offspring of a bear is referred to as a cub
The offspring of a chimpanzee is referred to as a baby
The offspring of a monkey is referred to as a infant
The offspring of a fly is referred to as a grub
The offspring of a beetle is referred to as a larva
The offspring of a horse is referred to as a
2024-07-31 00:53:03 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 00:55:09 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.3755, -0.0742,  0.5283,  ...,  0.3618,  0.0963,  0.0585],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.7070, -5.3281, -2.9258,  ...,  2.6875, -1.5205,  1.6045],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0311, -0.0118,  0.0019,  ...,  0.0006,  0.0006,  0.0030],
        [-0.0022,  0.0291,  0.0115,  ...,  0.0081,  0.0161, -0.0170],
        [ 0.0053,  0.0073,  0.0316,  ...,  0.0031, -0.0025, -0.0124],
        ...,
        [ 0.0057,  0.0012,  0.0024,  ...,  0.0259,  0.0029,  0.0009],
        [-0.0014,  0.0219,  0.0062,  ...,  0.0109,  0.0066, -0.0092],
        [ 0.0022, -0.0030,  0.0068,  ..., -0.0117, -0.0032,  0.0162]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.2188, -4.8750, -2.7969,  ...,  2.7402, -2.3379,  1.5596]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 00:55:11 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The offspring of a cat is referred to as a kitten
The offspring of a muskrat is referred to as a kit
The offspring of a bear is referred to as a cub
The offspring of a chimpanzee is referred to as a baby
The offspring of a monkey is referred to as a infant
The offspring of a fly is referred to as a grub
The offspring of a beetle is referred to as a larva
The offspring of a horse is referred to as a
2024-07-31 00:55:11 root INFO     [order_1_approx] starting weight calculation for The offspring of a muskrat is referred to as a kit
The offspring of a fly is referred to as a grub
The offspring of a bear is referred to as a cub
The offspring of a beetle is referred to as a larva
The offspring of a cat is referred to as a kitten
The offspring of a chimpanzee is referred to as a baby
The offspring of a horse is referred to as a foal
The offspring of a monkey is referred to as a
2024-07-31 00:55:11 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 00:57:14 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2043,  0.0033,  0.3745,  ...,  0.0568, -0.7881,  0.0148],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.4883, -3.8984, -0.4270,  ..., -0.3486, -4.1836,  2.6191],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0395, -0.0056, -0.0085,  ...,  0.0049,  0.0015, -0.0042],
        [-0.0010,  0.0446,  0.0025,  ..., -0.0114,  0.0130, -0.0189],
        [ 0.0125,  0.0131,  0.0446,  ...,  0.0146, -0.0014, -0.0031],
        ...,
        [-0.0027,  0.0124, -0.0018,  ...,  0.0442,  0.0160, -0.0044],
        [ 0.0156,  0.0036,  0.0066,  ..., -0.0058,  0.0080, -0.0109],
        [-0.0178, -0.0058, -0.0066,  ..., -0.0248,  0.0087,  0.0268]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.7520, -3.8633, -0.9805,  ..., -0.0095, -4.4883,  2.6289]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 00:57:14 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The offspring of a muskrat is referred to as a kit
The offspring of a fly is referred to as a grub
The offspring of a bear is referred to as a cub
The offspring of a beetle is referred to as a larva
The offspring of a cat is referred to as a kitten
The offspring of a chimpanzee is referred to as a baby
The offspring of a horse is referred to as a foal
The offspring of a monkey is referred to as a
2024-07-31 00:57:15 root INFO     [order_1_approx] starting weight calculation for The offspring of a muskrat is referred to as a kit
The offspring of a monkey is referred to as a infant
The offspring of a horse is referred to as a foal
The offspring of a chimpanzee is referred to as a baby
The offspring of a fly is referred to as a grub
The offspring of a beetle is referred to as a larva
The offspring of a bear is referred to as a cub
The offspring of a cat is referred to as a
2024-07-31 00:57:15 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 00:59:19 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0053, -0.1876,  0.5391,  ...,  0.2966,  0.1052, -0.0277],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.9297, -3.5098, -2.2832,  ..., -0.3965,  0.0750,  0.3027],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0191, -0.0123, -0.0045,  ...,  0.0030,  0.0103,  0.0009],
        [ 0.0043,  0.0287,  0.0097,  ..., -0.0059,  0.0086, -0.0166],
        [-0.0060,  0.0115,  0.0409,  ..., -0.0005, -0.0030, -0.0094],
        ...,
        [-0.0052, -0.0033, -0.0020,  ...,  0.0238,  0.0111, -0.0049],
        [ 0.0202,  0.0068,  0.0132,  ...,  0.0161,  0.0126, -0.0141],
        [-0.0023, -0.0090, -0.0050,  ..., -0.0119, -0.0007,  0.0295]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.4746, -3.3867, -1.9131,  ..., -0.2749, -0.7451,  0.5625]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 00:59:20 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The offspring of a muskrat is referred to as a kit
The offspring of a monkey is referred to as a infant
The offspring of a horse is referred to as a foal
The offspring of a chimpanzee is referred to as a baby
The offspring of a fly is referred to as a grub
The offspring of a beetle is referred to as a larva
The offspring of a bear is referred to as a cub
The offspring of a cat is referred to as a
2024-07-31 00:59:20 root INFO     [order_1_approx] starting weight calculation for The offspring of a horse is referred to as a foal
The offspring of a bear is referred to as a cub
The offspring of a fly is referred to as a grub
The offspring of a monkey is referred to as a infant
The offspring of a cat is referred to as a kitten
The offspring of a beetle is referred to as a larva
The offspring of a muskrat is referred to as a kit
The offspring of a chimpanzee is referred to as a
2024-07-31 00:59:20 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 01:01:24 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3706,  0.2357,  0.1254,  ..., -0.4795, -0.9204, -0.1332],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.9648, -4.4219, -0.8384,  ...,  0.1143, -4.7109,  2.8125],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 7.7744e-03,  5.1403e-04, -2.4962e-04,  ...,  2.5654e-04,
          6.1464e-04, -1.7147e-03],
        [-2.9373e-03,  4.7226e-03,  4.3201e-04,  ..., -2.0542e-03,
          2.8076e-03, -4.9515e-03],
        [-1.2531e-03, -4.8876e-05,  7.0686e-03,  ...,  2.1172e-04,
          1.3962e-03, -1.3704e-03],
        ...,
        [ 1.1015e-04, -1.2045e-03, -5.9748e-04,  ...,  5.2185e-03,
          1.4420e-03, -4.2963e-04],
        [ 1.5402e-03,  1.3866e-03,  8.9455e-04,  ...,  1.6336e-03,
          3.6812e-03,  5.2071e-04],
        [-2.6989e-03,  1.3981e-03, -1.0777e-03,  ..., -4.7150e-03,
         -3.1757e-04,  4.4327e-03]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.9648, -4.3945, -0.8242,  ...,  0.1322, -4.7031,  2.8281]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 01:01:25 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The offspring of a horse is referred to as a foal
The offspring of a bear is referred to as a cub
The offspring of a fly is referred to as a grub
The offspring of a monkey is referred to as a infant
The offspring of a cat is referred to as a kitten
The offspring of a beetle is referred to as a larva
The offspring of a muskrat is referred to as a kit
The offspring of a chimpanzee is referred to as a
2024-07-31 01:01:25 root INFO     [order_1_approx] starting weight calculation for The offspring of a bear is referred to as a cub
The offspring of a horse is referred to as a foal
The offspring of a fly is referred to as a grub
The offspring of a cat is referred to as a kitten
The offspring of a beetle is referred to as a larva
The offspring of a monkey is referred to as a infant
The offspring of a chimpanzee is referred to as a baby
The offspring of a muskrat is referred to as a
2024-07-31 01:01:25 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 01:03:32 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4790, -0.1780,  0.2629,  ..., -0.7305, -1.0615,  0.3779],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.1094, -1.0615, -1.1602,  ..., -0.6484, -1.6514,  1.9033],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0440, -0.0076,  0.0011,  ...,  0.0085,  0.0036, -0.0092],
        [ 0.0195,  0.0188,  0.0069,  ...,  0.0151,  0.0039, -0.0120],
        [ 0.0067,  0.0181,  0.0287,  ...,  0.0128, -0.0103, -0.0031],
        ...,
        [ 0.0055,  0.0040,  0.0069,  ...,  0.0342,  0.0090,  0.0040],
        [ 0.0048, -0.0001,  0.0110,  ...,  0.0135,  0.0094,  0.0037],
        [ 0.0009,  0.0070,  0.0065,  ...,  0.0012, -0.0014,  0.0199]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.9824, -0.6851, -1.1611,  ..., -0.5425, -2.2344,  2.2207]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 01:03:33 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The offspring of a bear is referred to as a cub
The offspring of a horse is referred to as a foal
The offspring of a fly is referred to as a grub
The offspring of a cat is referred to as a kitten
The offspring of a beetle is referred to as a larva
The offspring of a monkey is referred to as a infant
The offspring of a chimpanzee is referred to as a baby
The offspring of a muskrat is referred to as a
2024-07-31 01:03:33 root INFO     [order_1_approx] starting weight calculation for The offspring of a cat is referred to as a kitten
The offspring of a chimpanzee is referred to as a baby
The offspring of a fly is referred to as a grub
The offspring of a monkey is referred to as a infant
The offspring of a beetle is referred to as a larva
The offspring of a muskrat is referred to as a kit
The offspring of a horse is referred to as a foal
The offspring of a bear is referred to as a
2024-07-31 01:03:33 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 01:05:37 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.6367, -0.0289,  0.5186,  ..., -0.0147, -0.6802,  0.3022],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.9980, -4.9492, -1.8652,  ...,  0.3540, -1.7002,  1.7490],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 4.3213e-02, -1.2230e-02,  1.2589e-03,  ...,  8.7128e-03,
          2.4948e-03,  3.0899e-03],
        [-9.3746e-04,  3.3722e-02,  9.6512e-03,  ...,  7.7057e-04,
         -5.8365e-03, -1.9974e-02],
        [-7.2021e-03,  8.4839e-03,  3.6499e-02,  ...,  8.0948e-03,
          1.1139e-02, -1.6861e-02],
        ...,
        [ 2.4796e-05,  1.0853e-03,  4.0817e-03,  ...,  4.7150e-02,
          1.7059e-02,  2.3022e-03],
        [ 1.5726e-03,  3.2616e-03,  1.6006e-02,  ..., -8.0872e-04,
          2.8717e-02, -5.8327e-03],
        [-1.1986e-02, -1.4206e-02,  1.1292e-03,  ..., -1.5335e-02,
         -4.6349e-03,  2.7618e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.3496, -4.6523, -1.3555,  ...,  0.5005, -1.8555,  1.8584]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 01:05:38 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The offspring of a cat is referred to as a kitten
The offspring of a chimpanzee is referred to as a baby
The offspring of a fly is referred to as a grub
The offspring of a monkey is referred to as a infant
The offspring of a beetle is referred to as a larva
The offspring of a muskrat is referred to as a kit
The offspring of a horse is referred to as a foal
The offspring of a bear is referred to as a
2024-07-31 01:05:38 root INFO     total operator prediction time: 1010.6679081916809 seconds
2024-07-31 01:05:38 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on animal - sound
2024-07-31 01:05:38 root INFO     building operator animal - sound
2024-07-31 01:05:38 root INFO     [order_1_approx] starting weight calculation for The sound that a hyena makes is called a laugh
The sound that a snake makes is called a hiss
The sound that a raven makes is called a caw
The sound that a mallard makes is called a quack
The sound that a seal makes is called a bark
The sound that a leopard makes is called a growl
The sound that a pig makes is called a oink
The sound that a songbird makes is called a
2024-07-31 01:05:38 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 01:07:38 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0453,  0.1151,  0.2866,  ..., -0.1190, -0.1990, -0.0295],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.1836, -3.6602,  2.6465,  ...,  0.2021, -0.6406, -1.3047],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0368,  0.0089, -0.0079,  ..., -0.0047, -0.0083,  0.0190],
        [ 0.0017,  0.0410, -0.0003,  ...,  0.0157,  0.0060, -0.0177],
        [ 0.0016,  0.0196,  0.0334,  ..., -0.0028,  0.0061,  0.0056],
        ...,
        [-0.0047,  0.0065,  0.0093,  ...,  0.0453, -0.0023, -0.0066],
        [-0.0138,  0.0082,  0.0006,  ..., -0.0007,  0.0278,  0.0012],
        [-0.0137, -0.0122, -0.0025,  ..., -0.0193, -0.0004,  0.0371]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.1006, -3.6348,  2.8008,  ...,  0.0966, -0.9375, -1.3643]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 01:07:39 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The sound that a hyena makes is called a laugh
The sound that a snake makes is called a hiss
The sound that a raven makes is called a caw
The sound that a mallard makes is called a quack
The sound that a seal makes is called a bark
The sound that a leopard makes is called a growl
The sound that a pig makes is called a oink
The sound that a songbird makes is called a
2024-07-31 01:07:39 root INFO     [order_1_approx] starting weight calculation for The sound that a leopard makes is called a growl
The sound that a mallard makes is called a quack
The sound that a raven makes is called a caw
The sound that a songbird makes is called a chirrup
The sound that a seal makes is called a bark
The sound that a hyena makes is called a laugh
The sound that a snake makes is called a hiss
The sound that a pig makes is called a
2024-07-31 01:07:39 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 01:09:40 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2834, -0.0357,  0.2671,  ..., -0.1584, -0.3601, -0.1479],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.5469, -1.3691,  3.3047,  ..., -1.8594,  0.4277,  2.0781],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0578, -0.0106,  0.0005,  ..., -0.0176, -0.0040, -0.0104],
        [ 0.0093,  0.0257, -0.0027,  ..., -0.0177, -0.0037, -0.0155],
        [ 0.0295,  0.0108,  0.0571,  ..., -0.0217, -0.0127, -0.0125],
        ...,
        [ 0.0186, -0.0117,  0.0145,  ...,  0.0308, -0.0254, -0.0039],
        [-0.0083,  0.0145,  0.0052,  ...,  0.0079,  0.0408,  0.0030],
        [ 0.0156, -0.0127,  0.0053,  ..., -0.0221,  0.0010,  0.0202]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.8926, -1.1299,  3.1133,  ..., -2.2227,  0.4460,  1.8096]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 01:09:41 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The sound that a leopard makes is called a growl
The sound that a mallard makes is called a quack
The sound that a raven makes is called a caw
The sound that a songbird makes is called a chirrup
The sound that a seal makes is called a bark
The sound that a hyena makes is called a laugh
The sound that a snake makes is called a hiss
The sound that a pig makes is called a
2024-07-31 01:09:41 root INFO     [order_1_approx] starting weight calculation for The sound that a songbird makes is called a chirrup
The sound that a seal makes is called a bark
The sound that a hyena makes is called a laugh
The sound that a leopard makes is called a growl
The sound that a snake makes is called a hiss
The sound that a pig makes is called a oink
The sound that a mallard makes is called a quack
The sound that a raven makes is called a
2024-07-31 01:09:41 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 01:11:45 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1137, -0.1735,  0.4556,  ...,  0.0718, -0.3530, -0.0042],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.1836, -3.3672,  0.6631,  ..., -1.4648,  0.9229,  1.9404],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 4.6082e-02, -2.0599e-03, -7.1526e-06,  ..., -1.5106e-02,
         -2.1973e-02, -5.5885e-03],
        [-1.2344e-02,  2.6566e-02,  7.0305e-03,  ...,  3.0823e-02,
          7.1030e-03, -3.7445e-02],
        [ 4.7150e-03, -1.1108e-02,  4.5532e-02,  ..., -6.0349e-03,
         -8.1100e-03, -2.1774e-02],
        ...,
        [ 1.2367e-02, -9.8801e-03,  9.3307e-03,  ...,  5.3558e-02,
          8.7738e-03, -9.4147e-03],
        [-4.2694e-02, -9.5215e-03, -1.0033e-02,  ..., -4.2191e-03,
          3.3997e-02, -9.4452e-03],
        [ 8.3466e-03, -7.4539e-03,  3.5992e-03,  ..., -8.9264e-03,
         -2.1240e-02,  4.1412e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.9844, -3.2578,  0.6318,  ..., -1.8301,  0.2119,  1.7422]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 01:11:46 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The sound that a songbird makes is called a chirrup
The sound that a seal makes is called a bark
The sound that a hyena makes is called a laugh
The sound that a leopard makes is called a growl
The sound that a snake makes is called a hiss
The sound that a pig makes is called a oink
The sound that a mallard makes is called a quack
The sound that a raven makes is called a
2024-07-31 01:11:47 root INFO     [order_1_approx] starting weight calculation for The sound that a mallard makes is called a quack
The sound that a seal makes is called a bark
The sound that a leopard makes is called a growl
The sound that a raven makes is called a caw
The sound that a snake makes is called a hiss
The sound that a songbird makes is called a chirrup
The sound that a pig makes is called a oink
The sound that a hyena makes is called a
2024-07-31 01:11:47 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 01:13:54 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2274, -0.1028,  0.9087,  ...,  0.2634, -0.4050,  0.0830],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.3992, -4.5820,  1.2959,  ..., -0.9092, -0.1416, -0.2363],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0728,  0.0037,  0.0148,  ...,  0.0035, -0.0064,  0.0103],
        [-0.0139,  0.0291, -0.0139,  ..., -0.0081,  0.0072, -0.0110],
        [ 0.0403,  0.0221,  0.0523,  ..., -0.0751, -0.0173, -0.0104],
        ...,
        [ 0.0176,  0.0065,  0.0086,  ...,  0.0431,  0.0076,  0.0120],
        [-0.0128, -0.0035, -0.0024,  ...,  0.0087,  0.0546, -0.0041],
        [-0.0099, -0.0301, -0.0271,  ..., -0.0136, -0.0135,  0.0322]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.3132, -4.1016,  1.2461,  ..., -0.7534, -0.4653, -0.5596]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 01:13:55 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The sound that a mallard makes is called a quack
The sound that a seal makes is called a bark
The sound that a leopard makes is called a growl
The sound that a raven makes is called a caw
The sound that a snake makes is called a hiss
The sound that a songbird makes is called a chirrup
The sound that a pig makes is called a oink
The sound that a hyena makes is called a
2024-07-31 01:13:55 root INFO     [order_1_approx] starting weight calculation for The sound that a mallard makes is called a quack
The sound that a songbird makes is called a chirrup
The sound that a hyena makes is called a laugh
The sound that a seal makes is called a bark
The sound that a snake makes is called a hiss
The sound that a pig makes is called a oink
The sound that a raven makes is called a caw
The sound that a leopard makes is called a
2024-07-31 01:13:56 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 01:16:03 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0776, -0.1707,  0.2832,  ...,  0.3394, -0.2664,  0.2827],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.7549, -4.7070, -2.6367,  ..., -2.1602, -0.2520,  0.9766],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 2.3102e-02,  2.9182e-03, -3.3617e-04,  ..., -2.8477e-03,
         -7.0610e-03,  6.3629e-03],
        [-2.4223e-03,  1.2711e-02,  3.0518e-05,  ..., -4.0741e-03,
          1.2672e-02, -9.6664e-03],
        [ 5.6000e-03,  2.2259e-03,  1.2009e-02,  ..., -1.5373e-02,
          9.8114e-03,  9.7351e-03],
        ...,
        [ 1.0521e-02,  2.2774e-03,  4.9973e-03,  ...,  2.3468e-02,
          4.1580e-03, -6.9084e-03],
        [-3.9253e-03, -9.6893e-04, -1.0323e-02,  ..., -6.9199e-03,
          2.3468e-02,  5.5542e-03],
        [-7.5302e-03, -8.2550e-03, -9.8267e-03,  ..., -7.3357e-03,
          1.7996e-03,  6.2714e-03]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.5977, -4.5391, -2.5254,  ..., -2.0703, -0.3574,  0.9604]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 01:16:04 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The sound that a mallard makes is called a quack
The sound that a songbird makes is called a chirrup
The sound that a hyena makes is called a laugh
The sound that a seal makes is called a bark
The sound that a snake makes is called a hiss
The sound that a pig makes is called a oink
The sound that a raven makes is called a caw
The sound that a leopard makes is called a
2024-07-31 01:16:04 root INFO     [order_1_approx] starting weight calculation for The sound that a hyena makes is called a laugh
The sound that a leopard makes is called a growl
The sound that a raven makes is called a caw
The sound that a pig makes is called a oink
The sound that a seal makes is called a bark
The sound that a songbird makes is called a chirrup
The sound that a snake makes is called a hiss
The sound that a mallard makes is called a
2024-07-31 01:16:04 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 01:18:09 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0157, -0.0573, -0.0717,  ...,  0.0748, -0.6260,  0.0451],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.2925, -6.0938,  1.4199,  ..., -0.0078, -4.3281,  0.6719],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0247,  0.0093, -0.0065,  ...,  0.0090, -0.0045, -0.0002],
        [ 0.0127,  0.0292,  0.0161,  ...,  0.0223, -0.0003, -0.0093],
        [ 0.0064,  0.0108,  0.0427,  ...,  0.0001, -0.0280, -0.0126],
        ...,
        [-0.0041,  0.0092,  0.0142,  ...,  0.0628, -0.0024,  0.0095],
        [ 0.0037,  0.0062, -0.0181,  ..., -0.0128,  0.0472, -0.0043],
        [-0.0163, -0.0137,  0.0097,  ..., -0.0191, -0.0261,  0.0261]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.3992, -5.7148,  1.2676,  ..., -0.3328, -4.0078,  0.4985]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 01:18:10 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The sound that a hyena makes is called a laugh
The sound that a leopard makes is called a growl
The sound that a raven makes is called a caw
The sound that a pig makes is called a oink
The sound that a seal makes is called a bark
The sound that a songbird makes is called a chirrup
The sound that a snake makes is called a hiss
The sound that a mallard makes is called a
2024-07-31 01:18:10 root INFO     [order_1_approx] starting weight calculation for The sound that a snake makes is called a hiss
The sound that a raven makes is called a caw
The sound that a mallard makes is called a quack
The sound that a hyena makes is called a laugh
The sound that a leopard makes is called a growl
The sound that a songbird makes is called a chirrup
The sound that a pig makes is called a oink
The sound that a seal makes is called a
2024-07-31 01:18:10 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 01:20:11 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.6665, -0.3586,  0.3706,  ..., -0.0217, -0.8276,  0.2100],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.0625, -1.0312, -0.8833,  ..., -0.7090,  0.0684,  1.3555],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0640,  0.0034, -0.0127,  ..., -0.0097, -0.0168, -0.0201],
        [ 0.0171,  0.0557, -0.0151,  ..., -0.0043, -0.0151, -0.0414],
        [ 0.0332,  0.0123,  0.0457,  ..., -0.0159, -0.0161, -0.0240],
        ...,
        [ 0.0061, -0.0023,  0.0158,  ...,  0.0427, -0.0040, -0.0146],
        [-0.0211, -0.0026, -0.0149,  ...,  0.0011,  0.0358,  0.0079],
        [-0.0147, -0.0099, -0.0179,  ...,  0.0047, -0.0001,  0.0375]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.6245, -1.6758, -0.8877,  ..., -1.1621,  0.1288,  1.3086]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 01:20:12 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The sound that a snake makes is called a hiss
The sound that a raven makes is called a caw
The sound that a mallard makes is called a quack
The sound that a hyena makes is called a laugh
The sound that a leopard makes is called a growl
The sound that a songbird makes is called a chirrup
The sound that a pig makes is called a oink
The sound that a seal makes is called a
2024-07-31 01:20:12 root INFO     [order_1_approx] starting weight calculation for The sound that a pig makes is called a oink
The sound that a raven makes is called a caw
The sound that a seal makes is called a bark
The sound that a mallard makes is called a quack
The sound that a hyena makes is called a laugh
The sound that a songbird makes is called a chirrup
The sound that a leopard makes is called a growl
The sound that a snake makes is called a
2024-07-31 01:20:12 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 01:22:15 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2629,  0.1084,  0.3796,  ..., -0.2122,  0.3892, -0.1086],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.7310, -0.9678,  1.9531,  ..., -0.0541, -0.1924,  2.2324],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0318,  0.0167,  0.0060,  ..., -0.0093, -0.0093,  0.0173],
        [-0.0023,  0.0381, -0.0026,  ...,  0.0013, -0.0162, -0.0071],
        [ 0.0251,  0.0047,  0.0522,  ..., -0.0150, -0.0156, -0.0092],
        ...,
        [ 0.0247,  0.0211,  0.0073,  ...,  0.0497, -0.0250, -0.0149],
        [-0.0150, -0.0035, -0.0075,  ...,  0.0017,  0.0261, -0.0129],
        [-0.0102, -0.0068, -0.0235,  ..., -0.0104,  0.0003,  0.0508]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.0537, -1.0947,  1.6846,  ..., -0.3804, -0.1794,  2.4863]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 01:22:16 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The sound that a pig makes is called a oink
The sound that a raven makes is called a caw
The sound that a seal makes is called a bark
The sound that a mallard makes is called a quack
The sound that a hyena makes is called a laugh
The sound that a songbird makes is called a chirrup
The sound that a leopard makes is called a growl
The sound that a snake makes is called a
2024-07-31 01:22:16 root INFO     total operator prediction time: 998.0329413414001 seconds
2024-07-31 01:22:16 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on things - color
2024-07-31 01:22:16 root INFO     building operator things - color
2024-07-31 01:22:16 root INFO     [order_1_approx] starting weight calculation for The cucumber is colored green
The ruby is colored red
The paper is colored white
The radish is colored red
The cauliflower is colored white
The apple is colored red
The yoghurt is colored white
The blood is colored
2024-07-31 01:22:16 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 01:24:17 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0579, -0.4771, -0.2761,  ..., -0.1494, -0.2976, -0.2051],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-2.0625, -9.5781, -2.1465,  ..., -2.6172,  1.2871, -3.0137],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0715, -0.0046,  0.0132,  ...,  0.0045,  0.0114,  0.0186],
        [ 0.0045,  0.0356,  0.0064,  ..., -0.0204,  0.0228, -0.0108],
        [-0.0083, -0.0032,  0.0318,  ...,  0.0039,  0.0029,  0.0018],
        ...,
        [-0.0041, -0.0066,  0.0007,  ...,  0.0386, -0.0077, -0.0065],
        [-0.0075,  0.0077, -0.0044,  ...,  0.0220,  0.0521,  0.0036],
        [-0.0135, -0.0206,  0.0123,  ...,  0.0043, -0.0122,  0.0507]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-2.2246, -9.5391, -2.4297,  ..., -2.4961,  1.3301, -3.0312]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 01:24:18 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The cucumber is colored green
The ruby is colored red
The paper is colored white
The radish is colored red
The cauliflower is colored white
The apple is colored red
The yoghurt is colored white
The blood is colored
2024-07-31 01:24:18 root INFO     [order_1_approx] starting weight calculation for The radish is colored red
The blood is colored red
The paper is colored white
The apple is colored red
The ruby is colored red
The cucumber is colored green
The yoghurt is colored white
The cauliflower is colored
2024-07-31 01:24:18 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 01:26:17 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0375, -0.2571,  0.0011,  ..., -0.1678, -0.7598, -0.2043],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.7129, -5.3984,  0.3584,  ..., -1.3613,  0.1062, -1.2783],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0333,  0.0029,  0.0049,  ..., -0.0044,  0.0077, -0.0044],
        [ 0.0079,  0.0253,  0.0065,  ..., -0.0119,  0.0035, -0.0116],
        [-0.0024, -0.0090,  0.0255,  ...,  0.0109, -0.0007,  0.0019],
        ...,
        [ 0.0072, -0.0020, -0.0030,  ...,  0.0317, -0.0050, -0.0043],
        [ 0.0049,  0.0020, -0.0025,  ...,  0.0127,  0.0319, -0.0014],
        [-0.0051, -0.0025,  0.0063,  ..., -0.0016,  0.0012,  0.0285]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.7544, -5.2617,  0.3013,  ..., -1.2285,  0.2334, -1.1650]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 01:26:18 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The radish is colored red
The blood is colored red
The paper is colored white
The apple is colored red
The ruby is colored red
The cucumber is colored green
The yoghurt is colored white
The cauliflower is colored
2024-07-31 01:26:18 root INFO     [order_1_approx] starting weight calculation for The yoghurt is colored white
The apple is colored red
The ruby is colored red
The radish is colored red
The blood is colored red
The cucumber is colored green
The cauliflower is colored white
The paper is colored
2024-07-31 01:26:18 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 01:28:14 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.3469, -0.5664, -0.4607,  ...,  0.1295, -0.2197,  0.1892],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-2.4648, -3.9180,  1.4658,  ..., -1.0332, -2.5020,  1.8887],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 5.1453e-02,  4.6959e-03,  2.0523e-03,  ..., -4.1351e-03,
          2.3022e-03,  5.6992e-03],
        [ 1.4282e-02,  4.6997e-02,  5.8708e-03,  ..., -3.0098e-03,
          1.1307e-02, -9.1095e-03],
        [ 3.7804e-03,  4.3869e-03,  2.3315e-02,  ...,  1.1597e-02,
          1.1320e-03,  4.4479e-03],
        ...,
        [-1.3748e-02,  7.0095e-05, -5.9700e-04,  ...,  2.9663e-02,
         -6.1464e-04, -3.2196e-03],
        [-7.7667e-03,  4.1351e-03,  4.2877e-03,  ...,  8.3847e-03,
          3.7415e-02,  1.9493e-03],
        [ 5.3787e-03,  2.9335e-03,  6.5155e-03,  ...,  1.5579e-02,
         -1.7807e-02,  3.7750e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-2.4609, -3.9082,  1.2539,  ..., -0.7886, -2.1797,  1.7568]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 01:28:15 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The yoghurt is colored white
The apple is colored red
The ruby is colored red
The radish is colored red
The blood is colored red
The cucumber is colored green
The cauliflower is colored white
The paper is colored
2024-07-31 01:28:15 root INFO     [order_1_approx] starting weight calculation for The paper is colored white
The ruby is colored red
The radish is colored red
The cucumber is colored green
The cauliflower is colored white
The apple is colored red
The blood is colored red
The yoghurt is colored
2024-07-31 01:28:15 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 01:30:14 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2032, -0.3687,  0.3411,  ...,  0.5161, -0.8086, -0.2693],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.0151, -4.7969,  0.8970,  ..., -2.9062, -1.5527, -1.8105],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0509,  0.0093,  0.0067,  ...,  0.0008, -0.0030,  0.0033],
        [ 0.0068,  0.0556,  0.0111,  ...,  0.0021,  0.0100, -0.0124],
        [-0.0047, -0.0014,  0.0359,  ...,  0.0188,  0.0132,  0.0011],
        ...,
        [ 0.0081, -0.0042, -0.0061,  ...,  0.0509,  0.0028, -0.0051],
        [-0.0097, -0.0105,  0.0089,  ...,  0.0248,  0.0456, -0.0113],
        [-0.0023, -0.0035, -0.0075,  ..., -0.0028, -0.0012,  0.0536]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.0909, -5.1328,  0.8779,  ..., -2.9102, -1.3945, -1.7285]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 01:30:15 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The paper is colored white
The ruby is colored red
The radish is colored red
The cucumber is colored green
The cauliflower is colored white
The apple is colored red
The blood is colored red
The yoghurt is colored
2024-07-31 01:30:15 root INFO     [order_1_approx] starting weight calculation for The radish is colored red
The cauliflower is colored white
The yoghurt is colored white
The apple is colored red
The paper is colored white
The blood is colored red
The cucumber is colored green
The ruby is colored
2024-07-31 01:30:15 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 01:32:21 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1879, -0.1813, -0.2874,  ..., -0.3340, -0.6230,  0.1862],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-2.4961, -4.5820, -0.4219,  ..., -1.4072, -0.6504,  1.4258],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0785, -0.0122, -0.0032,  ..., -0.0027,  0.0098,  0.0045],
        [ 0.0183,  0.0986,  0.0311,  ...,  0.0082,  0.0050, -0.0108],
        [ 0.0225, -0.0111,  0.0493,  ..., -0.0102, -0.0065,  0.0192],
        ...,
        [-0.0027, -0.0115,  0.0334,  ...,  0.0775,  0.0064, -0.0154],
        [-0.0075, -0.0029,  0.0070,  ...,  0.0481,  0.0577,  0.0053],
        [-0.0090, -0.0238,  0.0077,  ..., -0.0025, -0.0226,  0.0594]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-2.5176, -5.1406, -0.4438,  ..., -1.2012, -0.3469,  1.2607]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 01:32:22 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The radish is colored red
The cauliflower is colored white
The yoghurt is colored white
The apple is colored red
The paper is colored white
The blood is colored red
The cucumber is colored green
The ruby is colored
2024-07-31 01:32:22 root INFO     [order_1_approx] starting weight calculation for The cucumber is colored green
The blood is colored red
The radish is colored red
The ruby is colored red
The cauliflower is colored white
The paper is colored white
The yoghurt is colored white
The apple is colored
2024-07-31 01:32:23 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 01:34:24 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2212, -0.7207, -0.3123,  ...,  0.3013, -0.4321, -0.5825],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-2.3320, -8.3516, -1.5439,  ..., -2.4062, -1.2998, -5.6914],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0565,  0.0027, -0.0005,  ..., -0.0139, -0.0021,  0.0009],
        [ 0.0047,  0.0390,  0.0260,  ..., -0.0256,  0.0144, -0.0287],
        [-0.0024, -0.0018,  0.0421,  ...,  0.0193, -0.0051, -0.0096],
        ...,
        [-0.0055, -0.0151,  0.0106,  ...,  0.0567, -0.0126,  0.0035],
        [ 0.0022,  0.0119, -0.0073,  ...,  0.0390,  0.0576, -0.0051],
        [-0.0211, -0.0275,  0.0093,  ..., -0.0278, -0.0182,  0.0567]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-2.0527, -7.7461, -1.9053,  ..., -2.3184, -1.3750, -5.2109]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 01:34:25 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The cucumber is colored green
The blood is colored red
The radish is colored red
The ruby is colored red
The cauliflower is colored white
The paper is colored white
The yoghurt is colored white
The apple is colored
2024-07-31 01:34:25 root INFO     [order_1_approx] starting weight calculation for The radish is colored red
The cauliflower is colored white
The paper is colored white
The yoghurt is colored white
The blood is colored red
The apple is colored red
The ruby is colored red
The cucumber is colored
2024-07-31 01:34:25 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 01:36:33 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2446, -0.4216,  0.2800,  ..., -0.0845, -0.6245, -0.4182],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.2500, -2.3047, -0.0200,  ..., -1.0605, -1.6982, -2.5195],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0623,  0.0075, -0.0038,  ...,  0.0108,  0.0104, -0.0040],
        [ 0.0265,  0.0307,  0.0074,  ...,  0.0035,  0.0165, -0.0130],
        [-0.0068, -0.0057,  0.0362,  ..., -0.0026,  0.0013, -0.0088],
        ...,
        [ 0.0011, -0.0125, -0.0059,  ...,  0.0549, -0.0012, -0.0069],
        [ 0.0076,  0.0074, -0.0065,  ...,  0.0213,  0.0397, -0.0116],
        [-0.0042,  0.0004,  0.0083,  ..., -0.0048, -0.0071,  0.0455]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.0376, -2.2871, -0.2452,  ..., -0.9307, -1.4814, -2.4414]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 01:36:34 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The radish is colored red
The cauliflower is colored white
The paper is colored white
The yoghurt is colored white
The blood is colored red
The apple is colored red
The ruby is colored red
The cucumber is colored
2024-07-31 01:36:34 root INFO     [order_1_approx] starting weight calculation for The cauliflower is colored white
The ruby is colored red
The blood is colored red
The yoghurt is colored white
The cucumber is colored green
The apple is colored red
The paper is colored white
The radish is colored
2024-07-31 01:36:34 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 01:38:39 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.6021, -0.4136,  0.1370,  ..., -0.1462, -0.9565, -0.5220],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.0518, -5.4375,  0.1096,  ..., -2.4922, -0.1792, -2.6797],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0726,  0.0116,  0.0047,  ..., -0.0086,  0.0088, -0.0070],
        [ 0.0261,  0.0523,  0.0112,  ..., -0.0059,  0.0066, -0.0300],
        [ 0.0006, -0.0141,  0.0629,  ...,  0.0154, -0.0058,  0.0051],
        ...,
        [ 0.0118, -0.0188,  0.0041,  ...,  0.0669, -0.0074, -0.0015],
        [ 0.0088,  0.0099, -0.0060,  ...,  0.0284,  0.0621, -0.0029],
        [-0.0183, -0.0169,  0.0088,  ..., -0.0016, -0.0080,  0.0562]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.3428, -5.3594,  0.1083,  ..., -2.4902, -0.3892, -2.4922]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 01:38:40 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The cauliflower is colored white
The ruby is colored red
The blood is colored red
The yoghurt is colored white
The cucumber is colored green
The apple is colored red
The paper is colored white
The radish is colored
2024-07-31 01:38:40 root INFO     total operator prediction time: 983.8705196380615 seconds
2024-07-31 01:38:40 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on country - capital
2024-07-31 01:38:40 root INFO     building operator country - capital
2024-07-31 01:38:40 root INFO     [order_1_approx] starting weight calculation for The country with nairobi as its capital is known as kenya
The country with cairo as its capital is known as egypt
The country with brussels as its capital is known as belgium
The country with tbilisi as its capital is known as georgia
The country with amman as its capital is known as jordan
The country with bucharest as its capital is known as romania
The country with beijing as its capital is known as china
The country with stockholm as its capital is known as
2024-07-31 01:38:40 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 01:40:46 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3860, -0.2482, -0.4260,  ...,  0.2262,  0.3484,  0.2583],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.4102, -6.0977, -1.7539,  ..., -1.3994, -1.7031, -3.1055],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0257, -0.0003,  0.0110,  ..., -0.0021, -0.0051,  0.0068],
        [ 0.0018, -0.0012,  0.0089,  ...,  0.0110, -0.0050, -0.0245],
        [-0.0076,  0.0022,  0.0347,  ...,  0.0090,  0.0033, -0.0012],
        ...,
        [ 0.0035, -0.0007,  0.0034,  ...,  0.0442,  0.0168, -0.0046],
        [ 0.0013,  0.0066, -0.0224,  ...,  0.0084,  0.0141,  0.0050],
        [-0.0196, -0.0090, -0.0150,  ...,  0.0043, -0.0103,  0.0261]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.3008, -6.0117, -1.7627,  ..., -1.3252, -1.2969, -2.8848]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 01:40:47 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country with nairobi as its capital is known as kenya
The country with cairo as its capital is known as egypt
The country with brussels as its capital is known as belgium
The country with tbilisi as its capital is known as georgia
The country with amman as its capital is known as jordan
The country with bucharest as its capital is known as romania
The country with beijing as its capital is known as china
The country with stockholm as its capital is known as
2024-07-31 01:40:47 root INFO     [order_1_approx] starting weight calculation for The country with cairo as its capital is known as egypt
The country with beijing as its capital is known as china
The country with bucharest as its capital is known as romania
The country with nairobi as its capital is known as kenya
The country with brussels as its capital is known as belgium
The country with stockholm as its capital is known as sweden
The country with amman as its capital is known as jordan
The country with tbilisi as its capital is known as
2024-07-31 01:40:47 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 01:42:54 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3521, -0.0636, -0.3193,  ...,  0.0034, -0.1553,  0.1882],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.8535, -5.5000, -0.7100,  ..., -2.7949,  0.1465, -2.9258],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0183, -0.0042,  0.0030,  ...,  0.0049, -0.0002,  0.0042],
        [ 0.0074,  0.0163,  0.0012,  ...,  0.0008,  0.0097, -0.0114],
        [-0.0023,  0.0017,  0.0152,  ...,  0.0154, -0.0046, -0.0011],
        ...,
        [ 0.0018,  0.0014, -0.0077,  ...,  0.0307, -0.0022,  0.0031],
        [-0.0017,  0.0018, -0.0130,  ...,  0.0033,  0.0134,  0.0021],
        [-0.0107, -0.0137, -0.0084,  ...,  0.0047,  0.0102,  0.0205]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.6719, -5.4961, -0.7656,  ..., -2.7891, -0.0122, -2.9531]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 01:42:55 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country with cairo as its capital is known as egypt
The country with beijing as its capital is known as china
The country with bucharest as its capital is known as romania
The country with nairobi as its capital is known as kenya
The country with brussels as its capital is known as belgium
The country with stockholm as its capital is known as sweden
The country with amman as its capital is known as jordan
The country with tbilisi as its capital is known as
2024-07-31 01:42:56 root INFO     [order_1_approx] starting weight calculation for The country with tbilisi as its capital is known as georgia
The country with bucharest as its capital is known as romania
The country with stockholm as its capital is known as sweden
The country with beijing as its capital is known as china
The country with amman as its capital is known as jordan
The country with cairo as its capital is known as egypt
The country with nairobi as its capital is known as kenya
The country with brussels as its capital is known as
2024-07-31 01:42:56 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 01:44:59 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.8857, -0.3521, -0.3752,  ...,  0.2808,  0.1611,  0.2284],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.7656, -6.4531, -2.0840,  ..., -0.5747,  0.8628, -4.5078],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0073,  0.0008, -0.0012,  ...,  0.0015, -0.0003,  0.0005],
        [ 0.0074,  0.0019,  0.0055,  ..., -0.0042, -0.0017, -0.0002],
        [ 0.0045,  0.0001,  0.0121,  ...,  0.0078,  0.0064,  0.0057],
        ...,
        [-0.0017, -0.0050, -0.0057,  ...,  0.0145,  0.0082, -0.0010],
        [ 0.0021, -0.0054, -0.0044,  ...,  0.0048,  0.0050, -0.0016],
        [-0.0075, -0.0067, -0.0006,  ..., -0.0036, -0.0058,  0.0173]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.7090, -6.3984, -2.0352,  ..., -0.5737,  0.7441, -4.3320]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 01:45:00 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country with tbilisi as its capital is known as georgia
The country with bucharest as its capital is known as romania
The country with stockholm as its capital is known as sweden
The country with beijing as its capital is known as china
The country with amman as its capital is known as jordan
The country with cairo as its capital is known as egypt
The country with nairobi as its capital is known as kenya
The country with brussels as its capital is known as
2024-07-31 01:45:01 root INFO     [order_1_approx] starting weight calculation for The country with stockholm as its capital is known as sweden
The country with bucharest as its capital is known as romania
The country with amman as its capital is known as jordan
The country with tbilisi as its capital is known as georgia
The country with brussels as its capital is known as belgium
The country with beijing as its capital is known as china
The country with cairo as its capital is known as egypt
The country with nairobi as its capital is known as
2024-07-31 01:45:01 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 01:47:06 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1334, -0.2363, -0.0536,  ...,  0.2172, -0.3413, -0.2896],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.4258, -3.8340, -1.9590,  ...,  0.1512, -0.8359, -3.0117],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 2.1225e-02, -9.0027e-03,  6.1684e-03,  ...,  7.0724e-03,
         -3.0460e-03,  6.8359e-03],
        [ 5.2338e-03,  2.5940e-02, -3.8357e-03,  ..., -1.9798e-03,
          8.7585e-03, -3.8300e-03],
        [-8.1863e-03,  3.5057e-03,  3.6926e-02,  ...,  1.8921e-02,
         -1.6184e-03, -5.7220e-06],
        ...,
        [ 6.2866e-03,  5.0583e-03,  2.3232e-03,  ...,  3.2257e-02,
          1.5221e-03,  3.8261e-03],
        [-1.2024e-02,  8.4915e-03, -8.4352e-04,  ..., -5.2185e-03,
          7.0076e-03,  2.1667e-03],
        [-1.0124e-02, -1.0818e-02, -1.2894e-02,  ...,  1.8940e-03,
          1.0139e-02,  2.8580e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.2500, -3.6621, -2.0977,  ...,  0.0745, -0.6714, -3.3516]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 01:47:07 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country with stockholm as its capital is known as sweden
The country with bucharest as its capital is known as romania
The country with amman as its capital is known as jordan
The country with tbilisi as its capital is known as georgia
The country with brussels as its capital is known as belgium
The country with beijing as its capital is known as china
The country with cairo as its capital is known as egypt
The country with nairobi as its capital is known as
2024-07-31 01:47:07 root INFO     [order_1_approx] starting weight calculation for The country with bucharest as its capital is known as romania
The country with stockholm as its capital is known as sweden
The country with brussels as its capital is known as belgium
The country with cairo as its capital is known as egypt
The country with amman as its capital is known as jordan
The country with tbilisi as its capital is known as georgia
The country with nairobi as its capital is known as kenya
The country with beijing as its capital is known as
2024-07-31 01:47:07 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 01:49:10 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1948, -0.1644, -0.4871,  ...,  0.3020, -0.1371,  0.1331],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.0830, -3.9297,  1.3877,  ...,  0.7197,  2.0996, -2.3086],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 1.2772e-02, -2.5253e-03,  1.9350e-03,  ...,  2.4033e-03,
         -1.1597e-02, -9.1171e-04],
        [ 5.1346e-03,  1.0109e-02,  6.2561e-03,  ...,  1.9073e-04,
          2.3651e-03, -6.6528e-03],
        [-7.8659e-03,  5.3368e-03,  1.9653e-02,  ...,  1.4618e-02,
         -6.3181e-05, -3.5591e-03],
        ...,
        [ 8.7509e-03,  2.6779e-03, -8.4915e-03,  ...,  1.6220e-02,
          2.4967e-03, -3.2730e-03],
        [-8.6975e-03, -1.3218e-03, -4.7874e-03,  ...,  9.9945e-04,
          5.2948e-03, -9.2163e-03],
        [-6.7024e-03, -7.3967e-03, -6.1340e-03,  ...,  4.4861e-03,
          4.1580e-03,  8.1253e-03]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.0576, -3.8730,  1.2930,  ...,  0.7822,  2.1289, -2.3320]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 01:49:11 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country with bucharest as its capital is known as romania
The country with stockholm as its capital is known as sweden
The country with brussels as its capital is known as belgium
The country with cairo as its capital is known as egypt
The country with amman as its capital is known as jordan
The country with tbilisi as its capital is known as georgia
The country with nairobi as its capital is known as kenya
The country with beijing as its capital is known as
2024-07-31 01:49:11 root INFO     [order_1_approx] starting weight calculation for The country with stockholm as its capital is known as sweden
The country with beijing as its capital is known as china
The country with brussels as its capital is known as belgium
The country with tbilisi as its capital is known as georgia
The country with bucharest as its capital is known as romania
The country with amman as its capital is known as jordan
The country with nairobi as its capital is known as kenya
The country with cairo as its capital is known as
2024-07-31 01:49:11 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 01:51:16 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0715, -0.1174, -0.2949,  ...,  0.3794, -0.3330,  0.5088],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.6055, -3.3125,  1.9014,  ..., -0.8779,  0.5068, -1.2109],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 2.6047e-02,  8.4019e-04,  6.3400e-03,  ...,  7.6294e-03,
         -1.1398e-02,  5.8060e-03],
        [ 1.1578e-03,  1.4175e-02,  4.1771e-03,  ..., -7.0419e-03,
          9.0256e-03, -1.4183e-02],
        [ 1.6357e-02,  2.3331e-02,  3.1616e-02,  ...,  2.6398e-02,
         -1.1589e-02, -9.2983e-05],
        ...,
        [ 7.1411e-03,  1.0864e-02, -8.1100e-03,  ...,  3.4210e-02,
         -5.2452e-04, -7.4005e-03],
        [-6.6376e-03, -1.4839e-03, -4.3030e-03,  ..., -7.6447e-03,
          2.2217e-02,  1.4820e-03],
        [-9.8801e-03, -5.0125e-03, -1.6998e-02,  ...,  1.1032e-02,
          1.3046e-03,  2.8778e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.5918, -3.0312,  1.5703,  ..., -0.9189,  0.3838, -1.1826]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 01:51:17 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country with stockholm as its capital is known as sweden
The country with beijing as its capital is known as china
The country with brussels as its capital is known as belgium
The country with tbilisi as its capital is known as georgia
The country with bucharest as its capital is known as romania
The country with amman as its capital is known as jordan
The country with nairobi as its capital is known as kenya
The country with cairo as its capital is known as
2024-07-31 01:51:17 root INFO     [order_1_approx] starting weight calculation for The country with cairo as its capital is known as egypt
The country with nairobi as its capital is known as kenya
The country with tbilisi as its capital is known as georgia
The country with stockholm as its capital is known as sweden
The country with bucharest as its capital is known as romania
The country with beijing as its capital is known as china
The country with brussels as its capital is known as belgium
The country with amman as its capital is known as
2024-07-31 01:51:18 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 01:53:26 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0298, -0.0501, -0.3726,  ...,  0.5078, -0.6089,  0.0232],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.7036, -4.6719,  1.1094,  ..., -0.8745, -0.4414, -2.3066],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0417, -0.0053, -0.0076,  ...,  0.0121,  0.0066, -0.0025],
        [ 0.0018,  0.0312,  0.0200,  ...,  0.0107,  0.0204, -0.0148],
        [-0.0143, -0.0010,  0.0338,  ..., -0.0085, -0.0032, -0.0011],
        ...,
        [ 0.0028,  0.0178, -0.0034,  ...,  0.0528, -0.0057, -0.0094],
        [-0.0047,  0.0217, -0.0102,  ..., -0.0012,  0.0304,  0.0078],
        [-0.0266, -0.0060, -0.0087,  ...,  0.0283,  0.0089,  0.0280]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.9121, -4.4766,  1.0820,  ..., -1.0215, -0.5254, -2.0547]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 01:53:26 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country with cairo as its capital is known as egypt
The country with nairobi as its capital is known as kenya
The country with tbilisi as its capital is known as georgia
The country with stockholm as its capital is known as sweden
The country with bucharest as its capital is known as romania
The country with beijing as its capital is known as china
The country with brussels as its capital is known as belgium
The country with amman as its capital is known as
2024-07-31 01:53:27 root INFO     [order_1_approx] starting weight calculation for The country with tbilisi as its capital is known as georgia
The country with beijing as its capital is known as china
The country with brussels as its capital is known as belgium
The country with stockholm as its capital is known as sweden
The country with amman as its capital is known as jordan
The country with cairo as its capital is known as egypt
The country with nairobi as its capital is known as kenya
The country with bucharest as its capital is known as
2024-07-31 01:53:27 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 01:55:27 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.6118, -0.2581, -0.3291,  ...,  0.1841,  0.2096, -0.1027],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.4014, -6.1250, -1.6475,  ..., -2.4688, -0.3232, -3.5039],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0261, -0.0033,  0.0025,  ...,  0.0027, -0.0094,  0.0076],
        [ 0.0019,  0.0102,  0.0139,  ...,  0.0014,  0.0084, -0.0127],
        [-0.0075,  0.0016,  0.0279,  ...,  0.0101,  0.0080,  0.0012],
        ...,
        [ 0.0096,  0.0035, -0.0135,  ...,  0.0257,  0.0135,  0.0044],
        [-0.0002, -0.0033, -0.0150,  ..., -0.0067,  0.0258, -0.0019],
        [-0.0137, -0.0056, -0.0128,  ...,  0.0085,  0.0130,  0.0213]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.5166, -5.7812, -1.7471,  ..., -2.3730, -0.6123, -3.4141]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 01:55:28 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country with tbilisi as its capital is known as georgia
The country with beijing as its capital is known as china
The country with brussels as its capital is known as belgium
The country with stockholm as its capital is known as sweden
The country with amman as its capital is known as jordan
The country with cairo as its capital is known as egypt
The country with nairobi as its capital is known as kenya
The country with bucharest as its capital is known as
2024-07-31 01:55:28 root INFO     total operator prediction time: 1007.9780950546265 seconds
2024-07-31 01:55:28 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on name - occupation
2024-07-31 01:55:28 root INFO     building operator name - occupation
2024-07-31 01:55:28 root INFO     [order_1_approx] starting weight calculation for kepler was known for their work as a  mathematician
locke was known for their work as a  philosopher
marx was known for their work as a  philosopher
mozart was known for their work as a  composer
strauss was known for their work as a  composer
hegel was known for their work as a  philosopher
stalin was known for their work as a  dictator
wagner was known for their work as a 
2024-07-31 01:55:28 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 01:57:32 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3008,  0.4058,  0.6465,  ..., -0.1146, -0.1658, -0.2227],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.3809, -6.3477,  3.3125,  ..., -2.5430,  0.2145, -1.5439],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 3.3813e-02, -2.2964e-03,  3.6964e-03,  ..., -2.8152e-03,
         -1.4709e-02,  8.5545e-04],
        [-1.7633e-03,  2.2278e-02,  2.9583e-03,  ..., -7.5569e-03,
         -6.9332e-04, -1.7853e-03],
        [ 3.6812e-03,  3.0231e-03,  2.9236e-02,  ...,  1.1978e-03,
         -2.1324e-03,  5.3864e-03],
        ...,
        [ 8.9569e-03,  2.7542e-03,  4.3869e-05,  ...,  3.4424e-02,
         -1.7433e-03, -7.0343e-03],
        [-1.4362e-03,  5.8899e-03,  5.0812e-03,  ..., -2.8973e-03,
          2.1240e-02, -2.5864e-03],
        [-1.0323e-02, -9.8896e-04, -6.0349e-03,  ...,  7.0000e-04,
         -2.5406e-03,  2.7634e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.2324, -6.2188,  3.0898,  ..., -2.5566,  0.2354, -1.4385]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 01:57:33 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for kepler was known for their work as a  mathematician
locke was known for their work as a  philosopher
marx was known for their work as a  philosopher
mozart was known for their work as a  composer
strauss was known for their work as a  composer
hegel was known for their work as a  philosopher
stalin was known for their work as a  dictator
wagner was known for their work as a 
2024-07-31 01:57:33 root INFO     [order_1_approx] starting weight calculation for mozart was known for their work as a  composer
marx was known for their work as a  philosopher
wagner was known for their work as a  composer
strauss was known for their work as a  composer
locke was known for their work as a  philosopher
hegel was known for their work as a  philosopher
kepler was known for their work as a  mathematician
stalin was known for their work as a 
2024-07-31 01:57:33 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 01:59:38 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0956, -0.3765, -0.1660,  ...,  0.5791, -0.1924,  0.4617],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.4336, -5.0586,  3.1211,  ..., -3.0195,  0.8691, -3.3281],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0413,  0.0063,  0.0021,  ...,  0.0083, -0.0079,  0.0135],
        [-0.0008,  0.0428,  0.0085,  ...,  0.0003,  0.0006, -0.0122],
        [ 0.0094, -0.0020,  0.0367,  ...,  0.0012,  0.0048,  0.0152],
        ...,
        [ 0.0087,  0.0054, -0.0049,  ...,  0.0544, -0.0047, -0.0118],
        [-0.0081,  0.0065,  0.0055,  ..., -0.0039,  0.0199,  0.0041],
        [-0.0080,  0.0054, -0.0004,  ..., -0.0045,  0.0026,  0.0315]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.2656, -5.0078,  2.8145,  ..., -3.1562,  0.7983, -3.2676]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 01:59:39 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for mozart was known for their work as a  composer
marx was known for their work as a  philosopher
wagner was known for their work as a  composer
strauss was known for their work as a  composer
locke was known for their work as a  philosopher
hegel was known for their work as a  philosopher
kepler was known for their work as a  mathematician
stalin was known for their work as a 
2024-07-31 01:59:39 root INFO     [order_1_approx] starting weight calculation for kepler was known for their work as a  mathematician
locke was known for their work as a  philosopher
mozart was known for their work as a  composer
stalin was known for their work as a  dictator
marx was known for their work as a  philosopher
hegel was known for their work as a  philosopher
wagner was known for their work as a  composer
strauss was known for their work as a 
2024-07-31 01:59:39 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 02:01:47 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1477, -0.4482,  0.4907,  ..., -0.1847,  0.0191, -0.3347],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.4556, -5.1523,  3.1445,  ..., -3.2812,  0.1890, -3.9688],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0410,  0.0039, -0.0005,  ..., -0.0062, -0.0165,  0.0023],
        [-0.0008,  0.0368,  0.0018,  ..., -0.0036,  0.0002, -0.0125],
        [ 0.0078,  0.0045,  0.0298,  ...,  0.0009, -0.0024,  0.0076],
        ...,
        [ 0.0076,  0.0099, -0.0043,  ...,  0.0487, -0.0009, -0.0025],
        [-0.0059,  0.0040,  0.0054,  ..., -0.0136,  0.0172, -0.0005],
        [-0.0080,  0.0041, -0.0021,  ..., -0.0009,  0.0066,  0.0413]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.3611, -5.0859,  2.9883,  ..., -3.4668,  0.3857, -3.8105]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 02:01:47 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for kepler was known for their work as a  mathematician
locke was known for their work as a  philosopher
mozart was known for their work as a  composer
stalin was known for their work as a  dictator
marx was known for their work as a  philosopher
hegel was known for their work as a  philosopher
wagner was known for their work as a  composer
strauss was known for their work as a 
2024-07-31 02:01:48 root INFO     [order_1_approx] starting weight calculation for stalin was known for their work as a  dictator
locke was known for their work as a  philosopher
wagner was known for their work as a  composer
marx was known for their work as a  philosopher
mozart was known for their work as a  composer
hegel was known for their work as a  philosopher
strauss was known for their work as a  composer
kepler was known for their work as a 
2024-07-31 02:01:48 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 02:03:45 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0563, -0.2291,  0.1584,  ..., -0.2229, -0.0747,  0.5210],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.9004, -5.7031,  1.8457,  ..., -6.7070,  0.1611, -0.5391],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0583, -0.0023,  0.0046,  ..., -0.0153, -0.0127, -0.0031],
        [ 0.0063,  0.0565, -0.0070,  ...,  0.0101,  0.0017, -0.0102],
        [ 0.0058, -0.0003,  0.0617,  ..., -0.0146, -0.0024,  0.0146],
        ...,
        [ 0.0112,  0.0036,  0.0021,  ...,  0.0544,  0.0026, -0.0047],
        [-0.0106,  0.0048, -0.0088,  ...,  0.0037,  0.0440, -0.0030],
        [-0.0060,  0.0141, -0.0055,  ...,  0.0083, -0.0032,  0.0573]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.9233, -5.8750,  1.9971,  ..., -6.2422,  0.4539, -0.8369]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 02:03:46 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for stalin was known for their work as a  dictator
locke was known for their work as a  philosopher
wagner was known for their work as a  composer
marx was known for their work as a  philosopher
mozart was known for their work as a  composer
hegel was known for their work as a  philosopher
strauss was known for their work as a  composer
kepler was known for their work as a 
2024-07-31 02:03:46 root INFO     [order_1_approx] starting weight calculation for marx was known for their work as a  philosopher
strauss was known for their work as a  composer
kepler was known for their work as a  mathematician
locke was known for their work as a  philosopher
stalin was known for their work as a  dictator
wagner was known for their work as a  composer
mozart was known for their work as a  composer
hegel was known for their work as a 
2024-07-31 02:03:46 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 02:05:47 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3062,  0.0813,  0.2269,  ...,  0.3423,  0.1350, -0.0885],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.7920, -6.4805,  4.3281,  ..., -5.0508, -0.4941, -1.3633],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0676, -0.0021,  0.0071,  ..., -0.0028, -0.0089,  0.0136],
        [-0.0138,  0.0579, -0.0014,  ..., -0.0142, -0.0087, -0.0157],
        [ 0.0108,  0.0052,  0.0579,  ..., -0.0070,  0.0017,  0.0109],
        ...,
        [ 0.0156,  0.0089,  0.0070,  ...,  0.0798,  0.0091,  0.0108],
        [ 0.0019,  0.0080, -0.0049,  ...,  0.0039,  0.0490, -0.0090],
        [-0.0260,  0.0013, -0.0134,  ...,  0.0003,  0.0004,  0.0621]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.7847, -6.2422,  4.0977,  ..., -5.2539, -0.5425, -1.3564]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 02:05:48 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for marx was known for their work as a  philosopher
strauss was known for their work as a  composer
kepler was known for their work as a  mathematician
locke was known for their work as a  philosopher
stalin was known for their work as a  dictator
wagner was known for their work as a  composer
mozart was known for their work as a  composer
hegel was known for their work as a 
2024-07-31 02:05:48 root INFO     [order_1_approx] starting weight calculation for locke was known for their work as a  philosopher
wagner was known for their work as a  composer
kepler was known for their work as a  mathematician
stalin was known for their work as a  dictator
mozart was known for their work as a  composer
strauss was known for their work as a  composer
hegel was known for their work as a  philosopher
marx was known for their work as a 
2024-07-31 02:05:48 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 02:07:53 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3042, -0.1709,  0.6250,  ...,  0.0070, -0.0599,  0.4800],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.6230, -8.5156,  4.5117,  ..., -5.4844,  1.1191, -2.7500],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0251, -0.0016,  0.0056,  ..., -0.0040, -0.0094,  0.0031],
        [-0.0023,  0.0257,  0.0072,  ..., -0.0095, -0.0032, -0.0031],
        [ 0.0111, -0.0060,  0.0273,  ..., -0.0049, -0.0004, -0.0008],
        ...,
        [ 0.0131,  0.0002, -0.0054,  ...,  0.0349,  0.0009, -0.0072],
        [-0.0096,  0.0102,  0.0049,  ...,  0.0065,  0.0171, -0.0009],
        [-0.0007,  0.0054, -0.0118,  ...,  0.0040,  0.0021,  0.0300]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.6006, -8.3828,  4.4180,  ..., -5.3945,  1.0596, -2.7910]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 02:07:54 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for locke was known for their work as a  philosopher
wagner was known for their work as a  composer
kepler was known for their work as a  mathematician
stalin was known for their work as a  dictator
mozart was known for their work as a  composer
strauss was known for their work as a  composer
hegel was known for their work as a  philosopher
marx was known for their work as a 
2024-07-31 02:07:54 root INFO     [order_1_approx] starting weight calculation for mozart was known for their work as a  composer
kepler was known for their work as a  mathematician
wagner was known for their work as a  composer
stalin was known for their work as a  dictator
marx was known for their work as a  philosopher
strauss was known for their work as a  composer
hegel was known for their work as a  philosopher
locke was known for their work as a 
2024-07-31 02:07:54 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 02:10:01 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1439, -0.3665, -0.5298,  ...,  0.1166, -0.0324,  0.0715],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.9214, -3.5781,  2.7520,  ..., -6.3789,  0.9424, -3.2852],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 5.3925e-02,  1.8463e-03,  2.4738e-03,  ...,  6.1369e-04,
         -1.8311e-02, -1.5965e-03],
        [-9.4414e-05,  4.3182e-02, -3.7842e-03,  ...,  7.6714e-03,
         -6.5689e-03, -4.5166e-03],
        [ 4.7569e-03,  1.9169e-03,  4.4434e-02,  ..., -5.4588e-03,
          8.5220e-03,  1.0345e-02],
        ...,
        [ 5.6610e-03,  3.9215e-03, -6.4774e-03,  ...,  5.9631e-02,
          2.0103e-03, -3.9635e-03],
        [-8.7662e-03,  1.4984e-02, -3.5439e-03,  ...,  1.4816e-02,
          3.5828e-02,  2.8133e-03],
        [-1.6129e-02,  5.4245e-03, -7.9498e-03,  ..., -6.4697e-03,
         -1.8692e-04,  5.2246e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.6860, -3.7031,  2.9160,  ..., -6.1953,  1.0439, -3.2910]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 02:10:02 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for mozart was known for their work as a  composer
kepler was known for their work as a  mathematician
wagner was known for their work as a  composer
stalin was known for their work as a  dictator
marx was known for their work as a  philosopher
strauss was known for their work as a  composer
hegel was known for their work as a  philosopher
locke was known for their work as a 
2024-07-31 02:10:02 root INFO     [order_1_approx] starting weight calculation for kepler was known for their work as a  mathematician
wagner was known for their work as a  composer
locke was known for their work as a  philosopher
strauss was known for their work as a  composer
hegel was known for their work as a  philosopher
marx was known for their work as a  philosopher
stalin was known for their work as a  dictator
mozart was known for their work as a 
2024-07-31 02:10:02 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 02:12:05 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0846,  0.1539,  0.0940,  ...,  0.0613, -0.2808,  0.0886],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.2422, -5.0547,  2.5977,  ..., -3.8164,  1.6865, -0.5137],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 2.7771e-02, -5.2872e-03,  8.5220e-03,  ..., -3.9673e-03,
         -1.4450e-02, -1.8673e-03],
        [ 4.1103e-04,  2.9449e-02,  2.9964e-03,  ..., -1.0002e-02,
         -6.6757e-03, -1.3218e-03],
        [ 4.9858e-03, -2.0561e-03,  3.1036e-02,  ..., -1.0071e-02,
         -3.8862e-05,  3.3092e-03],
        ...,
        [ 9.8343e-03,  3.9062e-03, -2.2793e-03,  ...,  3.6499e-02,
          4.3945e-03, -2.0466e-03],
        [ 4.0398e-03,  1.2634e-02, -1.5221e-03,  ...,  5.9624e-03,
          2.4048e-02,  4.5624e-03],
        [-9.2010e-03,  7.8249e-04, -5.4016e-03,  ...,  4.0245e-03,
         -6.7444e-03,  3.1082e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.1953, -4.8945,  2.6582,  ..., -3.7324,  1.6045, -0.6094]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 02:12:07 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for kepler was known for their work as a  mathematician
wagner was known for their work as a  composer
locke was known for their work as a  philosopher
strauss was known for their work as a  composer
hegel was known for their work as a  philosopher
marx was known for their work as a  philosopher
stalin was known for their work as a  dictator
mozart was known for their work as a 
2024-07-31 02:12:07 root INFO     total operator prediction time: 998.8392050266266 seconds
2024-07-31 02:12:07 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on male - female
2024-07-31 02:12:07 root INFO     building operator male - female
2024-07-31 02:12:07 root INFO     [order_1_approx] starting weight calculation for A female fisherman is known as a fisherwoman
A female boar is known as a sow
A female stallion is known as a mare
A female dad is known as a mom
A female actor is known as a actress
A female batman is known as a batwoman
A female hound is known as a bitch
A female gentleman is known as a
2024-07-31 02:12:07 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 02:14:11 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.9341,  0.6724, -0.4697,  ..., -0.2173, -0.4094, -0.1194],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 5.9258, -1.3438, -3.5039,  ...,  0.4883, -4.0547, -1.4814],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0668, -0.0142,  0.0063,  ..., -0.0096, -0.0171,  0.0194],
        [ 0.0187,  0.0593,  0.0356,  ...,  0.0406,  0.0079,  0.0182],
        [ 0.0189, -0.0058,  0.0535,  ..., -0.0328,  0.0088, -0.0019],
        ...,
        [-0.0113,  0.0003,  0.0403,  ...,  0.1083, -0.0125, -0.0109],
        [-0.0264, -0.0071,  0.0004,  ...,  0.0042,  0.0314, -0.0119],
        [-0.0144,  0.0277, -0.0156,  ..., -0.0047, -0.0058,  0.0455]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 5.8672, -1.3291, -2.7695,  ...,  0.2817, -4.2148, -0.8364]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 02:14:12 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A female fisherman is known as a fisherwoman
A female boar is known as a sow
A female stallion is known as a mare
A female dad is known as a mom
A female actor is known as a actress
A female batman is known as a batwoman
A female hound is known as a bitch
A female gentleman is known as a
2024-07-31 02:14:12 root INFO     [order_1_approx] starting weight calculation for A female boar is known as a sow
A female gentleman is known as a lady
A female hound is known as a bitch
A female dad is known as a mom
A female stallion is known as a mare
A female actor is known as a actress
A female fisherman is known as a fisherwoman
A female batman is known as a
2024-07-31 02:14:12 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 02:16:16 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4910,  0.4995, -0.3291,  ..., -0.1163, -0.3474,  0.1863],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.1406, -4.2734,  2.9922,  ..., -1.4854, -1.8965,  0.9302],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0624, -0.0172,  0.0164,  ...,  0.0037, -0.0186, -0.0031],
        [-0.0044,  0.0598, -0.0073,  ..., -0.0257, -0.0028, -0.0115],
        [ 0.0084, -0.0008,  0.0635,  ...,  0.0062, -0.0082, -0.0088],
        ...,
        [-0.0059,  0.0126, -0.0069,  ...,  0.0553,  0.0027,  0.0087],
        [ 0.0063, -0.0039,  0.0150,  ...,  0.0357,  0.0476,  0.0066],
        [-0.0292, -0.0033, -0.0125,  ..., -0.0263, -0.0218,  0.0348]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.9453, -3.9414,  2.8516,  ..., -1.3828, -1.5283,  0.7598]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 02:16:17 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A female boar is known as a sow
A female gentleman is known as a lady
A female hound is known as a bitch
A female dad is known as a mom
A female stallion is known as a mare
A female actor is known as a actress
A female fisherman is known as a fisherwoman
A female batman is known as a
2024-07-31 02:16:17 root INFO     [order_1_approx] starting weight calculation for A female boar is known as a sow
A female dad is known as a mom
A female gentleman is known as a lady
A female batman is known as a batwoman
A female actor is known as a actress
A female fisherman is known as a fisherwoman
A female stallion is known as a mare
A female hound is known as a
2024-07-31 02:16:17 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 02:18:22 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1116,  0.2939,  0.5073,  ...,  0.1572, -0.5054, -0.2273],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.4961, -6.3555, -0.9277,  ..., -0.3525, -2.8438,  2.9023],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0588,  0.0202, -0.0011,  ...,  0.0041, -0.0166,  0.0023],
        [-0.0088,  0.0655, -0.0088,  ..., -0.0059,  0.0522, -0.0382],
        [ 0.0256, -0.0014,  0.0662,  ..., -0.0156, -0.0197, -0.0451],
        ...,
        [ 0.0009, -0.0090,  0.0217,  ...,  0.0569, -0.0071, -0.0061],
        [ 0.0236,  0.0013,  0.0121,  ...,  0.0217,  0.0502, -0.0149],
        [ 0.0169, -0.0266,  0.0135,  ...,  0.0034, -0.0240,  0.0373]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.5156, -6.2773, -1.0742,  ..., -1.0371, -3.3594,  2.4805]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 02:18:23 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A female boar is known as a sow
A female dad is known as a mom
A female gentleman is known as a lady
A female batman is known as a batwoman
A female actor is known as a actress
A female fisherman is known as a fisherwoman
A female stallion is known as a mare
A female hound is known as a
2024-07-31 02:18:23 root INFO     [order_1_approx] starting weight calculation for A female hound is known as a bitch
A female fisherman is known as a fisherwoman
A female boar is known as a sow
A female batman is known as a batwoman
A female gentleman is known as a lady
A female actor is known as a actress
A female dad is known as a mom
A female stallion is known as a
2024-07-31 02:18:23 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 02:20:29 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4070, -0.2302,  0.2445,  ...,  0.1860, -0.4463,  0.6797],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.9746, -5.4531, -2.3398,  ..., -0.4094, -1.8701,  2.4844],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 6.4331e-02,  9.8190e-03, -6.4392e-03,  ..., -3.6373e-03,
         -1.3275e-02, -5.0430e-03],
        [ 1.0101e-02,  5.2551e-02,  4.3335e-03,  ...,  1.7227e-02,
          4.1260e-02, -1.0635e-02],
        [ 5.9814e-03, -1.2466e-02,  5.9448e-02,  ..., -7.9498e-03,
         -5.4359e-05, -2.0630e-02],
        ...,
        [ 8.5449e-04, -7.2823e-03, -7.9117e-03,  ...,  5.6030e-02,
          6.0883e-03,  3.3741e-03],
        [-1.2817e-02,  1.1894e-02, -1.1192e-02,  ...,  1.5152e-02,
          3.5553e-02,  6.1417e-04],
        [ 3.2501e-03, -1.8875e-02,  6.7749e-03,  ...,  2.0370e-03,
         -3.3875e-03,  3.4485e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.1172, -4.8945, -2.3965,  ..., -0.2734, -2.1758,  2.5195]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 02:20:29 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A female hound is known as a bitch
A female fisherman is known as a fisherwoman
A female boar is known as a sow
A female batman is known as a batwoman
A female gentleman is known as a lady
A female actor is known as a actress
A female dad is known as a mom
A female stallion is known as a
2024-07-31 02:20:30 root INFO     [order_1_approx] starting weight calculation for A female batman is known as a batwoman
A female stallion is known as a mare
A female hound is known as a bitch
A female fisherman is known as a fisherwoman
A female actor is known as a actress
A female gentleman is known as a lady
A female dad is known as a mom
A female boar is known as a
2024-07-31 02:20:30 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 02:22:32 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.5093, -0.4067,  0.1046,  ...,  0.0712, -0.7129,  0.8135],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.4570, -4.3203, -0.7036,  ..., -1.7061, -1.4512,  1.0166],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 7.5439e-02, -4.5776e-05, -1.3781e-03,  ...,  7.1030e-03,
         -1.5823e-02, -1.1322e-02],
        [ 1.4946e-02,  6.1035e-02, -1.0864e-02,  ...,  2.0447e-02,
          1.6708e-02, -2.8961e-02],
        [ 2.1591e-02, -9.5062e-03,  6.5430e-02,  ...,  9.9640e-03,
         -5.1193e-03, -1.2421e-02],
        ...,
        [-7.7133e-03, -1.6998e-02,  2.1164e-02,  ...,  7.6904e-02,
         -5.1193e-03, -1.4008e-02],
        [ 1.2505e-02,  1.8768e-02,  2.4734e-02,  ...,  1.6296e-02,
          6.5857e-02,  1.2276e-02],
        [ 4.7150e-03,  8.8501e-03, -3.6507e-03,  ...,  5.9128e-03,
         -4.3869e-03,  3.7170e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.9180, -3.9355, -1.0508,  ..., -1.4434, -2.0020,  0.1880]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 02:22:33 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A female batman is known as a batwoman
A female stallion is known as a mare
A female hound is known as a bitch
A female fisherman is known as a fisherwoman
A female actor is known as a actress
A female gentleman is known as a lady
A female dad is known as a mom
A female boar is known as a
2024-07-31 02:22:33 root INFO     [order_1_approx] starting weight calculation for A female hound is known as a bitch
A female fisherman is known as a fisherwoman
A female stallion is known as a mare
A female batman is known as a batwoman
A female gentleman is known as a lady
A female boar is known as a sow
A female actor is known as a actress
A female dad is known as a
2024-07-31 02:22:33 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 02:24:37 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4177,  0.2225, -0.0215,  ...,  0.0201, -0.7344,  0.0259],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 5.4727, -3.4062, -1.7188,  ...,  2.2188, -5.4453, -2.0332],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 5.6793e-02, -1.7441e-02,  1.6296e-02,  ...,  1.2077e-02,
         -1.3618e-03,  1.0925e-02],
        [ 1.4465e-02,  4.5868e-02, -6.8436e-03,  ...,  4.9019e-03,
          7.3700e-03, -1.6556e-02],
        [ 1.1238e-02, -1.0910e-02,  8.6182e-02,  ..., -3.6526e-03,
         -1.5182e-03, -8.0872e-03],
        ...,
        [-4.9591e-04,  4.9286e-03, -1.3794e-02,  ...,  6.3171e-02,
         -8.4152e-03, -1.2482e-02],
        [ 3.6240e-03, -1.2955e-02, -8.3389e-03,  ...,  1.6861e-02,
          3.4851e-02, -1.0925e-02],
        [ 1.2108e-02,  4.5776e-05, -7.9956e-03,  ..., -2.1896e-02,
          2.8362e-03,  4.8279e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 5.5078, -3.3379, -1.7695,  ...,  2.6895, -5.1406, -1.8213]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 02:24:38 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A female hound is known as a bitch
A female fisherman is known as a fisherwoman
A female stallion is known as a mare
A female batman is known as a batwoman
A female gentleman is known as a lady
A female boar is known as a sow
A female actor is known as a actress
A female dad is known as a
2024-07-31 02:24:38 root INFO     [order_1_approx] starting weight calculation for A female dad is known as a mom
A female batman is known as a batwoman
A female boar is known as a sow
A female hound is known as a bitch
A female stallion is known as a mare
A female gentleman is known as a lady
A female actor is known as a actress
A female fisherman is known as a
2024-07-31 02:24:38 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 02:26:47 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.7031,  0.2195, -0.4871,  ..., -0.4297, -0.3174,  0.3884],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 5.6797, -4.6250, -0.6309,  ...,  0.3599, -4.5078, -0.0205],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0628, -0.0149,  0.0020,  ...,  0.0006, -0.0101, -0.0067],
        [ 0.0065,  0.0441, -0.0010,  ..., -0.0020,  0.0176, -0.0162],
        [ 0.0078, -0.0080,  0.0284,  ..., -0.0080, -0.0039, -0.0004],
        ...,
        [-0.0227,  0.0137, -0.0078,  ...,  0.0224, -0.0085,  0.0044],
        [ 0.0245,  0.0403, -0.0106,  ...,  0.0039,  0.0162,  0.0007],
        [-0.0157, -0.0095, -0.0057,  ..., -0.0152, -0.0062,  0.0352]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 5.8750, -4.4648, -0.5747,  ...,  0.1969, -4.1562, -0.1561]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 02:26:48 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A female dad is known as a mom
A female batman is known as a batwoman
A female boar is known as a sow
A female hound is known as a bitch
A female stallion is known as a mare
A female gentleman is known as a lady
A female actor is known as a actress
A female fisherman is known as a
2024-07-31 02:26:48 root INFO     [order_1_approx] starting weight calculation for A female dad is known as a mom
A female stallion is known as a mare
A female fisherman is known as a fisherwoman
A female hound is known as a bitch
A female gentleman is known as a lady
A female batman is known as a batwoman
A female boar is known as a sow
A female actor is known as a
2024-07-31 02:26:48 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 02:28:55 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3325,  0.4658, -0.3208,  ..., -0.0583, -0.7095, -0.4189],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.2461, -4.7617,  1.2295,  ..., -1.0459, -3.9180, -1.2441],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0624, -0.0002, -0.0142,  ...,  0.0085,  0.0101,  0.0002],
        [ 0.0031,  0.0372,  0.0122,  ...,  0.0189, -0.0032, -0.0217],
        [-0.0080,  0.0167,  0.0699,  ..., -0.0117, -0.0077, -0.0148],
        ...,
        [ 0.0015,  0.0100,  0.0064,  ...,  0.0579, -0.0031, -0.0049],
        [ 0.0110,  0.0231, -0.0055,  ..., -0.0127,  0.0439, -0.0109],
        [-0.0025, -0.0035, -0.0145,  ..., -0.0009, -0.0096,  0.0561]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.4609, -4.8203,  1.2988,  ..., -1.2129, -3.7656, -0.9761]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 02:28:56 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A female dad is known as a mom
A female stallion is known as a mare
A female fisherman is known as a fisherwoman
A female hound is known as a bitch
A female gentleman is known as a lady
A female batman is known as a batwoman
A female boar is known as a sow
A female actor is known as a
2024-07-31 02:28:56 root INFO     total operator prediction time: 1009.0238871574402 seconds
2024-07-31 02:28:56 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on animal - shelter
2024-07-31 02:28:56 root INFO     building operator animal - shelter
2024-07-31 02:28:56 root INFO     [order_1_approx] starting weight calculation for The place goldfish lives in is called pond
The place pig lives in is called sty
The place ant lives in is called anthill
The place mouse lives in is called nest
The place cattle lives in is called barn
The place hornet lives in is called nest
The place fish lives in is called sea
The place whale lives in is called
2024-07-31 02:28:56 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 02:31:02 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3767, -0.3965, -0.0109,  ..., -0.4878, -0.3962,  0.0253],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.0381, -7.3125,  0.4639,  ..., -2.5645,  0.7842, -1.0254],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0178, -0.0008, -0.0080,  ..., -0.0038, -0.0138, -0.0056],
        [ 0.0024,  0.0237, -0.0090,  ..., -0.0003, -0.0034, -0.0173],
        [-0.0125,  0.0108,  0.0254,  ..., -0.0060, -0.0057,  0.0007],
        ...,
        [-0.0058,  0.0019,  0.0078,  ...,  0.0308, -0.0022, -0.0115],
        [ 0.0015,  0.0044, -0.0006,  ...,  0.0017,  0.0225, -0.0064],
        [-0.0081, -0.0239,  0.0028,  ..., -0.0074,  0.0035,  0.0211]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.1826, -7.1680,  0.3796,  ..., -2.7109,  1.0146, -1.1279]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 02:31:03 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The place goldfish lives in is called pond
The place pig lives in is called sty
The place ant lives in is called anthill
The place mouse lives in is called nest
The place cattle lives in is called barn
The place hornet lives in is called nest
The place fish lives in is called sea
The place whale lives in is called
2024-07-31 02:31:04 root INFO     [order_1_approx] starting weight calculation for The place pig lives in is called sty
The place ant lives in is called anthill
The place whale lives in is called sea
The place goldfish lives in is called pond
The place hornet lives in is called nest
The place mouse lives in is called nest
The place fish lives in is called sea
The place cattle lives in is called
2024-07-31 02:31:04 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 02:33:12 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1316, -0.6035,  0.1569,  ...,  0.1604, -0.0598,  0.1536],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.3906, -8.4609,  3.9961,  ..., -2.1094,  3.6914, -1.8828],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0192, -0.0102, -0.0012,  ...,  0.0035, -0.0012, -0.0071],
        [ 0.0064,  0.0413, -0.0045,  ..., -0.0099, -0.0023, -0.0118],
        [ 0.0002, -0.0113,  0.0259,  ...,  0.0082, -0.0053, -0.0127],
        ...,
        [ 0.0061, -0.0061, -0.0036,  ...,  0.0576, -0.0015, -0.0049],
        [ 0.0239,  0.0050, -0.0082,  ...,  0.0067,  0.0355, -0.0157],
        [-0.0097, -0.0157,  0.0014,  ..., -0.0161, -0.0035,  0.0322]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.6738, -8.2266,  3.6465,  ..., -2.0547,  3.2344, -1.5449]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 02:33:13 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The place pig lives in is called sty
The place ant lives in is called anthill
The place whale lives in is called sea
The place goldfish lives in is called pond
The place hornet lives in is called nest
The place mouse lives in is called nest
The place fish lives in is called sea
The place cattle lives in is called
2024-07-31 02:33:13 root INFO     [order_1_approx] starting weight calculation for The place fish lives in is called sea
The place ant lives in is called anthill
The place cattle lives in is called barn
The place goldfish lives in is called pond
The place whale lives in is called sea
The place mouse lives in is called nest
The place pig lives in is called sty
The place hornet lives in is called
2024-07-31 02:33:13 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 02:35:17 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2007, -0.0700,  0.2172,  ...,  0.3354,  0.0016, -0.1061],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.8828, -6.6094,  2.4414,  ..., -3.1211,  1.0566, -0.6484],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0587, -0.0064,  0.0004,  ...,  0.0026,  0.0007, -0.0056],
        [-0.0032,  0.0686,  0.0065,  ...,  0.0205,  0.0035, -0.0414],
        [ 0.0021,  0.0362,  0.0789,  ...,  0.0216, -0.0255,  0.0081],
        ...,
        [ 0.0069, -0.0208,  0.0193,  ...,  0.0834,  0.0092, -0.0252],
        [ 0.0135, -0.0007,  0.0009,  ...,  0.0269,  0.0303,  0.0115],
        [-0.0288, -0.0053, -0.0060,  ..., -0.0175, -0.0048,  0.0659]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.0352, -6.8594,  2.1738,  ..., -3.1367,  1.0039, -0.4434]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 02:35:18 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The place fish lives in is called sea
The place ant lives in is called anthill
The place cattle lives in is called barn
The place goldfish lives in is called pond
The place whale lives in is called sea
The place mouse lives in is called nest
The place pig lives in is called sty
The place hornet lives in is called
2024-07-31 02:35:18 root INFO     [order_1_approx] starting weight calculation for The place cattle lives in is called barn
The place whale lives in is called sea
The place fish lives in is called sea
The place ant lives in is called anthill
The place mouse lives in is called nest
The place hornet lives in is called nest
The place goldfish lives in is called pond
The place pig lives in is called
2024-07-31 02:35:18 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 02:37:18 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2073, -0.3877, -0.1434,  ...,  0.1190, -0.1227, -0.1130],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.5859, -6.8359,  3.0840,  ..., -2.3418,  0.7026,  1.1855],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0498,  0.0033, -0.0175,  ...,  0.0066, -0.0091, -0.0104],
        [ 0.0044,  0.0457, -0.0104,  ..., -0.0067, -0.0127, -0.0293],
        [-0.0155,  0.0005,  0.0501,  ...,  0.0099, -0.0095,  0.0097],
        ...,
        [-0.0055,  0.0035,  0.0034,  ...,  0.0612,  0.0018, -0.0096],
        [ 0.0159,  0.0068,  0.0186,  ...,  0.0096,  0.0355, -0.0063],
        [-0.0095, -0.0059, -0.0049,  ..., -0.0260, -0.0003,  0.0211]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.7578, -6.3672,  2.7070,  ..., -2.4668,  0.5698,  1.4160]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 02:37:18 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The place cattle lives in is called barn
The place whale lives in is called sea
The place fish lives in is called sea
The place ant lives in is called anthill
The place mouse lives in is called nest
The place hornet lives in is called nest
The place goldfish lives in is called pond
The place pig lives in is called
2024-07-31 02:37:19 root INFO     [order_1_approx] starting weight calculation for The place goldfish lives in is called pond
The place fish lives in is called sea
The place ant lives in is called anthill
The place hornet lives in is called nest
The place whale lives in is called sea
The place pig lives in is called sty
The place cattle lives in is called barn
The place mouse lives in is called
2024-07-31 02:37:19 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 02:39:23 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.3047, -0.5439,  0.4180,  ...,  0.1047, -0.1429, -0.1692],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.4209, -5.3984,  1.5615,  ..., -0.7100, -0.4531,  1.0146],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 3.9825e-02,  3.0003e-03,  1.8051e-02,  ...,  6.5880e-03,
         -8.2855e-03, -6.8283e-03],
        [-2.4529e-03,  3.4119e-02, -9.4681e-03,  ...,  4.2496e-03,
          1.3107e-02, -3.2288e-02],
        [-5.4398e-03,  2.6962e-02,  4.7546e-02,  ...,  7.0000e-03,
         -1.4496e-02,  1.5602e-02],
        ...,
        [-9.9182e-05, -1.4923e-02,  2.0081e-02,  ...,  3.3752e-02,
          5.8632e-03, -2.4719e-02],
        [ 6.3896e-03,  1.3000e-02, -5.0316e-03,  ...,  1.1902e-02,
          3.9764e-02,  5.5885e-03],
        [-2.3651e-02, -1.4248e-03,  3.6564e-03,  ..., -1.7120e-02,
         -2.4033e-03,  5.8044e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.8745, -5.4844,  1.4766,  ..., -0.8408, -0.4309,  0.6030]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 02:39:24 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The place goldfish lives in is called pond
The place fish lives in is called sea
The place ant lives in is called anthill
The place hornet lives in is called nest
The place whale lives in is called sea
The place pig lives in is called sty
The place cattle lives in is called barn
The place mouse lives in is called
2024-07-31 02:39:25 root INFO     [order_1_approx] starting weight calculation for The place goldfish lives in is called pond
The place pig lives in is called sty
The place hornet lives in is called nest
The place fish lives in is called sea
The place mouse lives in is called nest
The place cattle lives in is called barn
The place whale lives in is called sea
The place ant lives in is called
2024-07-31 02:39:25 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 02:41:33 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2957, -0.3462,  0.0622,  ..., -0.4175,  0.4456, -0.7285],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.7285, -6.4844,  1.0371,  ..., -3.3750,  1.0068, -3.5312],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 4.3610e-02, -1.9073e-03, -3.6240e-05,  ...,  3.5858e-02,
         -4.5586e-03,  7.3929e-03],
        [-3.7155e-03,  3.2654e-02, -1.1578e-03,  ..., -1.0979e-02,
          1.7014e-02, -1.5594e-02],
        [ 1.4687e-02,  5.1605e-02,  5.5573e-02,  ...,  2.4078e-02,
         -3.3752e-02,  2.2202e-02],
        ...,
        [ 8.4229e-03, -1.1810e-02,  1.0727e-02,  ...,  5.8167e-02,
          8.6136e-03, -1.0330e-02],
        [-1.0391e-02,  7.1144e-03,  1.1024e-03,  ...,  1.1322e-02,
          2.7039e-02,  1.5488e-02],
        [-1.4923e-02, -5.2681e-03,  2.4719e-03,  ..., -2.0828e-03,
         -1.2474e-02,  5.1361e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.7852, -6.7070,  0.9448,  ..., -2.9902,  0.8037, -3.3828]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 02:41:34 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The place goldfish lives in is called pond
The place pig lives in is called sty
The place hornet lives in is called nest
The place fish lives in is called sea
The place mouse lives in is called nest
The place cattle lives in is called barn
The place whale lives in is called sea
The place ant lives in is called
2024-07-31 02:41:34 root INFO     [order_1_approx] starting weight calculation for The place whale lives in is called sea
The place pig lives in is called sty
The place ant lives in is called anthill
The place goldfish lives in is called pond
The place hornet lives in is called nest
The place mouse lives in is called nest
The place cattle lives in is called barn
The place fish lives in is called
2024-07-31 02:41:35 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 02:43:42 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0277, -0.2642, -0.1433,  ..., -0.4302,  0.0783,  0.0077],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.4512, -5.5312,  1.5889,  ..., -3.1602, -0.0972, -2.2148],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0253, -0.0151, -0.0029,  ...,  0.0063, -0.0237, -0.0060],
        [-0.0020,  0.0253, -0.0080,  ..., -0.0020, -0.0053, -0.0251],
        [-0.0106,  0.0026,  0.0343,  ...,  0.0183, -0.0045,  0.0100],
        ...,
        [-0.0100, -0.0030,  0.0089,  ...,  0.0264,  0.0003, -0.0198],
        [ 0.0131,  0.0180,  0.0047,  ...,  0.0110,  0.0324,  0.0048],
        [-0.0157, -0.0043, -0.0099,  ..., -0.0116, -0.0114,  0.0332]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.4590, -5.4531,  1.4502,  ..., -3.1855, -0.1863, -2.1191]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 02:43:43 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The place whale lives in is called sea
The place pig lives in is called sty
The place ant lives in is called anthill
The place goldfish lives in is called pond
The place hornet lives in is called nest
The place mouse lives in is called nest
The place cattle lives in is called barn
The place fish lives in is called
2024-07-31 02:43:43 root INFO     [order_1_approx] starting weight calculation for The place ant lives in is called anthill
The place mouse lives in is called nest
The place fish lives in is called sea
The place whale lives in is called sea
The place pig lives in is called sty
The place cattle lives in is called barn
The place hornet lives in is called nest
The place goldfish lives in is called
2024-07-31 02:43:43 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 02:45:53 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1986, -0.6655,  0.1490,  ..., -0.4766, -0.5742,  0.3530],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.9370, -4.2266, -0.4512,  ..., -3.3672,  1.1074, -0.9551],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0374,  0.0099, -0.0015,  ..., -0.0180, -0.0172, -0.0076],
        [ 0.0014,  0.0422, -0.0281,  ..., -0.0065, -0.0085, -0.0103],
        [ 0.0141,  0.0033,  0.0648,  ...,  0.0292, -0.0054, -0.0032],
        ...,
        [-0.0069, -0.0060, -0.0085,  ...,  0.0299,  0.0046, -0.0169],
        [ 0.0152,  0.0044, -0.0053,  ...,  0.0258,  0.0489, -0.0108],
        [-0.0250, -0.0049, -0.0129,  ..., -0.0082, -0.0035,  0.0450]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.3789, -4.4922, -0.4282,  ..., -3.3477,  0.7935, -1.2891]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 02:45:54 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The place ant lives in is called anthill
The place mouse lives in is called nest
The place fish lives in is called sea
The place whale lives in is called sea
The place pig lives in is called sty
The place cattle lives in is called barn
The place hornet lives in is called nest
The place goldfish lives in is called
2024-07-31 02:45:54 root INFO     total operator prediction time: 1018.5082433223724 seconds
2024-07-31 02:45:54 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on country - language
2024-07-31 02:45:54 root INFO     building operator country - language
2024-07-31 02:45:54 root INFO     [order_1_approx] starting weight calculation for The country of argentina primarily speaks the language of spanish
The country of guatemala primarily speaks the language of spanish
The country of fiji primarily speaks the language of english
The country of netherlands primarily speaks the language of dutch
The country of denmark primarily speaks the language of danish
The country of austria primarily speaks the language of german
The country of iraq primarily speaks the language of arabic
The country of kosovo primarily speaks the language of
2024-07-31 02:45:55 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 02:48:00 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4688,  0.2522, -0.1646,  ...,  0.7979, -0.1802,  0.3767],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.4346, -4.9688,  1.4590,  ..., -1.6152,  0.0835, -0.7827],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0230, -0.0003, -0.0008,  ...,  0.0098, -0.0036, -0.0167],
        [-0.0056,  0.0326,  0.0016,  ..., -0.0050, -0.0020, -0.0218],
        [-0.0088, -0.0063,  0.0283,  ...,  0.0160,  0.0074, -0.0107],
        ...,
        [-0.0164, -0.0067, -0.0121,  ...,  0.0332,  0.0025, -0.0084],
        [ 0.0099,  0.0201, -0.0005,  ..., -0.0033,  0.0259,  0.0050],
        [-0.0112, -0.0097, -0.0057,  ...,  0.0014,  0.0085,  0.0210]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.4873, -4.5352,  1.1729,  ..., -1.7773,  0.0827, -0.7178]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 02:48:01 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country of argentina primarily speaks the language of spanish
The country of guatemala primarily speaks the language of spanish
The country of fiji primarily speaks the language of english
The country of netherlands primarily speaks the language of dutch
The country of denmark primarily speaks the language of danish
The country of austria primarily speaks the language of german
The country of iraq primarily speaks the language of arabic
The country of kosovo primarily speaks the language of
2024-07-31 02:48:01 root INFO     [order_1_approx] starting weight calculation for The country of iraq primarily speaks the language of arabic
The country of austria primarily speaks the language of german
The country of guatemala primarily speaks the language of spanish
The country of kosovo primarily speaks the language of albanian
The country of fiji primarily speaks the language of english
The country of netherlands primarily speaks the language of dutch
The country of argentina primarily speaks the language of spanish
The country of denmark primarily speaks the language of
2024-07-31 02:48:01 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 02:50:08 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1614,  0.1040, -0.3516,  ...,  0.0411,  0.3359,  0.1429],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.1699, -3.1582,  1.5801,  ..., -1.7314, -1.4707, -0.7725],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0309,  0.0007,  0.0038,  ...,  0.0074, -0.0038, -0.0055],
        [-0.0078,  0.0121,  0.0006,  ..., -0.0096, -0.0053, -0.0088],
        [-0.0176,  0.0146,  0.0394,  ...,  0.0095,  0.0018, -0.0006],
        ...,
        [-0.0059, -0.0002,  0.0018,  ...,  0.0260,  0.0076,  0.0057],
        [-0.0019,  0.0060, -0.0063,  ...,  0.0076,  0.0237,  0.0010],
        [-0.0126, -0.0108, -0.0096,  ...,  0.0018, -0.0060,  0.0280]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.1309, -3.1113,  1.3496,  ..., -1.7070, -1.5518, -0.5762]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 02:50:09 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country of iraq primarily speaks the language of arabic
The country of austria primarily speaks the language of german
The country of guatemala primarily speaks the language of spanish
The country of kosovo primarily speaks the language of albanian
The country of fiji primarily speaks the language of english
The country of netherlands primarily speaks the language of dutch
The country of argentina primarily speaks the language of spanish
The country of denmark primarily speaks the language of
2024-07-31 02:50:09 root INFO     [order_1_approx] starting weight calculation for The country of kosovo primarily speaks the language of albanian
The country of guatemala primarily speaks the language of spanish
The country of netherlands primarily speaks the language of dutch
The country of iraq primarily speaks the language of arabic
The country of argentina primarily speaks the language of spanish
The country of austria primarily speaks the language of german
The country of denmark primarily speaks the language of danish
The country of fiji primarily speaks the language of
2024-07-31 02:50:09 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 02:52:14 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.6211, -0.3333, -0.4131,  ...,  0.0187, -0.1420,  0.2507],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.4336, -0.0234,  3.4473,  ...,  1.1055, -3.6992, -0.2207],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0417,  0.0001,  0.0027,  ...,  0.0111, -0.0005, -0.0081],
        [ 0.0065,  0.0406,  0.0040,  ..., -0.0022, -0.0132, -0.0297],
        [-0.0016,  0.0112,  0.0580,  ...,  0.0166,  0.0143,  0.0094],
        ...,
        [-0.0213,  0.0070,  0.0038,  ...,  0.0422,  0.0167,  0.0094],
        [ 0.0069, -0.0013,  0.0047,  ..., -0.0030,  0.0459, -0.0058],
        [-0.0083,  0.0138,  0.0080,  ...,  0.0076,  0.0002,  0.0453]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.3230,  0.0966,  3.1602,  ...,  0.7588, -3.3594,  0.0330]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 02:52:15 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country of kosovo primarily speaks the language of albanian
The country of guatemala primarily speaks the language of spanish
The country of netherlands primarily speaks the language of dutch
The country of iraq primarily speaks the language of arabic
The country of argentina primarily speaks the language of spanish
The country of austria primarily speaks the language of german
The country of denmark primarily speaks the language of danish
The country of fiji primarily speaks the language of
2024-07-31 02:52:16 root INFO     [order_1_approx] starting weight calculation for The country of guatemala primarily speaks the language of spanish
The country of iraq primarily speaks the language of arabic
The country of netherlands primarily speaks the language of dutch
The country of denmark primarily speaks the language of danish
The country of austria primarily speaks the language of german
The country of fiji primarily speaks the language of english
The country of kosovo primarily speaks the language of albanian
The country of argentina primarily speaks the language of
2024-07-31 02:52:16 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 02:54:23 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1940, -0.1364,  0.1627,  ...,  0.2778, -0.5684, -0.0663],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.8594, -3.0938,  0.7461,  ...,  1.1777,  0.4609, -2.2832],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0112, -0.0062, -0.0018,  ...,  0.0047,  0.0008, -0.0004],
        [-0.0050,  0.0149,  0.0107,  ...,  0.0006, -0.0088, -0.0170],
        [ 0.0050,  0.0021,  0.0102,  ...,  0.0109,  0.0114,  0.0046],
        ...,
        [ 0.0004, -0.0003, -0.0047,  ...,  0.0176,  0.0023,  0.0063],
        [ 0.0016, -0.0054, -0.0029,  ...,  0.0023,  0.0116, -0.0022],
        [-0.0111, -0.0046, -0.0007,  ..., -0.0019, -0.0038,  0.0092]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.8242, -3.0742,  0.7632,  ...,  1.1709,  0.4719, -2.2949]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 02:54:24 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country of guatemala primarily speaks the language of spanish
The country of iraq primarily speaks the language of arabic
The country of netherlands primarily speaks the language of dutch
The country of denmark primarily speaks the language of danish
The country of austria primarily speaks the language of german
The country of fiji primarily speaks the language of english
The country of kosovo primarily speaks the language of albanian
The country of argentina primarily speaks the language of
2024-07-31 02:54:24 root INFO     [order_1_approx] starting weight calculation for The country of netherlands primarily speaks the language of dutch
The country of iraq primarily speaks the language of arabic
The country of argentina primarily speaks the language of spanish
The country of kosovo primarily speaks the language of albanian
The country of denmark primarily speaks the language of danish
The country of austria primarily speaks the language of german
The country of fiji primarily speaks the language of english
The country of guatemala primarily speaks the language of
2024-07-31 02:54:24 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 02:56:32 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2063, -0.0262,  0.2073,  ...,  0.5127, -0.5605,  0.1111],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.7778, -0.8281,  1.2754,  ..., -0.4966, -1.6328, -4.6172],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0191, -0.0036,  0.0020,  ..., -0.0025, -0.0076, -0.0014],
        [ 0.0018,  0.0096,  0.0073,  ...,  0.0024, -0.0038, -0.0101],
        [-0.0018, -0.0003,  0.0124,  ...,  0.0129,  0.0079,  0.0033],
        ...,
        [-0.0015, -0.0014, -0.0027,  ...,  0.0110,  0.0027,  0.0020],
        [-0.0047,  0.0008, -0.0046,  ..., -0.0058,  0.0138,  0.0006],
        [-0.0047, -0.0034,  0.0030,  ..., -0.0039, -0.0052,  0.0121]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.7461, -0.8267,  1.2666,  ..., -0.5410, -1.7168, -4.5703]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 02:56:33 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country of netherlands primarily speaks the language of dutch
The country of iraq primarily speaks the language of arabic
The country of argentina primarily speaks the language of spanish
The country of kosovo primarily speaks the language of albanian
The country of denmark primarily speaks the language of danish
The country of austria primarily speaks the language of german
The country of fiji primarily speaks the language of english
The country of guatemala primarily speaks the language of
2024-07-31 02:56:33 root INFO     [order_1_approx] starting weight calculation for The country of iraq primarily speaks the language of arabic
The country of fiji primarily speaks the language of english
The country of guatemala primarily speaks the language of spanish
The country of kosovo primarily speaks the language of albanian
The country of denmark primarily speaks the language of danish
The country of netherlands primarily speaks the language of dutch
The country of argentina primarily speaks the language of spanish
The country of austria primarily speaks the language of
2024-07-31 02:56:33 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 02:58:38 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3682,  0.3401, -0.2632,  ...,  0.4639,  0.2368,  0.0075],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.3948, -6.5234,  0.9219,  ...,  0.1350, -0.3242, -2.0156],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0341, -0.0002,  0.0038,  ...,  0.0128, -0.0002, -0.0062],
        [-0.0030,  0.0078,  0.0082,  ...,  0.0061,  0.0077, -0.0169],
        [-0.0046, -0.0026,  0.0223,  ...,  0.0109,  0.0051,  0.0009],
        ...,
        [-0.0030, -0.0012, -0.0068,  ...,  0.0290,  0.0033,  0.0024],
        [ 0.0036,  0.0018, -0.0057,  ...,  0.0001,  0.0104, -0.0050],
        [-0.0099, -0.0027,  0.0029,  ..., -0.0025,  0.0005,  0.0190]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.1064, -6.0820,  0.5996,  ..., -0.1355, -0.4019, -1.9590]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 02:58:39 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country of iraq primarily speaks the language of arabic
The country of fiji primarily speaks the language of english
The country of guatemala primarily speaks the language of spanish
The country of kosovo primarily speaks the language of albanian
The country of denmark primarily speaks the language of danish
The country of netherlands primarily speaks the language of dutch
The country of argentina primarily speaks the language of spanish
The country of austria primarily speaks the language of
2024-07-31 02:58:40 root INFO     [order_1_approx] starting weight calculation for The country of austria primarily speaks the language of german
The country of kosovo primarily speaks the language of albanian
The country of fiji primarily speaks the language of english
The country of argentina primarily speaks the language of spanish
The country of guatemala primarily speaks the language of spanish
The country of iraq primarily speaks the language of arabic
The country of denmark primarily speaks the language of danish
The country of netherlands primarily speaks the language of
2024-07-31 02:58:40 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 03:00:44 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3105,  0.0254,  0.1965,  ...,  0.4033,  0.0894, -0.0226],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.4238, -3.1719,  1.5332,  ..., -0.6309, -0.9233, -3.6562],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0273,  0.0057,  0.0048,  ...,  0.0173,  0.0031, -0.0103],
        [-0.0078,  0.0219,  0.0141,  ..., -0.0022, -0.0150, -0.0117],
        [-0.0024,  0.0089,  0.0313,  ...,  0.0285,  0.0111,  0.0014],
        ...,
        [-0.0041, -0.0106, -0.0014,  ...,  0.0202,  0.0061,  0.0044],
        [-0.0049, -0.0041, -0.0037,  ..., -0.0064,  0.0172, -0.0029],
        [-0.0071, -0.0024, -0.0067,  ..., -0.0047,  0.0018,  0.0297]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.4402, -3.2129,  1.4346,  ..., -0.6270, -0.8276, -3.5547]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 03:00:45 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country of austria primarily speaks the language of german
The country of kosovo primarily speaks the language of albanian
The country of fiji primarily speaks the language of english
The country of argentina primarily speaks the language of spanish
The country of guatemala primarily speaks the language of spanish
The country of iraq primarily speaks the language of arabic
The country of denmark primarily speaks the language of danish
The country of netherlands primarily speaks the language of
2024-07-31 03:00:45 root INFO     [order_1_approx] starting weight calculation for The country of austria primarily speaks the language of german
The country of fiji primarily speaks the language of english
The country of argentina primarily speaks the language of spanish
The country of denmark primarily speaks the language of danish
The country of kosovo primarily speaks the language of albanian
The country of guatemala primarily speaks the language of spanish
The country of netherlands primarily speaks the language of dutch
The country of iraq primarily speaks the language of
2024-07-31 03:00:45 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 03:02:53 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2949,  0.1527, -0.1202,  ...,  0.6157, -0.9189,  0.2773],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.7686, -2.7969,  0.9790,  ..., -1.3379, -0.1758, -2.0176],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0119, -0.0073,  0.0090,  ...,  0.0136, -0.0062, -0.0087],
        [-0.0059,  0.0209,  0.0119,  ..., -0.0065,  0.0047, -0.0220],
        [-0.0053, -0.0043,  0.0229,  ...,  0.0107,  0.0036,  0.0005],
        ...,
        [-0.0025,  0.0001, -0.0145,  ...,  0.0119, -0.0019, -0.0003],
        [ 0.0017,  0.0009, -0.0004,  ..., -0.0061,  0.0198,  0.0006],
        [-0.0053, -0.0117, -0.0028,  ..., -0.0029, -0.0024,  0.0148]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.6162, -2.5723,  1.1104,  ..., -1.4385, -0.1222, -1.9912]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 03:02:54 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country of austria primarily speaks the language of german
The country of fiji primarily speaks the language of english
The country of argentina primarily speaks the language of spanish
The country of denmark primarily speaks the language of danish
The country of kosovo primarily speaks the language of albanian
The country of guatemala primarily speaks the language of spanish
The country of netherlands primarily speaks the language of dutch
The country of iraq primarily speaks the language of
2024-07-31 03:02:54 root INFO     total operator prediction time: 1019.7846803665161 seconds
2024-07-31 03:02:54 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on name - nationality
2024-07-31 03:02:54 root INFO     building operator name - nationality
2024-07-31 03:02:54 root INFO     [order_1_approx] starting weight calculation for hitler was german
strauss was austrian
stalin was soviet
raphael was italian
maxwell was scottish
dostoyevsky was russian
euclid was greek
leibniz was
2024-07-31 03:02:54 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 03:05:00 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3223, -0.0429, -0.1077,  ..., -0.1125, -0.2935,  0.3069],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.4062, -4.4883,  1.2607,  ..., -3.2578, -1.5430, -1.1016],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0840, -0.0022, -0.0052,  ..., -0.0036,  0.0135, -0.0059],
        [-0.0024,  0.0699,  0.0196,  ...,  0.0069, -0.0035, -0.0117],
        [ 0.0187,  0.0027,  0.0688,  ...,  0.0130,  0.0143,  0.0135],
        ...,
        [-0.0018, -0.0041, -0.0015,  ...,  0.0621, -0.0098,  0.0072],
        [ 0.0210,  0.0253,  0.0041,  ...,  0.0029,  0.0606, -0.0054],
        [-0.0185, -0.0014, -0.0067,  ...,  0.0081, -0.0155,  0.0851]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.6943, -5.0312,  0.8452,  ..., -3.3535, -1.5273, -1.8965]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 03:05:01 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for hitler was german
strauss was austrian
stalin was soviet
raphael was italian
maxwell was scottish
dostoyevsky was russian
euclid was greek
leibniz was
2024-07-31 03:05:01 root INFO     [order_1_approx] starting weight calculation for hitler was german
euclid was greek
maxwell was scottish
leibniz was german
raphael was italian
strauss was austrian
stalin was soviet
dostoyevsky was
2024-07-31 03:05:01 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 03:07:05 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0574, -0.0682, -0.4604,  ..., -0.5132, -0.5210, -0.1460],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.5752, -2.6953,  1.4492,  ..., -7.3398, -0.9863, -1.0391],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 7.5073e-02, -6.0921e-03,  7.1106e-03,  ..., -2.3849e-02,
         -6.0349e-03, -8.7051e-03],
        [ 3.5143e-04,  5.2795e-02,  1.0498e-02,  ...,  1.6541e-02,
          1.7147e-03, -1.6922e-02],
        [-4.7722e-03, -4.3411e-03,  4.5959e-02,  ...,  2.5360e-02,
         -6.2943e-05,  1.4984e-02],
        ...,
        [-4.2267e-03, -1.3199e-02, -1.1894e-02,  ...,  4.5624e-02,
          1.1292e-02, -2.3499e-03],
        [ 1.4511e-02,  1.5450e-02,  1.9493e-03,  ..., -1.3840e-02,
          5.5298e-02,  3.1490e-03],
        [-2.6291e-02, -1.2369e-03, -1.3069e-02,  ...,  2.6993e-02,
         -5.1155e-03,  5.7800e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.7471, -2.7266,  1.4639,  ..., -7.4219, -0.7119, -1.3008]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 03:07:06 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for hitler was german
euclid was greek
maxwell was scottish
leibniz was german
raphael was italian
strauss was austrian
stalin was soviet
dostoyevsky was
2024-07-31 03:07:06 root INFO     [order_1_approx] starting weight calculation for leibniz was german
hitler was german
stalin was soviet
dostoyevsky was russian
maxwell was scottish
strauss was austrian
raphael was italian
euclid was
2024-07-31 03:07:06 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 03:09:11 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.4229, -0.5376, -0.3982,  ..., -0.0747, -0.4272,  0.1476],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.5684, -2.7637,  1.3350,  ..., -4.6016, -0.8359, -0.7959],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.1069, -0.0014, -0.0080,  ..., -0.0257,  0.0073, -0.0199],
        [-0.0045,  0.0798,  0.0312,  ...,  0.0164,  0.0098, -0.0242],
        [-0.0032, -0.0031,  0.0887,  ...,  0.0106, -0.0090,  0.0068],
        ...,
        [ 0.0152, -0.0127, -0.0149,  ...,  0.0771, -0.0020, -0.0176],
        [ 0.0192,  0.0148,  0.0028,  ...,  0.0004,  0.0651, -0.0079],
        [-0.0084,  0.0160,  0.0031,  ...,  0.0206, -0.0079,  0.0942]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.5195, -3.6484,  1.0859,  ..., -5.0234, -0.6494, -1.2988]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 03:09:12 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for leibniz was german
hitler was german
stalin was soviet
dostoyevsky was russian
maxwell was scottish
strauss was austrian
raphael was italian
euclid was
2024-07-31 03:09:12 root INFO     [order_1_approx] starting weight calculation for hitler was german
strauss was austrian
leibniz was german
dostoyevsky was russian
raphael was italian
maxwell was scottish
euclid was greek
stalin was
2024-07-31 03:09:12 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 03:11:10 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1370, -0.5156, -0.1367,  ...,  0.5049, -0.4668,  0.2394],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.1641, -1.8447,  0.1021,  ..., -3.5527, -0.5840, -0.6924],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 9.7229e-02, -3.2673e-03,  2.4834e-03,  ..., -9.0027e-03,
          9.0790e-04,  5.3482e-03],
        [-7.6294e-05,  6.4758e-02,  8.8501e-03,  ...,  1.6144e-02,
          2.4414e-03, -4.3152e-02],
        [ 1.5205e-02, -1.7380e-02,  7.2144e-02,  ...,  1.8723e-02,
          1.3458e-02,  2.3636e-02],
        ...,
        [ 5.7106e-03, -1.2512e-02, -1.4526e-02,  ...,  1.1023e-01,
         -2.3712e-02, -2.5902e-03],
        [ 6.2523e-03,  1.7151e-02,  1.1749e-02,  ..., -8.6670e-03,
          6.5857e-02,  1.3876e-03],
        [-1.6388e-02,  1.0170e-02, -2.0706e-02,  ...,  2.8061e-02,
         -1.1826e-02,  7.1777e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.1602, -1.9023, -0.1846,  ..., -3.9805, -0.3491, -0.7051]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 03:11:11 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for hitler was german
strauss was austrian
leibniz was german
dostoyevsky was russian
raphael was italian
maxwell was scottish
euclid was greek
stalin was
2024-07-31 03:11:12 root INFO     [order_1_approx] starting weight calculation for hitler was german
stalin was soviet
raphael was italian
euclid was greek
maxwell was scottish
dostoyevsky was russian
leibniz was german
strauss was
2024-07-31 03:11:12 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 03:13:14 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0826, -0.3379,  0.1785,  ...,  0.0332, -0.2230, -0.2773],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.0918, -5.5781,  0.2114,  ..., -3.8359, -0.7744, -0.9092],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0841,  0.0003, -0.0080,  ..., -0.0288, -0.0249,  0.0047],
        [ 0.0047,  0.0699, -0.0040,  ...,  0.0139, -0.0094, -0.0211],
        [ 0.0216,  0.0074,  0.0613,  ...,  0.0082,  0.0014,  0.0212],
        ...,
        [-0.0042,  0.0016, -0.0176,  ...,  0.0917,  0.0085,  0.0146],
        [ 0.0251,  0.0272, -0.0101,  ..., -0.0168,  0.0580, -0.0196],
        [-0.0039, -0.0039, -0.0121,  ...,  0.0084, -0.0168,  0.0878]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.3389, -5.7305, -0.1882,  ..., -4.3086, -0.1045, -1.1045]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 03:13:15 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for hitler was german
stalin was soviet
raphael was italian
euclid was greek
maxwell was scottish
dostoyevsky was russian
leibniz was german
strauss was
2024-07-31 03:13:15 root INFO     [order_1_approx] starting weight calculation for dostoyevsky was russian
leibniz was german
hitler was german
euclid was greek
strauss was austrian
raphael was italian
stalin was soviet
maxwell was
2024-07-31 03:13:15 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 03:15:17 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.4558, -0.3579, -0.0110,  ...,  0.2314, -0.2047,  0.2817],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.7393, -2.8398, -0.5679,  ..., -3.9688, -1.3887, -1.8828],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0847,  0.0314, -0.0161,  ..., -0.0410,  0.0057, -0.0262],
        [ 0.0041,  0.0869,  0.0201,  ...,  0.0430, -0.0225,  0.0004],
        [ 0.0273,  0.0030,  0.0604,  ...,  0.0042,  0.0134,  0.0144],
        ...,
        [ 0.0017, -0.0110,  0.0018,  ...,  0.0645,  0.0050, -0.0015],
        [ 0.0062,  0.0148, -0.0136,  ...,  0.0015,  0.0687, -0.0009],
        [-0.0197,  0.0172, -0.0073,  ...,  0.0138, -0.0088,  0.1080]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.1797, -3.5254, -0.6670,  ..., -3.8398, -1.2061, -1.8359]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 03:15:18 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for dostoyevsky was russian
leibniz was german
hitler was german
euclid was greek
strauss was austrian
raphael was italian
stalin was soviet
maxwell was
2024-07-31 03:15:18 root INFO     [order_1_approx] starting weight calculation for dostoyevsky was russian
stalin was soviet
hitler was german
strauss was austrian
euclid was greek
leibniz was german
maxwell was scottish
raphael was
2024-07-31 03:15:18 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 03:17:23 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.4453, -0.2019, -0.1027,  ..., -0.3293, -0.2556,  0.1587],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.7695, -4.3047,  2.0020,  ..., -4.4727, -1.3984, -1.2871],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 9.2957e-02,  1.6418e-02, -1.7365e-02,  ..., -1.1101e-03,
         -2.3842e-05, -4.2000e-03],
        [ 2.5101e-02,  7.9407e-02,  2.2202e-02,  ..., -3.7354e-02,
          1.9333e-02, -2.8152e-02],
        [ 3.0060e-02, -8.9417e-03,  4.7241e-02,  ...,  4.7791e-02,
          8.9569e-03,  1.6541e-02],
        ...,
        [ 3.5629e-03, -4.0131e-03, -9.0027e-04,  ...,  5.5511e-02,
          1.6602e-02, -8.7814e-03],
        [ 1.0757e-02,  8.7280e-03,  1.7517e-02,  ..., -4.3793e-02,
          7.0801e-02,  1.2405e-02],
        [-4.8065e-03,  8.4763e-03,  1.1627e-02,  ..., -4.8889e-02,
         -8.2169e-03,  7.1594e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.9141, -3.4180,  1.4043,  ..., -3.8008, -1.1230, -1.0439]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 03:17:24 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for dostoyevsky was russian
stalin was soviet
hitler was german
strauss was austrian
euclid was greek
leibniz was german
maxwell was scottish
raphael was
2024-07-31 03:17:24 root INFO     [order_1_approx] starting weight calculation for stalin was soviet
raphael was italian
maxwell was scottish
euclid was greek
strauss was austrian
leibniz was german
dostoyevsky was russian
hitler was
2024-07-31 03:17:24 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 03:19:29 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4429, -0.2025, -0.1948,  ...,  0.6680, -0.0507,  0.2932],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.3071, -5.2344, -0.7139,  ..., -2.7656, -1.3604, -1.9531],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0720,  0.0022,  0.0043,  ..., -0.0195,  0.0078,  0.0067],
        [ 0.0054,  0.0446, -0.0057,  ..., -0.0010, -0.0027, -0.0215],
        [ 0.0060, -0.0074,  0.0769,  ..., -0.0141,  0.0100,  0.0189],
        ...,
        [ 0.0060, -0.0130, -0.0080,  ...,  0.0822, -0.0126, -0.0075],
        [ 0.0025,  0.0081,  0.0216,  ..., -0.0145,  0.0618, -0.0047],
        [-0.0121, -0.0125, -0.0177,  ...,  0.0164, -0.0137,  0.0642]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.5820, -5.2656, -0.9834,  ..., -2.7129, -1.2402, -2.0469]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 03:19:30 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for stalin was soviet
raphael was italian
maxwell was scottish
euclid was greek
strauss was austrian
leibniz was german
dostoyevsky was russian
hitler was
2024-07-31 03:19:30 root INFO     total operator prediction time: 995.7263782024384 seconds
2024-07-31 03:19:30 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on UK_city - county
2024-07-31 03:19:30 root INFO     building operator UK_city - county
2024-07-31 03:19:30 root INFO     [order_1_approx] starting weight calculation for In the United Kingdom, the city of carlisle is in the county of cumbria
In the United Kingdom, the city of cardiff is in the county of glamorgan
In the United Kingdom, the city of gloucester is in the county of gloucestershire
In the United Kingdom, the city of wakefield is in the county of yorkshire
In the United Kingdom, the city of crawley is in the county of sussex
In the United Kingdom, the city of hereford is in the county of herefordshire
In the United Kingdom, the city of newcastle is in the county of northumberland
In the United Kingdom, the city of leeds is in the county of
2024-07-31 03:19:30 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 03:22:20 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2512, -0.1880, -0.3047,  ...,  0.2131, -0.2671,  0.4897],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.4141, -4.7305, -1.0264,  ..., -2.1738,  0.3477, -0.9053],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0075,  0.0042,  0.0088,  ..., -0.0075, -0.0073, -0.0131],
        [-0.0061,  0.0147,  0.0076,  ..., -0.0211, -0.0004,  0.0014],
        [-0.0036, -0.0083,  0.0224,  ...,  0.0304, -0.0108, -0.0023],
        ...,
        [ 0.0055, -0.0022, -0.0102,  ...,  0.0445,  0.0011, -0.0014],
        [ 0.0093, -0.0095, -0.0049,  ...,  0.0188,  0.0217,  0.0019],
        [-0.0061, -0.0017, -0.0213,  ..., -0.0206, -0.0117,  0.0270]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.3633, -4.6484, -1.0088,  ..., -1.9277,  0.4956, -0.9507]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 03:22:21 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for In the United Kingdom, the city of carlisle is in the county of cumbria
In the United Kingdom, the city of cardiff is in the county of glamorgan
In the United Kingdom, the city of gloucester is in the county of gloucestershire
In the United Kingdom, the city of wakefield is in the county of yorkshire
In the United Kingdom, the city of crawley is in the county of sussex
In the United Kingdom, the city of hereford is in the county of herefordshire
In the United Kingdom, the city of newcastle is in the county of northumberland
In the United Kingdom, the city of leeds is in the county of
2024-07-31 03:22:22 root INFO     [order_1_approx] starting weight calculation for In the United Kingdom, the city of leeds is in the county of yorkshire
In the United Kingdom, the city of carlisle is in the county of cumbria
In the United Kingdom, the city of newcastle is in the county of northumberland
In the United Kingdom, the city of crawley is in the county of sussex
In the United Kingdom, the city of wakefield is in the county of yorkshire
In the United Kingdom, the city of cardiff is in the county of glamorgan
In the United Kingdom, the city of hereford is in the county of herefordshire
In the United Kingdom, the city of gloucester is in the county of
2024-07-31 03:22:22 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 03:25:15 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2896, -0.2830, -0.1143,  ..., -0.2058, -0.2622,  0.3613],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.2031, -2.1230,  1.2510,  ..., -3.1172,  2.8711, -0.8389],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0041, -0.0023,  0.0107,  ...,  0.0086,  0.0037, -0.0091],
        [ 0.0080,  0.0111, -0.0068,  ...,  0.0029,  0.0026, -0.0068],
        [-0.0025, -0.0043,  0.0124,  ...,  0.0037,  0.0032, -0.0118],
        ...,
        [ 0.0014, -0.0096, -0.0025,  ...,  0.0224,  0.0130, -0.0035],
        [-0.0031,  0.0003,  0.0017,  ..., -0.0004,  0.0018, -0.0029],
        [-0.0027, -0.0103,  0.0017,  ..., -0.0151, -0.0039,  0.0126]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.1484, -2.0469,  1.2129,  ..., -3.0215,  2.9258, -0.9922]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 03:25:16 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for In the United Kingdom, the city of leeds is in the county of yorkshire
In the United Kingdom, the city of carlisle is in the county of cumbria
In the United Kingdom, the city of newcastle is in the county of northumberland
In the United Kingdom, the city of crawley is in the county of sussex
In the United Kingdom, the city of wakefield is in the county of yorkshire
In the United Kingdom, the city of cardiff is in the county of glamorgan
In the United Kingdom, the city of hereford is in the county of herefordshire
In the United Kingdom, the city of gloucester is in the county of
2024-07-31 03:25:16 root INFO     [order_1_approx] starting weight calculation for In the United Kingdom, the city of leeds is in the county of yorkshire
In the United Kingdom, the city of crawley is in the county of sussex
In the United Kingdom, the city of wakefield is in the county of yorkshire
In the United Kingdom, the city of gloucester is in the county of gloucestershire
In the United Kingdom, the city of cardiff is in the county of glamorgan
In the United Kingdom, the city of newcastle is in the county of northumberland
In the United Kingdom, the city of carlisle is in the county of cumbria
In the United Kingdom, the city of hereford is in the county of
2024-07-31 03:25:16 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 03:28:08 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1099, -0.3206,  0.3525,  ...,  0.4343, -0.4028, -0.0499],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.8604, -3.7637,  1.9180,  ..., -2.7695,  0.2578,  0.1650],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0368, -0.0057,  0.0327,  ...,  0.0074, -0.0062, -0.0071],
        [-0.0057,  0.0228,  0.0038,  ...,  0.0277,  0.0045, -0.0100],
        [ 0.0045,  0.0105,  0.0063,  ...,  0.0017,  0.0030, -0.0208],
        ...,
        [ 0.0124, -0.0053, -0.0099,  ...,  0.0478,  0.0084, -0.0033],
        [-0.0249, -0.0098,  0.0023,  ..., -0.0003,  0.0019,  0.0009],
        [ 0.0177,  0.0005, -0.0122,  ..., -0.0128,  0.0029,  0.0139]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.2734, -3.5215,  1.2734,  ..., -2.6504,  0.0592, -0.1638]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 03:28:08 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for In the United Kingdom, the city of leeds is in the county of yorkshire
In the United Kingdom, the city of crawley is in the county of sussex
In the United Kingdom, the city of wakefield is in the county of yorkshire
In the United Kingdom, the city of gloucester is in the county of gloucestershire
In the United Kingdom, the city of cardiff is in the county of glamorgan
In the United Kingdom, the city of newcastle is in the county of northumberland
In the United Kingdom, the city of carlisle is in the county of cumbria
In the United Kingdom, the city of hereford is in the county of
2024-07-31 03:28:09 root INFO     [order_1_approx] starting weight calculation for In the United Kingdom, the city of hereford is in the county of herefordshire
In the United Kingdom, the city of cardiff is in the county of glamorgan
In the United Kingdom, the city of leeds is in the county of yorkshire
In the United Kingdom, the city of crawley is in the county of sussex
In the United Kingdom, the city of wakefield is in the county of yorkshire
In the United Kingdom, the city of carlisle is in the county of cumbria
In the United Kingdom, the city of gloucester is in the county of gloucestershire
In the United Kingdom, the city of newcastle is in the county of
2024-07-31 03:28:09 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 03:31:00 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3184,  0.2939, -0.3774,  ...,  0.3821, -0.4023,  0.2676],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.4355, -1.9355,  2.1602,  ..., -2.0059, -2.7148, -0.8203],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0226, -0.0095,  0.0199,  ..., -0.0041, -0.0041, -0.0140],
        [ 0.0102,  0.0234,  0.0181,  ...,  0.0020,  0.0151, -0.0029],
        [ 0.0026, -0.0072,  0.0237,  ...,  0.0254,  0.0004, -0.0125],
        ...,
        [ 0.0110, -0.0152, -0.0054,  ...,  0.0355, -0.0042,  0.0011],
        [ 0.0107, -0.0075, -0.0057,  ..., -0.0089,  0.0193,  0.0057],
        [ 0.0200, -0.0077, -0.0184,  ..., -0.0138, -0.0187,  0.0290]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.6445, -1.8721,  1.7500,  ..., -2.1836, -1.9570, -0.7632]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 03:31:01 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for In the United Kingdom, the city of hereford is in the county of herefordshire
In the United Kingdom, the city of cardiff is in the county of glamorgan
In the United Kingdom, the city of leeds is in the county of yorkshire
In the United Kingdom, the city of crawley is in the county of sussex
In the United Kingdom, the city of wakefield is in the county of yorkshire
In the United Kingdom, the city of carlisle is in the county of cumbria
In the United Kingdom, the city of gloucester is in the county of gloucestershire
In the United Kingdom, the city of newcastle is in the county of
2024-07-31 03:31:01 root INFO     [order_1_approx] starting weight calculation for In the United Kingdom, the city of crawley is in the county of sussex
In the United Kingdom, the city of leeds is in the county of yorkshire
In the United Kingdom, the city of cardiff is in the county of glamorgan
In the United Kingdom, the city of hereford is in the county of herefordshire
In the United Kingdom, the city of wakefield is in the county of yorkshire
In the United Kingdom, the city of newcastle is in the county of northumberland
In the United Kingdom, the city of gloucester is in the county of gloucestershire
In the United Kingdom, the city of carlisle is in the county of
2024-07-31 03:31:01 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 03:33:53 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3926, -0.0347, -0.3999,  ..., -0.2339, -0.4639,  0.2573],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.3965, -2.8398,  2.0352,  ..., -4.8242,  1.0869,  1.0420],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0057, -0.0009,  0.0172,  ..., -0.0027, -0.0002, -0.0030],
        [ 0.0034,  0.0072,  0.0004,  ..., -0.0013,  0.0007, -0.0055],
        [-0.0093,  0.0009,  0.0205,  ...,  0.0098,  0.0040, -0.0033],
        ...,
        [ 0.0009, -0.0129, -0.0073,  ...,  0.0341,  0.0095,  0.0095],
        [-0.0010, -0.0031, -0.0046,  ..., -0.0058,  0.0034,  0.0025],
        [ 0.0055, -0.0204, -0.0028,  ..., -0.0104, -0.0005,  0.0132]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.3479, -2.7852,  2.0508,  ..., -4.6445,  1.1055,  0.9907]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 03:33:54 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for In the United Kingdom, the city of crawley is in the county of sussex
In the United Kingdom, the city of leeds is in the county of yorkshire
In the United Kingdom, the city of cardiff is in the county of glamorgan
In the United Kingdom, the city of hereford is in the county of herefordshire
In the United Kingdom, the city of wakefield is in the county of yorkshire
In the United Kingdom, the city of newcastle is in the county of northumberland
In the United Kingdom, the city of gloucester is in the county of gloucestershire
In the United Kingdom, the city of carlisle is in the county of
2024-07-31 03:33:54 root INFO     [order_1_approx] starting weight calculation for In the United Kingdom, the city of newcastle is in the county of northumberland
In the United Kingdom, the city of crawley is in the county of sussex
In the United Kingdom, the city of wakefield is in the county of yorkshire
In the United Kingdom, the city of carlisle is in the county of cumbria
In the United Kingdom, the city of hereford is in the county of herefordshire
In the United Kingdom, the city of leeds is in the county of yorkshire
In the United Kingdom, the city of gloucester is in the county of gloucestershire
In the United Kingdom, the city of cardiff is in the county of
2024-07-31 03:33:54 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 03:36:46 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.5400, -0.4509, -0.5225,  ...,  0.1830, -0.0908,  0.2554],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 5.0664, -4.8008,  0.6479,  ..., -2.7773,  0.4805,  0.7246],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0061,  0.0022,  0.0156,  ...,  0.0068, -0.0036,  0.0055],
        [-0.0047, -0.0035,  0.0103,  ..., -0.0031, -0.0046,  0.0020],
        [ 0.0052,  0.0020,  0.0292,  ...,  0.0129,  0.0064, -0.0159],
        ...,
        [ 0.0029, -0.0205, -0.0029,  ...,  0.0225,  0.0021, -0.0053],
        [-0.0061, -0.0050, -0.0074,  ...,  0.0077,  0.0085,  0.0063],
        [-0.0036, -0.0006, -0.0113,  ..., -0.0228, -0.0044,  0.0117]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.8438, -4.6914,  0.3638,  ..., -2.7832,  0.4529,  0.6973]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 03:36:48 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for In the United Kingdom, the city of newcastle is in the county of northumberland
In the United Kingdom, the city of crawley is in the county of sussex
In the United Kingdom, the city of wakefield is in the county of yorkshire
In the United Kingdom, the city of carlisle is in the county of cumbria
In the United Kingdom, the city of hereford is in the county of herefordshire
In the United Kingdom, the city of leeds is in the county of yorkshire
In the United Kingdom, the city of gloucester is in the county of gloucestershire
In the United Kingdom, the city of cardiff is in the county of
2024-07-31 03:36:48 root INFO     [order_1_approx] starting weight calculation for In the United Kingdom, the city of cardiff is in the county of glamorgan
In the United Kingdom, the city of crawley is in the county of sussex
In the United Kingdom, the city of leeds is in the county of yorkshire
In the United Kingdom, the city of gloucester is in the county of gloucestershire
In the United Kingdom, the city of hereford is in the county of herefordshire
In the United Kingdom, the city of newcastle is in the county of northumberland
In the United Kingdom, the city of carlisle is in the county of cumbria
In the United Kingdom, the city of wakefield is in the county of
2024-07-31 03:36:48 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 03:39:40 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3804,  0.0554, -0.4443,  ...,  0.0692, -0.4126,  0.4868],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.4062, -3.4922, -1.0508,  ..., -1.4434,  0.6143, -0.3232],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0181,  0.0042,  0.0140,  ...,  0.0058,  0.0113, -0.0169],
        [-0.0004,  0.0057, -0.0039,  ..., -0.0196,  0.0049, -0.0076],
        [ 0.0024, -0.0122,  0.0145,  ...,  0.0119, -0.0076, -0.0051],
        ...,
        [ 0.0240, -0.0039, -0.0076,  ...,  0.0368,  0.0010, -0.0032],
        [ 0.0035,  0.0012,  0.0047,  ...,  0.0208,  0.0093, -0.0018],
        [-0.0084,  0.0055, -0.0275,  ..., -0.0210, -0.0110,  0.0276]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.3809, -3.4863, -0.9375,  ..., -1.2451,  0.6875, -0.5068]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 03:39:41 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for In the United Kingdom, the city of cardiff is in the county of glamorgan
In the United Kingdom, the city of crawley is in the county of sussex
In the United Kingdom, the city of leeds is in the county of yorkshire
In the United Kingdom, the city of gloucester is in the county of gloucestershire
In the United Kingdom, the city of hereford is in the county of herefordshire
In the United Kingdom, the city of newcastle is in the county of northumberland
In the United Kingdom, the city of carlisle is in the county of cumbria
In the United Kingdom, the city of wakefield is in the county of
2024-07-31 03:39:41 root INFO     [order_1_approx] starting weight calculation for In the United Kingdom, the city of gloucester is in the county of gloucestershire
In the United Kingdom, the city of leeds is in the county of yorkshire
In the United Kingdom, the city of newcastle is in the county of northumberland
In the United Kingdom, the city of hereford is in the county of herefordshire
In the United Kingdom, the city of wakefield is in the county of yorkshire
In the United Kingdom, the city of cardiff is in the county of glamorgan
In the United Kingdom, the city of carlisle is in the county of cumbria
In the United Kingdom, the city of crawley is in the county of
2024-07-31 03:39:41 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 03:42:37 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.5674,  0.0994, -0.5293,  ...,  0.5112, -0.1058,  0.0409],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.7207, -3.5469,  0.0771,  ..., -2.5781,  1.3418, -0.4099],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0349,  0.0101,  0.0095,  ..., -0.0006,  0.0035, -0.0181],
        [ 0.0008,  0.0257,  0.0054,  ...,  0.0075,  0.0078, -0.0071],
        [-0.0149, -0.0281,  0.0099,  ...,  0.0023, -0.0053,  0.0150],
        ...,
        [-0.0001,  0.0066, -0.0115,  ...,  0.0413,  0.0080, -0.0016],
        [-0.0091,  0.0069,  0.0088,  ...,  0.0235,  0.0092, -0.0079],
        [ 0.0111,  0.0142, -0.0269,  ...,  0.0087, -0.0101,  0.0183]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.7520, -3.5859,  0.3352,  ..., -2.8086,  1.1592, -0.7715]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 03:42:38 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for In the United Kingdom, the city of gloucester is in the county of gloucestershire
In the United Kingdom, the city of leeds is in the county of yorkshire
In the United Kingdom, the city of newcastle is in the county of northumberland
In the United Kingdom, the city of hereford is in the county of herefordshire
In the United Kingdom, the city of wakefield is in the county of yorkshire
In the United Kingdom, the city of cardiff is in the county of glamorgan
In the United Kingdom, the city of carlisle is in the county of cumbria
In the United Kingdom, the city of crawley is in the county of
2024-07-31 03:42:38 root INFO     total operator prediction time: 1388.6262216567993 seconds
2024-07-31 03:42:38 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on verb+ment_irreg
2024-07-31 03:42:38 root INFO     building operator verb+ment_irreg
2024-07-31 03:42:39 root INFO     [order_1_approx] starting weight calculation for To acknowledge results in a acknowledgement
To excite results in a excitement
To advertise results in a advertisement
To manage results in a management
To fulfill results in a fulfillment
To enlighten results in a enlightenment
To develop results in a development
To resent results in a
2024-07-31 03:42:39 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 03:44:42 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.3777, -0.1021, -0.8618,  ..., -0.2119,  0.2129, -0.1924],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.1523, -3.7656,  0.0059,  ..., -1.5605,  0.0137, -1.2148],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0665, -0.0056,  0.0041,  ..., -0.0068,  0.0056, -0.0222],
        [ 0.0223,  0.0868, -0.0017,  ...,  0.0039, -0.0008,  0.0165],
        [ 0.0086, -0.0120,  0.0568,  ..., -0.0078, -0.0061, -0.0189],
        ...,
        [ 0.0076,  0.0111,  0.0033,  ...,  0.0774,  0.0034,  0.0188],
        [-0.0014,  0.0010,  0.0100,  ...,  0.0132,  0.0708, -0.0069],
        [ 0.0039, -0.0049, -0.0003,  ...,  0.0030, -0.0289,  0.0917]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.8027, -2.6367,  0.1736,  ..., -0.8486, -0.4790, -1.6445]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 03:44:43 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To acknowledge results in a acknowledgement
To excite results in a excitement
To advertise results in a advertisement
To manage results in a management
To fulfill results in a fulfillment
To enlighten results in a enlightenment
To develop results in a development
To resent results in a
2024-07-31 03:44:43 root INFO     [order_1_approx] starting weight calculation for To resent results in a resentment
To acknowledge results in a acknowledgement
To manage results in a management
To excite results in a excitement
To fulfill results in a fulfillment
To develop results in a development
To advertise results in a advertisement
To enlighten results in a
2024-07-31 03:44:43 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 03:46:45 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0231,  0.4219, -0.1556,  ..., -0.0031, -0.2822, -0.0719],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.0176, -0.3428,  1.6660,  ...,  5.1406, -2.8672, -2.8047],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 3.5645e-02,  5.3406e-03,  6.1836e-03,  ..., -5.5885e-04,
          7.7820e-03, -9.5367e-05],
        [-8.7814e-03,  3.9703e-02,  4.7340e-03,  ...,  1.3535e-02,
         -9.8495e-03,  3.5381e-03],
        [ 4.0512e-03, -1.3870e-02,  3.9276e-02,  ..., -8.0185e-03,
          6.4087e-03, -2.1248e-03],
        ...,
        [ 9.5272e-04, -4.6310e-03, -2.6608e-04,  ...,  4.5227e-02,
          3.3588e-03,  7.4654e-03],
        [-9.8324e-04,  7.1754e-03, -4.3259e-03,  ..., -2.4071e-03,
          3.1067e-02, -1.0406e-02],
        [ 3.2349e-03, -8.6060e-03,  1.5783e-03,  ...,  9.5749e-04,
         -1.4229e-02,  4.2847e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.8721, -0.1863,  1.4355,  ...,  4.9570, -2.8008, -2.9238]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 03:46:46 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To resent results in a resentment
To acknowledge results in a acknowledgement
To manage results in a management
To excite results in a excitement
To fulfill results in a fulfillment
To develop results in a development
To advertise results in a advertisement
To enlighten results in a
2024-07-31 03:46:47 root INFO     [order_1_approx] starting weight calculation for To develop results in a development
To excite results in a excitement
To enlighten results in a enlightenment
To advertise results in a advertisement
To manage results in a management
To resent results in a resentment
To fulfill results in a fulfillment
To acknowledge results in a
2024-07-31 03:46:47 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 03:48:52 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.4365,  0.5640, -0.4089,  ..., -0.3218, -0.2131, -0.4155],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.0703, -1.8340, -0.6118,  ...,  1.4932, -2.3574,  1.1924],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 5.1270e-02,  6.3705e-03, -1.3351e-05,  ..., -3.2196e-03,
          9.5367e-04, -5.5046e-03],
        [-5.0621e-03,  4.9774e-02, -6.8665e-04,  ...,  7.7286e-03,
         -1.2970e-03,  1.2405e-02],
        [ 8.5983e-03, -1.1276e-02,  3.4607e-02,  ..., -4.1962e-03,
         -4.2877e-03, -6.1226e-04],
        ...,
        [-2.7905e-03,  5.4932e-03,  1.5926e-04,  ...,  4.9255e-02,
         -9.1629e-03,  1.3809e-02],
        [-1.0033e-02,  6.7062e-03, -5.7030e-04,  ..., -3.8681e-03,
          4.9408e-02, -5.0087e-03],
        [-1.7624e-03, -5.8517e-03,  8.4152e-03,  ..., -7.4196e-04,
         -1.3657e-02,  4.7394e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.9375, -1.5488, -0.6338,  ...,  1.8574, -2.3203,  0.8130]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 03:48:53 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To develop results in a development
To excite results in a excitement
To enlighten results in a enlightenment
To advertise results in a advertisement
To manage results in a management
To resent results in a resentment
To fulfill results in a fulfillment
To acknowledge results in a
2024-07-31 03:48:53 root INFO     [order_1_approx] starting weight calculation for To excite results in a excitement
To enlighten results in a enlightenment
To advertise results in a advertisement
To develop results in a development
To resent results in a resentment
To acknowledge results in a acknowledgement
To fulfill results in a fulfillment
To manage results in a
2024-07-31 03:48:53 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 03:50:56 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2058,  0.4624, -0.1942,  ...,  0.0271, -0.1505, -0.3208],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.4336, -3.8789,  1.8164,  ...,  2.1113, -2.8633, -4.2188],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0556,  0.0145, -0.0060,  ..., -0.0095,  0.0026,  0.0048],
        [-0.0014,  0.0563,  0.0010,  ...,  0.0308,  0.0004,  0.0086],
        [ 0.0126, -0.0116,  0.0564,  ..., -0.0019, -0.0105, -0.0012],
        ...,
        [ 0.0005,  0.0139,  0.0111,  ...,  0.0659,  0.0026,  0.0066],
        [-0.0067,  0.0076,  0.0101,  ..., -0.0093,  0.0576, -0.0218],
        [ 0.0037, -0.0074,  0.0068,  ..., -0.0070, -0.0193,  0.0570]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.1719, -3.3398,  1.3926,  ...,  2.1973, -2.9238, -4.0000]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 03:50:58 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To excite results in a excitement
To enlighten results in a enlightenment
To advertise results in a advertisement
To develop results in a development
To resent results in a resentment
To acknowledge results in a acknowledgement
To fulfill results in a fulfillment
To manage results in a
2024-07-31 03:50:58 root INFO     [order_1_approx] starting weight calculation for To manage results in a management
To acknowledge results in a acknowledgement
To excite results in a excitement
To fulfill results in a fulfillment
To enlighten results in a enlightenment
To develop results in a development
To resent results in a resentment
To advertise results in a
2024-07-31 03:50:58 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 03:53:01 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 3.2715e-02,  9.1553e-05, -4.7668e-02,  ...,  1.8372e-01,
         4.9561e-01, -4.6143e-02], device='cuda:0', dtype=torch.float16,
       grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.6484, -1.7705,  1.0566,  ...,  3.1973, -3.5879, -2.2266],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 5.7434e-02,  8.3771e-03,  2.6226e-03,  ..., -1.4210e-03,
         -3.7270e-03, -3.6430e-04],
        [-1.1429e-02,  4.2297e-02, -1.9109e-04,  ...,  2.4048e-02,
          5.2528e-03,  5.3139e-03],
        [ 5.4321e-03, -4.1046e-03,  3.8177e-02,  ...,  3.7804e-03,
         -9.5901e-03, -6.8617e-04],
        ...,
        [-3.3474e-04,  3.1128e-03,  9.8419e-03,  ...,  5.5511e-02,
          8.0719e-03,  6.3744e-03],
        [-7.3700e-03,  5.5161e-03, -3.8376e-03,  ...,  9.1457e-04,
          4.6082e-02, -1.1101e-02],
        [ 1.4515e-03, -1.3145e-02, -7.9041e-03,  ..., -6.1989e-06,
         -1.7181e-02,  4.7241e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.2891, -1.2480,  1.2373,  ...,  2.8066, -3.4180, -2.3496]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 03:53:03 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To manage results in a management
To acknowledge results in a acknowledgement
To excite results in a excitement
To fulfill results in a fulfillment
To enlighten results in a enlightenment
To develop results in a development
To resent results in a resentment
To advertise results in a
2024-07-31 03:53:03 root INFO     [order_1_approx] starting weight calculation for To develop results in a development
To advertise results in a advertisement
To resent results in a resentment
To manage results in a management
To enlighten results in a enlightenment
To acknowledge results in a acknowledgement
To fulfill results in a fulfillment
To excite results in a
2024-07-31 03:53:03 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 03:55:12 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.3110, -0.3921, -0.8774,  ..., -0.2273, -0.0645,  0.0928],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.5684, -2.7227, -0.2817,  ...,  2.3789, -0.3442, -1.7373],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0845,  0.0253,  0.0114,  ...,  0.0121,  0.0091, -0.0139],
        [ 0.0010,  0.0813,  0.0251,  ...,  0.0266,  0.0035, -0.0001],
        [ 0.0047, -0.0039,  0.0591,  ..., -0.0075, -0.0046, -0.0073],
        ...,
        [-0.0009,  0.0006,  0.0031,  ...,  0.0786,  0.0040,  0.0096],
        [ 0.0008,  0.0178,  0.0130,  ...,  0.0007,  0.0837, -0.0095],
        [ 0.0069, -0.0143, -0.0054,  ..., -0.0002, -0.0130,  0.0842]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.5703, -2.7754, -0.3281,  ...,  2.1719, -0.4800, -2.1094]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 03:55:12 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To develop results in a development
To advertise results in a advertisement
To resent results in a resentment
To manage results in a management
To enlighten results in a enlightenment
To acknowledge results in a acknowledgement
To fulfill results in a fulfillment
To excite results in a
2024-07-31 03:55:13 root INFO     [order_1_approx] starting weight calculation for To manage results in a management
To fulfill results in a fulfillment
To resent results in a resentment
To excite results in a excitement
To acknowledge results in a acknowledgement
To enlighten results in a enlightenment
To advertise results in a advertisement
To develop results in a
2024-07-31 03:55:13 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 03:57:21 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0778,  0.1841, -0.2837,  ..., -0.0684,  0.2157, -0.6406],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 5.0977, -5.2656,  1.7021,  ...,  4.3164, -3.7012, -2.2852],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0728,  0.0221, -0.0040,  ..., -0.0020, -0.0067,  0.0089],
        [-0.0020,  0.0667,  0.0078,  ...,  0.0294,  0.0089,  0.0010],
        [ 0.0096, -0.0088,  0.0443,  ..., -0.0057, -0.0073, -0.0042],
        ...,
        [-0.0037, -0.0046,  0.0130,  ...,  0.0746, -0.0016,  0.0054],
        [-0.0034, -0.0007,  0.0029,  ...,  0.0034,  0.0463, -0.0107],
        [-0.0036, -0.0107, -0.0067,  ..., -0.0083, -0.0299,  0.0739]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.9766, -4.7109,  1.8271,  ...,  3.9355, -3.7422, -2.0625]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 03:57:22 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To manage results in a management
To fulfill results in a fulfillment
To resent results in a resentment
To excite results in a excitement
To acknowledge results in a acknowledgement
To enlighten results in a enlightenment
To advertise results in a advertisement
To develop results in a
2024-07-31 03:57:22 root INFO     [order_1_approx] starting weight calculation for To acknowledge results in a acknowledgement
To enlighten results in a enlightenment
To resent results in a resentment
To excite results in a excitement
To manage results in a management
To advertise results in a advertisement
To develop results in a development
To fulfill results in a
2024-07-31 03:57:22 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 03:59:26 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2661,  0.1924,  0.0740,  ...,  0.1660, -0.3159, -0.1164],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.5234, -3.7344,  1.9697,  ...,  1.7754, -3.9258, -0.8926],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0963,  0.0092,  0.0175,  ..., -0.0026,  0.0030,  0.0191],
        [-0.0100,  0.0957, -0.0004,  ...,  0.0361,  0.0021, -0.0139],
        [ 0.0267, -0.0094,  0.0555,  ..., -0.0029, -0.0186, -0.0289],
        ...,
        [-0.0160,  0.0040,  0.0083,  ...,  0.0701, -0.0020,  0.0164],
        [-0.0079,  0.0250,  0.0002,  ...,  0.0183,  0.0642, -0.0277],
        [-0.0141, -0.0205, -0.0033,  ..., -0.0188, -0.0206,  0.0950]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.2227, -3.2969,  1.9023,  ...,  1.6113, -3.6777, -1.2891]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 03:59:27 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To acknowledge results in a acknowledgement
To enlighten results in a enlightenment
To resent results in a resentment
To excite results in a excitement
To manage results in a management
To advertise results in a advertisement
To develop results in a development
To fulfill results in a
2024-07-31 03:59:27 root INFO     total operator prediction time: 1009.0646018981934 seconds
2024-07-31 03:59:27 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on noun+less_reg
2024-07-31 03:59:27 root INFO     building operator noun+less_reg
2024-07-31 03:59:28 root INFO     [order_1_approx] starting weight calculation for Something without tooth is toothless
Something without art is artless
Something without guilt is guiltless
Something without bone is boneless
Something without home is homeless
Something without faith is faithless
Something without spine is spineless
Something without death is
2024-07-31 03:59:28 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 04:01:31 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0476, -0.5791,  0.0913,  ..., -0.2109,  0.2642,  0.0269],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.8716, -3.9707, -1.5430,  ..., -2.6250, -2.7812, -2.3926],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0120, -0.0046, -0.0011,  ...,  0.0212,  0.0217,  0.0036],
        [ 0.0021,  0.0409, -0.0043,  ..., -0.0078,  0.0046, -0.0164],
        [ 0.0212, -0.0007,  0.0260,  ...,  0.0057, -0.0037, -0.0013],
        ...,
        [-0.0090,  0.0145,  0.0023,  ...,  0.0251,  0.0033, -0.0047],
        [-0.0100,  0.0003,  0.0089,  ..., -0.0033,  0.0490, -0.0211],
        [ 0.0045, -0.0041,  0.0144,  ...,  0.0125, -0.0033,  0.0258]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.3506, -3.5059, -1.6182,  ..., -2.3789, -3.0098, -2.0859]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 04:01:32 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Something without tooth is toothless
Something without art is artless
Something without guilt is guiltless
Something without bone is boneless
Something without home is homeless
Something without faith is faithless
Something without spine is spineless
Something without death is
2024-07-31 04:01:32 root INFO     [order_1_approx] starting weight calculation for Something without tooth is toothless
Something without death is deathless
Something without faith is faithless
Something without bone is boneless
Something without spine is spineless
Something without guilt is guiltless
Something without art is artless
Something without home is
2024-07-31 04:01:32 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 04:03:37 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1193, -0.0962, -0.3093,  ..., -0.3296,  0.1426,  0.0704],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.6895, -2.6797, -2.0742,  ..., -2.3301, -2.4629,  1.8428],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0268, -0.0094,  0.0099,  ...,  0.0046,  0.0093,  0.0110],
        [ 0.0028,  0.0401, -0.0021,  ..., -0.0125,  0.0139, -0.0038],
        [ 0.0142, -0.0018,  0.0273,  ...,  0.0109, -0.0181,  0.0065],
        ...,
        [-0.0139,  0.0035, -0.0061,  ...,  0.0237,  0.0057,  0.0019],
        [-0.0032,  0.0246, -0.0039,  ...,  0.0065,  0.0293, -0.0206],
        [ 0.0153,  0.0043,  0.0091,  ...,  0.0099, -0.0146,  0.0349]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.8730, -2.6641, -2.3535,  ..., -2.0781, -2.6934,  1.7812]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 04:03:38 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Something without tooth is toothless
Something without death is deathless
Something without faith is faithless
Something without bone is boneless
Something without spine is spineless
Something without guilt is guiltless
Something without art is artless
Something without home is
2024-07-31 04:03:38 root INFO     [order_1_approx] starting weight calculation for Something without home is homeless
Something without spine is spineless
Something without death is deathless
Something without bone is boneless
Something without faith is faithless
Something without guilt is guiltless
Something without art is artless
Something without tooth is
2024-07-31 04:03:38 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 04:05:41 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2126, -0.1969,  0.2471,  ..., -0.1344, -0.0550,  0.2603],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.0479, -3.6797, -2.7129,  ..., -1.6836, -6.1172, -1.2285],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0406, -0.0063,  0.0058,  ..., -0.0056, -0.0067,  0.0157],
        [ 0.0188,  0.0616, -0.0155,  ...,  0.0112,  0.0238, -0.0150],
        [ 0.0409,  0.0019,  0.0423,  ..., -0.0024,  0.0071,  0.0108],
        ...,
        [ 0.0064,  0.0229, -0.0021,  ...,  0.0696,  0.0221,  0.0009],
        [-0.0044,  0.0092,  0.0162,  ..., -0.0098,  0.0376, -0.0009],
        [ 0.0125,  0.0007,  0.0033,  ...,  0.0139, -0.0081,  0.0341]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.8413, -3.3496, -2.8281,  ..., -1.3145, -6.3555, -1.5762]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 04:05:42 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Something without home is homeless
Something without spine is spineless
Something without death is deathless
Something without bone is boneless
Something without faith is faithless
Something without guilt is guiltless
Something without art is artless
Something without tooth is
2024-07-31 04:05:42 root INFO     [order_1_approx] starting weight calculation for Something without death is deathless
Something without art is artless
Something without bone is boneless
Something without home is homeless
Something without faith is faithless
Something without guilt is guiltless
Something without tooth is toothless
Something without spine is
2024-07-31 04:05:42 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 04:07:48 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2457, -0.5918, -0.4468,  ...,  0.3208,  0.0722,  0.5078],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.2266, -2.2031, -2.2148,  ..., -2.0020, -2.6016, -1.0400],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0491,  0.0069,  0.0169,  ...,  0.0009,  0.0152,  0.0236],
        [ 0.0173,  0.0663,  0.0016,  ...,  0.0038,  0.0251,  0.0045],
        [ 0.0335,  0.0119,  0.0403,  ...,  0.0057,  0.0057, -0.0030],
        ...,
        [ 0.0143,  0.0144,  0.0104,  ...,  0.0504,  0.0273, -0.0081],
        [-0.0098,  0.0188, -0.0004,  ..., -0.0043,  0.0361, -0.0219],
        [-0.0043, -0.0042, -0.0005,  ...,  0.0211,  0.0034,  0.0309]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.2793, -2.2246, -2.5703,  ..., -1.6387, -2.7812, -0.5801]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 04:07:49 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Something without death is deathless
Something without art is artless
Something without bone is boneless
Something without home is homeless
Something without faith is faithless
Something without guilt is guiltless
Something without tooth is toothless
Something without spine is
2024-07-31 04:07:49 root INFO     [order_1_approx] starting weight calculation for Something without tooth is toothless
Something without home is homeless
Something without death is deathless
Something without faith is faithless
Something without spine is spineless
Something without art is artless
Something without bone is boneless
Something without guilt is
2024-07-31 04:07:49 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 04:09:53 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1412, -0.0146, -0.3887,  ...,  0.2148,  0.2209,  0.5479],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.9102, -2.3086,  0.4180,  ..., -2.8359, -1.7520, -0.8203],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0415, -0.0045,  0.0053,  ...,  0.0056,  0.0013,  0.0101],
        [ 0.0064,  0.0448,  0.0009,  ...,  0.0147,  0.0037,  0.0018],
        [ 0.0242, -0.0211,  0.0379,  ...,  0.0098, -0.0075, -0.0068],
        ...,
        [-0.0157,  0.0098,  0.0015,  ...,  0.0429,  0.0167,  0.0022],
        [ 0.0010,  0.0014, -0.0027,  ..., -0.0034,  0.0423, -0.0123],
        [ 0.0344, -0.0005,  0.0251,  ...,  0.0127, -0.0046,  0.0461]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.5801, -2.4531,  0.0337,  ..., -2.3359, -2.1875, -0.6328]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 04:09:54 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Something without tooth is toothless
Something without home is homeless
Something without death is deathless
Something without faith is faithless
Something without spine is spineless
Something without art is artless
Something without bone is boneless
Something without guilt is
2024-07-31 04:09:54 root INFO     [order_1_approx] starting weight calculation for Something without tooth is toothless
Something without faith is faithless
Something without spine is spineless
Something without death is deathless
Something without guilt is guiltless
Something without art is artless
Something without home is homeless
Something without bone is
2024-07-31 04:09:54 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 04:11:58 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4707, -0.0280, -0.6133,  ...,  0.0480, -0.4292,  0.8125],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.2878, -1.6562, -0.2412,  ..., -2.4141, -2.0566, -1.3350],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 4.9652e-02, -2.3407e-02, -4.8943e-03,  ..., -4.3488e-03,
          3.5305e-03,  6.6490e-03],
        [ 6.6147e-03,  6.8542e-02,  4.4937e-03,  ...,  5.3902e-03,
          1.4145e-02,  4.4556e-03],
        [ 3.4523e-04,  2.5314e-02,  2.8809e-02,  ...,  1.0712e-02,
          9.2621e-03,  4.2915e-04],
        ...,
        [ 1.5640e-02,  1.9958e-02, -7.2365e-03,  ...,  5.9052e-02,
          2.7580e-03, -3.9711e-03],
        [-2.8214e-02,  1.9058e-02, -3.7193e-05,  ..., -2.3712e-02,
          3.7781e-02, -2.6917e-02],
        [ 2.5345e-02,  1.0719e-02,  1.9806e-02,  ...,  2.7710e-02,
         -7.2241e-05,  2.8229e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.4961, -1.7236, -0.6138,  ..., -2.3574, -2.0703, -1.3164]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 04:11:59 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Something without tooth is toothless
Something without faith is faithless
Something without spine is spineless
Something without death is deathless
Something without guilt is guiltless
Something without art is artless
Something without home is homeless
Something without bone is
2024-07-31 04:11:59 root INFO     [order_1_approx] starting weight calculation for Something without spine is spineless
Something without art is artless
Something without death is deathless
Something without guilt is guiltless
Something without bone is boneless
Something without home is homeless
Something without tooth is toothless
Something without faith is
2024-07-31 04:11:59 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 04:14:02 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3652, -0.2725, -0.1360,  ..., -0.1149, -0.1006,  0.8662],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.4492, -3.0781, -0.4102,  ..., -0.3762, -4.4766, -0.5811],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0464,  0.0005,  0.0071,  ..., -0.0034,  0.0073,  0.0117],
        [-0.0049,  0.0491, -0.0092,  ...,  0.0164,  0.0037, -0.0126],
        [ 0.0298, -0.0120,  0.0373,  ..., -0.0053,  0.0039,  0.0038],
        ...,
        [-0.0132,  0.0162, -0.0026,  ...,  0.0187, -0.0007,  0.0112],
        [-0.0102,  0.0108,  0.0052,  ..., -0.0137,  0.0419, -0.0211],
        [ 0.0176,  0.0066,  0.0030,  ...,  0.0075, -0.0168,  0.0366]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.7344, -2.8770, -0.7114,  ..., -0.2188, -4.8594, -0.4436]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 04:14:03 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Something without spine is spineless
Something without art is artless
Something without death is deathless
Something without guilt is guiltless
Something without bone is boneless
Something without home is homeless
Something without tooth is toothless
Something without faith is
2024-07-31 04:14:03 root INFO     [order_1_approx] starting weight calculation for Something without tooth is toothless
Something without bone is boneless
Something without faith is faithless
Something without guilt is guiltless
Something without spine is spineless
Something without death is deathless
Something without home is homeless
Something without art is
2024-07-31 04:14:03 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 04:16:08 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4011, -0.2712,  0.3462,  ..., -0.6216, -0.0526, -0.0609],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.4219, -4.8125,  0.1826,  ..., -2.9180, -4.1133, -0.3037],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 2.4216e-02,  9.4452e-03,  5.7716e-03,  ..., -1.4862e-02,
          1.1581e-02,  4.0932e-03],
        [ 1.8829e-02,  4.5074e-02,  1.3113e-04,  ...,  4.1466e-03,
          3.4409e-03,  2.7924e-03],
        [ 1.8173e-02,  2.3365e-03,  3.6804e-02,  ...,  6.9275e-03,
         -1.1307e-02, -4.7531e-03],
        ...,
        [ 1.8188e-02,  1.7883e-02,  2.9736e-03,  ...,  3.7628e-02,
          1.4542e-02, -2.2411e-05],
        [ 7.2098e-03,  1.1353e-02,  9.7580e-03,  ..., -1.8826e-03,
          4.1992e-02, -1.8829e-02],
        [ 2.2202e-02, -8.4496e-04,  1.2650e-02,  ...,  1.3428e-02,
         -3.3245e-03,  4.6112e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.5508, -4.7930, -0.1658,  ..., -2.8770, -4.0547, -0.5244]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 04:16:09 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Something without tooth is toothless
Something without bone is boneless
Something without faith is faithless
Something without guilt is guiltless
Something without spine is spineless
Something without death is deathless
Something without home is homeless
Something without art is
2024-07-31 04:16:09 root INFO     total operator prediction time: 1001.1522047519684 seconds
2024-07-31 04:16:09 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on adj+ness_reg
2024-07-31 04:16:09 root INFO     building operator adj+ness_reg
2024-07-31 04:16:09 root INFO     [order_1_approx] starting weight calculation for The state of being serious is seriousness
The state of being attractive is attractiveness
The state of being impressive is impressiveness
The state of being rare is rareness
The state of being useful is usefulness
The state of being helpful is helpfulness
The state of being aware is awareness
The state of being sad is
2024-07-31 04:16:09 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 04:18:15 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1066, -0.3142, -0.1768,  ...,  0.1069, -0.4832,  0.3909],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.7910, -4.2578, -0.8237,  ..., -6.4453, -1.7031, -3.3867],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0656,  0.0046, -0.0036,  ...,  0.0019, -0.0026,  0.0028],
        [ 0.0070,  0.0533, -0.0079,  ...,  0.0021,  0.0122, -0.0018],
        [-0.0029, -0.0176,  0.0569,  ...,  0.0215, -0.0103, -0.0215],
        ...,
        [ 0.0025,  0.0111,  0.0078,  ...,  0.0477, -0.0098,  0.0045],
        [ 0.0048,  0.0169, -0.0066,  ...,  0.0261,  0.0589, -0.0078],
        [-0.0026,  0.0117,  0.0012,  ..., -0.0025,  0.0017,  0.0640]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.6973, -3.8887, -1.1709,  ..., -5.9766, -2.0020, -3.2715]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 04:18:16 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The state of being serious is seriousness
The state of being attractive is attractiveness
The state of being impressive is impressiveness
The state of being rare is rareness
The state of being useful is usefulness
The state of being helpful is helpfulness
The state of being aware is awareness
The state of being sad is
2024-07-31 04:18:16 root INFO     [order_1_approx] starting weight calculation for The state of being attractive is attractiveness
The state of being aware is awareness
The state of being sad is sadness
The state of being rare is rareness
The state of being serious is seriousness
The state of being impressive is impressiveness
The state of being useful is usefulness
The state of being helpful is
2024-07-31 04:18:16 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 04:20:25 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0940, -0.2040,  0.5732,  ...,  0.1389, -0.2878,  0.0728],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.2217, -1.1016, -2.0195,  ...,  1.3926, -5.1484, -2.5488],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0244,  0.0232, -0.0020,  ...,  0.0250,  0.0042,  0.0158],
        [ 0.0036,  0.0346,  0.0015,  ...,  0.0222,  0.0059, -0.0005],
        [-0.0069, -0.0234,  0.0465,  ..., -0.0060, -0.0079, -0.0092],
        ...,
        [ 0.0145,  0.0027,  0.0041,  ...,  0.0172, -0.0045,  0.0102],
        [ 0.0066,  0.0119,  0.0080,  ..., -0.0066,  0.0258, -0.0076],
        [ 0.0119,  0.0035, -0.0074,  ..., -0.0028, -0.0090,  0.0345]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.2588, -0.6079, -2.0410,  ...,  1.3477, -5.4102, -2.6738]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 04:20:26 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The state of being attractive is attractiveness
The state of being aware is awareness
The state of being sad is sadness
The state of being rare is rareness
The state of being serious is seriousness
The state of being impressive is impressiveness
The state of being useful is usefulness
The state of being helpful is
2024-07-31 04:20:26 root INFO     [order_1_approx] starting weight calculation for The state of being sad is sadness
The state of being serious is seriousness
The state of being aware is awareness
The state of being rare is rareness
The state of being useful is usefulness
The state of being impressive is impressiveness
The state of being helpful is helpfulness
The state of being attractive is
2024-07-31 04:20:26 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 04:22:32 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2384, -0.3018, -0.2003,  ...,  0.3206,  0.4749, -0.0814],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.0205, -0.7715, -4.0352,  ..., -0.3301, -4.9258, -2.5430],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0482,  0.0003,  0.0089,  ...,  0.0062,  0.0035,  0.0031],
        [-0.0006,  0.0514,  0.0058,  ...,  0.0042,  0.0225, -0.0089],
        [ 0.0003, -0.0063,  0.0389,  ...,  0.0069, -0.0126, -0.0055],
        ...,
        [ 0.0079,  0.0149,  0.0028,  ...,  0.0252,  0.0024, -0.0113],
        [ 0.0015,  0.0169,  0.0070,  ..., -0.0055,  0.0311, -0.0014],
        [ 0.0062,  0.0113, -0.0041,  ...,  0.0028, -0.0030,  0.0396]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.0234, -0.9253, -3.9258,  ..., -0.3936, -4.9922, -2.4805]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 04:22:33 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The state of being sad is sadness
The state of being serious is seriousness
The state of being aware is awareness
The state of being rare is rareness
The state of being useful is usefulness
The state of being impressive is impressiveness
The state of being helpful is helpfulness
The state of being attractive is
2024-07-31 04:22:33 root INFO     [order_1_approx] starting weight calculation for The state of being helpful is helpfulness
The state of being impressive is impressiveness
The state of being useful is usefulness
The state of being serious is seriousness
The state of being rare is rareness
The state of being attractive is attractiveness
The state of being sad is sadness
The state of being aware is
2024-07-31 04:22:33 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 04:24:39 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0724, -0.1123, -0.3313,  ..., -0.1554,  0.1646,  0.0786],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.5645, -2.0586, -0.6865,  ..., -0.7949, -4.2422,  0.4609],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0844, -0.0045, -0.0127,  ...,  0.0224, -0.0075,  0.0167],
        [-0.0020,  0.0535,  0.0050,  ...,  0.0190,  0.0116,  0.0050],
        [ 0.0020, -0.0261,  0.0714,  ..., -0.0081, -0.0145,  0.0235],
        ...,
        [ 0.0175,  0.0223,  0.0066,  ...,  0.0433, -0.0167,  0.0158],
        [ 0.0095,  0.0105,  0.0101,  ..., -0.0125,  0.0530, -0.0161],
        [ 0.0134,  0.0078,  0.0048,  ..., -0.0002, -0.0207,  0.0792]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.9688, -1.7695, -0.6890,  ..., -1.1523, -4.1914,  0.4390]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 04:24:40 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The state of being helpful is helpfulness
The state of being impressive is impressiveness
The state of being useful is usefulness
The state of being serious is seriousness
The state of being rare is rareness
The state of being attractive is attractiveness
The state of being sad is sadness
The state of being aware is
2024-07-31 04:24:41 root INFO     [order_1_approx] starting weight calculation for The state of being serious is seriousness
The state of being sad is sadness
The state of being rare is rareness
The state of being impressive is impressiveness
The state of being helpful is helpfulness
The state of being attractive is attractiveness
The state of being aware is awareness
The state of being useful is
2024-07-31 04:24:41 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 04:26:49 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2971, -0.3010,  0.5508,  ...,  0.4226, -0.5225, -0.2036],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.9141, -1.9414, -1.8018,  ..., -2.3574, -4.5547, -1.6426],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0629,  0.0010, -0.0025,  ...,  0.0095,  0.0090,  0.0094],
        [-0.0025,  0.0677,  0.0086,  ...,  0.0300,  0.0201,  0.0037],
        [ 0.0023, -0.0164,  0.0668,  ..., -0.0095, -0.0017, -0.0087],
        ...,
        [ 0.0202,  0.0122,  0.0245,  ...,  0.0434, -0.0077, -0.0036],
        [-0.0105,  0.0263,  0.0157,  ..., -0.0211,  0.0452, -0.0021],
        [ 0.0180,  0.0078,  0.0062,  ..., -0.0176, -0.0214,  0.0724]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.0801, -1.4365, -1.9912,  ..., -2.4043, -4.7617, -1.5918]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 04:26:50 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The state of being serious is seriousness
The state of being sad is sadness
The state of being rare is rareness
The state of being impressive is impressiveness
The state of being helpful is helpfulness
The state of being attractive is attractiveness
The state of being aware is awareness
The state of being useful is
2024-07-31 04:26:50 root INFO     [order_1_approx] starting weight calculation for The state of being serious is seriousness
The state of being useful is usefulness
The state of being impressive is impressiveness
The state of being attractive is attractiveness
The state of being aware is awareness
The state of being helpful is helpfulness
The state of being sad is sadness
The state of being rare is
2024-07-31 04:26:50 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 04:28:54 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0537, -0.6763, -0.8633,  ..., -0.6094,  0.4038,  0.0671],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.6104, -4.1562, -3.0898,  ..., -5.3398, -5.4648, -5.0156],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0856, -0.0038,  0.0076,  ..., -0.0075, -0.0181, -0.0048],
        [ 0.0057,  0.0749, -0.0045,  ...,  0.0227,  0.0145, -0.0042],
        [ 0.0080, -0.0014,  0.0641,  ...,  0.0033,  0.0142,  0.0119],
        ...,
        [ 0.0338,  0.0280,  0.0151,  ...,  0.0492, -0.0184,  0.0086],
        [-0.0168,  0.0307,  0.0158,  ..., -0.0119,  0.0451,  0.0235],
        [ 0.0471,  0.0146,  0.0058,  ...,  0.0074, -0.0203,  0.0955]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.3633, -4.2617, -2.9238,  ..., -5.4492, -5.6562, -5.1523]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 04:28:55 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The state of being serious is seriousness
The state of being useful is usefulness
The state of being impressive is impressiveness
The state of being attractive is attractiveness
The state of being aware is awareness
The state of being helpful is helpfulness
The state of being sad is sadness
The state of being rare is
2024-07-31 04:28:55 root INFO     [order_1_approx] starting weight calculation for The state of being serious is seriousness
The state of being aware is awareness
The state of being useful is usefulness
The state of being helpful is helpfulness
The state of being rare is rareness
The state of being attractive is attractiveness
The state of being sad is sadness
The state of being impressive is
2024-07-31 04:28:56 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 04:31:01 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0785, -0.0031, -0.2979,  ..., -0.2073, -0.0633, -0.0211],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.6680, -1.5010, -2.1953,  ..., -1.1123, -3.4141, -3.9570],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 6.8726e-02,  1.5762e-02,  1.1452e-02,  ..., -2.8019e-03,
         -1.2451e-02,  8.7357e-03],
        [-7.8583e-03,  5.6396e-02,  4.7660e-04,  ...,  6.7902e-03,
          2.5406e-02, -4.5357e-03],
        [ 8.8043e-03, -1.3245e-02,  5.8228e-02,  ..., -7.2212e-03,
         -1.2550e-02, -5.8174e-03],
        ...,
        [ 1.2115e-02,  4.2953e-03,  1.0460e-02,  ...,  4.6082e-02,
          9.7466e-04, -5.5504e-03],
        [ 1.0536e-02,  2.2888e-02,  1.7151e-02,  ..., -1.4709e-02,
          3.1494e-02,  7.7515e-03],
        [-4.0245e-03,  2.5139e-03, -5.7220e-05,  ...,  5.5466e-03,
         -1.5579e-02,  3.6438e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.6797, -1.4902, -2.1035,  ..., -1.1943, -3.3945, -3.6914]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 04:31:02 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The state of being serious is seriousness
The state of being aware is awareness
The state of being useful is usefulness
The state of being helpful is helpfulness
The state of being rare is rareness
The state of being attractive is attractiveness
The state of being sad is sadness
The state of being impressive is
2024-07-31 04:31:02 root INFO     [order_1_approx] starting weight calculation for The state of being sad is sadness
The state of being aware is awareness
The state of being useful is usefulness
The state of being impressive is impressiveness
The state of being attractive is attractiveness
The state of being rare is rareness
The state of being helpful is helpfulness
The state of being serious is
2024-07-31 04:31:02 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 04:33:02 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0178, -0.2216, -0.3145,  ...,  0.1737, -0.9722,  0.6841],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.2598, -2.9062, -2.3730,  ..., -3.8242, -1.8965, -3.5664],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0923, -0.0085, -0.0028,  ..., -0.0071, -0.0050,  0.0254],
        [-0.0007,  0.0691,  0.0049,  ...,  0.0129,  0.0002, -0.0021],
        [ 0.0133, -0.0186,  0.0869,  ...,  0.0041, -0.0023,  0.0010],
        ...,
        [ 0.0102,  0.0185,  0.0124,  ...,  0.0365, -0.0040,  0.0191],
        [-0.0234,  0.0414,  0.0022,  ..., -0.0022,  0.0703, -0.0163],
        [ 0.0225, -0.0138,  0.0151,  ..., -0.0037, -0.0259,  0.0668]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.0967, -2.7656, -2.3828,  ..., -3.8984, -1.7803, -3.2461]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 04:33:03 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The state of being sad is sadness
The state of being aware is awareness
The state of being useful is usefulness
The state of being impressive is impressiveness
The state of being attractive is attractiveness
The state of being rare is rareness
The state of being helpful is helpfulness
The state of being serious is
2024-07-31 04:33:03 root INFO     total operator prediction time: 1014.6095743179321 seconds
2024-07-31 04:33:03 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on re+verb_reg
2024-07-31 04:33:03 root INFO     building operator re+verb_reg
2024-07-31 04:33:03 root INFO     [order_1_approx] starting weight calculation for To unite again is to reunite
To deem again is to redeem
To solve again is to resolve
To interpret again is to reinterpret
To arrange again is to rearrange
To appoint again is to reappoint
To confirm again is to reconfirm
To appear again is to
2024-07-31 04:33:03 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 04:35:09 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0205, -0.0178, -0.2410,  ..., -0.4070, -0.0575, -0.2152],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.7627, -1.7783, -1.2715,  ...,  3.3672, -5.5391, -3.4961],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0936,  0.0028,  0.0143,  ...,  0.0072, -0.0033,  0.0196],
        [ 0.0006,  0.0558, -0.0027,  ...,  0.0204,  0.0067,  0.0015],
        [ 0.0097, -0.0045,  0.0827,  ...,  0.0018, -0.0024, -0.0098],
        ...,
        [-0.0140, -0.0038,  0.0029,  ...,  0.0778, -0.0107,  0.0012],
        [ 0.0001,  0.0286, -0.0009,  ..., -0.0194,  0.0576, -0.0292],
        [ 0.0031, -0.0058,  0.0102,  ..., -0.0091, -0.0247,  0.0820]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.5381, -1.8945, -1.4102,  ...,  3.4375, -5.3633, -3.1777]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 04:35:10 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To unite again is to reunite
To deem again is to redeem
To solve again is to resolve
To interpret again is to reinterpret
To arrange again is to rearrange
To appoint again is to reappoint
To confirm again is to reconfirm
To appear again is to
2024-07-31 04:35:10 root INFO     [order_1_approx] starting weight calculation for To interpret again is to reinterpret
To confirm again is to reconfirm
To solve again is to resolve
To unite again is to reunite
To deem again is to redeem
To appoint again is to reappoint
To appear again is to reappear
To arrange again is to
2024-07-31 04:35:10 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 04:37:15 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3779,  0.1029, -0.2467,  ..., -0.3191, -0.2438, -0.2246],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.1633, -3.7227, -0.1836,  ...,  2.6484, -5.7188, -6.1875],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 8.9478e-02,  6.1073e-03,  1.8372e-02,  ..., -4.0283e-03,
         -8.7128e-03,  2.1194e-02],
        [ 3.2578e-03,  6.6711e-02, -8.5526e-03,  ...,  1.8890e-02,
          6.3438e-03,  1.1406e-02],
        [-7.9632e-04, -1.5335e-03,  6.9153e-02,  ..., -1.4938e-02,
         -1.3857e-03, -1.3626e-02],
        ...,
        [ 2.0416e-02, -9.6321e-04, -4.7417e-03,  ...,  9.0210e-02,
          1.1406e-03, -5.7907e-03],
        [-1.4854e-02,  1.4641e-02,  2.4719e-02,  ...,  4.0016e-03,
          7.0007e-02, -1.2413e-02],
        [ 1.0284e-02, -5.3406e-05, -1.0040e-02,  ..., -1.1658e-02,
         -1.8494e-02,  7.8125e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.3015, -3.9004, -0.3308,  ...,  2.7949, -5.6328, -6.0469]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 04:37:16 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To interpret again is to reinterpret
To confirm again is to reconfirm
To solve again is to resolve
To unite again is to reunite
To deem again is to redeem
To appoint again is to reappoint
To appear again is to reappear
To arrange again is to
2024-07-31 04:37:16 root INFO     [order_1_approx] starting weight calculation for To arrange again is to rearrange
To confirm again is to reconfirm
To deem again is to redeem
To unite again is to reunite
To interpret again is to reinterpret
To appoint again is to reappoint
To appear again is to reappear
To solve again is to
2024-07-31 04:37:16 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 04:39:22 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0413, -0.5254, -0.2581,  ..., -0.4214, -0.7822,  0.4490],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.7344, -1.7402, -1.3086,  ...,  1.4121, -5.1250, -1.7266],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 5.6396e-02,  9.2163e-03,  1.1673e-03,  ..., -6.7444e-03,
         -8.7738e-05,  9.6741e-03],
        [ 1.5472e-02,  5.8044e-02,  3.2158e-03,  ...,  2.3346e-02,
         -6.0959e-03,  9.3155e-03],
        [ 3.0727e-03, -1.2779e-02,  5.1453e-02,  ..., -1.6846e-02,
          8.9264e-03, -2.6611e-02],
        ...,
        [ 1.9882e-02,  4.1504e-03,  1.4290e-02,  ...,  7.8369e-02,
         -1.6222e-03,  1.0872e-02],
        [-1.3153e-02,  1.1528e-02,  6.8817e-03,  ...,  5.5847e-03,
          4.4769e-02, -1.1383e-02],
        [ 7.7209e-03, -6.6147e-03,  1.9104e-02,  ...,  6.6376e-04,
         -1.3885e-02,  6.0669e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.6323, -1.5547, -1.0273,  ...,  1.5049, -5.0000, -1.9404]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 04:39:23 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To arrange again is to rearrange
To confirm again is to reconfirm
To deem again is to redeem
To unite again is to reunite
To interpret again is to reinterpret
To appoint again is to reappoint
To appear again is to reappear
To solve again is to
2024-07-31 04:39:23 root INFO     [order_1_approx] starting weight calculation for To interpret again is to reinterpret
To unite again is to reunite
To arrange again is to rearrange
To solve again is to resolve
To deem again is to redeem
To appoint again is to reappoint
To appear again is to reappear
To confirm again is to
2024-07-31 04:39:23 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 04:41:25 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0035, -0.1053, -0.0786,  ...,  0.3884, -0.2573,  0.1863],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.3809, -3.7734,  1.5439,  ...,  2.5469, -4.4492, -3.5586],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0635, -0.0234,  0.0307,  ...,  0.0030, -0.0026,  0.0245],
        [ 0.0022,  0.0600, -0.0056,  ...,  0.0113, -0.0019,  0.0041],
        [ 0.0092,  0.0070,  0.0507,  ..., -0.0042, -0.0073,  0.0037],
        ...,
        [ 0.0046, -0.0068, -0.0009,  ...,  0.0731,  0.0111,  0.0099],
        [-0.0038,  0.0263,  0.0079,  ..., -0.0015,  0.0380, -0.0098],
        [-0.0039, -0.0003, -0.0065,  ..., -0.0210, -0.0257,  0.0454]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.3252, -3.8828,  1.4707,  ...,  2.7637, -4.5703, -3.4102]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 04:41:26 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To interpret again is to reinterpret
To unite again is to reunite
To arrange again is to rearrange
To solve again is to resolve
To deem again is to redeem
To appoint again is to reappoint
To appear again is to reappear
To confirm again is to
2024-07-31 04:41:26 root INFO     [order_1_approx] starting weight calculation for To unite again is to reunite
To appoint again is to reappoint
To solve again is to resolve
To confirm again is to reconfirm
To interpret again is to reinterpret
To arrange again is to rearrange
To appear again is to reappear
To deem again is to
2024-07-31 04:41:26 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 04:43:30 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0900, -0.1416, -0.0943,  ...,  0.1373, -0.6738,  0.9224],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.6924, -4.3945,  1.3477,  ...,  0.1628, -6.0703, -3.1758],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 7.8857e-02, -1.6830e-02,  2.6810e-02,  ...,  8.0948e-03,
          7.4158e-03,  1.1765e-02],
        [ 1.6754e-02,  7.5012e-02, -2.1088e-02,  ..., -2.2964e-03,
          7.5912e-03, -1.6890e-03],
        [-4.3068e-03, -1.8219e-02,  5.7098e-02,  ..., -1.0010e-02,
         -1.1391e-02, -2.0050e-02],
        ...,
        [ 2.8198e-02,  2.1362e-02, -1.2085e-02,  ...,  8.0994e-02,
          7.7515e-03, -1.8524e-02],
        [-4.5204e-03,  3.8147e-05,  1.3153e-02,  ...,  1.1894e-02,
          6.6284e-02, -1.5854e-02],
        [ 1.2390e-02,  1.3176e-02,  2.4948e-03,  ..., -9.7656e-03,
         -3.2288e-02,  7.5012e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.7109, -3.7520,  1.3340,  ...,  0.9746, -6.1719, -2.9297]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 04:43:31 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To unite again is to reunite
To appoint again is to reappoint
To solve again is to resolve
To confirm again is to reconfirm
To interpret again is to reinterpret
To arrange again is to rearrange
To appear again is to reappear
To deem again is to
2024-07-31 04:43:31 root INFO     [order_1_approx] starting weight calculation for To interpret again is to reinterpret
To solve again is to resolve
To appear again is to reappear
To arrange again is to rearrange
To unite again is to reunite
To deem again is to redeem
To confirm again is to reconfirm
To appoint again is to
2024-07-31 04:43:31 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 04:45:32 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0098,  0.2114, -0.0737,  ...,  0.1261, -0.4399, -0.0782],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.0137, -4.2422, -0.1298,  ...,  2.7227, -5.9375, -5.2188],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0674, -0.0134,  0.0101,  ...,  0.0065, -0.0037,  0.0090],
        [ 0.0217,  0.0440, -0.0006,  ...,  0.0192, -0.0047, -0.0094],
        [ 0.0066, -0.0060,  0.0321,  ...,  0.0034, -0.0143, -0.0084],
        ...,
        [-0.0019, -0.0003, -0.0141,  ...,  0.0683, -0.0119,  0.0093],
        [-0.0124,  0.0063,  0.0005,  ..., -0.0114,  0.0407, -0.0227],
        [ 0.0040, -0.0020, -0.0087,  ..., -0.0063, -0.0182,  0.0712]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.1406, -4.1875, -0.2932,  ...,  2.7715, -5.8125, -5.0352]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 04:45:33 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To interpret again is to reinterpret
To solve again is to resolve
To appear again is to reappear
To arrange again is to rearrange
To unite again is to reunite
To deem again is to redeem
To confirm again is to reconfirm
To appoint again is to
2024-07-31 04:45:34 root INFO     [order_1_approx] starting weight calculation for To solve again is to resolve
To appoint again is to reappoint
To confirm again is to reconfirm
To unite again is to reunite
To deem again is to redeem
To appear again is to reappear
To arrange again is to rearrange
To interpret again is to
2024-07-31 04:45:34 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 04:47:38 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2355, -0.1505,  0.1283,  ..., -0.1191, -0.3699,  0.4685],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.6270, -1.8691,  1.2402,  ..., -0.0068, -3.1523, -5.2305],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0671,  0.0004,  0.0151,  ...,  0.0133, -0.0083,  0.0230],
        [ 0.0112,  0.0556,  0.0097,  ...,  0.0076,  0.0014, -0.0035],
        [-0.0003, -0.0151,  0.0497,  ..., -0.0083,  0.0094, -0.0190],
        ...,
        [ 0.0093,  0.0002, -0.0042,  ...,  0.0798,  0.0008,  0.0008],
        [-0.0148, -0.0026,  0.0128,  ..., -0.0093,  0.0436, -0.0138],
        [-0.0109,  0.0016,  0.0158,  ..., -0.0087, -0.0273,  0.0703]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.5537, -1.6572,  1.1826,  ..., -0.0061, -3.3477, -5.4336]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 04:47:39 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To solve again is to resolve
To appoint again is to reappoint
To confirm again is to reconfirm
To unite again is to reunite
To deem again is to redeem
To appear again is to reappear
To arrange again is to rearrange
To interpret again is to
2024-07-31 04:47:39 root INFO     [order_1_approx] starting weight calculation for To appear again is to reappear
To deem again is to redeem
To interpret again is to reinterpret
To solve again is to resolve
To appoint again is to reappoint
To confirm again is to reconfirm
To arrange again is to rearrange
To unite again is to
2024-07-31 04:47:40 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 04:49:45 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4307, -0.2288, -0.1925,  ...,  0.1643, -0.4329,  0.5000],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.6577, -3.2773,  1.0771,  ...,  1.9512, -4.0938, -3.0625],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0730,  0.0023,  0.0139,  ...,  0.0153, -0.0012,  0.0144],
        [ 0.0014,  0.0469, -0.0023,  ...,  0.0044, -0.0162, -0.0019],
        [-0.0025,  0.0032,  0.0492,  ..., -0.0016, -0.0035, -0.0123],
        ...,
        [-0.0049,  0.0108, -0.0007,  ...,  0.0501, -0.0083, -0.0140],
        [-0.0108,  0.0115,  0.0181,  ..., -0.0100,  0.0611, -0.0189],
        [ 0.0085, -0.0113, -0.0002,  ..., -0.0047, -0.0175,  0.0701]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.7705, -3.4824,  1.1084,  ...,  1.9199, -4.0703, -3.2383]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 04:49:46 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To appear again is to reappear
To deem again is to redeem
To interpret again is to reinterpret
To solve again is to resolve
To appoint again is to reappoint
To confirm again is to reconfirm
To arrange again is to rearrange
To unite again is to
2024-07-31 04:49:46 root INFO     total operator prediction time: 1003.028242111206 seconds
2024-07-31 04:49:46 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on un+adj_reg
2024-07-31 04:49:46 root INFO     building operator un+adj_reg
2024-07-31 04:49:46 root INFO     [order_1_approx] starting weight calculation for The opposite of fortunate is unfortunate
The opposite of realistic is unrealistic
The opposite of healthy is unhealthy
The opposite of believable is unbelievable
The opposite of identified is unidentified
The opposite of lawful is unlawful
The opposite of affected is unaffected
The opposite of satisfactory is
2024-07-31 04:49:47 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 04:51:55 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1604,  0.0732, -0.3994,  ..., -0.4790, -0.2498, -0.0751],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.3828, -1.3027,  2.4062,  ..., -1.6309, -2.8516, -0.7349],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0413,  0.0033,  0.0193,  ...,  0.0010,  0.0067,  0.0281],
        [ 0.0020,  0.0752, -0.0199,  ...,  0.0422,  0.0137, -0.0116],
        [ 0.0116, -0.0148,  0.0364,  ..., -0.0099, -0.0202, -0.0033],
        ...,
        [-0.0084,  0.0259,  0.0058,  ...,  0.0418, -0.0032, -0.0113],
        [-0.0076, -0.0060,  0.0295,  ..., -0.0162,  0.0288,  0.0182],
        [-0.0036, -0.0061, -0.0328,  ..., -0.0013, -0.0022,  0.0483]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.3633, -1.4229,  2.6406,  ..., -1.6631, -2.5703, -0.3054]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 04:51:56 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of fortunate is unfortunate
The opposite of realistic is unrealistic
The opposite of healthy is unhealthy
The opposite of believable is unbelievable
The opposite of identified is unidentified
The opposite of lawful is unlawful
The opposite of affected is unaffected
The opposite of satisfactory is
2024-07-31 04:51:56 root INFO     [order_1_approx] starting weight calculation for The opposite of healthy is unhealthy
The opposite of believable is unbelievable
The opposite of satisfactory is unsatisfactory
The opposite of fortunate is unfortunate
The opposite of affected is unaffected
The opposite of lawful is unlawful
The opposite of realistic is unrealistic
The opposite of identified is
2024-07-31 04:51:56 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 04:54:05 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1052,  0.1548, -0.3682,  ...,  0.2133, -0.4526, -0.4907],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.0723, -0.5791,  1.7090,  ..., -0.2047, -1.4639, -1.2832],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0600,  0.0047,  0.0341,  ..., -0.0092, -0.0017,  0.0400],
        [-0.0248,  0.0882, -0.0526,  ...,  0.0580,  0.0051, -0.0379],
        [ 0.0151, -0.0234,  0.0561,  ...,  0.0132,  0.0081,  0.0150],
        ...,
        [ 0.0032,  0.0173, -0.0288,  ...,  0.1003, -0.0268, -0.0297],
        [ 0.0010, -0.0081,  0.0243,  ...,  0.0029,  0.0560, -0.0189],
        [-0.0105,  0.0043, -0.0242,  ...,  0.0217, -0.0155,  0.0693]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.3267, -0.4966,  1.9561,  ...,  0.0308, -1.1650, -1.3330]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 04:54:06 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of healthy is unhealthy
The opposite of believable is unbelievable
The opposite of satisfactory is unsatisfactory
The opposite of fortunate is unfortunate
The opposite of affected is unaffected
The opposite of lawful is unlawful
The opposite of realistic is unrealistic
The opposite of identified is
2024-07-31 04:54:06 root INFO     [order_1_approx] starting weight calculation for The opposite of believable is unbelievable
The opposite of identified is unidentified
The opposite of lawful is unlawful
The opposite of realistic is unrealistic
The opposite of affected is unaffected
The opposite of fortunate is unfortunate
The opposite of satisfactory is unsatisfactory
The opposite of healthy is
2024-07-31 04:54:06 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 04:56:08 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2844, -0.9292, -0.0965,  ..., -0.3926,  0.0277, -0.1050],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.9062, -1.5957, -0.5444,  ..., -1.6045, -1.7314, -1.1328],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0394,  0.0180, -0.0112,  ...,  0.0042, -0.0210,  0.0077],
        [-0.0056,  0.0420, -0.0034,  ...,  0.0204,  0.0149,  0.0092],
        [ 0.0153,  0.0063,  0.0150,  ..., -0.0083, -0.0238,  0.0028],
        ...,
        [ 0.0177,  0.0424,  0.0085,  ...,  0.0082,  0.0053, -0.0055],
        [-0.0381, -0.0083,  0.0136,  ..., -0.0264,  0.0096, -0.0075],
        [-0.0371, -0.0026, -0.0014,  ..., -0.0111,  0.0096,  0.0221]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.1602, -1.5811,  0.1050,  ..., -1.3301, -1.5439, -1.2021]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 04:56:09 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of believable is unbelievable
The opposite of identified is unidentified
The opposite of lawful is unlawful
The opposite of realistic is unrealistic
The opposite of affected is unaffected
The opposite of fortunate is unfortunate
The opposite of satisfactory is unsatisfactory
The opposite of healthy is
2024-07-31 04:56:09 root INFO     [order_1_approx] starting weight calculation for The opposite of healthy is unhealthy
The opposite of lawful is unlawful
The opposite of satisfactory is unsatisfactory
The opposite of fortunate is unfortunate
The opposite of affected is unaffected
The opposite of believable is unbelievable
The opposite of identified is unidentified
The opposite of realistic is
2024-07-31 04:56:09 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 04:58:13 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1730,  0.0587, -0.4937,  ..., -0.6714, -0.0571, -0.1522],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.0859, -0.6626, -0.7178,  ..., -3.0781, -1.7383, -1.3867],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0600,  0.0123, -0.0076,  ...,  0.0081, -0.0055, -0.0172],
        [-0.0115,  0.0568, -0.0061,  ...,  0.0126,  0.0132, -0.0082],
        [ 0.0107, -0.0230,  0.0346,  ...,  0.0074, -0.0289, -0.0011],
        ...,
        [ 0.0102,  0.0093,  0.0005,  ...,  0.0251, -0.0038, -0.0110],
        [-0.0096,  0.0083,  0.0114,  ..., -0.0100,  0.0336,  0.0015],
        [ 0.0006, -0.0172, -0.0135,  ...,  0.0025, -0.0110,  0.0461]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.2305, -0.8164, -0.6562,  ..., -2.5117, -1.8994, -1.5723]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 04:58:14 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of healthy is unhealthy
The opposite of lawful is unlawful
The opposite of satisfactory is unsatisfactory
The opposite of fortunate is unfortunate
The opposite of affected is unaffected
The opposite of believable is unbelievable
The opposite of identified is unidentified
The opposite of realistic is
2024-07-31 04:58:14 root INFO     [order_1_approx] starting weight calculation for The opposite of healthy is unhealthy
The opposite of identified is unidentified
The opposite of affected is unaffected
The opposite of realistic is unrealistic
The opposite of lawful is unlawful
The opposite of satisfactory is unsatisfactory
The opposite of fortunate is unfortunate
The opposite of believable is
2024-07-31 04:58:14 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 05:00:18 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2002,  0.1267,  0.0614,  ..., -0.2810, -0.2214,  0.3279],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.7197, -3.4062,  0.4287,  ..., -1.7910, -1.6934, -3.3789],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0280,  0.0136, -0.0030,  ...,  0.0033, -0.0017,  0.0069],
        [-0.0044,  0.0358,  0.0061,  ...,  0.0061,  0.0177,  0.0133],
        [-0.0073, -0.0010,  0.0273,  ..., -0.0112, -0.0165, -0.0091],
        ...,
        [ 0.0126,  0.0134, -0.0189,  ...,  0.0195, -0.0050,  0.0051],
        [ 0.0135,  0.0036,  0.0122,  ..., -0.0068,  0.0227, -0.0188],
        [-0.0111,  0.0088, -0.0065,  ..., -0.0062, -0.0041,  0.0294]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.0156, -3.3203,  0.5532,  ..., -1.3320, -1.5566, -3.1504]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 05:00:19 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of healthy is unhealthy
The opposite of identified is unidentified
The opposite of affected is unaffected
The opposite of realistic is unrealistic
The opposite of lawful is unlawful
The opposite of satisfactory is unsatisfactory
The opposite of fortunate is unfortunate
The opposite of believable is
2024-07-31 05:00:19 root INFO     [order_1_approx] starting weight calculation for The opposite of affected is unaffected
The opposite of identified is unidentified
The opposite of satisfactory is unsatisfactory
The opposite of realistic is unrealistic
The opposite of fortunate is unfortunate
The opposite of healthy is unhealthy
The opposite of believable is unbelievable
The opposite of lawful is
2024-07-31 05:00:19 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 05:02:26 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3225,  0.0249, -0.3076,  ..., -0.0814, -0.1356, -0.4604],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.1602, -1.8896,  0.9897,  ...,  2.7344,  0.1992, -0.6787],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0531, -0.0047,  0.0048,  ...,  0.0078,  0.0121,  0.0102],
        [ 0.0203,  0.0524, -0.0148,  ...,  0.0166, -0.0078,  0.0094],
        [-0.0059,  0.0334,  0.0303,  ...,  0.0132, -0.0298, -0.0098],
        ...,
        [ 0.0039,  0.0266, -0.0188,  ...,  0.0141, -0.0210,  0.0016],
        [-0.0237,  0.0068,  0.0220,  ..., -0.0060,  0.0283, -0.0013],
        [ 0.0091,  0.0026, -0.0377,  ..., -0.0152, -0.0161,  0.0661]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.2964, -1.9385,  1.2734,  ...,  3.0488,  0.3779, -1.0420]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 05:02:26 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of affected is unaffected
The opposite of identified is unidentified
The opposite of satisfactory is unsatisfactory
The opposite of realistic is unrealistic
The opposite of fortunate is unfortunate
The opposite of healthy is unhealthy
The opposite of believable is unbelievable
The opposite of lawful is
2024-07-31 05:02:26 root INFO     [order_1_approx] starting weight calculation for The opposite of realistic is unrealistic
The opposite of identified is unidentified
The opposite of lawful is unlawful
The opposite of healthy is unhealthy
The opposite of believable is unbelievable
The opposite of satisfactory is unsatisfactory
The opposite of affected is unaffected
The opposite of fortunate is
2024-07-31 05:02:27 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 05:04:30 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1732,  0.9673, -0.2886,  ..., -0.1775, -0.3494,  0.1794],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.7480,  1.1113, -0.7476,  ..., -1.2061,  0.0400, -3.7891],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0373, -0.0046,  0.0002,  ...,  0.0320,  0.0016,  0.0118],
        [ 0.0015,  0.0316, -0.0006,  ...,  0.0238,  0.0044,  0.0178],
        [ 0.0116, -0.0228,  0.0254,  ..., -0.0062, -0.0132, -0.0185],
        ...,
        [ 0.0243,  0.0335, -0.0022,  ...,  0.0226,  0.0037,  0.0112],
        [ 0.0057, -0.0120,  0.0317,  ...,  0.0023,  0.0354,  0.0003],
        [ 0.0018, -0.0059, -0.0108,  ...,  0.0027,  0.0010,  0.0617]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.5908,  1.0449, -0.5400,  ..., -0.8271,  0.2910, -3.6465]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 05:04:31 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of realistic is unrealistic
The opposite of identified is unidentified
The opposite of lawful is unlawful
The opposite of healthy is unhealthy
The opposite of believable is unbelievable
The opposite of satisfactory is unsatisfactory
The opposite of affected is unaffected
The opposite of fortunate is
2024-07-31 05:04:31 root INFO     [order_1_approx] starting weight calculation for The opposite of satisfactory is unsatisfactory
The opposite of believable is unbelievable
The opposite of healthy is unhealthy
The opposite of fortunate is unfortunate
The opposite of lawful is unlawful
The opposite of realistic is unrealistic
The opposite of identified is unidentified
The opposite of affected is
2024-07-31 05:04:31 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 05:06:37 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2137, -0.0630, -0.5312,  ..., -0.6748, -0.2207, -0.0883],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.4766, -0.9897, -0.1279,  ..., -1.9453, -2.4219, -3.4961],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0113, -0.0236, -0.0076,  ..., -0.0190, -0.0321,  0.0396],
        [ 0.0053,  0.1049, -0.0155,  ...,  0.0974,  0.0216, -0.0239],
        [-0.0231, -0.0196,  0.0608,  ...,  0.0120, -0.0016,  0.0366],
        ...,
        [ 0.0610,  0.0514,  0.0022,  ...,  0.0637,  0.0103, -0.0266],
        [ 0.0117, -0.0244,  0.0316,  ...,  0.0114,  0.0531,  0.0072],
        [ 0.0365,  0.0117, -0.0161,  ...,  0.0111,  0.0136,  0.1058]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.2324, -0.8276, -0.7085,  ..., -1.1777, -2.5469, -3.4082]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 05:06:38 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of satisfactory is unsatisfactory
The opposite of believable is unbelievable
The opposite of healthy is unhealthy
The opposite of fortunate is unfortunate
The opposite of lawful is unlawful
The opposite of realistic is unrealistic
The opposite of identified is unidentified
The opposite of affected is
2024-07-31 05:06:38 root INFO     total operator prediction time: 1011.6504483222961 seconds
2024-07-31 05:06:38 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on verb+able_reg
2024-07-31 05:06:38 root INFO     building operator verb+able_reg
2024-07-31 05:06:38 root INFO     [order_1_approx] starting weight calculation for If you can inflate something, that thing is inflatable
If you can represent something, that thing is representable
If you can dispose something, that thing is disposable
If you can contain something, that thing is containable
If you can enjoy something, that thing is enjoyable
If you can discover something, that thing is discoverable
If you can manage something, that thing is manageable
If you can consider something, that thing is
2024-07-31 05:06:38 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 05:08:44 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0506, -0.2000,  0.6191,  ...,  0.1641, -0.0605, -0.2159],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.1113, -0.7549,  1.7832,  ..., -3.0859, -6.6133, -1.8320],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0668,  0.0176, -0.0070,  ..., -0.0084, -0.0102,  0.0213],
        [ 0.0027,  0.0515,  0.0150,  ...,  0.0249,  0.0060,  0.0033],
        [-0.0093, -0.0203,  0.0736,  ...,  0.0186, -0.0162, -0.0281],
        ...,
        [ 0.0162,  0.0128,  0.0171,  ...,  0.0756,  0.0035, -0.0046],
        [ 0.0089, -0.0015,  0.0225,  ..., -0.0309,  0.0561, -0.0145],
        [ 0.0061,  0.0095,  0.0188,  ..., -0.0167, -0.0206,  0.0496]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.1423, -0.6592,  1.5469,  ..., -2.6875, -6.3203, -1.9688]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 05:08:45 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you can inflate something, that thing is inflatable
If you can represent something, that thing is representable
If you can dispose something, that thing is disposable
If you can contain something, that thing is containable
If you can enjoy something, that thing is enjoyable
If you can discover something, that thing is discoverable
If you can manage something, that thing is manageable
If you can consider something, that thing is
2024-07-31 05:08:45 root INFO     [order_1_approx] starting weight calculation for If you can dispose something, that thing is disposable
If you can consider something, that thing is considerable
If you can enjoy something, that thing is enjoyable
If you can contain something, that thing is containable
If you can manage something, that thing is manageable
If you can represent something, that thing is representable
If you can inflate something, that thing is inflatable
If you can discover something, that thing is
2024-07-31 05:08:45 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 05:10:51 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0186, -0.0060,  0.3538,  ..., -0.3528, -0.7397,  0.0201],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.5757, -2.6406,  0.6270,  ..., -2.0234, -6.4609,  0.8633],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0726,  0.0175,  0.0101,  ...,  0.0056,  0.0072,  0.0068],
        [-0.0067,  0.0544,  0.0005,  ...,  0.0165, -0.0068, -0.0024],
        [ 0.0029, -0.0146,  0.0564,  ...,  0.0071, -0.0075, -0.0148],
        ...,
        [ 0.0127,  0.0323,  0.0095,  ...,  0.0583,  0.0155, -0.0081],
        [ 0.0033,  0.0183,  0.0016,  ..., -0.0222,  0.0560, -0.0019],
        [ 0.0214,  0.0014,  0.0195,  ..., -0.0092, -0.0163,  0.0633]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.4587, -2.7617,  0.8730,  ..., -1.7988, -6.4648,  0.5010]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 05:10:52 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you can dispose something, that thing is disposable
If you can consider something, that thing is considerable
If you can enjoy something, that thing is enjoyable
If you can contain something, that thing is containable
If you can manage something, that thing is manageable
If you can represent something, that thing is representable
If you can inflate something, that thing is inflatable
If you can discover something, that thing is
2024-07-31 05:10:52 root INFO     [order_1_approx] starting weight calculation for If you can represent something, that thing is representable
If you can consider something, that thing is considerable
If you can manage something, that thing is manageable
If you can contain something, that thing is containable
If you can inflate something, that thing is inflatable
If you can enjoy something, that thing is enjoyable
If you can discover something, that thing is discoverable
If you can dispose something, that thing is
2024-07-31 05:10:52 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 05:12:56 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1320,  0.1400,  0.0977,  ...,  0.0254, -0.2764,  0.4941],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.5449, -2.5273, -1.4707,  ..., -4.1445, -4.8711, -1.0576],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 5.2917e-02,  1.8494e-02,  3.4008e-03,  ..., -3.8767e-04,
         -1.3161e-03,  2.2583e-02],
        [-2.4490e-03,  5.2826e-02,  1.5747e-02,  ...,  1.3687e-02,
         -3.9291e-03, -1.1368e-02],
        [ 2.9259e-03, -3.5820e-03,  3.1921e-02,  ...,  3.8357e-03,
         -1.4885e-02, -1.5869e-02],
        ...,
        [ 1.1978e-02,  2.3941e-02, -1.0468e-02,  ...,  6.8176e-02,
          1.2070e-02, -1.5572e-02],
        [-7.6294e-05, -3.4237e-03, -1.5915e-02,  ..., -1.1429e-02,
          5.3223e-02, -2.2369e-02],
        [-4.9667e-03, -9.1019e-03,  1.1559e-02,  ..., -1.3168e-02,
         -3.1967e-03,  3.8086e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.7285, -2.4785, -1.2412,  ..., -3.7793, -4.4766, -1.3887]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 05:12:57 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you can represent something, that thing is representable
If you can consider something, that thing is considerable
If you can manage something, that thing is manageable
If you can contain something, that thing is containable
If you can inflate something, that thing is inflatable
If you can enjoy something, that thing is enjoyable
If you can discover something, that thing is discoverable
If you can dispose something, that thing is
2024-07-31 05:12:57 root INFO     [order_1_approx] starting weight calculation for If you can consider something, that thing is considerable
If you can dispose something, that thing is disposable
If you can represent something, that thing is representable
If you can contain something, that thing is containable
If you can discover something, that thing is discoverable
If you can manage something, that thing is manageable
If you can inflate something, that thing is inflatable
If you can enjoy something, that thing is
2024-07-31 05:12:58 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 05:14:55 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.3914, -0.1833,  0.1492,  ..., -0.4451, -0.2041, -0.1093],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.3691, -1.4844, -2.0156,  ..., -2.5742, -7.4375, -2.4668],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 5.3589e-02,  9.3613e-03,  1.5289e-02,  ..., -8.2970e-05,
         -6.6261e-03,  1.7441e-02],
        [-1.1482e-03,  4.9286e-02, -3.4790e-03,  ...,  3.3188e-03,
         -1.3611e-02,  3.9940e-03],
        [-7.6256e-03, -1.7120e-02,  4.5685e-02,  ...,  1.0414e-02,
         -2.0966e-02, -2.8809e-02],
        ...,
        [ 2.1347e-02,  2.1667e-02, -8.2397e-03,  ...,  4.5319e-02,
          1.1566e-02, -6.2561e-03],
        [-3.9635e-03,  6.9046e-03, -6.6986e-03,  ..., -2.7924e-02,
          3.2013e-02, -7.2327e-03],
        [ 1.3313e-03, -6.0272e-03,  2.1629e-03,  ..., -1.0124e-02,
         -1.1452e-02,  4.3610e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.3086, -1.8877, -2.0078,  ..., -2.3672, -7.2031, -2.5879]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 05:14:56 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you can consider something, that thing is considerable
If you can dispose something, that thing is disposable
If you can represent something, that thing is representable
If you can contain something, that thing is containable
If you can discover something, that thing is discoverable
If you can manage something, that thing is manageable
If you can inflate something, that thing is inflatable
If you can enjoy something, that thing is
2024-07-31 05:14:57 root INFO     [order_1_approx] starting weight calculation for If you can dispose something, that thing is disposable
If you can enjoy something, that thing is enjoyable
If you can inflate something, that thing is inflatable
If you can discover something, that thing is discoverable
If you can represent something, that thing is representable
If you can manage something, that thing is manageable
If you can consider something, that thing is considerable
If you can contain something, that thing is
2024-07-31 05:14:57 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 05:16:59 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0938, -0.8735, -0.4165,  ..., -0.1227,  0.3052, -0.4539],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.0146, -0.1697, -0.3623,  ..., -4.8672, -3.9082, -2.9492],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0518, -0.0100, -0.0071,  ..., -0.0064,  0.0120,  0.0235],
        [-0.0037,  0.0587,  0.0006,  ...,  0.0103, -0.0042, -0.0140],
        [-0.0116, -0.0013,  0.0447,  ...,  0.0082, -0.0082, -0.0151],
        ...,
        [ 0.0153,  0.0119,  0.0147,  ...,  0.0344,  0.0093, -0.0157],
        [ 0.0126,  0.0023,  0.0087,  ..., -0.0216,  0.0407, -0.0089],
        [ 0.0105,  0.0065,  0.0024,  ..., -0.0198, -0.0283,  0.0414]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.1670, -0.1066, -0.0559,  ..., -4.8242, -3.7109, -3.0195]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 05:17:00 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you can dispose something, that thing is disposable
If you can enjoy something, that thing is enjoyable
If you can inflate something, that thing is inflatable
If you can discover something, that thing is discoverable
If you can represent something, that thing is representable
If you can manage something, that thing is manageable
If you can consider something, that thing is considerable
If you can contain something, that thing is
2024-07-31 05:17:00 root INFO     [order_1_approx] starting weight calculation for If you can enjoy something, that thing is enjoyable
If you can discover something, that thing is discoverable
If you can consider something, that thing is considerable
If you can manage something, that thing is manageable
If you can inflate something, that thing is inflatable
If you can dispose something, that thing is disposable
If you can contain something, that thing is containable
If you can represent something, that thing is
2024-07-31 05:17:00 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 05:18:58 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2764, -0.2996, -0.0574,  ..., -0.0227,  0.1331, -0.1681],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-2.5371,  1.9150,  1.1846,  ..., -3.0938, -7.0508, -2.3008],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 6.6895e-02, -1.3657e-03,  1.7548e-03,  ...,  2.4376e-03,
         -1.2703e-03,  3.5210e-03],
        [-7.1526e-05,  7.6965e-02,  7.7438e-04,  ...,  7.8583e-03,
         -2.5864e-03,  2.5082e-04],
        [-7.7896e-03, -2.0050e-02,  6.4697e-02,  ...,  7.8201e-04,
         -7.3128e-03, -1.5327e-02],
        ...,
        [ 1.9409e-02,  2.4017e-02,  7.9727e-03,  ...,  8.5083e-02,
          2.9297e-03, -4.6196e-03],
        [-6.5613e-04, -8.5983e-03,  6.7139e-04,  ..., -7.2403e-03,
          5.9387e-02, -1.9836e-02],
        [-5.5656e-03,  6.6414e-03,  1.2222e-02,  ..., -1.6434e-02,
         -2.2079e-02,  7.0679e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-2.5840,  1.6826,  1.2910,  ..., -3.3320, -7.0117, -2.5566]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 05:18:59 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you can enjoy something, that thing is enjoyable
If you can discover something, that thing is discoverable
If you can consider something, that thing is considerable
If you can manage something, that thing is manageable
If you can inflate something, that thing is inflatable
If you can dispose something, that thing is disposable
If you can contain something, that thing is containable
If you can represent something, that thing is
2024-07-31 05:18:59 root INFO     [order_1_approx] starting weight calculation for If you can inflate something, that thing is inflatable
If you can enjoy something, that thing is enjoyable
If you can represent something, that thing is representable
If you can discover something, that thing is discoverable
If you can dispose something, that thing is disposable
If you can contain something, that thing is containable
If you can consider something, that thing is considerable
If you can manage something, that thing is
2024-07-31 05:18:59 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 05:21:02 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1035,  0.3501,  0.1981,  ..., -0.0410, -0.1619, -0.1311],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.3633, -0.6226, -0.1123,  ..., -3.5156, -5.6719, -2.8086],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0520,  0.0109, -0.0096,  ..., -0.0117, -0.0038,  0.0174],
        [-0.0013,  0.0645,  0.0131,  ...,  0.0078,  0.0016, -0.0051],
        [-0.0031, -0.0167,  0.0324,  ..., -0.0033,  0.0100, -0.0184],
        ...,
        [ 0.0255,  0.0140,  0.0087,  ...,  0.0505,  0.0184, -0.0103],
        [-0.0051,  0.0099,  0.0166,  ..., -0.0254,  0.0527, -0.0171],
        [-0.0032,  0.0155,  0.0074,  ..., -0.0248, -0.0258,  0.0276]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.3633, -0.7456,  0.2703,  ..., -3.4805, -5.3164, -3.4727]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 05:21:03 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you can inflate something, that thing is inflatable
If you can enjoy something, that thing is enjoyable
If you can represent something, that thing is representable
If you can discover something, that thing is discoverable
If you can dispose something, that thing is disposable
If you can contain something, that thing is containable
If you can consider something, that thing is considerable
If you can manage something, that thing is
2024-07-31 05:21:03 root INFO     [order_1_approx] starting weight calculation for If you can represent something, that thing is representable
If you can consider something, that thing is considerable
If you can discover something, that thing is discoverable
If you can manage something, that thing is manageable
If you can dispose something, that thing is disposable
If you can enjoy something, that thing is enjoyable
If you can contain something, that thing is containable
If you can inflate something, that thing is
2024-07-31 05:21:03 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 05:23:07 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1648,  0.0258, -0.6646,  ..., -0.0874,  0.3083,  0.8008],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.0547, -0.7539,  0.9937,  ..., -0.9844, -4.6797, -2.5488],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 4.3579e-02,  1.7700e-02, -6.0539e-03,  ...,  1.0780e-02,
          4.5776e-05,  1.3031e-02],
        [ 4.1695e-03,  5.4840e-02,  8.3618e-03,  ...,  1.0727e-02,
         -7.9880e-03,  6.8741e-03],
        [-1.1673e-02, -5.2681e-03,  1.3107e-02,  ..., -3.2234e-03,
          2.5005e-03, -2.4292e-02],
        ...,
        [ 1.3489e-02,  3.4241e-02,  3.9978e-03,  ...,  5.8441e-02,
          1.4343e-03,  5.1117e-04],
        [ 2.3117e-03, -3.0327e-03, -2.4490e-03,  ..., -2.2949e-02,
          5.9814e-02, -1.8219e-02],
        [ 1.5747e-02,  1.2703e-02,  6.5231e-03,  ..., -2.3163e-02,
         -2.0935e-02,  4.2725e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.0957, -1.0791,  1.1523,  ..., -1.0908, -4.6602, -2.6172]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 05:23:08 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you can represent something, that thing is representable
If you can consider something, that thing is considerable
If you can discover something, that thing is discoverable
If you can manage something, that thing is manageable
If you can dispose something, that thing is disposable
If you can enjoy something, that thing is enjoyable
If you can contain something, that thing is containable
If you can inflate something, that thing is
2024-07-31 05:23:08 root INFO     total operator prediction time: 990.0616066455841 seconds
2024-07-31 05:23:08 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on verb+tion_irreg
2024-07-31 05:23:08 root INFO     building operator verb+tion_irreg
2024-07-31 05:23:08 root INFO     [order_1_approx] starting weight calculation for To civilize results in civilization
To minimize results in minimization
To explore results in exploration
To colonize results in colonization
To continue results in continuation
To standardize results in standardization
To declare results in declaration
To illumine results in
2024-07-31 05:23:08 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 05:25:11 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.3250,  0.2644, -0.3335,  ..., -0.3472, -0.1365, -0.1609],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.7861, -0.9536,  3.3086,  ...,  3.6016, -1.6816, -2.2031],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0559,  0.0041,  0.0104,  ..., -0.0047, -0.0067,  0.0018],
        [ 0.0038,  0.0407,  0.0118,  ...,  0.0126, -0.0050,  0.0048],
        [ 0.0004, -0.0047,  0.0408,  ..., -0.0049,  0.0041, -0.0031],
        ...,
        [ 0.0008, -0.0025,  0.0066,  ...,  0.0498, -0.0064,  0.0090],
        [ 0.0037,  0.0055, -0.0032,  ..., -0.0035,  0.0363, -0.0047],
        [-0.0023, -0.0038, -0.0004,  ...,  0.0018, -0.0124,  0.0535]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.8320, -0.9023,  3.3398,  ...,  3.7168, -1.6406, -2.2500]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 05:25:12 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To civilize results in civilization
To minimize results in minimization
To explore results in exploration
To colonize results in colonization
To continue results in continuation
To standardize results in standardization
To declare results in declaration
To illumine results in
2024-07-31 05:25:12 root INFO     [order_1_approx] starting weight calculation for To explore results in exploration
To illumine results in illumination
To colonize results in colonization
To civilize results in civilization
To continue results in continuation
To declare results in declaration
To standardize results in standardization
To minimize results in
2024-07-31 05:25:12 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 05:27:11 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4834, -0.3325, -0.5674,  ..., -0.2725,  0.3052, -0.3789],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.0283, -0.2185,  2.2754,  ..., -0.3293, -3.2949, -3.4688],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0436,  0.0102, -0.0048,  ..., -0.0218,  0.0044,  0.0027],
        [ 0.0044,  0.0551,  0.0011,  ...,  0.0190, -0.0014,  0.0049],
        [-0.0090, -0.0100,  0.0375,  ...,  0.0025,  0.0039, -0.0025],
        ...,
        [-0.0027,  0.0129,  0.0029,  ...,  0.0598, -0.0057,  0.0102],
        [-0.0080,  0.0031, -0.0029,  ..., -0.0049,  0.0504, -0.0078],
        [ 0.0025,  0.0057, -0.0004,  ..., -0.0018, -0.0155,  0.0582]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.2500, -0.1451,  2.3457,  ..., -0.1934, -3.5000, -3.4609]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 05:27:12 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To explore results in exploration
To illumine results in illumination
To colonize results in colonization
To civilize results in civilization
To continue results in continuation
To declare results in declaration
To standardize results in standardization
To minimize results in
2024-07-31 05:27:13 root INFO     [order_1_approx] starting weight calculation for To continue results in continuation
To colonize results in colonization
To minimize results in minimization
To standardize results in standardization
To civilize results in civilization
To illumine results in illumination
To explore results in exploration
To declare results in
2024-07-31 05:27:13 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 05:29:13 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2849, -0.3245,  0.0611,  ...,  0.0706, -0.2700, -0.2817],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.6748, -5.1719,  4.3242,  ...,  2.5684, -3.3848,  0.7090],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.1273,  0.0090,  0.0159,  ..., -0.0269, -0.0152,  0.0210],
        [ 0.0063,  0.1232, -0.0261,  ...,  0.0449, -0.0045, -0.0196],
        [ 0.0069, -0.0153,  0.1129,  ..., -0.0038, -0.0085, -0.0087],
        ...,
        [ 0.0008,  0.0263,  0.0102,  ...,  0.1343, -0.0076,  0.0034],
        [-0.0173,  0.0220,  0.0015,  ...,  0.0009,  0.0909, -0.0080],
        [ 0.0189, -0.0089,  0.0145,  ...,  0.0012, -0.0315,  0.1229]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.8525, -5.1602,  4.2930,  ...,  2.4473, -3.0918,  0.0522]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 05:29:14 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To continue results in continuation
To colonize results in colonization
To minimize results in minimization
To standardize results in standardization
To civilize results in civilization
To illumine results in illumination
To explore results in exploration
To declare results in
2024-07-31 05:29:15 root INFO     [order_1_approx] starting weight calculation for To illumine results in illumination
To standardize results in standardization
To civilize results in civilization
To explore results in exploration
To declare results in declaration
To continue results in continuation
To minimize results in minimization
To colonize results in
2024-07-31 05:29:15 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 05:31:19 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0552,  0.0536, -0.5449,  ..., -0.4131, -0.0233, -0.0346],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-2.1797, -2.2871,  3.5801,  ...,  0.6694, -1.0557, -3.0508],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0656, -0.0059,  0.0056,  ...,  0.0055,  0.0021,  0.0095],
        [ 0.0080,  0.0629, -0.0008,  ...,  0.0147,  0.0115, -0.0015],
        [-0.0035, -0.0043,  0.0434,  ..., -0.0012, -0.0062, -0.0029],
        ...,
        [ 0.0012,  0.0087,  0.0129,  ...,  0.0493, -0.0045,  0.0067],
        [-0.0022,  0.0163, -0.0004,  ...,  0.0026,  0.0594,  0.0020],
        [-0.0006, -0.0038,  0.0047,  ..., -0.0052, -0.0278,  0.0534]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-2.0527, -2.2031,  3.5449,  ...,  0.6196, -0.8105, -3.1426]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 05:31:20 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To illumine results in illumination
To standardize results in standardization
To civilize results in civilization
To explore results in exploration
To declare results in declaration
To continue results in continuation
To minimize results in minimization
To colonize results in
2024-07-31 05:31:20 root INFO     [order_1_approx] starting weight calculation for To standardize results in standardization
To civilize results in civilization
To continue results in continuation
To declare results in declaration
To minimize results in minimization
To illumine results in illumination
To colonize results in colonization
To explore results in
2024-07-31 05:31:20 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 05:33:23 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.3521,  0.2383, -0.2450,  ..., -0.3921, -0.1501, -0.3467],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.6729, -3.3203,  2.8047,  ...,  2.4004, -0.6738, -2.5039],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0660,  0.0090,  0.0029,  ...,  0.0020,  0.0052, -0.0014],
        [ 0.0028,  0.0610,  0.0064,  ...,  0.0159,  0.0100,  0.0126],
        [ 0.0090, -0.0057,  0.0411,  ...,  0.0011, -0.0061, -0.0097],
        ...,
        [-0.0022,  0.0065,  0.0198,  ...,  0.0655, -0.0006,  0.0060],
        [-0.0076,  0.0177, -0.0043,  ...,  0.0143,  0.0858, -0.0106],
        [ 0.0175, -0.0103,  0.0082,  ...,  0.0075, -0.0271,  0.0808]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.8252, -3.0059,  2.8867,  ...,  2.3066, -0.6489, -2.6055]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 05:33:24 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To standardize results in standardization
To civilize results in civilization
To continue results in continuation
To declare results in declaration
To minimize results in minimization
To illumine results in illumination
To colonize results in colonization
To explore results in
2024-07-31 05:33:24 root INFO     [order_1_approx] starting weight calculation for To illumine results in illumination
To continue results in continuation
To colonize results in colonization
To explore results in exploration
To minimize results in minimization
To declare results in declaration
To civilize results in civilization
To standardize results in
2024-07-31 05:33:24 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 05:35:27 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0212,  0.0929, -0.5215,  ..., -0.2257, -0.0592, -0.2991],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.2793, -3.6406,  1.1396,  ...,  1.1924, -2.0566, -2.7031],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0627,  0.0054,  0.0092,  ..., -0.0059,  0.0041, -0.0063],
        [-0.0094,  0.0541,  0.0013,  ...,  0.0080,  0.0048,  0.0112],
        [-0.0054, -0.0030,  0.0428,  ..., -0.0043,  0.0064, -0.0120],
        ...,
        [-0.0069,  0.0068,  0.0076,  ...,  0.0555, -0.0116,  0.0093],
        [-0.0140,  0.0155, -0.0003,  ...,  0.0050,  0.0481, -0.0146],
        [-0.0049, -0.0076,  0.0034,  ...,  0.0055, -0.0250,  0.0643]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.0302, -3.5430,  1.3018,  ...,  1.6152, -2.0410, -2.5938]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 05:35:28 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To illumine results in illumination
To continue results in continuation
To colonize results in colonization
To explore results in exploration
To minimize results in minimization
To declare results in declaration
To civilize results in civilization
To standardize results in
2024-07-31 05:35:28 root INFO     [order_1_approx] starting weight calculation for To illumine results in illumination
To continue results in continuation
To colonize results in colonization
To minimize results in minimization
To explore results in exploration
To standardize results in standardization
To declare results in declaration
To civilize results in
2024-07-31 05:35:28 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 05:37:33 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2583,  0.4705, -0.6387,  ..., -0.4839, -0.4429,  0.2983],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-2.1348, -1.9414,  2.8242,  ...,  1.1191, -0.3850, -1.5674],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0720, -0.0032,  0.0094,  ..., -0.0020, -0.0024,  0.0115],
        [ 0.0084,  0.0539,  0.0025,  ...,  0.0125, -0.0005, -0.0011],
        [-0.0114, -0.0046,  0.0422,  ..., -0.0002,  0.0071, -0.0073],
        ...,
        [ 0.0045,  0.0012, -0.0027,  ...,  0.0681, -0.0014,  0.0092],
        [-0.0037,  0.0080, -0.0028,  ...,  0.0077,  0.0544, -0.0150],
        [ 0.0088, -0.0081, -0.0078,  ...,  0.0012, -0.0280,  0.0674]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-2.2969, -1.8262,  2.6055,  ...,  1.3457, -0.2483, -1.2871]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 05:37:34 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To illumine results in illumination
To continue results in continuation
To colonize results in colonization
To minimize results in minimization
To explore results in exploration
To standardize results in standardization
To declare results in declaration
To civilize results in
2024-07-31 05:37:35 root INFO     [order_1_approx] starting weight calculation for To declare results in declaration
To explore results in exploration
To illumine results in illumination
To civilize results in civilization
To minimize results in minimization
To standardize results in standardization
To colonize results in colonization
To continue results in
2024-07-31 05:37:35 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 05:39:38 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0673, -0.2986, -0.4041,  ..., -0.0344, -0.8096,  0.5010],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.6631, -7.7344,  2.4453,  ...,  1.4453, -1.3281, -2.3906],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0635, -0.0009, -0.0144,  ..., -0.0110, -0.0017, -0.0088],
        [ 0.0268,  0.0764,  0.0061,  ...,  0.0400, -0.0128,  0.0256],
        [-0.0029, -0.0026,  0.0393,  ...,  0.0132, -0.0020, -0.0099],
        ...,
        [ 0.0131,  0.0022,  0.0257,  ...,  0.1014, -0.0048,  0.0225],
        [-0.0182,  0.0137,  0.0127,  ...,  0.0050,  0.0485, -0.0296],
        [ 0.0141,  0.0054,  0.0150,  ...,  0.0033, -0.0323,  0.0978]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.6128, -7.1953,  2.6953,  ...,  1.9473, -1.4990, -2.7090]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 05:39:39 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To declare results in declaration
To explore results in exploration
To illumine results in illumination
To civilize results in civilization
To minimize results in minimization
To standardize results in standardization
To colonize results in colonization
To continue results in
2024-07-31 05:39:39 root INFO     total operator prediction time: 990.7971925735474 seconds
2024-07-31 05:39:39 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on adj+ly_reg
2024-07-31 05:39:39 root INFO     building operator adj+ly_reg
2024-07-31 05:39:39 root INFO     [order_1_approx] starting weight calculation for The adjective form of mental is mentally
The adjective form of federal is federally
The adjective form of increasing is increasingly
The adjective form of regional is regionally
The adjective form of physical is physically
The adjective form of global is globally
The adjective form of creative is creatively
The adjective form of serious is
2024-07-31 05:39:39 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 05:41:46 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1489, -0.1571, -0.3225,  ..., -0.0365, -0.9507,  0.3093],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.2549, -2.1250,  0.0452,  ..., -2.3789, -0.5884, -3.9688],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.1238, -0.0134, -0.0002,  ..., -0.0097,  0.0187,  0.0419],
        [-0.0052,  0.0743,  0.0125,  ..., -0.0048, -0.0020,  0.0028],
        [ 0.0236,  0.0037,  0.0917,  ...,  0.0058, -0.0116,  0.0008],
        ...,
        [-0.0089,  0.0163, -0.0140,  ...,  0.0776, -0.0120,  0.0233],
        [-0.0202,  0.0213, -0.0036,  ...,  0.0056,  0.0735, -0.0047],
        [ 0.0201, -0.0323,  0.0107,  ..., -0.0053, -0.0457,  0.0800]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.7822, -2.0625,  0.0515,  ..., -2.2012, -0.2812, -3.9941]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 05:41:46 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The adjective form of mental is mentally
The adjective form of federal is federally
The adjective form of increasing is increasingly
The adjective form of regional is regionally
The adjective form of physical is physically
The adjective form of global is globally
The adjective form of creative is creatively
The adjective form of serious is
2024-07-31 05:41:47 root INFO     [order_1_approx] starting weight calculation for The adjective form of regional is regionally
The adjective form of physical is physically
The adjective form of global is globally
The adjective form of mental is mentally
The adjective form of increasing is increasingly
The adjective form of federal is federally
The adjective form of serious is seriously
The adjective form of creative is
2024-07-31 05:41:47 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 05:43:51 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1465,  0.2812,  0.2336,  ...,  0.0008, -0.1239, -0.2625],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.9707, -2.2734,  3.5586,  ..., -1.2373,  0.3716,  0.6055],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 8.1604e-02, -1.1581e-02, -9.6893e-04,  ..., -3.4542e-03,
          1.9928e-02,  5.4321e-03],
        [-1.4877e-02,  6.8726e-02,  1.3870e-02,  ..., -5.7220e-04,
          1.8372e-02, -4.9973e-04],
        [ 1.0536e-02, -1.8616e-02,  6.2683e-02,  ...,  9.7733e-03,
          4.7531e-03, -3.8147e-03],
        ...,
        [ 1.8982e-02,  1.5640e-02,  2.3003e-03,  ...,  5.9296e-02,
          1.3237e-03,  6.6528e-03],
        [ 7.6294e-05,  2.7405e-02,  5.9509e-04,  ..., -1.0414e-03,
          4.1901e-02, -2.1042e-02],
        [ 1.2222e-02, -3.5461e-02, -2.2324e-02,  ..., -3.3531e-03,
         -1.0284e-02,  5.3040e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.9780, -2.2852,  3.6230,  ..., -1.1074,  0.2029,  0.5762]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 05:43:52 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The adjective form of regional is regionally
The adjective form of physical is physically
The adjective form of global is globally
The adjective form of mental is mentally
The adjective form of increasing is increasingly
The adjective form of federal is federally
The adjective form of serious is seriously
The adjective form of creative is
2024-07-31 05:43:52 root INFO     [order_1_approx] starting weight calculation for The adjective form of increasing is increasingly
The adjective form of federal is federally
The adjective form of physical is physically
The adjective form of global is globally
The adjective form of serious is seriously
The adjective form of creative is creatively
The adjective form of regional is regionally
The adjective form of mental is
2024-07-31 05:43:52 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 05:45:56 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0037, -0.5918,  0.5259,  ..., -0.7393, -0.8145, -0.1962],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.4160, -0.2722,  2.2422,  ..., -3.0898, -1.9336, -1.8232],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0746, -0.0194, -0.0058,  ...,  0.0031,  0.0069,  0.0072],
        [-0.0129,  0.0938, -0.0055,  ..., -0.0048, -0.0009, -0.0088],
        [-0.0125, -0.0100,  0.0807,  ...,  0.0030,  0.0114,  0.0115],
        ...,
        [ 0.0325,  0.0125,  0.0098,  ...,  0.0927,  0.0007,  0.0120],
        [-0.0106,  0.0168, -0.0012,  ...,  0.0024,  0.0436, -0.0063],
        [ 0.0108, -0.0028,  0.0036,  ...,  0.0122, -0.0262,  0.0631]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.4844, -0.3413,  2.0371,  ..., -2.9121, -1.6689, -1.8896]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 05:45:57 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The adjective form of increasing is increasingly
The adjective form of federal is federally
The adjective form of physical is physically
The adjective form of global is globally
The adjective form of serious is seriously
The adjective form of creative is creatively
The adjective form of regional is regionally
The adjective form of mental is
2024-07-31 05:45:57 root INFO     [order_1_approx] starting weight calculation for The adjective form of creative is creatively
The adjective form of physical is physically
The adjective form of mental is mentally
The adjective form of global is globally
The adjective form of federal is federally
The adjective form of increasing is increasingly
The adjective form of serious is seriously
The adjective form of regional is
2024-07-31 05:45:57 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 05:47:59 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0444,  0.0973, -0.0135,  ..., -0.2463, -0.1388, -0.3672],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.3633, -2.8359,  1.3643,  ..., -4.0586, -0.7729, -1.7070],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 8.3374e-02, -2.6474e-02, -4.5204e-03,  ..., -9.6321e-05,
          1.4198e-02, -1.4030e-02],
        [-8.7051e-03,  9.1064e-02,  1.3687e-02,  ...,  1.2260e-02,
          1.1955e-02, -2.3727e-03],
        [ 2.1576e-02,  5.5008e-03,  7.1655e-02,  ...,  2.4567e-02,
         -1.1307e-02, -1.3763e-02],
        ...,
        [ 1.0780e-02,  3.7041e-03, -2.2415e-02,  ...,  6.3171e-02,
         -2.8992e-04,  1.3840e-02],
        [ 1.8616e-03,  1.0788e-02,  5.1994e-03,  ...,  6.2332e-03,
          8.6670e-02, -1.1818e-02],
        [ 1.6190e-02, -1.5137e-02,  3.3493e-03,  ...,  1.6108e-03,
         -2.4811e-02,  7.9712e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.2510, -3.1914,  1.6230,  ..., -3.6211, -0.8027, -2.1035]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 05:48:00 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The adjective form of creative is creatively
The adjective form of physical is physically
The adjective form of mental is mentally
The adjective form of global is globally
The adjective form of federal is federally
The adjective form of increasing is increasingly
The adjective form of serious is seriously
The adjective form of regional is
2024-07-31 05:48:00 root INFO     [order_1_approx] starting weight calculation for The adjective form of regional is regionally
The adjective form of increasing is increasingly
The adjective form of creative is creatively
The adjective form of mental is mentally
The adjective form of global is globally
The adjective form of federal is federally
The adjective form of serious is seriously
The adjective form of physical is
2024-07-31 05:48:00 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 05:50:06 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1260, -0.0944, -0.2167,  ..., -0.9287, -0.5918, -0.1146],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.0752, -3.3477,  1.0332,  ..., -3.2285, -2.3047, -2.4355],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0765, -0.0276, -0.0036,  ..., -0.0066,  0.0166,  0.0069],
        [-0.0154,  0.1047, -0.0083,  ..., -0.0115,  0.0317, -0.0143],
        [ 0.0250, -0.0055,  0.0781,  ...,  0.0080,  0.0070,  0.0053],
        ...,
        [-0.0081,  0.0129, -0.0227,  ...,  0.0745,  0.0014, -0.0169],
        [-0.0027, -0.0050,  0.0184,  ..., -0.0054,  0.0490, -0.0169],
        [ 0.0046, -0.0017, -0.0156,  ..., -0.0006, -0.0291,  0.0672]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.6963, -2.9844,  1.1006,  ..., -2.6680, -1.9346, -2.5352]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 05:50:07 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The adjective form of regional is regionally
The adjective form of increasing is increasingly
The adjective form of creative is creatively
The adjective form of mental is mentally
The adjective form of global is globally
The adjective form of federal is federally
The adjective form of serious is seriously
The adjective form of physical is
2024-07-31 05:50:07 root INFO     [order_1_approx] starting weight calculation for The adjective form of increasing is increasingly
The adjective form of regional is regionally
The adjective form of serious is seriously
The adjective form of physical is physically
The adjective form of mental is mentally
The adjective form of creative is creatively
The adjective form of global is globally
The adjective form of federal is
2024-07-31 05:50:07 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 05:52:09 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2788,  0.2512, -0.5703,  ..., -0.5273, -0.3833, -0.2690],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.0703, -1.5273,  4.4961,  ..., -1.5830, -1.0244, -1.0957],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0753, -0.0297, -0.0032,  ...,  0.0092,  0.0213,  0.0041],
        [ 0.0044,  0.0855,  0.0164,  ...,  0.0188, -0.0033, -0.0162],
        [ 0.0144,  0.0277,  0.0530,  ...,  0.0028,  0.0069,  0.0007],
        ...,
        [-0.0052,  0.0105, -0.0045,  ...,  0.0707,  0.0297, -0.0033],
        [ 0.0122,  0.0221,  0.0198,  ...,  0.0124,  0.0553, -0.0039],
        [ 0.0142, -0.0167, -0.0073,  ..., -0.0017, -0.0343,  0.0679]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.1270, -1.4531,  4.3125,  ..., -1.4922, -0.8462, -1.4404]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 05:52:11 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The adjective form of increasing is increasingly
The adjective form of regional is regionally
The adjective form of serious is seriously
The adjective form of physical is physically
The adjective form of mental is mentally
The adjective form of creative is creatively
The adjective form of global is globally
The adjective form of federal is
2024-07-31 05:52:11 root INFO     [order_1_approx] starting weight calculation for The adjective form of regional is regionally
The adjective form of physical is physically
The adjective form of mental is mentally
The adjective form of global is globally
The adjective form of serious is seriously
The adjective form of federal is federally
The adjective form of creative is creatively
The adjective form of increasing is
2024-07-31 05:52:11 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 05:54:13 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1992, -0.0895, -0.5117,  ...,  0.1267, -0.1853, -0.4775],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.7803, -2.9414,  0.3594,  ..., -0.6270, -2.0352, -1.9141],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 7.7942e-02, -7.3357e-03, -1.7700e-02,  ...,  9.9373e-04,
          1.2451e-02,  2.2903e-02],
        [ 1.3763e-02,  4.8126e-02,  5.4054e-03,  ...,  1.8417e-02,
          1.6489e-03,  1.5823e-02],
        [ 1.1734e-02,  1.0452e-02,  2.1942e-02,  ..., -1.7586e-03,
         -4.8447e-03, -1.1452e-02],
        ...,
        [-3.3875e-03,  8.3466e-03,  1.4389e-02,  ...,  6.2805e-02,
         -1.3046e-03,  1.5762e-02],
        [-3.0975e-02,  2.7695e-02, -6.3553e-03,  ..., -9.5367e-05,
          5.6915e-02, -1.2306e-02],
        [-9.5749e-03, -7.3776e-03, -4.1847e-03,  ..., -2.4033e-03,
         -1.1520e-02,  3.2166e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.6714, -3.5879,  1.1523,  ..., -0.5659, -1.6719, -1.5391]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 05:54:14 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The adjective form of regional is regionally
The adjective form of physical is physically
The adjective form of mental is mentally
The adjective form of global is globally
The adjective form of serious is seriously
The adjective form of federal is federally
The adjective form of creative is creatively
The adjective form of increasing is
2024-07-31 05:54:14 root INFO     [order_1_approx] starting weight calculation for The adjective form of federal is federally
The adjective form of regional is regionally
The adjective form of serious is seriously
The adjective form of increasing is increasingly
The adjective form of creative is creatively
The adjective form of physical is physically
The adjective form of mental is mentally
The adjective form of global is
2024-07-31 05:54:14 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 05:56:17 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2878,  0.1736,  0.0255,  ..., -0.5444, -0.3521, -0.1582],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.1299, -2.9023,  0.1465,  ..., -2.3965, -1.2881,  0.4785],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0636, -0.0159, -0.0090,  ...,  0.0033, -0.0058,  0.0022],
        [ 0.0103,  0.0911,  0.0289,  ...,  0.0022,  0.0098, -0.0090],
        [ 0.0308,  0.0103,  0.0658,  ...,  0.0066, -0.0044,  0.0159],
        ...,
        [-0.0139,  0.0195,  0.0084,  ...,  0.0511,  0.0055,  0.0176],
        [-0.0021,  0.0144, -0.0044,  ..., -0.0052,  0.0638, -0.0200],
        [ 0.0108, -0.0116,  0.0150,  ..., -0.0007, -0.0159,  0.0591]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.2324, -3.0645,  0.2544,  ..., -2.3164, -1.2988,  0.2583]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 05:56:18 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The adjective form of federal is federally
The adjective form of regional is regionally
The adjective form of serious is seriously
The adjective form of increasing is increasingly
The adjective form of creative is creatively
The adjective form of physical is physically
The adjective form of mental is mentally
The adjective form of global is
2024-07-31 05:56:18 root INFO     total operator prediction time: 998.9970941543579 seconds
2024-07-31 05:56:18 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on over+adj_reg
2024-07-31 05:56:18 root INFO     building operator over+adj_reg
2024-07-31 05:56:18 root INFO     [order_1_approx] starting weight calculation for If something is too shadowed, it is overshadowed
If something is too enthusiastic, it is overenthusiastic
If something is too strained, it is overstrained
If something is too populated, it is overpopulated
If something is too turned, it is overturned
If something is too stretched, it is overstretched
If something is too dressed, it is overdressed
If something is too written, it is
2024-07-31 05:56:18 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 05:58:17 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.4097,  0.0568, -0.4065,  ..., -0.6523, -0.4832,  0.0200],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.3721, -2.8672,  1.0879,  ..., -0.0721, -1.2148, -2.6445],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0830, -0.0105, -0.0051,  ..., -0.0061,  0.0102,  0.0219],
        [-0.0012,  0.0857,  0.0009,  ...,  0.0091, -0.0106, -0.0057],
        [ 0.0129, -0.0185,  0.0856,  ...,  0.0048,  0.0040,  0.0031],
        ...,
        [ 0.0051,  0.0028,  0.0069,  ...,  0.0853,  0.0118, -0.0038],
        [-0.0153,  0.0056,  0.0206,  ..., -0.0049,  0.0822, -0.0261],
        [ 0.0096,  0.0244,  0.0028,  ...,  0.0100, -0.0305,  0.0832]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.7217, -3.1797,  1.1650,  ...,  0.0840, -1.1211, -2.7754]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 05:58:18 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is too shadowed, it is overshadowed
If something is too enthusiastic, it is overenthusiastic
If something is too strained, it is overstrained
If something is too populated, it is overpopulated
If something is too turned, it is overturned
If something is too stretched, it is overstretched
If something is too dressed, it is overdressed
If something is too written, it is
2024-07-31 05:58:18 root INFO     [order_1_approx] starting weight calculation for If something is too stretched, it is overstretched
If something is too shadowed, it is overshadowed
If something is too strained, it is overstrained
If something is too turned, it is overturned
If something is too populated, it is overpopulated
If something is too enthusiastic, it is overenthusiastic
If something is too written, it is overwritten
If something is too dressed, it is
2024-07-31 05:58:18 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 06:00:20 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1047, -0.5215, -0.3503,  ..., -0.2979, -0.7397,  0.6880],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.3076, -4.2031, -1.1465,  ...,  1.2324, -3.6562, -2.7246],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0571, -0.0081, -0.0102,  ..., -0.0082,  0.0147,  0.0049],
        [-0.0023,  0.0516, -0.0023,  ..., -0.0122,  0.0042, -0.0082],
        [ 0.0271, -0.0165,  0.0436,  ..., -0.0135,  0.0048,  0.0062],
        ...,
        [ 0.0060,  0.0065,  0.0130,  ...,  0.0670,  0.0087, -0.0047],
        [-0.0103,  0.0019,  0.0032,  ...,  0.0101,  0.0483, -0.0057],
        [ 0.0029,  0.0052,  0.0088,  ...,  0.0054, -0.0203,  0.0466]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.1008, -4.2578, -1.0381,  ...,  1.4551, -3.2402, -2.7578]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 06:00:21 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is too stretched, it is overstretched
If something is too shadowed, it is overshadowed
If something is too strained, it is overstrained
If something is too turned, it is overturned
If something is too populated, it is overpopulated
If something is too enthusiastic, it is overenthusiastic
If something is too written, it is overwritten
If something is too dressed, it is
2024-07-31 06:00:21 root INFO     [order_1_approx] starting weight calculation for If something is too turned, it is overturned
If something is too dressed, it is overdressed
If something is too strained, it is overstrained
If something is too populated, it is overpopulated
If something is too shadowed, it is overshadowed
If something is too written, it is overwritten
If something is too stretched, it is overstretched
If something is too enthusiastic, it is
2024-07-31 06:00:21 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 06:02:27 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0042, -0.3813, -0.5381,  ..., -0.2423, -0.8926, -0.3950],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.5684, -3.2109,  0.0283,  ...,  0.0493, -2.1328, -2.4609],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0516, -0.0041, -0.0068,  ..., -0.0082,  0.0117,  0.0038],
        [ 0.0063,  0.0473, -0.0011,  ...,  0.0158,  0.0099,  0.0061],
        [ 0.0061, -0.0103,  0.0468,  ...,  0.0077, -0.0009,  0.0019],
        ...,
        [-0.0093,  0.0170,  0.0087,  ...,  0.0602,  0.0068,  0.0044],
        [-0.0032,  0.0015,  0.0148,  ...,  0.0091,  0.0475, -0.0136],
        [ 0.0031, -0.0040,  0.0101,  ...,  0.0010, -0.0176,  0.0497]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.7861, -3.3086,  0.0587,  ...,  0.1643, -2.1094, -2.4277]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 06:02:28 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is too turned, it is overturned
If something is too dressed, it is overdressed
If something is too strained, it is overstrained
If something is too populated, it is overpopulated
If something is too shadowed, it is overshadowed
If something is too written, it is overwritten
If something is too stretched, it is overstretched
If something is too enthusiastic, it is
2024-07-31 06:02:28 root INFO     [order_1_approx] starting weight calculation for If something is too shadowed, it is overshadowed
If something is too enthusiastic, it is overenthusiastic
If something is too stretched, it is overstretched
If something is too populated, it is overpopulated
If something is too strained, it is overstrained
If something is too written, it is overwritten
If something is too dressed, it is overdressed
If something is too turned, it is
2024-07-31 06:02:28 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 06:04:36 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0618, -0.2520, -0.3171,  ...,  0.3772, -0.2031, -0.1284],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.5840, -3.3594,  0.9453,  ...,  0.4250, -0.3533, -1.6074],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 8.9355e-02,  1.6449e-02, -7.8735e-03,  ..., -1.6708e-02,
          6.6223e-03,  2.0187e-02],
        [-2.4796e-03,  7.2266e-02, -2.5238e-02,  ...,  2.5818e-02,
          1.2970e-02, -5.1498e-03],
        [ 5.2673e-02, -3.4546e-02,  1.0437e-01,  ...,  1.7731e-02,
          5.6419e-03, -8.5602e-03],
        ...,
        [ 1.7212e-02,  7.6485e-03,  2.5848e-02,  ...,  1.1023e-01,
          3.2776e-02,  1.3924e-04],
        [-1.2939e-02, -6.4850e-05,  1.0445e-02,  ...,  1.3266e-03,
          7.7393e-02, -4.1412e-02],
        [ 1.1368e-03,  2.6855e-02,  2.0294e-02,  ..., -2.9999e-02,
         -2.8961e-02,  9.2346e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.7363, -3.2109,  0.4326,  ...,  0.3289, -0.2515, -1.9414]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 06:04:37 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is too shadowed, it is overshadowed
If something is too enthusiastic, it is overenthusiastic
If something is too stretched, it is overstretched
If something is too populated, it is overpopulated
If something is too strained, it is overstrained
If something is too written, it is overwritten
If something is too dressed, it is overdressed
If something is too turned, it is
2024-07-31 06:04:37 root INFO     [order_1_approx] starting weight calculation for If something is too shadowed, it is overshadowed
If something is too dressed, it is overdressed
If something is too written, it is overwritten
If something is too strained, it is overstrained
If something is too turned, it is overturned
If something is too populated, it is overpopulated
If something is too enthusiastic, it is overenthusiastic
If something is too stretched, it is
2024-07-31 06:04:37 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 06:06:42 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.5645, -0.9185,  0.1772,  ..., -0.4736,  0.2710,  0.4377],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.2910, -3.7852,  1.0352,  ..., -0.1147,  1.2734, -2.8633],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0554,  0.0094, -0.0094,  ..., -0.0050,  0.0064,  0.0166],
        [ 0.0055,  0.0463, -0.0042,  ...,  0.0087,  0.0024, -0.0047],
        [ 0.0206, -0.0047,  0.0539,  ...,  0.0071,  0.0025, -0.0062],
        ...,
        [ 0.0175,  0.0112,  0.0100,  ...,  0.0724,  0.0101, -0.0069],
        [-0.0049,  0.0157, -0.0074,  ...,  0.0095,  0.0441, -0.0273],
        [-0.0048, -0.0024, -0.0060,  ..., -0.0083, -0.0025,  0.0598]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.3848, -3.8223,  1.0732,  ..., -0.1608,  1.2168, -2.8145]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 06:06:43 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is too shadowed, it is overshadowed
If something is too dressed, it is overdressed
If something is too written, it is overwritten
If something is too strained, it is overstrained
If something is too turned, it is overturned
If something is too populated, it is overpopulated
If something is too enthusiastic, it is overenthusiastic
If something is too stretched, it is
2024-07-31 06:06:43 root INFO     [order_1_approx] starting weight calculation for If something is too dressed, it is overdressed
If something is too populated, it is overpopulated
If something is too stretched, it is overstretched
If something is too enthusiastic, it is overenthusiastic
If something is too written, it is overwritten
If something is too turned, it is overturned
If something is too shadowed, it is overshadowed
If something is too strained, it is
2024-07-31 06:06:43 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 06:08:50 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3594, -0.6079, -0.5063,  ..., -0.6416,  0.1107,  0.1327],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.0020, -3.9023,  0.6875,  ...,  0.2866,  1.8662, -3.1660],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0619, -0.0046, -0.0137,  ..., -0.0032,  0.0090,  0.0164],
        [ 0.0037,  0.0687, -0.0132,  ...,  0.0067, -0.0010, -0.0153],
        [ 0.0296, -0.0152,  0.0717,  ...,  0.0067,  0.0098,  0.0023],
        ...,
        [ 0.0128,  0.0159,  0.0074,  ...,  0.0779,  0.0173, -0.0039],
        [ 0.0053,  0.0089,  0.0063,  ...,  0.0074,  0.0681, -0.0283],
        [-0.0057, -0.0014, -0.0129,  ..., -0.0036, -0.0153,  0.0674]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.2539, -3.8535,  0.5967,  ...,  0.3716,  1.7051, -2.9531]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 06:08:50 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is too dressed, it is overdressed
If something is too populated, it is overpopulated
If something is too stretched, it is overstretched
If something is too enthusiastic, it is overenthusiastic
If something is too written, it is overwritten
If something is too turned, it is overturned
If something is too shadowed, it is overshadowed
If something is too strained, it is
2024-07-31 06:08:51 root INFO     [order_1_approx] starting weight calculation for If something is too stretched, it is overstretched
If something is too enthusiastic, it is overenthusiastic
If something is too strained, it is overstrained
If something is too written, it is overwritten
If something is too dressed, it is overdressed
If something is too populated, it is overpopulated
If something is too turned, it is overturned
If something is too shadowed, it is
2024-07-31 06:08:51 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 06:10:55 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1576, -0.5527, -0.7764,  ..., -0.2524, -0.3125, -0.0636],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.0781, -1.9229,  0.0703,  ..., -0.0342, -0.1990, -2.0957],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0384, -0.0057, -0.0063,  ...,  0.0007, -0.0026,  0.0080],
        [ 0.0099,  0.0442,  0.0071,  ...,  0.0034,  0.0013, -0.0016],
        [ 0.0081, -0.0032,  0.0362,  ...,  0.0010, -0.0021, -0.0007],
        ...,
        [ 0.0015,  0.0116,  0.0072,  ...,  0.0497,  0.0010,  0.0009],
        [ 0.0050,  0.0034, -0.0012,  ...,  0.0024,  0.0445, -0.0114],
        [-0.0043, -0.0052,  0.0002,  ..., -0.0079, -0.0079,  0.0416]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.2998, -2.0508,  0.0745,  ...,  0.1006, -0.0975, -1.9961]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 06:10:56 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is too stretched, it is overstretched
If something is too enthusiastic, it is overenthusiastic
If something is too strained, it is overstrained
If something is too written, it is overwritten
If something is too dressed, it is overdressed
If something is too populated, it is overpopulated
If something is too turned, it is overturned
If something is too shadowed, it is
2024-07-31 06:10:56 root INFO     [order_1_approx] starting weight calculation for If something is too shadowed, it is overshadowed
If something is too strained, it is overstrained
If something is too enthusiastic, it is overenthusiastic
If something is too turned, it is overturned
If something is too written, it is overwritten
If something is too dressed, it is overdressed
If something is too stretched, it is overstretched
If something is too populated, it is
2024-07-31 06:10:56 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 06:12:59 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1337,  0.4202, -0.7515,  ...,  0.1539, -0.5986,  0.0811],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.3779, -2.7539,  0.7358,  ..., -0.5361, -0.2383, -1.9482],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0669, -0.0036, -0.0005,  ..., -0.0035,  0.0122,  0.0182],
        [ 0.0141,  0.0523,  0.0036,  ...,  0.0084,  0.0064,  0.0005],
        [ 0.0070, -0.0037,  0.0477,  ..., -0.0037, -0.0009,  0.0100],
        ...,
        [-0.0157,  0.0016,  0.0219,  ...,  0.0632,  0.0108, -0.0036],
        [-0.0085,  0.0158,  0.0044,  ...,  0.0023,  0.0570, -0.0110],
        [ 0.0047,  0.0073,  0.0141,  ..., -0.0040, -0.0262,  0.0646]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.5303, -2.9238,  0.9238,  ..., -0.3679,  0.0457, -1.9561]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 06:13:00 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is too shadowed, it is overshadowed
If something is too strained, it is overstrained
If something is too enthusiastic, it is overenthusiastic
If something is too turned, it is overturned
If something is too written, it is overwritten
If something is too dressed, it is overdressed
If something is too stretched, it is overstretched
If something is too populated, it is
2024-07-31 06:13:00 root INFO     total operator prediction time: 1001.9905667304993 seconds
2024-07-31 06:13:00 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on verb+er_irreg
2024-07-31 06:13:00 root INFO     building operator verb+er_irreg
2024-07-31 06:13:00 root INFO     [order_1_approx] starting weight calculation for If you recommend something, you are a recommender
If you slay something, you are a slayer
If you organise something, you are a organiser
If you lose something, you are a loser
If you determine something, you are a determiner
If you molest something, you are a molester
If you teach something, you are a teacher
If you preach something, you are a
2024-07-31 06:13:00 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 06:15:01 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0217,  0.0139,  0.2190,  ..., -0.1279, -0.7314,  0.7905],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 5.3828, -6.0977,  2.4844,  ...,  0.4395, -2.8359, -1.1084],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0585, -0.0071,  0.0087,  ...,  0.0138, -0.0038, -0.0118],
        [-0.0006,  0.0569,  0.0088,  ...,  0.0177,  0.0113, -0.0053],
        [ 0.0031,  0.0013,  0.0570,  ...,  0.0145, -0.0136, -0.0082],
        ...,
        [-0.0048,  0.0211, -0.0042,  ...,  0.0712,  0.0116, -0.0083],
        [-0.0132,  0.0164,  0.0067,  ..., -0.0088,  0.0546, -0.0188],
        [-0.0002,  0.0086,  0.0067,  ...,  0.0173, -0.0172,  0.0470]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 5.9609, -5.7969,  2.5391,  ...,  0.9258, -2.9395, -1.1230]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 06:15:02 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you recommend something, you are a recommender
If you slay something, you are a slayer
If you organise something, you are a organiser
If you lose something, you are a loser
If you determine something, you are a determiner
If you molest something, you are a molester
If you teach something, you are a teacher
If you preach something, you are a
2024-07-31 06:15:02 root INFO     [order_1_approx] starting weight calculation for If you teach something, you are a teacher
If you lose something, you are a loser
If you slay something, you are a slayer
If you recommend something, you are a recommender
If you determine something, you are a determiner
If you organise something, you are a organiser
If you preach something, you are a preacher
If you molest something, you are a
2024-07-31 06:15:02 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 06:17:08 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.3469, -0.1583, -0.1393,  ..., -0.6636, -0.2247,  0.1721],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.2461, -3.1035, -1.2402,  ..., -2.2812, -3.3242,  0.0898],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 6.5796e-02,  3.9291e-03,  2.1866e-02,  ...,  1.0391e-02,
          5.1546e-04, -1.6899e-03],
        [-7.2479e-04,  4.4434e-02, -2.6474e-02,  ...,  2.1759e-02,
         -1.5640e-04, -7.0343e-03],
        [ 2.2705e-02, -9.3613e-03,  5.7251e-02,  ...,  1.4420e-02,
          7.7744e-03, -5.9128e-05],
        ...,
        [ 1.2596e-02, -9.3765e-03,  2.5635e-03,  ...,  9.7656e-02,
          1.2192e-02,  5.5923e-03],
        [ 9.3231e-03,  7.1831e-03,  2.5330e-02,  ..., -1.3939e-02,
          5.9753e-02, -2.1149e-02],
        [ 6.6605e-03,  1.5602e-02,  5.1003e-03,  ..., -2.1347e-02,
         -9.7122e-03,  7.1228e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.2734, -2.9961, -0.3618,  ..., -1.7510, -3.1504, -0.3218]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 06:17:09 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you teach something, you are a teacher
If you lose something, you are a loser
If you slay something, you are a slayer
If you recommend something, you are a recommender
If you determine something, you are a determiner
If you organise something, you are a organiser
If you preach something, you are a preacher
If you molest something, you are a
2024-07-31 06:17:09 root INFO     [order_1_approx] starting weight calculation for If you determine something, you are a determiner
If you recommend something, you are a recommender
If you slay something, you are a slayer
If you lose something, you are a loser
If you organise something, you are a organiser
If you molest something, you are a molester
If you preach something, you are a preacher
If you teach something, you are a
2024-07-31 06:17:09 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 06:19:12 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.3262,  0.1021,  0.3567,  ..., -0.5312, -0.4175,  0.2595],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.1797, -3.6914,  4.0273,  ...,  2.2656, -4.5703, -5.4062],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0342,  0.0061,  0.0063,  ..., -0.0032,  0.0010,  0.0005],
        [-0.0050,  0.0488,  0.0002,  ...,  0.0175,  0.0018, -0.0229],
        [ 0.0029, -0.0093,  0.0467,  ...,  0.0020, -0.0090,  0.0077],
        ...,
        [ 0.0085,  0.0180,  0.0019,  ...,  0.0427,  0.0047, -0.0060],
        [-0.0066,  0.0040,  0.0034,  ..., -0.0122,  0.0351, -0.0075],
        [ 0.0035, -0.0021,  0.0242,  ..., -0.0029, -0.0100,  0.0314]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.5703, -3.6719,  4.1797,  ...,  2.6523, -4.5117, -5.3125]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 06:19:13 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you determine something, you are a determiner
If you recommend something, you are a recommender
If you slay something, you are a slayer
If you lose something, you are a loser
If you organise something, you are a organiser
If you molest something, you are a molester
If you preach something, you are a preacher
If you teach something, you are a
2024-07-31 06:19:13 root INFO     [order_1_approx] starting weight calculation for If you preach something, you are a preacher
If you slay something, you are a slayer
If you recommend something, you are a recommender
If you molest something, you are a molester
If you determine something, you are a determiner
If you teach something, you are a teacher
If you lose something, you are a loser
If you organise something, you are a
2024-07-31 06:19:13 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 06:21:16 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2627,  0.6250,  0.0309,  ..., -0.3347,  0.0397, -0.3501],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.5098, -4.8281,  0.8857,  ...,  0.2852, -4.0586, -4.3594],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0742,  0.0105,  0.0102,  ..., -0.0057,  0.0022,  0.0113],
        [ 0.0029,  0.0529,  0.0005,  ...,  0.0202,  0.0148, -0.0203],
        [-0.0042, -0.0104,  0.0299,  ...,  0.0020, -0.0052,  0.0073],
        ...,
        [ 0.0130,  0.0180,  0.0077,  ...,  0.0553,  0.0027, -0.0011],
        [-0.0354,  0.0256,  0.0116,  ..., -0.0168,  0.0499, -0.0056],
        [ 0.0055,  0.0062,  0.0050,  ..., -0.0112, -0.0170,  0.0363]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.3564, -4.9023,  1.0586,  ...,  0.2451, -3.9355, -4.5938]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 06:21:17 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you preach something, you are a preacher
If you slay something, you are a slayer
If you recommend something, you are a recommender
If you molest something, you are a molester
If you determine something, you are a determiner
If you teach something, you are a teacher
If you lose something, you are a loser
If you organise something, you are a
2024-07-31 06:21:17 root INFO     [order_1_approx] starting weight calculation for If you molest something, you are a molester
If you teach something, you are a teacher
If you recommend something, you are a recommender
If you lose something, you are a loser
If you preach something, you are a preacher
If you determine something, you are a determiner
If you organise something, you are a organiser
If you slay something, you are a
2024-07-31 06:21:17 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 06:23:21 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1760, -0.1915, -0.3079,  ..., -0.3228,  0.1004,  0.1243],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.7402, -4.0156, -1.8340,  ..., -4.0938, -2.9453, -2.6348],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0728, -0.0085,  0.0151,  ...,  0.0009, -0.0041,  0.0108],
        [ 0.0019,  0.0386,  0.0051,  ...,  0.0004,  0.0096, -0.0138],
        [-0.0059, -0.0313,  0.0653,  ...,  0.0122, -0.0087, -0.0162],
        ...,
        [-0.0103,  0.0210,  0.0213,  ...,  0.0520,  0.0140,  0.0025],
        [-0.0289,  0.0277,  0.0043,  ..., -0.0182,  0.0678, -0.0168],
        [ 0.0282,  0.0005, -0.0046,  ..., -0.0097,  0.0017,  0.0602]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.9297, -3.9609, -1.2578,  ..., -3.7598, -3.0000, -2.9707]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 06:23:22 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you molest something, you are a molester
If you teach something, you are a teacher
If you recommend something, you are a recommender
If you lose something, you are a loser
If you preach something, you are a preacher
If you determine something, you are a determiner
If you organise something, you are a organiser
If you slay something, you are a
2024-07-31 06:23:23 root INFO     [order_1_approx] starting weight calculation for If you molest something, you are a molester
If you teach something, you are a teacher
If you slay something, you are a slayer
If you lose something, you are a loser
If you recommend something, you are a recommender
If you organise something, you are a organiser
If you preach something, you are a preacher
If you determine something, you are a
2024-07-31 06:23:23 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 06:25:26 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0422, -0.0499,  0.2195,  ...,  0.3252, -0.5049, -0.0663],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.1641, -4.1523,  3.3906,  ..., -0.9707, -5.2109, -4.1250],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 5.3864e-02,  2.0309e-02,  1.1429e-02,  ...,  5.4703e-03,
         -4.0665e-03,  5.5313e-05],
        [ 4.1542e-03,  6.1035e-02,  2.2537e-02,  ...,  2.4017e-02,
         -3.8147e-05, -9.8267e-03],
        [ 2.1088e-02,  3.5896e-03,  4.1534e-02,  ...,  8.1711e-03,
          9.3079e-03, -5.1804e-03],
        ...,
        [ 1.2718e-02,  1.9714e-02,  1.3184e-02,  ...,  6.0883e-02,
         -2.9182e-03,  6.1684e-03],
        [-9.6359e-03, -5.3406e-04,  1.2398e-03,  ..., -1.8723e-02,
          4.2786e-02, -4.6577e-03],
        [ 1.5404e-02,  4.5166e-03,  5.3291e-03,  ..., -8.5602e-03,
         -2.6794e-02,  3.9032e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.3750, -4.3047,  3.6641,  ..., -0.3271, -5.1172, -4.4609]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 06:25:27 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you molest something, you are a molester
If you teach something, you are a teacher
If you slay something, you are a slayer
If you lose something, you are a loser
If you recommend something, you are a recommender
If you organise something, you are a organiser
If you preach something, you are a preacher
If you determine something, you are a
2024-07-31 06:25:27 root INFO     [order_1_approx] starting weight calculation for If you organise something, you are a organiser
If you preach something, you are a preacher
If you teach something, you are a teacher
If you lose something, you are a loser
If you determine something, you are a determiner
If you molest something, you are a molester
If you slay something, you are a slayer
If you recommend something, you are a
2024-07-31 06:25:27 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 06:27:35 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.6997, -0.1677,  0.4307,  ...,  0.1926, -0.0314, -0.4146],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.1406, -3.2070,  1.8418,  ...,  0.6650, -6.7500, -4.4375],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 4.8859e-02, -3.1185e-03,  9.2316e-03,  ...,  1.8707e-02,
         -1.2276e-02,  9.2926e-03],
        [-2.1301e-02,  5.0934e-02,  1.9073e-05,  ...,  2.2491e-02,
          4.7684e-03, -5.3749e-03],
        [ 1.9104e-02, -1.1063e-02,  3.6804e-02,  ...,  4.0970e-03,
         -1.5945e-02,  1.4160e-02],
        ...,
        [-8.1406e-03,  4.8676e-03,  8.5831e-03,  ...,  6.7932e-02,
          7.9269e-03, -1.0086e-02],
        [-4.6310e-03,  7.8964e-03,  1.2405e-02,  ..., -1.6144e-02,
          5.5359e-02, -1.8890e-02],
        [ 1.2871e-02, -6.7234e-04,  1.3123e-03,  ..., -1.7914e-02,
         -2.1759e-02,  3.1921e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.1367, -3.3027,  1.8262,  ...,  1.1992, -6.4414, -4.6992]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 06:27:36 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you organise something, you are a organiser
If you preach something, you are a preacher
If you teach something, you are a teacher
If you lose something, you are a loser
If you determine something, you are a determiner
If you molest something, you are a molester
If you slay something, you are a slayer
If you recommend something, you are a
2024-07-31 06:27:36 root INFO     [order_1_approx] starting weight calculation for If you teach something, you are a teacher
If you recommend something, you are a recommender
If you organise something, you are a organiser
If you slay something, you are a slayer
If you molest something, you are a molester
If you preach something, you are a preacher
If you determine something, you are a determiner
If you lose something, you are a
2024-07-31 06:27:36 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 06:29:44 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.3743,  0.1003,  0.6138,  ..., -0.3359,  0.2991, -0.0785],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.9023, -2.4102, -0.3237,  ..., -0.1226, -3.9727,  0.1914],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 2.9648e-02, -1.3962e-02,  7.7324e-03,  ...,  7.6065e-03,
          3.2425e-05,  1.7227e-02],
        [-1.5205e-02,  2.5513e-02, -3.2387e-03,  ...,  1.3290e-02,
         -7.2479e-03, -6.4564e-04],
        [ 1.7487e-02, -1.3565e-02,  2.3560e-02,  ..., -1.6647e-02,
         -7.4768e-04, -2.7752e-03],
        ...,
        [ 2.8572e-03,  2.1530e-02,  2.8229e-03,  ...,  3.0945e-02,
          2.5215e-03, -5.5275e-03],
        [ 7.5073e-03,  3.4027e-02,  1.0300e-02,  ..., -1.6129e-02,
          3.6499e-02, -3.3997e-02],
        [ 8.7051e-03, -5.1613e-03,  1.8555e-02,  ..., -1.7944e-02,
         -1.1414e-02,  2.2766e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.9863, -2.6621, -0.1569,  ...,  0.2812, -4.1680, -0.3054]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 06:29:45 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you teach something, you are a teacher
If you recommend something, you are a recommender
If you organise something, you are a organiser
If you slay something, you are a slayer
If you molest something, you are a molester
If you preach something, you are a preacher
If you determine something, you are a determiner
If you lose something, you are a
2024-07-31 06:29:45 root INFO     total operator prediction time: 1005.4841017723083 seconds
2024-07-31 06:29:45 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on adj - superlative
2024-07-31 06:29:45 root INFO     building operator adj - superlative
2024-07-31 06:29:46 root INFO     [order_1_approx] starting weight calculation for If something is the most risky, it is riskiest
If something is the most sexy, it is sexiest
If something is the most lazy, it is laziest
If something is the most cheap, it is cheapest
If something is the most shiny, it is shiniest
If something is the most nasty, it is nastiest
If something is the most angry, it is angriest
If something is the most merry, it is
2024-07-31 06:29:46 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 06:31:53 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0555,  0.3450, -0.0649,  ..., -0.5625, -0.9004, -0.1055],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.8008, -3.7246, -2.5039,  ...,  0.6133, -1.4844, -1.9375],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0525, -0.0084,  0.0180,  ...,  0.0060,  0.0116,  0.0247],
        [-0.0002,  0.0203, -0.0009,  ...,  0.0020,  0.0021,  0.0071],
        [ 0.0002,  0.0034,  0.0419,  ..., -0.0060, -0.0139,  0.0022],
        ...,
        [ 0.0037,  0.0062,  0.0095,  ...,  0.0420, -0.0001, -0.0095],
        [ 0.0014, -0.0076, -0.0107,  ..., -0.0024,  0.0308, -0.0208],
        [ 0.0123, -0.0120,  0.0058,  ..., -0.0124,  0.0101,  0.0402]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.9160, -3.3535, -2.6133,  ...,  0.8403, -1.5410, -1.6631]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 06:31:54 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is the most risky, it is riskiest
If something is the most sexy, it is sexiest
If something is the most lazy, it is laziest
If something is the most cheap, it is cheapest
If something is the most shiny, it is shiniest
If something is the most nasty, it is nastiest
If something is the most angry, it is angriest
If something is the most merry, it is
2024-07-31 06:31:54 root INFO     [order_1_approx] starting weight calculation for If something is the most risky, it is riskiest
If something is the most merry, it is merriest
If something is the most lazy, it is laziest
If something is the most shiny, it is shiniest
If something is the most cheap, it is cheapest
If something is the most sexy, it is sexiest
If something is the most nasty, it is nastiest
If something is the most angry, it is
2024-07-31 06:31:54 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 06:33:54 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.4487,  0.1589, -0.6416,  ...,  0.0503, -0.4724, -0.2485],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-2.8965, -7.3359, -1.9717,  ..., -2.8086, -1.2070, -1.3574],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0443, -0.0055,  0.0031,  ..., -0.0021,  0.0009,  0.0111],
        [ 0.0060,  0.0391,  0.0136,  ...,  0.0091,  0.0223, -0.0114],
        [ 0.0090, -0.0182,  0.0424,  ..., -0.0017,  0.0103, -0.0002],
        ...,
        [ 0.0125,  0.0198,  0.0013,  ...,  0.0243, -0.0009, -0.0102],
        [-0.0070, -0.0034,  0.0001,  ...,  0.0009,  0.0418, -0.0304],
        [-0.0028, -0.0090,  0.0113,  ..., -0.0088, -0.0063,  0.0269]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-2.8633, -7.2109, -2.1426,  ..., -2.6133, -1.2207, -1.3975]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 06:33:55 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is the most risky, it is riskiest
If something is the most merry, it is merriest
If something is the most lazy, it is laziest
If something is the most shiny, it is shiniest
If something is the most cheap, it is cheapest
If something is the most sexy, it is sexiest
If something is the most nasty, it is nastiest
If something is the most angry, it is
2024-07-31 06:33:56 root INFO     [order_1_approx] starting weight calculation for If something is the most lazy, it is laziest
If something is the most angry, it is angriest
If something is the most nasty, it is nastiest
If something is the most shiny, it is shiniest
If something is the most cheap, it is cheapest
If something is the most risky, it is riskiest
If something is the most merry, it is merriest
If something is the most sexy, it is
2024-07-31 06:33:56 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 06:36:00 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0669, -0.3496, -0.3813,  ..., -0.2230, -0.2482,  0.2783],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-3.7891, -3.2402, -3.3770,  ..., -0.1675, -1.8359, -2.6602],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0444, -0.0062,  0.0209,  ..., -0.0023, -0.0024,  0.0088],
        [ 0.0042,  0.0524,  0.0090,  ..., -0.0162,  0.0181, -0.0055],
        [-0.0077, -0.0023,  0.0468,  ...,  0.0066, -0.0133, -0.0009],
        ...,
        [ 0.0186,  0.0346, -0.0065,  ...,  0.0443,  0.0062, -0.0167],
        [-0.0069, -0.0117, -0.0110,  ...,  0.0004,  0.0403, -0.0022],
        [ 0.0007,  0.0088,  0.0130,  ...,  0.0045,  0.0087,  0.0395]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-3.7676, -2.9004, -3.6367,  ..., -0.3931, -1.7178, -2.3535]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 06:36:01 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is the most lazy, it is laziest
If something is the most angry, it is angriest
If something is the most nasty, it is nastiest
If something is the most shiny, it is shiniest
If something is the most cheap, it is cheapest
If something is the most risky, it is riskiest
If something is the most merry, it is merriest
If something is the most sexy, it is
2024-07-31 06:36:01 root INFO     [order_1_approx] starting weight calculation for If something is the most sexy, it is sexiest
If something is the most shiny, it is shiniest
If something is the most risky, it is riskiest
If something is the most merry, it is merriest
If something is the most angry, it is angriest
If something is the most nasty, it is nastiest
If something is the most cheap, it is cheapest
If something is the most lazy, it is
2024-07-31 06:36:02 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 06:38:04 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3384,  0.0527, -0.5288,  ..., -0.4736, -0.1975,  0.1720],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-2.5898, -5.1719, -1.3945,  ..., -2.3613, -0.8184, -2.3320],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 6.3965e-02, -1.0391e-02,  1.2619e-02,  ...,  6.6223e-03,
          5.3635e-03,  1.0193e-02],
        [-7.6141e-03,  3.5889e-02,  1.1467e-02,  ..., -3.7098e-03,
          8.8272e-03,  8.5831e-03],
        [ 2.9659e-03, -1.6724e-02,  5.2124e-02,  ...,  9.1553e-05,
         -6.9809e-03,  3.9520e-03],
        ...,
        [ 2.6703e-04,  2.6047e-02, -2.5520e-03,  ...,  4.0375e-02,
         -7.3700e-03, -1.6937e-02],
        [-1.8921e-03,  1.9436e-03, -1.5915e-02,  ..., -2.3499e-03,
          4.4708e-02, -2.4338e-02],
        [ 6.2103e-03, -7.3128e-03,  1.5671e-02,  ..., -2.3376e-02,
         -1.2909e-02,  3.8330e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-2.7676, -4.8594, -1.6611,  ..., -2.0059, -0.6338, -2.1621]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 06:38:05 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is the most sexy, it is sexiest
If something is the most shiny, it is shiniest
If something is the most risky, it is riskiest
If something is the most merry, it is merriest
If something is the most angry, it is angriest
If something is the most nasty, it is nastiest
If something is the most cheap, it is cheapest
If something is the most lazy, it is
2024-07-31 06:38:05 root INFO     [order_1_approx] starting weight calculation for If something is the most nasty, it is nastiest
If something is the most risky, it is riskiest
If something is the most shiny, it is shiniest
If something is the most lazy, it is laziest
If something is the most sexy, it is sexiest
If something is the most angry, it is angriest
If something is the most merry, it is merriest
If something is the most cheap, it is
2024-07-31 06:38:05 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 06:40:10 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3149, -0.4524, -0.5088,  ..., -0.1306, -0.2991,  0.0591],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-2.1289, -0.6221, -1.9473,  ..., -2.1543, -2.3008, -1.2422],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0558, -0.0073,  0.0086,  ...,  0.0112,  0.0038,  0.0169],
        [-0.0117,  0.0384,  0.0193,  ..., -0.0158, -0.0076, -0.0073],
        [-0.0008,  0.0036,  0.0410,  ..., -0.0034,  0.0029,  0.0157],
        ...,
        [-0.0012,  0.0188,  0.0146,  ...,  0.0404,  0.0075, -0.0116],
        [ 0.0057,  0.0069, -0.0112,  ..., -0.0072,  0.0428, -0.0197],
        [-0.0037, -0.0146, -0.0012,  ..., -0.0126,  0.0004,  0.0382]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-2.2949, -0.6841, -2.2285,  ..., -2.1191, -2.0879, -1.0605]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 06:40:11 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is the most nasty, it is nastiest
If something is the most risky, it is riskiest
If something is the most shiny, it is shiniest
If something is the most lazy, it is laziest
If something is the most sexy, it is sexiest
If something is the most angry, it is angriest
If something is the most merry, it is merriest
If something is the most cheap, it is
2024-07-31 06:40:11 root INFO     [order_1_approx] starting weight calculation for If something is the most sexy, it is sexiest
If something is the most lazy, it is laziest
If something is the most merry, it is merriest
If something is the most cheap, it is cheapest
If something is the most risky, it is riskiest
If something is the most shiny, it is shiniest
If something is the most angry, it is angriest
If something is the most nasty, it is
2024-07-31 06:40:11 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 06:42:15 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2690, -0.0561, -0.0467,  ..., -0.5635, -0.1448, -0.1948],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.4548, -6.3125, -4.4844,  ..., -4.0391, -2.4004, -0.2852],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0442,  0.0082,  0.0168,  ..., -0.0095, -0.0110,  0.0112],
        [ 0.0062,  0.0258,  0.0016,  ..., -0.0114,  0.0160, -0.0035],
        [ 0.0026,  0.0066,  0.0221,  ..., -0.0014, -0.0017,  0.0019],
        ...,
        [ 0.0093,  0.0086, -0.0021,  ...,  0.0222,  0.0015, -0.0089],
        [ 0.0064, -0.0042,  0.0035,  ...,  0.0103,  0.0317, -0.0087],
        [ 0.0009,  0.0032,  0.0098,  ..., -0.0132, -0.0037,  0.0184]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.1445, -6.1875, -4.3125,  ..., -3.9961, -2.1875, -0.3093]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 06:42:16 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is the most sexy, it is sexiest
If something is the most lazy, it is laziest
If something is the most merry, it is merriest
If something is the most cheap, it is cheapest
If something is the most risky, it is riskiest
If something is the most shiny, it is shiniest
If something is the most angry, it is angriest
If something is the most nasty, it is
2024-07-31 06:42:16 root INFO     [order_1_approx] starting weight calculation for If something is the most nasty, it is nastiest
If something is the most angry, it is angriest
If something is the most shiny, it is shiniest
If something is the most cheap, it is cheapest
If something is the most lazy, it is laziest
If something is the most sexy, it is sexiest
If something is the most merry, it is merriest
If something is the most risky, it is
2024-07-31 06:42:16 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 06:44:18 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2651,  0.3364, -0.8022,  ...,  0.0025,  0.0933, -0.3967],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-3.0625, -5.3672, -3.1250,  ..., -3.3555, -0.0449,  0.5498],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 5.3467e-02,  3.5629e-03,  1.1353e-02,  ...,  7.5722e-04,
          4.1389e-03,  1.8066e-02],
        [ 7.1526e-03,  2.7588e-02,  1.1665e-02,  ..., -5.2989e-05,
          3.1719e-03,  8.0643e-03],
        [ 6.1417e-03, -2.4586e-03,  1.9974e-02,  ...,  9.1171e-03,
         -9.0408e-03,  1.0315e-02],
        ...,
        [ 2.1423e-02,  1.8372e-02,  1.7822e-02,  ...,  2.9984e-02,
          1.0269e-02,  5.1880e-03],
        [-5.5466e-03,  4.9820e-03,  2.0542e-03,  ...,  9.8190e-03,
          2.9160e-02, -1.6769e-02],
        [-1.0128e-03, -6.7329e-04,  1.4488e-02,  ..., -5.3024e-03,
         -7.4768e-03,  2.2751e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-3.2148, -5.2422, -3.0938,  ..., -3.3711, -0.1526,  0.7202]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 06:44:19 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is the most nasty, it is nastiest
If something is the most angry, it is angriest
If something is the most shiny, it is shiniest
If something is the most cheap, it is cheapest
If something is the most lazy, it is laziest
If something is the most sexy, it is sexiest
If something is the most merry, it is merriest
If something is the most risky, it is
2024-07-31 06:44:19 root INFO     [order_1_approx] starting weight calculation for If something is the most merry, it is merriest
If something is the most lazy, it is laziest
If something is the most angry, it is angriest
If something is the most cheap, it is cheapest
If something is the most nasty, it is nastiest
If something is the most risky, it is riskiest
If something is the most sexy, it is sexiest
If something is the most shiny, it is
2024-07-31 06:44:19 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 06:46:24 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0045, -0.0405, -0.4004,  ...,  0.2676,  0.1117, -0.3618],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-2.3457, -1.8633, -3.0703,  ...,  0.8184, -1.0791,  0.8828],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0812, -0.0190,  0.0123,  ...,  0.0017,  0.0057,  0.0035],
        [ 0.0010,  0.0704,  0.0241,  ..., -0.0103,  0.0093,  0.0040],
        [ 0.0103,  0.0003,  0.0549,  ..., -0.0060, -0.0136, -0.0053],
        ...,
        [ 0.0163,  0.0246,  0.0147,  ...,  0.0670, -0.0027, -0.0077],
        [-0.0117,  0.0061, -0.0020,  ...,  0.0034,  0.0482, -0.0032],
        [-0.0133, -0.0061,  0.0093,  ..., -0.0277, -0.0178,  0.0402]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-2.2070, -1.6094, -3.2832,  ...,  1.0625, -0.9902,  0.9619]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 06:46:25 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is the most merry, it is merriest
If something is the most lazy, it is laziest
If something is the most angry, it is angriest
If something is the most cheap, it is cheapest
If something is the most nasty, it is nastiest
If something is the most risky, it is riskiest
If something is the most sexy, it is sexiest
If something is the most shiny, it is
2024-07-31 06:46:25 root INFO     total operator prediction time: 999.8802766799927 seconds
2024-07-31 06:46:25 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on verb_3pSg - Ved
2024-07-31 06:46:25 root INFO     building operator verb_3pSg - Ved
2024-07-31 06:46:25 root INFO     [order_1_approx] starting weight calculation for When he introduces something, something has been introduced
When he involves something, something has been involved
When he continues something, something has been continued
When he appears something, something has been appeared
When he publishes something, something has been published
When he happens something, something has been happened
When he contains something, something has been contained
When he intends something, something has been
2024-07-31 06:46:25 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 06:48:30 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.8804, -0.4990,  0.0175,  ...,  0.2817,  0.1694,  0.2042],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.9219,  2.3984,  1.1797,  ..., -0.6792, -1.1064, -2.9883],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0326, -0.0160,  0.0158,  ..., -0.0041, -0.0085, -0.0048],
        [-0.0068,  0.0262,  0.0125,  ...,  0.0108, -0.0051, -0.0157],
        [ 0.0058, -0.0012,  0.0213,  ..., -0.0177, -0.0098, -0.0170],
        ...,
        [-0.0170, -0.0005,  0.0088,  ...,  0.0339,  0.0045,  0.0116],
        [ 0.0101,  0.0005,  0.0038,  ...,  0.0079,  0.0277, -0.0034],
        [-0.0087,  0.0139,  0.0251,  ..., -0.0027, -0.0067,  0.0134]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.9258,  2.6152,  0.8975,  ..., -0.3342, -1.2354, -2.7266]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 06:48:31 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When he introduces something, something has been introduced
When he involves something, something has been involved
When he continues something, something has been continued
When he appears something, something has been appeared
When he publishes something, something has been published
When he happens something, something has been happened
When he contains something, something has been contained
When he intends something, something has been
2024-07-31 06:48:31 root INFO     [order_1_approx] starting weight calculation for When he intends something, something has been intended
When he involves something, something has been involved
When he continues something, something has been continued
When he contains something, something has been contained
When he happens something, something has been happened
When he appears something, something has been appeared
When he introduces something, something has been introduced
When he publishes something, something has been
2024-07-31 06:48:32 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 06:50:38 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1360, -0.2383,  0.1891,  ..., -0.1953, -0.0028,  0.4937],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.6172, -1.9678,  2.1152,  ..., -1.7861, -2.1523,  0.6191],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 4.5319e-03,  1.3687e-02,  3.1223e-03,  ..., -1.3075e-03,
         -4.4136e-03,  1.4229e-02],
        [-9.2163e-03,  2.6512e-03,  6.0120e-03,  ...,  1.1528e-02,
          5.9166e-03,  5.3368e-03],
        [ 1.3664e-02, -3.6812e-03,  6.3553e-03,  ..., -5.2490e-03,
         -6.1264e-03, -5.4092e-03],
        ...,
        [-4.4785e-03,  2.8152e-03, -4.6310e-03,  ...,  6.9733e-03,
         -3.8147e-06,  1.7529e-03],
        [ 4.6959e-03, -4.6539e-03, -9.1019e-03,  ..., -2.8496e-03,
          1.6815e-02, -1.5793e-02],
        [-2.4376e-03,  1.2711e-02,  1.2245e-03,  ..., -4.7569e-03,
          3.0518e-05,  3.8109e-03]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.6797, -2.1211,  2.3730,  ..., -2.0898, -2.0684,  0.2244]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 06:50:39 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When he intends something, something has been intended
When he involves something, something has been involved
When he continues something, something has been continued
When he contains something, something has been contained
When he happens something, something has been happened
When he appears something, something has been appeared
When he introduces something, something has been introduced
When he publishes something, something has been
2024-07-31 06:50:39 root INFO     [order_1_approx] starting weight calculation for When he involves something, something has been involved
When he contains something, something has been contained
When he publishes something, something has been published
When he appears something, something has been appeared
When he continues something, something has been continued
When he introduces something, something has been introduced
When he intends something, something has been intended
When he happens something, something has been
2024-07-31 06:50:39 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 06:52:41 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.8604, -0.3206,  0.4375,  ..., -0.4001, -0.0709, -0.7529],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.1250,  1.1201,  2.8184,  ...,  0.2488, -4.4766,  0.2441],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0235, -0.0123,  0.0104,  ...,  0.0022, -0.0034,  0.0080],
        [-0.0170,  0.0244,  0.0020,  ...,  0.0255, -0.0043, -0.0151],
        [ 0.0031,  0.0012,  0.0159,  ..., -0.0082,  0.0116, -0.0159],
        ...,
        [-0.0038,  0.0190, -0.0255,  ...,  0.0348, -0.0008,  0.0030],
        [ 0.0067,  0.0096, -0.0005,  ..., -0.0096,  0.0364, -0.0294],
        [-0.0131, -0.0117,  0.0155,  ..., -0.0014, -0.0095,  0.0434]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.2617,  1.4570,  2.7969,  ...,  0.6792, -4.2969,  0.1700]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 06:52:42 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When he involves something, something has been involved
When he contains something, something has been contained
When he publishes something, something has been published
When he appears something, something has been appeared
When he continues something, something has been continued
When he introduces something, something has been introduced
When he intends something, something has been intended
When he happens something, something has been
2024-07-31 06:52:42 root INFO     [order_1_approx] starting weight calculation for When he involves something, something has been involved
When he happens something, something has been happened
When he contains something, something has been contained
When he publishes something, something has been published
When he continues something, something has been continued
When he intends something, something has been intended
When he appears something, something has been appeared
When he introduces something, something has been
2024-07-31 06:52:42 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 06:54:48 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.7383, -0.4658,  0.0853,  ...,  0.4292,  0.1329,  0.1151],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.1777,  1.3867,  3.2754,  ...,  1.3408, -2.1836, -0.5781],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0551, -0.0020,  0.0147,  ...,  0.0061, -0.0025,  0.0076],
        [-0.0076,  0.0302,  0.0006,  ...,  0.0216, -0.0099, -0.0075],
        [ 0.0042, -0.0067,  0.0284,  ..., -0.0119, -0.0041, -0.0086],
        ...,
        [ 0.0052, -0.0072,  0.0101,  ...,  0.0419, -0.0040,  0.0107],
        [ 0.0033, -0.0037,  0.0051,  ..., -0.0097,  0.0381, -0.0163],
        [-0.0122,  0.0080,  0.0143,  ..., -0.0138, -0.0042,  0.0345]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.4629,  1.5039,  3.1465,  ...,  1.1963, -2.2754, -0.5879]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 06:54:49 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When he involves something, something has been involved
When he happens something, something has been happened
When he contains something, something has been contained
When he publishes something, something has been published
When he continues something, something has been continued
When he intends something, something has been intended
When he appears something, something has been appeared
When he introduces something, something has been
2024-07-31 06:54:50 root INFO     [order_1_approx] starting weight calculation for When he publishes something, something has been published
When he introduces something, something has been introduced
When he involves something, something has been involved
When he appears something, something has been appeared
When he continues something, something has been continued
When he intends something, something has been intended
When he happens something, something has been happened
When he contains something, something has been
2024-07-31 06:54:50 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 06:56:54 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0798, -0.9380, -0.3787,  ...,  0.1049, -0.0795, -0.5977],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.0254,  1.6641,  3.8438,  ..., -1.9111, -0.4878, -3.5234],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0599, -0.0110, -0.0034,  ..., -0.0098, -0.0004,  0.0141],
        [-0.0110,  0.0439,  0.0063,  ...,  0.0108, -0.0020,  0.0004],
        [-0.0096,  0.0011,  0.0327,  ..., -0.0042,  0.0022, -0.0323],
        ...,
        [ 0.0080,  0.0048,  0.0070,  ...,  0.0370, -0.0011,  0.0094],
        [ 0.0069, -0.0133, -0.0068,  ..., -0.0065,  0.0484, -0.0187],
        [-0.0086,  0.0005,  0.0121,  ..., -0.0141, -0.0127,  0.0415]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.3613,  2.1895,  3.7637,  ..., -1.8096, -0.2964, -3.3887]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 06:56:55 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When he publishes something, something has been published
When he introduces something, something has been introduced
When he involves something, something has been involved
When he appears something, something has been appeared
When he continues something, something has been continued
When he intends something, something has been intended
When he happens something, something has been happened
When he contains something, something has been
2024-07-31 06:56:56 root INFO     [order_1_approx] starting weight calculation for When he intends something, something has been intended
When he introduces something, something has been introduced
When he publishes something, something has been published
When he appears something, something has been appeared
When he contains something, something has been contained
When he continues something, something has been continued
When he happens something, something has been happened
When he involves something, something has been
2024-07-31 06:56:56 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 06:59:01 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1752, -0.2659,  0.3262,  ...,  0.0514, -0.4927, -0.4692],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.5781,  1.6797,  3.3398,  ...,  0.2197,  1.2256, -3.0020],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0387,  0.0060,  0.0087,  ...,  0.0030,  0.0191, -0.0044],
        [-0.0100,  0.0450,  0.0126,  ...,  0.0276,  0.0006, -0.0014],
        [ 0.0005, -0.0158,  0.0268,  ..., -0.0128,  0.0058, -0.0153],
        ...,
        [ 0.0140, -0.0003, -0.0049,  ...,  0.0539, -0.0096,  0.0105],
        [-0.0145,  0.0114, -0.0131,  ...,  0.0110,  0.0515, -0.0260],
        [-0.0292,  0.0131,  0.0185,  ..., -0.0012, -0.0040,  0.0392]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.5762,  2.0059,  3.3164,  ...,  0.3027,  0.8306, -2.8594]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 06:59:02 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When he intends something, something has been intended
When he introduces something, something has been introduced
When he publishes something, something has been published
When he appears something, something has been appeared
When he contains something, something has been contained
When he continues something, something has been continued
When he happens something, something has been happened
When he involves something, something has been
2024-07-31 06:59:02 root INFO     [order_1_approx] starting weight calculation for When he happens something, something has been happened
When he intends something, something has been intended
When he contains something, something has been contained
When he introduces something, something has been introduced
When he publishes something, something has been published
When he appears something, something has been appeared
When he involves something, something has been involved
When he continues something, something has been
2024-07-31 06:59:02 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 07:01:08 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1050, -0.6621, -0.3008,  ..., -0.0215, -0.5630,  0.6406],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.7422, -1.0352,  2.3965,  ..., -0.2969,  1.2891, -1.2930],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0439, -0.0060,  0.0006,  ...,  0.0050, -0.0012,  0.0241],
        [-0.0014,  0.0417,  0.0117,  ...,  0.0226,  0.0077, -0.0050],
        [ 0.0111, -0.0009,  0.0196,  ..., -0.0024, -0.0002, -0.0146],
        ...,
        [-0.0031,  0.0060,  0.0157,  ...,  0.0414, -0.0137,  0.0023],
        [ 0.0190,  0.0064, -0.0193,  ..., -0.0134,  0.0334, -0.0301],
        [-0.0111, -0.0030,  0.0118,  ..., -0.0280, -0.0198,  0.0151]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.8613, -0.6836,  2.1387,  ...,  0.0552,  1.0820, -1.3633]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 07:01:08 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When he happens something, something has been happened
When he intends something, something has been intended
When he contains something, something has been contained
When he introduces something, something has been introduced
When he publishes something, something has been published
When he appears something, something has been appeared
When he involves something, something has been involved
When he continues something, something has been
2024-07-31 07:01:09 root INFO     [order_1_approx] starting weight calculation for When he contains something, something has been contained
When he continues something, something has been continued
When he introduces something, something has been introduced
When he happens something, something has been happened
When he publishes something, something has been published
When he intends something, something has been intended
When he involves something, something has been involved
When he appears something, something has been
2024-07-31 07:01:09 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 07:03:09 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2166, -0.1624, -0.1357,  ..., -0.1311, -0.0970, -0.4265],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.8584,  1.0107,  2.5059,  ...,  0.6162, -1.5811,  0.6191],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0393, -0.0055,  0.0149,  ...,  0.0119,  0.0074,  0.0057],
        [ 0.0006,  0.0352,  0.0062,  ...,  0.0222,  0.0007, -0.0049],
        [ 0.0029, -0.0115,  0.0400,  ..., -0.0072, -0.0036, -0.0194],
        ...,
        [-0.0092,  0.0016, -0.0059,  ...,  0.0432, -0.0072, -0.0047],
        [ 0.0169, -0.0036, -0.0029,  ..., -0.0076,  0.0456, -0.0189],
        [-0.0175,  0.0040,  0.0163,  ..., -0.0108, -0.0119,  0.0366]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.0488,  0.7534,  2.5684,  ...,  0.6543, -1.5088,  0.6357]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 07:03:10 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When he contains something, something has been contained
When he continues something, something has been continued
When he introduces something, something has been introduced
When he happens something, something has been happened
When he publishes something, something has been published
When he intends something, something has been intended
When he involves something, something has been involved
When he appears something, something has been
2024-07-31 07:03:10 root INFO     total operator prediction time: 1005.0987095832825 seconds
2024-07-31 07:03:10 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on noun - plural_reg
2024-07-31 07:03:10 root INFO     building operator noun - plural_reg
2024-07-31 07:03:11 root INFO     [order_1_approx] starting weight calculation for The plural form of song is songs
The plural form of student is students
The plural form of god is gods
The plural form of office is offices
The plural form of album is albums
The plural form of hour is hours
The plural form of department is departments
The plural form of road is
2024-07-31 07:03:11 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 07:05:17 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1177,  0.0778,  0.1989,  ...,  0.1158, -0.0076, -0.4941],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.9365, -5.2266, -1.4238,  ...,  0.0402, -0.6909, -2.5156],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0961,  0.0117, -0.0086,  ...,  0.0111,  0.0298,  0.0066],
        [ 0.0131,  0.0665,  0.0023,  ..., -0.0042,  0.0280,  0.0012],
        [-0.0061,  0.0140,  0.0595,  ...,  0.0074,  0.0148,  0.0138],
        ...,
        [ 0.0220, -0.0115,  0.0477,  ...,  0.0677, -0.0137,  0.0204],
        [-0.0180,  0.0145, -0.0070,  ..., -0.0020,  0.0775,  0.0017],
        [-0.0125,  0.0110, -0.0036,  ..., -0.0007, -0.0009,  0.0576]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.6748, -5.2734, -1.2607,  ..., -0.0994, -0.1475, -2.5410]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 07:05:18 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of song is songs
The plural form of student is students
The plural form of god is gods
The plural form of office is offices
The plural form of album is albums
The plural form of hour is hours
The plural form of department is departments
The plural form of road is
2024-07-31 07:05:18 root INFO     [order_1_approx] starting weight calculation for The plural form of department is departments
The plural form of hour is hours
The plural form of god is gods
The plural form of student is students
The plural form of office is offices
The plural form of road is roads
The plural form of album is albums
The plural form of song is
2024-07-31 07:05:18 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 07:07:21 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0354,  0.5806,  0.1069,  ..., -0.0083, -0.2083, -0.5459],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.1611, -3.8574,  2.2070,  ..., -2.5312, -1.0088, -2.3613],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0698,  0.0058,  0.0077,  ...,  0.0121,  0.0081, -0.0054],
        [ 0.0039,  0.0712, -0.0012,  ..., -0.0165,  0.0168, -0.0211],
        [ 0.0118,  0.0005,  0.0732,  ...,  0.0104, -0.0083,  0.0036],
        ...,
        [ 0.0174,  0.0206, -0.0056,  ...,  0.0469, -0.0076,  0.0016],
        [-0.0145,  0.0197, -0.0316,  ..., -0.0069,  0.0247, -0.0037],
        [ 0.0128,  0.0092, -0.0013,  ..., -0.0067,  0.0083,  0.0417]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.0789, -3.9844,  1.8877,  ..., -2.2754, -0.5732, -2.1133]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 07:07:22 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of department is departments
The plural form of hour is hours
The plural form of god is gods
The plural form of student is students
The plural form of office is offices
The plural form of road is roads
The plural form of album is albums
The plural form of song is
2024-07-31 07:07:22 root INFO     [order_1_approx] starting weight calculation for The plural form of hour is hours
The plural form of song is songs
The plural form of office is offices
The plural form of album is albums
The plural form of god is gods
The plural form of department is departments
The plural form of road is roads
The plural form of student is
2024-07-31 07:07:22 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 07:09:31 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0553, -0.0089, -0.3450,  ...,  0.1087, -0.2878, -0.0703],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.8975, -1.7188,  2.7539,  ..., -0.2266,  0.3525, -1.5947],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0744,  0.0239, -0.0029,  ...,  0.0063, -0.0117,  0.0178],
        [-0.0029,  0.0673, -0.0016,  ...,  0.0040,  0.0227,  0.0076],
        [-0.0110,  0.0020,  0.0654,  ..., -0.0162, -0.0169,  0.0161],
        ...,
        [ 0.0143,  0.0159, -0.0005,  ...,  0.0472, -0.0038,  0.0004],
        [-0.0136,  0.0149, -0.0033,  ..., -0.0291,  0.0214, -0.0094],
        [-0.0139,  0.0133, -0.0141,  ...,  0.0144, -0.0182,  0.0546]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.7705, -1.7363,  2.7715,  ..., -0.5840,  0.6411, -1.3828]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 07:09:32 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of hour is hours
The plural form of song is songs
The plural form of office is offices
The plural form of album is albums
The plural form of god is gods
The plural form of department is departments
The plural form of road is roads
The plural form of student is
2024-07-31 07:09:32 root INFO     [order_1_approx] starting weight calculation for The plural form of song is songs
The plural form of road is roads
The plural form of student is students
The plural form of office is offices
The plural form of hour is hours
The plural form of god is gods
The plural form of department is departments
The plural form of album is
2024-07-31 07:09:32 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 07:11:41 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2278,  0.1959, -0.3916,  ...,  0.0239, -0.3420,  0.2627],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.1511, -3.9805,  1.5146,  ...,  0.0162, -0.9209, -0.9248],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.1248,  0.0069,  0.0091,  ..., -0.0049,  0.0098,  0.0012],
        [-0.0197,  0.0930,  0.0033,  ...,  0.0159,  0.0048, -0.0068],
        [ 0.0124, -0.0147,  0.0828,  ..., -0.0086, -0.0117,  0.0066],
        ...,
        [ 0.0052,  0.0174, -0.0159,  ...,  0.0765, -0.0239,  0.0083],
        [-0.0386,  0.0052, -0.0030,  ...,  0.0127,  0.0865, -0.0193],
        [-0.0077,  0.0016, -0.0098,  ..., -0.0159, -0.0025,  0.0729]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.0775, -3.8730,  1.8145,  ...,  0.1401, -0.9922, -0.5830]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 07:11:42 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of song is songs
The plural form of road is roads
The plural form of student is students
The plural form of office is offices
The plural form of hour is hours
The plural form of god is gods
The plural form of department is departments
The plural form of album is
2024-07-31 07:11:42 root INFO     [order_1_approx] starting weight calculation for The plural form of song is songs
The plural form of hour is hours
The plural form of student is students
The plural form of department is departments
The plural form of road is roads
The plural form of god is gods
The plural form of album is albums
The plural form of office is
2024-07-31 07:11:42 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 07:13:51 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1351,  0.2346, -0.5439,  ...,  0.0247, -0.3191, -0.9551],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.9688, -3.0234,  1.3789,  ..., -0.2700,  0.3472, -0.7832],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0618, -0.0026, -0.0155,  ...,  0.0093,  0.0091,  0.0277],
        [-0.0091,  0.0530, -0.0086,  ...,  0.0095,  0.0016, -0.0100],
        [ 0.0109,  0.0238,  0.0706,  ...,  0.0048, -0.0191, -0.0042],
        ...,
        [ 0.0095,  0.0122,  0.0092,  ...,  0.0446, -0.0098,  0.0218],
        [-0.0241,  0.0163, -0.0099,  ...,  0.0043,  0.0540, -0.0053],
        [ 0.0048, -0.0168, -0.0140,  ...,  0.0038, -0.0070,  0.0562]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.9844, -3.0000,  1.4004,  ..., -0.4568,  0.5234, -0.3296]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 07:13:52 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of song is songs
The plural form of hour is hours
The plural form of student is students
The plural form of department is departments
The plural form of road is roads
The plural form of god is gods
The plural form of album is albums
The plural form of office is
2024-07-31 07:13:52 root INFO     [order_1_approx] starting weight calculation for The plural form of song is songs
The plural form of album is albums
The plural form of road is roads
The plural form of hour is hours
The plural form of office is offices
The plural form of student is students
The plural form of department is departments
The plural form of god is
2024-07-31 07:13:52 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 07:16:00 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1205,  0.2068, -0.0059,  ..., -0.3684, -0.2644, -0.2227],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 5.0547, -4.2461,  1.0039,  ..., -1.3330,  0.3711, -3.0859],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0588, -0.0099, -0.0030,  ...,  0.0141, -0.0139,  0.0082],
        [ 0.0219,  0.0706,  0.0240,  ...,  0.0166,  0.0188, -0.0078],
        [ 0.0048, -0.0150,  0.0564,  ...,  0.0200,  0.0012,  0.0026],
        ...,
        [ 0.0236,  0.0090, -0.0134,  ...,  0.0604, -0.0134,  0.0041],
        [ 0.0050,  0.0059, -0.0173,  ..., -0.0449,  0.0224, -0.0153],
        [-0.0193,  0.0234, -0.0054,  ..., -0.0028, -0.0096,  0.0721]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 5.0234, -4.1289,  0.9673,  ..., -1.0293,  0.8794, -2.9824]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 07:16:01 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of song is songs
The plural form of album is albums
The plural form of road is roads
The plural form of hour is hours
The plural form of office is offices
The plural form of student is students
The plural form of department is departments
The plural form of god is
2024-07-31 07:16:02 root INFO     [order_1_approx] starting weight calculation for The plural form of office is offices
The plural form of student is students
The plural form of song is songs
The plural form of album is albums
The plural form of god is gods
The plural form of department is departments
The plural form of road is roads
The plural form of hour is
2024-07-31 07:16:02 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 07:18:10 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2864, -0.0656,  0.0527,  ...,  0.2446, -0.0120, -0.2014],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.4980, -3.1406,  0.9209,  ..., -1.7803,  0.4102, -2.6172],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0970,  0.0280,  0.0089,  ...,  0.0165, -0.0059,  0.0237],
        [ 0.0063,  0.0743, -0.0148,  ...,  0.0066,  0.0112, -0.0095],
        [ 0.0136,  0.0035,  0.0714,  ...,  0.0059,  0.0013,  0.0248],
        ...,
        [ 0.0186,  0.0073,  0.0149,  ...,  0.0796, -0.0195,  0.0149],
        [-0.0172,  0.0104,  0.0035,  ...,  0.0188,  0.0637, -0.0130],
        [-0.0170,  0.0040, -0.0099,  ..., -0.0049, -0.0141,  0.0755]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.3027, -2.9805,  0.5732,  ..., -1.7773,  0.5483, -2.4883]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 07:18:11 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of office is offices
The plural form of student is students
The plural form of song is songs
The plural form of album is albums
The plural form of god is gods
The plural form of department is departments
The plural form of road is roads
The plural form of hour is
2024-07-31 07:18:11 root INFO     [order_1_approx] starting weight calculation for The plural form of office is offices
The plural form of god is gods
The plural form of hour is hours
The plural form of song is songs
The plural form of album is albums
The plural form of student is students
The plural form of road is roads
The plural form of department is
2024-07-31 07:18:11 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 07:20:17 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1560,  0.2329, -0.3887,  ..., -0.1575, -0.1643, -0.5449],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.5176, -3.2168,  3.2363,  ..., -1.1523,  1.0127, -2.4375],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0811,  0.0072, -0.0053,  ...,  0.0046,  0.0003,  0.0154],
        [ 0.0038,  0.0441,  0.0049,  ...,  0.0116,  0.0016, -0.0116],
        [ 0.0059,  0.0081,  0.0636,  ...,  0.0173, -0.0017,  0.0149],
        ...,
        [ 0.0076,  0.0144,  0.0113,  ...,  0.0625, -0.0189,  0.0010],
        [-0.0262,  0.0231, -0.0121,  ...,  0.0096,  0.0594,  0.0076],
        [ 0.0087, -0.0094, -0.0068,  ...,  0.0018, -0.0254,  0.0460]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.4102, -3.5918,  3.1602,  ..., -1.3203,  1.2471, -2.0781]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 07:20:18 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of office is offices
The plural form of god is gods
The plural form of hour is hours
The plural form of song is songs
The plural form of album is albums
The plural form of student is students
The plural form of road is roads
The plural form of department is
2024-07-31 07:20:18 root INFO     total operator prediction time: 1027.2322759628296 seconds
2024-07-31 07:20:18 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on verb_Ving - 3pSg
2024-07-31 07:20:18 root INFO     building operator verb_Ving - 3pSg
2024-07-31 07:20:18 root INFO     [order_1_approx] starting weight calculation for When something is understanding, it understands
When something is sitting, it sits
When something is performing, it performs
When something is suggesting, it suggests
When something is occurring, it occurs
When something is including, it includes
When something is explaining, it explains
When something is enabling, it
2024-07-31 07:20:18 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 07:22:22 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0276, -0.3596,  0.1344,  ..., -0.7451, -0.2810,  0.1877],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.1162, -3.1699, -0.3633,  ..., -0.9189, -8.2734, -1.3809],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0529,  0.0030,  0.0266,  ..., -0.0025, -0.0083,  0.0068],
        [-0.0061,  0.0718, -0.0201,  ...,  0.0269, -0.0019, -0.0084],
        [-0.0104, -0.0171,  0.0536,  ..., -0.0311,  0.0200, -0.0167],
        ...,
        [ 0.0064,  0.0150,  0.0030,  ...,  0.0659,  0.0021,  0.0008],
        [-0.0059, -0.0154, -0.0038,  ..., -0.0049,  0.0833, -0.0557],
        [-0.0046, -0.0056,  0.0205,  ..., -0.0147, -0.0128,  0.0775]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.3838, -2.5703,  0.0271,  ..., -0.6104, -8.3906, -1.7881]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 07:22:23 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When something is understanding, it understands
When something is sitting, it sits
When something is performing, it performs
When something is suggesting, it suggests
When something is occurring, it occurs
When something is including, it includes
When something is explaining, it explains
When something is enabling, it
2024-07-31 07:22:24 root INFO     [order_1_approx] starting weight calculation for When something is explaining, it explains
When something is performing, it performs
When something is understanding, it understands
When something is sitting, it sits
When something is enabling, it enables
When something is suggesting, it suggests
When something is occurring, it occurs
When something is including, it
2024-07-31 07:22:24 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 07:24:29 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0197, -0.1907,  0.0972,  ..., -0.1110, -0.0995, -0.5347],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.7471, -1.6279,  1.4238,  ..., -0.8896, -5.8438, -1.9746],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0987,  0.0056,  0.0255,  ...,  0.0180, -0.0161,  0.0055],
        [-0.0034,  0.1115, -0.0017,  ...,  0.0274, -0.0122,  0.0024],
        [ 0.0147, -0.0081,  0.0637,  ..., -0.0281, -0.0143, -0.0139],
        ...,
        [ 0.0206,  0.0041,  0.0032,  ...,  0.0939, -0.0039,  0.0053],
        [-0.0215,  0.0010,  0.0011,  ..., -0.0130,  0.1021, -0.0558],
        [-0.0034,  0.0102,  0.0034,  ..., -0.0261, -0.0230,  0.0909]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.0547, -1.2480,  1.5430,  ..., -0.5303, -5.8867, -2.1973]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 07:24:30 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When something is explaining, it explains
When something is performing, it performs
When something is understanding, it understands
When something is sitting, it sits
When something is enabling, it enables
When something is suggesting, it suggests
When something is occurring, it occurs
When something is including, it
2024-07-31 07:24:30 root INFO     [order_1_approx] starting weight calculation for When something is including, it includes
When something is sitting, it sits
When something is explaining, it explains
When something is suggesting, it suggests
When something is occurring, it occurs
When something is understanding, it understands
When something is enabling, it enables
When something is performing, it
2024-07-31 07:24:30 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 07:26:32 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2224,  0.1418, -0.1121,  ..., -0.6074, -0.0168, -0.3765],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.0195, -4.8164,  1.2734,  ..., -1.2578, -5.5938, -2.2227],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0744,  0.0019, -0.0060,  ...,  0.0016,  0.0039,  0.0012],
        [ 0.0029,  0.0698, -0.0077,  ...,  0.0157,  0.0054,  0.0092],
        [ 0.0082,  0.0040,  0.0535,  ...,  0.0055,  0.0072, -0.0073],
        ...,
        [ 0.0096,  0.0148,  0.0102,  ...,  0.0731,  0.0112, -0.0061],
        [-0.0173, -0.0320,  0.0257,  ..., -0.0090,  0.0559, -0.0390],
        [-0.0023, -0.0044,  0.0267,  ..., -0.0043, -0.0009,  0.0514]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.1172, -4.4180,  1.1875,  ..., -0.7256, -5.2500, -2.0898]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 07:26:33 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When something is including, it includes
When something is sitting, it sits
When something is explaining, it explains
When something is suggesting, it suggests
When something is occurring, it occurs
When something is understanding, it understands
When something is enabling, it enables
When something is performing, it
2024-07-31 07:26:33 root INFO     [order_1_approx] starting weight calculation for When something is suggesting, it suggests
When something is explaining, it explains
When something is enabling, it enables
When something is occurring, it occurs
When something is including, it includes
When something is sitting, it sits
When something is performing, it performs
When something is understanding, it
2024-07-31 07:26:33 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 07:28:37 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.4170,  0.1495,  0.1240,  ..., -0.2603, -0.2041, -0.5396],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.5527, -1.8672,  1.1328,  ..., -0.8413, -5.6680,  2.0449],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 5.3406e-02,  9.8648e-03, -6.8092e-04,  ..., -2.2354e-03,
         -5.1270e-03,  9.6588e-03],
        [ 4.9591e-05,  4.8981e-02,  4.3716e-03,  ...,  1.0071e-02,
         -1.2917e-02,  2.0859e-02],
        [-1.3710e-02, -1.9196e-02,  4.3457e-02,  ..., -1.7334e-02,
          7.3090e-03, -3.0823e-02],
        ...,
        [ 3.5477e-04,  5.6915e-03,  1.1612e-02,  ...,  5.8105e-02,
         -2.4834e-03, -7.6523e-03],
        [-1.3351e-02,  1.3161e-03, -8.3466e-03,  ..., -2.1210e-02,
          5.4596e-02, -2.5604e-02],
        [-5.5466e-03, -3.2330e-03,  1.7395e-02,  ..., -7.0953e-03,
         -1.0101e-02,  4.8401e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.3223, -1.6406,  1.1553,  ..., -0.6743, -5.7695,  1.6943]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 07:28:38 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When something is suggesting, it suggests
When something is explaining, it explains
When something is enabling, it enables
When something is occurring, it occurs
When something is including, it includes
When something is sitting, it sits
When something is performing, it performs
When something is understanding, it
2024-07-31 07:28:38 root INFO     [order_1_approx] starting weight calculation for When something is sitting, it sits
When something is enabling, it enables
When something is explaining, it explains
When something is suggesting, it suggests
When something is performing, it performs
When something is including, it includes
When something is understanding, it understands
When something is occurring, it
2024-07-31 07:28:38 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 07:30:44 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1244,  0.0486, -0.2688,  ..., -0.5283, -0.0268, -0.8950],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.4102, -4.7656,  0.4238,  ..., -1.5098, -2.8145,  0.5859],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0613, -0.0012, -0.0060,  ...,  0.0086, -0.0015,  0.0050],
        [-0.0008,  0.0602, -0.0125,  ...,  0.0192, -0.0093, -0.0134],
        [-0.0024,  0.0012,  0.0284,  ..., -0.0159,  0.0055, -0.0266],
        ...,
        [ 0.0030,  0.0110,  0.0131,  ...,  0.0428, -0.0101, -0.0008],
        [-0.0121, -0.0026,  0.0016,  ..., -0.0134,  0.0532, -0.0252],
        [-0.0005, -0.0041,  0.0138,  ..., -0.0076, -0.0045,  0.0607]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.6763, -4.2461,  0.3669,  ..., -1.1699, -3.1582,  0.5376]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 07:30:45 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When something is sitting, it sits
When something is enabling, it enables
When something is explaining, it explains
When something is suggesting, it suggests
When something is performing, it performs
When something is including, it includes
When something is understanding, it understands
When something is occurring, it
2024-07-31 07:30:45 root INFO     [order_1_approx] starting weight calculation for When something is including, it includes
When something is performing, it performs
When something is suggesting, it suggests
When something is understanding, it understands
When something is explaining, it explains
When something is enabling, it enables
When something is occurring, it occurs
When something is sitting, it
2024-07-31 07:30:45 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 07:32:47 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2744, -0.5117, -0.1179,  ...,  0.1990, -0.7373, -0.2593],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.6152, -3.4609, -0.3164,  ..., -2.8203, -3.2617, -1.5977],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0772, -0.0146,  0.0020,  ...,  0.0032,  0.0083, -0.0059],
        [ 0.0176,  0.0532, -0.0110,  ...,  0.0205, -0.0049,  0.0042],
        [-0.0261, -0.0073,  0.0586,  ..., -0.0064,  0.0032, -0.0132],
        ...,
        [ 0.0103, -0.0137,  0.0259,  ...,  0.0889, -0.0042, -0.0113],
        [-0.0080,  0.0135, -0.0205,  ..., -0.0196,  0.0608, -0.0241],
        [-0.0071,  0.0268,  0.0182,  ..., -0.0203, -0.0281,  0.0778]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.4219, -3.5625,  0.0752,  ..., -2.3613, -3.2734, -1.7812]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 07:32:48 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When something is including, it includes
When something is performing, it performs
When something is suggesting, it suggests
When something is understanding, it understands
When something is explaining, it explains
When something is enabling, it enables
When something is occurring, it occurs
When something is sitting, it
2024-07-31 07:32:48 root INFO     [order_1_approx] starting weight calculation for When something is enabling, it enables
When something is including, it includes
When something is sitting, it sits
When something is suggesting, it suggests
When something is occurring, it occurs
When something is performing, it performs
When something is understanding, it understands
When something is explaining, it
2024-07-31 07:32:48 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 07:34:52 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0233, -0.5820,  0.5210,  ..., -0.5786,  0.1775, -0.5107],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.3926, -3.0000,  2.7207,  ...,  0.3052, -5.4727,  0.7617],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0444,  0.0042, -0.0011,  ...,  0.0048,  0.0021,  0.0125],
        [-0.0138,  0.0536,  0.0066,  ...,  0.0180, -0.0057,  0.0057],
        [-0.0119, -0.0068,  0.0215,  ..., -0.0208,  0.0065, -0.0294],
        ...,
        [-0.0072,  0.0045,  0.0194,  ...,  0.0553,  0.0016, -0.0015],
        [-0.0089, -0.0038, -0.0112,  ..., -0.0044,  0.0474, -0.0333],
        [ 0.0100,  0.0093,  0.0201,  ...,  0.0002, -0.0026,  0.0529]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.0762, -2.6836,  2.7031,  ...,  0.6816, -5.3594,  0.5723]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 07:34:53 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When something is enabling, it enables
When something is including, it includes
When something is sitting, it sits
When something is suggesting, it suggests
When something is occurring, it occurs
When something is performing, it performs
When something is understanding, it understands
When something is explaining, it
2024-07-31 07:34:54 root INFO     [order_1_approx] starting weight calculation for When something is sitting, it sits
When something is understanding, it understands
When something is performing, it performs
When something is enabling, it enables
When something is occurring, it occurs
When something is including, it includes
When something is explaining, it explains
When something is suggesting, it
2024-07-31 07:34:54 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 07:36:59 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0688, -0.0146,  0.6436,  ..., -0.0243, -0.0066, -0.3271],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.8164, -2.8770, -0.9902,  ...,  1.1279, -3.6328,  1.5234],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 6.7383e-02,  9.3155e-03,  5.4207e-03,  ..., -1.1993e-02,
         -9.3613e-03,  7.6523e-03],
        [-1.7151e-02,  5.4108e-02, -8.7128e-03,  ...,  1.5427e-02,
         -4.7722e-03,  1.5114e-02],
        [ 2.7637e-03, -1.6876e-02,  3.3813e-02,  ..., -2.6123e-02,
          7.6370e-03, -2.1988e-02],
        ...,
        [-1.5869e-02, -9.5367e-05,  3.0136e-02,  ...,  5.7526e-02,
         -4.3831e-03,  6.1569e-03],
        [-1.2924e-02,  3.6087e-03, -1.5507e-03,  ...,  1.0468e-02,
          4.8462e-02, -4.1077e-02],
        [ 3.8815e-03,  3.1403e-02,  7.6180e-03,  ..., -6.8617e-04,
         -9.2010e-03,  3.3569e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.5391, -2.9219, -0.4458,  ...,  1.2217, -3.7773,  0.9175]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 07:37:00 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When something is sitting, it sits
When something is understanding, it understands
When something is performing, it performs
When something is enabling, it enables
When something is occurring, it occurs
When something is including, it includes
When something is explaining, it explains
When something is suggesting, it
2024-07-31 07:37:00 root INFO     total operator prediction time: 1002.6410129070282 seconds
2024-07-31 07:37:00 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on verb_inf - 3pSg
2024-07-31 07:37:00 root INFO     building operator verb_inf - 3pSg
2024-07-31 07:37:00 root INFO     [order_1_approx] starting weight calculation for I appear, he appears
I happen, he happens
I achieve, he achieves
I require, he requires
I consider, he considers
I add, he adds
I reduce, he reduces
I receive, he
2024-07-31 07:37:00 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 07:39:06 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2080,  0.2505, -0.0320,  ..., -0.2410, -0.3250,  0.3071],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.4590, -1.5820, -3.5000,  ..., -2.0449, -6.8359, -2.7617],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0363, -0.0047,  0.0097,  ...,  0.0123, -0.0070,  0.0309],
        [-0.0095,  0.0547,  0.0017,  ...,  0.0028,  0.0041, -0.0162],
        [ 0.0040,  0.0112,  0.0142,  ..., -0.0127, -0.0037, -0.0158],
        ...,
        [ 0.0043,  0.0186,  0.0212,  ...,  0.0349,  0.0024, -0.0049],
        [ 0.0131,  0.0042,  0.0055,  ..., -0.0224,  0.0274, -0.0037],
        [-0.0109, -0.0060,  0.0015,  ..., -0.0112,  0.0023,  0.0142]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.1885, -1.4756, -3.4023,  ..., -1.9551, -6.6055, -2.8535]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 07:39:07 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for I appear, he appears
I happen, he happens
I achieve, he achieves
I require, he requires
I consider, he considers
I add, he adds
I reduce, he reduces
I receive, he
2024-07-31 07:39:08 root INFO     [order_1_approx] starting weight calculation for I add, he adds
I require, he requires
I receive, he receives
I achieve, he achieves
I happen, he happens
I reduce, he reduces
I appear, he appears
I consider, he
2024-07-31 07:39:08 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 07:41:10 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0736, -0.0206,  0.1953,  ..., -0.1092, -0.2913, -0.2119],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.4453, -4.2578,  2.3945,  ..., -1.0820, -4.1484,  0.9062],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0580,  0.0007,  0.0305,  ...,  0.0023,  0.0006,  0.0471],
        [-0.0062,  0.0371, -0.0192,  ...,  0.0095,  0.0022, -0.0228],
        [-0.0115, -0.0035,  0.0382,  ...,  0.0006, -0.0068, -0.0146],
        ...,
        [ 0.0053, -0.0025,  0.0125,  ...,  0.0593, -0.0063, -0.0039],
        [-0.0183, -0.0028,  0.0051,  ..., -0.0211,  0.0369,  0.0007],
        [-0.0015,  0.0011,  0.0092,  ..., -0.0102, -0.0190,  0.0341]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.9336, -3.6523,  2.2012,  ..., -0.7520, -4.3555,  0.9209]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 07:41:11 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for I add, he adds
I require, he requires
I receive, he receives
I achieve, he achieves
I happen, he happens
I reduce, he reduces
I appear, he appears
I consider, he
2024-07-31 07:41:11 root INFO     [order_1_approx] starting weight calculation for I achieve, he achieves
I happen, he happens
I receive, he receives
I consider, he considers
I add, he adds
I appear, he appears
I require, he requires
I reduce, he
2024-07-31 07:41:11 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 07:43:16 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2477, -0.0698, -0.0925,  ..., -0.3418,  0.2057,  0.0630],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.4189, -2.0703, -1.0234,  ..., -2.3438, -6.7617, -3.4316],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0489,  0.0059,  0.0121,  ...,  0.0089, -0.0107,  0.0269],
        [-0.0005,  0.0327, -0.0031,  ...,  0.0051,  0.0013, -0.0003],
        [-0.0037,  0.0033,  0.0291,  ..., -0.0044, -0.0046, -0.0073],
        ...,
        [-0.0032, -0.0019,  0.0058,  ...,  0.0440, -0.0080,  0.0082],
        [-0.0140, -0.0145, -0.0061,  ..., -0.0061,  0.0365, -0.0131],
        [-0.0143,  0.0051,  0.0035,  ..., -0.0094,  0.0021,  0.0171]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.6177, -1.8652, -0.9155,  ..., -1.9727, -6.7344, -3.1797]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 07:43:17 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for I achieve, he achieves
I happen, he happens
I receive, he receives
I consider, he considers
I add, he adds
I appear, he appears
I require, he requires
I reduce, he
2024-07-31 07:43:17 root INFO     [order_1_approx] starting weight calculation for I require, he requires
I happen, he happens
I reduce, he reduces
I add, he adds
I achieve, he achieves
I consider, he considers
I receive, he receives
I appear, he
2024-07-31 07:43:17 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 07:45:23 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0271, -0.2440, -0.5820,  ..., -0.1384, -0.0064, -0.3271],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.4229, -2.6699, -1.0918,  ...,  1.6855, -5.1875,  1.7227],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0361,  0.0048,  0.0052,  ...,  0.0072, -0.0033,  0.0223],
        [ 0.0141,  0.0373, -0.0103,  ...,  0.0036, -0.0076, -0.0143],
        [-0.0058,  0.0034,  0.0312,  ..., -0.0145, -0.0134, -0.0082],
        ...,
        [-0.0092,  0.0038,  0.0208,  ...,  0.0256, -0.0106,  0.0040],
        [-0.0047, -0.0084,  0.0049,  ..., -0.0172,  0.0249,  0.0113],
        [-0.0020, -0.0068,  0.0047,  ..., -0.0187, -0.0219,  0.0324]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.1055, -2.5684, -1.3242,  ...,  1.6934, -5.3828,  1.9297]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 07:45:24 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for I require, he requires
I happen, he happens
I reduce, he reduces
I add, he adds
I achieve, he achieves
I consider, he considers
I receive, he receives
I appear, he
2024-07-31 07:45:24 root INFO     [order_1_approx] starting weight calculation for I receive, he receives
I require, he requires
I reduce, he reduces
I add, he adds
I consider, he considers
I appear, he appears
I happen, he happens
I achieve, he
2024-07-31 07:45:25 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 07:47:29 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.5366, -0.0958, -0.3301,  ..., -0.2991, -0.6870,  0.4683],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.9980, -2.0312, -1.6934,  ..., -1.4648, -7.7773, -0.1523],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0331,  0.0167,  0.0142,  ...,  0.0068, -0.0077,  0.0316],
        [-0.0085,  0.0218, -0.0145,  ..., -0.0009,  0.0069, -0.0193],
        [-0.0033,  0.0071,  0.0003,  ..., -0.0141, -0.0034, -0.0153],
        ...,
        [-0.0100, -0.0018, -0.0090,  ...,  0.0119,  0.0030, -0.0155],
        [-0.0063, -0.0029,  0.0047,  ..., -0.0060,  0.0183, -0.0030],
        [ 0.0120, -0.0089,  0.0031,  ..., -0.0078, -0.0067,  0.0123]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.7637, -1.7344, -1.6973,  ..., -1.2061, -7.7734, -0.1111]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 07:47:30 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for I receive, he receives
I require, he requires
I reduce, he reduces
I add, he adds
I consider, he considers
I appear, he appears
I happen, he happens
I achieve, he
2024-07-31 07:47:31 root INFO     [order_1_approx] starting weight calculation for I achieve, he achieves
I require, he requires
I appear, he appears
I consider, he considers
I receive, he receives
I reduce, he reduces
I happen, he happens
I add, he
2024-07-31 07:47:31 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 07:49:34 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1827, -0.4111,  0.2155,  ..., -0.2488, -0.1206,  0.0272],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.0000, -1.1084, -2.4141,  ...,  0.7134, -9.1328,  0.7754],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0522, -0.0032,  0.0053,  ..., -0.0024, -0.0056,  0.0122],
        [ 0.0073,  0.0383, -0.0192,  ..., -0.0032, -0.0047, -0.0181],
        [-0.0102,  0.0023,  0.0259,  ...,  0.0036, -0.0122, -0.0097],
        ...,
        [ 0.0092,  0.0045,  0.0100,  ...,  0.0335, -0.0041,  0.0063],
        [-0.0007, -0.0036, -0.0188,  ..., -0.0120,  0.0261, -0.0153],
        [-0.0073,  0.0017,  0.0063,  ..., -0.0135, -0.0125,  0.0297]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.7617, -0.9512, -2.1797,  ...,  0.9385, -8.5625,  0.5303]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 07:49:36 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for I achieve, he achieves
I require, he requires
I appear, he appears
I consider, he considers
I receive, he receives
I reduce, he reduces
I happen, he happens
I add, he
2024-07-31 07:49:36 root INFO     [order_1_approx] starting weight calculation for I add, he adds
I reduce, he reduces
I receive, he receives
I consider, he considers
I require, he requires
I achieve, he achieves
I appear, he appears
I happen, he
2024-07-31 07:49:36 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 07:51:36 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.5645, -0.1815,  0.1606,  ..., -0.5474,  0.0345, -0.1837],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.8633, -1.4473, -0.7168,  ..., -0.4912, -6.3633,  1.1348],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0114,  0.0080,  0.0084,  ...,  0.0033,  0.0015,  0.0091],
        [-0.0016,  0.0300, -0.0056,  ...,  0.0043,  0.0042, -0.0065],
        [-0.0074,  0.0068,  0.0024,  ..., -0.0036, -0.0091, -0.0156],
        ...,
        [-0.0037, -0.0014,  0.0039,  ...,  0.0173, -0.0100,  0.0017],
        [-0.0023,  0.0126, -0.0065,  ..., -0.0217,  0.0045,  0.0077],
        [-0.0048, -0.0017,  0.0101,  ..., -0.0114, -0.0104,  0.0082]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.8467, -1.2842, -0.3811,  ..., -0.1191, -6.7734,  1.0273]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 07:51:38 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for I add, he adds
I reduce, he reduces
I receive, he receives
I consider, he considers
I require, he requires
I achieve, he achieves
I appear, he appears
I happen, he
2024-07-31 07:51:38 root INFO     [order_1_approx] starting weight calculation for I achieve, he achieves
I appear, he appears
I consider, he considers
I happen, he happens
I receive, he receives
I reduce, he reduces
I add, he adds
I require, he
2024-07-31 07:51:38 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 07:53:41 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.3916, -0.1543, -0.2671,  ..., -0.2083, -0.4473, -0.3962],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.6113, -2.5215,  1.0801,  ..., -0.6543, -6.9609, -0.4941],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0403,  0.0051,  0.0178,  ...,  0.0102, -0.0020,  0.0268],
        [-0.0164,  0.0395, -0.0175,  ..., -0.0023,  0.0021, -0.0074],
        [ 0.0006,  0.0039,  0.0290,  ..., -0.0226, -0.0085,  0.0019],
        ...,
        [ 0.0042,  0.0053,  0.0191,  ...,  0.0383, -0.0232,  0.0242],
        [-0.0211, -0.0098,  0.0095,  ..., -0.0246,  0.0305, -0.0103],
        [-0.0013,  0.0012,  0.0025,  ..., -0.0290, -0.0073,  0.0280]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.2595, -2.3848,  1.0400,  ..., -0.4585, -7.0625, -0.5269]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 07:53:42 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for I achieve, he achieves
I appear, he appears
I consider, he considers
I happen, he happens
I receive, he receives
I reduce, he reduces
I add, he adds
I require, he
2024-07-31 07:53:42 root INFO     total operator prediction time: 1002.1063826084137 seconds
2024-07-31 07:53:42 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on verb_inf - Ved
2024-07-31 07:53:42 root INFO     building operator verb_inf - Ved
2024-07-31 07:53:42 root INFO     [order_1_approx] starting weight calculation for If the present form is hear, the past form is heard
If the present form is perform, the past form is performed
If the present form is spend, the past form is spent
If the present form is remain, the past form is remained
If the present form is discover, the past form is discovered
If the present form is believe, the past form is believed
If the present form is agree, the past form is agreed
If the present form is include, the past form is
2024-07-31 07:53:43 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 07:55:48 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2001, -0.1094,  0.0558,  ..., -0.0214,  0.3909, -0.4062],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.7852,  0.3420,  0.1792,  ..., -1.1162, -0.6582, -1.7734],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.1052, -0.0026,  0.0229,  ..., -0.0026,  0.0077,  0.0161],
        [-0.0117,  0.0871, -0.0082,  ...,  0.0189, -0.0148, -0.0238],
        [ 0.0230,  0.0168,  0.0546,  ..., -0.0205, -0.0059,  0.0043],
        ...,
        [-0.0134, -0.0005,  0.0010,  ...,  0.0953, -0.0180,  0.0165],
        [-0.0086, -0.0026,  0.0076,  ..., -0.0275,  0.0468, -0.0218],
        [-0.0184, -0.0009,  0.0064,  ..., -0.0244, -0.0266,  0.0587]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.6089,  0.7251, -0.0837,  ..., -1.6738, -0.3896, -0.9707]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 07:55:49 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If the present form is hear, the past form is heard
If the present form is perform, the past form is performed
If the present form is spend, the past form is spent
If the present form is remain, the past form is remained
If the present form is discover, the past form is discovered
If the present form is believe, the past form is believed
If the present form is agree, the past form is agreed
If the present form is include, the past form is
2024-07-31 07:55:49 root INFO     [order_1_approx] starting weight calculation for If the present form is remain, the past form is remained
If the present form is spend, the past form is spent
If the present form is hear, the past form is heard
If the present form is include, the past form is included
If the present form is perform, the past form is performed
If the present form is believe, the past form is believed
If the present form is agree, the past form is agreed
If the present form is discover, the past form is
2024-07-31 07:55:49 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 07:57:53 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0472,  0.0160,  0.2185,  ..., -0.4932, -0.5425,  0.0297],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.0000, -1.5488,  2.4648,  ..., -0.9712, -0.5957,  0.5654],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0780, -0.0017,  0.0209,  ...,  0.0067,  0.0049,  0.0095],
        [-0.0203,  0.0606,  0.0108,  ...,  0.0202, -0.0141,  0.0046],
        [ 0.0175,  0.0042,  0.0316,  ..., -0.0137,  0.0046, -0.0140],
        ...,
        [-0.0128,  0.0085, -0.0034,  ...,  0.0725, -0.0014,  0.0081],
        [ 0.0011,  0.0088, -0.0022,  ..., -0.0044,  0.0416, -0.0140],
        [-0.0125,  0.0010,  0.0092,  ..., -0.0174, -0.0146,  0.0441]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.0312, -1.4238,  2.1836,  ..., -0.6577, -0.2825,  0.7529]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 07:57:54 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If the present form is remain, the past form is remained
If the present form is spend, the past form is spent
If the present form is hear, the past form is heard
If the present form is include, the past form is included
If the present form is perform, the past form is performed
If the present form is believe, the past form is believed
If the present form is agree, the past form is agreed
If the present form is discover, the past form is
2024-07-31 07:57:55 root INFO     [order_1_approx] starting weight calculation for If the present form is discover, the past form is discovered
If the present form is hear, the past form is heard
If the present form is believe, the past form is believed
If the present form is remain, the past form is remained
If the present form is include, the past form is included
If the present form is perform, the past form is performed
If the present form is agree, the past form is agreed
If the present form is spend, the past form is
2024-07-31 07:57:55 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 07:59:59 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.3081, -0.3013,  0.3999,  ..., -0.3950, -0.0950, -0.2754],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.9287, -1.5342, -1.7480,  ..., -1.9199, -2.4609, -1.2881],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 8.0811e-02,  1.5717e-03,  5.7449e-03,  ..., -1.3870e-02,
          1.7227e-02,  3.0655e-02],
        [-7.3853e-03,  5.4565e-02, -2.6340e-03,  ...,  7.5912e-03,
          3.4256e-03,  1.1778e-03],
        [ 2.1011e-02, -7.8125e-03,  3.9948e-02,  ..., -2.0798e-02,
         -1.2535e-02, -1.3475e-03],
        ...,
        [ 1.2100e-02, -7.6294e-06,  9.5673e-03,  ...,  8.2703e-02,
          3.4618e-03,  1.0612e-02],
        [ 1.9730e-02,  1.9493e-03, -6.7863e-03,  ..., -1.3756e-02,
          4.5624e-02, -1.9501e-02],
        [-2.0874e-02,  6.0120e-03,  3.1261e-03,  ..., -1.9485e-02,
         -2.4246e-02,  4.5715e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.6416, -1.4150, -1.8555,  ..., -1.7109, -1.9277, -1.2188]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 08:00:00 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If the present form is discover, the past form is discovered
If the present form is hear, the past form is heard
If the present form is believe, the past form is believed
If the present form is remain, the past form is remained
If the present form is include, the past form is included
If the present form is perform, the past form is performed
If the present form is agree, the past form is agreed
If the present form is spend, the past form is
2024-07-31 08:00:00 root INFO     [order_1_approx] starting weight calculation for If the present form is include, the past form is included
If the present form is believe, the past form is believed
If the present form is hear, the past form is heard
If the present form is remain, the past form is remained
If the present form is spend, the past form is spent
If the present form is perform, the past form is performed
If the present form is discover, the past form is discovered
If the present form is agree, the past form is
2024-07-31 08:00:01 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 08:02:06 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0987, -0.2268, -0.1559,  ..., -0.0613, -0.1892, -0.3550],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.9453, -2.1211,  0.7705,  ..., -0.6787, -2.5879,  0.7227],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0760, -0.0154,  0.0091,  ..., -0.0084,  0.0103,  0.0327],
        [-0.0273,  0.0598,  0.0009,  ...,  0.0097, -0.0187, -0.0211],
        [-0.0007, -0.0114,  0.0288,  ...,  0.0106,  0.0093, -0.0044],
        ...,
        [ 0.0014, -0.0052, -0.0108,  ...,  0.0665, -0.0132, -0.0051],
        [-0.0217,  0.0052, -0.0193,  ..., -0.0094,  0.0437, -0.0222],
        [-0.0007, -0.0136,  0.0110,  ..., -0.0246, -0.0155,  0.0496]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.2178, -2.2383,  0.8047,  ..., -0.9004, -2.6895,  0.9072]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 08:02:07 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If the present form is include, the past form is included
If the present form is believe, the past form is believed
If the present form is hear, the past form is heard
If the present form is remain, the past form is remained
If the present form is spend, the past form is spent
If the present form is perform, the past form is performed
If the present form is discover, the past form is discovered
If the present form is agree, the past form is
2024-07-31 08:02:07 root INFO     [order_1_approx] starting weight calculation for If the present form is spend, the past form is spent
If the present form is agree, the past form is agreed
If the present form is perform, the past form is performed
If the present form is remain, the past form is remained
If the present form is believe, the past form is believed
If the present form is include, the past form is included
If the present form is discover, the past form is discovered
If the present form is hear, the past form is
2024-07-31 08:02:07 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 08:04:08 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1350, -0.1456,  0.1815,  ..., -0.0569, -0.1547, -0.0384],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.9277, -1.3213,  0.7227,  ..., -0.1716, -3.5547, -3.2109],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0958, -0.0225,  0.0110,  ..., -0.0087,  0.0165,  0.0181],
        [-0.0002,  0.0966, -0.0226,  ...,  0.0148, -0.0017, -0.0129],
        [ 0.0158,  0.0057,  0.0645,  ..., -0.0135, -0.0084,  0.0002],
        ...,
        [ 0.0100,  0.0218, -0.0007,  ...,  0.0692, -0.0014, -0.0162],
        [-0.0089, -0.0033, -0.0034,  ..., -0.0125,  0.0350, -0.0296],
        [-0.0060, -0.0091,  0.0199,  ..., -0.0049,  0.0086,  0.0477]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.3374, -1.2021,  0.6099,  ..., -0.0777, -3.4375, -2.9062]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 08:04:09 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If the present form is spend, the past form is spent
If the present form is agree, the past form is agreed
If the present form is perform, the past form is performed
If the present form is remain, the past form is remained
If the present form is believe, the past form is believed
If the present form is include, the past form is included
If the present form is discover, the past form is discovered
If the present form is hear, the past form is
2024-07-31 08:04:09 root INFO     [order_1_approx] starting weight calculation for If the present form is remain, the past form is remained
If the present form is hear, the past form is heard
If the present form is perform, the past form is performed
If the present form is spend, the past form is spent
If the present form is discover, the past form is discovered
If the present form is agree, the past form is agreed
If the present form is include, the past form is included
If the present form is believe, the past form is
2024-07-31 08:04:09 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 08:06:11 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1597,  0.4146, -0.0601,  ..., -0.5781, -0.3137,  0.2568],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.7832, -2.9219,  0.9868,  ..., -0.5083, -1.4082, -1.7393],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0560, -0.0303,  0.0115,  ...,  0.0007,  0.0040,  0.0354],
        [-0.0104,  0.0547,  0.0064,  ...,  0.0251, -0.0104,  0.0097],
        [ 0.0032,  0.0096,  0.0405,  ..., -0.0049, -0.0042,  0.0069],
        ...,
        [-0.0018, -0.0003, -0.0171,  ...,  0.0560,  0.0004,  0.0016],
        [ 0.0023, -0.0035, -0.0161,  ..., -0.0015,  0.0236, -0.0348],
        [-0.0092,  0.0165,  0.0067,  ..., -0.0114, -0.0117,  0.0293]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.6338, -3.0371,  0.5347,  ..., -0.5635, -1.1865, -1.7822]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 08:06:12 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If the present form is remain, the past form is remained
If the present form is hear, the past form is heard
If the present form is perform, the past form is performed
If the present form is spend, the past form is spent
If the present form is discover, the past form is discovered
If the present form is agree, the past form is agreed
If the present form is include, the past form is included
If the present form is believe, the past form is
2024-07-31 08:06:13 root INFO     [order_1_approx] starting weight calculation for If the present form is perform, the past form is performed
If the present form is hear, the past form is heard
If the present form is include, the past form is included
If the present form is spend, the past form is spent
If the present form is discover, the past form is discovered
If the present form is believe, the past form is believed
If the present form is agree, the past form is agreed
If the present form is remain, the past form is
2024-07-31 08:06:13 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 08:08:18 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1504,  0.0257,  0.2424,  ..., -0.5991,  0.1376, -0.2064],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.0264, -0.8154,  0.7349,  ..., -2.6152, -0.4082, -1.5791],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.1175, -0.0246, -0.0018,  ..., -0.0075,  0.0322,  0.0186],
        [-0.0493,  0.0709, -0.0282,  ...,  0.0195,  0.0002, -0.0141],
        [-0.0041,  0.0096,  0.0734,  ..., -0.0118, -0.0413, -0.0081],
        ...,
        [-0.0266,  0.0169,  0.0048,  ...,  0.0901, -0.0040,  0.0077],
        [ 0.0313, -0.0071, -0.0058,  ..., -0.0002,  0.0405,  0.0134],
        [-0.0531,  0.0342, -0.0199,  ..., -0.0155, -0.0198,  0.0631]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.0284, -0.5244,  0.5508,  ..., -2.1953, -0.3948, -1.5986]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 08:08:19 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If the present form is perform, the past form is performed
If the present form is hear, the past form is heard
If the present form is include, the past form is included
If the present form is spend, the past form is spent
If the present form is discover, the past form is discovered
If the present form is believe, the past form is believed
If the present form is agree, the past form is agreed
If the present form is remain, the past form is
2024-07-31 08:08:19 root INFO     [order_1_approx] starting weight calculation for If the present form is discover, the past form is discovered
If the present form is hear, the past form is heard
If the present form is include, the past form is included
If the present form is spend, the past form is spent
If the present form is agree, the past form is agreed
If the present form is believe, the past form is believed
If the present form is remain, the past form is remained
If the present form is perform, the past form is
2024-07-31 08:08:19 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 08:10:21 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0472,  0.2678, -0.1804,  ..., -0.7368, -0.1967, -0.1794],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.5020e-01,  9.7656e-04,  2.7520e+00,  ..., -1.8496e+00,
        -2.0430e+00, -1.6074e+00], device='cuda:0', dtype=torch.float16,
       grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 6.5796e-02, -8.8501e-04, -2.4796e-05,  ..., -5.7640e-03,
          3.1372e-02,  1.2039e-02],
        [-1.5717e-02,  6.9397e-02, -1.8234e-03,  ...,  1.5961e-02,
          1.0010e-02, -1.4465e-02],
        [ 3.9948e-02, -2.0242e-04,  4.0100e-02,  ..., -6.1226e-03,
          4.7302e-03,  2.3468e-02],
        ...,
        [-3.3665e-03,  2.3079e-03, -2.3727e-02,  ...,  7.3242e-02,
          4.0703e-03,  4.2953e-03],
        [-4.9629e-03, -9.5520e-03,  9.0637e-03,  ...,  3.2673e-03,
          3.3661e-02, -1.1040e-02],
        [-1.6571e-02, -8.0109e-03,  8.4229e-03,  ..., -2.4841e-02,
         -2.5116e-02,  2.8992e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.8384, -0.0581,  2.5020,  ..., -1.7920, -1.7627, -0.8940]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 08:10:23 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If the present form is discover, the past form is discovered
If the present form is hear, the past form is heard
If the present form is include, the past form is included
If the present form is spend, the past form is spent
If the present form is agree, the past form is agreed
If the present form is believe, the past form is believed
If the present form is remain, the past form is remained
If the present form is perform, the past form is
2024-07-31 08:10:23 root INFO     total operator prediction time: 1000.2158904075623 seconds
2024-07-31 08:10:23 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on verb_Ving - Ved
2024-07-31 08:10:23 root INFO     building operator verb_Ving - Ved
2024-07-31 08:10:23 root INFO     [order_1_approx] starting weight calculation for After something is considering, it has considered
After something is reducing, it has reduced
After something is replacing, it has replaced
After something is receiving, it has received
After something is losing, it has lost
After something is creating, it has created
After something is representing, it has represented
After something is providing, it has
2024-07-31 08:10:23 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 08:12:23 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1824, -0.4180, -0.1322,  ..., -0.4170,  0.2377, -0.4360],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.1875, -2.9883,  1.9561,  ..., -1.9912, -2.0371, -0.0879],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0837,  0.0049,  0.0302,  ..., -0.0015,  0.0072,  0.0173],
        [-0.0357,  0.0592, -0.0032,  ...,  0.0083,  0.0019,  0.0067],
        [ 0.0084, -0.0200,  0.0465,  ..., -0.0077, -0.0005, -0.0115],
        ...,
        [ 0.0054,  0.0012,  0.0060,  ...,  0.0856,  0.0008,  0.0050],
        [ 0.0072, -0.0030, -0.0229,  ..., -0.0009,  0.0690, -0.0336],
        [-0.0085,  0.0165, -0.0013,  ..., -0.0220, -0.0096,  0.0591]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.5703, -2.3809,  2.2676,  ..., -1.3945, -2.1914,  0.0386]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 08:12:24 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for After something is considering, it has considered
After something is reducing, it has reduced
After something is replacing, it has replaced
After something is receiving, it has received
After something is losing, it has lost
After something is creating, it has created
After something is representing, it has represented
After something is providing, it has
2024-07-31 08:12:24 root INFO     [order_1_approx] starting weight calculation for After something is receiving, it has received
After something is reducing, it has reduced
After something is creating, it has created
After something is replacing, it has replaced
After something is representing, it has represented
After something is providing, it has provided
After something is considering, it has considered
After something is losing, it has
2024-07-31 08:12:24 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 08:14:26 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1193, -0.3032,  0.1812,  ..., -0.4705,  0.6299, -0.2788],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.2329, -0.5391,  0.5327,  ..., -2.4277, -0.4209, -1.6592],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0748,  0.0103,  0.0163,  ...,  0.0009, -0.0097,  0.0112],
        [-0.0244,  0.0501,  0.0006,  ...,  0.0155, -0.0015,  0.0006],
        [ 0.0116, -0.0006,  0.0355,  ..., -0.0101,  0.0049, -0.0250],
        ...,
        [-0.0078,  0.0316, -0.0063,  ...,  0.0461,  0.0001,  0.0117],
        [ 0.0050,  0.0083, -0.0067,  ..., -0.0030,  0.0520, -0.0287],
        [-0.0088,  0.0178,  0.0378,  ..., -0.0417, -0.0024,  0.0351]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.3386, -0.5615,  0.6670,  ..., -2.0566, -0.4854, -1.9600]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 08:14:28 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for After something is receiving, it has received
After something is reducing, it has reduced
After something is creating, it has created
After something is replacing, it has replaced
After something is representing, it has represented
After something is providing, it has provided
After something is considering, it has considered
After something is losing, it has
2024-07-31 08:14:28 root INFO     [order_1_approx] starting weight calculation for After something is reducing, it has reduced
After something is replacing, it has replaced
After something is considering, it has considered
After something is creating, it has created
After something is providing, it has provided
After something is losing, it has lost
After something is receiving, it has received
After something is representing, it has
2024-07-31 08:14:28 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 08:16:34 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2306,  0.0497, -0.5269,  ..., -0.3325,  0.3711, -0.2776],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.9580,  0.7407,  2.3906,  ..., -1.5283, -0.8608, -0.7090],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0643,  0.0102,  0.0154,  ...,  0.0029,  0.0074,  0.0098],
        [-0.0197,  0.0700, -0.0132,  ...,  0.0099, -0.0025, -0.0112],
        [ 0.0057,  0.0050,  0.0564,  ..., -0.0052, -0.0119, -0.0192],
        ...,
        [ 0.0113,  0.0175, -0.0010,  ...,  0.0733,  0.0036,  0.0047],
        [ 0.0041,  0.0062, -0.0011,  ..., -0.0117,  0.0491, -0.0257],
        [-0.0175, -0.0015,  0.0105,  ..., -0.0050, -0.0150,  0.0515]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.0557,  0.8628,  2.4297,  ..., -1.3867, -0.7646, -0.9766]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 08:16:35 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for After something is reducing, it has reduced
After something is replacing, it has replaced
After something is considering, it has considered
After something is creating, it has created
After something is providing, it has provided
After something is losing, it has lost
After something is receiving, it has received
After something is representing, it has
2024-07-31 08:16:35 root INFO     [order_1_approx] starting weight calculation for After something is representing, it has represented
After something is providing, it has provided
After something is considering, it has considered
After something is receiving, it has received
After something is reducing, it has reduced
After something is losing, it has lost
After something is replacing, it has replaced
After something is creating, it has
2024-07-31 08:16:35 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 08:18:40 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1558,  0.0905,  0.2378,  ..., -0.3235, -0.0378, -0.4062],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.2773, -0.0692,  2.2305,  ..., -0.6270, -2.2246, -0.3789],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0735,  0.0064,  0.0095,  ...,  0.0077, -0.0074,  0.0109],
        [-0.0101,  0.0737, -0.0088,  ...,  0.0156, -0.0041,  0.0027],
        [ 0.0056, -0.0063,  0.0634,  ...,  0.0181,  0.0069, -0.0178],
        ...,
        [ 0.0008,  0.0236,  0.0057,  ...,  0.0631, -0.0034, -0.0134],
        [ 0.0150,  0.0088, -0.0141,  ..., -0.0212,  0.0679, -0.0204],
        [-0.0175,  0.0032,  0.0028,  ..., -0.0087, -0.0087,  0.0482]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.1301, -0.2751,  1.8984,  ..., -0.3315, -2.5352, -0.3394]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 08:18:41 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for After something is representing, it has represented
After something is providing, it has provided
After something is considering, it has considered
After something is receiving, it has received
After something is reducing, it has reduced
After something is losing, it has lost
After something is replacing, it has replaced
After something is creating, it has
2024-07-31 08:18:41 root INFO     [order_1_approx] starting weight calculation for After something is representing, it has represented
After something is losing, it has lost
After something is creating, it has created
After something is reducing, it has reduced
After something is replacing, it has replaced
After something is considering, it has considered
After something is providing, it has provided
After something is receiving, it has
2024-07-31 08:18:41 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 08:20:46 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1304,  0.4722,  0.3042,  ..., -0.3030, -0.0317, -0.2262],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.9102,  0.5918, -0.2056,  ..., -2.8242, -2.1543, -2.2266],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0637, -0.0020,  0.0163,  ..., -0.0033,  0.0146,  0.0305],
        [-0.0249,  0.0462, -0.0093,  ...,  0.0146,  0.0037, -0.0114],
        [ 0.0180,  0.0027,  0.0370,  ..., -0.0207,  0.0007, -0.0146],
        ...,
        [ 0.0061,  0.0203,  0.0091,  ...,  0.0644, -0.0132,  0.0009],
        [ 0.0066,  0.0086, -0.0027,  ..., -0.0062,  0.0626, -0.0196],
        [-0.0190,  0.0154,  0.0192,  ..., -0.0094,  0.0035,  0.0340]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.8486,  0.5386, -0.1975,  ..., -2.6152, -2.1484, -2.1758]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 08:20:47 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for After something is representing, it has represented
After something is losing, it has lost
After something is creating, it has created
After something is reducing, it has reduced
After something is replacing, it has replaced
After something is considering, it has considered
After something is providing, it has provided
After something is receiving, it has
2024-07-31 08:20:48 root INFO     [order_1_approx] starting weight calculation for After something is representing, it has represented
After something is receiving, it has received
After something is considering, it has considered
After something is providing, it has provided
After something is creating, it has created
After something is replacing, it has replaced
After something is losing, it has lost
After something is reducing, it has
2024-07-31 08:20:48 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 08:22:54 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1272, -0.1357, -0.1349,  ..., -0.4546,  0.2067, -0.3647],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.7266,  0.3311,  0.6797,  ..., -5.1406, -1.0156, -5.0391],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0537, -0.0062, -0.0042,  ..., -0.0102,  0.0070,  0.0144],
        [-0.0103,  0.0512,  0.0005,  ...,  0.0251,  0.0080,  0.0164],
        [-0.0066, -0.0034,  0.0317,  ..., -0.0141, -0.0015, -0.0192],
        ...,
        [ 0.0089,  0.0047, -0.0066,  ...,  0.0654,  0.0138,  0.0019],
        [-0.0041,  0.0012, -0.0086,  ..., -0.0074,  0.0571, -0.0109],
        [-0.0140,  0.0043,  0.0155,  ..., -0.0045, -0.0072,  0.0389]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.7559,  0.1582,  0.5981,  ..., -4.5781, -0.8960, -5.0117]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 08:22:55 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for After something is representing, it has represented
After something is receiving, it has received
After something is considering, it has considered
After something is providing, it has provided
After something is creating, it has created
After something is replacing, it has replaced
After something is losing, it has lost
After something is reducing, it has
2024-07-31 08:22:55 root INFO     [order_1_approx] starting weight calculation for After something is replacing, it has replaced
After something is representing, it has represented
After something is losing, it has lost
After something is creating, it has created
After something is providing, it has provided
After something is receiving, it has received
After something is reducing, it has reduced
After something is considering, it has
2024-07-31 08:22:55 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 08:25:01 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0958, -0.2112,  0.0446,  ..., -0.2122,  0.2546, -0.3552],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.4062, -0.3735,  3.7461,  ..., -2.0859, -0.6489, -0.4199],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0700,  0.0050,  0.0159,  ...,  0.0026,  0.0032,  0.0233],
        [-0.0033,  0.0393,  0.0001,  ...,  0.0117, -0.0062,  0.0100],
        [-0.0142, -0.0037,  0.0377,  ..., -0.0196, -0.0073, -0.0364],
        ...,
        [ 0.0027,  0.0044,  0.0193,  ...,  0.0606,  0.0025,  0.0147],
        [ 0.0026,  0.0159,  0.0023,  ..., -0.0170,  0.0504, -0.0274],
        [ 0.0052,  0.0149,  0.0097,  ..., -0.0080, -0.0168,  0.0249]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.1914, -0.4165,  3.3164,  ..., -1.6719, -0.8735, -0.4685]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 08:25:02 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for After something is replacing, it has replaced
After something is representing, it has represented
After something is losing, it has lost
After something is creating, it has created
After something is providing, it has provided
After something is receiving, it has received
After something is reducing, it has reduced
After something is considering, it has
2024-07-31 08:25:02 root INFO     [order_1_approx] starting weight calculation for After something is considering, it has considered
After something is representing, it has represented
After something is losing, it has lost
After something is providing, it has provided
After something is creating, it has created
After something is reducing, it has reduced
After something is receiving, it has received
After something is replacing, it has
2024-07-31 08:25:02 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 08:27:04 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1599, -0.3682, -0.7275,  ..., -0.2172,  0.1553, -0.3506],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.0156, -0.1484,  0.1938,  ..., -2.0254, -0.0298,  0.8516],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0742, -0.0112,  0.0161,  ..., -0.0073,  0.0008,  0.0143],
        [-0.0289,  0.0723, -0.0291,  ...,  0.0132,  0.0052,  0.0057],
        [ 0.0154, -0.0041,  0.0309,  ..., -0.0270, -0.0030, -0.0270],
        ...,
        [ 0.0197,  0.0202, -0.0126,  ...,  0.0940, -0.0040,  0.0067],
        [ 0.0119,  0.0095, -0.0022,  ..., -0.0155,  0.0740, -0.0080],
        [-0.0012,  0.0179,  0.0065,  ..., -0.0007, -0.0141,  0.0597]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.1949, -0.0044,  0.2837,  ..., -1.8945, -0.0968,  0.5098]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 08:27:05 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for After something is considering, it has considered
After something is representing, it has represented
After something is losing, it has lost
After something is providing, it has provided
After something is creating, it has created
After something is reducing, it has reduced
After something is receiving, it has received
After something is replacing, it has
2024-07-31 08:27:05 root INFO     total operator prediction time: 1002.8823750019073 seconds
2024-07-31 08:27:05 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on Ving - verb_inf
2024-07-31 08:27:05 root INFO     building operator Ving - verb_inf
2024-07-31 08:27:06 root INFO     [order_1_approx] starting weight calculation for happening is the active form of happen
preventing is the active form of prevent
enjoying is the active form of enjoy
understanding is the active form of understand
sitting is the active form of sit
promoting is the active form of promote
following is the active form of follow
adding is the active form of
2024-07-31 08:27:06 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 08:29:11 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1456, -0.6113,  0.2112,  ..., -0.0065,  0.1016, -0.4736],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.4199, -2.3672, -1.9180,  ...,  3.6660, -3.4219, -1.2598],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0824, -0.0091,  0.0137,  ..., -0.0080, -0.0021,  0.0180],
        [-0.0023,  0.0594,  0.0022,  ...,  0.0139, -0.0245, -0.0144],
        [ 0.0234, -0.0132,  0.0542,  ..., -0.0056, -0.0019,  0.0038],
        ...,
        [ 0.0231,  0.0276, -0.0009,  ...,  0.0772, -0.0051, -0.0013],
        [-0.0057,  0.0056,  0.0072,  ..., -0.0040,  0.0394, -0.0173],
        [-0.0044,  0.0118, -0.0131,  ..., -0.0369, -0.0320,  0.0798]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.7109, -2.5273, -2.0840,  ...,  3.3594, -3.4824, -1.1719]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 08:29:12 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for happening is the active form of happen
preventing is the active form of prevent
enjoying is the active form of enjoy
understanding is the active form of understand
sitting is the active form of sit
promoting is the active form of promote
following is the active form of follow
adding is the active form of
2024-07-31 08:29:12 root INFO     [order_1_approx] starting weight calculation for adding is the active form of add
following is the active form of follow
sitting is the active form of sit
preventing is the active form of prevent
enjoying is the active form of enjoy
understanding is the active form of understand
happening is the active form of happen
promoting is the active form of
2024-07-31 08:29:12 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 08:31:18 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0985, -0.2449,  0.0502,  ...,  0.3262,  0.3193, -0.0878],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.2207, -4.0547, -0.3555,  ...,  2.4727, -2.3281, -2.0020],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0634,  0.0142,  0.0071,  ...,  0.0019, -0.0026,  0.0123],
        [-0.0038,  0.0532,  0.0038,  ...,  0.0132, -0.0121, -0.0083],
        [ 0.0146, -0.0072,  0.0424,  ...,  0.0064, -0.0021, -0.0006],
        ...,
        [ 0.0122, -0.0030,  0.0117,  ...,  0.0630, -0.0118, -0.0096],
        [-0.0058,  0.0099, -0.0012,  ...,  0.0141,  0.0372, -0.0178],
        [ 0.0015, -0.0022, -0.0161,  ..., -0.0144, -0.0216,  0.0536]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.2246, -3.8203, -0.3494,  ...,  2.6465, -2.2695, -1.9434]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 08:31:19 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for adding is the active form of add
following is the active form of follow
sitting is the active form of sit
preventing is the active form of prevent
enjoying is the active form of enjoy
understanding is the active form of understand
happening is the active form of happen
promoting is the active form of
2024-07-31 08:31:20 root INFO     [order_1_approx] starting weight calculation for preventing is the active form of prevent
enjoying is the active form of enjoy
happening is the active form of happen
adding is the active form of add
promoting is the active form of promote
sitting is the active form of sit
understanding is the active form of understand
following is the active form of
2024-07-31 08:31:20 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 08:33:24 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4399, -0.4998,  0.0398,  ...,  0.0764, -0.0596, -0.0652],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.6699, -3.7656,  2.0156,  ...,  2.3164, -1.8535, -2.1836],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0679, -0.0031, -0.0006,  ...,  0.0052,  0.0142,  0.0164],
        [ 0.0074,  0.0722, -0.0006,  ...,  0.0107, -0.0068, -0.0133],
        [ 0.0058, -0.0005,  0.0372,  ..., -0.0059, -0.0144, -0.0026],
        ...,
        [ 0.0079,  0.0173, -0.0067,  ...,  0.0514, -0.0199,  0.0038],
        [-0.0031, -0.0011,  0.0075,  ...,  0.0055,  0.0360, -0.0068],
        [-0.0112,  0.0091, -0.0043,  ..., -0.0057, -0.0059,  0.0451]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.6562, -3.9551,  2.1055,  ...,  2.3750, -1.8672, -2.1133]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 08:33:25 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for preventing is the active form of prevent
enjoying is the active form of enjoy
happening is the active form of happen
adding is the active form of add
promoting is the active form of promote
sitting is the active form of sit
understanding is the active form of understand
following is the active form of
2024-07-31 08:33:25 root INFO     [order_1_approx] starting weight calculation for promoting is the active form of promote
adding is the active form of add
happening is the active form of happen
preventing is the active form of prevent
understanding is the active form of understand
following is the active form of follow
enjoying is the active form of enjoy
sitting is the active form of
2024-07-31 08:33:25 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 08:35:29 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4673, -0.3916, -0.1231,  ...,  0.3679, -0.5762,  0.0557],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.4199, -3.8613, -0.7070,  ..., -0.5991,  0.8271, -2.8945],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0924, -0.0131,  0.0066,  ...,  0.0016, -0.0014,  0.0050],
        [ 0.0063,  0.0359,  0.0048,  ...,  0.0113, -0.0167, -0.0211],
        [-0.0075, -0.0107,  0.0486,  ...,  0.0003, -0.0039,  0.0021],
        ...,
        [-0.0072, -0.0063,  0.0026,  ...,  0.0534, -0.0211, -0.0182],
        [-0.0159,  0.0120, -0.0093,  ...,  0.0050,  0.0379, -0.0022],
        [-0.0074,  0.0042,  0.0004,  ..., -0.0121, -0.0211,  0.0626]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.1016, -3.8105, -0.7437,  ..., -0.2690,  0.5391, -2.9746]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 08:35:30 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for promoting is the active form of promote
adding is the active form of add
happening is the active form of happen
preventing is the active form of prevent
understanding is the active form of understand
following is the active form of follow
enjoying is the active form of enjoy
sitting is the active form of
2024-07-31 08:35:30 root INFO     [order_1_approx] starting weight calculation for enjoying is the active form of enjoy
understanding is the active form of understand
adding is the active form of add
sitting is the active form of sit
promoting is the active form of promote
following is the active form of follow
preventing is the active form of prevent
happening is the active form of
2024-07-31 08:35:30 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 08:37:29 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.3250, -0.0471,  0.4985,  ..., -0.3381,  0.0779, -0.5615],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.7295, -3.4336,  0.9023,  ...,  2.1758, -2.5703, -0.3574],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0538, -0.0068, -0.0045,  ..., -0.0002, -0.0030,  0.0137],
        [-0.0017,  0.0354,  0.0034,  ...,  0.0039,  0.0009, -0.0141],
        [ 0.0061, -0.0030,  0.0239,  ...,  0.0083,  0.0023, -0.0276],
        ...,
        [ 0.0028,  0.0083, -0.0082,  ...,  0.0399, -0.0043, -0.0160],
        [-0.0084,  0.0017,  0.0037,  ...,  0.0019,  0.0317,  0.0059],
        [-0.0069,  0.0025,  0.0075,  ..., -0.0040, -0.0126,  0.0420]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.6514, -3.5469,  0.9834,  ...,  2.3301, -2.6309, -0.4512]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 08:37:30 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for enjoying is the active form of enjoy
understanding is the active form of understand
adding is the active form of add
sitting is the active form of sit
promoting is the active form of promote
following is the active form of follow
preventing is the active form of prevent
happening is the active form of
2024-07-31 08:37:30 root INFO     [order_1_approx] starting weight calculation for happening is the active form of happen
promoting is the active form of promote
preventing is the active form of prevent
sitting is the active form of sit
enjoying is the active form of enjoy
following is the active form of follow
adding is the active form of add
understanding is the active form of
2024-07-31 08:37:30 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 08:39:32 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.3286, -0.0360,  0.1862,  ...,  0.0439,  0.0183, -0.4741],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.3984, -2.2598,  0.3523,  ...,  0.3452, -0.7285, -0.5527],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0583, -0.0021,  0.0046,  ..., -0.0006, -0.0015,  0.0145],
        [ 0.0124,  0.0435, -0.0062,  ...,  0.0146, -0.0058,  0.0040],
        [ 0.0051, -0.0236,  0.0421,  ..., -0.0037, -0.0056, -0.0099],
        ...,
        [ 0.0010,  0.0065, -0.0108,  ...,  0.0585,  0.0108, -0.0090],
        [-0.0093,  0.0066,  0.0111,  ..., -0.0003,  0.0269, -0.0013],
        [ 0.0097,  0.0089,  0.0002,  ..., -0.0146, -0.0084,  0.0402]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.3574, -2.3301,  0.3611,  ...,  0.4744, -0.9067, -0.6543]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 08:39:33 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for happening is the active form of happen
promoting is the active form of promote
preventing is the active form of prevent
sitting is the active form of sit
enjoying is the active form of enjoy
following is the active form of follow
adding is the active form of add
understanding is the active form of
2024-07-31 08:39:33 root INFO     [order_1_approx] starting weight calculation for happening is the active form of happen
adding is the active form of add
sitting is the active form of sit
following is the active form of follow
enjoying is the active form of enjoy
promoting is the active form of promote
understanding is the active form of understand
preventing is the active form of
2024-07-31 08:39:33 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 08:41:36 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1129, -0.3872,  0.1290,  ..., -0.4370,  0.0779, -0.4761],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.3789, -3.5645, -1.7051,  ...,  2.2207, -0.6426, -2.3105],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 4.3823e-02, -8.7509e-03,  7.8278e-03,  ...,  1.2505e-02,
         -6.3934e-03,  1.6632e-02],
        [-8.5220e-03,  3.8635e-02,  1.5860e-03,  ...,  7.4234e-03,
         -2.0142e-03, -8.3466e-03],
        [ 1.4053e-02, -1.6739e-02,  2.7328e-02,  ...,  6.1111e-03,
         -9.9182e-04, -5.9204e-03],
        ...,
        [ 8.1177e-03, -4.0054e-05, -2.1210e-03,  ...,  3.7323e-02,
         -3.5515e-03,  1.6632e-03],
        [-4.5547e-03, -5.3635e-03, -1.1959e-03,  ..., -3.1109e-03,
          3.2623e-02, -1.8661e-02],
        [-3.2196e-03,  3.3875e-03, -1.1616e-03,  ..., -1.4534e-03,
         -4.1389e-03,  3.6682e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.6045, -3.4668, -1.7412,  ...,  2.3105, -0.7783, -2.0938]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 08:41:38 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for happening is the active form of happen
adding is the active form of add
sitting is the active form of sit
following is the active form of follow
enjoying is the active form of enjoy
promoting is the active form of promote
understanding is the active form of understand
preventing is the active form of
2024-07-31 08:41:38 root INFO     [order_1_approx] starting weight calculation for following is the active form of follow
adding is the active form of add
promoting is the active form of promote
understanding is the active form of understand
sitting is the active form of sit
happening is the active form of happen
preventing is the active form of prevent
enjoying is the active form of
2024-07-31 08:41:38 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 08:43:39 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1921, -0.3313,  0.1687,  ..., -0.5757, -0.0955, -0.1508],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.0371, -3.2617, -0.8208,  ...,  1.8955, -2.6699, -2.9434],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.1037, -0.0167,  0.0090,  ...,  0.0037,  0.0050,  0.0214],
        [ 0.0091,  0.0837, -0.0069,  ...,  0.0154, -0.0045, -0.0097],
        [ 0.0176, -0.0183,  0.0633,  ...,  0.0018,  0.0030, -0.0177],
        ...,
        [-0.0105, -0.0025, -0.0042,  ...,  0.0789, -0.0146, -0.0246],
        [-0.0037,  0.0088,  0.0054,  ...,  0.0111,  0.0545, -0.0124],
        [-0.0139,  0.0022, -0.0103,  ..., -0.0179, -0.0203,  0.0754]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.2637, -3.3848, -1.0371,  ...,  2.4258, -2.7324, -2.8848]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 08:43:40 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for following is the active form of follow
adding is the active form of add
promoting is the active form of promote
understanding is the active form of understand
sitting is the active form of sit
happening is the active form of happen
preventing is the active form of prevent
enjoying is the active form of
2024-07-31 08:43:40 root INFO     total operator prediction time: 994.505133152008 seconds
2024-07-31 08:43:40 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on noun - plural_irreg
2024-07-31 08:43:40 root INFO     building operator noun - plural_irreg
2024-07-31 08:43:40 root INFO     [order_1_approx] starting weight calculation for The plural form of family is families
The plural form of business is businesses
The plural form of datum is data
The plural form of theory is theories
The plural form of safety is safeties
The plural form of majority is majorities
The plural form of loss is losses
The plural form of agency is
2024-07-31 08:43:40 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 08:45:44 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2144,  0.8086, -0.3926,  ..., -0.3354,  0.0686, -0.4009],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.4431, -0.1572,  2.7188,  ..., -1.4238,  0.0562, -3.6758],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0698,  0.0151,  0.0197,  ..., -0.0038,  0.0027,  0.0092],
        [-0.0045,  0.0827, -0.0186,  ...,  0.0310, -0.0012,  0.0139],
        [ 0.0016, -0.0045,  0.0840,  ...,  0.0283,  0.0092,  0.0109],
        ...,
        [ 0.0297,  0.0336, -0.0137,  ...,  0.1162, -0.0081,  0.0041],
        [-0.0222,  0.0278,  0.0149,  ...,  0.0245,  0.1039,  0.0128],
        [ 0.0271, -0.0113, -0.0174,  ..., -0.0067, -0.0027,  0.1003]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.8403,  0.0935,  2.6230,  ..., -1.1406, -0.1508, -3.2109]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 08:45:45 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of family is families
The plural form of business is businesses
The plural form of datum is data
The plural form of theory is theories
The plural form of safety is safeties
The plural form of majority is majorities
The plural form of loss is losses
The plural form of agency is
2024-07-31 08:45:45 root INFO     [order_1_approx] starting weight calculation for The plural form of business is businesses
The plural form of datum is data
The plural form of safety is safeties
The plural form of loss is losses
The plural form of family is families
The plural form of agency is agencies
The plural form of theory is theories
The plural form of majority is
2024-07-31 08:45:45 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 08:47:47 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3472,  0.6519, -0.6621,  ...,  0.2676, -0.2886, -0.2510],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.9688, -0.5308, -1.5195,  ..., -5.6250, -1.1465, -2.4238],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0762,  0.0074,  0.0167,  ...,  0.0102, -0.0151, -0.0042],
        [ 0.0322,  0.0690,  0.0013,  ...,  0.0442, -0.0071,  0.0057],
        [ 0.0408,  0.0055,  0.0812,  ..., -0.0068,  0.0013,  0.0072],
        ...,
        [ 0.0373,  0.0378,  0.0499,  ...,  0.0686, -0.0252,  0.0286],
        [-0.0350,  0.0164, -0.0271,  ..., -0.0081,  0.0385,  0.0046],
        [ 0.0183,  0.0081, -0.0149,  ...,  0.0259,  0.0004,  0.0831]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.6660, -0.2039, -1.3311,  ..., -4.8984, -1.5000, -2.5156]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 08:47:48 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of business is businesses
The plural form of datum is data
The plural form of safety is safeties
The plural form of loss is losses
The plural form of family is families
The plural form of agency is agencies
The plural form of theory is theories
The plural form of majority is
2024-07-31 08:47:48 root INFO     [order_1_approx] starting weight calculation for The plural form of loss is losses
The plural form of agency is agencies
The plural form of majority is majorities
The plural form of datum is data
The plural form of business is businesses
The plural form of family is families
The plural form of theory is theories
The plural form of safety is
2024-07-31 08:47:48 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 08:49:55 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0050, -0.1119, -0.2615,  ...,  0.1942,  0.0959, -0.1520],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.4648, -1.5459, -0.2058,  ...,  0.1050, -4.0312, -2.7559],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.1306,  0.0046, -0.0016,  ..., -0.0083, -0.0243,  0.0028],
        [-0.0171,  0.1081, -0.0117,  ...,  0.0222,  0.0296,  0.0037],
        [ 0.0276,  0.0241,  0.1073,  ...,  0.0110,  0.0031, -0.0066],
        ...,
        [ 0.0003,  0.0431,  0.0331,  ...,  0.1076, -0.0209,  0.0077],
        [-0.0029,  0.0223,  0.0077,  ..., -0.0028,  0.0710,  0.0159],
        [-0.0082, -0.0032,  0.0077,  ...,  0.0154, -0.0176,  0.1014]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.0879, -1.8018, -0.0054,  ...,  0.3472, -4.0000, -2.2383]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 08:49:56 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of loss is losses
The plural form of agency is agencies
The plural form of majority is majorities
The plural form of datum is data
The plural form of business is businesses
The plural form of family is families
The plural form of theory is theories
The plural form of safety is
2024-07-31 08:49:56 root INFO     [order_1_approx] starting weight calculation for The plural form of safety is safeties
The plural form of theory is theories
The plural form of agency is agencies
The plural form of loss is losses
The plural form of majority is majorities
The plural form of family is families
The plural form of datum is data
The plural form of business is
2024-07-31 08:49:56 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 08:51:55 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0334,  0.5752,  0.0397,  ..., -0.0197, -0.1978, -0.2915],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.9961, -2.4492, -0.7988,  ...,  0.2622, -0.1033, -1.8730],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0660,  0.0070, -0.0075,  ...,  0.0003, -0.0064,  0.0296],
        [ 0.0046,  0.0660,  0.0009,  ...,  0.0358, -0.0109, -0.0088],
        [ 0.0081,  0.0116,  0.0711,  ...,  0.0078,  0.0168,  0.0181],
        ...,
        [ 0.0242,  0.0137,  0.0106,  ...,  0.0615,  0.0057, -0.0062],
        [-0.0196,  0.0273, -0.0068,  ..., -0.0035,  0.0658,  0.0004],
        [-0.0073, -0.0011, -0.0125,  ..., -0.0035, -0.0087,  0.0693]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.0742, -2.0879, -0.9058,  ...,  0.1790, -0.2412, -1.7334]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 08:51:56 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of safety is safeties
The plural form of theory is theories
The plural form of agency is agencies
The plural form of loss is losses
The plural form of majority is majorities
The plural form of family is families
The plural form of datum is data
The plural form of business is
2024-07-31 08:51:56 root INFO     [order_1_approx] starting weight calculation for The plural form of safety is safeties
The plural form of loss is losses
The plural form of business is businesses
The plural form of majority is majorities
The plural form of family is families
The plural form of datum is data
The plural form of agency is agencies
The plural form of theory is
2024-07-31 08:51:56 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 08:53:56 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0933, -0.1130, -0.2377,  ..., -0.3535, -0.1882, -0.0494],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.1172, -2.7520,  2.4160,  ..., -0.0310, -2.7383, -3.5176],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0599, -0.0101, -0.0040,  ...,  0.0068,  0.0008,  0.0179],
        [-0.0084,  0.0712,  0.0078,  ...,  0.0028, -0.0022,  0.0097],
        [-0.0022, -0.0052,  0.0161,  ..., -0.0089,  0.0081,  0.0059],
        ...,
        [ 0.0112,  0.0143,  0.0094,  ...,  0.0354, -0.0231,  0.0152],
        [ 0.0050,  0.0203,  0.0077,  ..., -0.0024,  0.0376, -0.0157],
        [ 0.0077,  0.0091,  0.0025,  ...,  0.0056,  0.0058,  0.0533]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.9648, -2.6973,  2.3281,  ..., -0.2045, -2.7207, -3.4609]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 08:53:57 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of safety is safeties
The plural form of loss is losses
The plural form of business is businesses
The plural form of majority is majorities
The plural form of family is families
The plural form of datum is data
The plural form of agency is agencies
The plural form of theory is
2024-07-31 08:53:57 root INFO     [order_1_approx] starting weight calculation for The plural form of agency is agencies
The plural form of majority is majorities
The plural form of theory is theories
The plural form of family is families
The plural form of business is businesses
The plural form of datum is data
The plural form of safety is safeties
The plural form of loss is
2024-07-31 08:53:57 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 08:56:03 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1365,  0.5669,  0.1709,  ..., -0.1730,  0.5801, -0.3127],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.3867, -0.5195, -2.2402,  ..., -2.0840, -2.4336, -1.8525],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 8.4534e-02,  5.4245e-03, -3.7804e-03,  ...,  1.0956e-02,
          2.2675e-02,  2.7344e-02],
        [ 7.9060e-04,  1.0034e-01,  9.1791e-05,  ...,  3.3447e-02,
         -1.2901e-02,  3.5706e-03],
        [ 4.8256e-03,  2.6436e-03,  7.3608e-02,  ..., -9.2163e-03,
         -1.6098e-03, -9.3002e-03],
        ...,
        [ 1.5778e-02,  2.6505e-02, -1.6388e-02,  ...,  6.7444e-02,
         -2.3331e-02,  1.1467e-02],
        [-1.8890e-02, -1.2798e-03, -1.2566e-02,  ..., -2.2171e-02,
          3.3295e-02, -1.2856e-03],
        [-8.6517e-03,  2.4719e-02,  9.7427e-03,  ..., -8.8043e-03,
          2.3251e-03,  9.1736e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.5791, -0.6792, -1.6191,  ..., -1.1768, -2.6484, -1.7451]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 08:56:04 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of agency is agencies
The plural form of majority is majorities
The plural form of theory is theories
The plural form of family is families
The plural form of business is businesses
The plural form of datum is data
The plural form of safety is safeties
The plural form of loss is
2024-07-31 08:56:05 root INFO     [order_1_approx] starting weight calculation for The plural form of safety is safeties
The plural form of business is businesses
The plural form of agency is agencies
The plural form of theory is theories
The plural form of majority is majorities
The plural form of family is families
The plural form of loss is losses
The plural form of datum is
2024-07-31 08:56:05 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
2024-07-31 08:58:08 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.5527,  0.3293, -0.4990,  ...,  0.0730, -0.5859,  0.0497],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.5332, -2.3281,  2.3594,  ..., -0.8066, -3.7910, -1.8193],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.1126, -0.0338,  0.0229,  ..., -0.0401,  0.0312, -0.0284],
        [ 0.0182,  0.1250,  0.0011,  ...,  0.0478, -0.0160,  0.0435],
        [ 0.0113,  0.0018,  0.0901,  ..., -0.0148,  0.0151, -0.0229],
        ...,
        [ 0.0171,  0.0289,  0.0028,  ...,  0.1191, -0.0521,  0.0279],
        [-0.0151,  0.0291,  0.0038,  ..., -0.0158,  0.0796, -0.0049],
        [ 0.0018,  0.0395, -0.0022,  ..., -0.0134, -0.0186,  0.1124]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.8320, -3.2734,  2.8164,  ..., -1.0010, -3.6992, -1.6611]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 08:58:10 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of safety is safeties
The plural form of business is businesses
The plural form of agency is agencies
The plural form of theory is theories
The plural form of majority is majorities
The plural form of family is families
The plural form of loss is losses
The plural form of datum is
2024-07-31 08:58:10 root INFO     [order_1_approx] starting weight calculation for The plural form of theory is theories
The plural form of majority is majorities
The plural form of loss is losses
The plural form of agency is agencies
The plural form of datum is data
The plural form of safety is safeties
The plural form of business is businesses
The plural form of family is
2024-07-31 08:58:10 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.14
