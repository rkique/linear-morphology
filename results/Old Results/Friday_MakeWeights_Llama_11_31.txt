2024-07-28 19:01:20 root INFO     loading model + tokenizer
2024-07-28 19:01:29 root INFO     loading model + tokenizer
2024-07-28 19:01:45 root INFO     loading model + tokenizer
2024-07-28 19:01:48 root INFO     model + tokenizer loaded
2024-07-28 19:01:48 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on verb+ment_irreg
2024-07-28 19:01:48 root INFO     building operator verb+ment_irreg
2024-07-28 19:01:49 root INFO     [order_1_approx] starting weight calculation for To entitle results in a entitlement
To invest results in a investment
To require results in a requirement
To establish results in a establishment
To encourage results in a encouragement
To replace results in a replacement
To develop results in a development
To appoint results in a
2024-07-28 19:01:49 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-28 19:04:10 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2507,  0.9629, -0.1558,  ...,  0.2554, -0.4377, -0.0551],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.6787, -3.9004,  1.2598,  ...,  4.1562, -2.1719, -2.3613],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 3.4821e-02,  1.4572e-03, -2.0126e-02,  ..., -2.7649e-02,
          3.7422e-03, -2.2888e-05],
        [ 1.1978e-02,  5.6152e-02,  5.3528e-02,  ...,  6.2805e-02,
          1.1261e-02, -5.6953e-03],
        [ 2.6825e-02, -1.6006e-02,  3.8239e-02,  ..., -6.2637e-03,
         -3.6102e-02, -5.0964e-03],
        ...,
        [-1.4412e-02,  1.2695e-02, -3.2158e-03,  ...,  3.6346e-02,
          2.3010e-02,  2.7283e-02],
        [-6.8626e-03,  1.9283e-03, -1.5778e-02,  ..., -1.4107e-02,
          1.2772e-02, -3.3936e-02],
        [ 9.0942e-03,  3.8567e-03,  3.0327e-04,  ...,  2.1973e-02,
         -2.2602e-04,  5.5725e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.0088, -3.5703,  1.4014,  ...,  3.7676, -2.2090, -2.4844]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 19:04:11 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To entitle results in a entitlement
To invest results in a investment
To require results in a requirement
To establish results in a establishment
To encourage results in a encouragement
To replace results in a replacement
To develop results in a development
To appoint results in a
2024-07-28 19:04:11 root INFO     [order_1_approx] starting weight calculation for To invest results in a investment
To replace results in a replacement
To require results in a requirement
To entitle results in a entitlement
To appoint results in a appointment
To establish results in a establishment
To encourage results in a encouragement
To develop results in a
2024-07-28 19:04:11 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-28 19:06:34 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1877,  0.4170, -0.3337,  ...,  0.0909, -0.2190,  0.0895],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.9512, -5.1875, -0.0901,  ...,  2.5527, -0.7842, -2.3223],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 3.6865e-02,  1.8936e-02, -8.9493e-03,  ...,  2.8610e-05,
         -1.4732e-02,  3.4454e-02],
        [-1.2604e-02,  5.9021e-02,  5.7526e-03,  ...,  1.1429e-02,
          1.2497e-02,  5.1498e-03],
        [ 5.7907e-03, -2.4292e-02,  4.0527e-02,  ...,  2.0752e-02,
          6.8741e-03,  8.2016e-03],
        ...,
        [ 1.5808e-02,  2.0180e-03,  6.7749e-03,  ...,  3.7628e-02,
         -2.8412e-02,  2.8488e-02],
        [-1.6357e-02, -5.8441e-03, -1.1002e-02,  ..., -4.7188e-03,
          2.6886e-02, -1.0864e-02],
        [-1.1299e-02, -4.8714e-03,  3.4561e-03,  ...,  1.7502e-02,
         -1.2817e-02,  5.0751e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.4502, -5.4023, -0.0745,  ...,  2.1738, -1.2988, -2.1230]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 19:06:35 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To invest results in a investment
To replace results in a replacement
To require results in a requirement
To entitle results in a entitlement
To appoint results in a appointment
To establish results in a establishment
To encourage results in a encouragement
To develop results in a
2024-07-28 19:06:35 root INFO     [order_1_approx] starting weight calculation for To invest results in a investment
To encourage results in a encouragement
To develop results in a development
To replace results in a replacement
To require results in a requirement
To establish results in a establishment
To appoint results in a appointment
To entitle results in a
2024-07-28 19:06:35 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-28 19:08:58 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2305,  0.5449, -0.4104,  ..., -0.1572, -0.3379,  0.4001],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.6157, -3.9688, -0.1152,  ...,  1.9150, -2.0391, -2.3066],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 3.9368e-02,  2.0081e-02, -2.3193e-02,  ...,  8.1940e-03,
         -8.9798e-03,  3.0556e-03],
        [ 4.2572e-03,  7.3608e-02,  1.5755e-03,  ...,  5.4718e-02,
          1.6556e-02,  1.9775e-02],
        [ 2.4872e-03, -3.4149e-02,  1.3618e-02,  ..., -6.0768e-03,
         -2.3514e-02,  2.4567e-03],
        ...,
        [ 5.2490e-03,  2.9968e-02,  9.3460e-05,  ...,  3.9154e-02,
          1.6479e-02,  3.5309e-02],
        [ 3.4332e-05, -1.1322e-02,  2.0203e-02,  ...,  2.0950e-02,
          3.9642e-02, -2.6611e-02],
        [ 1.0887e-02, -1.7624e-02, -1.6296e-02,  ...,  3.7292e-02,
         -5.2986e-03,  6.1798e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.7881, -3.3027, -0.1489,  ...,  2.1992, -2.2676, -2.0840]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 19:08:59 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To invest results in a investment
To encourage results in a encouragement
To develop results in a development
To replace results in a replacement
To require results in a requirement
To establish results in a establishment
To appoint results in a appointment
To entitle results in a
2024-07-28 19:08:59 root INFO     [order_1_approx] starting weight calculation for To develop results in a development
To invest results in a investment
To entitle results in a entitlement
To replace results in a replacement
To establish results in a establishment
To encourage results in a encouragement
To appoint results in a appointment
To require results in a
2024-07-28 19:08:59 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-28 19:11:22 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.3823,  0.6387, -0.6025,  ...,  0.0627, -0.3679, -0.0026],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.5889, -3.4121, -0.3799,  ...,  0.3481, -2.4043, -2.0898],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0308,  0.0018,  0.0048,  ...,  0.0040, -0.0278,  0.0080],
        [-0.0151,  0.0557,  0.0080,  ...,  0.0404,  0.0250,  0.0289],
        [ 0.0092, -0.0084,  0.0375,  ..., -0.0057, -0.0157,  0.0270],
        ...,
        [ 0.0170,  0.0093, -0.0013,  ...,  0.0594,  0.0140,  0.0173],
        [ 0.0082, -0.0073, -0.0053,  ..., -0.0125,  0.0138, -0.0385],
        [ 0.0105, -0.0139,  0.0213,  ...,  0.0131, -0.0043,  0.0423]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.3169, -2.9902, -0.1398,  ...,  0.6929, -2.3418, -1.9170]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 19:11:23 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To develop results in a development
To invest results in a investment
To entitle results in a entitlement
To replace results in a replacement
To establish results in a establishment
To encourage results in a encouragement
To appoint results in a appointment
To require results in a
2024-07-28 19:11:23 root INFO     [order_1_approx] starting weight calculation for To require results in a requirement
To entitle results in a entitlement
To invest results in a investment
To appoint results in a appointment
To establish results in a establishment
To develop results in a development
To encourage results in a encouragement
To replace results in a
2024-07-28 19:11:23 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-28 19:13:46 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1766,  0.1127, -0.5718,  ...,  0.1777, -0.2832,  0.1532],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.8525, -4.1484, -0.8452,  ...,  2.1738, -0.9932, -1.0957],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0557,  0.0119,  0.0063,  ..., -0.0140, -0.0059,  0.0270],
        [-0.0074,  0.0273,  0.0023,  ...,  0.0696,  0.0289,  0.0202],
        [ 0.0106, -0.0104,  0.0299,  ..., -0.0106, -0.0018,  0.0020],
        ...,
        [ 0.0003,  0.0069, -0.0147,  ...,  0.0627,  0.0065,  0.0329],
        [ 0.0055,  0.0235,  0.0081,  ..., -0.0134,  0.0354, -0.0270],
        [ 0.0103, -0.0319,  0.0033,  ...,  0.0184,  0.0037,  0.1115]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.6338, -3.4629,  0.0122,  ...,  2.6094, -1.3652, -1.3945]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 19:13:47 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To require results in a requirement
To entitle results in a entitlement
To invest results in a investment
To appoint results in a appointment
To establish results in a establishment
To develop results in a development
To encourage results in a encouragement
To replace results in a
2024-07-28 19:13:47 root INFO     [order_1_approx] starting weight calculation for To establish results in a establishment
To entitle results in a entitlement
To require results in a requirement
To replace results in a replacement
To encourage results in a encouragement
To develop results in a development
To appoint results in a appointment
To invest results in a
2024-07-28 19:13:47 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-28 19:16:09 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0151,  0.1570, -0.3232,  ..., -0.0238, -0.2424, -0.2289],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.8213, -2.5098, -0.9980,  ...,  1.6094, -0.5166, -2.5117],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0449,  0.0117, -0.0029,  ..., -0.0061, -0.0163, -0.0010],
        [-0.0027,  0.0549,  0.0175,  ...,  0.0424,  0.0308,  0.0155],
        [ 0.0061, -0.0046,  0.0493,  ..., -0.0165, -0.0113,  0.0099],
        ...,
        [ 0.0044,  0.0018,  0.0038,  ...,  0.0399,  0.0082, -0.0006],
        [-0.0046,  0.0073,  0.0240,  ...,  0.0058,  0.0482, -0.0172],
        [-0.0027, -0.0064,  0.0014,  ...,  0.0048,  0.0013,  0.0425]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.8140, -1.7676, -1.1270,  ...,  1.9629, -0.4336, -2.6328]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 19:16:10 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To establish results in a establishment
To entitle results in a entitlement
To require results in a requirement
To replace results in a replacement
To encourage results in a encouragement
To develop results in a development
To appoint results in a appointment
To invest results in a
2024-07-28 19:16:11 root INFO     [order_1_approx] starting weight calculation for To establish results in a establishment
To develop results in a development
To invest results in a investment
To appoint results in a appointment
To entitle results in a entitlement
To require results in a requirement
To replace results in a replacement
To encourage results in a
2024-07-28 19:16:11 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-28 19:18:34 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0278,  0.7266, -0.5537,  ...,  0.0896, -0.1520,  0.0093],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.0029, -3.0312, -0.5400,  ...,  2.7715, -1.0986, -2.6387],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0536,  0.0143,  0.0063,  ..., -0.0098, -0.0268,  0.0247],
        [-0.0038,  0.0758, -0.0053,  ...,  0.0396,  0.0161, -0.0033],
        [ 0.0122, -0.0263,  0.0258,  ..., -0.0112, -0.0085,  0.0058],
        ...,
        [-0.0101, -0.0333,  0.0140,  ...,  0.0823,  0.0186,  0.0114],
        [ 0.0095,  0.0179,  0.0180,  ...,  0.0085,  0.0549, -0.0078],
        [-0.0013, -0.0159, -0.0083,  ...,  0.0238, -0.0124,  0.0497]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.2070, -2.9863, -0.3979,  ...,  2.5566, -1.2080, -2.4883]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 19:18:35 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To establish results in a establishment
To develop results in a development
To invest results in a investment
To appoint results in a appointment
To entitle results in a entitlement
To require results in a requirement
To replace results in a replacement
To encourage results in a
2024-07-28 19:18:35 root INFO     [order_1_approx] starting weight calculation for To replace results in a replacement
To encourage results in a encouragement
To invest results in a investment
To appoint results in a appointment
To develop results in a development
To entitle results in a entitlement
To require results in a requirement
To establish results in a
2024-07-28 19:18:35 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-28 19:20:58 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0567,  0.4792, -0.6807,  ...,  0.2247, -0.4917,  0.0626],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.9482, -3.3398, -0.5962,  ...,  2.3223, -1.8086, -1.2490],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0379,  0.0233, -0.0105,  ..., -0.0146, -0.0162,  0.0230],
        [-0.0093,  0.0836,  0.0324,  ...,  0.0539,  0.0245,  0.0152],
        [ 0.0267, -0.0092,  0.0605,  ..., -0.0119,  0.0137, -0.0033],
        ...,
        [ 0.0065, -0.0148, -0.0174,  ...,  0.0680,  0.0059,  0.0303],
        [-0.0261,  0.0384,  0.0163,  ...,  0.0177,  0.0450, -0.0057],
        [-0.0190, -0.0175,  0.0116,  ...,  0.0283, -0.0045,  0.0424]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.7251, -2.6953, -0.0483,  ...,  2.4102, -2.0156, -1.3330]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 19:21:01 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To replace results in a replacement
To encourage results in a encouragement
To invest results in a investment
To appoint results in a appointment
To develop results in a development
To entitle results in a entitlement
To require results in a requirement
To establish results in a
2024-07-28 19:21:01 root INFO     total operator prediction time: 1153.4999613761902 seconds
2024-07-28 19:21:01 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on noun+less_reg
2024-07-28 19:21:01 root INFO     building operator noun+less_reg
2024-07-28 19:21:02 root INFO     [order_1_approx] starting weight calculation for Something without art is artless
Something without arm is armless
Something without penny is penniless
Something without talent is talentless
Something without soul is soulless
Something without window is windowless
Something without speech is speechless
Something without child is
2024-07-28 19:21:02 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-28 19:23:22 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0422, -0.4292, -0.2878,  ..., -0.3755, -0.8774,  0.0013],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.6758, -1.9229,  1.6172,  ..., -2.5410, -2.3652, -0.3711],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0370, -0.0306,  0.0188,  ...,  0.0039, -0.0047,  0.0072],
        [-0.0066,  0.0116, -0.0093,  ...,  0.0064,  0.0131, -0.0072],
        [-0.0063,  0.0136,  0.0244,  ...,  0.0031,  0.0069,  0.0092],
        ...,
        [-0.0091,  0.0094, -0.0074,  ...,  0.0027,  0.0161,  0.0139],
        [ 0.0162,  0.0003, -0.0003,  ..., -0.0124,  0.0186, -0.0299],
        [-0.0089,  0.0116,  0.0026,  ...,  0.0006, -0.0042,  0.0089]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.6157, -1.9648,  1.3389,  ..., -2.2012, -2.3418, -0.4026]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 19:23:23 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Something without art is artless
Something without arm is armless
Something without penny is penniless
Something without talent is talentless
Something without soul is soulless
Something without window is windowless
Something without speech is speechless
Something without child is
2024-07-28 19:23:23 root INFO     [order_1_approx] starting weight calculation for Something without child is childless
Something without talent is talentless
Something without window is windowless
Something without arm is armless
Something without soul is soulless
Something without art is artless
Something without penny is penniless
Something without speech is
2024-07-28 19:23:23 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-28 19:25:46 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1541, -0.3596, -0.0023,  ...,  0.0939,  0.0162,  0.2888],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.8027, -2.8945,  0.4551,  ...,  0.6816, -1.0195, -0.3604],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0117, -0.0123, -0.0115,  ...,  0.0140,  0.0034,  0.0018],
        [ 0.0115,  0.0551,  0.0246,  ...,  0.0021, -0.0125,  0.0226],
        [ 0.0187, -0.0075,  0.0436,  ...,  0.0137, -0.0196, -0.0048],
        ...,
        [-0.0019,  0.0132,  0.0048,  ...,  0.0257,  0.0107, -0.0002],
        [ 0.0004,  0.0068,  0.0048,  ..., -0.0261,  0.0280, -0.0196],
        [-0.0083,  0.0162,  0.0017,  ..., -0.0074, -0.0043,  0.0248]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.2642, -3.3477, -0.3130,  ...,  0.3232, -1.0811, -0.4106]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 19:25:47 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Something without child is childless
Something without talent is talentless
Something without window is windowless
Something without arm is armless
Something without soul is soulless
Something without art is artless
Something without penny is penniless
Something without speech is
2024-07-28 19:25:47 root INFO     [order_1_approx] starting weight calculation for Something without child is childless
Something without window is windowless
Something without speech is speechless
Something without arm is armless
Something without art is artless
Something without soul is soulless
Something without talent is talentless
Something without penny is
2024-07-28 19:25:47 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-28 19:28:08 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1265, -0.4482, -0.1746,  ..., -0.4399,  0.0008,  0.0497],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.3374, -3.3008,  0.2026,  ..., -4.2031, -4.7070, -1.5645],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0425, -0.0292, -0.0004,  ..., -0.0079, -0.0030,  0.0238],
        [ 0.0002,  0.0248,  0.0158,  ...,  0.0134,  0.0049, -0.0140],
        [ 0.0220,  0.0142,  0.0425,  ..., -0.0077, -0.0025,  0.0155],
        ...,
        [ 0.0010, -0.0163, -0.0119,  ...,  0.0247,  0.0278,  0.0299],
        [ 0.0016,  0.0298,  0.0210,  ...,  0.0114,  0.0193, -0.0324],
        [-0.0056,  0.0017, -0.0089,  ..., -0.0004,  0.0090,  0.0303]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.3047, -3.3379, -0.6216,  ..., -4.2070, -3.9355, -1.6406]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 19:28:09 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Something without child is childless
Something without window is windowless
Something without speech is speechless
Something without arm is armless
Something without art is artless
Something without soul is soulless
Something without talent is talentless
Something without penny is
2024-07-28 19:28:10 root INFO     [order_1_approx] starting weight calculation for Something without art is artless
Something without speech is speechless
Something without arm is armless
Something without soul is soulless
Something without child is childless
Something without talent is talentless
Something without penny is penniless
Something without window is
2024-07-28 19:28:10 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-28 19:30:32 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0392, -0.6885, -0.5278,  ...,  0.1464, -0.0823,  0.0479],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.9717, -4.4102,  0.6680,  ..., -2.9336, -3.1367,  1.5508],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0194, -0.0076, -0.0134,  ..., -0.0046, -0.0142, -0.0024],
        [ 0.0005,  0.0158, -0.0192,  ..., -0.0092, -0.0029, -0.0116],
        [ 0.0141,  0.0301,  0.0339,  ..., -0.0013, -0.0173,  0.0313],
        ...,
        [ 0.0092,  0.0402,  0.0177,  ...,  0.0157,  0.0142,  0.0097],
        [-0.0099,  0.0091,  0.0043,  ..., -0.0370,  0.0565,  0.0017],
        [ 0.0267,  0.0291, -0.0137,  ...,  0.0090, -0.0003,  0.0428]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.8184, -4.2461,  0.0068,  ..., -3.2129, -3.4863,  1.3242]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 19:30:34 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Something without art is artless
Something without speech is speechless
Something without arm is armless
Something without soul is soulless
Something without child is childless
Something without talent is talentless
Something without penny is penniless
Something without window is
2024-07-28 19:30:34 root INFO     [order_1_approx] starting weight calculation for Something without penny is penniless
Something without speech is speechless
Something without art is artless
Something without arm is armless
Something without window is windowless
Something without child is childless
Something without soul is soulless
Something without talent is
2024-07-28 19:30:34 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-28 19:32:57 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2000, -0.2705, -0.0286,  ..., -0.1649,  0.0384, -0.1187],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.5098, -1.2734,  1.4033,  ..., -3.6113, -4.1953, -1.8828],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 3.5034e-02, -6.3667e-03,  1.0284e-02,  ..., -9.2621e-03,
         -5.7220e-03,  1.4450e-02],
        [ 2.4796e-02,  5.1544e-02,  2.1400e-03,  ...,  1.9333e-02,
          3.9215e-03, -3.8147e-05],
        [-2.5768e-03, -1.2939e-02,  3.0869e-02,  ...,  3.5381e-03,
          3.0842e-03, -1.6083e-02],
        ...,
        [ 2.3621e-02,  4.7089e-02,  3.0441e-03,  ...,  2.1912e-02,
          5.8174e-03,  2.9831e-03],
        [-1.1780e-02,  1.1429e-02,  2.2171e-02,  ..., -1.7288e-02,
          1.0429e-02, -2.1881e-02],
        [ 5.3528e-02,  2.9182e-03,  4.0817e-03,  ..., -4.3411e-03,
          1.2703e-02,  2.4017e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.4980, -1.0752,  1.1211,  ..., -3.0469, -4.4062, -1.2568]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 19:32:58 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Something without penny is penniless
Something without speech is speechless
Something without art is artless
Something without arm is armless
Something without window is windowless
Something without child is childless
Something without soul is soulless
Something without talent is
2024-07-28 19:32:58 root INFO     [order_1_approx] starting weight calculation for Something without window is windowless
Something without talent is talentless
Something without penny is penniless
Something without soul is soulless
Something without speech is speechless
Something without child is childless
Something without arm is armless
Something without art is
2024-07-28 19:32:58 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-28 19:35:21 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0412, -0.2355, -0.1088,  ..., -0.5737,  0.0580, -0.0068],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.0547, -5.3047,  0.4863,  ..., -2.4355, -3.1289, -0.5449],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0110, -0.0205,  0.0024,  ..., -0.0284, -0.0155, -0.0042],
        [ 0.0296,  0.0352, -0.0088,  ...,  0.0119, -0.0112,  0.0310],
        [ 0.0007,  0.0131,  0.0268,  ...,  0.0161, -0.0139,  0.0007],
        ...,
        [ 0.0241,  0.0169, -0.0101,  ...,  0.0143,  0.0109,  0.0163],
        [-0.0055, -0.0251, -0.0102,  ..., -0.0199,  0.0120, -0.0336],
        [ 0.0135,  0.0084, -0.0028,  ...,  0.0278,  0.0031,  0.0012]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.9092, -5.4727,  0.2437,  ..., -2.4648, -2.8457, -0.6108]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 19:35:22 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Something without window is windowless
Something without talent is talentless
Something without penny is penniless
Something without soul is soulless
Something without speech is speechless
Something without child is childless
Something without arm is armless
Something without art is
2024-07-28 19:35:22 root INFO     [order_1_approx] starting weight calculation for Something without art is artless
Something without child is childless
Something without penny is penniless
Something without window is windowless
Something without arm is armless
Something without talent is talentless
Something without speech is speechless
Something without soul is
2024-07-28 19:35:22 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-28 19:37:45 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2966, -0.4136,  0.0148,  ..., -0.1173, -0.2632,  0.2861],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.8145, -1.4629,  1.2588,  ..., -4.2500, -2.1367,  0.1836],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0321,  0.0086, -0.0041,  ..., -0.0159,  0.0126,  0.0027],
        [ 0.0255,  0.0539,  0.0132,  ..., -0.0121,  0.0051,  0.0174],
        [ 0.0017,  0.0045,  0.0126,  ...,  0.0170, -0.0055,  0.0349],
        ...,
        [-0.0087,  0.0062, -0.0060,  ...,  0.0195, -0.0051, -0.0119],
        [-0.0050,  0.0319, -0.0021,  ..., -0.0118,  0.0501, -0.0251],
        [ 0.0198,  0.0289, -0.0047,  ...,  0.0055, -0.0029,  0.0422]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.4316, -1.6152,  1.5039,  ..., -3.5352, -2.1465,  0.1304]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 19:37:47 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Something without art is artless
Something without child is childless
Something without penny is penniless
Something without window is windowless
Something without arm is armless
Something without talent is talentless
Something without speech is speechless
Something without soul is
2024-07-28 19:37:47 root INFO     [order_1_approx] starting weight calculation for Something without art is artless
Something without speech is speechless
Something without talent is talentless
Something without window is windowless
Something without penny is penniless
Something without child is childless
Something without soul is soulless
Something without arm is
2024-07-28 19:37:47 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-28 19:40:10 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1790, -0.4387,  0.0521,  ..., -0.4092, -0.0323, -0.1377],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.2588, -4.7578, -1.2939,  ..., -1.6396, -1.5557, -1.5527],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0342, -0.0305, -0.0027,  ..., -0.0064, -0.0268, -0.0128],
        [ 0.0143,  0.0424,  0.0015,  ..., -0.0076,  0.0151, -0.0040],
        [ 0.0137,  0.0024,  0.0356,  ..., -0.0171, -0.0140, -0.0102],
        ...,
        [ 0.0030,  0.0224,  0.0022,  ...,  0.0522,  0.0242, -0.0027],
        [ 0.0097,  0.0206,  0.0126,  ...,  0.0003,  0.0528,  0.0058],
        [ 0.0169,  0.0291,  0.0113,  ...,  0.0063,  0.0157,  0.0285]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.5469, -4.3438, -1.3691,  ..., -1.5156, -2.1973, -1.8799]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 19:40:11 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Something without art is artless
Something without speech is speechless
Something without talent is talentless
Something without window is windowless
Something without penny is penniless
Something without child is childless
Something without soul is soulless
Something without arm is
2024-07-28 19:40:11 root INFO     total operator prediction time: 1149.518555879593 seconds
2024-07-28 19:40:11 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on adj+ness_reg
2024-07-28 19:40:11 root INFO     building operator adj+ness_reg
2024-07-28 19:40:11 root INFO     [order_1_approx] starting weight calculation for The state of being hot is hotness
The state of being situated is situatedness
The state of being attractive is attractiveness
The state of being careful is carefulness
The state of being random is randomness
The state of being foreign is foreignness
The state of being righteous is righteousness
The state of being distinctive is
2024-07-28 19:40:11 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-28 19:42:35 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1277, -0.6255, -0.3821,  ...,  0.1234,  0.0035,  0.2291],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.4160, -2.2129, -0.8013,  ..., -2.6602, -4.4258, -1.6094],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0345, -0.0230, -0.0060,  ..., -0.0129,  0.0139,  0.0032],
        [-0.0131,  0.0345,  0.0143,  ...,  0.0232,  0.0174, -0.0005],
        [ 0.0131, -0.0222,  0.0364,  ..., -0.0008, -0.0134, -0.0118],
        ...,
        [ 0.0142,  0.0140, -0.0046,  ...,  0.0369,  0.0110, -0.0111],
        [ 0.0064,  0.0117,  0.0123,  ..., -0.0010,  0.0272,  0.0010],
        [ 0.0114,  0.0082, -0.0061,  ...,  0.0190, -0.0055,  0.0208]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.4595, -2.1016, -0.6685,  ..., -2.6895, -4.9844, -1.5986]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 19:42:36 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The state of being hot is hotness
The state of being situated is situatedness
The state of being attractive is attractiveness
The state of being careful is carefulness
The state of being random is randomness
The state of being foreign is foreignness
The state of being righteous is righteousness
The state of being distinctive is
2024-07-28 19:42:36 root INFO     [order_1_approx] starting weight calculation for The state of being foreign is foreignness
The state of being careful is carefulness
The state of being distinctive is distinctiveness
The state of being righteous is righteousness
The state of being hot is hotness
The state of being random is randomness
The state of being situated is situatedness
The state of being attractive is
2024-07-28 19:42:37 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-28 19:45:00 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2275, -0.2632, -0.1290,  ...,  0.0849, -0.2773, -0.1775],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.4307, -0.8262, -3.3359,  ..., -0.6523, -4.1797, -2.8262],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0330, -0.0049,  0.0044,  ..., -0.0070,  0.0047,  0.0096],
        [-0.0107,  0.0358,  0.0141,  ...,  0.0141,  0.0198,  0.0017],
        [-0.0063, -0.0094,  0.0378,  ..., -0.0009, -0.0071, -0.0140],
        ...,
        [ 0.0250,  0.0157, -0.0119,  ...,  0.0175,  0.0112, -0.0065],
        [ 0.0074,  0.0213,  0.0089,  ..., -0.0065,  0.0331, -0.0134],
        [-0.0015,  0.0127,  0.0022,  ...,  0.0077,  0.0030,  0.0151]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.2140, -0.9580, -3.3418,  ..., -0.6816, -4.3906, -2.7637]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 19:45:01 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The state of being foreign is foreignness
The state of being careful is carefulness
The state of being distinctive is distinctiveness
The state of being righteous is righteousness
The state of being hot is hotness
The state of being random is randomness
The state of being situated is situatedness
The state of being attractive is
2024-07-28 19:45:01 root INFO     [order_1_approx] starting weight calculation for The state of being distinctive is distinctiveness
The state of being righteous is righteousness
The state of being attractive is attractiveness
The state of being hot is hotness
The state of being situated is situatedness
The state of being foreign is foreignness
The state of being careful is carefulness
The state of being random is
2024-07-28 19:45:01 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-28 19:47:25 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.5205,  0.3384, -0.2629,  ...,  0.1931, -0.3257, -0.2102],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.6553, -2.1914, -2.6758,  ..., -1.0674, -3.4258, -5.0352],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 4.5288e-02, -2.0771e-03,  1.0117e-02,  ...,  1.6663e-02,
         -2.4948e-03, -1.9073e-06],
        [-1.1246e-02,  3.3081e-02,  2.1423e-02,  ...,  3.6591e-02,
          7.0648e-03,  4.9400e-03],
        [ 1.5732e-02, -1.5411e-02,  3.9825e-02,  ..., -1.5854e-02,
          5.1689e-03, -8.3008e-03],
        ...,
        [ 1.7899e-02,  3.7140e-02,  2.5284e-02,  ...,  3.0411e-02,
         -5.8670e-03,  2.1744e-04],
        [ 1.4412e-02,  4.4342e-02,  1.5060e-02,  ..., -9.1629e-03,
          2.4826e-02,  5.1975e-04],
        [ 4.0741e-03,  1.0170e-02, -1.7643e-04,  ..., -9.4299e-03,
         -2.0370e-02,  1.3542e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.6675, -1.6699, -2.7109,  ..., -1.2139, -3.5312, -5.5312]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 19:47:26 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The state of being distinctive is distinctiveness
The state of being righteous is righteousness
The state of being attractive is attractiveness
The state of being hot is hotness
The state of being situated is situatedness
The state of being foreign is foreignness
The state of being careful is carefulness
The state of being random is
2024-07-28 19:47:27 root INFO     [order_1_approx] starting weight calculation for The state of being distinctive is distinctiveness
The state of being careful is carefulness
The state of being righteous is righteousness
The state of being attractive is attractiveness
The state of being foreign is foreignness
The state of being random is randomness
The state of being hot is hotness
The state of being situated is
2024-07-28 19:47:27 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-28 19:49:49 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.3625,  0.1392, -0.3376,  ...,  0.1907, -0.7393,  0.0709],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.2305, -2.5977, -1.6367,  ..., -3.2930, -4.5547, -4.1445],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0580, -0.0017,  0.0103,  ...,  0.0022,  0.0001,  0.0199],
        [-0.0128,  0.0549,  0.0101,  ...,  0.0324,  0.0158,  0.0310],
        [ 0.0215, -0.0034,  0.0261,  ..., -0.0055, -0.0283, -0.0109],
        ...,
        [ 0.0171,  0.0212,  0.0036,  ...,  0.0365,  0.0032,  0.0110],
        [-0.0141,  0.0246,  0.0089,  ..., -0.0051,  0.0472, -0.0131],
        [-0.0114,  0.0064,  0.0099,  ...,  0.0032, -0.0384,  0.0351]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.0430, -2.7188, -2.0508,  ..., -3.3809, -4.9922, -4.3320]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 19:49:50 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The state of being distinctive is distinctiveness
The state of being careful is carefulness
The state of being righteous is righteousness
The state of being attractive is attractiveness
The state of being foreign is foreignness
The state of being random is randomness
The state of being hot is hotness
The state of being situated is
2024-07-28 19:49:50 root INFO     [order_1_approx] starting weight calculation for The state of being situated is situatedness
The state of being distinctive is distinctiveness
The state of being attractive is attractiveness
The state of being foreign is foreignness
The state of being righteous is righteousness
The state of being random is randomness
The state of being careful is carefulness
The state of being hot is
2024-07-28 19:49:50 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-28 19:52:12 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1967, -0.3728,  0.1028,  ...,  0.1438, -0.3813,  0.0854],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.3826, -1.1768, -0.8467,  ..., -4.3594, -5.5469, -1.1211],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0279,  0.0148, -0.0098,  ..., -0.0200, -0.0073,  0.0008],
        [-0.0013,  0.0246,  0.0126,  ...,  0.0060,  0.0033, -0.0044],
        [-0.0020, -0.0035,  0.0381,  ...,  0.0172,  0.0083,  0.0192],
        ...,
        [ 0.0007, -0.0012,  0.0059,  ...,  0.0156,  0.0028, -0.0164],
        [ 0.0114,  0.0193, -0.0012,  ..., -0.0040,  0.0450,  0.0020],
        [-0.0121, -0.0198, -0.0115,  ..., -0.0013,  0.0094,  0.0252]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.3975, -0.7920, -1.4678,  ..., -3.8008, -6.2227, -0.8545]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 19:52:13 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The state of being situated is situatedness
The state of being distinctive is distinctiveness
The state of being attractive is attractiveness
The state of being foreign is foreignness
The state of being righteous is righteousness
The state of being random is randomness
The state of being careful is carefulness
The state of being hot is
2024-07-28 19:52:14 root INFO     [order_1_approx] starting weight calculation for The state of being careful is carefulness
The state of being righteous is righteousness
The state of being random is randomness
The state of being distinctive is distinctiveness
The state of being situated is situatedness
The state of being hot is hotness
The state of being attractive is attractiveness
The state of being foreign is
2024-07-28 19:52:14 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-28 19:54:36 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1371,  0.1268,  0.0637,  ..., -0.1047, -0.0039,  0.4360],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.9453, -2.9980,  0.2070,  ..., -2.3027, -2.6836, -0.9546],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0256,  0.0075, -0.0012,  ...,  0.0073,  0.0070,  0.0098],
        [-0.0008,  0.0164, -0.0018,  ...,  0.0066,  0.0161, -0.0087],
        [-0.0044,  0.0031,  0.0358,  ..., -0.0123,  0.0036,  0.0150],
        ...,
        [ 0.0032,  0.0195, -0.0166,  ...,  0.0052,  0.0020, -0.0254],
        [ 0.0059,  0.0111,  0.0105,  ..., -0.0128,  0.0331, -0.0085],
        [ 0.0023,  0.0220, -0.0004,  ...,  0.0017,  0.0018,  0.0111]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.1064, -2.5371, -0.1013,  ..., -2.0410, -2.6484, -1.0400]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 19:54:37 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The state of being careful is carefulness
The state of being righteous is righteousness
The state of being random is randomness
The state of being distinctive is distinctiveness
The state of being situated is situatedness
The state of being hot is hotness
The state of being attractive is attractiveness
The state of being foreign is
2024-07-28 19:54:37 root INFO     [order_1_approx] starting weight calculation for The state of being righteous is righteousness
The state of being hot is hotness
The state of being foreign is foreignness
The state of being attractive is attractiveness
The state of being distinctive is distinctiveness
The state of being situated is situatedness
The state of being random is randomness
The state of being careful is
2024-07-28 19:54:37 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-28 19:56:59 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.6748, -0.0969, -0.1465,  ..., -0.0829, -0.3989,  0.4077],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.3447, -3.4805, -0.7900,  ..., -2.4375, -1.9062, -1.7803],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0638,  0.0042, -0.0266,  ...,  0.0164,  0.0074,  0.0044],
        [ 0.0105,  0.0218,  0.0270,  ...,  0.0290,  0.0165,  0.0109],
        [-0.0222, -0.0154,  0.0299,  ...,  0.0030, -0.0244,  0.0145],
        ...,
        [ 0.0062,  0.0336,  0.0267,  ...,  0.0340,  0.0015, -0.0186],
        [ 0.0025,  0.0119,  0.0103,  ..., -0.0177,  0.0367, -0.0201],
        [-0.0322, -0.0077,  0.0222,  ...,  0.0152, -0.0093,  0.0153]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.7568, -3.4355, -0.9668,  ..., -2.2773, -2.0840, -1.7217]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 19:57:00 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The state of being righteous is righteousness
The state of being hot is hotness
The state of being foreign is foreignness
The state of being attractive is attractiveness
The state of being distinctive is distinctiveness
The state of being situated is situatedness
The state of being random is randomness
The state of being careful is
2024-07-28 19:57:00 root INFO     [order_1_approx] starting weight calculation for The state of being attractive is attractiveness
The state of being distinctive is distinctiveness
The state of being situated is situatedness
The state of being random is randomness
The state of being foreign is foreignness
The state of being hot is hotness
The state of being careful is carefulness
The state of being righteous is
2024-07-28 19:57:00 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-28 19:59:23 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0106, -0.2307, -0.2625,  ..., -0.0236, -0.6211,  0.0286],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.3257, -1.7188,  0.7456,  ..., -4.4648, -3.8867, -1.4941],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 4.3030e-02, -3.0289e-03,  2.1496e-03,  ...,  7.0572e-03,
         -4.9591e-05, -4.6005e-03],
        [ 6.1417e-04,  2.2400e-02,  1.8738e-02,  ...,  1.7197e-02,
          1.5442e-02,  4.2229e-03],
        [-2.9869e-03, -7.8278e-03,  4.2542e-02,  ..., -1.2863e-02,
         -8.0795e-03,  7.1335e-03],
        ...,
        [ 2.6489e-02,  5.5618e-03, -9.0790e-03,  ...,  2.8366e-02,
          2.4738e-03, -2.9106e-03],
        [ 4.9515e-03,  2.7481e-02,  5.1537e-03,  ..., -1.7807e-02,
          1.9348e-02,  1.8253e-03],
        [-6.9809e-03,  1.2985e-02, -7.7133e-03,  ..., -5.9357e-03,
         -6.2485e-03,  2.8442e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.1735, -1.5801,  0.6421,  ..., -4.2969, -4.2461, -1.4590]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 19:59:24 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The state of being attractive is attractiveness
The state of being distinctive is distinctiveness
The state of being situated is situatedness
The state of being random is randomness
The state of being foreign is foreignness
The state of being hot is hotness
The state of being careful is carefulness
The state of being righteous is
2024-07-28 19:59:24 root INFO     total operator prediction time: 1153.3138675689697 seconds
2024-07-28 19:59:24 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on re+verb_reg
2024-07-28 19:59:24 root INFO     building operator re+verb_reg
2024-07-28 19:59:25 root INFO     [order_1_approx] starting weight calculation for To decorate again is to redecorate
To consider again is to reconsider
To emerge again is to reemerge
To assure again is to reassure
To appoint again is to reappoint
To publish again is to republish
To configure again is to reconfigure
To install again is to
2024-07-28 19:59:25 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-28 20:01:47 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0224,  0.2263, -0.3296,  ...,  0.2615, -0.1602, -0.0537],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.1809, -2.1875, -0.2717,  ...,  1.8730, -2.9102, -3.0840],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 2.2842e-02, -2.2644e-02,  1.1688e-02,  ...,  2.6627e-03,
          3.1338e-03,  1.3023e-02],
        [-7.1678e-03,  3.2227e-02,  1.8778e-03,  ...,  1.4145e-02,
         -3.0193e-03,  6.6414e-03],
        [ 1.9669e-02,  1.5268e-03,  3.8513e-02,  ..., -1.8188e-02,
         -8.5678e-03,  6.4888e-03],
        ...,
        [ 1.1848e-02,  8.1177e-03, -1.2665e-02,  ...,  3.6163e-02,
          1.5991e-02,  4.0722e-04],
        [-2.9297e-03, -1.5671e-02,  9.3613e-03,  ..., -5.6992e-03,
          3.1605e-03, -9.7580e-03],
        [ 1.0090e-03,  5.3406e-05, -1.9245e-03,  ..., -1.0300e-03,
         -1.6956e-03,  1.7609e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.2118, -2.2852, -0.2773,  ...,  2.1230, -2.4043, -3.0996]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 20:01:48 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To decorate again is to redecorate
To consider again is to reconsider
To emerge again is to reemerge
To assure again is to reassure
To appoint again is to reappoint
To publish again is to republish
To configure again is to reconfigure
To install again is to
2024-07-28 20:01:48 root INFO     [order_1_approx] starting weight calculation for To emerge again is to reemerge
To install again is to reinstall
To configure again is to reconfigure
To publish again is to republish
To assure again is to reassure
To consider again is to reconsider
To appoint again is to reappoint
To decorate again is to
2024-07-28 20:01:48 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-28 20:04:09 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2974, -0.0405, -0.2515,  ...,  0.1245, -0.5615,  0.0465],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-2.3223, -1.9150, -0.7422,  ...,  2.1523, -4.4727, -2.3965],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0495, -0.0137,  0.0078,  ..., -0.0050, -0.0102,  0.0043],
        [-0.0007,  0.0469, -0.0026,  ...,  0.0093, -0.0007, -0.0045],
        [ 0.0075, -0.0018,  0.0238,  ..., -0.0134,  0.0008,  0.0129],
        ...,
        [-0.0018, -0.0034, -0.0039,  ...,  0.0289,  0.0037,  0.0062],
        [ 0.0230,  0.0101, -0.0109,  ..., -0.0002,  0.0213, -0.0060],
        [-0.0021,  0.0077, -0.0040,  ..., -0.0052, -0.0113,  0.0223]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-2.4102, -1.9336, -0.5977,  ...,  2.4004, -4.1562, -2.2891]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 20:04:10 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To emerge again is to reemerge
To install again is to reinstall
To configure again is to reconfigure
To publish again is to republish
To assure again is to reassure
To consider again is to reconsider
To appoint again is to reappoint
To decorate again is to
2024-07-28 20:04:10 root INFO     [order_1_approx] starting weight calculation for To decorate again is to redecorate
To configure again is to reconfigure
To appoint again is to reappoint
To consider again is to reconsider
To install again is to reinstall
To emerge again is to reemerge
To publish again is to republish
To assure again is to
2024-07-28 20:04:10 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-28 20:06:33 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2859,  0.5713, -0.2607,  ...,  0.0707, -0.1589, -0.1715],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.8242, -2.5605, -2.3242,  ...,  2.3125, -4.4336, -3.0234],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 5.6519e-02, -1.8250e-02, -1.2016e-04,  ..., -8.2626e-03,
         -1.0004e-03,  2.1454e-02],
        [-1.5396e-02,  5.7190e-02, -2.7180e-03,  ...,  1.4198e-02,
         -1.8997e-02,  1.0139e-02],
        [ 1.0109e-02,  3.7727e-03,  3.0884e-02,  ...,  4.6349e-04,
          1.8253e-03,  9.5940e-04],
        ...,
        [ 8.4610e-03, -1.0710e-03, -1.3039e-02,  ...,  6.6528e-02,
          2.5925e-02,  2.6703e-02],
        [ 9.8572e-03, -1.2276e-02,  8.1558e-03,  ...,  5.8289e-03,
          4.4281e-02, -1.5099e-02],
        [ 9.2621e-03,  9.9182e-05, -5.1079e-03,  ..., -1.3878e-02,
         -1.6342e-02,  4.8035e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.8208, -2.9922, -2.1348,  ...,  2.6289, -4.5078, -3.0273]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 20:06:34 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To decorate again is to redecorate
To configure again is to reconfigure
To appoint again is to reappoint
To consider again is to reconsider
To install again is to reinstall
To emerge again is to reemerge
To publish again is to republish
To assure again is to
2024-07-28 20:06:35 root INFO     [order_1_approx] starting weight calculation for To consider again is to reconsider
To install again is to reinstall
To publish again is to republish
To decorate again is to redecorate
To assure again is to reassure
To configure again is to reconfigure
To appoint again is to reappoint
To emerge again is to
2024-07-28 20:06:35 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-28 20:08:56 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1086,  0.0099, -0.4932,  ...,  0.0448, -0.1406,  0.4033],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.6069, -1.0879, -1.0977,  ...,  2.9102, -3.7773, -1.8223],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 5.1514e-02, -9.7046e-03,  2.2827e-02,  ..., -3.4332e-05,
          1.6830e-02,  2.1790e-02],
        [-7.7362e-03,  5.8868e-02, -7.2327e-03,  ...,  9.5978e-03,
         -1.5198e-02, -6.7558e-03],
        [ 3.5019e-03,  8.8425e-03,  2.1698e-02,  ...,  9.6436e-03,
         -3.3817e-03, -1.2390e-02],
        ...,
        [ 1.7242e-03,  2.0020e-02,  2.4548e-03,  ...,  5.3070e-02,
         -1.0841e-02, -1.2924e-02],
        [-2.0935e-02,  8.8196e-03,  1.3752e-03,  ..., -1.9207e-03,
          2.7664e-02, -1.5701e-02],
        [-7.5817e-05,  1.0559e-02,  8.3828e-04,  ..., -9.3384e-03,
         -2.5665e-02,  3.9337e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.4336, -0.9824, -0.9941,  ...,  2.9434, -3.8047, -1.9102]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 20:08:57 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To consider again is to reconsider
To install again is to reinstall
To publish again is to republish
To decorate again is to redecorate
To assure again is to reassure
To configure again is to reconfigure
To appoint again is to reappoint
To emerge again is to
2024-07-28 20:08:57 root INFO     [order_1_approx] starting weight calculation for To assure again is to reassure
To publish again is to republish
To configure again is to reconfigure
To appoint again is to reappoint
To install again is to reinstall
To decorate again is to redecorate
To emerge again is to reemerge
To consider again is to
2024-07-28 20:08:57 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-28 20:11:19 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2222,  0.1696, -0.2351,  ...,  0.1427, -0.0977, -0.0895],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.1978, -3.6621,  0.3789,  ...,  1.0898, -1.9316, -3.1348],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0553, -0.0240,  0.0007,  ..., -0.0025,  0.0014,  0.0047],
        [ 0.0083,  0.0278, -0.0004,  ...,  0.0214, -0.0036,  0.0162],
        [-0.0108,  0.0021,  0.0730,  ..., -0.0105, -0.0076,  0.0205],
        ...,
        [ 0.0193, -0.0083,  0.0087,  ...,  0.0731,  0.0157,  0.0024],
        [ 0.0062,  0.0179,  0.0140,  ..., -0.0179,  0.0279, -0.0025],
        [-0.0054,  0.0038, -0.0047,  ..., -0.0093, -0.0125,  0.0238]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.0161, -3.9590,  0.1184,  ...,  1.6465, -2.0859, -2.9531]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 20:11:20 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To assure again is to reassure
To publish again is to republish
To configure again is to reconfigure
To appoint again is to reappoint
To install again is to reinstall
To decorate again is to redecorate
To emerge again is to reemerge
To consider again is to
2024-07-28 20:11:20 root INFO     [order_1_approx] starting weight calculation for To emerge again is to reemerge
To appoint again is to reappoint
To decorate again is to redecorate
To configure again is to reconfigure
To install again is to reinstall
To consider again is to reconsider
To assure again is to reassure
To publish again is to
2024-07-28 20:11:20 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-28 20:13:45 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0807,  0.4429,  0.1888,  ...,  0.3296, -0.3125,  0.3232],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.6885, -1.8633, -1.2969,  ...,  1.9922, -3.1094, -2.7988],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0529, -0.0022,  0.0107,  ...,  0.0005, -0.0030,  0.0179],
        [-0.0125,  0.0477, -0.0016,  ...,  0.0063, -0.0022,  0.0076],
        [ 0.0191, -0.0070,  0.0306,  ..., -0.0178, -0.0156, -0.0028],
        ...,
        [ 0.0197, -0.0008, -0.0143,  ...,  0.0520,  0.0081,  0.0098],
        [ 0.0022, -0.0165,  0.0029,  ...,  0.0069,  0.0217, -0.0078],
        [-0.0008,  0.0030, -0.0084,  ..., -0.0117, -0.0240,  0.0208]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.7012, -2.1680, -1.0703,  ...,  2.0527, -2.7754, -3.1348]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 20:13:46 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To emerge again is to reemerge
To appoint again is to reappoint
To decorate again is to redecorate
To configure again is to reconfigure
To install again is to reinstall
To consider again is to reconsider
To assure again is to reassure
To publish again is to
2024-07-28 20:13:46 root INFO     [order_1_approx] starting weight calculation for To assure again is to reassure
To emerge again is to reemerge
To decorate again is to redecorate
To publish again is to republish
To install again is to reinstall
To appoint again is to reappoint
To consider again is to reconsider
To configure again is to
2024-07-28 20:13:47 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-28 20:16:09 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0526, -0.0630, -0.8135,  ...,  0.0906, -0.1763, -0.0729],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.3164, -1.6387,  1.3203,  ...,  3.3574, -1.5928, -2.3066],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0558, -0.0218,  0.0167,  ..., -0.0037,  0.0123,  0.0164],
        [-0.0050,  0.0622, -0.0030,  ...,  0.0250,  0.0084,  0.0092],
        [ 0.0232,  0.0409,  0.0386,  ..., -0.0086,  0.0090,  0.0073],
        ...,
        [ 0.0103,  0.0067, -0.0073,  ...,  0.0546,  0.0010, -0.0169],
        [-0.0012,  0.0041, -0.0049,  ..., -0.0273,  0.0363, -0.0171],
        [-0.0109,  0.0091, -0.0057,  ..., -0.0012, -0.0047,  0.0353]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.4453, -1.8398,  1.3086,  ...,  3.5137, -1.2578, -2.3750]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 20:16:10 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To assure again is to reassure
To emerge again is to reemerge
To decorate again is to redecorate
To publish again is to republish
To install again is to reinstall
To appoint again is to reappoint
To consider again is to reconsider
To configure again is to
2024-07-28 20:16:10 root INFO     [order_1_approx] starting weight calculation for To decorate again is to redecorate
To publish again is to republish
To consider again is to reconsider
To assure again is to reassure
To emerge again is to reemerge
To install again is to reinstall
To configure again is to reconfigure
To appoint again is to
2024-07-28 20:16:10 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-28 20:18:31 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1575,  0.6309, -0.2007,  ...,  0.1761, -0.3643,  0.0325],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.5498, -3.0039, -0.8091,  ...,  2.9941, -5.3125, -3.6328],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0434, -0.0158,  0.0042,  ...,  0.0016, -0.0077,  0.0104],
        [ 0.0121,  0.0340, -0.0015,  ...,  0.0142, -0.0069, -0.0087],
        [ 0.0120, -0.0028,  0.0230,  ..., -0.0070, -0.0144,  0.0032],
        ...,
        [ 0.0006,  0.0076, -0.0164,  ...,  0.0311,  0.0080,  0.0016],
        [-0.0050, -0.0078, -0.0002,  ..., -0.0061,  0.0252, -0.0182],
        [-0.0021, -0.0027, -0.0093,  ..., -0.0041, -0.0107,  0.0464]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.3901, -3.2051, -0.9624,  ...,  3.0254, -5.0312, -3.4648]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 20:18:32 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To decorate again is to redecorate
To publish again is to republish
To consider again is to reconsider
To assure again is to reassure
To emerge again is to reemerge
To install again is to reinstall
To configure again is to reconfigure
To appoint again is to
2024-07-28 20:18:32 root INFO     total operator prediction time: 1148.151861190796 seconds
2024-07-28 20:18:32 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on un+adj_reg
2024-07-28 20:18:32 root INFO     building operator un+adj_reg
2024-07-28 20:18:33 root INFO     [order_1_approx] starting weight calculation for The opposite of able is unable
The opposite of popular is unpopular
The opposite of used is unused
The opposite of available is unavailable
The opposite of biased is unbiased
The opposite of comfortable is uncomfortable
The opposite of reasonable is unreasonable
The opposite of restricted is
2024-07-28 20:18:33 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-28 20:20:56 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1976, -0.0417, -0.6494,  ..., -0.1122,  0.1366,  0.0964],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.6523,  0.3176,  1.1895,  ...,  0.6758, -1.8594, -1.6533],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0434, -0.0242, -0.0023,  ...,  0.0167, -0.0028,  0.0184],
        [-0.0100,  0.0522,  0.0114,  ...,  0.0004,  0.0173, -0.0014],
        [ 0.0201,  0.0042,  0.0280,  ...,  0.0050,  0.0037,  0.0202],
        ...,
        [ 0.0151,  0.0185,  0.0157,  ...,  0.0288,  0.0192, -0.0053],
        [ 0.0204, -0.0064,  0.0057,  ..., -0.0035,  0.0328,  0.0106],
        [-0.0011,  0.0115, -0.0128,  ..., -0.0024,  0.0095,  0.0522]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.0957,  0.1938,  1.1729,  ...,  0.5723, -2.0762, -1.4736]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 20:20:58 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of able is unable
The opposite of popular is unpopular
The opposite of used is unused
The opposite of available is unavailable
The opposite of biased is unbiased
The opposite of comfortable is uncomfortable
The opposite of reasonable is unreasonable
The opposite of restricted is
2024-07-28 20:20:58 root INFO     [order_1_approx] starting weight calculation for The opposite of reasonable is unreasonable
The opposite of used is unused
The opposite of able is unable
The opposite of biased is unbiased
The opposite of comfortable is uncomfortable
The opposite of available is unavailable
The opposite of restricted is unrestricted
The opposite of popular is
2024-07-28 20:20:58 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-28 20:23:22 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.5059, -0.0167,  0.1451,  ..., -0.0955, -0.2981, -0.0599],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.6689, -0.7266,  2.3086,  ..., -2.8086, -1.4541,  0.0967],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 5.5176e-02, -7.2479e-05,  1.6891e-02,  ...,  2.0981e-02,
         -8.7967e-03,  3.5797e-02],
        [ 8.5602e-03,  5.4749e-02, -5.2719e-03,  ...,  2.3254e-02,
         -1.8677e-02, -4.3869e-03],
        [ 7.1678e-03, -1.0910e-02,  4.8492e-02,  ...,  1.0208e-02,
          1.3687e-02,  8.9874e-03],
        ...,
        [ 3.0396e-02,  2.0996e-02, -1.2207e-02,  ...,  5.4932e-02,
          8.4534e-03, -2.8877e-03],
        [-2.1667e-02,  1.0353e-02,  3.2463e-03,  ...,  1.2558e-02,
          3.8086e-02, -3.3035e-03],
        [ 3.4088e-02,  2.9831e-03, -4.0558e-02,  ...,  5.2261e-03,
         -2.6321e-04,  2.3727e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.8291, -0.9834,  1.8682,  ..., -2.1875, -1.7178,  0.3076]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 20:23:24 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of reasonable is unreasonable
The opposite of used is unused
The opposite of able is unable
The opposite of biased is unbiased
The opposite of comfortable is uncomfortable
The opposite of available is unavailable
The opposite of restricted is unrestricted
The opposite of popular is
2024-07-28 20:23:24 root INFO     [order_1_approx] starting weight calculation for The opposite of used is unused
The opposite of reasonable is unreasonable
The opposite of comfortable is uncomfortable
The opposite of able is unable
The opposite of available is unavailable
The opposite of restricted is unrestricted
The opposite of popular is unpopular
The opposite of biased is
2024-07-28 20:23:24 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-28 20:25:46 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4346, -0.3247, -0.5049,  ...,  0.3179, -0.1587,  0.4119],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.2363, -1.0576, -0.9053,  ..., -1.3555, -3.3398, -3.2441],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0440, -0.0225, -0.0013,  ...,  0.0225,  0.0035,  0.0138],
        [-0.0151,  0.0579, -0.0031,  ...,  0.0122,  0.0017, -0.0246],
        [-0.0119, -0.0170,  0.0368,  ...,  0.0095,  0.0086,  0.0084],
        ...,
        [ 0.0064,  0.0273,  0.0091,  ...,  0.0305, -0.0049, -0.0085],
        [ 0.0204,  0.0130,  0.0261,  ..., -0.0269,  0.0344,  0.0189],
        [ 0.0108,  0.0137,  0.0145,  ...,  0.0024,  0.0174,  0.0384]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.9062, -1.2441, -1.0039,  ..., -1.4287, -3.2930, -3.6445]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 20:25:47 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of used is unused
The opposite of reasonable is unreasonable
The opposite of comfortable is uncomfortable
The opposite of able is unable
The opposite of available is unavailable
The opposite of restricted is unrestricted
The opposite of popular is unpopular
The opposite of biased is
2024-07-28 20:25:47 root INFO     [order_1_approx] starting weight calculation for The opposite of reasonable is unreasonable
The opposite of able is unable
The opposite of biased is unbiased
The opposite of popular is unpopular
The opposite of available is unavailable
The opposite of restricted is unrestricted
The opposite of used is unused
The opposite of comfortable is
2024-07-28 20:25:47 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-28 20:28:10 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1749, -0.2026, -0.2468,  ..., -0.3774, -0.4243,  0.3845],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.0234, -0.5630,  2.0859,  ..., -1.5576,  0.7725,  1.0820],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0468, -0.0093,  0.0161,  ..., -0.0042, -0.0086,  0.0288],
        [-0.0075,  0.0711,  0.0022,  ...,  0.0029,  0.0199,  0.0024],
        [ 0.0146, -0.0107,  0.0355,  ...,  0.0428,  0.0070,  0.0159],
        ...,
        [ 0.0048,  0.0260, -0.0195,  ...,  0.0409,  0.0068, -0.0208],
        [ 0.0155,  0.0169,  0.0092,  ..., -0.0188,  0.0653, -0.0044],
        [-0.0105, -0.0285, -0.0254,  ...,  0.0193,  0.0134,  0.0475]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.9355, -0.8555,  1.5225,  ..., -1.4639, -0.1069,  0.8369]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 20:28:11 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of reasonable is unreasonable
The opposite of able is unable
The opposite of biased is unbiased
The opposite of popular is unpopular
The opposite of available is unavailable
The opposite of restricted is unrestricted
The opposite of used is unused
The opposite of comfortable is
2024-07-28 20:28:11 root INFO     [order_1_approx] starting weight calculation for The opposite of restricted is unrestricted
The opposite of popular is unpopular
The opposite of able is unable
The opposite of biased is unbiased
The opposite of reasonable is unreasonable
The opposite of comfortable is uncomfortable
The opposite of used is unused
The opposite of available is
2024-07-28 20:28:11 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-28 20:30:34 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0751, -0.1484, -0.3442,  ..., -0.1113, -0.0050, -0.1689],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.7246, -2.2305,  0.6689,  ..., -1.0947, -0.7710, -1.0059],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 3.3142e-02, -6.4163e-03,  4.3869e-05,  ...,  1.4282e-02,
         -1.8753e-02,  9.1705e-03],
        [ 2.2537e-02,  5.5664e-02, -1.2558e-02,  ...,  2.5818e-02,
          8.1100e-03, -5.8899e-03],
        [-1.8402e-02,  4.8447e-04,  3.2806e-02,  ..., -1.5686e-02,
         -1.3634e-02, -6.8665e-04],
        ...,
        [-8.8882e-03,  1.7426e-02, -7.9269e-03,  ...,  1.5961e-02,
          3.0609e-02, -1.2650e-02],
        [-1.8158e-02,  9.4757e-03,  3.8086e-02,  ...,  8.5831e-04,
          6.0608e-02,  1.5717e-03],
        [-1.1642e-02,  6.4087e-03, -2.1561e-02,  ..., -5.7869e-03,
          8.9493e-03,  4.0588e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.1143, -1.9961,  0.4556,  ..., -0.9180, -0.9741, -0.8291]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 20:30:35 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of restricted is unrestricted
The opposite of popular is unpopular
The opposite of able is unable
The opposite of biased is unbiased
The opposite of reasonable is unreasonable
The opposite of comfortable is uncomfortable
The opposite of used is unused
The opposite of available is
2024-07-28 20:30:35 root INFO     [order_1_approx] starting weight calculation for The opposite of used is unused
The opposite of comfortable is uncomfortable
The opposite of popular is unpopular
The opposite of available is unavailable
The opposite of biased is unbiased
The opposite of reasonable is unreasonable
The opposite of restricted is unrestricted
The opposite of able is
2024-07-28 20:30:35 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-28 20:32:57 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1284, -0.1118, -0.2852,  ..., -0.8281, -0.0646,  0.2153],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.1104, -5.4922,  2.5312,  ...,  0.8389, -1.3076, -1.2617],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 1.5488e-03, -2.4551e-02,  1.3596e-02,  ...,  2.9816e-02,
         -4.3854e-02,  7.7438e-03],
        [-5.2948e-03,  3.7231e-02,  3.1528e-03,  ...,  2.1927e-02,
          3.4241e-02,  2.2507e-04],
        [-6.1417e-03,  9.2468e-03,  2.5558e-04,  ..., -1.3229e-02,
         -7.6828e-03,  5.3101e-03],
        ...,
        [-2.5368e-04,  1.6190e-02, -2.8152e-02,  ..., -2.6741e-03,
          3.9703e-02, -1.9409e-02],
        [-6.8665e-05, -2.1912e-02,  1.8082e-02,  ..., -1.0956e-02,
          6.1676e-02, -2.0554e-02],
        [ 4.8676e-03,  7.0190e-03, -3.8696e-02,  ..., -8.1863e-03,
          2.0233e-02,  2.6810e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.1729, -4.5273,  1.7793,  ...,  1.7520, -1.5957, -1.4443]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 20:32:58 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of used is unused
The opposite of comfortable is uncomfortable
The opposite of popular is unpopular
The opposite of available is unavailable
The opposite of biased is unbiased
The opposite of reasonable is unreasonable
The opposite of restricted is unrestricted
The opposite of able is
2024-07-28 20:32:59 root INFO     [order_1_approx] starting weight calculation for The opposite of comfortable is uncomfortable
The opposite of able is unable
The opposite of biased is unbiased
The opposite of available is unavailable
The opposite of popular is unpopular
The opposite of restricted is unrestricted
The opposite of used is unused
The opposite of reasonable is
2024-07-28 20:32:59 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-28 20:35:18 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4028,  0.1492, -0.1121,  ..., -0.4871, -0.3767,  0.0996],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.5840, -2.1152,  0.8438,  ..., -1.5654, -4.4180, -4.0977],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0554, -0.0090,  0.0200,  ..., -0.0019, -0.0018,  0.0237],
        [ 0.0202,  0.0625, -0.0291,  ...,  0.0123,  0.0008,  0.0016],
        [-0.0182,  0.0005,  0.0531,  ...,  0.0151, -0.0307,  0.0091],
        ...,
        [ 0.0029,  0.0041,  0.0020,  ...,  0.0356,  0.0177, -0.0046],
        [ 0.0036,  0.0237,  0.0207,  ..., -0.0117,  0.0752, -0.0345],
        [ 0.0069,  0.0119, -0.0163,  ..., -0.0051, -0.0164,  0.0243]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.6074, -2.1250,  0.8286,  ..., -1.3008, -4.7031, -3.9121]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 20:35:19 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of comfortable is uncomfortable
The opposite of able is unable
The opposite of biased is unbiased
The opposite of available is unavailable
The opposite of popular is unpopular
The opposite of restricted is unrestricted
The opposite of used is unused
The opposite of reasonable is
2024-07-28 20:35:19 root INFO     [order_1_approx] starting weight calculation for The opposite of restricted is unrestricted
The opposite of popular is unpopular
The opposite of able is unable
The opposite of comfortable is uncomfortable
The opposite of reasonable is unreasonable
The opposite of biased is unbiased
The opposite of available is unavailable
The opposite of used is
2024-07-28 20:35:19 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-28 20:37:43 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0323, -0.0346, -0.1058,  ..., -0.1484, -0.4766,  0.1970],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.6270, -1.7207, -0.4478,  ..., -1.4062, -2.7266, -1.3906],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0418, -0.0166, -0.0036,  ...,  0.0228, -0.0057,  0.0359],
        [-0.0047,  0.0388, -0.0029,  ...,  0.0067,  0.0188, -0.0171],
        [-0.0033, -0.0158,  0.0393,  ...,  0.0253, -0.0131,  0.0254],
        ...,
        [-0.0077,  0.0052, -0.0172,  ..., -0.0092, -0.0059, -0.0395],
        [ 0.0135, -0.0334, -0.0102,  ..., -0.0155,  0.0397,  0.0007],
        [ 0.0048,  0.0126, -0.0240,  ...,  0.0230,  0.0331,  0.0361]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.9258, -1.6377, -0.6064,  ..., -1.1211, -2.6484, -1.4668]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 20:37:45 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of restricted is unrestricted
The opposite of popular is unpopular
The opposite of able is unable
The opposite of comfortable is uncomfortable
The opposite of reasonable is unreasonable
The opposite of biased is unbiased
The opposite of available is unavailable
The opposite of used is
2024-07-28 20:37:45 root INFO     total operator prediction time: 1152.0603647232056 seconds
2024-07-28 20:37:45 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on verb+able_reg
2024-07-28 20:37:45 root INFO     building operator verb+able_reg
2024-07-28 20:37:45 root INFO     [order_1_approx] starting weight calculation for If you can foresee something, that thing is foreseeable
If you can prevent something, that thing is preventable
If you can write something, that thing is writeable
If you can understand something, that thing is understandable
If you can recommend something, that thing is recommendable
If you can improve something, that thing is improvable
If you can contain something, that thing is containable
If you can maintain something, that thing is
2024-07-28 20:37:45 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-28 20:40:06 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 5.2002e-01,  5.4395e-01, -3.5449e-01,  ...,  3.6621e-04,
        -2.2485e-01,  1.3281e-01], device='cuda:0', dtype=torch.float16,
       grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.4971, -0.1787, -3.0156,  ..., -3.4336, -4.8125, -1.9443],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0103,  0.0087, -0.0168,  ...,  0.0310,  0.0021,  0.0015],
        [ 0.0007,  0.0432,  0.0090,  ..., -0.0014,  0.0147,  0.0087],
        [ 0.0073, -0.0169,  0.0129,  ..., -0.0126, -0.0048, -0.0028],
        ...,
        [ 0.0197,  0.0179,  0.0077,  ...,  0.0363,  0.0035,  0.0077],
        [ 0.0285,  0.0070, -0.0096,  ..., -0.0382,  0.0264, -0.0239],
        [-0.0046, -0.0027, -0.0069,  ..., -0.0159, -0.0013,  0.0097]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.6943, -0.5952, -3.1875,  ..., -3.4688, -4.2812, -2.1113]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 20:40:07 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you can foresee something, that thing is foreseeable
If you can prevent something, that thing is preventable
If you can write something, that thing is writeable
If you can understand something, that thing is understandable
If you can recommend something, that thing is recommendable
If you can improve something, that thing is improvable
If you can contain something, that thing is containable
If you can maintain something, that thing is
2024-07-28 20:40:08 root INFO     [order_1_approx] starting weight calculation for If you can recommend something, that thing is recommendable
If you can prevent something, that thing is preventable
If you can improve something, that thing is improvable
If you can maintain something, that thing is maintainable
If you can understand something, that thing is understandable
If you can write something, that thing is writeable
If you can foresee something, that thing is foreseeable
If you can contain something, that thing is
2024-07-28 20:40:08 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-28 20:42:29 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4124, -0.1144, -0.2507,  ..., -0.0117, -0.1029, -0.3137],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.9277, -0.5571,  0.1030,  ..., -4.0000, -4.3477, -3.0840],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0449,  0.0179, -0.0046,  ...,  0.0216,  0.0190,  0.0347],
        [-0.0055,  0.0554,  0.0238,  ..., -0.0035, -0.0138, -0.0064],
        [-0.0012, -0.0154,  0.0349,  ..., -0.0312,  0.0023, -0.0019],
        ...,
        [ 0.0144,  0.0020,  0.0151,  ...,  0.0266,  0.0190, -0.0147],
        [ 0.0236,  0.0023, -0.0055,  ..., -0.0341,  0.0399, -0.0227],
        [ 0.0190,  0.0047,  0.0066,  ..., -0.0143, -0.0156,  0.0249]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.4062, -0.9067,  0.1191,  ..., -3.9805, -3.9121, -2.8379]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 20:42:30 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you can recommend something, that thing is recommendable
If you can prevent something, that thing is preventable
If you can improve something, that thing is improvable
If you can maintain something, that thing is maintainable
If you can understand something, that thing is understandable
If you can write something, that thing is writeable
If you can foresee something, that thing is foreseeable
If you can contain something, that thing is
2024-07-28 20:42:30 root INFO     [order_1_approx] starting weight calculation for If you can recommend something, that thing is recommendable
If you can maintain something, that thing is maintainable
If you can prevent something, that thing is preventable
If you can understand something, that thing is understandable
If you can write something, that thing is writeable
If you can improve something, that thing is improvable
If you can contain something, that thing is containable
If you can foresee something, that thing is
2024-07-28 20:42:31 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-28 20:44:54 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0653,  0.5229, -0.1187,  ..., -0.1559, -0.0253, -0.0075],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.6211,  1.3076, -1.7422,  ..., -2.4141, -6.9297, -2.1230],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0242,  0.0198, -0.0068,  ...,  0.0015,  0.0046, -0.0006],
        [-0.0116,  0.0345,  0.0131,  ...,  0.0061, -0.0030,  0.0018],
        [-0.0101, -0.0261,  0.0270,  ...,  0.0103,  0.0043, -0.0106],
        ...,
        [-0.0008,  0.0061, -0.0037,  ...,  0.0358, -0.0021,  0.0121],
        [ 0.0138, -0.0005, -0.0087,  ..., -0.0260,  0.0283, -0.0101],
        [-0.0003, -0.0033,  0.0095,  ..., -0.0013, -0.0185,  0.0235]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.6089,  1.3086, -1.6582,  ..., -2.4121, -6.8984, -2.1719]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 20:44:56 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you can recommend something, that thing is recommendable
If you can maintain something, that thing is maintainable
If you can prevent something, that thing is preventable
If you can understand something, that thing is understandable
If you can write something, that thing is writeable
If you can improve something, that thing is improvable
If you can contain something, that thing is containable
If you can foresee something, that thing is
2024-07-28 20:44:56 root INFO     [order_1_approx] starting weight calculation for If you can maintain something, that thing is maintainable
If you can improve something, that thing is improvable
If you can recommend something, that thing is recommendable
If you can contain something, that thing is containable
If you can foresee something, that thing is foreseeable
If you can write something, that thing is writeable
If you can prevent something, that thing is preventable
If you can understand something, that thing is
2024-07-28 20:44:56 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-28 20:47:20 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2145,  0.4836,  0.1472,  ...,  0.1005, -0.3669, -0.0889],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.1250,  0.9785,  1.5352,  ..., -1.4355, -7.6797, -0.0586],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0214, -0.0109,  0.0006,  ..., -0.0058, -0.0143,  0.0248],
        [ 0.0018,  0.0260,  0.0173,  ...,  0.0058, -0.0040,  0.0219],
        [ 0.0116, -0.0132,  0.0300,  ..., -0.0029,  0.0067, -0.0015],
        ...,
        [ 0.0055, -0.0055,  0.0143,  ...,  0.0202,  0.0101,  0.0042],
        [ 0.0093,  0.0019,  0.0073,  ..., -0.0171,  0.0044, -0.0119],
        [ 0.0052, -0.0080,  0.0166,  ..., -0.0178, -0.0092, -0.0020]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.3130,  0.8501,  1.6250,  ..., -1.0410, -7.4023,  0.0000]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 20:47:21 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you can maintain something, that thing is maintainable
If you can improve something, that thing is improvable
If you can recommend something, that thing is recommendable
If you can contain something, that thing is containable
If you can foresee something, that thing is foreseeable
If you can write something, that thing is writeable
If you can prevent something, that thing is preventable
If you can understand something, that thing is
2024-07-28 20:47:22 root INFO     [order_1_approx] starting weight calculation for If you can maintain something, that thing is maintainable
If you can write something, that thing is writeable
If you can recommend something, that thing is recommendable
If you can foresee something, that thing is foreseeable
If you can prevent something, that thing is preventable
If you can contain something, that thing is containable
If you can understand something, that thing is understandable
If you can improve something, that thing is
2024-07-28 20:47:22 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-28 20:49:42 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2856,  0.0266,  0.1643,  ...,  0.0232, -0.2040,  0.2734],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.7734, -0.8887,  0.2822,  ..., -1.6914, -8.9609, -3.1016],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0337, -0.0041, -0.0016,  ...,  0.0015,  0.0138,  0.0256],
        [ 0.0005,  0.0441,  0.0043,  ...,  0.0200, -0.0157,  0.0019],
        [-0.0077, -0.0059,  0.0312,  ...,  0.0057,  0.0260,  0.0003],
        ...,
        [ 0.0111, -0.0012,  0.0140,  ...,  0.0276,  0.0065,  0.0090],
        [-0.0017, -0.0073,  0.0034,  ..., -0.0237,  0.0177,  0.0017],
        [-0.0068, -0.0165,  0.0132,  ..., -0.0161, -0.0146,  0.0065]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.8408, -1.1172,  0.1948,  ..., -1.9004, -8.8438, -3.1777]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 20:49:43 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you can maintain something, that thing is maintainable
If you can write something, that thing is writeable
If you can recommend something, that thing is recommendable
If you can foresee something, that thing is foreseeable
If you can prevent something, that thing is preventable
If you can contain something, that thing is containable
If you can understand something, that thing is understandable
If you can improve something, that thing is
2024-07-28 20:49:43 root INFO     [order_1_approx] starting weight calculation for If you can foresee something, that thing is foreseeable
If you can improve something, that thing is improvable
If you can understand something, that thing is understandable
If you can recommend something, that thing is recommendable
If you can write something, that thing is writeable
If you can contain something, that thing is containable
If you can maintain something, that thing is maintainable
If you can prevent something, that thing is
2024-07-28 20:49:44 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-28 20:52:04 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0187,  0.2266, -0.0353,  ..., -0.2112, -0.0668,  0.0426],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.0693, -2.1680, -2.1367,  ..., -0.5957, -6.6875, -2.0703],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 5.0049e-02,  6.7215e-03, -7.3433e-03,  ...,  2.1896e-02,
          7.1259e-03,  6.6986e-03],
        [ 3.5763e-04,  6.4575e-02,  2.4933e-02,  ...,  1.8875e-02,
         -9.1171e-04,  1.0483e-02],
        [-8.2855e-03, -2.5101e-02,  1.5915e-02,  ..., -4.2648e-03,
         -7.4005e-03, -1.3405e-02],
        ...,
        [ 1.7990e-02, -2.0885e-03,  5.8441e-03,  ...,  3.4790e-02,
         -3.0861e-03,  1.8188e-02],
        [ 1.0094e-02, -2.5101e-02, -7.0572e-05,  ..., -2.4231e-02,
          3.8239e-02, -2.1042e-02],
        [-2.2840e-04, -6.2065e-03,  1.9440e-02,  ..., -1.7273e-02,
         -7.6370e-03,  1.0544e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.0215, -2.4766, -2.1074,  ..., -0.5562, -6.2852, -1.8262]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 20:52:05 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you can foresee something, that thing is foreseeable
If you can improve something, that thing is improvable
If you can understand something, that thing is understandable
If you can recommend something, that thing is recommendable
If you can write something, that thing is writeable
If you can contain something, that thing is containable
If you can maintain something, that thing is maintainable
If you can prevent something, that thing is
2024-07-28 20:52:06 root INFO     [order_1_approx] starting weight calculation for If you can contain something, that thing is containable
If you can prevent something, that thing is preventable
If you can foresee something, that thing is foreseeable
If you can maintain something, that thing is maintainable
If you can write something, that thing is writeable
If you can improve something, that thing is improvable
If you can understand something, that thing is understandable
If you can recommend something, that thing is
2024-07-28 20:52:06 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-28 20:54:30 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0865,  0.4536,  0.1959,  ...,  0.3936, -0.2654, -0.1506],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.5107,  0.5361, -0.5327,  ..., -1.1953, -7.9844, -3.9277],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0341,  0.0084, -0.0099,  ...,  0.0417, -0.0111,  0.0347],
        [ 0.0073,  0.0554, -0.0229,  ...,  0.0406, -0.0223,  0.0193],
        [ 0.0105,  0.0030,  0.0418,  ...,  0.0038, -0.0018, -0.0140],
        ...,
        [ 0.0198,  0.0191, -0.0033,  ...,  0.0676,  0.0059,  0.0226],
        [ 0.0380,  0.0012,  0.0019,  ..., -0.0338,  0.0149, -0.0099],
        [-0.0072, -0.0095, -0.0104,  ..., -0.0105,  0.0011,  0.0207]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.6865,  0.9043, -1.0029,  ..., -0.9487, -8.0391, -3.8027]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 20:54:31 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you can contain something, that thing is containable
If you can prevent something, that thing is preventable
If you can foresee something, that thing is foreseeable
If you can maintain something, that thing is maintainable
If you can write something, that thing is writeable
If you can improve something, that thing is improvable
If you can understand something, that thing is understandable
If you can recommend something, that thing is
2024-07-28 20:54:32 root INFO     [order_1_approx] starting weight calculation for If you can understand something, that thing is understandable
If you can contain something, that thing is containable
If you can improve something, that thing is improvable
If you can foresee something, that thing is foreseeable
If you can recommend something, that thing is recommendable
If you can prevent something, that thing is preventable
If you can maintain something, that thing is maintainable
If you can write something, that thing is
2024-07-28 20:54:32 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-28 20:56:50 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1010,  0.2874,  0.2260,  ..., -0.0964, -0.3228,  0.1582],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.2656, -1.6758,  0.2393,  ..., -2.6094, -7.9297, -0.5586],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0288, -0.0213,  0.0034,  ..., -0.0011,  0.0082,  0.0057],
        [-0.0019,  0.0453, -0.0131,  ...,  0.0029, -0.0257, -0.0034],
        [-0.0039, -0.0086,  0.0436,  ...,  0.0204, -0.0049,  0.0102],
        ...,
        [ 0.0217,  0.0250, -0.0063,  ...,  0.0201, -0.0015, -0.0013],
        [ 0.0180,  0.0014,  0.0261,  ..., -0.0245,  0.0343,  0.0068],
        [ 0.0062, -0.0048, -0.0048,  ..., -0.0030,  0.0002,  0.0100]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.1621e+00, -1.9531e+00, -1.0986e-03,  ..., -2.4844e+00,
         -7.7109e+00, -4.0820e-01]], device='cuda:0', dtype=torch.float16,
       grad_fn=<SubBackward0>) 

                    
2024-07-28 20:56:51 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you can understand something, that thing is understandable
If you can contain something, that thing is containable
If you can improve something, that thing is improvable
If you can foresee something, that thing is foreseeable
If you can recommend something, that thing is recommendable
If you can prevent something, that thing is preventable
If you can maintain something, that thing is maintainable
If you can write something, that thing is
2024-07-28 20:56:51 root INFO     total operator prediction time: 1146.6250324249268 seconds
2024-07-28 20:56:51 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on verb+tion_irreg
2024-07-28 20:56:51 root INFO     building operator verb+tion_irreg
2024-07-28 20:56:51 root INFO     [order_1_approx] starting weight calculation for To globalize results in globalization
To restore results in restoration
To declare results in declaration
To illumine results in illumination
To derive results in derivation
To starve results in starvation
To utilize results in utilization
To standardize results in
2024-07-28 20:56:51 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-28 20:59:13 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0687,  0.1130, -0.5322,  ..., -0.2278, -0.3936, -0.1733],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.5640, -4.3203,  0.6338,  ...,  1.1377, -2.4004, -3.3652],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0630,  0.0065, -0.0041,  ...,  0.0032,  0.0057, -0.0053],
        [-0.0146,  0.0457, -0.0021,  ..., -0.0083,  0.0148,  0.0264],
        [-0.0119,  0.0013,  0.0410,  ...,  0.0050,  0.0071, -0.0035],
        ...,
        [-0.0144,  0.0107,  0.0108,  ...,  0.0583, -0.0002,  0.0249],
        [-0.0227,  0.0172, -0.0045,  ...,  0.0320,  0.0491, -0.0045],
        [-0.0134, -0.0041,  0.0061,  ..., -0.0108, -0.0240,  0.0632]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.1909, -3.6738,  1.1211,  ...,  1.7031, -2.5703, -2.8203]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 20:59:15 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To globalize results in globalization
To restore results in restoration
To declare results in declaration
To illumine results in illumination
To derive results in derivation
To starve results in starvation
To utilize results in utilization
To standardize results in
2024-07-28 20:59:15 root INFO     [order_1_approx] starting weight calculation for To derive results in derivation
To restore results in restoration
To illumine results in illumination
To globalize results in globalization
To standardize results in standardization
To starve results in starvation
To declare results in declaration
To utilize results in
2024-07-28 20:59:15 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-28 21:01:37 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3093,  0.1884, -0.0659,  ...,  0.0692, -0.6064, -0.1255],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.4590, -2.0918,  1.3105,  ...,  0.8877, -4.1055, -2.5215],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0182,  0.0125, -0.0052,  ..., -0.0097, -0.0025,  0.0222],
        [-0.0017,  0.0280,  0.0118,  ...,  0.0172,  0.0073, -0.0005],
        [-0.0119, -0.0069,  0.0275,  ..., -0.0102,  0.0005, -0.0089],
        ...,
        [ 0.0096, -0.0032,  0.0089,  ...,  0.0524, -0.0113, -0.0013],
        [ 0.0001,  0.0103, -0.0017,  ...,  0.0095,  0.0396,  0.0035],
        [ 0.0018, -0.0062,  0.0047,  ..., -0.0050, -0.0186,  0.0267]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.1340, -1.9180,  1.6094,  ...,  1.0869, -3.7402, -2.2695]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 21:01:38 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To derive results in derivation
To restore results in restoration
To illumine results in illumination
To globalize results in globalization
To standardize results in standardization
To starve results in starvation
To declare results in declaration
To utilize results in
2024-07-28 21:01:39 root INFO     [order_1_approx] starting weight calculation for To illumine results in illumination
To globalize results in globalization
To derive results in derivation
To starve results in starvation
To restore results in restoration
To utilize results in utilization
To standardize results in standardization
To declare results in
2024-07-28 21:01:39 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-28 21:04:01 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3040,  0.1351, -0.4443,  ..., -0.0187, -0.5234,  0.0118],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.4766, -5.5781,  4.2266,  ...,  2.2129, -3.1523,  0.6211],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 3.6072e-02, -3.1555e-02, -3.6713e-02,  ..., -2.7145e-02,
         -1.2207e-02, -1.5640e-04],
        [ 2.3956e-02,  1.1517e-01,  2.6108e-02,  ...,  4.2603e-02,
          6.3629e-03,  2.5665e-02],
        [-3.8872e-03, -4.6448e-02,  3.2654e-02,  ..., -1.2360e-02,
         -1.0910e-02, -3.1433e-02],
        ...,
        [ 6.9923e-03,  2.7252e-02,  1.5442e-02,  ...,  8.3862e-02,
         -3.9101e-03,  2.3895e-02],
        [-7.2479e-05,  1.1978e-02,  1.7456e-02,  ...,  1.8036e-02,
          5.2856e-02, -4.3564e-03],
        [ 2.4689e-02, -5.4359e-03,  1.8372e-02,  ...,  8.8730e-03,
         -2.2125e-02,  5.2612e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.6460, -4.6484,  3.0625,  ...,  2.0449, -3.2344, -0.1055]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 21:04:02 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To illumine results in illumination
To globalize results in globalization
To derive results in derivation
To starve results in starvation
To restore results in restoration
To utilize results in utilization
To standardize results in standardization
To declare results in
2024-07-28 21:04:02 root INFO     [order_1_approx] starting weight calculation for To globalize results in globalization
To illumine results in illumination
To standardize results in standardization
To utilize results in utilization
To starve results in starvation
To restore results in restoration
To declare results in declaration
To derive results in
2024-07-28 21:04:02 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-28 21:06:24 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1392, -0.1460,  0.0151,  ..., -0.3611, -0.3579,  0.2620],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.0332, -2.6289,  0.7866,  ...,  0.3206, -1.5918, -1.1318],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0384,  0.0189, -0.0171,  ..., -0.0140, -0.0068,  0.0159],
        [-0.0118,  0.0780,  0.0476,  ...,  0.0214, -0.0055,  0.0247],
        [-0.0080, -0.0196,  0.0578,  ...,  0.0248, -0.0146,  0.0070],
        ...,
        [ 0.0224,  0.0149,  0.0123,  ...,  0.0425,  0.0202, -0.0027],
        [-0.0148, -0.0012, -0.0011,  ...,  0.0034,  0.0463, -0.0194],
        [ 0.0120, -0.0086,  0.0163,  ...,  0.0217, -0.0213,  0.0750]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.1809, -2.4316,  1.0469,  ...,  0.4885, -2.2539, -0.8135]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 21:06:25 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To globalize results in globalization
To illumine results in illumination
To standardize results in standardization
To utilize results in utilization
To starve results in starvation
To restore results in restoration
To declare results in declaration
To derive results in
2024-07-28 21:06:26 root INFO     [order_1_approx] starting weight calculation for To utilize results in utilization
To globalize results in globalization
To restore results in restoration
To standardize results in standardization
To declare results in declaration
To derive results in derivation
To starve results in starvation
To illumine results in
2024-07-28 21:06:26 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-28 21:08:48 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.3770,  0.4302, -0.6006,  ..., -0.0424, -0.4766, -0.0018],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.7129, -1.1230,  2.5938,  ...,  3.8770, -2.0391, -2.2578],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0356,  0.0026, -0.0021,  ..., -0.0170, -0.0132,  0.0093],
        [ 0.0021,  0.0471,  0.0258,  ...,  0.0326,  0.0133,  0.0218],
        [ 0.0063,  0.0003,  0.0447,  ..., -0.0051,  0.0006,  0.0027],
        ...,
        [ 0.0026, -0.0083,  0.0127,  ...,  0.0534, -0.0043,  0.0023],
        [-0.0047,  0.0055, -0.0185,  ..., -0.0153,  0.0233, -0.0054],
        [ 0.0025, -0.0017,  0.0108,  ...,  0.0130,  0.0038,  0.0517]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.8076, -0.8325,  2.7578,  ...,  3.9922, -2.4004, -1.8799]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 21:08:49 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To utilize results in utilization
To globalize results in globalization
To restore results in restoration
To standardize results in standardization
To declare results in declaration
To derive results in derivation
To starve results in starvation
To illumine results in
2024-07-28 21:08:49 root INFO     [order_1_approx] starting weight calculation for To derive results in derivation
To utilize results in utilization
To restore results in restoration
To standardize results in standardization
To illumine results in illumination
To globalize results in globalization
To declare results in declaration
To starve results in
2024-07-28 21:08:49 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-28 21:11:11 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2236, -0.2389, -0.5737,  ..., -0.0758, -0.0829,  0.0947],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.7969, -4.6367,  2.9961,  ...,  1.0439, -1.9834, -1.0449],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0750,  0.0090,  0.0251,  ...,  0.0070, -0.0304,  0.0053],
        [-0.0232,  0.0512, -0.0109,  ...,  0.0425,  0.0296,  0.0107],
        [ 0.0168, -0.0212,  0.0554,  ..., -0.0050, -0.0246,  0.0073],
        ...,
        [ 0.0182, -0.0045,  0.0021,  ...,  0.0420, -0.0093, -0.0143],
        [-0.0139,  0.0170,  0.0337,  ...,  0.0322,  0.0526,  0.0067],
        [ 0.0007, -0.0150, -0.0242,  ...,  0.0076, -0.0155,  0.0615]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.8086, -4.8125,  2.9551,  ...,  1.9170, -2.1758, -1.2969]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 21:11:12 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To derive results in derivation
To utilize results in utilization
To restore results in restoration
To standardize results in standardization
To illumine results in illumination
To globalize results in globalization
To declare results in declaration
To starve results in
2024-07-28 21:11:13 root INFO     [order_1_approx] starting weight calculation for To standardize results in standardization
To starve results in starvation
To utilize results in utilization
To illumine results in illumination
To declare results in declaration
To globalize results in globalization
To derive results in derivation
To restore results in
2024-07-28 21:11:13 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-28 21:13:36 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1812, -0.0486, -0.9160,  ..., -0.4541, -0.3081,  0.5049],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.6318, -3.9805,  0.2090,  ...,  0.7485, -2.0859, -0.8867],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0113, -0.0043, -0.0073,  ..., -0.0129,  0.0063,  0.0408],
        [ 0.0053,  0.0672,  0.0013,  ...,  0.0391,  0.0102,  0.0180],
        [ 0.0242, -0.0128,  0.0289,  ...,  0.0136, -0.0039, -0.0187],
        ...,
        [-0.0030,  0.0210, -0.0117,  ...,  0.0383, -0.0049, -0.0018],
        [-0.0266, -0.0002,  0.0055,  ...,  0.0094,  0.0312, -0.0076],
        [ 0.0125,  0.0037, -0.0190,  ...,  0.0072, -0.0098,  0.0565]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.0293, -3.8750,  0.6689,  ...,  0.8184, -2.7070, -0.8892]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 21:13:38 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To standardize results in standardization
To starve results in starvation
To utilize results in utilization
To illumine results in illumination
To declare results in declaration
To globalize results in globalization
To derive results in derivation
To restore results in
2024-07-28 21:13:38 root INFO     [order_1_approx] starting weight calculation for To restore results in restoration
To utilize results in utilization
To starve results in starvation
To derive results in derivation
To declare results in declaration
To standardize results in standardization
To illumine results in illumination
To globalize results in
2024-07-28 21:13:38 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-28 21:15:59 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0203,  0.3611, -0.4448,  ...,  0.2495, -0.3164,  0.1026],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.9531, -2.8730,  1.1953,  ...,  0.9141, -2.7227, -2.1914],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0414,  0.0036,  0.0095,  ...,  0.0015, -0.0069,  0.0131],
        [-0.0171,  0.0477,  0.0071,  ...,  0.0236,  0.0073,  0.0222],
        [-0.0039, -0.0033,  0.0359,  ..., -0.0030,  0.0027,  0.0038],
        ...,
        [-0.0066,  0.0052, -0.0092,  ...,  0.0522,  0.0018,  0.0028],
        [-0.0080,  0.0085,  0.0014,  ...,  0.0062,  0.0394, -0.0072],
        [-0.0043, -0.0085,  0.0030,  ...,  0.0049, -0.0075,  0.0434]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.9551, -2.9102,  1.3320,  ...,  0.9346, -2.8086, -2.2227]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 21:16:00 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To restore results in restoration
To utilize results in utilization
To starve results in starvation
To derive results in derivation
To declare results in declaration
To standardize results in standardization
To illumine results in illumination
To globalize results in
2024-07-28 21:16:00 root INFO     total operator prediction time: 1148.3939654827118 seconds
2024-07-28 21:16:00 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on adj+ly_reg
2024-07-28 21:16:00 root INFO     building operator adj+ly_reg
2024-07-28 21:16:00 root INFO     [order_1_approx] starting weight calculation for The adjective form of virtual is virtually
The adjective form of significant is significantly
The adjective form of increasing is increasingly
The adjective form of strong is strongly
The adjective form of nice is nicely
The adjective form of actual is actually
The adjective form of extensive is extensively
The adjective form of famous is
2024-07-28 21:16:00 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-28 21:18:24 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3511,  0.2563, -0.5273,  ..., -0.2434, -0.5396, -0.0588],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.1641, -1.3896,  1.9717,  ..., -1.2803, -3.2383, -2.3945],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0525, -0.0191, -0.0013,  ...,  0.0193,  0.0075,  0.0280],
        [-0.0064,  0.0475,  0.0155,  ...,  0.0270, -0.0024,  0.0008],
        [ 0.0089, -0.0119,  0.0587,  ...,  0.0092, -0.0104, -0.0040],
        ...,
        [ 0.0413,  0.0207,  0.0233,  ...,  0.0606, -0.0017,  0.0210],
        [ 0.0156,  0.0351,  0.0091,  ..., -0.0301,  0.0355,  0.0143],
        [ 0.0177, -0.0037,  0.0036,  ..., -0.0082, -0.0240,  0.0255]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.1895, -1.1836,  2.3633,  ..., -1.2822, -3.2168, -2.4668]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 21:18:25 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The adjective form of virtual is virtually
The adjective form of significant is significantly
The adjective form of increasing is increasingly
The adjective form of strong is strongly
The adjective form of nice is nicely
The adjective form of actual is actually
The adjective form of extensive is extensively
The adjective form of famous is
2024-07-28 21:18:25 root INFO     [order_1_approx] starting weight calculation for The adjective form of famous is famously
The adjective form of significant is significantly
The adjective form of strong is strongly
The adjective form of virtual is virtually
The adjective form of extensive is extensively
The adjective form of actual is actually
The adjective form of nice is nicely
The adjective form of increasing is
2024-07-28 21:18:25 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-28 21:20:47 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0717, -0.0288, -0.5127,  ..., -0.0375, -0.1969, -0.1321],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.2188, -1.2266, -0.2622,  ..., -0.3770, -3.2344, -1.4258],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0576, -0.0077, -0.0085,  ...,  0.0042,  0.0072,  0.0485],
        [ 0.0367,  0.0718, -0.0227,  ...,  0.0545, -0.0140,  0.0144],
        [ 0.0397,  0.0100,  0.0266,  ...,  0.0071,  0.0005,  0.0031],
        ...,
        [ 0.0156,  0.0147,  0.0036,  ...,  0.0701,  0.0144,  0.0003],
        [-0.0190,  0.0174,  0.0108,  ..., -0.0104,  0.0313, -0.0168],
        [ 0.0176,  0.0179, -0.0070,  ..., -0.0033, -0.0062,  0.0286]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.2910, -1.5361,  0.1016,  ..., -0.5840, -3.2051, -1.6357]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 21:20:48 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The adjective form of famous is famously
The adjective form of significant is significantly
The adjective form of strong is strongly
The adjective form of virtual is virtually
The adjective form of extensive is extensively
The adjective form of actual is actually
The adjective form of nice is nicely
The adjective form of increasing is
2024-07-28 21:20:48 root INFO     [order_1_approx] starting weight calculation for The adjective form of extensive is extensively
The adjective form of strong is strongly
The adjective form of increasing is increasingly
The adjective form of famous is famously
The adjective form of actual is actually
The adjective form of significant is significantly
The adjective form of virtual is virtually
The adjective form of nice is
2024-07-28 21:20:48 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-28 21:23:10 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4414,  0.0753, -0.4556,  ..., -0.1548, -0.4556,  0.0692],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.9175, -2.0137, -1.8955,  ..., -0.0596, -6.3828, -1.5156],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0833, -0.0531,  0.0129,  ..., -0.0500,  0.0177,  0.0258],
        [ 0.0122,  0.0439, -0.0083,  ...,  0.0447,  0.0059, -0.0217],
        [ 0.0065, -0.0482,  0.0544,  ...,  0.0159, -0.0043,  0.0006],
        ...,
        [ 0.0298, -0.0136,  0.0006,  ...,  0.0903,  0.0046,  0.0029],
        [ 0.0082,  0.0454,  0.0301,  ...,  0.0486,  0.0411, -0.0005],
        [ 0.0015, -0.0002, -0.0044,  ..., -0.0087, -0.0404,  0.0298]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.7725, -2.2559, -1.7822,  ..., -0.0764, -6.3594, -1.6777]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 21:23:11 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The adjective form of extensive is extensively
The adjective form of strong is strongly
The adjective form of increasing is increasingly
The adjective form of famous is famously
The adjective form of actual is actually
The adjective form of significant is significantly
The adjective form of virtual is virtually
The adjective form of nice is
2024-07-28 21:23:12 root INFO     [order_1_approx] starting weight calculation for The adjective form of nice is nicely
The adjective form of increasing is increasingly
The adjective form of extensive is extensively
The adjective form of virtual is virtually
The adjective form of actual is actually
The adjective form of famous is famously
The adjective form of significant is significantly
The adjective form of strong is
2024-07-28 21:23:12 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-28 21:25:34 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2959, -0.3506, -0.2529,  ..., -0.0608, -0.1738,  0.2332],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.5625, -3.1035, -1.0918,  ...,  0.0703, -2.6816, -3.9316],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0407, -0.0143, -0.0051,  ..., -0.0076, -0.0025,  0.0439],
        [-0.0063,  0.0537,  0.0156,  ...,  0.0237,  0.0166, -0.0070],
        [ 0.0086, -0.0294,  0.0470,  ...,  0.0018, -0.0100,  0.0012],
        ...,
        [ 0.0033,  0.0242, -0.0204,  ...,  0.0765,  0.0053,  0.0045],
        [-0.0033,  0.0267, -0.0016,  ..., -0.0123,  0.0571, -0.0041],
        [-0.0058,  0.0053, -0.0020,  ...,  0.0375, -0.0067,  0.0114]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.3730, -2.9941, -0.8003,  ..., -0.1432, -2.9863, -3.4395]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 21:25:35 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The adjective form of nice is nicely
The adjective form of increasing is increasingly
The adjective form of extensive is extensively
The adjective form of virtual is virtually
The adjective form of actual is actually
The adjective form of famous is famously
The adjective form of significant is significantly
The adjective form of strong is
2024-07-28 21:25:35 root INFO     [order_1_approx] starting weight calculation for The adjective form of famous is famously
The adjective form of virtual is virtually
The adjective form of strong is strongly
The adjective form of significant is significantly
The adjective form of extensive is extensively
The adjective form of increasing is increasingly
The adjective form of nice is nicely
The adjective form of actual is
2024-07-28 21:25:35 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-28 21:27:57 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.5586,  0.1147, -0.4463,  ..., -0.3630, -0.2128,  0.1246],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.8086, -3.3926,  0.3989,  ..., -0.3755, -3.1445, -1.0107],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0809, -0.0500,  0.0138,  ...,  0.0182,  0.0187,  0.0365],
        [ 0.0072,  0.0709, -0.0043,  ...,  0.0438, -0.0002, -0.0179],
        [ 0.0019, -0.0145,  0.0548,  ...,  0.0207, -0.0222, -0.0147],
        ...,
        [ 0.0200,  0.0645, -0.0361,  ...,  0.0601, -0.0012, -0.0195],
        [ 0.0049,  0.0117,  0.0156,  ..., -0.0323,  0.0424, -0.0309],
        [ 0.0568, -0.0144, -0.0133,  ...,  0.0019, -0.0362,  0.0315]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.4688, -3.3945,  0.1896,  ..., -0.0339, -3.0078, -1.5635]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 21:27:58 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The adjective form of famous is famously
The adjective form of virtual is virtually
The adjective form of strong is strongly
The adjective form of significant is significantly
The adjective form of extensive is extensively
The adjective form of increasing is increasingly
The adjective form of nice is nicely
The adjective form of actual is
2024-07-28 21:27:59 root INFO     [order_1_approx] starting weight calculation for The adjective form of increasing is increasingly
The adjective form of nice is nicely
The adjective form of actual is actually
The adjective form of strong is strongly
The adjective form of famous is famously
The adjective form of extensive is extensively
The adjective form of virtual is virtually
The adjective form of significant is
2024-07-28 21:27:59 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-28 21:30:20 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0449,  0.1207, -0.7344,  ..., -0.3279, -0.1686, -0.1049],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.2305,  0.4414, -0.8433,  ..., -4.7969, -0.8115, -3.1055],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 7.0068e-02, -1.1032e-02,  4.6425e-03,  ..., -3.8357e-03,
          1.7639e-02,  6.7139e-03],
        [ 3.5667e-03,  4.8462e-02,  2.2018e-02,  ...,  2.0065e-02,
          6.3038e-04,  1.5497e-03],
        [ 1.2527e-02, -1.9875e-03,  4.8035e-02,  ...,  1.1835e-03,
         -8.7738e-05,  1.1688e-02],
        ...,
        [-1.2238e-02, -8.7738e-03,  1.9196e-02,  ...,  7.5378e-02,
          1.4694e-02,  7.0419e-03],
        [-1.2329e-02,  1.7075e-02,  8.4076e-03,  ..., -1.8295e-02,
          5.8380e-02,  8.2016e-05],
        [ 9.9182e-03,  2.2385e-02, -5.2986e-03,  ...,  2.5692e-03,
         -3.6163e-02,  1.8723e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.2891,  0.2249, -0.1846,  ..., -4.6172, -0.8750, -2.8848]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 21:30:21 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The adjective form of increasing is increasingly
The adjective form of nice is nicely
The adjective form of actual is actually
The adjective form of strong is strongly
The adjective form of famous is famously
The adjective form of extensive is extensively
The adjective form of virtual is virtually
The adjective form of significant is
2024-07-28 21:30:21 root INFO     [order_1_approx] starting weight calculation for The adjective form of strong is strongly
The adjective form of famous is famously
The adjective form of significant is significantly
The adjective form of nice is nicely
The adjective form of actual is actually
The adjective form of increasing is increasingly
The adjective form of virtual is virtually
The adjective form of extensive is
2024-07-28 21:30:21 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-28 21:32:42 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1592,  0.0591, -0.5591,  ..., -0.5884, -0.2627,  0.1106],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.2305, -0.5566, -1.3135,  ..., -1.6299, -1.4756, -3.7246],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0679, -0.0176, -0.0092,  ...,  0.0211,  0.0052,  0.0298],
        [ 0.0058,  0.0868,  0.0045,  ...,  0.0185,  0.0067,  0.0034],
        [ 0.0330, -0.0215,  0.0528,  ..., -0.0070,  0.0082,  0.0278],
        ...,
        [ 0.0475,  0.0030,  0.0238,  ...,  0.1006,  0.0105, -0.0143],
        [ 0.0086,  0.0183,  0.0078,  ..., -0.0070,  0.0436, -0.0136],
        [ 0.0186,  0.0161, -0.0097,  ..., -0.0099, -0.0094,  0.0247]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.4434, -0.9824, -1.1826,  ..., -1.7783, -1.0410, -3.5488]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 21:32:43 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The adjective form of strong is strongly
The adjective form of famous is famously
The adjective form of significant is significantly
The adjective form of nice is nicely
The adjective form of actual is actually
The adjective form of increasing is increasingly
The adjective form of virtual is virtually
The adjective form of extensive is
2024-07-28 21:32:43 root INFO     [order_1_approx] starting weight calculation for The adjective form of strong is strongly
The adjective form of actual is actually
The adjective form of nice is nicely
The adjective form of extensive is extensively
The adjective form of famous is famously
The adjective form of increasing is increasingly
The adjective form of significant is significantly
The adjective form of virtual is
2024-07-28 21:32:43 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-28 21:35:05 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4653, -0.2671, -0.2172,  ..., -0.2426, -0.0153,  0.4143],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.9307, -3.4727, -0.4211,  ..., -3.2324, -1.0244, -0.7490],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0717, -0.0374,  0.0108,  ...,  0.0099,  0.0270,  0.0212],
        [ 0.0054,  0.0781, -0.0153,  ...,  0.0312, -0.0143, -0.0216],
        [ 0.0110, -0.0239,  0.0913,  ..., -0.0039, -0.0090,  0.0095],
        ...,
        [ 0.0486,  0.0139, -0.0078,  ...,  0.1003, -0.0005,  0.0176],
        [ 0.0108,  0.0468, -0.0155,  ..., -0.0101,  0.0742, -0.0108],
        [ 0.0210,  0.0350,  0.0019,  ...,  0.0177, -0.0172,  0.0571]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.7729, -3.6602, -0.4463,  ..., -3.1660, -0.8750, -1.1953]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 21:35:06 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The adjective form of strong is strongly
The adjective form of actual is actually
The adjective form of nice is nicely
The adjective form of extensive is extensively
The adjective form of famous is famously
The adjective form of increasing is increasingly
The adjective form of significant is significantly
The adjective form of virtual is
2024-07-28 21:35:06 root INFO     total operator prediction time: 1146.3463172912598 seconds
2024-07-28 21:35:06 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on over+adj_reg
2024-07-28 21:35:06 root INFO     building operator over+adj_reg
2024-07-28 21:35:06 root INFO     [order_1_approx] starting weight calculation for If something is too excited, it is overexcited
If something is too spent, it is overspent
If something is too done, it is overdone
If something is too confident, it is overconfident
If something is too stocked, it is overstocked
If something is too represented, it is overrepresented
If something is too arching, it is overarching
If something is too populated, it is
2024-07-28 21:35:06 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-28 21:37:28 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1093,  0.1997, -0.5518,  ...,  0.0376, -0.4790, -0.0342],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.5703, -2.6699,  0.5142,  ..., -0.4927, -0.7949, -1.6436],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0407, -0.0024,  0.0058,  ...,  0.0033, -0.0051,  0.0119],
        [ 0.0159,  0.0443,  0.0050,  ...,  0.0266,  0.0132,  0.0036],
        [ 0.0145,  0.0102,  0.0414,  ..., -0.0114, -0.0139,  0.0122],
        ...,
        [ 0.0010,  0.0119,  0.0058,  ...,  0.0543,  0.0033,  0.0015],
        [-0.0063,  0.0112,  0.0067,  ..., -0.0107,  0.0267, -0.0174],
        [ 0.0007,  0.0163,  0.0082,  ..., -0.0077, -0.0254,  0.0605]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.4053, -2.8398,  0.4617,  ..., -0.3730, -0.6387, -1.9531]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 21:37:29 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is too excited, it is overexcited
If something is too spent, it is overspent
If something is too done, it is overdone
If something is too confident, it is overconfident
If something is too stocked, it is overstocked
If something is too represented, it is overrepresented
If something is too arching, it is overarching
If something is too populated, it is
2024-07-28 21:37:29 root INFO     [order_1_approx] starting weight calculation for If something is too arching, it is overarching
If something is too stocked, it is overstocked
If something is too confident, it is overconfident
If something is too populated, it is overpopulated
If something is too done, it is overdone
If something is too represented, it is overrepresented
If something is too spent, it is overspent
If something is too excited, it is
2024-07-28 21:37:29 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-28 21:39:55 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0139, -0.2354, -0.7041,  ...,  0.0262, -0.6963,  0.1611],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.0527, -4.1094, -0.0850,  ...,  0.6611, -1.6240, -2.5684],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0522,  0.0028, -0.0169,  ..., -0.0125,  0.0198,  0.0015],
        [ 0.0071,  0.0620, -0.0077,  ...,  0.0074, -0.0005, -0.0088],
        [ 0.0290,  0.0044,  0.0456,  ...,  0.0064, -0.0034,  0.0073],
        ...,
        [ 0.0137,  0.0235,  0.0068,  ...,  0.0542,  0.0042,  0.0172],
        [ 0.0002,  0.0046, -0.0079,  ..., -0.0022,  0.0331, -0.0307],
        [ 0.0005,  0.0012,  0.0153,  ...,  0.0173, -0.0115,  0.0409]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.4314, -4.2695, -0.0496,  ...,  0.3611, -1.2988, -2.8086]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 21:39:56 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is too arching, it is overarching
If something is too stocked, it is overstocked
If something is too confident, it is overconfident
If something is too populated, it is overpopulated
If something is too done, it is overdone
If something is too represented, it is overrepresented
If something is too spent, it is overspent
If something is too excited, it is
2024-07-28 21:39:56 root INFO     [order_1_approx] starting weight calculation for If something is too done, it is overdone
If something is too represented, it is overrepresented
If something is too arching, it is overarching
If something is too confident, it is overconfident
If something is too excited, it is overexcited
If something is too populated, it is overpopulated
If something is too stocked, it is overstocked
If something is too spent, it is
2024-07-28 21:39:56 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-28 21:42:19 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0724, -0.1082, -0.3020,  ..., -0.2800, -0.4595,  0.1451],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.6680, -3.0664, -1.2012,  ..., -1.6172, -2.1484, -3.0371],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0452,  0.0098, -0.0092,  ...,  0.0206, -0.0054,  0.0206],
        [-0.0030,  0.0488, -0.0128,  ...,  0.0306,  0.0034,  0.0188],
        [ 0.0258,  0.0004,  0.0538,  ...,  0.0033, -0.0074,  0.0028],
        ...,
        [ 0.0239,  0.0040, -0.0050,  ...,  0.0673,  0.0020, -0.0093],
        [-0.0038,  0.0072, -0.0052,  ...,  0.0137,  0.0309, -0.0245],
        [-0.0085,  0.0237, -0.0023,  ...,  0.0052, -0.0026,  0.0702]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.3711, -3.0430, -1.4072,  ..., -1.1836, -1.3877, -3.0195]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 21:42:20 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is too done, it is overdone
If something is too represented, it is overrepresented
If something is too arching, it is overarching
If something is too confident, it is overconfident
If something is too excited, it is overexcited
If something is too populated, it is overpopulated
If something is too stocked, it is overstocked
If something is too spent, it is
2024-07-28 21:42:20 root INFO     [order_1_approx] starting weight calculation for If something is too arching, it is overarching
If something is too confident, it is overconfident
If something is too populated, it is overpopulated
If something is too done, it is overdone
If something is too stocked, it is overstocked
If something is too spent, it is overspent
If something is too excited, it is overexcited
If something is too represented, it is
2024-07-28 21:42:20 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-28 21:44:37 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1765, -0.0483, -0.7021,  ..., -0.3711, -0.3057, -0.2233],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.6221, -2.4082,  0.6479,  ..., -0.6006, -2.4766, -4.0664],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0627, -0.0037,  0.0110,  ...,  0.0072,  0.0015,  0.0169],
        [ 0.0007,  0.0607,  0.0142,  ...,  0.0233, -0.0173, -0.0082],
        [ 0.0120, -0.0044,  0.0434,  ...,  0.0021, -0.0142,  0.0151],
        ...,
        [ 0.0133,  0.0103, -0.0182,  ...,  0.0615, -0.0092,  0.0288],
        [ 0.0042,  0.0020, -0.0169,  ..., -0.0238,  0.0498, -0.0176],
        [-0.0069, -0.0010, -0.0117,  ...,  0.0165, -0.0226,  0.0569]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.5098, -2.8770,  0.7183,  ..., -0.4041, -1.9854, -4.0547]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 21:44:38 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is too arching, it is overarching
If something is too confident, it is overconfident
If something is too populated, it is overpopulated
If something is too done, it is overdone
If something is too stocked, it is overstocked
If something is too spent, it is overspent
If something is too excited, it is overexcited
If something is too represented, it is
2024-07-28 21:44:38 root INFO     [order_1_approx] starting weight calculation for If something is too populated, it is overpopulated
If something is too done, it is overdone
If something is too represented, it is overrepresented
If something is too arching, it is overarching
If something is too stocked, it is overstocked
If something is too excited, it is overexcited
If something is too spent, it is overspent
If something is too confident, it is
2024-07-28 21:44:38 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-28 21:46:59 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0331,  0.1766, -0.4434,  ...,  0.4165, -0.3508, -0.0353],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.5645, -3.9062,  1.7715,  ...,  1.7852, -1.7959, -0.7480],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 4.9713e-02, -8.9798e-03, -1.0109e-04,  ...,  2.6321e-04,
         -3.0022e-03,  7.8888e-03],
        [ 8.1482e-03,  4.4769e-02,  5.0545e-05,  ..., -4.7035e-03,
          8.3237e-03,  1.0042e-03],
        [-1.5612e-03, -7.6790e-03,  5.4413e-02,  ...,  1.5488e-03,
          7.0724e-03,  9.4147e-03],
        ...,
        [ 9.2163e-03,  1.0811e-02,  4.6463e-03,  ...,  6.2195e-02,
          6.4049e-03,  7.6027e-03],
        [ 1.5488e-02,  1.4229e-02,  2.0370e-02,  ...,  1.9836e-03,
          4.0436e-02, -2.2659e-02],
        [-3.2768e-03, -9.2926e-03,  1.3138e-02,  ...,  2.7790e-03,
         -4.2152e-03,  3.5065e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.8809, -3.8320,  1.4502,  ...,  1.7861, -1.6992, -0.6855]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 21:47:00 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is too populated, it is overpopulated
If something is too done, it is overdone
If something is too represented, it is overrepresented
If something is too arching, it is overarching
If something is too stocked, it is overstocked
If something is too excited, it is overexcited
If something is too spent, it is overspent
If something is too confident, it is
2024-07-28 21:47:00 root INFO     [order_1_approx] starting weight calculation for If something is too confident, it is overconfident
If something is too represented, it is overrepresented
If something is too done, it is overdone
If something is too populated, it is overpopulated
If something is too excited, it is overexcited
If something is too spent, it is overspent
If something is too arching, it is overarching
If something is too stocked, it is
2024-07-28 21:47:00 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-28 21:49:20 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2255, -0.1405, -0.5659,  ..., -0.2185, -0.1389, -0.0967],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.1777, -3.0078, -0.1243,  ..., -0.3921, -1.9521, -2.3125],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 4.5319e-02, -1.6266e-02,  2.6226e-06,  ..., -6.7062e-03,
          1.1322e-02,  9.8724e-03],
        [-1.3893e-02,  5.3955e-02,  6.3705e-03,  ...,  1.3260e-02,
          5.5046e-03,  6.3248e-03],
        [ 1.6403e-02,  1.8299e-04,  4.0009e-02,  ...,  4.1237e-03,
         -1.8501e-04,  3.5706e-03],
        ...,
        [ 5.2567e-03,  2.7847e-04,  5.1041e-03,  ...,  5.9021e-02,
          4.5662e-03, -2.5940e-03],
        [ 6.0577e-03,  8.5907e-03, -5.7716e-03,  ..., -1.1330e-03,
          3.3997e-02, -1.9714e-02],
        [-3.5114e-03, -2.9984e-03, -7.8201e-03,  ..., -1.1826e-04,
         -8.9417e-03,  4.8737e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.1797, -2.8379, -0.3105,  ..., -0.2325, -1.6143, -2.0938]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 21:49:21 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is too confident, it is overconfident
If something is too represented, it is overrepresented
If something is too done, it is overdone
If something is too populated, it is overpopulated
If something is too excited, it is overexcited
If something is too spent, it is overspent
If something is too arching, it is overarching
If something is too stocked, it is
2024-07-28 21:49:21 root INFO     [order_1_approx] starting weight calculation for If something is too confident, it is overconfident
If something is too spent, it is overspent
If something is too done, it is overdone
If something is too populated, it is overpopulated
If something is too stocked, it is overstocked
If something is too excited, it is overexcited
If something is too represented, it is overrepresented
If something is too arching, it is
2024-07-28 21:49:21 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-28 21:51:42 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0692, -0.4922, -0.1802,  ..., -0.0878, -0.4321, -0.4729],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.9653, -3.6250,  2.0293,  ...,  0.6040, -1.4102, -2.7812],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0699, -0.0111, -0.0061,  ...,  0.0111,  0.0213,  0.0147],
        [ 0.0043,  0.0760,  0.0001,  ...,  0.0011, -0.0093,  0.0045],
        [ 0.0024,  0.0219,  0.0516,  ...,  0.0078,  0.0183,  0.0058],
        ...,
        [ 0.0148,  0.0231,  0.0130,  ...,  0.0625,  0.0100, -0.0020],
        [ 0.0305,  0.0112,  0.0161,  ..., -0.0251,  0.0531, -0.0169],
        [-0.0164, -0.0008,  0.0019,  ...,  0.0032, -0.0223,  0.0468]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.1279, -3.6426,  1.5098,  ...,  0.7441, -1.3613, -2.8594]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 21:51:43 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is too confident, it is overconfident
If something is too spent, it is overspent
If something is too done, it is overdone
If something is too populated, it is overpopulated
If something is too stocked, it is overstocked
If something is too excited, it is overexcited
If something is too represented, it is overrepresented
If something is too arching, it is
2024-07-28 21:51:43 root INFO     [order_1_approx] starting weight calculation for If something is too represented, it is overrepresented
If something is too spent, it is overspent
If something is too arching, it is overarching
If something is too stocked, it is overstocked
If something is too confident, it is overconfident
If something is too excited, it is overexcited
If something is too populated, it is overpopulated
If something is too done, it is
2024-07-28 21:51:43 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-28 21:54:05 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0042, -0.1426, -0.4678,  ..., -0.3506, -0.5029,  0.2749],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.4321, -2.7852, -0.8047,  ...,  1.4902, -3.6250, -1.4287],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0384,  0.0246,  0.0110,  ...,  0.0141,  0.0271,  0.0387],
        [-0.0001,  0.0474,  0.0063,  ...,  0.0335,  0.0075, -0.0073],
        [ 0.0241, -0.0221,  0.0397,  ...,  0.0023, -0.0004,  0.0176],
        ...,
        [ 0.0182,  0.0090,  0.0037,  ...,  0.0559, -0.0064, -0.0009],
        [ 0.0167, -0.0190, -0.0080,  ...,  0.0019,  0.0183, -0.0031],
        [ 0.0143,  0.0042,  0.0023,  ...,  0.0020, -0.0012,  0.0378]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.0627, -2.6895, -0.6348,  ...,  1.1973, -3.3281, -1.1992]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 21:54:06 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is too represented, it is overrepresented
If something is too spent, it is overspent
If something is too arching, it is overarching
If something is too stocked, it is overstocked
If something is too confident, it is overconfident
If something is too excited, it is overexcited
If something is too populated, it is overpopulated
If something is too done, it is
2024-07-28 21:54:06 root INFO     total operator prediction time: 1139.8694746494293 seconds
2024-07-28 21:54:06 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on verb+er_irreg
2024-07-28 21:54:06 root INFO     building operator verb+er_irreg
2024-07-28 21:54:06 root INFO     [order_1_approx] starting weight calculation for If you receive something, you are a receiver
If you provide something, you are a provider
If you eat something, you are a eater
If you promote something, you are a promoter
If you explore something, you are a explorer
If you offend something, you are a offender
If you manage something, you are a manager
If you destroy something, you are a
2024-07-28 21:54:06 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-28 21:56:28 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.3557,  0.1956, -0.0391,  ...,  0.1097, -0.0184,  0.0996],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 6.3594, -2.5059,  0.4268,  ..., -2.9727, -3.8770, -0.4302],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0493,  0.0171,  0.0008,  ...,  0.0063, -0.0012, -0.0154],
        [ 0.0024,  0.0388,  0.0047,  ...,  0.0036,  0.0016,  0.0046],
        [ 0.0251,  0.0074,  0.0159,  ...,  0.0059,  0.0085, -0.0035],
        ...,
        [ 0.0059,  0.0161, -0.0004,  ...,  0.0100,  0.0198, -0.0070],
        [-0.0173,  0.0131, -0.0035,  ..., -0.0171,  0.0269,  0.0053],
        [ 0.0113,  0.0031, -0.0113,  ...,  0.0010, -0.0042,  0.0188]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 6.4766, -2.7812,  0.4397,  ..., -2.9531, -3.7363, -0.3970]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 21:56:29 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you receive something, you are a receiver
If you provide something, you are a provider
If you eat something, you are a eater
If you promote something, you are a promoter
If you explore something, you are a explorer
If you offend something, you are a offender
If you manage something, you are a manager
If you destroy something, you are a
2024-07-28 21:56:29 root INFO     [order_1_approx] starting weight calculation for If you provide something, you are a provider
If you eat something, you are a eater
If you destroy something, you are a destroyer
If you explore something, you are a explorer
If you manage something, you are a manager
If you offend something, you are a offender
If you receive something, you are a receiver
If you promote something, you are a
2024-07-28 21:56:30 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-28 21:58:53 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2206,  0.3481, -0.0382,  ...,  0.3584,  0.0980,  0.1716],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.5820, -3.2422,  0.3564,  ...,  1.5332, -5.3164, -2.5586],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0405, -0.0042,  0.0179,  ...,  0.0135, -0.0111,  0.0192],
        [-0.0120,  0.0447,  0.0055,  ...,  0.0337,  0.0222, -0.0165],
        [ 0.0173,  0.0037,  0.0393,  ...,  0.0062, -0.0206,  0.0319],
        ...,
        [ 0.0085,  0.0037,  0.0064,  ...,  0.0583,  0.0313, -0.0026],
        [ 0.0017,  0.0032, -0.0141,  ..., -0.0366,  0.0347, -0.0178],
        [ 0.0102, -0.0227, -0.0029,  ..., -0.0268, -0.0138,  0.0218]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.8320, -3.3984,  0.5015,  ...,  1.8262, -5.8008, -3.0352]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 21:58:54 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you provide something, you are a provider
If you eat something, you are a eater
If you destroy something, you are a destroyer
If you explore something, you are a explorer
If you manage something, you are a manager
If you offend something, you are a offender
If you receive something, you are a receiver
If you promote something, you are a
2024-07-28 21:58:54 root INFO     [order_1_approx] starting weight calculation for If you receive something, you are a receiver
If you manage something, you are a manager
If you explore something, you are a explorer
If you provide something, you are a provider
If you destroy something, you are a destroyer
If you offend something, you are a offender
If you promote something, you are a promoter
If you eat something, you are a
2024-07-28 21:58:55 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-28 22:01:17 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.3613, -0.2881, -0.0254,  ..., -0.0441, -0.1882,  0.2218],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.0137,  0.0732,  0.1838,  ..., -0.2676, -7.1992, -3.1934],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0331, -0.0069,  0.0079,  ...,  0.0164,  0.0197, -0.0054],
        [ 0.0001,  0.0435, -0.0284,  ..., -0.0131,  0.0150, -0.0321],
        [ 0.0105, -0.0118,  0.0365,  ..., -0.0010, -0.0110,  0.0153],
        ...,
        [ 0.0249,  0.0108,  0.0029,  ...,  0.0300,  0.0043, -0.0203],
        [-0.0051,  0.0151, -0.0202,  ..., -0.0207,  0.0198,  0.0065],
        [ 0.0054, -0.0078,  0.0065,  ..., -0.0022, -0.0128,  0.0250]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.1328,  0.2365, -0.0674,  ...,  0.0955, -7.2773, -3.3652]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 22:01:19 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you receive something, you are a receiver
If you manage something, you are a manager
If you explore something, you are a explorer
If you provide something, you are a provider
If you destroy something, you are a destroyer
If you offend something, you are a offender
If you promote something, you are a promoter
If you eat something, you are a
2024-07-28 22:01:19 root INFO     [order_1_approx] starting weight calculation for If you promote something, you are a promoter
If you receive something, you are a receiver
If you explore something, you are a explorer
If you offend something, you are a offender
If you eat something, you are a eater
If you destroy something, you are a destroyer
If you provide something, you are a provider
If you manage something, you are a
2024-07-28 22:01:19 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-28 22:03:42 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1202,  0.7339, -0.2634,  ...,  0.1500, -0.0410, -0.1227],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.4512, -2.5293,  1.9707,  ..., -1.6279, -4.3672, -4.2344],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0415,  0.0030, -0.0048,  ...,  0.0079, -0.0031,  0.0292],
        [ 0.0046,  0.0367,  0.0046,  ...,  0.0050,  0.0070, -0.0052],
        [ 0.0040, -0.0123,  0.0356,  ..., -0.0112, -0.0026, -0.0047],
        ...,
        [ 0.0149,  0.0202,  0.0190,  ...,  0.0334,  0.0187, -0.0003],
        [-0.0122,  0.0061,  0.0006,  ..., -0.0110,  0.0150, -0.0122],
        [ 0.0030, -0.0050,  0.0127,  ..., -0.0148,  0.0045,  0.0146]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.6562, -2.8672,  1.8047,  ..., -1.2266, -4.6484, -4.4922]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 22:03:43 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you promote something, you are a promoter
If you receive something, you are a receiver
If you explore something, you are a explorer
If you offend something, you are a offender
If you eat something, you are a eater
If you destroy something, you are a destroyer
If you provide something, you are a provider
If you manage something, you are a
2024-07-28 22:03:43 root INFO     [order_1_approx] starting weight calculation for If you manage something, you are a manager
If you provide something, you are a provider
If you explore something, you are a explorer
If you destroy something, you are a destroyer
If you offend something, you are a offender
If you eat something, you are a eater
If you promote something, you are a promoter
If you receive something, you are a
2024-07-28 22:03:43 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-28 22:06:03 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0355,  0.4509, -0.0852,  ..., -0.1185,  0.0388, -0.1663],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.3643,  0.0820, -1.6582,  ..., -2.1875, -4.5547, -2.8555],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0456,  0.0033,  0.0337,  ...,  0.0199,  0.0114,  0.0202],
        [-0.0129,  0.0317,  0.0104,  ...,  0.0228,  0.0013, -0.0078],
        [-0.0007, -0.0078,  0.0193,  ..., -0.0050,  0.0218, -0.0017],
        ...,
        [ 0.0220,  0.0047,  0.0008,  ...,  0.0484,  0.0084,  0.0136],
        [ 0.0013,  0.0036,  0.0082,  ..., -0.0343,  0.0214, -0.0012],
        [-0.0054,  0.0009, -0.0092,  ..., -0.0046, -0.0073,  0.0224]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.8535,  0.3645, -1.5654,  ..., -1.5098, -4.7656, -3.2930]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 22:06:04 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you manage something, you are a manager
If you provide something, you are a provider
If you explore something, you are a explorer
If you destroy something, you are a destroyer
If you offend something, you are a offender
If you eat something, you are a eater
If you promote something, you are a promoter
If you receive something, you are a
2024-07-28 22:06:05 root INFO     [order_1_approx] starting weight calculation for If you receive something, you are a receiver
If you provide something, you are a provider
If you destroy something, you are a destroyer
If you manage something, you are a manager
If you offend something, you are a offender
If you promote something, you are a promoter
If you eat something, you are a eater
If you explore something, you are a
2024-07-28 22:06:05 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-28 22:08:23 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.3181,  0.3447, -0.0093,  ...,  0.0671, -0.0746, -0.0702],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.2012, -1.1035,  0.4238,  ..., -1.7314, -5.4766, -3.2324],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 5.3253e-02, -1.3222e-02,  1.6117e-04,  ...,  1.2299e-02,
          1.4847e-02, -1.3084e-03],
        [ 6.3896e-04,  4.3488e-02,  1.6098e-02,  ..., -2.5101e-03,
         -6.0921e-03, -3.9139e-03],
        [ 6.7520e-03, -9.0790e-03,  2.6413e-02,  ...,  5.0507e-03,
         -1.7288e-02,  4.2725e-03],
        ...,
        [ 2.4597e-02,  2.3376e-02, -7.4348e-03,  ...,  3.8483e-02,
          1.1986e-02, -3.5419e-03],
        [-8.1100e-03,  6.9046e-03, -3.5725e-03,  ..., -9.2468e-03,
          2.4826e-02,  9.4528e-03],
        [ 3.1967e-03,  2.6855e-03,  8.8043e-03,  ..., -9.7275e-05,
         -1.4915e-02,  2.2675e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.5410, -1.3115,  0.5542,  ..., -1.3281, -5.6016, -3.3789]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 22:08:24 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you receive something, you are a receiver
If you provide something, you are a provider
If you destroy something, you are a destroyer
If you manage something, you are a manager
If you offend something, you are a offender
If you promote something, you are a promoter
If you eat something, you are a eater
If you explore something, you are a
2024-07-28 22:08:25 root INFO     [order_1_approx] starting weight calculation for If you receive something, you are a receiver
If you offend something, you are a offender
If you promote something, you are a promoter
If you destroy something, you are a destroyer
If you explore something, you are a explorer
If you eat something, you are a eater
If you manage something, you are a manager
If you provide something, you are a
2024-07-28 22:08:25 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-28 22:10:43 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1475,  0.2170, -0.3069,  ...,  0.1742, -0.0887, -0.0137],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.8906, -5.8906,  0.9072,  ...,  1.0820, -5.3320, -1.8691],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0703,  0.0078,  0.0186,  ...,  0.0189,  0.0049,  0.0239],
        [-0.0214,  0.0284,  0.0066,  ...,  0.0100,  0.0028,  0.0075],
        [ 0.0009, -0.0057,  0.0333,  ..., -0.0106, -0.0044,  0.0168],
        ...,
        [ 0.0056,  0.0035,  0.0136,  ...,  0.0184,  0.0290,  0.0105],
        [ 0.0049, -0.0127, -0.0165,  ..., -0.0142,  0.0351, -0.0185],
        [ 0.0046,  0.0075,  0.0030,  ..., -0.0074, -0.0209,  0.0280]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.0938, -5.8594,  0.7202,  ...,  1.1387, -5.3711, -2.5098]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 22:10:44 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you receive something, you are a receiver
If you offend something, you are a offender
If you promote something, you are a promoter
If you destroy something, you are a destroyer
If you explore something, you are a explorer
If you eat something, you are a eater
If you manage something, you are a manager
If you provide something, you are a
2024-07-28 22:10:44 root INFO     [order_1_approx] starting weight calculation for If you provide something, you are a provider
If you promote something, you are a promoter
If you eat something, you are a eater
If you receive something, you are a receiver
If you destroy something, you are a destroyer
If you explore something, you are a explorer
If you manage something, you are a manager
If you offend something, you are a
2024-07-28 22:10:44 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-28 22:13:04 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0647,  0.3345, -0.3682,  ...,  0.5947, -0.2318,  0.0355],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.2227, -2.5430,  0.8838,  ..., -1.4619, -3.4102, -0.2344],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0663,  0.0034,  0.0203,  ...,  0.0257, -0.0052,  0.0217],
        [ 0.0153,  0.0487,  0.0259,  ..., -0.0077,  0.0041,  0.0099],
        [ 0.0094, -0.0030,  0.0338,  ...,  0.0158,  0.0073,  0.0179],
        ...,
        [ 0.0245,  0.0063, -0.0161,  ...,  0.0439,  0.0339, -0.0020],
        [ 0.0021,  0.0076,  0.0219,  ..., -0.0144,  0.0562,  0.0056],
        [-0.0047,  0.0135, -0.0197,  ..., -0.0011, -0.0076,  0.0426]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.2305, -2.9980,  0.9321,  ..., -1.0195, -3.4316, -0.1849]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 22:13:05 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you provide something, you are a provider
If you promote something, you are a promoter
If you eat something, you are a eater
If you receive something, you are a receiver
If you destroy something, you are a destroyer
If you explore something, you are a explorer
If you manage something, you are a manager
If you offend something, you are a
2024-07-28 22:13:05 root INFO     total operator prediction time: 1139.1806256771088 seconds
2024-07-28 22:13:05 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on adj - superlative
2024-07-28 22:13:05 root INFO     building operator adj - superlative
2024-07-28 22:13:05 root INFO     [order_1_approx] starting weight calculation for If something is the most nice, it is nicest
If something is the most cute, it is cutest
If something is the most nasty, it is nastiest
If something is the most sad, it is saddest
If something is the most lazy, it is laziest
If something is the most hungry, it is hungriest
If something is the most lucky, it is luckiest
If something is the most scary, it is
2024-07-28 22:13:05 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-28 22:15:28 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0693,  0.0984, -0.3625,  ...,  0.0956, -0.4180,  0.1057],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.9844, -3.6387, -1.7266,  ..., -2.1250, -0.9463, -1.8252],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0371, -0.0177,  0.0260,  ...,  0.0325,  0.0066,  0.0156],
        [ 0.0233,  0.0207,  0.0147,  ..., -0.0012,  0.0089,  0.0009],
        [-0.0057,  0.0062,  0.0050,  ..., -0.0034, -0.0161,  0.0048],
        ...,
        [ 0.0211,  0.0313, -0.0089,  ...,  0.0210,  0.0147,  0.0151],
        [-0.0041, -0.0075,  0.0104,  ..., -0.0053,  0.0043, -0.0144],
        [ 0.0057,  0.0034,  0.0149,  ...,  0.0151, -0.0087,  0.0040]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-2.0566, -4.1289, -1.7236,  ..., -1.9824, -0.9199, -1.9795]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 22:15:30 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is the most nice, it is nicest
If something is the most cute, it is cutest
If something is the most nasty, it is nastiest
If something is the most sad, it is saddest
If something is the most lazy, it is laziest
If something is the most hungry, it is hungriest
If something is the most lucky, it is luckiest
If something is the most scary, it is
2024-07-28 22:15:30 root INFO     [order_1_approx] starting weight calculation for If something is the most cute, it is cutest
If something is the most lazy, it is laziest
If something is the most sad, it is saddest
If something is the most lucky, it is luckiest
If something is the most nice, it is nicest
If something is the most hungry, it is hungriest
If something is the most scary, it is scariest
If something is the most nasty, it is
2024-07-28 22:15:30 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-28 22:17:57 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1422, -0.0695, -0.2327,  ..., -0.0916, -0.2490, -0.2410],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.9976, -5.7109, -3.5684,  ..., -3.8379, -2.1113, -0.3066],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 1.8402e-02,  3.0365e-03,  9.2392e-03,  ..., -1.7059e-02,
         -2.9087e-03,  5.2872e-03],
        [ 4.9324e-03,  3.6392e-03,  5.5733e-03,  ..., -7.3128e-03,
          2.0203e-02,  1.2115e-02],
        [ 1.2230e-02,  1.1536e-02,  4.5090e-03,  ...,  1.0452e-03,
         -3.3016e-03,  8.5602e-03],
        ...,
        [ 2.1729e-02,  1.0406e-02,  6.2466e-05,  ...,  2.4155e-02,
          8.1177e-03,  1.0849e-02],
        [ 1.4259e-02,  6.5231e-04, -7.7744e-03,  ...,  8.4229e-03,
          8.0490e-03, -2.8610e-04],
        [-4.7493e-03, -2.5806e-03, -5.3864e-03,  ..., -3.0727e-03,
         -6.0577e-03,  2.6703e-04]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.2080, -5.6133, -3.2324,  ..., -3.7949, -1.9248, -0.2043]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 22:17:58 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is the most cute, it is cutest
If something is the most lazy, it is laziest
If something is the most sad, it is saddest
If something is the most lucky, it is luckiest
If something is the most nice, it is nicest
If something is the most hungry, it is hungriest
If something is the most scary, it is scariest
If something is the most nasty, it is
2024-07-28 22:17:58 root INFO     [order_1_approx] starting weight calculation for If something is the most scary, it is scariest
If something is the most nasty, it is nastiest
If something is the most lucky, it is luckiest
If something is the most hungry, it is hungriest
If something is the most sad, it is saddest
If something is the most nice, it is nicest
If something is the most cute, it is cutest
If something is the most lazy, it is
2024-07-28 22:17:58 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-28 22:20:22 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0983, -0.0945, -0.3137,  ..., -0.2231, -0.2908,  0.3569],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-2.1836, -4.4844, -1.2148,  ..., -2.2383, -0.9336, -2.0605],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0428, -0.0096,  0.0193,  ...,  0.0160,  0.0126,  0.0097],
        [ 0.0070,  0.0273,  0.0105,  ..., -0.0047,  0.0102,  0.0066],
        [ 0.0052, -0.0053,  0.0345,  ..., -0.0063, -0.0208, -0.0006],
        ...,
        [ 0.0083,  0.0233,  0.0080,  ...,  0.0343,  0.0135,  0.0083],
        [ 0.0043,  0.0051, -0.0016,  ..., -0.0021,  0.0201, -0.0311],
        [ 0.0103, -0.0101,  0.0114,  ..., -0.0225, -0.0069,  0.0114]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-2.0977, -4.4102, -1.6211,  ..., -1.8926, -1.0820, -1.9111]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 22:20:23 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is the most scary, it is scariest
If something is the most nasty, it is nastiest
If something is the most lucky, it is luckiest
If something is the most hungry, it is hungriest
If something is the most sad, it is saddest
If something is the most nice, it is nicest
If something is the most cute, it is cutest
If something is the most lazy, it is
2024-07-28 22:20:23 root INFO     [order_1_approx] starting weight calculation for If something is the most scary, it is scariest
If something is the most nice, it is nicest
If something is the most sad, it is saddest
If something is the most nasty, it is nastiest
If something is the most cute, it is cutest
If something is the most lazy, it is laziest
If something is the most hungry, it is hungriest
If something is the most lucky, it is
2024-07-28 22:20:23 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-28 22:22:48 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0215,  0.0585, -0.2915,  ..., -0.2771, -0.2930,  0.0548],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.5244, -2.8672, -3.0547,  ..., -0.0439, -0.9419, -1.4355],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0331, -0.0073,  0.0146,  ...,  0.0009, -0.0085,  0.0102],
        [ 0.0092,  0.0224,  0.0161,  ...,  0.0126,  0.0076, -0.0062],
        [ 0.0113, -0.0058,  0.0224,  ...,  0.0059, -0.0120,  0.0098],
        ...,
        [ 0.0157,  0.0152,  0.0134,  ...,  0.0168,  0.0008,  0.0100],
        [-0.0019,  0.0051,  0.0027,  ..., -0.0072,  0.0109, -0.0165],
        [ 0.0032, -0.0021, -0.0003,  ...,  0.0062,  0.0003,  0.0052]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.6040, -2.7559, -3.0215,  ..., -0.0953, -0.9941, -1.3496]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 22:22:49 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is the most scary, it is scariest
If something is the most nice, it is nicest
If something is the most sad, it is saddest
If something is the most nasty, it is nastiest
If something is the most cute, it is cutest
If something is the most lazy, it is laziest
If something is the most hungry, it is hungriest
If something is the most lucky, it is
2024-07-28 22:22:50 root INFO     [order_1_approx] starting weight calculation for If something is the most nice, it is nicest
If something is the most nasty, it is nastiest
If something is the most lucky, it is luckiest
If something is the most cute, it is cutest
If something is the most lazy, it is laziest
If something is the most hungry, it is hungriest
If something is the most scary, it is scariest
If something is the most sad, it is
2024-07-28 22:22:50 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-28 22:25:09 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1442, -0.0369, -0.2061,  ...,  0.0386, -0.5176,  0.4241],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.0547, -5.1562, -2.6191,  ..., -4.3516,  0.6064, -2.5488],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 8.2626e-03, -2.7580e-03, -2.4834e-03,  ..., -1.5411e-03,
          1.9073e-04,  1.9665e-03],
        [ 1.5366e-02,  2.3651e-03,  2.0599e-02,  ...,  1.6785e-04,
          1.9119e-02, -1.9493e-03],
        [-5.6534e-03,  4.1199e-03,  5.1613e-03,  ...,  1.5049e-03,
         -1.2260e-02, -1.0414e-03],
        ...,
        [ 7.0457e-03,  1.7014e-02, -9.5215e-03,  ...,  1.7731e-02,
          1.0490e-02,  3.2257e-02],
        [ 2.0256e-03, -1.8196e-03,  1.8448e-02,  ...,  7.4234e-03,
          1.5350e-02, -2.0584e-02],
        [-3.1967e-03, -1.1688e-02, -1.1635e-04,  ..., -1.0498e-02,
          9.9182e-05,  1.2131e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.0383, -5.2070, -2.5723,  ..., -4.0820,  0.6035, -2.1445]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 22:25:10 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is the most nice, it is nicest
If something is the most nasty, it is nastiest
If something is the most lucky, it is luckiest
If something is the most cute, it is cutest
If something is the most lazy, it is laziest
If something is the most hungry, it is hungriest
If something is the most scary, it is scariest
If something is the most sad, it is
2024-07-28 22:25:11 root INFO     [order_1_approx] starting weight calculation for If something is the most lucky, it is luckiest
If something is the most sad, it is saddest
If something is the most scary, it is scariest
If something is the most nasty, it is nastiest
If something is the most hungry, it is hungriest
If something is the most cute, it is cutest
If something is the most lazy, it is laziest
If something is the most nice, it is
2024-07-28 22:25:11 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-28 22:27:30 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1523, -0.1057, -0.2603,  ..., -0.0129, -0.4536, -0.2532],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.3032, -0.6323, -4.1953,  ...,  0.5000, -3.5352, -0.7480],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0129, -0.0254,  0.0196,  ..., -0.0038,  0.0099,  0.0275],
        [ 0.0056,  0.0228,  0.0003,  ...,  0.0049,  0.0149, -0.0090],
        [ 0.0140, -0.0331,  0.0131,  ...,  0.0018, -0.0191,  0.0058],
        ...,
        [ 0.0155,  0.0289,  0.0088,  ...,  0.0373,  0.0097, -0.0072],
        [-0.0040, -0.0002,  0.0062,  ...,  0.0139,  0.0236, -0.0161],
        [-0.0125, -0.0199,  0.0155,  ...,  0.0114, -0.0161,  0.0192]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.4480, -0.7578, -4.5781,  ...,  0.7065, -3.4863, -1.0127]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 22:27:31 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is the most lucky, it is luckiest
If something is the most sad, it is saddest
If something is the most scary, it is scariest
If something is the most nasty, it is nastiest
If something is the most hungry, it is hungriest
If something is the most cute, it is cutest
If something is the most lazy, it is laziest
If something is the most nice, it is
2024-07-28 22:27:31 root INFO     [order_1_approx] starting weight calculation for If something is the most nasty, it is nastiest
If something is the most lucky, it is luckiest
If something is the most cute, it is cutest
If something is the most sad, it is saddest
If something is the most scary, it is scariest
If something is the most nice, it is nicest
If something is the most lazy, it is laziest
If something is the most hungry, it is
2024-07-28 22:27:31 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-28 22:29:55 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0259, -0.3425, -0.3638,  ..., -0.1514, -0.4065,  0.3638],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.2388, -4.5625,  0.4180,  ..., -2.0703, -3.6191, -1.2344],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0253, -0.0015,  0.0188,  ..., -0.0039,  0.0007,  0.0030],
        [-0.0032,  0.0289, -0.0081,  ..., -0.0068,  0.0103, -0.0095],
        [ 0.0183,  0.0109,  0.0021,  ...,  0.0043, -0.0008,  0.0060],
        ...,
        [ 0.0270,  0.0053,  0.0055,  ...,  0.0373, -0.0011,  0.0010],
        [ 0.0149,  0.0135, -0.0004,  ...,  0.0066,  0.0294, -0.0141],
        [-0.0012, -0.0141,  0.0099,  ..., -0.0149, -0.0185,  0.0087]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.2040, -4.2109,  0.3503,  ..., -2.0352, -3.5293, -1.0625]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 22:29:56 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is the most nasty, it is nastiest
If something is the most lucky, it is luckiest
If something is the most cute, it is cutest
If something is the most sad, it is saddest
If something is the most scary, it is scariest
If something is the most nice, it is nicest
If something is the most lazy, it is laziest
If something is the most hungry, it is
2024-07-28 22:29:56 root INFO     [order_1_approx] starting weight calculation for If something is the most scary, it is scariest
If something is the most hungry, it is hungriest
If something is the most sad, it is saddest
If something is the most nice, it is nicest
If something is the most lucky, it is luckiest
If something is the most nasty, it is nastiest
If something is the most lazy, it is laziest
If something is the most cute, it is
2024-07-28 22:29:56 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-28 22:32:18 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0758, -0.0873,  0.2092,  ..., -0.3965, -0.6626,  0.2002],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.9102, -1.7822, -1.0869,  ..., -0.7666, -0.4258,  1.9590],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0273, -0.0147,  0.0078,  ..., -0.0092, -0.0047,  0.0227],
        [-0.0053,  0.0489, -0.0021,  ...,  0.0190,  0.0065,  0.0115],
        [ 0.0108,  0.0086,  0.0151,  ..., -0.0026, -0.0222,  0.0029],
        ...,
        [ 0.0018,  0.0295,  0.0255,  ...,  0.0513,  0.0249, -0.0067],
        [ 0.0297, -0.0116,  0.0055,  ..., -0.0333,  0.0086, -0.0088],
        [-0.0071, -0.0137,  0.0110,  ...,  0.0009, -0.0064,  0.0303]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-2.0430, -2.2422, -1.2305,  ..., -0.8169, -0.2019,  1.6631]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 22:32:19 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is the most scary, it is scariest
If something is the most hungry, it is hungriest
If something is the most sad, it is saddest
If something is the most nice, it is nicest
If something is the most lucky, it is luckiest
If something is the most nasty, it is nastiest
If something is the most lazy, it is laziest
If something is the most cute, it is
2024-07-28 22:32:19 root INFO     total operator prediction time: 1154.0828006267548 seconds
2024-07-28 22:32:19 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on verb_3pSg - Ved
2024-07-28 22:32:19 root INFO     building operator verb_3pSg - Ved
2024-07-28 22:32:19 root INFO     [order_1_approx] starting weight calculation for When he sends something, something has been sent
When he relates something, something has been related
When he spends something, something has been spent
When he manages something, something has been managed
When he replaces something, something has been replaced
When he happens something, something has been happened
When he occurs something, something has been occurred
When he expects something, something has been
2024-07-28 22:32:19 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-28 22:34:36 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1089,  0.2356, -0.2327,  ..., -0.4065, -0.0471, -0.3027],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.1484,  0.5947, -2.0605,  ..., -0.4451, -2.6719, -1.7656],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 3.4149e-02, -5.3406e-04,  8.7357e-03,  ..., -6.0177e-04,
         -2.1744e-04,  1.6800e-02],
        [ 1.6861e-03,  4.3549e-02,  1.8448e-02,  ..., -6.9771e-03,
          5.3711e-03,  2.9564e-03],
        [ 1.2169e-02, -8.7929e-04,  7.6218e-03,  ..., -8.7433e-03,
         -3.6926e-03, -2.1332e-02],
        ...,
        [ 4.5395e-03,  1.9470e-02,  1.6384e-03,  ...,  1.8890e-02,
          1.5106e-02, -4.4727e-04],
        [ 1.2268e-02,  7.3700e-03, -1.5152e-02,  ...,  1.9104e-02,
          2.6306e-02, -2.6169e-02],
        [-2.0905e-03,  4.1962e-05,  2.9617e-02,  ...,  1.0719e-02,
         -2.5177e-04, -1.8559e-03]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.4062,  0.7451, -1.9873,  ..., -0.2717, -2.6309, -1.8633]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 22:34:37 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When he sends something, something has been sent
When he relates something, something has been related
When he spends something, something has been spent
When he manages something, something has been managed
When he replaces something, something has been replaced
When he happens something, something has been happened
When he occurs something, something has been occurred
When he expects something, something has been
2024-07-28 22:34:38 root INFO     [order_1_approx] starting weight calculation for When he replaces something, something has been replaced
When he happens something, something has been happened
When he occurs something, something has been occurred
When he expects something, something has been expected
When he relates something, something has been related
When he sends something, something has been sent
When he spends something, something has been spent
When he manages something, something has been
2024-07-28 22:34:38 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-28 22:36:58 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1641,  0.6504, -0.2585,  ..., -0.1250, -0.3677,  0.0197],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.2969, -1.0781,  1.9658,  ..., -0.3359, -1.1230, -2.5312],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 2.3529e-02,  8.7891e-03, -1.0468e-02,  ..., -1.2672e-02,
         -8.0109e-03,  2.3895e-02],
        [ 6.4087e-04,  1.8753e-02,  2.4902e-02,  ...,  2.0660e-02,
          5.2948e-03,  2.2095e-02],
        [-7.0572e-05,  6.2275e-04,  1.3031e-02,  ...,  1.3342e-03,
         -7.5340e-03, -1.2589e-02],
        ...,
        [ 5.3940e-03,  8.8425e-03,  5.1880e-03,  ...,  2.0584e-02,
         -2.3003e-03,  1.0063e-02],
        [ 7.5722e-04,  6.0158e-03, -2.0390e-03,  ..., -4.1275e-03,
          1.8005e-02, -1.8600e-02],
        [ 5.4550e-04, -4.3716e-03,  1.3077e-02,  ..., -4.8828e-03,
          7.4539e-03, -1.5030e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.3359, -1.3242,  1.6084,  ..., -0.1624, -1.2324, -2.4043]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 22:36:59 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When he replaces something, something has been replaced
When he happens something, something has been happened
When he occurs something, something has been occurred
When he expects something, something has been expected
When he relates something, something has been related
When he sends something, something has been sent
When he spends something, something has been spent
When he manages something, something has been
2024-07-28 22:36:59 root INFO     [order_1_approx] starting weight calculation for When he spends something, something has been spent
When he expects something, something has been expected
When he relates something, something has been related
When he sends something, something has been sent
When he replaces something, something has been replaced
When he happens something, something has been happened
When he manages something, something has been managed
When he occurs something, something has been
2024-07-28 22:36:59 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-28 22:39:20 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.4238,  0.0356, -0.4600,  ..., -0.3181, -0.2051, -0.6562],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.3711,  1.3535,  1.4121,  ..., -0.3574, -0.8076,  1.2969],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0124,  0.0099,  0.0293,  ...,  0.0153,  0.0034,  0.0191],
        [ 0.0010,  0.0416,  0.0156,  ...,  0.0143,  0.0091, -0.0107],
        [ 0.0297, -0.0064,  0.0079,  ..., -0.0287, -0.0009, -0.0130],
        ...,
        [ 0.0063,  0.0157,  0.0202,  ...,  0.0287,  0.0022,  0.0260],
        [-0.0052, -0.0065, -0.0190,  ..., -0.0050,  0.0245, -0.0009],
        [ 0.0163, -0.0071,  0.0279,  ...,  0.0036,  0.0100,  0.0245]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.3066,  1.4443,  1.7949,  ..., -0.2729, -0.7285,  1.7402]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 22:39:21 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When he spends something, something has been spent
When he expects something, something has been expected
When he relates something, something has been related
When he sends something, something has been sent
When he replaces something, something has been replaced
When he happens something, something has been happened
When he manages something, something has been managed
When he occurs something, something has been
2024-07-28 22:39:21 root INFO     [order_1_approx] starting weight calculation for When he expects something, something has been expected
When he occurs something, something has been occurred
When he relates something, something has been related
When he manages something, something has been managed
When he replaces something, something has been replaced
When he spends something, something has been spent
When he sends something, something has been sent
When he happens something, something has been
2024-07-28 22:39:21 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-28 22:41:43 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2229, -0.0697, -0.5479,  ..., -0.1737, -0.2544, -0.4636],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.3281,  0.7788,  1.9160,  ...,  0.7646, -3.7031,  1.0020],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0214,  0.0033,  0.0036,  ..., -0.0090, -0.0168,  0.0188],
        [-0.0074,  0.0340,  0.0192,  ...,  0.0084,  0.0157, -0.0141],
        [ 0.0168,  0.0073,  0.0046,  ..., -0.0005, -0.0039,  0.0042],
        ...,
        [ 0.0205,  0.0123, -0.0131,  ...,  0.0141,  0.0115,  0.0149],
        [ 0.0015,  0.0006, -0.0008,  ...,  0.0071,  0.0037, -0.0257],
        [-0.0123, -0.0074,  0.0225,  ...,  0.0011,  0.0086,  0.0031]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.2109,  0.7852,  2.0000,  ...,  0.7744, -3.3418,  0.9395]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 22:41:44 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When he expects something, something has been expected
When he occurs something, something has been occurred
When he relates something, something has been related
When he manages something, something has been managed
When he replaces something, something has been replaced
When he spends something, something has been spent
When he sends something, something has been sent
When he happens something, something has been
2024-07-28 22:41:44 root INFO     [order_1_approx] starting weight calculation for When he sends something, something has been sent
When he happens something, something has been happened
When he expects something, something has been expected
When he replaces something, something has been replaced
When he spends something, something has been spent
When he occurs something, something has been occurred
When he manages something, something has been managed
When he relates something, something has been
2024-07-28 22:41:44 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-28 22:44:01 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1126,  0.3462, -0.2637,  ...,  0.0349, -0.3438, -0.0775],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.1084,  1.1289,  2.1699,  ...,  1.6074, -2.0215, -0.7637],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 5.7373e-03, -3.3712e-04, -1.3168e-02,  ...,  1.5625e-02,
         -2.2831e-03,  2.1713e-02],
        [-1.8387e-02,  3.8910e-02,  2.8580e-02,  ...,  4.3869e-05,
          1.2497e-02,  4.1733e-03],
        [ 4.3755e-03, -1.0803e-02,  6.5651e-03,  ...,  1.4091e-02,
         -7.4806e-03, -1.5732e-02],
        ...,
        [ 1.1459e-02, -9.8896e-04, -1.4702e-02,  ...,  1.2802e-02,
          7.7171e-03,  2.3956e-02],
        [ 1.0902e-02, -9.5978e-03, -6.8130e-03,  ...,  2.2644e-02,
          1.6785e-02, -2.3636e-02],
        [-1.3107e-02, -1.2901e-02,  1.5060e-02,  ...,  1.7624e-02,
          1.2375e-02,  8.6594e-04]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.4072,  0.8604,  2.2246,  ...,  1.7168, -1.7402, -0.7095]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 22:44:02 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When he sends something, something has been sent
When he happens something, something has been happened
When he expects something, something has been expected
When he replaces something, something has been replaced
When he spends something, something has been spent
When he occurs something, something has been occurred
When he manages something, something has been managed
When he relates something, something has been
2024-07-28 22:44:02 root INFO     [order_1_approx] starting weight calculation for When he happens something, something has been happened
When he manages something, something has been managed
When he occurs something, something has been occurred
When he replaces something, something has been replaced
When he sends something, something has been sent
When he expects something, something has been expected
When he relates something, something has been related
When he spends something, something has been
2024-07-28 22:44:02 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-28 22:46:22 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0540,  0.1211, -0.2209,  ...,  0.0226, -0.3662, -0.2708],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.9688, -0.7935, -1.5811,  ..., -1.4277, -1.9219, -1.0918],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0375,  0.0076, -0.0057,  ..., -0.0126,  0.0073,  0.0116],
        [-0.0123,  0.0352,  0.0029,  ...,  0.0032, -0.0010,  0.0112],
        [-0.0048, -0.0171,  0.0143,  ..., -0.0096, -0.0061, -0.0064],
        ...,
        [ 0.0078,  0.0117,  0.0107,  ...,  0.0283,  0.0048,  0.0269],
        [-0.0020, -0.0029, -0.0172,  ...,  0.0118,  0.0223, -0.0284],
        [-0.0074, -0.0100,  0.0158,  ...,  0.0051, -0.0063,  0.0084]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.8789, -1.0723, -1.5439,  ..., -0.9512, -1.6699, -1.0391]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 22:46:23 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When he happens something, something has been happened
When he manages something, something has been managed
When he occurs something, something has been occurred
When he replaces something, something has been replaced
When he sends something, something has been sent
When he expects something, something has been expected
When he relates something, something has been related
When he spends something, something has been
2024-07-28 22:46:23 root INFO     [order_1_approx] starting weight calculation for When he relates something, something has been related
When he spends something, something has been spent
When he occurs something, something has been occurred
When he happens something, something has been happened
When he manages something, something has been managed
When he replaces something, something has been replaced
When he expects something, something has been expected
When he sends something, something has been
2024-07-28 22:46:23 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-28 22:48:45 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1025,  0.1581,  0.3015,  ...,  0.1654, -0.0345, -0.1005],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.0684, -1.7998, -1.1230,  ..., -1.9053, -0.3762, -2.4570],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0489, -0.0044,  0.0177,  ..., -0.0080,  0.0105,  0.0153],
        [-0.0098,  0.0445,  0.0049,  ..., -0.0054, -0.0025, -0.0017],
        [-0.0012, -0.0251,  0.0046,  ..., -0.0014, -0.0042, -0.0076],
        ...,
        [-0.0044,  0.0128,  0.0096,  ...,  0.0263, -0.0083,  0.0118],
        [-0.0005, -0.0005, -0.0007,  ...,  0.0059,  0.0152, -0.0223],
        [-0.0090, -0.0028,  0.0034,  ...,  0.0149, -0.0086,  0.0076]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.0215, -1.9893, -1.2021,  ..., -1.7031, -0.4202, -2.1484]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 22:48:46 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When he relates something, something has been related
When he spends something, something has been spent
When he occurs something, something has been occurred
When he happens something, something has been happened
When he manages something, something has been managed
When he replaces something, something has been replaced
When he expects something, something has been expected
When he sends something, something has been
2024-07-28 22:48:46 root INFO     [order_1_approx] starting weight calculation for When he spends something, something has been spent
When he occurs something, something has been occurred
When he manages something, something has been managed
When he sends something, something has been sent
When he happens something, something has been happened
When he expects something, something has been expected
When he relates something, something has been related
When he replaces something, something has been
2024-07-28 22:48:46 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-28 22:51:05 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1027, -0.0187, -0.6855,  ...,  0.0751, -0.1076,  0.1455],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.6738, -0.2322, -0.2393,  ..., -0.5547, -0.0742,  0.5801],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0243, -0.0121, -0.0007,  ...,  0.0039, -0.0059,  0.0409],
        [-0.0098,  0.0283,  0.0148,  ...,  0.0133, -0.0138,  0.0168],
        [ 0.0118, -0.0143, -0.0008,  ..., -0.0173,  0.0085, -0.0047],
        ...,
        [ 0.0007,  0.0077, -0.0120,  ...,  0.0189, -0.0023,  0.0269],
        [ 0.0149,  0.0147, -0.0091,  ..., -0.0040,  0.0184, -0.0074],
        [ 0.0072, -0.0057,  0.0239,  ..., -0.0067, -0.0070,  0.0075]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.7383, -0.4517,  0.2075,  ..., -0.2466,  0.1101,  0.7334]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 22:51:06 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When he spends something, something has been spent
When he occurs something, something has been occurred
When he manages something, something has been managed
When he sends something, something has been sent
When he happens something, something has been happened
When he expects something, something has been expected
When he relates something, something has been related
When he replaces something, something has been
2024-07-28 22:51:06 root INFO     total operator prediction time: 1126.6338288784027 seconds
2024-07-28 22:51:06 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on noun - plural_reg
2024-07-28 22:51:06 root INFO     building operator noun - plural_reg
2024-07-28 22:51:06 root INFO     [order_1_approx] starting weight calculation for The plural form of role is roles
The plural form of idea is ideas
The plural form of science is sciences
The plural form of player is players
The plural form of government is governments
The plural form of god is gods
The plural form of death is deaths
The plural form of car is
2024-07-28 22:51:06 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-28 22:53:29 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0591, -0.0748, -0.1820,  ..., -0.0156, -0.2468, -0.0324],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.2715, -4.4766,  1.1562,  ..., -1.9473,  1.4980, -0.2344],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 5.9845e-02,  1.2558e-02,  3.7659e-02,  ..., -1.6632e-02,
         -9.5901e-03,  1.9089e-02],
        [ 9.2239e-03,  3.3234e-02,  1.3412e-02,  ...,  2.6245e-02,
          1.8738e-02, -2.6199e-02],
        [-9.7580e-03,  5.7487e-03,  5.8258e-02,  ..., -2.2064e-02,
         -1.4816e-02,  6.1981e-02],
        ...,
        [-3.0804e-03,  3.2196e-02, -1.0468e-02,  ...,  1.9104e-02,
          1.0574e-02, -7.4158e-03],
        [ 4.1962e-05,  1.4908e-02, -1.3916e-02,  ..., -9.7351e-03,
          3.9185e-02, -2.5116e-02],
        [ 1.3733e-02,  1.2337e-02, -2.5360e-02,  ..., -1.2390e-02,
         -9.6207e-03,  3.7750e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.2090, -4.5039,  1.6035,  ..., -2.0977,  1.2715,  0.2324]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 22:53:30 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of role is roles
The plural form of idea is ideas
The plural form of science is sciences
The plural form of player is players
The plural form of government is governments
The plural form of god is gods
The plural form of death is deaths
The plural form of car is
2024-07-28 22:53:31 root INFO     [order_1_approx] starting weight calculation for The plural form of science is sciences
The plural form of government is governments
The plural form of god is gods
The plural form of role is roles
The plural form of player is players
The plural form of death is deaths
The plural form of car is cars
The plural form of idea is
2024-07-28 22:53:31 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-28 22:55:55 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0164,  0.0869,  0.0288,  ..., -0.3416, -0.3330,  0.1501],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.0176, -3.3242,  2.8711,  ..., -0.6133, -1.5664, -2.4316],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0726, -0.0126,  0.0005,  ...,  0.0019,  0.0008,  0.0259],
        [-0.0057,  0.0303,  0.0327,  ...,  0.0133, -0.0154, -0.0046],
        [-0.0286, -0.0097,  0.0461,  ..., -0.0280, -0.0033,  0.0255],
        ...,
        [ 0.0005,  0.0032, -0.0026,  ...,  0.0463,  0.0211, -0.0273],
        [-0.0170,  0.0184,  0.0048,  ..., -0.0239,  0.0419, -0.0196],
        [ 0.0339,  0.0016,  0.0042,  ...,  0.0118, -0.0050,  0.0488]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.8555, -3.6133,  3.1699,  ..., -0.2639, -1.5400, -2.6523]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 22:55:56 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of science is sciences
The plural form of government is governments
The plural form of god is gods
The plural form of role is roles
The plural form of player is players
The plural form of death is deaths
The plural form of car is cars
The plural form of idea is
2024-07-28 22:55:56 root INFO     [order_1_approx] starting weight calculation for The plural form of player is players
The plural form of car is cars
The plural form of death is deaths
The plural form of idea is ideas
The plural form of science is sciences
The plural form of government is governments
The plural form of god is gods
The plural form of role is
2024-07-28 22:55:56 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-28 22:58:17 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2236,  0.0111, -0.1381,  ..., -0.2329, -0.2756, -0.0623],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.0537, -2.9941,  0.1152,  ..., -2.7715, -0.0879, -4.4688],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0704, -0.0021,  0.0057,  ...,  0.0043,  0.0117, -0.0039],
        [-0.0014,  0.0560,  0.0087,  ...,  0.0146,  0.0067, -0.0236],
        [ 0.0002, -0.0144,  0.0721,  ..., -0.0041, -0.0103,  0.0116],
        ...,
        [ 0.0235,  0.0148, -0.0152,  ...,  0.0640, -0.0150,  0.0047],
        [-0.0214,  0.0207, -0.0185,  ...,  0.0018,  0.0446, -0.0024],
        [ 0.0253,  0.0023, -0.0128,  ..., -0.0049,  0.0030,  0.0602]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.0264, -3.0957,  0.2399,  ..., -2.6719, -0.4043, -4.1719]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 22:58:18 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of player is players
The plural form of car is cars
The plural form of death is deaths
The plural form of idea is ideas
The plural form of science is sciences
The plural form of government is governments
The plural form of god is gods
The plural form of role is
2024-07-28 22:58:18 root INFO     [order_1_approx] starting weight calculation for The plural form of role is roles
The plural form of player is players
The plural form of god is gods
The plural form of idea is ideas
The plural form of car is cars
The plural form of government is governments
The plural form of death is deaths
The plural form of science is
2024-07-28 22:58:18 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-28 23:00:39 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0303, -0.0067, -0.3418,  ..., -0.0621, -0.1938, -0.2852],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.5508, -2.2539,  2.6387,  ..., -0.0381, -1.9941, -2.0977],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 5.8411e-02, -9.7122e-03,  3.2654e-02,  ..., -2.2079e-02,
          1.9287e-02, -4.3716e-03],
        [ 8.0109e-04,  7.5745e-02,  2.9648e-02,  ..., -3.7022e-03,
         -1.8738e-02, -7.7324e-03],
        [-1.3489e-02, -2.6230e-02,  4.8401e-02,  ...,  6.6147e-03,
         -9.5825e-03,  1.7670e-02],
        ...,
        [ 2.4643e-02,  2.3697e-02,  1.0010e-02,  ...,  7.0801e-02,
          1.4465e-02,  8.5297e-03],
        [-9.7275e-05, -2.2545e-03, -4.2877e-03,  ..., -1.2970e-02,
          2.5894e-02, -3.4790e-03],
        [ 8.1787e-03,  1.7136e-02, -2.6016e-02,  ..., -4.3068e-03,
          1.0201e-02,  3.4302e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.9297, -2.4668,  2.9023,  ...,  0.1975, -2.4570, -1.7070]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 23:00:40 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of role is roles
The plural form of player is players
The plural form of god is gods
The plural form of idea is ideas
The plural form of car is cars
The plural form of government is governments
The plural form of death is deaths
The plural form of science is
2024-07-28 23:00:40 root INFO     [order_1_approx] starting weight calculation for The plural form of god is gods
The plural form of government is governments
The plural form of player is players
The plural form of idea is ideas
The plural form of car is cars
The plural form of role is roles
The plural form of science is sciences
The plural form of death is
2024-07-28 23:00:40 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-28 23:03:01 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0756, -0.2068, -0.0739,  ..., -0.1814, -0.2175,  0.2087],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.7207, -3.0742,  1.2373,  ..., -1.2627, -0.7900, -2.8262],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0563, -0.0144,  0.0157,  ...,  0.0053,  0.0146,  0.0215],
        [ 0.0085,  0.0622,  0.0054,  ..., -0.0024, -0.0105, -0.0019],
        [-0.0178,  0.0014,  0.0582,  ..., -0.0075, -0.0153,  0.0358],
        ...,
        [ 0.0059, -0.0017, -0.0030,  ...,  0.0386,  0.0101, -0.0026],
        [-0.0192,  0.0264, -0.0041,  ..., -0.0103,  0.0540, -0.0094],
        [ 0.0022, -0.0065, -0.0010,  ..., -0.0007, -0.0038,  0.0702]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.4453, -2.8066,  1.2158,  ..., -1.0615, -0.8286, -2.7422]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 23:03:02 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of god is gods
The plural form of government is governments
The plural form of player is players
The plural form of idea is ideas
The plural form of car is cars
The plural form of role is roles
The plural form of science is sciences
The plural form of death is
2024-07-28 23:03:02 root INFO     [order_1_approx] starting weight calculation for The plural form of car is cars
The plural form of player is players
The plural form of science is sciences
The plural form of god is gods
The plural form of role is roles
The plural form of death is deaths
The plural form of idea is ideas
The plural form of government is
2024-07-28 23:03:02 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-28 23:05:22 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4275,  0.2089, -0.2245,  ..., -0.3145, -0.4995, -0.0607],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.9785, -2.0938,  0.4097,  ..., -1.5176, -0.8271, -2.8203],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0568,  0.0128,  0.0067,  ...,  0.0151,  0.0021,  0.0133],
        [ 0.0142,  0.0428, -0.0079,  ...,  0.0130,  0.0212,  0.0009],
        [-0.0036,  0.0015,  0.0481,  ...,  0.0002, -0.0055,  0.0127],
        ...,
        [ 0.0126,  0.0004, -0.0147,  ...,  0.0418,  0.0007,  0.0022],
        [-0.0139,  0.0077, -0.0287,  ..., -0.0293,  0.0259,  0.0123],
        [-0.0037,  0.0179, -0.0263,  ..., -0.0053,  0.0049,  0.0400]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.4863, -2.0449,  0.3855,  ..., -1.3291, -0.6572, -2.2617]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 23:05:23 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of car is cars
The plural form of player is players
The plural form of science is sciences
The plural form of god is gods
The plural form of role is roles
The plural form of death is deaths
The plural form of idea is ideas
The plural form of government is
2024-07-28 23:05:23 root INFO     [order_1_approx] starting weight calculation for The plural form of idea is ideas
The plural form of science is sciences
The plural form of player is players
The plural form of government is governments
The plural form of role is roles
The plural form of car is cars
The plural form of death is deaths
The plural form of god is
2024-07-28 23:05:23 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-28 23:07:45 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1328,  0.2202, -0.3271,  ..., -0.0598, -0.2222, -0.0055],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.5391, -3.8867,  0.4600,  ..., -1.4385,  0.4355, -2.4609],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0541, -0.0089,  0.0115,  ...,  0.0326, -0.0053,  0.0150],
        [ 0.0247,  0.0249,  0.0108,  ..., -0.0079,  0.0284,  0.0020],
        [-0.0011, -0.0278,  0.0376,  ...,  0.0088, -0.0032,  0.0310],
        ...,
        [ 0.0172,  0.0218, -0.0352,  ...,  0.0338,  0.0192, -0.0027],
        [-0.0055, -0.0032, -0.0088,  ..., -0.0388, -0.0061, -0.0321],
        [-0.0011,  0.0173, -0.0319,  ..., -0.0021,  0.0054,  0.0411]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.3438, -3.3340,  0.1316,  ..., -1.2666,  0.8047, -2.3027]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 23:07:46 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of idea is ideas
The plural form of science is sciences
The plural form of player is players
The plural form of government is governments
The plural form of role is roles
The plural form of car is cars
The plural form of death is deaths
The plural form of god is
2024-07-28 23:07:46 root INFO     [order_1_approx] starting weight calculation for The plural form of science is sciences
The plural form of god is gods
The plural form of death is deaths
The plural form of car is cars
The plural form of role is roles
The plural form of idea is ideas
The plural form of government is governments
The plural form of player is
2024-07-28 23:07:46 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-28 23:10:09 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3210,  0.1015, -0.0065,  ..., -0.1733, -0.2966, -0.0754],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.7363, -5.4922,  0.6348,  ..., -0.6436, -1.8809, -2.1074],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 7.8552e-02, -1.0071e-02,  1.6800e-02,  ...,  5.9662e-03,
          1.9150e-02,  2.6230e-02],
        [ 5.0621e-03,  7.0435e-02, -1.6403e-02,  ..., -5.7526e-03,
          7.0496e-03,  1.5621e-03],
        [-2.1423e-02, -2.0409e-03,  5.3833e-02,  ..., -1.2726e-02,
         -7.2098e-03, -3.8147e-06],
        ...,
        [-2.6970e-03,  2.9846e-02, -8.2855e-03,  ...,  5.7098e-02,
          1.9577e-02,  1.1192e-02],
        [-2.3682e-02,  1.8814e-02, -1.9836e-03,  ..., -1.0803e-02,
          4.7760e-02, -1.7532e-02],
        [ 1.1223e-02,  2.2797e-02, -1.2695e-02,  ..., -3.1090e-03,
          1.4519e-02,  2.8763e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.8887, -5.3750,  1.0361,  ..., -0.9297, -1.6357, -1.6641]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 23:10:13 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of science is sciences
The plural form of god is gods
The plural form of death is deaths
The plural form of car is cars
The plural form of role is roles
The plural form of idea is ideas
The plural form of government is governments
The plural form of player is
2024-07-28 23:10:13 root INFO     total operator prediction time: 1147.303055524826 seconds
2024-07-28 23:10:13 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on verb_Ving - 3pSg
2024-07-28 23:10:13 root INFO     building operator verb_Ving - 3pSg
2024-07-28 23:10:14 root INFO     [order_1_approx] starting weight calculation for When something is happening, it happens
When something is relating, it relates
When something is discovering, it discovers
When something is spending, it spends
When something is remaining, it remains
When something is representing, it represents
When something is learning, it learns
When something is reducing, it
2024-07-28 23:10:14 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-28 23:12:37 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0127, -0.1214, -0.3999,  ..., -0.1658,  0.2191, -0.1982],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.2681, -2.3750, -0.6426,  ..., -2.7520, -5.6211, -3.2539],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0493,  0.0021, -0.0014,  ...,  0.0223,  0.0050,  0.0195],
        [-0.0203,  0.0276,  0.0058,  ...,  0.0134,  0.0037,  0.0275],
        [ 0.0112,  0.0031,  0.0431,  ..., -0.0095, -0.0114, -0.0072],
        ...,
        [ 0.0229, -0.0034,  0.0019,  ...,  0.0213,  0.0059,  0.0143],
        [ 0.0083,  0.0097, -0.0167,  ..., -0.0159,  0.0307, -0.0338],
        [ 0.0016, -0.0026,  0.0234,  ..., -0.0026,  0.0018,  0.0066]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.5986, -2.4238, -0.8457,  ..., -2.5000, -5.8477, -3.0527]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 23:12:38 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When something is happening, it happens
When something is relating, it relates
When something is discovering, it discovers
When something is spending, it spends
When something is remaining, it remains
When something is representing, it represents
When something is learning, it learns
When something is reducing, it
2024-07-28 23:12:38 root INFO     [order_1_approx] starting weight calculation for When something is relating, it relates
When something is spending, it spends
When something is discovering, it discovers
When something is representing, it represents
When something is happening, it happens
When something is learning, it learns
When something is reducing, it reduces
When something is remaining, it
2024-07-28 23:12:38 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-28 23:14:59 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0869,  0.1479, -0.2866,  ..., -0.5547, -0.0228,  0.2012],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.4941, -3.4121, -0.7559,  ..., -2.8984, -1.7324, -1.0791],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0357, -0.0020, -0.0038,  ...,  0.0076, -0.0034,  0.0232],
        [-0.0018,  0.0448,  0.0083,  ...,  0.0092,  0.0193,  0.0160],
        [-0.0065, -0.0067,  0.0432,  ..., -0.0055, -0.0005, -0.0113],
        ...,
        [ 0.0128,  0.0097, -0.0169,  ...,  0.0269, -0.0092,  0.0244],
        [ 0.0091,  0.0174,  0.0206,  ..., -0.0134,  0.0254, -0.0264],
        [-0.0190, -0.0033,  0.0178,  ..., -0.0107, -0.0102, -0.0078]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.6660, -3.5312, -0.7617,  ..., -2.8535, -2.0117, -1.2686]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 23:15:01 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When something is relating, it relates
When something is spending, it spends
When something is discovering, it discovers
When something is representing, it represents
When something is happening, it happens
When something is learning, it learns
When something is reducing, it reduces
When something is remaining, it
2024-07-28 23:15:01 root INFO     [order_1_approx] starting weight calculation for When something is relating, it relates
When something is reducing, it reduces
When something is remaining, it remains
When something is happening, it happens
When something is spending, it spends
When something is learning, it learns
When something is representing, it represents
When something is discovering, it
2024-07-28 23:15:01 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-28 23:17:20 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3931,  0.0453, -0.0776,  ..., -0.1255, -0.3506, -0.0176],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.1387, -3.9102,  1.6396,  ..., -0.6431, -5.1094,  1.4531],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 2.3041e-02,  1.2299e-02,  1.2756e-02,  ...,  1.6388e-02,
         -1.8845e-03,  3.8452e-03],
        [-6.1035e-05,  2.5314e-02,  1.3161e-04,  ..., -4.2953e-03,
         -7.3853e-03,  1.4328e-02],
        [ 6.7596e-03, -1.6037e-02,  2.3346e-02,  ..., -7.0190e-03,
          1.1253e-02, -1.0902e-02],
        ...,
        [ 7.9803e-03,  6.9084e-03,  8.1062e-05,  ...,  1.0658e-02,
         -5.3291e-03,  8.1787e-03],
        [ 1.5182e-02, -4.4136e-03, -7.9422e-03,  ..., -1.1902e-02,
          1.7975e-02, -2.0630e-02],
        [ 6.4850e-04, -7.1983e-03,  2.6093e-02,  ..., -4.6539e-04,
         -9.6130e-03,  5.9547e-03]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.8086, -3.6348,  1.4668,  ..., -0.3127, -5.3320,  1.2510]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 23:17:21 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When something is relating, it relates
When something is reducing, it reduces
When something is remaining, it remains
When something is happening, it happens
When something is spending, it spends
When something is learning, it learns
When something is representing, it represents
When something is discovering, it
2024-07-28 23:17:21 root INFO     [order_1_approx] starting weight calculation for When something is relating, it relates
When something is remaining, it remains
When something is representing, it represents
When something is reducing, it reduces
When something is spending, it spends
When something is learning, it learns
When something is discovering, it discovers
When something is happening, it
2024-07-28 23:17:21 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-28 23:19:42 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0174, -0.0589, -0.1019,  ...,  0.1796, -0.0296, -0.4741],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.8359, -2.9473,  0.1777,  ...,  0.0801, -6.0508, -0.2832],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0574, -0.0080, -0.0095,  ...,  0.0172, -0.0133,  0.0107],
        [-0.0046,  0.0361,  0.0033,  ...,  0.0038, -0.0012,  0.0064],
        [-0.0002,  0.0090,  0.0199,  ...,  0.0035, -0.0053, -0.0077],
        ...,
        [ 0.0323,  0.0059, -0.0209,  ...,  0.0399, -0.0068, -0.0069],
        [ 0.0109,  0.0151, -0.0048,  ..., -0.0140,  0.0197, -0.0182],
        [-0.0111, -0.0124,  0.0167,  ..., -0.0009, -0.0058,  0.0192]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.8242, -3.1309,  0.0936,  ...,  0.0245, -5.9688, -0.2844]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 23:19:43 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When something is relating, it relates
When something is remaining, it remains
When something is representing, it represents
When something is reducing, it reduces
When something is spending, it spends
When something is learning, it learns
When something is discovering, it discovers
When something is happening, it
2024-07-28 23:19:43 root INFO     [order_1_approx] starting weight calculation for When something is happening, it happens
When something is relating, it relates
When something is learning, it learns
When something is discovering, it discovers
When something is representing, it represents
When something is remaining, it remains
When something is reducing, it reduces
When something is spending, it
2024-07-28 23:19:43 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-28 23:22:04 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2400,  0.3125, -0.0161,  ...,  0.0511, -0.2311, -0.0846],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.7969, -1.2344, -3.9277,  ..., -1.2402, -5.9141, -1.9961],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0304,  0.0118, -0.0084,  ...,  0.0039,  0.0024,  0.0096],
        [-0.0191,  0.0099, -0.0119,  ..., -0.0009,  0.0039,  0.0078],
        [ 0.0067,  0.0066,  0.0113,  ..., -0.0098, -0.0064, -0.0169],
        ...,
        [ 0.0053,  0.0043,  0.0145,  ...,  0.0289, -0.0044,  0.0054],
        [ 0.0048,  0.0182, -0.0027,  ..., -0.0177,  0.0112, -0.0213],
        [-0.0118, -0.0005,  0.0098,  ..., -0.0009, -0.0070,  0.0091]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.3145, -1.0635, -3.7285,  ..., -1.2881, -5.9922, -2.1875]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 23:22:05 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When something is happening, it happens
When something is relating, it relates
When something is learning, it learns
When something is discovering, it discovers
When something is representing, it represents
When something is remaining, it remains
When something is reducing, it reduces
When something is spending, it
2024-07-28 23:22:05 root INFO     [order_1_approx] starting weight calculation for When something is learning, it learns
When something is discovering, it discovers
When something is representing, it represents
When something is spending, it spends
When something is reducing, it reduces
When something is happening, it happens
When something is remaining, it remains
When something is relating, it
2024-07-28 23:22:05 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-28 23:24:23 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1114,  0.1379, -0.4771,  ...,  0.1833, -0.4927, -0.2405],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.2905, -2.6172,  1.2305,  ...,  0.9824, -6.8750,  1.9277],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0396,  0.0006, -0.0012,  ...,  0.0120, -0.0157,  0.0154],
        [-0.0275,  0.0612,  0.0305,  ...,  0.0005,  0.0073, -0.0003],
        [-0.0052,  0.0145,  0.0419,  ...,  0.0091, -0.0070, -0.0117],
        ...,
        [ 0.0166, -0.0073, -0.0075,  ...,  0.0339,  0.0097,  0.0172],
        [ 0.0173,  0.0153, -0.0203,  ..., -0.0193,  0.0307, -0.0517],
        [-0.0181, -0.0064,  0.0259,  ...,  0.0126,  0.0166,  0.0246]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.4587, -2.8398,  1.0645,  ...,  1.1484, -6.5312,  1.8984]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 23:24:24 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When something is learning, it learns
When something is discovering, it discovers
When something is representing, it represents
When something is spending, it spends
When something is reducing, it reduces
When something is happening, it happens
When something is remaining, it remains
When something is relating, it
2024-07-28 23:24:24 root INFO     [order_1_approx] starting weight calculation for When something is representing, it represents
When something is happening, it happens
When something is relating, it relates
When something is remaining, it remains
When something is reducing, it reduces
When something is discovering, it discovers
When something is spending, it spends
When something is learning, it
2024-07-28 23:24:25 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-28 23:26:45 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1724,  0.1567, -0.3333,  ..., -0.2954, -0.3582, -0.1312],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.9180, -2.7305,  0.7070,  ...,  1.1787, -4.4141, -4.1328],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0452, -0.0082,  0.0024,  ...,  0.0052,  0.0029,  0.0068],
        [-0.0011,  0.0445, -0.0160,  ...,  0.0024,  0.0039,  0.0088],
        [-0.0011, -0.0227,  0.0409,  ..., -0.0047,  0.0080, -0.0025],
        ...,
        [ 0.0138,  0.0004,  0.0018,  ...,  0.0323,  0.0051,  0.0003],
        [ 0.0093,  0.0082, -0.0115,  ..., -0.0027,  0.0074, -0.0308],
        [-0.0184, -0.0038,  0.0099,  ..., -0.0136, -0.0087,  0.0111]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.8398, -2.6328,  0.6758,  ...,  1.3428, -4.0508, -3.8125]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 23:26:48 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When something is representing, it represents
When something is happening, it happens
When something is relating, it relates
When something is remaining, it remains
When something is reducing, it reduces
When something is discovering, it discovers
When something is spending, it spends
When something is learning, it
2024-07-28 23:26:51 root INFO     [order_1_approx] starting weight calculation for When something is reducing, it reduces
When something is discovering, it discovers
When something is spending, it spends
When something is relating, it relates
When something is learning, it learns
When something is remaining, it remains
When something is happening, it happens
When something is representing, it
2024-07-28 23:26:51 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-28 23:29:11 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0177, -0.0732, -0.6260,  ..., -0.1429,  0.1175, -0.2266],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.1875, -3.4375,  2.6367,  ...,  2.1680, -8.7031,  0.8965],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0562, -0.0044,  0.0064,  ...,  0.0073,  0.0062,  0.0100],
        [-0.0094,  0.0497,  0.0011,  ...,  0.0005,  0.0033,  0.0041],
        [ 0.0002,  0.0101,  0.0235,  ..., -0.0020, -0.0271, -0.0113],
        ...,
        [ 0.0116,  0.0242, -0.0138,  ...,  0.0587, -0.0184,  0.0164],
        [ 0.0160, -0.0108, -0.0133,  ..., -0.0314,  0.0432, -0.0280],
        [-0.0128, -0.0160,  0.0183,  ...,  0.0023, -0.0094,  0.0206]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.3093, -3.1211,  2.8789,  ...,  2.3691, -8.5156,  0.8125]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 23:29:12 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When something is reducing, it reduces
When something is discovering, it discovers
When something is spending, it spends
When something is relating, it relates
When something is learning, it learns
When something is remaining, it remains
When something is happening, it happens
When something is representing, it
2024-07-28 23:29:12 root INFO     total operator prediction time: 1139.1074764728546 seconds
2024-07-28 23:29:12 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on verb_inf - 3pSg
2024-07-28 23:29:12 root INFO     building operator verb_inf - 3pSg
2024-07-28 23:29:12 root INFO     [order_1_approx] starting weight calculation for I describe, he describes
I refer, he refers
I protect, he protects
I accept, he accepts
I follow, he follows
I promote, he promotes
I improve, he improves
I learn, he
2024-07-28 23:29:12 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-28 23:31:35 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0199,  0.1702, -0.0686,  ..., -0.3035, -0.4958,  0.1199],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.6816, -3.5059, -1.1836,  ...,  1.1855, -7.4297, -3.1758],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0336,  0.0147, -0.0098,  ..., -0.0088,  0.0179,  0.0191],
        [-0.0017,  0.0231, -0.0039,  ...,  0.0011,  0.0102, -0.0062],
        [-0.0111, -0.0011,  0.0130,  ..., -0.0233,  0.0120, -0.0012],
        ...,
        [ 0.0042, -0.0081, -0.0123,  ...,  0.0159,  0.0209, -0.0090],
        [ 0.0140,  0.0025, -0.0052,  ...,  0.0054, -0.0096, -0.0315],
        [-0.0163, -0.0041,  0.0053,  ..., -0.0180,  0.0081, -0.0138]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.8809, -3.7832, -1.1514,  ...,  1.5059, -7.6719, -3.1699]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 23:31:36 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for I describe, he describes
I refer, he refers
I protect, he protects
I accept, he accepts
I follow, he follows
I promote, he promotes
I improve, he improves
I learn, he
2024-07-28 23:31:36 root INFO     [order_1_approx] starting weight calculation for I improve, he improves
I refer, he refers
I accept, he accepts
I protect, he protects
I follow, he follows
I learn, he learns
I describe, he describes
I promote, he
2024-07-28 23:31:36 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-28 23:33:59 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0502,  0.1104, -0.1205,  ..., -0.0229, -0.0947,  0.2312],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 5.4180, -4.4219, -0.2207,  ..., -0.1670, -9.0000,  0.0859],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 2.7100e-02, -7.6294e-05,  2.4796e-04,  ...,  4.0741e-03,
          1.1002e-02,  2.3148e-02],
        [-2.2491e-02,  1.8051e-02, -1.3290e-02,  ..., -9.9182e-05,
         -8.6117e-04,  1.1765e-02],
        [ 1.7807e-02,  2.3621e-02,  1.1192e-02,  ..., -1.3565e-02,
         -8.0261e-03,  3.6163e-02],
        ...,
        [-3.1929e-03, -7.4844e-03,  1.0395e-03,  ...,  1.6006e-02,
          1.7593e-02, -2.9602e-03],
        [-2.7771e-03, -2.4719e-03, -3.2990e-02,  ..., -1.9684e-02,
          2.4719e-03, -3.7109e-02],
        [ 9.3155e-03,  6.9084e-03, -1.1425e-03,  ..., -3.1860e-02,
         -2.2064e-02, -3.1471e-03]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 5.2891, -4.5898,  0.0270,  ...,  0.2136, -9.1328, -0.0270]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 23:34:00 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for I improve, he improves
I refer, he refers
I accept, he accepts
I protect, he protects
I follow, he follows
I learn, he learns
I describe, he describes
I promote, he
2024-07-28 23:34:00 root INFO     [order_1_approx] starting weight calculation for I promote, he promotes
I describe, he describes
I improve, he improves
I learn, he learns
I follow, he follows
I protect, he protects
I refer, he refers
I accept, he
2024-07-28 23:34:00 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-28 23:36:22 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1244,  0.5776, -0.3115,  ...,  0.0766, -0.3262,  0.1354],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 5.1875, -3.2617, -2.6992,  ...,  0.2852, -9.5312,  0.4609],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0536,  0.0125,  0.0120,  ..., -0.0035,  0.0116,  0.0387],
        [-0.0157,  0.0203,  0.0048,  ...,  0.0267,  0.0119, -0.0172],
        [-0.0196,  0.0235, -0.0043,  ...,  0.0002,  0.0044, -0.0058],
        ...,
        [-0.0046,  0.0024, -0.0002,  ...,  0.0405,  0.0194, -0.0195],
        [-0.0471, -0.0077, -0.0312,  ..., -0.0208,  0.0582, -0.0240],
        [ 0.0162, -0.0141,  0.0007,  ..., -0.0231, -0.0258,  0.0076]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.5195, -3.0957, -3.0781,  ...,  0.6953, -9.8203,  1.1543]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 23:36:23 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for I promote, he promotes
I describe, he describes
I improve, he improves
I learn, he learns
I follow, he follows
I protect, he protects
I refer, he refers
I accept, he
2024-07-28 23:36:23 root INFO     [order_1_approx] starting weight calculation for I improve, he improves
I accept, he accepts
I promote, he promotes
I follow, he follows
I protect, he protects
I learn, he learns
I refer, he refers
I describe, he
2024-07-28 23:36:24 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-28 23:38:46 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0254,  0.0237,  0.0007,  ..., -0.2274, -0.1912, -0.2012],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.3281, -3.9141,  2.9316,  ..., -0.9209, -7.2891, -1.7129],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0239, -0.0021,  0.0031,  ..., -0.0044,  0.0037,  0.0088],
        [-0.0098,  0.0481, -0.0031,  ..., -0.0015,  0.0264,  0.0180],
        [ 0.0057,  0.0090,  0.0061,  ...,  0.0011, -0.0097,  0.0166],
        ...,
        [ 0.0068, -0.0121,  0.0130,  ...,  0.0141,  0.0063,  0.0045],
        [-0.0205, -0.0026, -0.0271,  ..., -0.0128,  0.0215, -0.0243],
        [-0.0046, -0.0036,  0.0064,  ..., -0.0247, -0.0090,  0.0043]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.3906, -4.2188,  2.7812,  ..., -0.6064, -7.0625, -1.4883]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 23:38:47 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for I improve, he improves
I accept, he accepts
I promote, he promotes
I follow, he follows
I protect, he protects
I learn, he learns
I refer, he refers
I describe, he
2024-07-28 23:38:47 root INFO     [order_1_approx] starting weight calculation for I improve, he improves
I refer, he refers
I accept, he accepts
I protect, he protects
I promote, he promotes
I learn, he learns
I describe, he describes
I follow, he
2024-07-28 23:38:47 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-28 23:41:08 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0322,  0.1094, -0.1056,  ..., -0.1343,  0.0391,  0.2426],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.9316, -3.5781,  0.5215,  ..., -1.1133, -9.2344, -1.1152],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 3.6652e-02,  8.6212e-03,  2.5024e-03,  ...,  5.1765e-03,
          3.1219e-02,  3.4821e-02],
        [-5.8022e-03,  2.2629e-02, -1.3763e-02,  ..., -1.2192e-02,
          1.4999e-02, -5.2452e-03],
        [-1.4175e-02,  4.0665e-03, -8.6365e-03,  ..., -2.6031e-02,
         -3.4695e-03, -2.1820e-02],
        ...,
        [-1.0231e-02, -5.6343e-03, -1.6708e-02,  ...,  1.8234e-02,
          2.6489e-02,  3.4332e-05],
        [-1.5764e-03, -2.2430e-02, -3.1769e-02,  ..., -8.6975e-03,
         -9.6054e-03, -3.8300e-02],
        [-1.8753e-02, -3.9749e-03,  1.7502e-02,  ..., -1.4122e-02,
         -1.8906e-02, -2.6733e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.0293, -3.7539,  0.9199,  ..., -0.7920, -9.2734, -1.0430]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 23:41:09 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for I improve, he improves
I refer, he refers
I accept, he accepts
I protect, he protects
I promote, he promotes
I learn, he learns
I describe, he describes
I follow, he
2024-07-28 23:41:09 root INFO     [order_1_approx] starting weight calculation for I describe, he describes
I learn, he learns
I accept, he accepts
I promote, he promotes
I refer, he refers
I follow, he follows
I improve, he improves
I protect, he
2024-07-28 23:41:09 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-28 23:43:31 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3042, -0.1432, -0.0267,  ..., -0.2349, -0.1860,  0.1161],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.3867, -5.6094, -1.3281,  ..., -1.1445, -7.7617,  0.1250],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0205,  0.0161,  0.0060,  ..., -0.0081,  0.0046,  0.0273],
        [-0.0324,  0.0212,  0.0086,  ...,  0.0033,  0.0228,  0.0094],
        [ 0.0099,  0.0202,  0.0210,  ..., -0.0073, -0.0164,  0.0050],
        ...,
        [-0.0094, -0.0075,  0.0060,  ...,  0.0089,  0.0164, -0.0036],
        [ 0.0010, -0.0187, -0.0205,  ..., -0.0224,  0.0253, -0.0484],
        [ 0.0024, -0.0059,  0.0117,  ..., -0.0145, -0.0044,  0.0108]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.0840, -5.7266, -1.4258,  ..., -0.7080, -7.7930,  0.1111]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 23:43:35 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for I describe, he describes
I learn, he learns
I accept, he accepts
I promote, he promotes
I refer, he refers
I follow, he follows
I improve, he improves
I protect, he
2024-07-28 23:43:37 root INFO     [order_1_approx] starting weight calculation for I protect, he protects
I promote, he promotes
I describe, he describes
I accept, he accepts
I improve, he improves
I learn, he learns
I follow, he follows
I refer, he
2024-07-28 23:43:37 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-28 23:45:59 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1907,  0.1704, -0.1875,  ...,  0.1302, -0.4146, -0.1499],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([  2.7227,  -4.1953,  -1.0762,  ...,   0.4219, -10.9688,  -2.2031],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0444,  0.0032,  0.0038,  ...,  0.0145,  0.0112,  0.0137],
        [-0.0221,  0.0459, -0.0115,  ..., -0.0151,  0.0102,  0.0106],
        [ 0.0215,  0.0095,  0.0084,  ..., -0.0113, -0.0157,  0.0044],
        ...,
        [ 0.0446,  0.0028, -0.0178,  ...,  0.0406,  0.0062,  0.0122],
        [-0.0256, -0.0174,  0.0017,  ..., -0.0204,  0.0056, -0.0346],
        [ 0.0043, -0.0030,  0.0041,  ..., -0.0033, -0.0212,  0.0086]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[  2.6582,  -4.3008,  -0.9448,  ...,   0.5098, -10.6250,  -1.9209]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 23:46:00 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for I protect, he protects
I promote, he promotes
I describe, he describes
I accept, he accepts
I improve, he improves
I learn, he learns
I follow, he follows
I refer, he
2024-07-28 23:46:00 root INFO     [order_1_approx] starting weight calculation for I describe, he describes
I refer, he refers
I follow, he follows
I promote, he promotes
I accept, he accepts
I protect, he protects
I learn, he learns
I improve, he
2024-07-28 23:46:00 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-28 23:48:22 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0249,  0.0972, -0.2036,  ..., -0.2246, -0.4221,  0.3689],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 6.5469, -3.7871, -1.9570,  ...,  0.6030, -7.7539,  0.3477],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 2.7283e-02,  2.4796e-03, -2.5139e-03,  ..., -4.5395e-03,
          1.3969e-02,  1.1375e-02],
        [ 2.1248e-03,  2.0050e-02,  4.9133e-03,  ..., -2.5005e-03,
          3.5191e-03,  3.7003e-03],
        [ 2.6932e-03,  1.8477e-04,  7.2670e-03,  ..., -9.0361e-05,
         -1.4076e-03,  1.0014e-03],
        ...,
        [-6.3019e-03,  1.6174e-03, -8.0643e-03,  ...,  2.2675e-02,
          3.6182e-03,  1.5221e-03],
        [-4.9438e-03, -1.8036e-02, -8.8577e-03,  ..., -4.7760e-03,
         -1.7014e-03, -2.0020e-02],
        [-1.8250e-02, -2.7199e-03,  1.7920e-03,  ..., -1.8143e-02,
         -5.2299e-03, -7.2556e-03]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 6.2891, -4.0742, -2.1113,  ...,  1.0088, -7.9688,  0.0295]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 23:48:23 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for I describe, he describes
I refer, he refers
I follow, he follows
I promote, he promotes
I accept, he accepts
I protect, he protects
I learn, he learns
I improve, he
2024-07-28 23:48:23 root INFO     total operator prediction time: 1151.1327159404755 seconds
2024-07-28 23:48:23 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on verb_inf - Ved
2024-07-28 23:48:23 root INFO     building operator verb_inf - Ved
2024-07-28 23:48:24 root INFO     [order_1_approx] starting weight calculation for If the present form is introduce, the past form is introduced
If the present form is refer, the past form is referred
If the present form is locate, the past form is located
If the present form is manage, the past form is managed
If the present form is hear, the past form is heard
If the present form is include, the past form is included
If the present form is announce, the past form is announced
If the present form is reduce, the past form is
2024-07-28 23:48:24 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-28 23:50:46 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0925,  0.1187, -0.3838,  ..., -0.0750,  0.0177, -0.1211],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-2.2871, -0.5645,  0.9746,  ..., -4.1133, -1.5244, -4.4844],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 4.8279e-02,  5.1765e-03, -7.5417e-03,  ...,  1.8738e-02,
          8.4686e-03,  1.8631e-02],
        [-1.0361e-02,  4.7791e-02,  2.0462e-02,  ...,  1.3016e-02,
         -1.7042e-03,  5.2605e-03],
        [ 2.0996e-02,  4.9553e-03,  2.1988e-02,  ..., -1.8524e-02,
         -1.0880e-02,  9.6436e-03],
        ...,
        [ 1.8097e-02, -1.5007e-02, -2.9465e-02,  ...,  4.3762e-02,
          1.4664e-02,  1.2268e-02],
        [ 2.7084e-02,  2.7695e-03,  8.4152e-03,  ..., -1.0712e-02,
          4.7363e-02, -9.0942e-03],
        [-1.1955e-02, -1.5175e-02, -2.0695e-03,  ..., -1.4000e-02,
         -4.9591e-05,  2.6535e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-2.4004, -0.9238,  0.9238,  ..., -3.6875, -1.2383, -4.1953]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 23:50:47 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If the present form is introduce, the past form is introduced
If the present form is refer, the past form is referred
If the present form is locate, the past form is located
If the present form is manage, the past form is managed
If the present form is hear, the past form is heard
If the present form is include, the past form is included
If the present form is announce, the past form is announced
If the present form is reduce, the past form is
2024-07-28 23:50:47 root INFO     [order_1_approx] starting weight calculation for If the present form is manage, the past form is managed
If the present form is hear, the past form is heard
If the present form is announce, the past form is announced
If the present form is reduce, the past form is reduced
If the present form is include, the past form is included
If the present form is refer, the past form is referred
If the present form is locate, the past form is located
If the present form is introduce, the past form is
2024-07-28 23:50:47 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-28 23:53:11 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.3909,  0.3145,  0.0160,  ..., -0.0967, -0.1914,  0.1711],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.3359,  1.4805,  2.9980,  ...,  0.8257, -2.4219, -0.5684],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 7.3669e-02,  1.3008e-02,  4.6234e-03,  ...,  1.4412e-02,
          3.8357e-03,  1.6556e-02],
        [-1.7746e-02,  5.2246e-02,  6.2256e-03,  ...,  9.6741e-03,
         -2.3819e-02, -1.1139e-03],
        [ 7.5684e-03,  7.4425e-03,  2.9877e-02,  ...,  2.3132e-02,
         -3.1006e-02,  4.5547e-03],
        ...,
        [ 4.1351e-03,  3.2711e-04, -1.1665e-02,  ...,  5.9540e-02,
         -8.6670e-03,  1.8219e-02],
        [ 1.8066e-02,  9.9182e-05,  5.2109e-03,  ..., -1.2894e-02,
          2.2446e-02, -7.1716e-03],
        [-1.5518e-02, -1.6159e-02,  3.0655e-02,  ..., -1.9379e-02,
         -2.8580e-02,  3.4302e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.0466,  1.3984,  3.0742,  ...,  0.7314, -1.9102, -0.4817]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 23:53:13 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If the present form is manage, the past form is managed
If the present form is hear, the past form is heard
If the present form is announce, the past form is announced
If the present form is reduce, the past form is reduced
If the present form is include, the past form is included
If the present form is refer, the past form is referred
If the present form is locate, the past form is located
If the present form is introduce, the past form is
2024-07-28 23:53:13 root INFO     [order_1_approx] starting weight calculation for If the present form is manage, the past form is managed
If the present form is announce, the past form is announced
If the present form is refer, the past form is referred
If the present form is introduce, the past form is introduced
If the present form is hear, the past form is heard
If the present form is reduce, the past form is reduced
If the present form is locate, the past form is located
If the present form is include, the past form is
2024-07-28 23:53:13 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-28 23:55:35 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([0.0475, 0.1528, 0.0196,  ..., 0.0542, 0.1031, 0.1099], device='cuda:0',
       dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.1387,  1.3467,  0.1089,  ..., -1.3516, -0.2139, -1.5391],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 5.5634e-02, -1.0109e-02,  1.9638e-02,  ...,  1.1826e-04,
          6.3972e-03,  1.4275e-02],
        [-1.4809e-02,  6.1462e-02,  2.3422e-02,  ...,  1.7380e-02,
          6.3515e-04, -1.9409e-02],
        [-6.8130e-03, -9.2010e-03,  1.5594e-02,  ..., -5.1651e-03,
         -2.5146e-02, -9.9182e-05],
        ...,
        [-1.5747e-02,  7.7896e-03, -3.8052e-04,  ...,  5.2612e-02,
          1.0061e-03,  2.0111e-02],
        [ 7.6828e-03,  1.4099e-02, -1.8616e-03,  ..., -8.1253e-03,
          6.3286e-03,  7.1297e-03],
        [-9.8038e-03, -4.0588e-03,  1.0204e-03,  ..., -2.8976e-02,
         -1.7944e-02,  2.9160e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.7441,  1.5410,  0.1196,  ..., -1.4277,  0.5908, -0.7373]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 23:55:36 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If the present form is manage, the past form is managed
If the present form is announce, the past form is announced
If the present form is refer, the past form is referred
If the present form is introduce, the past form is introduced
If the present form is hear, the past form is heard
If the present form is reduce, the past form is reduced
If the present form is locate, the past form is located
If the present form is include, the past form is
2024-07-28 23:55:37 root INFO     [order_1_approx] starting weight calculation for If the present form is refer, the past form is referred
If the present form is introduce, the past form is introduced
If the present form is include, the past form is included
If the present form is hear, the past form is heard
If the present form is reduce, the past form is reduced
If the present form is manage, the past form is managed
If the present form is locate, the past form is located
If the present form is announce, the past form is
2024-07-28 23:55:37 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-28 23:58:01 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4141,  0.4390, -0.0444,  ..., -0.1001, -0.6777, -0.0118],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.4399, -0.0250,  3.0508,  ...,  0.6235, -2.2832,  0.0547],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 4.4220e-02,  5.3902e-03,  9.8991e-04,  ..., -3.4981e-03,
         -1.4820e-03,  1.8600e-02],
        [-9.8419e-03,  2.5894e-02,  1.5671e-02,  ...,  4.3602e-03,
          1.0017e-02, -1.0757e-02],
        [ 1.0880e-02,  4.8637e-05,  3.7193e-03,  ...,  9.4986e-03,
         -1.8967e-02,  1.2497e-02],
        ...,
        [-1.6460e-03,  6.0120e-03, -1.8158e-02,  ...,  2.8015e-02,
          3.1281e-03,  1.7029e-02],
        [ 1.8890e-02, -1.7357e-03, -7.7896e-03,  ...,  3.4351e-03,
          8.1482e-03, -1.8892e-03],
        [ 1.3634e-02,  1.2939e-02,  1.2398e-02,  ..., -1.4435e-02,
         -8.8425e-03,  4.1077e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.3364, -0.1702,  3.2734,  ...,  0.7637, -1.7910,  0.0088]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 23:58:02 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If the present form is refer, the past form is referred
If the present form is introduce, the past form is introduced
If the present form is include, the past form is included
If the present form is hear, the past form is heard
If the present form is reduce, the past form is reduced
If the present form is manage, the past form is managed
If the present form is locate, the past form is located
If the present form is announce, the past form is
2024-07-28 23:58:02 root INFO     [order_1_approx] starting weight calculation for If the present form is introduce, the past form is introduced
If the present form is reduce, the past form is reduced
If the present form is include, the past form is included
If the present form is hear, the past form is heard
If the present form is locate, the past form is located
If the present form is manage, the past form is managed
If the present form is announce, the past form is announced
If the present form is refer, the past form is
2024-07-28 23:58:02 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-29 00:00:22 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1931, -0.1368, -0.1354,  ...,  0.1724, -0.4263,  0.0609],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.0449, -1.0400,  0.2637,  ...,  1.3594, -2.1191, -2.9570],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0773, -0.0023,  0.0194,  ...,  0.0040,  0.0138,  0.0422],
        [-0.0600,  0.0510,  0.0151,  ..., -0.0094, -0.0101, -0.0101],
        [ 0.0214, -0.0017,  0.0289,  ..., -0.0084, -0.0107,  0.0208],
        ...,
        [ 0.0201,  0.0200, -0.0156,  ...,  0.0533,  0.0052,  0.0400],
        [ 0.0473, -0.0073,  0.0100,  ...,  0.0045,  0.0079, -0.0120],
        [-0.0108, -0.0023,  0.0085,  ..., -0.0185, -0.0129,  0.0265]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.1611, -1.1758,  0.3564,  ...,  1.4121, -1.8105, -2.6582]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 00:00:25 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If the present form is introduce, the past form is introduced
If the present form is reduce, the past form is reduced
If the present form is include, the past form is included
If the present form is hear, the past form is heard
If the present form is locate, the past form is located
If the present form is manage, the past form is managed
If the present form is announce, the past form is announced
If the present form is refer, the past form is
2024-07-29 00:00:27 root INFO     [order_1_approx] starting weight calculation for If the present form is introduce, the past form is introduced
If the present form is refer, the past form is referred
If the present form is include, the past form is included
If the present form is locate, the past form is located
If the present form is announce, the past form is announced
If the present form is manage, the past form is managed
If the present form is reduce, the past form is reduced
If the present form is hear, the past form is
2024-07-29 00:00:27 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-29 00:02:51 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0979, -0.0038,  0.1284,  ...,  0.1042, -0.2445,  0.2190],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.1338, -0.4131,  1.3516,  ..., -0.4116, -3.4219, -3.1367],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 8.2275e-02, -4.7379e-03,  9.8343e-03,  ..., -2.0733e-03,
          3.5156e-02,  3.0029e-02],
        [ 5.6458e-03,  1.0669e-01,  8.2493e-05,  ...,  1.3527e-02,
          4.1466e-03, -1.3916e-02],
        [ 2.2869e-03,  1.1101e-02,  6.5613e-02,  ..., -1.3252e-02,
         -2.1744e-02,  5.3444e-03],
        ...,
        [ 2.7435e-02,  3.6438e-02, -5.9891e-03,  ...,  5.1056e-02,
          2.0996e-02,  9.2316e-04],
        [ 1.4481e-02,  9.4910e-03, -1.5144e-03,  ...,  7.3242e-04,
          2.1927e-02, -6.8283e-03],
        [-8.2397e-03,  1.4832e-02,  1.1513e-02,  ...,  6.4735e-03,
          5.3024e-03,  4.1260e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.2158, -0.7861,  1.1602,  ..., -0.2524, -3.1094, -3.0879]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 00:02:52 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If the present form is introduce, the past form is introduced
If the present form is refer, the past form is referred
If the present form is include, the past form is included
If the present form is locate, the past form is located
If the present form is announce, the past form is announced
If the present form is manage, the past form is managed
If the present form is reduce, the past form is reduced
If the present form is hear, the past form is
2024-07-29 00:02:52 root INFO     [order_1_approx] starting weight calculation for If the present form is locate, the past form is located
If the present form is hear, the past form is heard
If the present form is introduce, the past form is introduced
If the present form is refer, the past form is referred
If the present form is include, the past form is included
If the present form is announce, the past form is announced
If the present form is reduce, the past form is reduced
If the present form is manage, the past form is
2024-07-29 00:02:52 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-29 00:05:11 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1562,  0.4199, -0.0536,  ..., -0.4307, -0.2668,  0.1147],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.5098, -0.6855,  1.8496,  ..., -1.8594, -0.9214, -1.6387],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0533,  0.0276,  0.0004,  ..., -0.0102, -0.0012,  0.0291],
        [-0.0002,  0.0698,  0.0179,  ..., -0.0043,  0.0112,  0.0006],
        [ 0.0033,  0.0080,  0.0366,  ...,  0.0007, -0.0070, -0.0057],
        ...,
        [-0.0032,  0.0135,  0.0088,  ...,  0.0607,  0.0103,  0.0047],
        [ 0.0067, -0.0128,  0.0152,  ..., -0.0143,  0.0199, -0.0423],
        [-0.0019, -0.0071,  0.0040,  ..., -0.0087, -0.0182,  0.0229]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.0234, -0.6343,  1.6172,  ..., -1.6191, -0.8662, -1.7656]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 00:05:12 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If the present form is locate, the past form is located
If the present form is hear, the past form is heard
If the present form is introduce, the past form is introduced
If the present form is refer, the past form is referred
If the present form is include, the past form is included
If the present form is announce, the past form is announced
If the present form is reduce, the past form is reduced
If the present form is manage, the past form is
2024-07-29 00:05:12 root INFO     [order_1_approx] starting weight calculation for If the present form is refer, the past form is referred
If the present form is manage, the past form is managed
If the present form is hear, the past form is heard
If the present form is reduce, the past form is reduced
If the present form is introduce, the past form is introduced
If the present form is announce, the past form is announced
If the present form is include, the past form is included
If the present form is locate, the past form is
2024-07-29 00:05:12 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-29 00:07:34 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0955,  0.2632, -0.7417,  ..., -0.0607, -0.4788,  0.0750],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.8809, -0.8135, -1.2178,  ..., -2.2500, -1.0977, -2.2734],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0580, -0.0055, -0.0039,  ..., -0.0023,  0.0071,  0.0172],
        [-0.0088,  0.0625,  0.0028,  ..., -0.0012, -0.0085, -0.0006],
        [ 0.0073, -0.0036,  0.0352,  ..., -0.0132, -0.0177,  0.0044],
        ...,
        [-0.0010,  0.0201, -0.0014,  ...,  0.0548, -0.0006,  0.0134],
        [ 0.0306, -0.0205, -0.0096,  ..., -0.0029,  0.0228, -0.0164],
        [ 0.0070, -0.0100, -0.0104,  ..., -0.0234, -0.0278,  0.0414]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.1924, -0.6328, -1.4062,  ..., -1.8770, -0.6816, -2.2070]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 00:07:35 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If the present form is refer, the past form is referred
If the present form is manage, the past form is managed
If the present form is hear, the past form is heard
If the present form is reduce, the past form is reduced
If the present form is introduce, the past form is introduced
If the present form is announce, the past form is announced
If the present form is include, the past form is included
If the present form is locate, the past form is
2024-07-29 00:07:35 root INFO     total operator prediction time: 1151.96804189682 seconds
2024-07-29 00:07:35 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on verb_Ving - Ved
2024-07-29 00:07:35 root INFO     building operator verb_Ving - Ved
2024-07-29 00:07:35 root INFO     [order_1_approx] starting weight calculation for After something is proposing, it has proposed
After something is providing, it has provided
After something is agreeing, it has agreed
After something is hearing, it has heard
After something is receiving, it has received
After something is allowing, it has allowed
After something is continuing, it has continued
After something is including, it has
2024-07-29 00:07:36 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-29 00:10:01 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0869, -0.1210, -0.0464,  ...,  0.0868,  0.0513, -0.2114],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.0225,  0.8018,  1.2578,  ..., -1.5215, -0.1475, -2.3301],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 2.9205e-02,  5.2643e-04, -4.9744e-03,  ...,  1.0918e-02,
         -9.7351e-03, -3.7270e-03],
        [-2.4551e-02,  5.0934e-02,  6.7711e-05,  ...,  7.9956e-03,
         -5.4665e-03, -2.1011e-02],
        [ 6.0081e-04,  7.7629e-04,  2.5543e-02,  ..., -5.5084e-03,
         -1.3618e-02,  9.8114e-03],
        ...,
        [ 1.6937e-02,  2.3087e-02, -2.7161e-02,  ...,  3.3142e-02,
         -1.0818e-02,  1.4053e-02],
        [ 1.9440e-02,  1.8433e-02, -2.7206e-02,  ...,  4.0550e-03,
          2.4147e-03, -1.5305e-02],
        [-1.1292e-02, -3.2768e-03,  1.3672e-02,  ...,  6.1035e-05,
         -2.2011e-03,  1.9867e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.1006,  0.7461,  1.4795,  ..., -1.5127,  0.2258, -1.8184]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 00:10:02 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for After something is proposing, it has proposed
After something is providing, it has provided
After something is agreeing, it has agreed
After something is hearing, it has heard
After something is receiving, it has received
After something is allowing, it has allowed
After something is continuing, it has continued
After something is including, it has
2024-07-29 00:10:02 root INFO     [order_1_approx] starting weight calculation for After something is hearing, it has heard
After something is proposing, it has proposed
After something is continuing, it has continued
After something is agreeing, it has agreed
After something is including, it has included
After something is allowing, it has allowed
After something is receiving, it has received
After something is providing, it has
2024-07-29 00:10:02 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-29 00:12:26 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1873, -0.0588, -0.2742,  ..., -0.2203, -0.0191, -0.0898],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.4277, -3.1055,  1.7041,  ..., -1.3555, -2.3398,  0.5254],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0579,  0.0053,  0.0312,  ...,  0.0078,  0.0048,  0.0370],
        [-0.0173,  0.0379,  0.0265,  ...,  0.0022, -0.0085,  0.0149],
        [ 0.0026, -0.0118,  0.0104,  ..., -0.0025, -0.0085,  0.0026],
        ...,
        [ 0.0158,  0.0230, -0.0164,  ...,  0.0508,  0.0197,  0.0290],
        [ 0.0207, -0.0185, -0.0167,  ..., -0.0048,  0.0239, -0.0390],
        [-0.0033,  0.0196,  0.0148,  ..., -0.0282, -0.0026,  0.0476]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.1074, -2.2676,  1.1777,  ..., -1.4316, -1.7100,  0.2109]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 00:12:27 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for After something is hearing, it has heard
After something is proposing, it has proposed
After something is continuing, it has continued
After something is agreeing, it has agreed
After something is including, it has included
After something is allowing, it has allowed
After something is receiving, it has received
After something is providing, it has
2024-07-29 00:12:27 root INFO     [order_1_approx] starting weight calculation for After something is proposing, it has proposed
After something is continuing, it has continued
After something is allowing, it has allowed
After something is providing, it has provided
After something is including, it has included
After something is receiving, it has received
After something is hearing, it has heard
After something is agreeing, it has
2024-07-29 00:12:27 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-29 00:14:50 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1714,  0.0168, -0.2009,  ...,  0.1577, -0.4604, -0.1016],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.2793, -1.9033,  1.9473,  ..., -0.5186, -0.1201, -0.1172],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0269, -0.0033,  0.0061,  ...,  0.0128,  0.0123,  0.0131],
        [-0.0111,  0.0289,  0.0061,  ...,  0.0114, -0.0015, -0.0054],
        [ 0.0082,  0.0039,  0.0199,  ...,  0.0006, -0.0048,  0.0082],
        ...,
        [ 0.0051,  0.0154, -0.0153,  ...,  0.0153,  0.0026, -0.0060],
        [ 0.0136, -0.0044, -0.0062,  ..., -0.0124,  0.0081, -0.0086],
        [-0.0013,  0.0159,  0.0259,  ...,  0.0064,  0.0011,  0.0042]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.1699, -1.9375,  2.0605,  ..., -0.2043, -0.2040, -0.1268]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 00:14:51 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for After something is proposing, it has proposed
After something is continuing, it has continued
After something is allowing, it has allowed
After something is providing, it has provided
After something is including, it has included
After something is receiving, it has received
After something is hearing, it has heard
After something is agreeing, it has
2024-07-29 00:14:51 root INFO     [order_1_approx] starting weight calculation for After something is providing, it has provided
After something is hearing, it has heard
After something is including, it has included
After something is continuing, it has continued
After something is proposing, it has proposed
After something is agreeing, it has agreed
After something is allowing, it has allowed
After something is receiving, it has
2024-07-29 00:14:51 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-29 00:17:16 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1516,  0.0502, -0.0449,  ..., -0.3730,  0.0312, -0.0267],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.6709,  0.2642, -0.4277,  ..., -2.4180, -2.5449, -2.6426],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 5.1056e-02, -1.2779e-02,  3.2898e-02,  ..., -1.8921e-03,
         -1.3367e-02,  2.8183e-02],
        [-3.7994e-02,  5.6732e-02,  1.6983e-02,  ...,  1.1536e-02,
         -4.2267e-03, -8.4991e-03],
        [-2.0409e-03, -1.1047e-02,  1.5259e-02,  ..., -2.4567e-02,
          1.2035e-03, -7.9155e-05],
        ...,
        [ 2.0172e-02,  2.8824e-02, -3.4218e-03,  ...,  4.5807e-02,
          5.8479e-03,  2.0111e-02],
        [ 2.4597e-02, -3.2959e-03, -6.8130e-03,  ..., -1.2634e-02,
          3.8269e-02, -1.1589e-02],
        [-1.9760e-02,  1.7822e-02,  1.4488e-02,  ..., -4.5471e-03,
         -1.1795e-02, -4.4060e-03]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.8848, -0.0176, -0.2219,  ..., -2.1465, -2.3164, -2.5000]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 00:17:18 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for After something is providing, it has provided
After something is hearing, it has heard
After something is including, it has included
After something is continuing, it has continued
After something is proposing, it has proposed
After something is agreeing, it has agreed
After something is allowing, it has allowed
After something is receiving, it has
2024-07-29 00:17:18 root INFO     [order_1_approx] starting weight calculation for After something is proposing, it has proposed
After something is allowing, it has allowed
After something is providing, it has provided
After something is continuing, it has continued
After something is agreeing, it has agreed
After something is including, it has included
After something is receiving, it has received
After something is hearing, it has
2024-07-29 00:17:18 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-29 00:19:41 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1008,  0.0039, -0.1114,  ..., -0.0157, -0.0249,  0.1277],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.9375, -0.7974,  1.2637,  ..., -0.4868, -4.3281, -3.2871],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0431,  0.0210,  0.0219,  ...,  0.0038,  0.0105,  0.0171],
        [-0.0168,  0.0711, -0.0011,  ...,  0.0112,  0.0037, -0.0119],
        [ 0.0008,  0.0065,  0.0252,  ..., -0.0143,  0.0016, -0.0066],
        ...,
        [ 0.0145,  0.0086, -0.0064,  ...,  0.0292,  0.0128,  0.0016],
        [ 0.0151, -0.0361,  0.0006,  ..., -0.0129,  0.0186, -0.0157],
        [-0.0200,  0.0300,  0.0329,  ...,  0.0154, -0.0049,  0.0065]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.5205, -1.0664,  0.8379,  ...,  0.0220, -3.7070, -3.5195]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 00:19:42 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for After something is proposing, it has proposed
After something is allowing, it has allowed
After something is providing, it has provided
After something is continuing, it has continued
After something is agreeing, it has agreed
After something is including, it has included
After something is receiving, it has received
After something is hearing, it has
2024-07-29 00:19:42 root INFO     [order_1_approx] starting weight calculation for After something is including, it has included
After something is receiving, it has received
After something is allowing, it has allowed
After something is providing, it has provided
After something is agreeing, it has agreed
After something is continuing, it has continued
After something is hearing, it has heard
After something is proposing, it has
2024-07-29 00:19:42 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-29 00:21:59 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0229,  0.0312, -0.0401,  ..., -0.0016, -0.2822,  0.0181],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.6758, -2.8555,  1.3691,  ..., -1.4004, -1.3945,  0.6270],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0318, -0.0057,  0.0065,  ...,  0.0126,  0.0037,  0.0216],
        [-0.0150,  0.0212,  0.0143,  ...,  0.0093, -0.0111,  0.0063],
        [-0.0098, -0.0019,  0.0253,  ..., -0.0113, -0.0028,  0.0117],
        ...,
        [-0.0081, -0.0005,  0.0109,  ...,  0.0246,  0.0143,  0.0033],
        [ 0.0152,  0.0017, -0.0054,  ..., -0.0214, -0.0007, -0.0176],
        [ 0.0027,  0.0175,  0.0035,  ...,  0.0133, -0.0230,  0.0021]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.5664, -2.9043,  1.6182,  ..., -1.2852, -1.4932,  0.3291]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 00:22:00 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for After something is including, it has included
After something is receiving, it has received
After something is allowing, it has allowed
After something is providing, it has provided
After something is agreeing, it has agreed
After something is continuing, it has continued
After something is hearing, it has heard
After something is proposing, it has
2024-07-29 00:22:01 root INFO     [order_1_approx] starting weight calculation for After something is hearing, it has heard
After something is receiving, it has received
After something is providing, it has provided
After something is including, it has included
After something is proposing, it has proposed
After something is agreeing, it has agreed
After something is continuing, it has continued
After something is allowing, it has
2024-07-29 00:22:01 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-29 00:24:22 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1675,  0.1373, -0.0188,  ..., -0.3977,  0.1067, -0.1963],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.4004, -2.5020, -0.3237,  ..., -1.3535, -1.5098,  0.6855],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0511, -0.0141, -0.0224,  ...,  0.0015, -0.0020, -0.0014],
        [-0.0123,  0.0565, -0.0207,  ...,  0.0173, -0.0068, -0.0177],
        [-0.0114, -0.0190,  0.0326,  ..., -0.0070, -0.0152,  0.0026],
        ...,
        [ 0.0056,  0.0257, -0.0136,  ...,  0.0311,  0.0201,  0.0155],
        [ 0.0044,  0.0126, -0.0111,  ...,  0.0011,  0.0467, -0.0268],
        [ 0.0020,  0.0283,  0.0055,  ...,  0.0055, -0.0073,  0.0114]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.1133, -2.4199, -0.1147,  ..., -0.7627, -0.9536,  0.3857]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 00:24:23 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for After something is hearing, it has heard
After something is receiving, it has received
After something is providing, it has provided
After something is including, it has included
After something is proposing, it has proposed
After something is agreeing, it has agreed
After something is continuing, it has continued
After something is allowing, it has
2024-07-29 00:24:24 root INFO     [order_1_approx] starting weight calculation for After something is providing, it has provided
After something is including, it has included
After something is receiving, it has received
After something is hearing, it has heard
After something is agreeing, it has agreed
After something is allowing, it has allowed
After something is proposing, it has proposed
After something is continuing, it has
2024-07-29 00:24:24 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-29 00:26:44 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2881, -0.2402, -0.2793,  ..., -0.1100, -0.0848,  0.3423],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.3223, -2.2266,  2.3105,  ..., -1.9922,  0.0791, -2.1172],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 2.3102e-02, -9.4700e-04, -1.4313e-02,  ...,  9.7656e-03,
         -5.1765e-03,  1.0391e-02],
        [-1.5945e-02,  4.4128e-02,  7.3318e-03,  ...,  6.1874e-03,
          5.9319e-03, -7.1602e-03],
        [-1.1921e-03,  1.2291e-02,  2.8748e-02,  ...,  4.6501e-03,
         -6.3858e-03,  3.0499e-03],
        ...,
        [ 3.3936e-02,  1.2009e-02,  5.1880e-03,  ...,  6.1340e-02,
         -3.2883e-03,  2.3842e-05],
        [ 3.2715e-02,  2.8687e-02, -2.4017e-02,  ..., -8.2474e-03,
          1.0391e-02, -6.3515e-04],
        [-1.6724e-02,  3.5267e-03,  1.2341e-03,  ..., -1.9943e-02,
         -1.2955e-02,  3.2787e-03]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.0391, -2.2070,  2.2285,  ..., -1.7812, -0.1708, -2.1094]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 00:26:45 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for After something is providing, it has provided
After something is including, it has included
After something is receiving, it has received
After something is hearing, it has heard
After something is agreeing, it has agreed
After something is allowing, it has allowed
After something is proposing, it has proposed
After something is continuing, it has
2024-07-29 00:26:45 root INFO     total operator prediction time: 1149.6179587841034 seconds
2024-07-29 00:26:45 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on Ving - verb_inf
2024-07-29 00:26:45 root INFO     building operator Ving - verb_inf
2024-07-29 00:26:45 root INFO     [order_1_approx] starting weight calculation for expecting is the active form of expect
believing is the active form of believe
adding is the active form of add
involving is the active form of involve
remaining is the active form of remain
requiring is the active form of require
developing is the active form of develop
remembering is the active form of
2024-07-29 00:26:45 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-29 00:29:08 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1218, -0.3184,  0.0253,  ..., -0.3726, -0.0907, -0.1644],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.6367, -3.3164, -0.0791,  ...,  0.8604, -1.8291, -2.7070],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0159, -0.0143,  0.0128,  ...,  0.0024, -0.0023,  0.0028],
        [ 0.0070,  0.0348,  0.0032,  ...,  0.0010,  0.0060, -0.0007],
        [ 0.0170, -0.0016,  0.0147,  ..., -0.0085, -0.0036, -0.0050],
        ...,
        [ 0.0093,  0.0106, -0.0071,  ...,  0.0265, -0.0049,  0.0040],
        [ 0.0088,  0.0029, -0.0044,  ...,  0.0035,  0.0141, -0.0037],
        [ 0.0020,  0.0044, -0.0038,  ..., -0.0022, -0.0054,  0.0143]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.5601, -3.3770, -0.0551,  ...,  0.9541, -1.7988, -2.6934]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 00:29:09 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for expecting is the active form of expect
believing is the active form of believe
adding is the active form of add
involving is the active form of involve
remaining is the active form of remain
requiring is the active form of require
developing is the active form of develop
remembering is the active form of
2024-07-29 00:29:09 root INFO     [order_1_approx] starting weight calculation for developing is the active form of develop
remembering is the active form of remember
remaining is the active form of remain
requiring is the active form of require
expecting is the active form of expect
believing is the active form of believe
adding is the active form of add
involving is the active form of
2024-07-29 00:29:09 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-29 00:31:31 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1080, -0.1287, -0.3257,  ..., -0.1553, -0.1103, -0.0140],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.3320, -1.4580,  1.9678,  ...,  1.5635,  0.4092, -4.3242],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0439,  0.0018, -0.0002,  ..., -0.0008,  0.0026,  0.0073],
        [-0.0017,  0.0405,  0.0065,  ...,  0.0062, -0.0040,  0.0063],
        [ 0.0161, -0.0066,  0.0185,  ..., -0.0173,  0.0010,  0.0076],
        ...,
        [ 0.0137,  0.0247,  0.0019,  ...,  0.0374,  0.0096,  0.0006],
        [ 0.0065,  0.0014,  0.0047,  ...,  0.0043,  0.0271,  0.0123],
        [ 0.0012, -0.0013, -0.0020,  ..., -0.0099, -0.0113,  0.0268]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.1721, -1.5166,  1.7998,  ...,  1.5693,  0.3420, -4.3242]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 00:31:32 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for developing is the active form of develop
remembering is the active form of remember
remaining is the active form of remain
requiring is the active form of require
expecting is the active form of expect
believing is the active form of believe
adding is the active form of add
involving is the active form of
2024-07-29 00:31:32 root INFO     [order_1_approx] starting weight calculation for expecting is the active form of expect
requiring is the active form of require
involving is the active form of involve
believing is the active form of believe
adding is the active form of add
developing is the active form of develop
remembering is the active form of remember
remaining is the active form of
2024-07-29 00:31:32 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-29 00:33:54 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1230, -0.3101, -0.3333,  ..., -0.5269,  0.0272,  0.2341],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.1426, -4.1797, -0.4419,  ..., -0.8721, -0.0049, -2.9961],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0567, -0.0157,  0.0026,  ...,  0.0155,  0.0263,  0.0098],
        [ 0.0092,  0.0565, -0.0020,  ..., -0.0023, -0.0034,  0.0017],
        [-0.0034, -0.0175,  0.0366,  ..., -0.0136, -0.0005, -0.0013],
        ...,
        [ 0.0144,  0.0114, -0.0106,  ...,  0.0433, -0.0077,  0.0135],
        [ 0.0054,  0.0125, -0.0049,  ...,  0.0034,  0.0255,  0.0034],
        [-0.0110,  0.0165, -0.0162,  ..., -0.0097, -0.0061,  0.0387]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.0054, -4.2266, -0.3191,  ..., -1.2422, -0.2351, -2.7324]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 00:33:56 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for expecting is the active form of expect
requiring is the active form of require
involving is the active form of involve
believing is the active form of believe
adding is the active form of add
developing is the active form of develop
remembering is the active form of remember
remaining is the active form of
2024-07-29 00:33:56 root INFO     [order_1_approx] starting weight calculation for expecting is the active form of expect
remembering is the active form of remember
developing is the active form of develop
adding is the active form of add
remaining is the active form of remain
requiring is the active form of require
involving is the active form of involve
believing is the active form of
2024-07-29 00:33:56 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-29 00:36:16 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1146, -0.0592, -0.2095,  ..., -0.1404, -0.3989,  0.2208],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.7461, -5.6562,  0.9849,  ...,  1.6680, -1.7744, -3.2090],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 2.3941e-02, -7.8888e-03,  5.7554e-04,  ..., -1.4076e-03,
         -1.4099e-02,  1.1765e-02],
        [ 1.3550e-02,  2.8275e-02, -1.8501e-04,  ...,  1.6556e-02,
          6.2904e-03,  6.0272e-03],
        [ 2.0996e-02,  1.8940e-03,  3.2928e-02,  ..., -2.5978e-03,
         -5.7907e-03,  1.5160e-02],
        ...,
        [ 7.5035e-03,  1.9470e-02, -9.0179e-03,  ...,  2.2659e-02,
         -1.0328e-03, -8.0228e-05],
        [ 5.4054e-03,  2.1484e-02,  6.9313e-03,  ...,  7.6523e-03,
          1.5182e-02, -1.2543e-02],
        [ 1.0023e-03,  8.7128e-03, -1.6794e-03,  ..., -7.9346e-03,
         -2.6112e-03,  1.8433e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.5234, -5.8633,  0.9272,  ...,  1.6416, -1.6289, -3.5332]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 00:36:17 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for expecting is the active form of expect
remembering is the active form of remember
developing is the active form of develop
adding is the active form of add
remaining is the active form of remain
requiring is the active form of require
involving is the active form of involve
believing is the active form of
2024-07-29 00:36:18 root INFO     [order_1_approx] starting weight calculation for requiring is the active form of require
developing is the active form of develop
adding is the active form of add
remaining is the active form of remain
believing is the active form of believe
involving is the active form of involve
remembering is the active form of remember
expecting is the active form of
2024-07-29 00:36:18 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-29 00:38:40 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0841, -0.4375, -0.1349,  ..., -0.2993, -0.0333, -0.1307],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.5654, -3.7461, -1.2715,  ...,  0.7466, -1.9883, -2.8340],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0223, -0.0063,  0.0063,  ...,  0.0125,  0.0003,  0.0065],
        [ 0.0119,  0.0306, -0.0058,  ...,  0.0023,  0.0036,  0.0019],
        [ 0.0095,  0.0082,  0.0119,  ..., -0.0076, -0.0027,  0.0032],
        ...,
        [ 0.0067,  0.0121, -0.0064,  ...,  0.0228,  0.0032,  0.0046],
        [ 0.0145,  0.0026, -0.0043,  ...,  0.0095,  0.0112, -0.0096],
        [ 0.0033,  0.0085, -0.0028,  ..., -0.0005, -0.0069,  0.0179]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.6523, -3.6016, -1.2334,  ...,  0.8081, -2.0332, -2.8750]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 00:38:41 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for requiring is the active form of require
developing is the active form of develop
adding is the active form of add
remaining is the active form of remain
believing is the active form of believe
involving is the active form of involve
remembering is the active form of remember
expecting is the active form of
2024-07-29 00:38:41 root INFO     [order_1_approx] starting weight calculation for remembering is the active form of remember
developing is the active form of develop
believing is the active form of believe
expecting is the active form of expect
requiring is the active form of require
involving is the active form of involve
remaining is the active form of remain
adding is the active form of
2024-07-29 00:38:41 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-29 00:41:01 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0363, -0.4927, -0.2769,  ..., -0.0113,  0.0745, -0.2209],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.8896, -2.1719, -1.6416,  ...,  3.4570, -3.7227, -1.5020],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0525, -0.0047, -0.0059,  ..., -0.0045,  0.0040,  0.0047],
        [-0.0023,  0.0399,  0.0136,  ...,  0.0122, -0.0194, -0.0041],
        [ 0.0114, -0.0020,  0.0347,  ...,  0.0001, -0.0090,  0.0126],
        ...,
        [ 0.0090,  0.0273,  0.0069,  ...,  0.0324, -0.0098,  0.0070],
        [ 0.0137, -0.0288,  0.0195,  ...,  0.0122,  0.0197,  0.0095],
        [-0.0023,  0.0085,  0.0001,  ..., -0.0108, -0.0055,  0.0473]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.1113, -2.5059, -1.7949,  ...,  3.1504, -3.5723, -1.6914]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 00:41:02 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for remembering is the active form of remember
developing is the active form of develop
believing is the active form of believe
expecting is the active form of expect
requiring is the active form of require
involving is the active form of involve
remaining is the active form of remain
adding is the active form of
2024-07-29 00:41:02 root INFO     [order_1_approx] starting weight calculation for expecting is the active form of expect
involving is the active form of involve
remaining is the active form of remain
remembering is the active form of remember
adding is the active form of add
believing is the active form of believe
developing is the active form of develop
requiring is the active form of
2024-07-29 00:41:03 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-29 00:43:27 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0065, -0.1769, -0.3623,  ..., -0.4458, -0.0552, -0.0430],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.3906, -4.0547,  1.2568,  ...,  0.3596, -2.3926, -2.1797],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0457, -0.0012,  0.0104,  ..., -0.0015,  0.0061, -0.0042],
        [ 0.0100,  0.0398,  0.0050,  ...,  0.0115, -0.0137,  0.0041],
        [ 0.0135, -0.0033,  0.0272,  ..., -0.0180, -0.0054,  0.0083],
        ...,
        [ 0.0071,  0.0118, -0.0013,  ...,  0.0458,  0.0081, -0.0026],
        [-0.0044,  0.0197,  0.0058,  ..., -0.0050,  0.0273,  0.0017],
        [-0.0063,  0.0078, -0.0047,  ..., -0.0076, -0.0153,  0.0265]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.4102, -4.3086,  1.2715,  ...,  0.3723, -2.3691, -2.2227]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 00:43:28 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for expecting is the active form of expect
involving is the active form of involve
remaining is the active form of remain
remembering is the active form of remember
adding is the active form of add
believing is the active form of believe
developing is the active form of develop
requiring is the active form of
2024-07-29 00:43:28 root INFO     [order_1_approx] starting weight calculation for involving is the active form of involve
remembering is the active form of remember
adding is the active form of add
remaining is the active form of remain
expecting is the active form of expect
believing is the active form of believe
requiring is the active form of require
developing is the active form of
2024-07-29 00:43:28 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-29 00:45:51 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1421, -0.2439, -0.2720,  ..., -0.3337,  0.0175,  0.0119],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.4688, -4.3633,  2.0391,  ...,  1.7734, -1.4082, -2.3730],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0104,  0.0026, -0.0010,  ...,  0.0102, -0.0088,  0.0083],
        [ 0.0017,  0.0336,  0.0034,  ..., -0.0034, -0.0042, -0.0033],
        [ 0.0030, -0.0049,  0.0106,  ..., -0.0075,  0.0032,  0.0016],
        ...,
        [ 0.0036,  0.0063,  0.0030,  ...,  0.0216, -0.0068,  0.0038],
        [ 0.0010,  0.0077, -0.0018,  ..., -0.0014,  0.0118,  0.0040],
        [ 0.0068,  0.0053, -0.0093,  ..., -0.0006, -0.0084,  0.0178]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.3887, -4.3477,  2.0195,  ...,  1.6113, -1.3857, -2.3691]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 00:45:52 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for involving is the active form of involve
remembering is the active form of remember
adding is the active form of add
remaining is the active form of remain
expecting is the active form of expect
believing is the active form of believe
requiring is the active form of require
developing is the active form of
2024-07-29 00:45:52 root INFO     total operator prediction time: 1147.4176092147827 seconds
2024-07-29 00:45:52 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on noun - plural_irreg
2024-07-29 00:45:52 root INFO     building operator noun - plural_irreg
2024-07-29 00:45:53 root INFO     [order_1_approx] starting weight calculation for The plural form of wife is wives
The plural form of business is businesses
The plural form of child is children
The plural form of formula is formulae
The plural form of energy is energies
The plural form of loss is losses
The plural form of family is families
The plural form of agency is
2024-07-29 00:45:53 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-29 00:48:14 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2134,  0.5972, -0.2969,  ..., -0.2573, -0.0778, -0.1119],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.6875, -0.4482,  3.1797,  ..., -1.5098,  0.2773, -3.2227],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0537,  0.0146, -0.0132,  ..., -0.0086, -0.0088, -0.0010],
        [-0.0004,  0.0557,  0.0074,  ...,  0.0177,  0.0042,  0.0271],
        [ 0.0073,  0.0136,  0.0503,  ...,  0.0116,  0.0083,  0.0355],
        ...,
        [ 0.0296,  0.0260, -0.0007,  ...,  0.0648,  0.0088,  0.0230],
        [-0.0365,  0.0359,  0.0035,  ...,  0.0165,  0.0722,  0.0022],
        [ 0.0334, -0.0275,  0.0140,  ..., -0.0044, -0.0038,  0.0915]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.2461, -0.5176,  2.9805,  ..., -1.3701, -0.1458, -3.2129]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 00:48:15 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of wife is wives
The plural form of business is businesses
The plural form of child is children
The plural form of formula is formulae
The plural form of energy is energies
The plural form of loss is losses
The plural form of family is families
The plural form of agency is
2024-07-29 00:48:15 root INFO     [order_1_approx] starting weight calculation for The plural form of formula is formulae
The plural form of family is families
The plural form of energy is energies
The plural form of agency is agencies
The plural form of loss is losses
The plural form of business is businesses
The plural form of child is children
The plural form of wife is
2024-07-29 00:48:15 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-29 00:50:39 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1133,  0.1627, -0.1899,  ...,  0.0634, -0.2018,  0.0626],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.5859, -3.3945,  1.6631,  ..., -0.7881, -0.1250,  1.4434],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 4.8676e-02,  1.6518e-03,  5.5313e-03,  ..., -5.7755e-03,
          1.3580e-03,  4.0512e-03],
        [-5.0011e-03,  5.7037e-02,  1.1909e-02,  ...,  2.1667e-03,
          1.5198e-02, -6.0539e-03],
        [ 4.0436e-04, -8.0414e-03,  3.1738e-02,  ...,  1.8936e-02,
         -2.3834e-02,  3.3081e-02],
        ...,
        [-4.5433e-03,  2.3819e-02, -1.2985e-02,  ...,  5.6519e-02,
          1.4404e-02,  1.6647e-02],
        [ 1.2417e-03, -1.3084e-02, -4.0054e-05,  ..., -1.9821e-02,
          2.6321e-02, -8.7280e-03],
        [ 1.0208e-02,  9.6130e-04, -1.6647e-02,  ...,  5.3940e-03,
         -4.9210e-03,  3.7231e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.6855, -3.2695,  2.0859,  ..., -0.8945, -0.0942,  1.1201]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 00:50:41 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of formula is formulae
The plural form of family is families
The plural form of energy is energies
The plural form of agency is agencies
The plural form of loss is losses
The plural form of business is businesses
The plural form of child is children
The plural form of wife is
2024-07-29 00:50:41 root INFO     [order_1_approx] starting weight calculation for The plural form of business is businesses
The plural form of loss is losses
The plural form of wife is wives
The plural form of formula is formulae
The plural form of family is families
The plural form of agency is agencies
The plural form of energy is energies
The plural form of child is
2024-07-29 00:50:41 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-29 00:53:05 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2361, -0.1470, -0.1074,  ..., -0.2275, -0.5718,  0.1151],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.4375, -2.0312,  1.4082,  ..., -1.3457, -0.4927, -1.9551],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0552, -0.0110,  0.0137,  ..., -0.0038,  0.0074,  0.0061],
        [-0.0098,  0.0370,  0.0186,  ..., -0.0077,  0.0106,  0.0013],
        [ 0.0037, -0.0101,  0.0457,  ..., -0.0143, -0.0128,  0.0213],
        ...,
        [-0.0262,  0.0243, -0.0127,  ...,  0.0449,  0.0020,  0.0163],
        [-0.0024,  0.0264, -0.0226,  ...,  0.0195,  0.0339, -0.0104],
        [-0.0004, -0.0160,  0.0037,  ..., -0.0158, -0.0157,  0.0302]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.4199, -1.6357,  1.6660,  ..., -1.2051, -1.0605, -1.6504]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 00:53:06 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of business is businesses
The plural form of loss is losses
The plural form of wife is wives
The plural form of formula is formulae
The plural form of family is families
The plural form of agency is agencies
The plural form of energy is energies
The plural form of child is
2024-07-29 00:53:06 root INFO     [order_1_approx] starting weight calculation for The plural form of business is businesses
The plural form of formula is formulae
The plural form of child is children
The plural form of family is families
The plural form of energy is energies
The plural form of agency is agencies
The plural form of wife is wives
The plural form of loss is
2024-07-29 00:53:06 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-29 00:55:24 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1653,  0.1929,  0.0625,  ..., -0.1257,  0.3005,  0.0739],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.1250, -0.6797, -1.3633,  ..., -1.8682, -1.7422, -1.3389],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0652,  0.0040, -0.0116,  ..., -0.0035,  0.0144,  0.0116],
        [-0.0029,  0.0562,  0.0116,  ...,  0.0252,  0.0089,  0.0045],
        [-0.0061, -0.0053,  0.0552,  ..., -0.0300, -0.0057,  0.0201],
        ...,
        [ 0.0077,  0.0104, -0.0193,  ...,  0.0217,  0.0010,  0.0216],
        [-0.0128, -0.0077, -0.0122,  ..., -0.0208,  0.0468, -0.0155],
        [-0.0128, -0.0014,  0.0041,  ...,  0.0012, -0.0085,  0.0708]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.3672, -0.7842, -1.0117,  ..., -1.2812, -1.6621, -0.6509]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 00:55:25 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of business is businesses
The plural form of formula is formulae
The plural form of child is children
The plural form of family is families
The plural form of energy is energies
The plural form of agency is agencies
The plural form of wife is wives
The plural form of loss is
2024-07-29 00:55:25 root INFO     [order_1_approx] starting weight calculation for The plural form of energy is energies
The plural form of agency is agencies
The plural form of wife is wives
The plural form of child is children
The plural form of formula is formulae
The plural form of family is families
The plural form of loss is losses
The plural form of business is
2024-07-29 00:55:25 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-29 00:57:45 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2927,  0.3552, -0.0048,  ..., -0.1915, -0.4236, -0.0424],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.8965, -2.5410, -0.9165,  ...,  0.2764,  0.1360, -1.8066],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0624,  0.0177, -0.0223,  ...,  0.0035, -0.0037,  0.0168],
        [-0.0097,  0.0432,  0.0125,  ...,  0.0131, -0.0058,  0.0002],
        [-0.0139, -0.0009,  0.0590,  ...,  0.0135,  0.0117,  0.0456],
        ...,
        [-0.0028,  0.0083, -0.0005,  ...,  0.0324,  0.0026,  0.0069],
        [-0.0306,  0.0045, -0.0323,  ...,  0.0108,  0.0373,  0.0012],
        [-0.0063, -0.0009,  0.0051,  ...,  0.0015, -0.0018,  0.0437]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.1621, -2.2559, -0.9409,  ...,  0.3362, -0.1809, -1.5605]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 00:57:47 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of energy is energies
The plural form of agency is agencies
The plural form of wife is wives
The plural form of child is children
The plural form of formula is formulae
The plural form of family is families
The plural form of loss is losses
The plural form of business is
2024-07-29 00:57:47 root INFO     [order_1_approx] starting weight calculation for The plural form of energy is energies
The plural form of agency is agencies
The plural form of business is businesses
The plural form of wife is wives
The plural form of formula is formulae
The plural form of child is children
The plural form of loss is losses
The plural form of family is
2024-07-29 00:57:47 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-29 01:00:11 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 7.6416e-02, -1.5637e-01, -3.2373e-01,  ..., -2.9321e-01,
        -2.5781e-01, -1.8311e-04], device='cuda:0', dtype=torch.float16,
       grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.6855, -1.5420,  3.3164,  ..., -1.4727, -1.6777, -3.3965],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0550, -0.0119, -0.0098,  ..., -0.0315, -0.0142, -0.0117],
        [-0.0106,  0.0400,  0.0206,  ...,  0.0139,  0.0034, -0.0083],
        [-0.0095, -0.0037,  0.0382,  ..., -0.0044, -0.0032,  0.0173],
        ...,
        [ 0.0033,  0.0358, -0.0014,  ...,  0.0386,  0.0056,  0.0088],
        [-0.0116,  0.0184, -0.0230,  ..., -0.0168,  0.0253, -0.0064],
        [ 0.0218,  0.0062,  0.0120,  ...,  0.0045, -0.0030,  0.0346]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.2227, -1.1504,  3.3672,  ..., -1.2188, -1.7988, -2.9785]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 01:00:12 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of energy is energies
The plural form of agency is agencies
The plural form of business is businesses
The plural form of wife is wives
The plural form of formula is formulae
The plural form of child is children
The plural form of loss is losses
The plural form of family is
2024-07-29 01:00:13 root INFO     [order_1_approx] starting weight calculation for The plural form of energy is energies
The plural form of wife is wives
The plural form of agency is agencies
The plural form of child is children
The plural form of loss is losses
The plural form of business is businesses
The plural form of family is families
The plural form of formula is
2024-07-29 01:00:13 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-29 01:02:30 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4148,  0.0251, -0.0086,  ..., -0.0629, -0.3921,  0.3601],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.1089, -1.3047,  4.1406,  ..., -0.9619, -2.3672, -0.1777],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0792, -0.0238, -0.0185,  ..., -0.0619, -0.0100, -0.0282],
        [-0.0124,  0.1085,  0.0153,  ...,  0.0320, -0.0306,  0.0200],
        [ 0.0026, -0.0394,  0.0557,  ...,  0.0059, -0.0018,  0.0295],
        ...,
        [ 0.0252,  0.0261,  0.0158,  ...,  0.0848, -0.0131,  0.0173],
        [-0.0059, -0.0054, -0.0024,  ...,  0.0080,  0.0749,  0.0140],
        [ 0.0068,  0.0206,  0.0175,  ...,  0.0287, -0.0099,  0.0734]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.5479, -2.0293,  4.9336,  ..., -1.0732, -2.3652, -0.7969]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 01:02:30 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of energy is energies
The plural form of wife is wives
The plural form of agency is agencies
The plural form of child is children
The plural form of loss is losses
The plural form of business is businesses
The plural form of family is families
The plural form of formula is
2024-07-29 01:02:31 root INFO     [order_1_approx] starting weight calculation for The plural form of child is children
The plural form of agency is agencies
The plural form of business is businesses
The plural form of loss is losses
The plural form of formula is formulae
The plural form of wife is wives
The plural form of family is families
The plural form of energy is
2024-07-29 01:02:31 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-29 01:04:50 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0681, -0.0328, -0.1855,  ..., -0.1497, -0.0568,  0.1527],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.6758,  0.4746,  1.4473,  ..., -2.7031, -3.1953, -2.8320],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0448, -0.0064, -0.0192,  ..., -0.0177, -0.0117, -0.0037],
        [ 0.0127,  0.0699,  0.0221,  ...,  0.0549,  0.0048,  0.0176],
        [-0.0114,  0.0026,  0.0427,  ...,  0.0035, -0.0175,  0.0329],
        ...,
        [ 0.0039, -0.0109, -0.0186,  ...,  0.0280,  0.0147, -0.0041],
        [ 0.0066,  0.0296, -0.0034,  ..., -0.0219,  0.0325, -0.0054],
        [-0.0022, -0.0201,  0.0044,  ...,  0.0068, -0.0117,  0.0392]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.0020, -0.0410,  1.0850,  ..., -1.7861, -3.2969, -2.4727]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 01:04:51 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of child is children
The plural form of agency is agencies
The plural form of business is businesses
The plural form of loss is losses
The plural form of formula is formulae
The plural form of wife is wives
The plural form of family is families
The plural form of energy is
2024-07-29 01:04:51 root INFO     total operator prediction time: 1138.4781513214111 seconds
2024-07-29 01:04:51 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on meronyms - member
2024-07-29 01:04:51 root INFO     building operator meronyms - member
2024-07-29 01:04:51 root INFO     [order_1_approx] starting weight calculation for A secretary is a member of a staff
A calf is a member of a cattle
A sheep is a member of a flock
A cattle is a member of a herd
A nomad is a member of a horde
A song is a member of a album
A letter is a member of a alphabet
A acrobat is a member of a
2024-07-29 01:04:51 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-29 01:07:14 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3022, -0.3174, -0.0527,  ..., -0.0962, -0.4475,  0.3547],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.2031, -6.0078,  4.5508,  ...,  0.3745, -0.2715, -0.9043],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0390,  0.0015,  0.0060,  ...,  0.0076,  0.0134,  0.0067],
        [-0.0246,  0.0317,  0.0022,  ...,  0.0007, -0.0018, -0.0129],
        [-0.0092,  0.0107,  0.0513,  ..., -0.0162, -0.0007,  0.0077],
        ...,
        [ 0.0184,  0.0231,  0.0092,  ...,  0.0530, -0.0043, -0.0137],
        [ 0.0081,  0.0396, -0.0154,  ...,  0.0045,  0.0689,  0.0067],
        [-0.0123, -0.0323, -0.0140,  ...,  0.0064, -0.0263,  0.0456]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.0391, -5.9492,  4.2656,  ...,  0.3545, -0.4893, -0.6611]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 01:07:16 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A secretary is a member of a staff
A calf is a member of a cattle
A sheep is a member of a flock
A cattle is a member of a herd
A nomad is a member of a horde
A song is a member of a album
A letter is a member of a alphabet
A acrobat is a member of a
2024-07-29 01:07:17 root INFO     [order_1_approx] starting weight calculation for A calf is a member of a cattle
A sheep is a member of a flock
A secretary is a member of a staff
A nomad is a member of a horde
A acrobat is a member of a troupe
A cattle is a member of a herd
A song is a member of a album
A letter is a member of a
2024-07-29 01:07:17 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-29 01:09:38 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1593,  0.0940, -0.5259,  ..., -0.1621,  0.0092, -0.0997],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.0293, -2.6504, -0.6963,  ...,  0.1777, -2.7539, -2.0547],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0858,  0.0042, -0.0160,  ..., -0.0137,  0.0164,  0.0073],
        [-0.0033,  0.0650,  0.0004,  ..., -0.0023,  0.0278,  0.0084],
        [ 0.0278, -0.0366,  0.0245,  ...,  0.0322, -0.0350, -0.0160],
        ...,
        [ 0.0316,  0.0483,  0.0146,  ...,  0.0443,  0.0564, -0.0241],
        [-0.0022, -0.0310, -0.0257,  ...,  0.0483, -0.0023,  0.0157],
        [ 0.0104, -0.0191,  0.0164,  ..., -0.0096,  0.0599,  0.0562]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.0645, -2.9609,  0.1650,  ..., -0.3818, -1.8213, -1.9697]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 01:09:39 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A calf is a member of a cattle
A sheep is a member of a flock
A secretary is a member of a staff
A nomad is a member of a horde
A acrobat is a member of a troupe
A cattle is a member of a herd
A song is a member of a album
A letter is a member of a
2024-07-29 01:09:39 root INFO     [order_1_approx] starting weight calculation for A acrobat is a member of a troupe
A song is a member of a album
A sheep is a member of a flock
A calf is a member of a cattle
A letter is a member of a alphabet
A cattle is a member of a herd
A secretary is a member of a staff
A nomad is a member of a
2024-07-29 01:09:39 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-29 01:12:02 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1616,  0.0588, -0.4958,  ...,  0.2559, -0.2866,  0.3008],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.6465, -2.5254,  1.2549,  ..., -1.1055, -2.0039, -0.3413],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0723,  0.0001,  0.0237,  ..., -0.0093, -0.0349, -0.0092],
        [ 0.0164,  0.0394, -0.0046,  ...,  0.0004,  0.0063, -0.0312],
        [ 0.0082, -0.0106,  0.0529,  ..., -0.0024,  0.0005,  0.0057],
        ...,
        [ 0.0204,  0.0131, -0.0026,  ...,  0.0757,  0.0057, -0.0060],
        [ 0.0100,  0.0047, -0.0059,  ..., -0.0071,  0.0633, -0.0048],
        [ 0.0043, -0.0010, -0.0031,  ...,  0.0140, -0.0190,  0.0770]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.4111, -2.3320,  1.1885,  ..., -1.0215, -1.4883, -0.4849]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 01:12:03 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A acrobat is a member of a troupe
A song is a member of a album
A sheep is a member of a flock
A calf is a member of a cattle
A letter is a member of a alphabet
A cattle is a member of a herd
A secretary is a member of a staff
A nomad is a member of a
2024-07-29 01:12:03 root INFO     [order_1_approx] starting weight calculation for A sheep is a member of a flock
A song is a member of a album
A secretary is a member of a staff
A cattle is a member of a herd
A acrobat is a member of a troupe
A nomad is a member of a horde
A letter is a member of a alphabet
A calf is a member of a
2024-07-29 01:12:03 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-29 01:14:23 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2390, -0.4241,  0.0945,  ..., -0.0891, -0.2595,  0.4888],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 5.2734, -1.9688,  1.5537,  ..., -1.4258, -0.3262, -1.4365],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0406,  0.0186,  0.0005,  ...,  0.0203, -0.0134, -0.0029],
        [ 0.0169,  0.0585, -0.0184,  ...,  0.0198,  0.0108, -0.0241],
        [-0.0031, -0.0142,  0.0425,  ..., -0.0010, -0.0268, -0.0098],
        ...,
        [ 0.0140, -0.0003,  0.0119,  ...,  0.0461,  0.0186, -0.0269],
        [ 0.0092,  0.0230, -0.0085,  ...,  0.0163,  0.0534, -0.0157],
        [ 0.0070, -0.0162,  0.0027,  ..., -0.0047,  0.0075,  0.0490]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.9492, -2.1289,  1.7646,  ..., -1.1582, -0.5654, -1.5723]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 01:14:24 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A sheep is a member of a flock
A song is a member of a album
A secretary is a member of a staff
A cattle is a member of a herd
A acrobat is a member of a troupe
A nomad is a member of a horde
A letter is a member of a alphabet
A calf is a member of a
2024-07-29 01:14:24 root INFO     [order_1_approx] starting weight calculation for A acrobat is a member of a troupe
A song is a member of a album
A sheep is a member of a flock
A letter is a member of a alphabet
A secretary is a member of a staff
A calf is a member of a cattle
A nomad is a member of a horde
A cattle is a member of a
2024-07-29 01:14:24 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-29 01:16:43 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 4.8828e-04,  8.3984e-02, -6.4941e-02,  ..., -6.3818e-01,
        -1.9604e-01,  7.5073e-02], device='cuda:0', dtype=torch.float16,
       grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.7500, -3.0059,  3.6465,  ..., -3.2363, -1.6045, -2.0352],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0456, -0.0037,  0.0054,  ...,  0.0224,  0.0019,  0.0255],
        [ 0.0100,  0.0198,  0.0095,  ...,  0.0077, -0.0061, -0.0068],
        [ 0.0133,  0.0063,  0.0373,  ...,  0.0164, -0.0142,  0.0075],
        ...,
        [-0.0207, -0.0129, -0.0008,  ...,  0.0261,  0.0038, -0.0300],
        [-0.0146,  0.0323, -0.0127,  ..., -0.0092,  0.0406, -0.0017],
        [-0.0299, -0.0204,  0.0015,  ..., -0.0159, -0.0118,  0.0152]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.5977, -3.1113,  3.2500,  ..., -2.9043, -2.0449, -1.2930]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 01:16:44 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A acrobat is a member of a troupe
A song is a member of a album
A sheep is a member of a flock
A letter is a member of a alphabet
A secretary is a member of a staff
A calf is a member of a cattle
A nomad is a member of a horde
A cattle is a member of a
2024-07-29 01:16:44 root INFO     [order_1_approx] starting weight calculation for A letter is a member of a alphabet
A nomad is a member of a horde
A cattle is a member of a herd
A acrobat is a member of a troupe
A sheep is a member of a flock
A calf is a member of a cattle
A song is a member of a album
A secretary is a member of a
2024-07-29 01:16:44 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-29 01:19:06 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2915, -0.3413, -0.3262,  ..., -0.0101, -0.1885,  0.1018],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.6621, -3.3359,  2.7637,  ..., -0.1104, -0.1041, -1.6279],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0849, -0.0284,  0.0405,  ...,  0.0464,  0.0099, -0.0007],
        [ 0.0028,  0.0354, -0.0240,  ..., -0.0043,  0.0167, -0.0117],
        [ 0.0028,  0.0210,  0.0853,  ..., -0.0105,  0.0017, -0.0017],
        ...,
        [ 0.0283,  0.0352,  0.0382,  ...,  0.0688,  0.0778, -0.0124],
        [ 0.0287,  0.0172, -0.0018,  ...,  0.0353,  0.0801,  0.0002],
        [ 0.0042, -0.0293, -0.0173,  ..., -0.0169,  0.0012,  0.0757]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.7930, -3.1992,  2.8066,  ..., -0.3667,  0.1791, -1.6201]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 01:19:07 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A letter is a member of a alphabet
A nomad is a member of a horde
A cattle is a member of a herd
A acrobat is a member of a troupe
A sheep is a member of a flock
A calf is a member of a cattle
A song is a member of a album
A secretary is a member of a
2024-07-29 01:19:07 root INFO     [order_1_approx] starting weight calculation for A secretary is a member of a staff
A nomad is a member of a horde
A cattle is a member of a herd
A acrobat is a member of a troupe
A letter is a member of a alphabet
A calf is a member of a cattle
A song is a member of a album
A sheep is a member of a
2024-07-29 01:19:07 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-29 01:21:30 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1189,  0.0283, -0.1921,  ...,  0.1436, -0.1682,  0.4922],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.0039, -0.9141,  3.4336,  ..., -1.8340, -3.6973, -0.3750],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 6.4453e-02,  7.0343e-03,  1.0002e-02,  ...,  6.5804e-04,
         -1.4656e-02, -8.7261e-04],
        [ 3.5381e-03,  7.1411e-02, -3.5477e-03,  ...,  1.4069e-02,
         -2.3071e-02, -1.8829e-02],
        [ 1.2932e-02, -8.4686e-04,  4.4281e-02,  ..., -6.2141e-03,
          1.5259e-05,  2.1896e-03],
        ...,
        [ 1.1108e-02,  3.6346e-02,  9.2010e-03,  ...,  5.7800e-02,
          1.3428e-02, -2.2308e-02],
        [ 5.3406e-03,  2.6657e-02,  9.8877e-03,  ...,  1.2131e-02,
          4.9774e-02,  1.8478e-02],
        [-1.6754e-02, -2.0615e-02, -2.9106e-03,  ..., -2.3300e-02,
         -1.0017e-02,  2.6031e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.8535, -0.6353,  3.2051,  ..., -1.7520, -3.9785, -0.3596]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 01:21:31 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A secretary is a member of a staff
A nomad is a member of a horde
A cattle is a member of a herd
A acrobat is a member of a troupe
A letter is a member of a alphabet
A calf is a member of a cattle
A song is a member of a album
A sheep is a member of a
2024-07-29 01:21:31 root INFO     [order_1_approx] starting weight calculation for A cattle is a member of a herd
A sheep is a member of a flock
A letter is a member of a alphabet
A secretary is a member of a staff
A calf is a member of a cattle
A nomad is a member of a horde
A acrobat is a member of a troupe
A song is a member of a
2024-07-29 01:21:31 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-29 01:23:54 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2131,  0.0726,  0.2157,  ...,  0.2054, -0.3262, -0.2124],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.4985, -6.1367,  3.6621,  ..., -0.2905, -0.5400, -1.9238],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0413, -0.0037,  0.0080,  ...,  0.0143, -0.0172, -0.0105],
        [ 0.0030,  0.0452,  0.0075,  ...,  0.0209,  0.0154, -0.0129],
        [ 0.0188,  0.0123,  0.0539,  ..., -0.0131, -0.0003,  0.0107],
        ...,
        [ 0.0101,  0.0103,  0.0170,  ...,  0.0544,  0.0140, -0.0119],
        [-0.0011,  0.0024, -0.0427,  ...,  0.0034,  0.0448,  0.0034],
        [-0.0006, -0.0277,  0.0034,  ..., -0.0254,  0.0034,  0.0486]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.3459, -6.1445,  3.6934,  ..., -0.2695, -0.3701, -1.8984]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 01:23:55 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A cattle is a member of a herd
A sheep is a member of a flock
A letter is a member of a alphabet
A secretary is a member of a staff
A calf is a member of a cattle
A nomad is a member of a horde
A acrobat is a member of a troupe
A song is a member of a
2024-07-29 01:23:55 root INFO     total operator prediction time: 1144.1579732894897 seconds
2024-07-29 01:23:55 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on antonyms - binary
2024-07-29 01:23:55 root INFO     building operator antonyms - binary
2024-07-29 01:23:55 root INFO     [order_1_approx] starting weight calculation for The opposite of employ is dismiss
The opposite of ahead is behind
The opposite of after is before
The opposite of internal is external
The opposite of forward is backward
The opposite of previously is subsequently
The opposite of decrement is increment
The opposite of top is
2024-07-29 01:23:55 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-29 01:26:18 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1515, -0.3030,  0.1533,  ..., -0.1940,  0.0055,  0.1123],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.0039, -1.1104,  0.5732,  ..., -3.0039,  2.2461, -4.5625],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0639, -0.0422,  0.0157,  ..., -0.0087, -0.0006,  0.0226],
        [ 0.0133,  0.0815, -0.0144,  ..., -0.0070, -0.0105, -0.0387],
        [-0.0062, -0.0034,  0.0159,  ..., -0.0098, -0.0098,  0.0131],
        ...,
        [ 0.0178,  0.0163, -0.0010,  ...,  0.0739,  0.0184,  0.0086],
        [ 0.0092, -0.0121, -0.0028,  ...,  0.0021,  0.0418,  0.0034],
        [ 0.0305, -0.0156,  0.0049,  ..., -0.0093,  0.0249,  0.0147]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.9160, -0.4492, -0.3354,  ..., -2.8086,  1.5645, -4.8867]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 01:26:19 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of employ is dismiss
The opposite of ahead is behind
The opposite of after is before
The opposite of internal is external
The opposite of forward is backward
The opposite of previously is subsequently
The opposite of decrement is increment
The opposite of top is
2024-07-29 01:26:19 root INFO     [order_1_approx] starting weight calculation for The opposite of forward is backward
The opposite of employ is dismiss
The opposite of ahead is behind
The opposite of previously is subsequently
The opposite of decrement is increment
The opposite of top is bottom
The opposite of after is before
The opposite of internal is
2024-07-29 01:26:19 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-29 01:28:42 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0081, -0.2991, -0.0467,  ..., -0.1302,  0.1736,  0.3157],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.4336, -0.1021,  1.3633,  ..., -1.9404, -0.8755, -5.2344],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0634, -0.0137,  0.0082,  ..., -0.0118, -0.0416,  0.0110],
        [-0.0250,  0.0392,  0.0250,  ...,  0.0284,  0.0148,  0.0184],
        [-0.0256, -0.0110,  0.0359,  ..., -0.0112, -0.0174,  0.0011],
        ...,
        [ 0.0269,  0.0337,  0.0028,  ...,  0.0333,  0.0487, -0.0388],
        [ 0.0196,  0.0040, -0.0229,  ...,  0.0191,  0.0577, -0.0478],
        [-0.0057, -0.0008,  0.0082,  ..., -0.0049,  0.0063,  0.0864]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.7471,  0.0502,  0.5669,  ..., -2.3789, -1.4873, -4.9062]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 01:28:43 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of forward is backward
The opposite of employ is dismiss
The opposite of ahead is behind
The opposite of previously is subsequently
The opposite of decrement is increment
The opposite of top is bottom
The opposite of after is before
The opposite of internal is
2024-07-29 01:28:43 root INFO     [order_1_approx] starting weight calculation for The opposite of previously is subsequently
The opposite of after is before
The opposite of forward is backward
The opposite of top is bottom
The opposite of decrement is increment
The opposite of ahead is behind
The opposite of internal is external
The opposite of employ is
2024-07-29 01:28:44 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-29 01:31:06 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1124,  0.2983,  0.1532,  ..., -0.0645, -0.2988,  0.0203],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.0312, -2.6523,  1.4258,  ...,  1.3672, -2.8926, -0.9307],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 4.6600e-02, -7.3929e-03, -1.4503e-02,  ...,  2.7725e-02,
         -9.1400e-03,  1.0979e-02],
        [-3.4065e-03,  4.3457e-02,  1.1528e-02,  ...,  9.6359e-03,
         -1.7517e-02, -2.4094e-02],
        [ 1.5762e-02,  6.4011e-03,  2.8427e-02,  ...,  2.3003e-03,
          2.4261e-02,  3.9856e-02],
        ...,
        [ 1.6129e-02,  3.8147e-05,  2.4128e-04,  ...,  8.1558e-03,
          2.6108e-02, -2.5192e-02],
        [ 1.0597e-02,  1.0788e-02,  2.4139e-02,  ..., -1.3245e-02,
          3.8086e-02,  2.0844e-02],
        [ 3.3455e-03, -3.5645e-02, -3.0632e-03,  ...,  1.3161e-04,
          3.3325e-02,  1.4847e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.1475, -3.0137,  0.6714,  ...,  0.9619, -2.8691, -1.3320]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 01:31:07 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of previously is subsequently
The opposite of after is before
The opposite of forward is backward
The opposite of top is bottom
The opposite of decrement is increment
The opposite of ahead is behind
The opposite of internal is external
The opposite of employ is
2024-07-29 01:31:07 root INFO     [order_1_approx] starting weight calculation for The opposite of forward is backward
The opposite of employ is dismiss
The opposite of internal is external
The opposite of decrement is increment
The opposite of top is bottom
The opposite of previously is subsequently
The opposite of after is before
The opposite of ahead is
2024-07-29 01:31:07 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-29 01:33:25 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2135,  0.4531, -0.2651,  ..., -0.3062,  0.1318,  0.1870],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.1455, -2.6465,  0.7305,  ..., -4.4336, -1.1797, -2.6367],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0715, -0.0174, -0.0055,  ...,  0.0163, -0.0276, -0.0108],
        [-0.0011,  0.0573, -0.0152,  ...,  0.0108,  0.0094, -0.0157],
        [-0.0029, -0.0145,  0.0341,  ..., -0.0024, -0.0388,  0.0471],
        ...,
        [ 0.0022,  0.0196, -0.0096,  ...,  0.0323,  0.0418, -0.0494],
        [-0.0010,  0.0009,  0.0428,  ...,  0.0076,  0.0822, -0.0173],
        [-0.0013, -0.0263,  0.0143,  ...,  0.0185,  0.0108,  0.0217]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.9844, -2.2559,  0.4995,  ..., -3.7285, -1.0781, -2.5703]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 01:33:29 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of forward is backward
The opposite of employ is dismiss
The opposite of internal is external
The opposite of decrement is increment
The opposite of top is bottom
The opposite of previously is subsequently
The opposite of after is before
The opposite of ahead is
2024-07-29 01:33:29 root INFO     [order_1_approx] starting weight calculation for The opposite of employ is dismiss
The opposite of internal is external
The opposite of decrement is increment
The opposite of top is bottom
The opposite of ahead is behind
The opposite of forward is backward
The opposite of previously is subsequently
The opposite of after is
2024-07-29 01:33:29 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-29 01:35:48 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1523,  0.2573, -0.3464,  ..., -0.6221,  0.1177,  0.3459],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.1797, -1.9736, -0.4028,  ...,  0.9385, -0.5713, -4.0859],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0325,  0.0106,  0.0073,  ...,  0.0020,  0.0070,  0.0146],
        [-0.0078,  0.0330,  0.0038,  ...,  0.0358, -0.0044, -0.0168],
        [-0.0051,  0.0066,  0.0365,  ...,  0.0023, -0.0191,  0.0065],
        ...,
        [-0.0173, -0.0168,  0.0019,  ...,  0.0354,  0.0225, -0.0216],
        [ 0.0372, -0.0158,  0.0116,  ...,  0.0074,  0.0118, -0.0117],
        [-0.0023, -0.0043, -0.0235,  ..., -0.0015,  0.0105,  0.0212]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.8633, -1.5371, -0.5000,  ...,  0.2217, -0.6494, -4.0430]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 01:35:49 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of employ is dismiss
The opposite of internal is external
The opposite of decrement is increment
The opposite of top is bottom
The opposite of ahead is behind
The opposite of forward is backward
The opposite of previously is subsequently
The opposite of after is
2024-07-29 01:35:49 root INFO     [order_1_approx] starting weight calculation for The opposite of internal is external
The opposite of employ is dismiss
The opposite of after is before
The opposite of top is bottom
The opposite of previously is subsequently
The opposite of ahead is behind
The opposite of forward is backward
The opposite of decrement is
2024-07-29 01:35:49 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-29 01:38:11 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.4529,  0.4910, -0.1083,  ..., -0.0806, -0.2622,  0.1753],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.4214, -0.8867, -1.0146,  ...,  0.2749, -2.1758, -0.7397],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0221,  0.0044, -0.0020,  ...,  0.0058, -0.0245,  0.0231],
        [-0.0070,  0.0514, -0.0093,  ...,  0.0283, -0.0031, -0.0317],
        [ 0.0090, -0.0110,  0.0310,  ..., -0.0429, -0.0049,  0.0145],
        ...,
        [ 0.0172,  0.0381,  0.0075,  ...,  0.0205,  0.0610,  0.0231],
        [-0.0059, -0.0097,  0.0017,  ..., -0.0252,  0.0734,  0.0065],
        [-0.0017, -0.0022, -0.0119,  ..., -0.0128, -0.0056,  0.0612]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.2095, -1.3867, -1.6660,  ..., -0.4155, -2.4316, -0.8862]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 01:38:12 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of internal is external
The opposite of employ is dismiss
The opposite of after is before
The opposite of top is bottom
The opposite of previously is subsequently
The opposite of ahead is behind
The opposite of forward is backward
The opposite of decrement is
2024-07-29 01:38:12 root INFO     [order_1_approx] starting weight calculation for The opposite of forward is backward
The opposite of internal is external
The opposite of decrement is increment
The opposite of after is before
The opposite of employ is dismiss
The opposite of ahead is behind
The opposite of top is bottom
The opposite of previously is
2024-07-29 01:38:12 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-29 01:40:36 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0948, -0.1445, -0.2095,  ..., -0.3018, -0.4922,  0.2285],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.4590, -2.8828, -0.1152,  ..., -1.6201, -1.9336, -4.5703],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0536, -0.0286, -0.0020,  ...,  0.0126, -0.0050,  0.0459],
        [-0.0284,  0.0521, -0.0292,  ...,  0.0581,  0.0070,  0.0085],
        [-0.0075, -0.0177,  0.0544,  ...,  0.0028,  0.0087, -0.0111],
        ...,
        [-0.0123,  0.0145, -0.0258,  ...,  0.0273,  0.0200, -0.0239],
        [ 0.0266, -0.0216,  0.0425,  ...,  0.0273,  0.0540, -0.0121],
        [-0.0261,  0.0309, -0.0417,  ..., -0.0128, -0.0090,  0.0323]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.8418, -2.2305, -0.4180,  ..., -1.1318, -2.2129, -4.5859]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 01:40:37 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of forward is backward
The opposite of internal is external
The opposite of decrement is increment
The opposite of after is before
The opposite of employ is dismiss
The opposite of ahead is behind
The opposite of top is bottom
The opposite of previously is
2024-07-29 01:40:37 root INFO     [order_1_approx] starting weight calculation for The opposite of top is bottom
The opposite of employ is dismiss
The opposite of ahead is behind
The opposite of after is before
The opposite of decrement is increment
The opposite of internal is external
The opposite of previously is subsequently
The opposite of forward is
2024-07-29 01:40:37 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-29 01:42:58 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2612, -0.0042, -0.5273,  ..., -0.3638,  0.3672,  0.5908],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.3535, -2.5117,  0.5884,  ..., -1.8223, -2.6758, -2.1406],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 6.9702e-02, -6.1340e-03,  2.3941e-02,  ..., -2.2812e-03,
         -2.1347e-02,  2.7580e-03],
        [-2.9278e-03,  8.2581e-02,  1.0292e-02,  ...,  1.2375e-02,
         -6.0618e-05, -9.8228e-05],
        [ 9.8991e-04, -2.9526e-02,  4.3549e-02,  ...,  8.9874e-03,
         -2.7115e-02, -1.2505e-02],
        ...,
        [ 9.3842e-03,  1.3351e-04, -3.4241e-02,  ...,  6.2683e-02,
          4.6509e-02, -6.5269e-03],
        [-7.1716e-03,  1.4343e-02,  1.9875e-03,  ..., -1.0956e-02,
          7.4524e-02, -1.2253e-02],
        [-5.1193e-03, -3.3081e-02, -5.5695e-03,  ...,  7.3242e-03,
          2.8000e-03,  3.8849e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.8877, -2.8223,  0.9932,  ..., -2.1660, -3.2344, -2.4727]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 01:42:59 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of top is bottom
The opposite of employ is dismiss
The opposite of ahead is behind
The opposite of after is before
The opposite of decrement is increment
The opposite of internal is external
The opposite of previously is subsequently
The opposite of forward is
2024-07-29 01:42:59 root INFO     total operator prediction time: 1144.3012375831604 seconds
2024-07-29 01:42:59 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on hyponyms - misc
2024-07-29 01:42:59 root INFO     building operator hyponyms - misc
2024-07-29 01:43:00 root INFO     [order_1_approx] starting weight calculation for A more specific term for a weapon is gun
A more specific term for a emotion is anger
A more specific term for a spice is pepper
A more specific term for a cloud is thundercloud
A more specific term for a sweater is turtleneck
A more specific term for a poem is haiku
A more specific term for a color is white
A more specific term for a seat is
2024-07-29 01:43:00 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-29 01:45:19 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1345, -0.2454, -0.4238,  ...,  0.2915, -0.1935,  0.0754],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.7393, -4.9258,  4.1328,  ...,  2.5273, -2.5801,  0.9746],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0911, -0.0133,  0.0006,  ...,  0.0099, -0.0380, -0.0066],
        [-0.0290,  0.1000, -0.0008,  ...,  0.0199,  0.0444,  0.0121],
        [ 0.0173, -0.0362,  0.0584,  ..., -0.0064, -0.0488,  0.0035],
        ...,
        [ 0.0349,  0.0398, -0.0025,  ...,  0.0684,  0.0055,  0.0012],
        [-0.0063,  0.0072, -0.0126,  ...,  0.0244, -0.0118, -0.0032],
        [ 0.0155,  0.0132,  0.0013,  ...,  0.0100,  0.0084,  0.0506]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.8008, -5.5234,  3.8828,  ...,  2.3906, -2.6191,  1.1514]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 01:45:20 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more specific term for a weapon is gun
A more specific term for a emotion is anger
A more specific term for a spice is pepper
A more specific term for a cloud is thundercloud
A more specific term for a sweater is turtleneck
A more specific term for a poem is haiku
A more specific term for a color is white
A more specific term for a seat is
2024-07-29 01:45:20 root INFO     [order_1_approx] starting weight calculation for A more specific term for a seat is chair
A more specific term for a cloud is thundercloud
A more specific term for a spice is pepper
A more specific term for a weapon is gun
A more specific term for a emotion is anger
A more specific term for a color is white
A more specific term for a sweater is turtleneck
A more specific term for a poem is
2024-07-29 01:45:20 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-29 01:47:43 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0229,  0.1186, -0.0221,  ..., -0.0042, -0.4077,  0.0983],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.4395, -6.8203,  5.9453,  ...,  1.8457, -0.5010, -1.4873],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0585,  0.0034,  0.0066,  ...,  0.0057, -0.0339,  0.0325],
        [ 0.0073,  0.0517,  0.0035,  ...,  0.0355,  0.0275,  0.0226],
        [ 0.0121, -0.0099,  0.0719,  ...,  0.0026, -0.0248, -0.0219],
        ...,
        [ 0.0078,  0.0132,  0.0065,  ...,  0.0556,  0.0157, -0.0102],
        [-0.0162,  0.0119, -0.0120,  ...,  0.0070,  0.0573, -0.0185],
        [-0.0237,  0.0136, -0.0157,  ..., -0.0105,  0.0187,  0.0781]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.8613, -7.2812,  5.4805,  ...,  1.5303, -0.5439, -1.5430]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 01:47:44 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more specific term for a seat is chair
A more specific term for a cloud is thundercloud
A more specific term for a spice is pepper
A more specific term for a weapon is gun
A more specific term for a emotion is anger
A more specific term for a color is white
A more specific term for a sweater is turtleneck
A more specific term for a poem is
2024-07-29 01:47:44 root INFO     [order_1_approx] starting weight calculation for A more specific term for a poem is haiku
A more specific term for a color is white
A more specific term for a emotion is anger
A more specific term for a weapon is gun
A more specific term for a spice is pepper
A more specific term for a cloud is thundercloud
A more specific term for a seat is chair
A more specific term for a sweater is
2024-07-29 01:47:44 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-29 01:50:07 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0285, -0.0956,  0.2209,  ...,  0.1248, -0.6909, -0.0516],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.6436, -6.9609, -1.2852,  ...,  2.0918, -3.2754,  2.9609],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0465,  0.0060,  0.0101,  ...,  0.0239,  0.0228,  0.0231],
        [-0.0180,  0.0396,  0.0164,  ..., -0.0064, -0.0104, -0.0070],
        [ 0.0227, -0.0221,  0.0506,  ...,  0.0311, -0.0202,  0.0205],
        ...,
        [ 0.0459,  0.0242,  0.0031,  ...,  0.0714,  0.0050,  0.0029],
        [ 0.0059,  0.0056, -0.0040,  ...,  0.0241,  0.0497, -0.0327],
        [-0.0154, -0.0052, -0.0014,  ..., -0.0264, -0.0103,  0.0303]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.4922, -6.7500, -1.3848,  ...,  1.6895, -3.2578,  2.7305]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 01:50:17 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more specific term for a poem is haiku
A more specific term for a color is white
A more specific term for a emotion is anger
A more specific term for a weapon is gun
A more specific term for a spice is pepper
A more specific term for a cloud is thundercloud
A more specific term for a seat is chair
A more specific term for a sweater is
2024-07-29 01:50:17 root INFO     [order_1_approx] starting weight calculation for A more specific term for a seat is chair
A more specific term for a sweater is turtleneck
A more specific term for a spice is pepper
A more specific term for a weapon is gun
A more specific term for a emotion is anger
A more specific term for a poem is haiku
A more specific term for a cloud is thundercloud
A more specific term for a color is
2024-07-29 01:50:17 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-29 01:52:38 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.3606, -0.3025,  0.0368,  ...,  0.5605, -0.1534, -0.2590],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-2.5430, -2.6484,  0.8604,  ...,  1.6328, -2.2559,  0.8804],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0485, -0.0065,  0.0084,  ...,  0.0139,  0.0006,  0.0156],
        [ 0.0203,  0.0507,  0.0242,  ...,  0.0315,  0.0216, -0.0073],
        [-0.0179,  0.0052,  0.0615,  ..., -0.0106, -0.0208,  0.0190],
        ...,
        [ 0.0221,  0.0107, -0.0093,  ...,  0.0569,  0.0055, -0.0029],
        [-0.0240,  0.0056,  0.0089,  ..., -0.0014,  0.0409, -0.0011],
        [ 0.0076,  0.0061, -0.0271,  ...,  0.0034,  0.0251,  0.0325]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-2.6777, -2.2832,  0.5449,  ...,  1.8535, -2.7754,  1.3252]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 01:52:39 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more specific term for a seat is chair
A more specific term for a sweater is turtleneck
A more specific term for a spice is pepper
A more specific term for a weapon is gun
A more specific term for a emotion is anger
A more specific term for a poem is haiku
A more specific term for a cloud is thundercloud
A more specific term for a color is
2024-07-29 01:52:40 root INFO     [order_1_approx] starting weight calculation for A more specific term for a spice is pepper
A more specific term for a cloud is thundercloud
A more specific term for a sweater is turtleneck
A more specific term for a weapon is gun
A more specific term for a color is white
A more specific term for a seat is chair
A more specific term for a poem is haiku
A more specific term for a emotion is
2024-07-29 01:52:40 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-29 01:55:01 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2140,  0.0079,  0.0932,  ...,  0.2842, -0.0867, -0.0542],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 5.3867, -3.7109,  1.8711,  ...,  0.6470, -0.8320, -1.5547],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0373,  0.0307, -0.0191,  ..., -0.0146,  0.0178,  0.0148],
        [-0.0040,  0.0460,  0.0080,  ...,  0.0133,  0.0130, -0.0107],
        [-0.0229, -0.0154,  0.0392,  ...,  0.0072, -0.0278, -0.0148],
        ...,
        [ 0.0195,  0.0163,  0.0022,  ...,  0.0399, -0.0018, -0.0140],
        [-0.0237,  0.0094, -0.0020,  ..., -0.0082,  0.0188,  0.0146],
        [-0.0035, -0.0088, -0.0226,  ...,  0.0073, -0.0048,  0.0099]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.7891, -3.8301,  1.9121,  ...,  0.5596, -1.1182, -1.2773]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 01:55:02 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more specific term for a spice is pepper
A more specific term for a cloud is thundercloud
A more specific term for a sweater is turtleneck
A more specific term for a weapon is gun
A more specific term for a color is white
A more specific term for a seat is chair
A more specific term for a poem is haiku
A more specific term for a emotion is
2024-07-29 01:55:02 root INFO     [order_1_approx] starting weight calculation for A more specific term for a weapon is gun
A more specific term for a color is white
A more specific term for a poem is haiku
A more specific term for a seat is chair
A more specific term for a spice is pepper
A more specific term for a sweater is turtleneck
A more specific term for a emotion is anger
A more specific term for a cloud is
2024-07-29 01:55:02 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-29 01:57:24 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1281, -0.0622,  0.1440,  ..., -0.1675, -0.0521, -0.0328],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.1625, -3.6289,  4.1719,  ..., -0.5957, -1.3496,  1.3359],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0817,  0.0048,  0.0067,  ..., -0.0121,  0.0014,  0.0043],
        [ 0.0061,  0.0541, -0.0126,  ...,  0.0232, -0.0048, -0.0099],
        [ 0.0268, -0.0160,  0.0608,  ...,  0.0113, -0.0258,  0.0062],
        ...,
        [ 0.0034,  0.0157,  0.0099,  ...,  0.0662, -0.0115, -0.0021],
        [-0.0256, -0.0041,  0.0020,  ...,  0.0096,  0.0591, -0.0118],
        [-0.0019,  0.0049, -0.0136,  ..., -0.0072, -0.0237,  0.0378]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.0791, -4.2148,  3.6914,  ..., -0.2644, -1.3730,  1.3213]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 01:57:25 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more specific term for a weapon is gun
A more specific term for a color is white
A more specific term for a poem is haiku
A more specific term for a seat is chair
A more specific term for a spice is pepper
A more specific term for a sweater is turtleneck
A more specific term for a emotion is anger
A more specific term for a cloud is
2024-07-29 01:57:25 root INFO     [order_1_approx] starting weight calculation for A more specific term for a color is white
A more specific term for a cloud is thundercloud
A more specific term for a emotion is anger
A more specific term for a weapon is gun
A more specific term for a seat is chair
A more specific term for a sweater is turtleneck
A more specific term for a poem is haiku
A more specific term for a spice is
2024-07-29 01:57:25 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-29 01:59:49 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.3110,  0.2727, -0.1530,  ...,  0.1403, -0.0642, -0.3745],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.3320, -4.5625, -0.6338,  ..., -1.5781, -2.3887, -5.2500],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0598, -0.0080, -0.0087,  ...,  0.0016,  0.0139,  0.0006],
        [-0.0123,  0.0372,  0.0055,  ...,  0.0101,  0.0143,  0.0108],
        [-0.0096, -0.0310,  0.0479,  ...,  0.0280,  0.0053,  0.0134],
        ...,
        [ 0.0064,  0.0182,  0.0181,  ...,  0.0501,  0.0143, -0.0067],
        [-0.0055,  0.0028, -0.0040,  ..., -0.0099,  0.0455, -0.0004],
        [ 0.0228, -0.0085,  0.0132,  ..., -0.0020,  0.0123,  0.0243]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.1230, -4.4023, -0.4570,  ..., -1.6680, -2.7383, -5.0039]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 01:59:49 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more specific term for a color is white
A more specific term for a cloud is thundercloud
A more specific term for a emotion is anger
A more specific term for a weapon is gun
A more specific term for a seat is chair
A more specific term for a sweater is turtleneck
A more specific term for a poem is haiku
A more specific term for a spice is
2024-07-29 01:59:50 root INFO     [order_1_approx] starting weight calculation for A more specific term for a color is white
A more specific term for a cloud is thundercloud
A more specific term for a poem is haiku
A more specific term for a seat is chair
A more specific term for a spice is pepper
A more specific term for a emotion is anger
A more specific term for a sweater is turtleneck
A more specific term for a weapon is
2024-07-29 01:59:50 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-29 02:02:13 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1046,  0.1093,  0.3301,  ..., -0.1488, -0.3418, -0.0604],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-2.6953, -6.9883, -0.6797,  ...,  1.0693, -3.3750,  1.5117],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0413, -0.0039,  0.0049,  ..., -0.0009,  0.0142,  0.0096],
        [-0.0016,  0.0266,  0.0079,  ..., -0.0084,  0.0036, -0.0230],
        [-0.0011, -0.0064,  0.0598,  ...,  0.0123,  0.0047, -0.0003],
        ...,
        [ 0.0119,  0.0030, -0.0009,  ...,  0.0460,  0.0126,  0.0117],
        [-0.0359, -0.0043,  0.0075,  ...,  0.0079,  0.0221, -0.0227],
        [ 0.0216,  0.0066,  0.0117,  ..., -0.0082, -0.0087,  0.0365]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-2.5645, -6.7695, -0.7681,  ...,  0.8438, -3.4082,  1.6572]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 02:02:14 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more specific term for a color is white
A more specific term for a cloud is thundercloud
A more specific term for a poem is haiku
A more specific term for a seat is chair
A more specific term for a spice is pepper
A more specific term for a emotion is anger
A more specific term for a sweater is turtleneck
A more specific term for a weapon is
2024-07-29 02:02:14 root INFO     total operator prediction time: 1154.7410969734192 seconds
2024-07-29 02:02:14 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on hypernyms - animals
2024-07-29 02:02:14 root INFO     building operator hypernyms - animals
2024-07-29 02:02:14 root INFO     [order_1_approx] starting weight calculation for The anaconda falls into the category of snake
The mouse falls into the category of rodent
The orangutan falls into the category of primate
The gibbon falls into the category of primate
The velociraptor falls into the category of dinosaur
The duck falls into the category of fowl
The dog falls into the category of canine
The beaver falls into the category of
2024-07-29 02:02:14 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-29 02:04:37 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1636, -0.1552, -0.0769,  ...,  0.1311, -0.6416,  0.1992],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.5371, -5.0703,  1.9482,  ..., -1.0488, -6.8633, -1.8496],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0453, -0.0096,  0.0012,  ..., -0.0132, -0.0208,  0.0139],
        [ 0.0284,  0.0347, -0.0009,  ...,  0.0130,  0.0094, -0.0461],
        [-0.0325,  0.0106,  0.0748,  ..., -0.0275,  0.0005,  0.0131],
        ...,
        [-0.0025,  0.0144,  0.0122,  ...,  0.0402,  0.0016, -0.0071],
        [ 0.0156, -0.0136,  0.0088,  ..., -0.0088,  0.0627,  0.0047],
        [-0.0065, -0.0117, -0.0118,  ..., -0.0474, -0.0085,  0.0388]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.2148, -4.4648,  1.7402,  ..., -1.1045, -6.8555, -1.3711]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 02:04:38 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The anaconda falls into the category of snake
The mouse falls into the category of rodent
The orangutan falls into the category of primate
The gibbon falls into the category of primate
The velociraptor falls into the category of dinosaur
The duck falls into the category of fowl
The dog falls into the category of canine
The beaver falls into the category of
2024-07-29 02:04:38 root INFO     [order_1_approx] starting weight calculation for The gibbon falls into the category of primate
The beaver falls into the category of rodent
The mouse falls into the category of rodent
The duck falls into the category of fowl
The anaconda falls into the category of snake
The dog falls into the category of canine
The orangutan falls into the category of primate
The velociraptor falls into the category of
2024-07-29 02:04:38 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-29 02:06:58 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1398, -0.3354, -0.8174,  ...,  0.3850, -0.5293, -0.0150],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.6631, -5.9805,  2.6934,  ..., -1.3047, -7.7656,  0.9971],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0361, -0.0029, -0.0046,  ...,  0.0005, -0.0049, -0.0053],
        [ 0.0055,  0.0292,  0.0117,  ...,  0.0089,  0.0137, -0.0264],
        [ 0.0060,  0.0043,  0.0220,  ..., -0.0048, -0.0282,  0.0059],
        ...,
        [-0.0013, -0.0080,  0.0070,  ...,  0.0297,  0.0120, -0.0015],
        [-0.0074, -0.0015,  0.0079,  ...,  0.0085,  0.0301, -0.0131],
        [ 0.0002, -0.0111, -0.0095,  ..., -0.0017, -0.0036,  0.0321]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.4102, -5.9531,  2.6582,  ..., -1.2266, -8.3203,  1.1992]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 02:07:01 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The gibbon falls into the category of primate
The beaver falls into the category of rodent
The mouse falls into the category of rodent
The duck falls into the category of fowl
The anaconda falls into the category of snake
The dog falls into the category of canine
The orangutan falls into the category of primate
The velociraptor falls into the category of
2024-07-29 02:07:01 root INFO     [order_1_approx] starting weight calculation for The velociraptor falls into the category of dinosaur
The orangutan falls into the category of primate
The gibbon falls into the category of primate
The beaver falls into the category of rodent
The duck falls into the category of fowl
The anaconda falls into the category of snake
The mouse falls into the category of rodent
The dog falls into the category of
2024-07-29 02:07:01 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-29 02:09:23 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0854, -0.0455,  0.0608,  ...,  0.3162, -0.3303,  0.1792],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.1460, -4.6484,  1.8594,  ..., -2.1523, -5.5859, -0.2383],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0504,  0.0141, -0.0114,  ..., -0.0101,  0.0059, -0.0031],
        [ 0.0249,  0.0232, -0.0033,  ..., -0.0006, -0.0035, -0.0173],
        [-0.0159,  0.0150,  0.0568,  ..., -0.0217,  0.0101, -0.0007],
        ...,
        [ 0.0079,  0.0057,  0.0109,  ...,  0.0073,  0.0099,  0.0058],
        [-0.0043,  0.0045,  0.0048,  ...,  0.0093,  0.0422, -0.0026],
        [ 0.0132, -0.0172, -0.0194,  ...,  0.0079, -0.0132,  0.0392]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.2161, -3.8223,  1.0059,  ..., -2.0586, -5.5781,  0.4966]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 02:09:24 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The velociraptor falls into the category of dinosaur
The orangutan falls into the category of primate
The gibbon falls into the category of primate
The beaver falls into the category of rodent
The duck falls into the category of fowl
The anaconda falls into the category of snake
The mouse falls into the category of rodent
The dog falls into the category of
2024-07-29 02:09:24 root INFO     [order_1_approx] starting weight calculation for The duck falls into the category of fowl
The beaver falls into the category of rodent
The mouse falls into the category of rodent
The anaconda falls into the category of snake
The velociraptor falls into the category of dinosaur
The gibbon falls into the category of primate
The dog falls into the category of canine
The orangutan falls into the category of
2024-07-29 02:09:24 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-29 02:11:47 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1736, -0.5264, -0.2125,  ...,  0.3457, -0.6260,  0.0635],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.1697, -4.3516, -0.1631,  ..., -4.5156, -7.0391,  1.9922],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0273, -0.0031,  0.0090,  ...,  0.0027, -0.0100, -0.0069],
        [ 0.0063,  0.0090,  0.0006,  ..., -0.0017,  0.0124, -0.0087],
        [-0.0019,  0.0086,  0.0182,  ..., -0.0037, -0.0037, -0.0056],
        ...,
        [ 0.0045,  0.0028,  0.0032,  ...,  0.0152,  0.0027,  0.0048],
        [ 0.0027, -0.0050, -0.0022,  ..., -0.0004,  0.0249,  0.0017],
        [ 0.0071, -0.0093, -0.0023,  ...,  0.0025, -0.0015,  0.0214]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.3235, -4.1406, -0.2773,  ..., -4.5859, -7.0938,  2.0645]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 02:11:48 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The duck falls into the category of fowl
The beaver falls into the category of rodent
The mouse falls into the category of rodent
The anaconda falls into the category of snake
The velociraptor falls into the category of dinosaur
The gibbon falls into the category of primate
The dog falls into the category of canine
The orangutan falls into the category of
2024-07-29 02:11:48 root INFO     [order_1_approx] starting weight calculation for The anaconda falls into the category of snake
The dog falls into the category of canine
The beaver falls into the category of rodent
The mouse falls into the category of rodent
The velociraptor falls into the category of dinosaur
The duck falls into the category of fowl
The orangutan falls into the category of primate
The gibbon falls into the category of
2024-07-29 02:11:48 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-29 02:14:09 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0950, -0.4243,  0.3420,  ...,  0.1997, -0.7998,  0.6050],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.4512, -3.3594,  1.6855,  ..., -4.3398, -6.8984,  0.8984],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0747,  0.0087, -0.0082,  ..., -0.0166, -0.0045, -0.0057],
        [ 0.0067,  0.0443, -0.0158,  ..., -0.0025,  0.0171, -0.0195],
        [-0.0056,  0.0132,  0.0535,  ..., -0.0044, -0.0043, -0.0127],
        ...,
        [ 0.0250,  0.0272, -0.0060,  ...,  0.0406,  0.0036,  0.0045],
        [ 0.0032, -0.0097,  0.0037,  ...,  0.0017,  0.0452, -0.0156],
        [-0.0113, -0.0026, -0.0095,  ...,  0.0012, -0.0068,  0.0517]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.6489, -3.3379,  1.2979,  ..., -4.2070, -7.2383,  0.7769]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 02:14:11 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The anaconda falls into the category of snake
The dog falls into the category of canine
The beaver falls into the category of rodent
The mouse falls into the category of rodent
The velociraptor falls into the category of dinosaur
The duck falls into the category of fowl
The orangutan falls into the category of primate
The gibbon falls into the category of
2024-07-29 02:14:11 root INFO     [order_1_approx] starting weight calculation for The anaconda falls into the category of snake
The dog falls into the category of canine
The gibbon falls into the category of primate
The duck falls into the category of fowl
The beaver falls into the category of rodent
The velociraptor falls into the category of dinosaur
The orangutan falls into the category of primate
The mouse falls into the category of
2024-07-29 02:14:11 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-29 02:16:33 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.4172, -0.1367,  0.0904,  ...,  0.3003, -0.2378, -0.0959],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.5430, -3.8867,  2.0898,  ..., -3.5293, -6.2734, -0.3164],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 4.4281e-02, -1.9516e-02,  9.5367e-03,  ..., -7.2861e-03,
         -1.0727e-02,  7.6294e-05],
        [ 4.5776e-05,  3.7994e-02,  1.0101e-02,  ..., -9.4757e-03,
          2.0111e-02, -2.2705e-02],
        [ 1.7578e-02,  8.7662e-03,  5.6458e-02,  ..., -2.2949e-02,
         -4.7112e-03, -1.4820e-03],
        ...,
        [ 2.4605e-04,  6.0654e-04,  3.6182e-03,  ...,  4.0497e-02,
          1.1780e-02, -7.0953e-03],
        [ 9.2316e-03,  7.6904e-03, -1.4618e-02,  ..., -1.3710e-02,
          6.0577e-02,  3.7670e-03],
        [-2.5238e-02, -2.8336e-02, -6.5002e-03,  ..., -2.8610e-03,
         -5.9738e-03,  5.1300e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.2129, -3.7188,  1.4990,  ..., -3.4141, -6.6602,  0.2119]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 02:16:34 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The anaconda falls into the category of snake
The dog falls into the category of canine
The gibbon falls into the category of primate
The duck falls into the category of fowl
The beaver falls into the category of rodent
The velociraptor falls into the category of dinosaur
The orangutan falls into the category of primate
The mouse falls into the category of
2024-07-29 02:16:35 root INFO     [order_1_approx] starting weight calculation for The dog falls into the category of canine
The mouse falls into the category of rodent
The velociraptor falls into the category of dinosaur
The anaconda falls into the category of snake
The orangutan falls into the category of primate
The gibbon falls into the category of primate
The beaver falls into the category of rodent
The duck falls into the category of
2024-07-29 02:16:35 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-29 02:18:50 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1714, -0.2737,  0.1025,  ...,  0.2430, -0.3779,  0.2050],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.3936, -2.4199,  3.9922,  ..., -1.4727, -7.9297,  1.4209],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0548, -0.0155, -0.0199,  ...,  0.0052, -0.0020, -0.0101],
        [ 0.0276,  0.0180,  0.0189,  ...,  0.0349, -0.0028, -0.0260],
        [-0.0026,  0.0124,  0.0331,  ..., -0.0239, -0.0163,  0.0121],
        ...,
        [-0.0003, -0.0081,  0.0125,  ...,  0.0240,  0.0003, -0.0075],
        [ 0.0041, -0.0016, -0.0043,  ..., -0.0063,  0.0285,  0.0079],
        [ 0.0009, -0.0190, -0.0084,  ..., -0.0002,  0.0020,  0.0238]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.8535, -2.2598,  3.4766,  ..., -1.4033, -8.0391,  1.6475]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 02:18:51 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The dog falls into the category of canine
The mouse falls into the category of rodent
The velociraptor falls into the category of dinosaur
The anaconda falls into the category of snake
The orangutan falls into the category of primate
The gibbon falls into the category of primate
The beaver falls into the category of rodent
The duck falls into the category of
2024-07-29 02:18:51 root INFO     [order_1_approx] starting weight calculation for The beaver falls into the category of rodent
The orangutan falls into the category of primate
The dog falls into the category of canine
The velociraptor falls into the category of dinosaur
The mouse falls into the category of rodent
The gibbon falls into the category of primate
The duck falls into the category of fowl
The anaconda falls into the category of
2024-07-29 02:18:51 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-29 02:21:10 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1880, -0.4360, -0.3210,  ...,  0.0389, -0.4072,  0.0670],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.1934, -4.1641,  2.7852,  ..., -2.5391, -3.1797, -0.4419],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0499,  0.0090,  0.0017,  ..., -0.0076, -0.0052,  0.0158],
        [-0.0234,  0.0672,  0.0111,  ..., -0.0125,  0.0023, -0.0148],
        [ 0.0196,  0.0048,  0.0812,  ..., -0.0260, -0.0039, -0.0123],
        ...,
        [ 0.0070,  0.0139,  0.0167,  ...,  0.0709,  0.0143, -0.0032],
        [ 0.0161,  0.0106,  0.0027,  ...,  0.0138,  0.0451, -0.0087],
        [-0.0310, -0.0099, -0.0153,  ..., -0.0135,  0.0031,  0.0717]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.4131, -4.2734,  2.6191,  ..., -2.6445, -3.4922, -0.4399]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 02:21:11 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The beaver falls into the category of rodent
The orangutan falls into the category of primate
The dog falls into the category of canine
The velociraptor falls into the category of dinosaur
The mouse falls into the category of rodent
The gibbon falls into the category of primate
The duck falls into the category of fowl
The anaconda falls into the category of
2024-07-29 02:21:11 root INFO     total operator prediction time: 1136.8701810836792 seconds
2024-07-29 02:21:11 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on synonyms - intensity
2024-07-29 02:21:11 root INFO     building operator synonyms - intensity
2024-07-29 02:21:11 root INFO     [order_1_approx] starting weight calculation for A more intense word for angry is furious
A more intense word for soon is immediately
A more intense word for boring is tedious
A more intense word for necessary is essential
A more intense word for doze is sleep
A more intense word for dislike is hate
A more intense word for dinner is feast
A more intense word for snack is
2024-07-29 02:21:11 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-29 02:23:33 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0571, -0.1804, -0.0729,  ..., -0.0967, -0.5176, -0.2213],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.3086, -2.4297, -0.6426,  ...,  1.6914, -6.4219,  0.2734],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0357, -0.0153,  0.0295,  ...,  0.0007, -0.0110,  0.0464],
        [ 0.0197,  0.0665,  0.0070,  ..., -0.0224, -0.0026, -0.0124],
        [-0.0183, -0.0306,  0.0752,  ...,  0.0117, -0.0376,  0.0110],
        ...,
        [ 0.0260,  0.0208,  0.0240,  ...,  0.0533, -0.0132, -0.0065],
        [ 0.0111,  0.0113,  0.0307,  ...,  0.0205,  0.0266, -0.0141],
        [-0.0318, -0.0023, -0.0184,  ...,  0.0043,  0.0197,  0.0536]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.8906, -2.2129, -0.3174,  ...,  1.9531, -6.4727,  0.4675]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 02:23:40 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more intense word for angry is furious
A more intense word for soon is immediately
A more intense word for boring is tedious
A more intense word for necessary is essential
A more intense word for doze is sleep
A more intense word for dislike is hate
A more intense word for dinner is feast
A more intense word for snack is
2024-07-29 02:23:40 root INFO     [order_1_approx] starting weight calculation for A more intense word for boring is tedious
A more intense word for angry is furious
A more intense word for dinner is feast
A more intense word for necessary is essential
A more intense word for dislike is hate
A more intense word for snack is meal
A more intense word for soon is immediately
A more intense word for doze is
2024-07-29 02:23:40 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-29 02:25:59 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1294, -0.1360,  0.0476,  ..., -0.3394, -0.5547,  0.3057],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.9727, -3.4883,  2.1992,  ...,  0.7998, -2.0918,  0.4160],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0702,  0.0010,  0.0104,  ...,  0.0509, -0.0369,  0.0172],
        [ 0.0208,  0.0592,  0.0021,  ..., -0.0050,  0.0186,  0.0191],
        [-0.0717, -0.0369,  0.0406,  ...,  0.0058, -0.0449, -0.0385],
        ...,
        [ 0.0063,  0.0125, -0.0051,  ...,  0.0627,  0.0089, -0.0277],
        [ 0.0040, -0.0147, -0.0090,  ..., -0.0024, -0.0033, -0.0364],
        [ 0.0239, -0.0105, -0.0107,  ...,  0.0021, -0.0440,  0.0444]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.7061, -3.4551,  2.3086,  ...,  0.4102, -2.2754,  0.2395]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 02:26:00 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more intense word for boring is tedious
A more intense word for angry is furious
A more intense word for dinner is feast
A more intense word for necessary is essential
A more intense word for dislike is hate
A more intense word for snack is meal
A more intense word for soon is immediately
A more intense word for doze is
2024-07-29 02:26:00 root INFO     [order_1_approx] starting weight calculation for A more intense word for necessary is essential
A more intense word for snack is meal
A more intense word for doze is sleep
A more intense word for soon is immediately
A more intense word for dinner is feast
A more intense word for dislike is hate
A more intense word for boring is tedious
A more intense word for angry is
2024-07-29 02:26:00 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-29 02:28:18 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0451,  0.0451, -0.3633,  ..., -0.1915, -0.2910,  0.3801],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.6230, -5.9531, -0.8838,  ..., -2.2305, -1.5049, -0.0996],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0582,  0.0238,  0.0085,  ..., -0.0085, -0.0015,  0.0117],
        [ 0.0132,  0.0267, -0.0074,  ...,  0.0063, -0.0008,  0.0105],
        [ 0.0127,  0.0121,  0.0607,  ..., -0.0148, -0.0020,  0.0065],
        ...,
        [ 0.0162,  0.0191,  0.0020,  ...,  0.0297,  0.0006, -0.0104],
        [-0.0052,  0.0013, -0.0106,  ...,  0.0126,  0.0528, -0.0205],
        [ 0.0131, -0.0040, -0.0059,  ...,  0.0021, -0.0145,  0.0292]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.4453, -5.7930, -0.6133,  ..., -2.1914, -1.3750, -0.2416]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 02:28:19 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more intense word for necessary is essential
A more intense word for snack is meal
A more intense word for doze is sleep
A more intense word for soon is immediately
A more intense word for dinner is feast
A more intense word for dislike is hate
A more intense word for boring is tedious
A more intense word for angry is
2024-07-29 02:28:19 root INFO     [order_1_approx] starting weight calculation for A more intense word for necessary is essential
A more intense word for angry is furious
A more intense word for boring is tedious
A more intense word for dinner is feast
A more intense word for dislike is hate
A more intense word for snack is meal
A more intense word for doze is sleep
A more intense word for soon is
2024-07-29 02:28:19 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-29 02:30:41 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0013, -0.3530, -0.2703,  ..., -0.3425, -0.3630,  0.5225],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.4258, -3.3086, -1.9512,  ...,  0.2283, -4.1016, -0.9746],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0715,  0.0198, -0.0072,  ...,  0.0052,  0.0082,  0.0283],
        [-0.0266,  0.0432, -0.0143,  ...,  0.0194, -0.0347,  0.0013],
        [ 0.0057, -0.0312,  0.0530,  ...,  0.0231, -0.0039,  0.0066],
        ...,
        [-0.0269,  0.0221, -0.0090,  ...,  0.0657,  0.0164,  0.0011],
        [-0.0109, -0.0174, -0.0066,  ...,  0.0025,  0.0440, -0.0121],
        [ 0.0014, -0.0004, -0.0354,  ...,  0.0031, -0.0295,  0.0473]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.3633, -2.4180, -1.5488,  ...,  0.3740, -3.7148, -1.2920]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 02:30:42 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more intense word for necessary is essential
A more intense word for angry is furious
A more intense word for boring is tedious
A more intense word for dinner is feast
A more intense word for dislike is hate
A more intense word for snack is meal
A more intense word for doze is sleep
A more intense word for soon is
2024-07-29 02:30:42 root INFO     [order_1_approx] starting weight calculation for A more intense word for necessary is essential
A more intense word for boring is tedious
A more intense word for angry is furious
A more intense word for snack is meal
A more intense word for soon is immediately
A more intense word for dinner is feast
A more intense word for doze is sleep
A more intense word for dislike is
2024-07-29 02:30:42 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-29 02:33:07 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0011, -0.4922, -0.1768,  ...,  0.2202,  0.1847,  0.5088],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.0234, -5.4297,  0.3999,  ..., -1.3496, -3.7676, -2.4531],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0705,  0.0056,  0.0188,  ...,  0.0051, -0.0041,  0.0323],
        [ 0.0020,  0.0662,  0.0006,  ..., -0.0160,  0.0100,  0.0297],
        [ 0.0186, -0.0082,  0.0444,  ..., -0.0013, -0.0023, -0.0066],
        ...,
        [ 0.0192,  0.0182, -0.0217,  ...,  0.0392,  0.0125, -0.0079],
        [-0.0050, -0.0157,  0.0026,  ...,  0.0154,  0.0310, -0.0117],
        [ 0.0051,  0.0001, -0.0299,  ..., -0.0237, -0.0089,  0.0281]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.1035, -4.8984,  0.4348,  ..., -0.8789, -3.7891, -2.1387]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 02:33:09 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more intense word for necessary is essential
A more intense word for boring is tedious
A more intense word for angry is furious
A more intense word for snack is meal
A more intense word for soon is immediately
A more intense word for dinner is feast
A more intense word for doze is sleep
A more intense word for dislike is
2024-07-29 02:33:09 root INFO     [order_1_approx] starting weight calculation for A more intense word for soon is immediately
A more intense word for necessary is essential
A more intense word for snack is meal
A more intense word for doze is sleep
A more intense word for dinner is feast
A more intense word for angry is furious
A more intense word for dislike is hate
A more intense word for boring is
2024-07-29 02:33:09 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-29 02:35:33 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0977, -0.2225, -0.1744,  ..., -0.4226, -0.5000,  0.2888],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.7871, -1.7148,  4.6562,  ..., -2.7383, -4.9922, -1.7725],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0528,  0.0318,  0.0056,  ..., -0.0019,  0.0231,  0.0334],
        [-0.0040,  0.0736,  0.0223,  ..., -0.0136, -0.0145, -0.0276],
        [-0.0081,  0.0067,  0.0515,  ...,  0.0072, -0.0034,  0.0143],
        ...,
        [ 0.0510,  0.0157,  0.0120,  ...,  0.0473,  0.0134, -0.0159],
        [ 0.0074,  0.0059,  0.0360,  ...,  0.0202,  0.0062, -0.0261],
        [ 0.0275,  0.0072,  0.0157,  ..., -0.0123, -0.0108,  0.0499]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.8613, -2.0078,  4.4336,  ..., -2.8438, -5.1016, -2.0840]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 02:35:34 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more intense word for soon is immediately
A more intense word for necessary is essential
A more intense word for snack is meal
A more intense word for doze is sleep
A more intense word for dinner is feast
A more intense word for angry is furious
A more intense word for dislike is hate
A more intense word for boring is
2024-07-29 02:35:34 root INFO     [order_1_approx] starting weight calculation for A more intense word for angry is furious
A more intense word for snack is meal
A more intense word for necessary is essential
A more intense word for boring is tedious
A more intense word for doze is sleep
A more intense word for dislike is hate
A more intense word for soon is immediately
A more intense word for dinner is
2024-07-29 02:35:34 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-29 02:37:52 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1528, -0.1526, -0.3423,  ..., -0.3259, -0.5322, -0.0710],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.1133, -3.2969,  0.6362,  ..., -2.2012, -1.3848, -2.4824],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0302, -0.0064, -0.0153,  ..., -0.0099, -0.0085,  0.0003],
        [ 0.0054,  0.0380, -0.0058,  ...,  0.0060, -0.0044, -0.0051],
        [-0.0091, -0.0418,  0.1045,  ...,  0.0136, -0.0380, -0.0067],
        ...,
        [-0.0035,  0.0070,  0.0175,  ...,  0.0637,  0.0090, -0.0256],
        [ 0.0166,  0.0023,  0.0105,  ...,  0.0466,  0.0513,  0.0079],
        [-0.0234,  0.0080, -0.0043,  ..., -0.0095,  0.0035,  0.0167]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.3164, -2.8281,  1.0537,  ..., -1.5791, -2.0801, -1.9355]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 02:37:53 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more intense word for angry is furious
A more intense word for snack is meal
A more intense word for necessary is essential
A more intense word for boring is tedious
A more intense word for doze is sleep
A more intense word for dislike is hate
A more intense word for soon is immediately
A more intense word for dinner is
2024-07-29 02:37:53 root INFO     [order_1_approx] starting weight calculation for A more intense word for doze is sleep
A more intense word for dislike is hate
A more intense word for dinner is feast
A more intense word for soon is immediately
A more intense word for angry is furious
A more intense word for boring is tedious
A more intense word for snack is meal
A more intense word for necessary is
2024-07-29 02:37:53 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-29 02:40:15 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2271, -0.0353, -0.4102,  ..., -0.4001, -0.4165, -0.1028],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 5.1094, -0.5605, -0.5557,  ..., -0.1948, -6.0938, -1.1445],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 2.8595e-02, -1.0025e-02,  1.6495e-02,  ...,  2.3651e-02,
         -3.7155e-03,  1.4359e-02],
        [-1.1353e-02,  4.3976e-02, -1.0536e-02,  ...,  1.5671e-02,
          1.0117e-02, -4.6253e-05],
        [ 5.0583e-03,  4.2419e-03,  4.8889e-02,  ...,  2.4338e-03,
         -9.8419e-03, -1.2531e-03],
        ...,
        [ 1.6220e-02,  4.5776e-02,  6.7139e-03,  ...,  4.4830e-02,
          7.5912e-03, -1.2238e-02],
        [-6.0043e-03, -1.2177e-02, -9.8343e-03,  ..., -2.5711e-02,
          5.5847e-02, -1.7212e-02],
        [ 2.3163e-02, -1.2184e-02, -2.8214e-02,  ..., -1.5167e-02,
         -2.4902e-02,  6.1951e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.8867, -0.3462, -0.4783,  ..., -0.1727, -5.9648, -1.2031]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 02:40:25 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more intense word for doze is sleep
A more intense word for dislike is hate
A more intense word for dinner is feast
A more intense word for soon is immediately
A more intense word for angry is furious
A more intense word for boring is tedious
A more intense word for snack is meal
A more intense word for necessary is
2024-07-29 02:40:25 root INFO     total operator prediction time: 1153.9412677288055 seconds
2024-07-29 02:40:25 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on meronyms - substance
2024-07-29 02:40:25 root INFO     building operator meronyms - substance
2024-07-29 02:40:26 root INFO     [order_1_approx] starting weight calculation for A steel is made up of iron
A bag is made up of leather
A water is made up of oxygen
A chocolate is made up of cocoa
A mirror is made up of glass
A concrete is made up of silicon
A bottle is made up of glass
A penny is made up of
2024-07-29 02:40:26 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-29 02:42:50 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.3193,  0.2416, -0.2874,  ...,  0.0161, -0.1794,  0.2151],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.7188, -2.6680, -1.7891,  ..., -3.9336, -0.3142, -0.5000],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 5.5023e-02, -3.5370e-02,  8.5163e-04,  ..., -1.7607e-04,
          1.1444e-05, -1.0315e-02],
        [ 4.2343e-04,  6.0242e-02,  2.9480e-02,  ...,  1.5053e-02,
         -8.6975e-03, -2.3842e-03],
        [ 3.4218e-03,  4.2664e-02,  4.5776e-02,  ...,  1.7502e-02,
         -2.7588e-02,  9.3307e-03],
        ...,
        [-1.7090e-03,  4.3030e-02,  9.7198e-03,  ...,  6.6040e-02,
         -2.0050e-02,  2.2202e-03],
        [ 1.1932e-02,  1.3992e-02, -1.2741e-02,  ...,  2.4658e-02,
          1.3405e-02,  8.1177e-03],
        [-1.3596e-02,  8.4381e-03,  7.0114e-03,  ...,  4.4937e-03,
         -2.2163e-03,  4.2114e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.4492, -2.6699, -1.9053,  ..., -3.7188, -0.1178, -0.3352]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 02:42:51 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A steel is made up of iron
A bag is made up of leather
A water is made up of oxygen
A chocolate is made up of cocoa
A mirror is made up of glass
A concrete is made up of silicon
A bottle is made up of glass
A penny is made up of
2024-07-29 02:42:51 root INFO     [order_1_approx] starting weight calculation for A penny is made up of metal
A chocolate is made up of cocoa
A mirror is made up of glass
A water is made up of oxygen
A bottle is made up of glass
A bag is made up of leather
A concrete is made up of silicon
A steel is made up of
2024-07-29 02:42:51 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-29 02:45:14 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1031,  0.0690, -0.2910,  ...,  0.0300, -0.1613,  0.2725],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.8535, -4.6758,  0.4443,  ..., -3.9570, -1.3789, -3.2363],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0252, -0.0282, -0.0200,  ..., -0.0215, -0.0081,  0.0010],
        [-0.0144,  0.0196,  0.0108,  ..., -0.0011,  0.0086, -0.0061],
        [ 0.0239,  0.0201,  0.0363,  ...,  0.0370,  0.0050, -0.0020],
        ...,
        [ 0.0151, -0.0247,  0.0259,  ...,  0.0049,  0.0029, -0.0312],
        [-0.0147,  0.0225, -0.0327,  ...,  0.0112,  0.0287,  0.0303],
        [ 0.0017, -0.0167, -0.0082,  ..., -0.0308,  0.0118,  0.0196]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.0078, -4.5117,  0.0129,  ..., -3.3887, -1.4277, -3.2207]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 02:45:14 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A penny is made up of metal
A chocolate is made up of cocoa
A mirror is made up of glass
A water is made up of oxygen
A bottle is made up of glass
A bag is made up of leather
A concrete is made up of silicon
A steel is made up of
2024-07-29 02:45:15 root INFO     [order_1_approx] starting weight calculation for A bottle is made up of glass
A penny is made up of metal
A bag is made up of leather
A water is made up of oxygen
A steel is made up of iron
A mirror is made up of glass
A concrete is made up of silicon
A chocolate is made up of
2024-07-29 02:45:15 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-29 02:47:37 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0287, -0.0730, -0.5449,  ..., -0.0644, -0.3926, -0.0125],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.9609, -3.5254, -0.7104,  ..., -2.1367, -3.5156,  4.3711],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0129, -0.0026,  0.0075,  ..., -0.0054, -0.0230,  0.0020],
        [-0.0087,  0.0235,  0.0110,  ...,  0.0068,  0.0169,  0.0070],
        [ 0.0033,  0.0071,  0.0092,  ...,  0.0040, -0.0083,  0.0049],
        ...,
        [ 0.0074,  0.0043,  0.0112,  ...,  0.0219,  0.0019, -0.0050],
        [ 0.0061,  0.0179, -0.0088,  ...,  0.0174,  0.0157,  0.0071],
        [-0.0068, -0.0067, -0.0031,  ..., -0.0197,  0.0122,  0.0168]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.9766, -3.5840, -0.7422,  ..., -1.9766, -3.5547,  4.4766]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 02:47:39 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A bottle is made up of glass
A penny is made up of metal
A bag is made up of leather
A water is made up of oxygen
A steel is made up of iron
A mirror is made up of glass
A concrete is made up of silicon
A chocolate is made up of
2024-07-29 02:47:40 root INFO     [order_1_approx] starting weight calculation for A bag is made up of leather
A water is made up of oxygen
A concrete is made up of silicon
A chocolate is made up of cocoa
A steel is made up of iron
A penny is made up of metal
A bottle is made up of glass
A mirror is made up of
2024-07-29 02:47:40 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-29 02:50:02 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0483, -0.1019, -0.0305,  ...,  0.3225, -0.1779,  0.3306],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.4258, -4.0469, -0.0212,  ..., -2.7539, -2.2480,  1.1133],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0356, -0.0214,  0.0172,  ...,  0.0392, -0.0190, -0.0369],
        [ 0.0166,  0.0481, -0.0144,  ...,  0.0347, -0.0061, -0.0143],
        [ 0.0317, -0.0013,  0.0502,  ...,  0.0186, -0.0275, -0.0033],
        ...,
        [ 0.0109,  0.0208,  0.0189,  ...,  0.0312,  0.0084, -0.0040],
        [-0.0028,  0.0083, -0.0144,  ...,  0.0013,  0.0260,  0.0011],
        [-0.0002, -0.0270,  0.0114,  ...,  0.0029, -0.0050,  0.0262]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.5645, -4.1602,  0.1843,  ..., -2.8633, -2.2773,  1.5146]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 02:50:03 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A bag is made up of leather
A water is made up of oxygen
A concrete is made up of silicon
A chocolate is made up of cocoa
A steel is made up of iron
A penny is made up of metal
A bottle is made up of glass
A mirror is made up of
2024-07-29 02:50:03 root INFO     [order_1_approx] starting weight calculation for A bottle is made up of glass
A penny is made up of metal
A bag is made up of leather
A water is made up of oxygen
A steel is made up of iron
A mirror is made up of glass
A chocolate is made up of cocoa
A concrete is made up of
2024-07-29 02:50:03 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-29 02:52:26 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0690,  0.0051, -0.3914,  ...,  0.0084, -0.3887,  0.3162],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.6992, -7.7266, -0.6250,  ..., -0.3418,  1.0713, -0.9902],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0141,  0.0078,  0.0124,  ...,  0.0214, -0.0232, -0.0131],
        [-0.0078,  0.0233,  0.0252,  ..., -0.0130,  0.0211, -0.0030],
        [ 0.0006, -0.0098,  0.0200,  ..., -0.0080, -0.0022, -0.0049],
        ...,
        [-0.0058, -0.0008,  0.0300,  ...,  0.0354, -0.0016, -0.0158],
        [-0.0087, -0.0007, -0.0198,  ...,  0.0157,  0.0133, -0.0018],
        [ 0.0109,  0.0015, -0.0021,  ..., -0.0246,  0.0102,  0.0187]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.7227, -7.7344, -0.5884,  ...,  0.0693,  0.8574, -0.8633]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 02:52:27 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A bottle is made up of glass
A penny is made up of metal
A bag is made up of leather
A water is made up of oxygen
A steel is made up of iron
A mirror is made up of glass
A chocolate is made up of cocoa
A concrete is made up of
2024-07-29 02:52:27 root INFO     [order_1_approx] starting weight calculation for A concrete is made up of silicon
A chocolate is made up of cocoa
A mirror is made up of glass
A bottle is made up of glass
A steel is made up of iron
A water is made up of oxygen
A penny is made up of metal
A bag is made up of
2024-07-29 02:52:27 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-29 02:54:50 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3550,  0.0342, -0.3630,  ...,  0.1863, -0.4373, -0.2147],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 6.3125, -6.8594,  1.0664,  ...,  0.5820, -0.6123,  2.4570],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0301,  0.0134,  0.0139,  ...,  0.0087, -0.0137,  0.0139],
        [-0.0083,  0.0436,  0.0012,  ..., -0.0127,  0.0055, -0.0155],
        [-0.0069,  0.0050,  0.0326,  ..., -0.0057, -0.0136, -0.0059],
        ...,
        [ 0.0232, -0.0223,  0.0041,  ...,  0.0499, -0.0279, -0.0396],
        [-0.0138, -0.0055,  0.0034,  ...,  0.0159,  0.0479,  0.0015],
        [-0.0246,  0.0157,  0.0195,  ..., -0.0129, -0.0141,  0.0618]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 6.1484, -6.6758,  1.0713,  ...,  0.7412, -1.2051,  2.2383]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 02:54:51 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A concrete is made up of silicon
A chocolate is made up of cocoa
A mirror is made up of glass
A bottle is made up of glass
A steel is made up of iron
A water is made up of oxygen
A penny is made up of metal
A bag is made up of
2024-07-29 02:54:51 root INFO     [order_1_approx] starting weight calculation for A mirror is made up of glass
A concrete is made up of silicon
A penny is made up of metal
A bag is made up of leather
A steel is made up of iron
A bottle is made up of glass
A chocolate is made up of cocoa
A water is made up of
2024-07-29 02:54:51 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-29 02:57:13 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1560, -0.0499, -0.3494,  ..., -0.0776, -0.1965,  0.0262],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.4453, -3.3594,  2.1270,  ..., -3.2852,  2.3184, -0.8066],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0196, -0.0103, -0.0129,  ...,  0.0016,  0.0007, -0.0105],
        [-0.0101,  0.0434,  0.0007,  ...,  0.0183,  0.0096, -0.0018],
        [ 0.0030,  0.0011,  0.0062,  ...,  0.0053,  0.0115, -0.0242],
        ...,
        [ 0.0041,  0.0057,  0.0246,  ...,  0.0168,  0.0082, -0.0051],
        [-0.0058, -0.0055, -0.0199,  ..., -0.0026,  0.0301,  0.0113],
        [ 0.0012, -0.0011,  0.0197,  ..., -0.0176,  0.0066,  0.0230]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.8428, -3.3574,  2.2227,  ..., -3.1641,  2.2129, -0.5854]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 02:57:14 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A mirror is made up of glass
A concrete is made up of silicon
A penny is made up of metal
A bag is made up of leather
A steel is made up of iron
A bottle is made up of glass
A chocolate is made up of cocoa
A water is made up of
2024-07-29 02:57:14 root INFO     [order_1_approx] starting weight calculation for A penny is made up of metal
A concrete is made up of silicon
A mirror is made up of glass
A steel is made up of iron
A bag is made up of leather
A water is made up of oxygen
A chocolate is made up of cocoa
A bottle is made up of
2024-07-29 02:57:14 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-29 02:59:36 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4531,  0.0555, -0.5225,  ...,  0.1814, -0.4746,  0.0947],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.9922, -7.5547,  0.8516,  ..., -0.4812,  0.9849, -0.7568],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0204,  0.0006,  0.0016,  ...,  0.0181, -0.0120, -0.0058],
        [-0.0017,  0.0228,  0.0005,  ...,  0.0091, -0.0135, -0.0008],
        [ 0.0127, -0.0018,  0.0145,  ...,  0.0023,  0.0073, -0.0097],
        ...,
        [ 0.0183,  0.0187,  0.0248,  ...,  0.0381, -0.0114, -0.0091],
        [-0.0061,  0.0034, -0.0073,  ...,  0.0029,  0.0210, -0.0002],
        [ 0.0039, -0.0064,  0.0202,  ...,  0.0045,  0.0021,  0.0204]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.8594, -7.5039,  0.9551,  ..., -0.4917,  0.9956, -0.8062]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 02:59:37 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A penny is made up of metal
A concrete is made up of silicon
A mirror is made up of glass
A steel is made up of iron
A bag is made up of leather
A water is made up of oxygen
A chocolate is made up of cocoa
A bottle is made up of
2024-07-29 02:59:37 root INFO     total operator prediction time: 1152.3620028495789 seconds
2024-07-29 02:59:37 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on hypernyms - misc
2024-07-29 02:59:37 root INFO     building operator hypernyms - misc
2024-07-29 02:59:37 root INFO     [order_1_approx] starting weight calculation for The denim falls into the category of fabric
The blender falls into the category of appliance
The grapefruit falls into the category of citrus
The deodorant falls into the category of toiletry
The hairpin falls into the category of pin
The necklace falls into the category of jewelry
The hairnet falls into the category of net
The toothbrush falls into the category of
2024-07-29 02:59:38 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-29 03:02:00 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.5630, -0.1134, -0.1223,  ...,  0.2073, -0.6318, -0.4072],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.6445, -3.4746, -1.2715,  ..., -1.5430, -4.8438,  0.5820],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0541, -0.0100,  0.0009,  ...,  0.0141, -0.0133,  0.0154],
        [ 0.0169,  0.0380, -0.0117,  ...,  0.0133, -0.0139,  0.0138],
        [-0.0138,  0.0134,  0.0233,  ..., -0.0046, -0.0030, -0.0052],
        ...,
        [-0.0051, -0.0033,  0.0120,  ...,  0.0197,  0.0219, -0.0087],
        [ 0.0100, -0.0071,  0.0119,  ..., -0.0005,  0.0204, -0.0145],
        [-0.0142,  0.0003,  0.0172,  ..., -0.0062, -0.0060,  0.0197]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.5117, -3.8516, -1.2334,  ..., -1.2637, -4.6758,  0.5742]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 03:02:01 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The denim falls into the category of fabric
The blender falls into the category of appliance
The grapefruit falls into the category of citrus
The deodorant falls into the category of toiletry
The hairpin falls into the category of pin
The necklace falls into the category of jewelry
The hairnet falls into the category of net
The toothbrush falls into the category of
2024-07-29 03:02:02 root INFO     [order_1_approx] starting weight calculation for The hairnet falls into the category of net
The necklace falls into the category of jewelry
The deodorant falls into the category of toiletry
The blender falls into the category of appliance
The toothbrush falls into the category of brush
The denim falls into the category of fabric
The grapefruit falls into the category of citrus
The hairpin falls into the category of
2024-07-29 03:02:02 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-29 03:04:24 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0403, -0.5820, -0.3540,  ...,  0.3467,  0.2019, -0.0443],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.1406, -4.3398, -1.9414,  ..., -1.7139, -5.1523,  1.4912],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.1114, -0.0219,  0.0046,  ...,  0.0046, -0.0185,  0.0195],
        [-0.0175,  0.0813, -0.0393,  ...,  0.0271, -0.0188, -0.0083],
        [ 0.0100,  0.0124,  0.0785,  ..., -0.0151,  0.0171,  0.0018],
        ...,
        [ 0.0077, -0.0176,  0.0261,  ...,  0.0760,  0.0229, -0.0228],
        [ 0.0087,  0.0008,  0.0071,  ...,  0.0350,  0.0715, -0.0093],
        [-0.0198,  0.0034, -0.0069,  ..., -0.0134,  0.0007,  0.0696]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.5059, -5.0742, -2.3203,  ..., -1.4863, -4.9219,  0.9517]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 03:04:26 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The hairnet falls into the category of net
The necklace falls into the category of jewelry
The deodorant falls into the category of toiletry
The blender falls into the category of appliance
The toothbrush falls into the category of brush
The denim falls into the category of fabric
The grapefruit falls into the category of citrus
The hairpin falls into the category of
2024-07-29 03:04:29 root INFO     [order_1_approx] starting weight calculation for The toothbrush falls into the category of brush
The hairpin falls into the category of pin
The blender falls into the category of appliance
The deodorant falls into the category of toiletry
The necklace falls into the category of jewelry
The hairnet falls into the category of net
The denim falls into the category of fabric
The grapefruit falls into the category of
2024-07-29 03:04:29 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-29 03:06:43 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.3513, -0.5244, -0.2184,  ...,  0.0083, -0.5288,  0.1036],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.6455, -5.5195,  1.2402,  ..., -4.7344, -2.6914, -2.5527],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0470,  0.0158, -0.0096,  ...,  0.0153,  0.0011,  0.0169],
        [ 0.0081,  0.0511,  0.0165,  ...,  0.0240,  0.0125,  0.0079],
        [ 0.0060,  0.0084,  0.0300,  ...,  0.0121, -0.0231,  0.0096],
        ...,
        [-0.0015, -0.0037, -0.0015,  ...,  0.0553,  0.0106,  0.0034],
        [ 0.0146,  0.0068, -0.0132,  ...,  0.0135,  0.0248, -0.0017],
        [-0.0116, -0.0133,  0.0249,  ..., -0.0278, -0.0076,  0.0338]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.7812, -5.7695,  0.7354,  ..., -4.4844, -2.2871, -2.6211]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 03:06:44 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The toothbrush falls into the category of brush
The hairpin falls into the category of pin
The blender falls into the category of appliance
The deodorant falls into the category of toiletry
The necklace falls into the category of jewelry
The hairnet falls into the category of net
The denim falls into the category of fabric
The grapefruit falls into the category of
2024-07-29 03:06:44 root INFO     [order_1_approx] starting weight calculation for The grapefruit falls into the category of citrus
The hairnet falls into the category of net
The blender falls into the category of appliance
The toothbrush falls into the category of brush
The deodorant falls into the category of toiletry
The denim falls into the category of fabric
The hairpin falls into the category of pin
The necklace falls into the category of
2024-07-29 03:06:44 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-29 03:09:02 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1102,  0.1663, -0.2013,  ...,  0.0837, -0.4053, -0.2651],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.3467, -7.7656, -2.8125,  ..., -0.5947, -4.6992,  1.2412],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0676,  0.0015,  0.0017,  ..., -0.0076, -0.0031,  0.0183],
        [-0.0070,  0.0427, -0.0113,  ..., -0.0070,  0.0127, -0.0038],
        [ 0.0120,  0.0008,  0.0623,  ...,  0.0090, -0.0110, -0.0016],
        ...,
        [-0.0010,  0.0165,  0.0134,  ...,  0.0466,  0.0227, -0.0250],
        [ 0.0093, -0.0095, -0.0076,  ...,  0.0259,  0.0421, -0.0042],
        [-0.0141,  0.0057,  0.0013,  ..., -0.0244, -0.0055,  0.0445]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.2012, -7.5234, -2.6797,  ..., -0.4578, -4.6055,  1.1426]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 03:09:03 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The grapefruit falls into the category of citrus
The hairnet falls into the category of net
The blender falls into the category of appliance
The toothbrush falls into the category of brush
The deodorant falls into the category of toiletry
The denim falls into the category of fabric
The hairpin falls into the category of pin
The necklace falls into the category of
2024-07-29 03:09:03 root INFO     [order_1_approx] starting weight calculation for The deodorant falls into the category of toiletry
The hairpin falls into the category of pin
The denim falls into the category of fabric
The toothbrush falls into the category of brush
The grapefruit falls into the category of citrus
The blender falls into the category of appliance
The necklace falls into the category of jewelry
The hairnet falls into the category of
2024-07-29 03:09:03 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-29 03:11:29 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0323, -0.2031, -0.3669,  ...,  0.3159, -0.0520,  0.1572],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.3281, -2.8047,  1.1426,  ..., -0.9150, -4.3477,  4.4688],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.1120, -0.0025,  0.0135,  ...,  0.0131, -0.0153,  0.0005],
        [-0.0320,  0.0698, -0.0275,  ...,  0.0040,  0.0017, -0.0091],
        [ 0.0063,  0.0140,  0.0583,  ..., -0.0043, -0.0270,  0.0009],
        ...,
        [ 0.0131, -0.0068,  0.0359,  ...,  0.0555,  0.0282, -0.0027],
        [ 0.0009, -0.0073,  0.0013,  ...,  0.0197,  0.0438, -0.0358],
        [-0.0340, -0.0218, -0.0115,  ..., -0.0064, -0.0058,  0.0541]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.9414, -3.3145,  0.5454,  ..., -0.7769, -4.3359,  4.4727]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 03:11:30 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The deodorant falls into the category of toiletry
The hairpin falls into the category of pin
The denim falls into the category of fabric
The toothbrush falls into the category of brush
The grapefruit falls into the category of citrus
The blender falls into the category of appliance
The necklace falls into the category of jewelry
The hairnet falls into the category of
2024-07-29 03:11:30 root INFO     [order_1_approx] starting weight calculation for The necklace falls into the category of jewelry
The hairpin falls into the category of pin
The toothbrush falls into the category of brush
The grapefruit falls into the category of citrus
The deodorant falls into the category of toiletry
The blender falls into the category of appliance
The hairnet falls into the category of net
The denim falls into the category of
2024-07-29 03:11:30 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-29 03:13:53 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2969,  0.2117, -0.5972,  ...,  0.7417, -0.5122,  0.0734],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.9141, -7.1641,  1.9727,  ..., -0.0203, -4.4297,  1.2998],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0580, -0.0025,  0.0282,  ...,  0.0011, -0.0117, -0.0025],
        [-0.0056,  0.0472, -0.0341,  ...,  0.0087,  0.0148,  0.0110],
        [-0.0054,  0.0030,  0.0402,  ..., -0.0069, -0.0155,  0.0045],
        ...,
        [ 0.0173, -0.0096,  0.0112,  ...,  0.0572,  0.0139, -0.0145],
        [ 0.0179,  0.0063, -0.0128,  ...,  0.0066,  0.0388, -0.0139],
        [ 0.0249,  0.0039,  0.0199,  ..., -0.0258, -0.0040,  0.0612]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.6719, -6.9609,  1.8496,  ...,  0.2142, -4.3711,  1.4268]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 03:13:53 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The necklace falls into the category of jewelry
The hairpin falls into the category of pin
The toothbrush falls into the category of brush
The grapefruit falls into the category of citrus
The deodorant falls into the category of toiletry
The blender falls into the category of appliance
The hairnet falls into the category of net
The denim falls into the category of
2024-07-29 03:13:54 root INFO     [order_1_approx] starting weight calculation for The grapefruit falls into the category of citrus
The hairpin falls into the category of pin
The hairnet falls into the category of net
The blender falls into the category of appliance
The toothbrush falls into the category of brush
The necklace falls into the category of jewelry
The denim falls into the category of fabric
The deodorant falls into the category of
2024-07-29 03:13:54 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-29 03:16:15 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2341, -0.3457, -0.0979,  ...,  0.0390, -0.4468, -0.3975],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.8164, -3.7773, -0.3711,  ..., -2.6289, -3.9512, -0.3447],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0321, -0.0058,  0.0004,  ...,  0.0048, -0.0064,  0.0045],
        [-0.0026,  0.0416, -0.0015,  ..., -0.0023, -0.0012,  0.0111],
        [-0.0104,  0.0047,  0.0305,  ..., -0.0098, -0.0056, -0.0088],
        ...,
        [ 0.0072, -0.0034, -0.0011,  ...,  0.0283,  0.0164,  0.0025],
        [-0.0033,  0.0011,  0.0074,  ...,  0.0028,  0.0287, -0.0087],
        [ 0.0036, -0.0008,  0.0027,  ..., -0.0096, -0.0149,  0.0289]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.8281, -4.3711, -0.4570,  ..., -2.5938, -3.9844, -0.5293]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 03:16:16 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The grapefruit falls into the category of citrus
The hairpin falls into the category of pin
The hairnet falls into the category of net
The blender falls into the category of appliance
The toothbrush falls into the category of brush
The necklace falls into the category of jewelry
The denim falls into the category of fabric
The deodorant falls into the category of
2024-07-29 03:16:16 root INFO     [order_1_approx] starting weight calculation for The necklace falls into the category of jewelry
The hairnet falls into the category of net
The grapefruit falls into the category of citrus
The denim falls into the category of fabric
The toothbrush falls into the category of brush
The hairpin falls into the category of pin
The deodorant falls into the category of toiletry
The blender falls into the category of
2024-07-29 03:16:16 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-29 03:18:37 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.3140, -0.3022, -0.0721,  ...,  0.6689, -0.2227, -0.1792],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.6963, -4.0586, -0.5830,  ..., -1.7881, -4.0195,  0.1104],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0824, -0.0049, -0.0113,  ...,  0.0079, -0.0047,  0.0132],
        [ 0.0223,  0.0723,  0.0086,  ..., -0.0011, -0.0050,  0.0096],
        [-0.0120,  0.0173,  0.0514,  ..., -0.0086, -0.0059,  0.0018],
        ...,
        [-0.0106, -0.0097,  0.0123,  ...,  0.0584,  0.0453, -0.0024],
        [-0.0184, -0.0109,  0.0055,  ...,  0.0206,  0.0557, -0.0352],
        [ 0.0164, -0.0019,  0.0171,  ..., -0.0164, -0.0065,  0.0467]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.1562, -3.8711, -1.1992,  ..., -1.8828, -3.6816,  0.1004]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 03:18:38 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The necklace falls into the category of jewelry
The hairnet falls into the category of net
The grapefruit falls into the category of citrus
The denim falls into the category of fabric
The toothbrush falls into the category of brush
The hairpin falls into the category of pin
The deodorant falls into the category of toiletry
The blender falls into the category of
2024-07-29 03:18:38 root INFO     total operator prediction time: 1140.334665298462 seconds
2024-07-29 03:18:38 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on synonyms - exact
2024-07-29 03:18:38 root INFO     building operator synonyms - exact
2024-07-29 03:18:38 root INFO     [order_1_approx] starting weight calculation for Another word for baby is infant
Another word for railway is railroad
Another word for incorrect is wrong
Another word for sofa is couch
Another word for rational is logical
Another word for lazy is indolent
Another word for reasonable is sensible
Another word for hieroglyph is
2024-07-29 03:18:38 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-29 03:21:00 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2935,  0.4878, -0.0020,  ..., -0.3279, -0.3110,  0.3452],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.9463, -1.7891,  5.8633,  ...,  1.2881,  0.2812,  1.7207],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 5.8746e-02, -2.3651e-02,  2.4002e-02,  ...,  8.5220e-03,
          2.0905e-03,  2.4414e-03],
        [-1.0773e-02,  5.7007e-02,  1.7151e-02,  ..., -1.7044e-02,
          2.3384e-03, -9.1324e-03],
        [-1.7227e-02, -3.8452e-03,  3.9246e-02,  ...,  1.3962e-03,
         -1.5961e-02, -2.2598e-02],
        ...,
        [ 6.3744e-03,  2.5528e-02, -1.6804e-03,  ...,  6.8604e-02,
          2.6321e-03,  1.0605e-02],
        [-3.3356e-02, -2.1301e-02,  5.4092e-03,  ..., -4.6806e-03,
          3.7842e-02,  3.9215e-03],
        [ 6.6757e-05,  2.1591e-02, -6.0425e-03,  ...,  4.2114e-03,
         -3.2043e-02,  6.5247e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.7656, -1.8350,  5.8242,  ...,  1.4326,  0.2219,  1.4355]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 03:21:02 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Another word for baby is infant
Another word for railway is railroad
Another word for incorrect is wrong
Another word for sofa is couch
Another word for rational is logical
Another word for lazy is indolent
Another word for reasonable is sensible
Another word for hieroglyph is
2024-07-29 03:21:03 root INFO     [order_1_approx] starting weight calculation for Another word for incorrect is wrong
Another word for sofa is couch
Another word for baby is infant
Another word for hieroglyph is hieroglyphic
Another word for reasonable is sensible
Another word for lazy is indolent
Another word for railway is railroad
Another word for rational is
2024-07-29 03:21:03 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-29 03:23:20 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3110, -0.1313,  0.0129,  ..., -0.3491,  0.2123,  0.0055],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.6230,  1.9863,  1.5791,  ..., -0.2379, -6.1367, -1.2266],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0853,  0.0054,  0.0261,  ..., -0.0100, -0.0108,  0.0019],
        [ 0.0073,  0.0410,  0.0101,  ..., -0.0004,  0.0168, -0.0119],
        [-0.0061, -0.0073,  0.1005,  ...,  0.0085, -0.0088, -0.0002],
        ...,
        [ 0.0412,  0.0258,  0.0024,  ...,  0.1116,  0.0032, -0.0248],
        [ 0.0250,  0.0331,  0.0008,  ..., -0.0303,  0.0306,  0.0071],
        [ 0.0266, -0.0013,  0.0157,  ...,  0.0121,  0.0094,  0.0520]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.4766,  2.4922,  0.9683,  ..., -0.1963, -6.4883, -1.2627]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 03:23:21 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Another word for incorrect is wrong
Another word for sofa is couch
Another word for baby is infant
Another word for hieroglyph is hieroglyphic
Another word for reasonable is sensible
Another word for lazy is indolent
Another word for railway is railroad
Another word for rational is
2024-07-29 03:23:21 root INFO     [order_1_approx] starting weight calculation for Another word for railway is railroad
Another word for incorrect is wrong
Another word for lazy is indolent
Another word for baby is infant
Another word for rational is logical
Another word for reasonable is sensible
Another word for hieroglyph is hieroglyphic
Another word for sofa is
2024-07-29 03:23:21 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-29 03:25:43 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3604, -0.3318,  0.1693,  ...,  0.1951, -0.0237,  0.1030],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.9785, -3.4062,  4.4727,  ..., -0.8633, -2.9824, -2.0957],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0795,  0.0236,  0.0187,  ...,  0.0128, -0.0074,  0.0010],
        [ 0.0058,  0.0706,  0.0031,  ...,  0.0178,  0.0279, -0.0066],
        [-0.0194, -0.0163,  0.0820,  ..., -0.0129, -0.0149, -0.0221],
        ...,
        [ 0.0482,  0.0130, -0.0326,  ...,  0.1039,  0.0181, -0.0225],
        [ 0.0137,  0.0009, -0.0255,  ...,  0.0222,  0.0769,  0.0194],
        [ 0.0110,  0.0223, -0.0205,  ..., -0.0363,  0.0016,  0.0312]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.9395, -2.8008,  3.8887,  ..., -0.7808, -2.6777, -1.7109]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 03:25:44 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Another word for railway is railroad
Another word for incorrect is wrong
Another word for lazy is indolent
Another word for baby is infant
Another word for rational is logical
Another word for reasonable is sensible
Another word for hieroglyph is hieroglyphic
Another word for sofa is
2024-07-29 03:25:45 root INFO     [order_1_approx] starting weight calculation for Another word for railway is railroad
Another word for baby is infant
Another word for hieroglyph is hieroglyphic
Another word for rational is logical
Another word for sofa is couch
Another word for reasonable is sensible
Another word for incorrect is wrong
Another word for lazy is
2024-07-29 03:25:45 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-29 03:28:08 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.5928, -0.2786, -0.0212,  ..., -0.3584,  0.0382,  0.4023],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.9004, -2.3574,  1.0039,  ..., -2.3789, -3.5391, -2.5938],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0850,  0.0050,  0.0062,  ..., -0.0174,  0.0377,  0.0140],
        [-0.0059, -0.0115,  0.0036,  ..., -0.0121,  0.0141, -0.0087],
        [-0.0017,  0.0072,  0.0624,  ..., -0.0027,  0.0086,  0.0032],
        ...,
        [ 0.0256,  0.0007, -0.0017,  ...,  0.0994,  0.0222, -0.0113],
        [-0.0004,  0.0280, -0.0177,  ..., -0.0072,  0.0254, -0.0067],
        [ 0.0410,  0.0069,  0.0098,  ..., -0.0128,  0.0057,  0.0270]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.0322, -2.0957,  0.8828,  ..., -1.6738, -3.1777, -2.9375]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 03:28:08 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Another word for railway is railroad
Another word for baby is infant
Another word for hieroglyph is hieroglyphic
Another word for rational is logical
Another word for sofa is couch
Another word for reasonable is sensible
Another word for incorrect is wrong
Another word for lazy is
2024-07-29 03:28:09 root INFO     [order_1_approx] starting weight calculation for Another word for lazy is indolent
Another word for sofa is couch
Another word for incorrect is wrong
Another word for railway is railroad
Another word for hieroglyph is hieroglyphic
Another word for rational is logical
Another word for reasonable is sensible
Another word for baby is
2024-07-29 03:28:09 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-29 03:30:32 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0508, -0.0830, -0.1311,  ..., -0.1584, -0.6650,  0.2944],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.0977, -4.5352, -1.1299,  ..., -0.2139, -3.5176,  2.3926],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.1028, -0.0373,  0.0250,  ...,  0.0162, -0.0145,  0.0268],
        [-0.0065,  0.0467,  0.0054,  ..., -0.0022,  0.0163, -0.0426],
        [ 0.0019, -0.0164,  0.0566,  ...,  0.0118,  0.0250,  0.0222],
        ...,
        [-0.0385,  0.0449, -0.0154,  ...,  0.0288,  0.0068, -0.0083],
        [-0.0292, -0.0101,  0.0016,  ...,  0.0027,  0.0141,  0.0065],
        [ 0.0361, -0.0351,  0.0108,  ..., -0.0118,  0.0164,  0.0269]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.7861, -4.1758, -1.2832,  ...,  0.3838, -3.3145,  2.2676]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 03:30:33 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Another word for lazy is indolent
Another word for sofa is couch
Another word for incorrect is wrong
Another word for railway is railroad
Another word for hieroglyph is hieroglyphic
Another word for rational is logical
Another word for reasonable is sensible
Another word for baby is
2024-07-29 03:30:33 root INFO     [order_1_approx] starting weight calculation for Another word for lazy is indolent
Another word for railway is railroad
Another word for baby is infant
Another word for sofa is couch
Another word for incorrect is wrong
Another word for hieroglyph is hieroglyphic
Another word for rational is logical
Another word for reasonable is
2024-07-29 03:30:33 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-29 03:32:56 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3096,  0.0559,  0.0730,  ..., -0.8296, -0.0999,  0.0128],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.8594,  1.7549, -1.1328,  ..., -3.0645, -8.5469, -1.4824],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0642, -0.0121,  0.0207,  ...,  0.0091, -0.0187,  0.0360],
        [-0.0088,  0.0141,  0.0016,  ..., -0.0138,  0.0047,  0.0037],
        [ 0.0168, -0.0058,  0.0786,  ...,  0.0114,  0.0047,  0.0121],
        ...,
        [ 0.0077,  0.0239,  0.0307,  ...,  0.0764,  0.0228, -0.0195],
        [ 0.0421,  0.0343, -0.0070,  ..., -0.0109,  0.0280,  0.0237],
        [ 0.0109, -0.0039,  0.0169,  ..., -0.0023, -0.0173,  0.0327]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.7441,  1.8438, -0.9888,  ..., -2.6719, -8.2734, -1.4424]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 03:32:57 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Another word for lazy is indolent
Another word for railway is railroad
Another word for baby is infant
Another word for sofa is couch
Another word for incorrect is wrong
Another word for hieroglyph is hieroglyphic
Another word for rational is logical
Another word for reasonable is
2024-07-29 03:32:57 root INFO     [order_1_approx] starting weight calculation for Another word for railway is railroad
Another word for rational is logical
Another word for hieroglyph is hieroglyphic
Another word for reasonable is sensible
Another word for lazy is indolent
Another word for baby is infant
Another word for sofa is couch
Another word for incorrect is
2024-07-29 03:32:57 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-29 03:35:20 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0098, -0.1049, -0.2034,  ..., -0.1014, -0.1356,  0.1038],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.4434,  0.3130,  3.0020,  ...,  0.7251, -2.3730, -2.2305],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0486, -0.0453,  0.0221,  ...,  0.0273, -0.0278, -0.0072],
        [-0.0089,  0.0421,  0.0157,  ..., -0.0308, -0.0147, -0.0046],
        [-0.0052,  0.0063,  0.0706,  ...,  0.0066,  0.0164, -0.0237],
        ...,
        [ 0.0008,  0.0361,  0.0058,  ...,  0.0609,  0.0137, -0.0150],
        [-0.0077, -0.0135, -0.0087,  ..., -0.0062,  0.0496, -0.0026],
        [ 0.0155, -0.0032, -0.0203,  ...,  0.0033, -0.0186,  0.0583]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.0188,  0.5098,  3.1445,  ...,  0.9570, -2.3652, -2.3359]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 03:35:21 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Another word for railway is railroad
Another word for rational is logical
Another word for hieroglyph is hieroglyphic
Another word for reasonable is sensible
Another word for lazy is indolent
Another word for baby is infant
Another word for sofa is couch
Another word for incorrect is
2024-07-29 03:35:21 root INFO     [order_1_approx] starting weight calculation for Another word for incorrect is wrong
Another word for reasonable is sensible
Another word for rational is logical
Another word for hieroglyph is hieroglyphic
Another word for lazy is indolent
Another word for baby is infant
Another word for sofa is couch
Another word for railway is
2024-07-29 03:35:21 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-29 03:37:44 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1823, -0.0146,  0.2671,  ...,  0.0999,  0.2512,  0.0338],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.5015, -5.0273,  3.4258,  ...,  2.3418, -1.4170, -2.4766],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.1030,  0.0011,  0.0269,  ...,  0.0199,  0.0417,  0.0162],
        [-0.0137,  0.0814,  0.0120,  ..., -0.0047,  0.0278, -0.0246],
        [ 0.0019, -0.0010,  0.0577,  ..., -0.0167, -0.0314,  0.0525],
        ...,
        [ 0.0264,  0.0182,  0.0157,  ...,  0.0548,  0.0047, -0.0294],
        [-0.0372,  0.0286,  0.0077,  ...,  0.0102,  0.0770,  0.0153],
        [-0.0053,  0.0219,  0.0325,  ..., -0.0392, -0.0039,  0.0506]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.8760, -4.5234,  3.5820,  ...,  2.5020, -1.2070, -2.2266]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 03:37:48 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Another word for incorrect is wrong
Another word for reasonable is sensible
Another word for rational is logical
Another word for hieroglyph is hieroglyphic
Another word for lazy is indolent
Another word for baby is infant
Another word for sofa is couch
Another word for railway is
2024-07-29 03:37:48 root INFO     total operator prediction time: 1149.9543569087982 seconds
2024-07-29 03:37:48 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on animal - youth
2024-07-29 03:37:48 root INFO     building operator animal - youth
2024-07-29 03:37:56 root INFO     [order_1_approx] starting weight calculation for The offspring of a rabbit is referred to as a bunny
The offspring of a sheep is referred to as a lamb
The offspring of a goat is referred to as a kid
The offspring of a fly is referred to as a grub
The offspring of a wolf is referred to as a cub
The offspring of a tiger is referred to as a cub
The offspring of a gorilla is referred to as a infant
The offspring of a horse is referred to as a
2024-07-29 03:37:56 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-29 03:40:22 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1143, -0.1882, -0.0013,  ...,  0.2637, -0.0651,  0.1937],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.4062, -4.7891, -2.7695,  ...,  2.0527, -1.4463,  2.1562],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0246, -0.0303, -0.0096,  ..., -0.0055, -0.0212,  0.0127],
        [-0.0006,  0.0311,  0.0110,  ...,  0.0097,  0.0088, -0.0152],
        [-0.0021,  0.0006,  0.0348,  ..., -0.0035, -0.0271, -0.0083],
        ...,
        [ 0.0003, -0.0060,  0.0058,  ...,  0.0357,  0.0109, -0.0016],
        [ 0.0211,  0.0296,  0.0156,  ...,  0.0310,  0.0231,  0.0004],
        [ 0.0164, -0.0028,  0.0071,  ..., -0.0179,  0.0002,  0.0227]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.5391, -4.4297, -2.5254,  ...,  2.4062, -1.8887,  2.0879]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 03:40:23 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The offspring of a rabbit is referred to as a bunny
The offspring of a sheep is referred to as a lamb
The offspring of a goat is referred to as a kid
The offspring of a fly is referred to as a grub
The offspring of a wolf is referred to as a cub
The offspring of a tiger is referred to as a cub
The offspring of a gorilla is referred to as a infant
The offspring of a horse is referred to as a
2024-07-29 03:40:23 root INFO     [order_1_approx] starting weight calculation for The offspring of a horse is referred to as a foal
The offspring of a goat is referred to as a kid
The offspring of a rabbit is referred to as a bunny
The offspring of a gorilla is referred to as a infant
The offspring of a wolf is referred to as a cub
The offspring of a fly is referred to as a grub
The offspring of a tiger is referred to as a cub
The offspring of a sheep is referred to as a
2024-07-29 03:40:23 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-29 03:42:46 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 6.1890e-02, -3.6621e-04, -4.5319e-02,  ...,  2.6685e-01,
        -2.4414e-01,  4.7021e-01], device='cuda:0', dtype=torch.float16,
       grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.2109, -2.1289,  0.6069,  ...,  1.9346, -2.2539, -1.9434],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0153, -0.0204, -0.0064,  ..., -0.0010, -0.0339, -0.0219],
        [ 0.0040,  0.0333,  0.0139,  ...,  0.0114,  0.0027, -0.0299],
        [ 0.0086,  0.0022,  0.0353,  ..., -0.0139, -0.0120, -0.0053],
        ...,
        [ 0.0053,  0.0171,  0.0174,  ...,  0.0573,  0.0275, -0.0017],
        [ 0.0183,  0.0273,  0.0105,  ...,  0.0132,  0.0149,  0.0054],
        [ 0.0009,  0.0107, -0.0141,  ..., -0.0246, -0.0116,  0.0231]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.4121, -1.8984,  0.6743,  ...,  2.2617, -2.3008, -1.8008]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 03:42:47 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The offspring of a horse is referred to as a foal
The offspring of a goat is referred to as a kid
The offspring of a rabbit is referred to as a bunny
The offspring of a gorilla is referred to as a infant
The offspring of a wolf is referred to as a cub
The offspring of a fly is referred to as a grub
The offspring of a tiger is referred to as a cub
The offspring of a sheep is referred to as a
2024-07-29 03:42:47 root INFO     [order_1_approx] starting weight calculation for The offspring of a goat is referred to as a kid
The offspring of a gorilla is referred to as a infant
The offspring of a rabbit is referred to as a bunny
The offspring of a fly is referred to as a grub
The offspring of a horse is referred to as a foal
The offspring of a wolf is referred to as a cub
The offspring of a sheep is referred to as a lamb
The offspring of a tiger is referred to as a
2024-07-29 03:42:47 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-29 03:45:08 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0341,  0.2783, -0.2343,  ...,  0.2654, -0.3472, -0.1301],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.5547, -5.3359, -2.6523,  ...,  0.1123, -1.1660,  0.9170],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0370, -0.0174, -0.0246,  ...,  0.0035, -0.0133, -0.0014],
        [ 0.0006,  0.0287,  0.0153,  ..., -0.0125, -0.0071, -0.0192],
        [ 0.0049,  0.0077,  0.0463,  ...,  0.0147,  0.0177, -0.0049],
        ...,
        [ 0.0079, -0.0083,  0.0350,  ...,  0.0473,  0.0187, -0.0079],
        [ 0.0122, -0.0182,  0.0138,  ...,  0.0116,  0.0132,  0.0127],
        [-0.0010,  0.0027, -0.0200,  ..., -0.0343, -0.0200,  0.0417]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.6465, -4.8594, -2.2363,  ...,  0.5205, -1.1221,  0.6074]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 03:45:09 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The offspring of a goat is referred to as a kid
The offspring of a gorilla is referred to as a infant
The offspring of a rabbit is referred to as a bunny
The offspring of a fly is referred to as a grub
The offspring of a horse is referred to as a foal
The offspring of a wolf is referred to as a cub
The offspring of a sheep is referred to as a lamb
The offspring of a tiger is referred to as a
2024-07-29 03:45:10 root INFO     [order_1_approx] starting weight calculation for The offspring of a rabbit is referred to as a bunny
The offspring of a sheep is referred to as a lamb
The offspring of a wolf is referred to as a cub
The offspring of a horse is referred to as a foal
The offspring of a gorilla is referred to as a infant
The offspring of a goat is referred to as a kid
The offspring of a tiger is referred to as a cub
The offspring of a fly is referred to as a
2024-07-29 03:45:10 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-29 03:47:33 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4343,  0.0552, -0.2908,  ...,  0.3625,  0.1001,  0.5342],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.3672, -3.0664, -1.5264,  ..., -0.7515, -2.2168,  0.9199],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0440, -0.0137,  0.0088,  ...,  0.0307, -0.0144, -0.0151],
        [ 0.0076,  0.0333,  0.0221,  ..., -0.0060,  0.0130, -0.0189],
        [-0.0043,  0.0146,  0.0554,  ..., -0.0096, -0.0009, -0.0052],
        ...,
        [-0.0020, -0.0079, -0.0072,  ...,  0.0436,  0.0204,  0.0060],
        [ 0.0196, -0.0117,  0.0306,  ...,  0.0252, -0.0155,  0.0032],
        [ 0.0170, -0.0114, -0.0145,  ..., -0.0245, -0.0123,  0.0295]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.1719, -3.0254, -1.7666,  ..., -0.3281, -2.0918,  0.8389]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 03:47:34 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The offspring of a rabbit is referred to as a bunny
The offspring of a sheep is referred to as a lamb
The offspring of a wolf is referred to as a cub
The offspring of a horse is referred to as a foal
The offspring of a gorilla is referred to as a infant
The offspring of a goat is referred to as a kid
The offspring of a tiger is referred to as a cub
The offspring of a fly is referred to as a
2024-07-29 03:47:34 root INFO     [order_1_approx] starting weight calculation for The offspring of a wolf is referred to as a cub
The offspring of a horse is referred to as a foal
The offspring of a rabbit is referred to as a bunny
The offspring of a goat is referred to as a kid
The offspring of a sheep is referred to as a lamb
The offspring of a fly is referred to as a grub
The offspring of a tiger is referred to as a cub
The offspring of a gorilla is referred to as a
2024-07-29 03:47:34 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-29 03:49:55 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2881, -0.1416, -0.2272,  ..., -0.1575, -0.6777,  0.1586],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.5615, -3.8633, -0.9717,  ...,  0.4443, -3.0566,  1.8916],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0311, -0.0130, -0.0121,  ...,  0.0021,  0.0032, -0.0053],
        [-0.0071,  0.0195,  0.0206,  ..., -0.0046, -0.0025, -0.0013],
        [-0.0002,  0.0066,  0.0336,  ...,  0.0047,  0.0103, -0.0050],
        ...,
        [-0.0123,  0.0153, -0.0029,  ...,  0.0304,  0.0107, -0.0110],
        [ 0.0149, -0.0174,  0.0195,  ...,  0.0023,  0.0108,  0.0145],
        [-0.0153,  0.0031, -0.0107,  ..., -0.0304, -0.0186,  0.0187]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.5029, -3.8730, -0.7695,  ...,  0.8154, -3.4023,  1.5527]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 03:49:57 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The offspring of a wolf is referred to as a cub
The offspring of a horse is referred to as a foal
The offspring of a rabbit is referred to as a bunny
The offspring of a goat is referred to as a kid
The offspring of a sheep is referred to as a lamb
The offspring of a fly is referred to as a grub
The offspring of a tiger is referred to as a cub
The offspring of a gorilla is referred to as a
2024-07-29 03:49:57 root INFO     [order_1_approx] starting weight calculation for The offspring of a rabbit is referred to as a bunny
The offspring of a fly is referred to as a grub
The offspring of a tiger is referred to as a cub
The offspring of a wolf is referred to as a cub
The offspring of a horse is referred to as a foal
The offspring of a sheep is referred to as a lamb
The offspring of a gorilla is referred to as a infant
The offspring of a goat is referred to as a
2024-07-29 03:49:57 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-29 03:52:19 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1649, -0.0182,  0.2261,  ...,  0.0754, -0.3599,  0.4485],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 5.3828, -3.3594, -0.1016,  ...,  0.4814, -2.8730, -2.3281],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0371, -0.0085,  0.0087,  ..., -0.0058, -0.0024, -0.0097],
        [-0.0021,  0.0347,  0.0085,  ...,  0.0098, -0.0077, -0.0178],
        [-0.0009, -0.0099,  0.0221,  ..., -0.0092, -0.0037, -0.0063],
        ...,
        [-0.0011,  0.0044, -0.0075,  ...,  0.0515,  0.0233,  0.0032],
        [ 0.0303,  0.0191,  0.0144,  ...,  0.0094,  0.0136, -0.0017],
        [ 0.0061,  0.0048, -0.0152,  ..., -0.0206, -0.0053,  0.0287]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 5.3242, -3.0742,  0.0157,  ...,  0.9766, -3.0195, -2.3906]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 03:52:20 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The offspring of a rabbit is referred to as a bunny
The offspring of a fly is referred to as a grub
The offspring of a tiger is referred to as a cub
The offspring of a wolf is referred to as a cub
The offspring of a horse is referred to as a foal
The offspring of a sheep is referred to as a lamb
The offspring of a gorilla is referred to as a infant
The offspring of a goat is referred to as a
2024-07-29 03:52:20 root INFO     [order_1_approx] starting weight calculation for The offspring of a gorilla is referred to as a infant
The offspring of a tiger is referred to as a cub
The offspring of a horse is referred to as a foal
The offspring of a sheep is referred to as a lamb
The offspring of a goat is referred to as a kid
The offspring of a fly is referred to as a grub
The offspring of a wolf is referred to as a cub
The offspring of a rabbit is referred to as a
2024-07-29 03:52:20 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-29 03:54:44 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1775,  0.0310, -0.1228,  ..., -0.0165, -0.4019, -0.2194],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 6.1289, -2.4629, -0.4180,  ...,  1.1387, -2.2520, -0.4473],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0299, -0.0112, -0.0083,  ...,  0.0204, -0.0054, -0.0021],
        [-0.0003,  0.0215,  0.0192,  ...,  0.0117,  0.0139, -0.0233],
        [ 0.0049, -0.0010,  0.0214,  ..., -0.0001, -0.0034, -0.0159],
        ...,
        [ 0.0039,  0.0016,  0.0015,  ...,  0.0173,  0.0187, -0.0003],
        [ 0.0158, -0.0010,  0.0050,  ...,  0.0004,  0.0131,  0.0010],
        [-0.0073,  0.0126, -0.0151,  ..., -0.0194, -0.0113,  0.0224]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 6.1719, -2.4707, -0.4636,  ...,  1.1807, -2.2285, -0.5625]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 03:54:45 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The offspring of a gorilla is referred to as a infant
The offspring of a tiger is referred to as a cub
The offspring of a horse is referred to as a foal
The offspring of a sheep is referred to as a lamb
The offspring of a goat is referred to as a kid
The offspring of a fly is referred to as a grub
The offspring of a wolf is referred to as a cub
The offspring of a rabbit is referred to as a
2024-07-29 03:54:45 root INFO     [order_1_approx] starting weight calculation for The offspring of a horse is referred to as a foal
The offspring of a rabbit is referred to as a bunny
The offspring of a tiger is referred to as a cub
The offspring of a gorilla is referred to as a infant
The offspring of a goat is referred to as a kid
The offspring of a fly is referred to as a grub
The offspring of a sheep is referred to as a lamb
The offspring of a wolf is referred to as a
2024-07-29 03:54:45 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-29 03:57:12 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2708,  0.1193, -0.0550,  ...,  0.0548, -0.3110, -0.2996],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.4336, -6.6797, -3.1055,  ...,  0.3472, -2.5000,  2.2500],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 4.0710e-02, -2.2217e-02, -2.6337e-02,  ..., -4.9896e-03,
         -2.2324e-02,  1.1650e-02],
        [-5.5656e-03,  3.6926e-02,  5.2261e-03,  ..., -6.4011e-03,
          2.7817e-02, -1.2413e-02],
        [-8.3618e-03, -6.3858e-03,  2.4734e-02,  ...,  1.0815e-03,
         -1.5526e-02,  9.1553e-05],
        ...,
        [-2.1210e-03,  1.1276e-02,  3.0460e-03,  ...,  2.9831e-02,
          1.6754e-02, -6.9504e-03],
        [ 1.4313e-02, -2.2125e-02,  1.6312e-02,  ...,  2.3529e-02,
          6.3133e-03,  5.3406e-05],
        [ 8.5449e-03, -8.9169e-04,  9.3842e-03,  ..., -6.4201e-03,
         -1.5869e-02,  1.2062e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.5488, -5.9727, -2.4180,  ...,  0.6934, -2.4707,  1.9395]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 03:57:13 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The offspring of a horse is referred to as a foal
The offspring of a rabbit is referred to as a bunny
The offspring of a tiger is referred to as a cub
The offspring of a gorilla is referred to as a infant
The offspring of a goat is referred to as a kid
The offspring of a fly is referred to as a grub
The offspring of a sheep is referred to as a lamb
The offspring of a wolf is referred to as a
2024-07-29 03:57:13 root INFO     total operator prediction time: 1165.455759525299 seconds
2024-07-29 03:57:13 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on animal - sound
2024-07-29 03:57:13 root INFO     building operator animal - sound
2024-07-29 03:57:13 root INFO     [order_1_approx] starting weight calculation for The sound that a pigeon makes is called a coo
The sound that a elephant makes is called a trumpet
The sound that a gorilla makes is called a grunt
The sound that a coyote makes is called a howl
The sound that a whale makes is called a sing
The sound that a duck makes is called a quack
The sound that a bear makes is called a growl
The sound that a magpie makes is called a
2024-07-29 03:57:13 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-29 03:59:37 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0403,  0.0200, -0.2734,  ...,  0.5513, -0.6699,  0.1166],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.5493, -0.2764,  2.8750,  ...,  1.2734, -2.0449,  1.2178],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0799,  0.0091, -0.0058,  ..., -0.0043, -0.0222,  0.0024],
        [-0.0695,  0.0404,  0.0174,  ...,  0.0370,  0.0824, -0.0430],
        [ 0.0089,  0.0087,  0.0566,  ..., -0.0272, -0.0258,  0.0062],
        ...,
        [ 0.0364, -0.0092,  0.0428,  ...,  0.0414, -0.0032, -0.0175],
        [-0.0500,  0.0110, -0.0166,  ...,  0.0048,  0.0268,  0.0193],
        [ 0.0413,  0.0215, -0.0043,  ..., -0.0450, -0.0475,  0.0586]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.1523, -0.4187,  3.2305,  ...,  0.7007, -1.9043,  1.0215]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 03:59:38 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The sound that a pigeon makes is called a coo
The sound that a elephant makes is called a trumpet
The sound that a gorilla makes is called a grunt
The sound that a coyote makes is called a howl
The sound that a whale makes is called a sing
The sound that a duck makes is called a quack
The sound that a bear makes is called a growl
The sound that a magpie makes is called a
2024-07-29 03:59:38 root INFO     [order_1_approx] starting weight calculation for The sound that a elephant makes is called a trumpet
The sound that a coyote makes is called a howl
The sound that a pigeon makes is called a coo
The sound that a gorilla makes is called a grunt
The sound that a duck makes is called a quack
The sound that a magpie makes is called a chatter
The sound that a whale makes is called a sing
The sound that a bear makes is called a
2024-07-29 03:59:38 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-29 04:02:03 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1132,  0.0711, -0.0290,  ..., -0.1423, -0.4746,  0.1968],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.5449, -3.6523,  0.4648,  ..., -1.6094,  0.3608,  1.6328],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0421, -0.0286,  0.0071,  ..., -0.0171, -0.0419, -0.0165],
        [-0.0117,  0.0609, -0.0032,  ...,  0.0256, -0.0297, -0.0201],
        [-0.0089,  0.0152,  0.0604,  ..., -0.0300, -0.0074, -0.0111],
        ...,
        [ 0.0316,  0.0250,  0.0004,  ...,  0.0640,  0.0120, -0.0273],
        [ 0.0084, -0.0064, -0.0131,  ...,  0.0142,  0.0272,  0.0033],
        [-0.0201, -0.0090, -0.0359,  ..., -0.0182, -0.0042,  0.0395]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.7754, -4.0156,  0.3918,  ..., -1.7363,  0.5132,  1.6670]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 04:02:04 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The sound that a elephant makes is called a trumpet
The sound that a coyote makes is called a howl
The sound that a pigeon makes is called a coo
The sound that a gorilla makes is called a grunt
The sound that a duck makes is called a quack
The sound that a magpie makes is called a chatter
The sound that a whale makes is called a sing
The sound that a bear makes is called a
2024-07-29 04:02:04 root INFO     [order_1_approx] starting weight calculation for The sound that a coyote makes is called a howl
The sound that a whale makes is called a sing
The sound that a magpie makes is called a chatter
The sound that a elephant makes is called a trumpet
The sound that a gorilla makes is called a grunt
The sound that a duck makes is called a quack
The sound that a bear makes is called a growl
The sound that a pigeon makes is called a
2024-07-29 04:02:04 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-29 04:04:26 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1559, -0.1046, -0.2883,  ...,  0.1921, -0.1714, -0.2272],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.0410, -4.0938,  5.7656,  ...,  0.7344, -1.2500,  2.3594],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0169,  0.0026, -0.0017,  ..., -0.0063, -0.0101, -0.0084],
        [-0.0067,  0.0139,  0.0091,  ...,  0.0092,  0.0221, -0.0137],
        [-0.0088,  0.0059,  0.0204,  ..., -0.0061,  0.0042, -0.0092],
        ...,
        [ 0.0083,  0.0035,  0.0006,  ...,  0.0131,  0.0033, -0.0033],
        [ 0.0029,  0.0127, -0.0003,  ...,  0.0036,  0.0153, -0.0019],
        [-0.0028, -0.0068, -0.0008,  ..., -0.0146, -0.0069,  0.0072]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.1953, -4.2109,  5.6992,  ...,  0.6821, -1.3105,  2.4277]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 04:04:27 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The sound that a coyote makes is called a howl
The sound that a whale makes is called a sing
The sound that a magpie makes is called a chatter
The sound that a elephant makes is called a trumpet
The sound that a gorilla makes is called a grunt
The sound that a duck makes is called a quack
The sound that a bear makes is called a growl
The sound that a pigeon makes is called a
2024-07-29 04:04:27 root INFO     [order_1_approx] starting weight calculation for The sound that a magpie makes is called a chatter
The sound that a whale makes is called a sing
The sound that a duck makes is called a quack
The sound that a elephant makes is called a trumpet
The sound that a bear makes is called a growl
The sound that a coyote makes is called a howl
The sound that a pigeon makes is called a coo
The sound that a gorilla makes is called a
2024-07-29 04:04:27 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-29 04:06:44 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0962, -0.3508, -0.3064,  ..., -0.1448, -0.6738,  0.1343],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 5.2188, -4.8906,  1.5596,  ...,  0.0693, -0.9165,  0.3135],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0204,  0.0063, -0.0192,  ..., -0.0093, -0.0089, -0.0250],
        [ 0.0041,  0.0378, -0.0017,  ...,  0.0215, -0.0258, -0.0074],
        [-0.0082,  0.0049,  0.0355,  ..., -0.0325,  0.0173, -0.0065],
        ...,
        [ 0.0083,  0.0346, -0.0058,  ...,  0.0579, -0.0186,  0.0018],
        [ 0.0145, -0.0263,  0.0042,  ...,  0.0030,  0.0440, -0.0006],
        [-0.0184, -0.0014, -0.0171,  ..., -0.0404, -0.0009,  0.0312]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 5.4102, -4.9844,  1.5264,  ...,  0.1398, -1.1543,  0.1212]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 04:06:45 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The sound that a magpie makes is called a chatter
The sound that a whale makes is called a sing
The sound that a duck makes is called a quack
The sound that a elephant makes is called a trumpet
The sound that a bear makes is called a growl
The sound that a coyote makes is called a howl
The sound that a pigeon makes is called a coo
The sound that a gorilla makes is called a
2024-07-29 04:06:45 root INFO     [order_1_approx] starting weight calculation for The sound that a pigeon makes is called a coo
The sound that a whale makes is called a sing
The sound that a gorilla makes is called a grunt
The sound that a magpie makes is called a chatter
The sound that a elephant makes is called a trumpet
The sound that a bear makes is called a growl
The sound that a duck makes is called a quack
The sound that a coyote makes is called a
2024-07-29 04:06:45 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-29 04:09:07 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0764,  0.1726, -0.3015,  ...,  0.1462, -0.3130, -0.2484],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.9160, -6.4297,  0.2041,  ..., -2.6055, -0.3618,  2.0352],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0331, -0.0046,  0.0014,  ..., -0.0256, -0.0177,  0.0120],
        [-0.0257,  0.0350, -0.0044,  ...,  0.0032,  0.0159, -0.0366],
        [ 0.0061,  0.0081,  0.0535,  ..., -0.0179, -0.0213,  0.0034],
        ...,
        [-0.0043,  0.0179,  0.0037,  ...,  0.0581, -0.0054, -0.0050],
        [ 0.0107, -0.0207,  0.0056,  ..., -0.0009,  0.0015, -0.0027],
        [-0.0061, -0.0032, -0.0370,  ..., -0.0147, -0.0181,  0.0048]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.9863, -6.1602,  0.4565,  ..., -2.6289, -0.4106,  1.6992]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 04:09:08 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The sound that a pigeon makes is called a coo
The sound that a whale makes is called a sing
The sound that a gorilla makes is called a grunt
The sound that a magpie makes is called a chatter
The sound that a elephant makes is called a trumpet
The sound that a bear makes is called a growl
The sound that a duck makes is called a quack
The sound that a coyote makes is called a
2024-07-29 04:09:08 root INFO     [order_1_approx] starting weight calculation for The sound that a coyote makes is called a howl
The sound that a bear makes is called a growl
The sound that a pigeon makes is called a coo
The sound that a magpie makes is called a chatter
The sound that a gorilla makes is called a grunt
The sound that a duck makes is called a quack
The sound that a elephant makes is called a trumpet
The sound that a whale makes is called a
2024-07-29 04:09:08 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-29 04:11:23 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2258, -0.0332, -0.0642,  ..., -0.2671, -0.1479, -0.0463],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.4805, -1.0439,  3.2383,  ...,  1.4365, -1.8457,  1.3955],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0413, -0.0048, -0.0136,  ...,  0.0047, -0.0139,  0.0119],
        [ 0.0096,  0.0753, -0.0232,  ..., -0.0114, -0.0283, -0.0212],
        [-0.0174,  0.0119,  0.0425,  ..., -0.0008, -0.0228, -0.0237],
        ...,
        [ 0.0206,  0.0183, -0.0029,  ...,  0.0454, -0.0042, -0.0084],
        [-0.0001,  0.0039,  0.0041,  ...,  0.0102,  0.0126,  0.0011],
        [ 0.0122, -0.0199, -0.0074,  ..., -0.0072, -0.0080,  0.0321]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.2671, -1.1641,  2.9355,  ...,  1.4922, -1.6768,  1.4961]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 04:11:24 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The sound that a coyote makes is called a howl
The sound that a bear makes is called a growl
The sound that a pigeon makes is called a coo
The sound that a magpie makes is called a chatter
The sound that a gorilla makes is called a grunt
The sound that a duck makes is called a quack
The sound that a elephant makes is called a trumpet
The sound that a whale makes is called a
2024-07-29 04:11:24 root INFO     [order_1_approx] starting weight calculation for The sound that a bear makes is called a growl
The sound that a magpie makes is called a chatter
The sound that a gorilla makes is called a grunt
The sound that a whale makes is called a sing
The sound that a elephant makes is called a trumpet
The sound that a pigeon makes is called a coo
The sound that a coyote makes is called a howl
The sound that a duck makes is called a
2024-07-29 04:11:24 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-29 04:13:42 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1301, -0.1227,  0.3418,  ...,  0.1443, -0.3245,  0.1277],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.1260, -4.5625,  3.3828,  ...,  1.3086, -4.7422,  2.3105],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0294, -0.0134, -0.0139,  ...,  0.0028, -0.0186, -0.0065],
        [-0.0066,  0.0482,  0.0137,  ..., -0.0064, -0.0147, -0.0200],
        [-0.0150, -0.0063,  0.0337,  ..., -0.0221, -0.0133,  0.0038],
        ...,
        [ 0.0042,  0.0103,  0.0046,  ...,  0.0364,  0.0088, -0.0184],
        [ 0.0046,  0.0149,  0.0163,  ...,  0.0154,  0.0332,  0.0003],
        [-0.0051, -0.0045, -0.0053,  ..., -0.0231, -0.0102,  0.0293]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.2700, -4.7383,  3.3828,  ...,  1.0527, -4.6992,  2.5254]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 04:13:43 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The sound that a bear makes is called a growl
The sound that a magpie makes is called a chatter
The sound that a gorilla makes is called a grunt
The sound that a whale makes is called a sing
The sound that a elephant makes is called a trumpet
The sound that a pigeon makes is called a coo
The sound that a coyote makes is called a howl
The sound that a duck makes is called a
2024-07-29 04:13:43 root INFO     [order_1_approx] starting weight calculation for The sound that a whale makes is called a sing
The sound that a magpie makes is called a chatter
The sound that a pigeon makes is called a coo
The sound that a bear makes is called a growl
The sound that a coyote makes is called a howl
The sound that a duck makes is called a quack
The sound that a gorilla makes is called a grunt
The sound that a elephant makes is called a
2024-07-29 04:13:43 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-29 04:16:03 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0941, -0.2246,  0.3503,  ...,  0.0491, -0.4075, -0.2515],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.3633, -2.9551,  2.2031,  ...,  1.3506, -0.8984,  0.5547],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0010,  0.0009, -0.0033,  ..., -0.0060, -0.0105,  0.0007],
        [-0.0009,  0.0098,  0.0065,  ..., -0.0032, -0.0030, -0.0072],
        [-0.0119, -0.0072,  0.0043,  ..., -0.0108,  0.0018, -0.0031],
        ...,
        [ 0.0051,  0.0074, -0.0011,  ...,  0.0158,  0.0002, -0.0052],
        [ 0.0086, -0.0026,  0.0007,  ...,  0.0009,  0.0040,  0.0010],
        [-0.0010, -0.0062, -0.0050,  ..., -0.0081,  0.0026,  0.0028]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.3730, -2.9141,  2.1602,  ...,  1.3203, -0.8945,  0.4961]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 04:16:03 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The sound that a whale makes is called a sing
The sound that a magpie makes is called a chatter
The sound that a pigeon makes is called a coo
The sound that a bear makes is called a growl
The sound that a coyote makes is called a howl
The sound that a duck makes is called a quack
The sound that a gorilla makes is called a grunt
The sound that a elephant makes is called a
2024-07-29 04:16:03 root INFO     total operator prediction time: 1130.4402770996094 seconds
2024-07-29 04:16:03 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on things - color
2024-07-29 04:16:03 root INFO     building operator things - color
2024-07-29 04:16:04 root INFO     [order_1_approx] starting weight calculation for The grass is colored green
The cloud is colored white
The parsley is colored green
The peony is colored red
The coal is colored black
The frog is colored green
The soil is colored black
The sun is colored
2024-07-29 04:16:04 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-29 04:18:26 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1638, -0.0673, -0.2073,  ...,  0.0217, -0.4299, -0.1750],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-3.8125, -7.7383, -0.9907,  ..., -1.8770, -2.1250, -1.0088],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0436, -0.0112, -0.0046,  ..., -0.0066, -0.0011,  0.0052],
        [-0.0014,  0.0543,  0.0141,  ..., -0.0059,  0.0025, -0.0192],
        [-0.0136,  0.0016,  0.0522,  ...,  0.0100,  0.0145,  0.0306],
        ...,
        [-0.0046,  0.0011,  0.0174,  ...,  0.0656,  0.0061, -0.0057],
        [ 0.0011, -0.0033,  0.0181,  ..., -0.0034,  0.0237,  0.0078],
        [-0.0053, -0.0009,  0.0061,  ...,  0.0022, -0.0108,  0.0423]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-3.6309, -7.7773, -1.0879,  ..., -1.7529, -2.2520, -1.0186]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 04:18:27 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The grass is colored green
The cloud is colored white
The parsley is colored green
The peony is colored red
The coal is colored black
The frog is colored green
The soil is colored black
The sun is colored
2024-07-29 04:18:28 root INFO     [order_1_approx] starting weight calculation for The sun is colored yellow
The cloud is colored white
The parsley is colored green
The soil is colored black
The grass is colored green
The frog is colored green
The coal is colored black
The peony is colored
2024-07-29 04:18:28 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-29 04:20:50 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0720, -0.0578, -0.4749,  ..., -0.1013, -0.5361, -0.0347],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.1348, -5.2148,  1.9912,  ...,  0.1299, -1.8623, -0.0518],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0532, -0.0067,  0.0173,  ..., -0.0118,  0.0174,  0.0033],
        [ 0.0028,  0.0311,  0.0267,  ..., -0.0060,  0.0101, -0.0063],
        [-0.0004,  0.0145,  0.0343,  ...,  0.0157,  0.0077,  0.0064],
        ...,
        [ 0.0128,  0.0014, -0.0051,  ...,  0.0452, -0.0215, -0.0037],
        [-0.0005,  0.0004, -0.0087,  ...,  0.0139,  0.0464, -0.0176],
        [-0.0153,  0.0035, -0.0007,  ...,  0.0172, -0.0008,  0.0284]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.0664, -5.2227,  1.7842,  ...,  0.3325, -1.8340, -0.2418]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 04:20:51 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The sun is colored yellow
The cloud is colored white
The parsley is colored green
The soil is colored black
The grass is colored green
The frog is colored green
The coal is colored black
The peony is colored
2024-07-29 04:20:51 root INFO     [order_1_approx] starting weight calculation for The grass is colored green
The cloud is colored white
The soil is colored black
The frog is colored green
The parsley is colored green
The peony is colored red
The sun is colored yellow
The coal is colored
2024-07-29 04:20:51 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-29 04:23:13 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1743, -0.0197, -0.4580,  ..., -0.1586, -0.0554,  0.3386],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.2178, -5.6719, -0.9824,  ..., -4.6367,  0.6621, -4.1758],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0771,  0.0199, -0.0046,  ..., -0.0017,  0.0181, -0.0076],
        [ 0.0123,  0.0369,  0.0187,  ..., -0.0046,  0.0204, -0.0032],
        [-0.0024, -0.0076,  0.0220,  ...,  0.0116,  0.0072,  0.0091],
        ...,
        [ 0.0148, -0.0100,  0.0153,  ...,  0.0489,  0.0237,  0.0068],
        [ 0.0074,  0.0284,  0.0061,  ...,  0.0002,  0.0332, -0.0023],
        [-0.0039, -0.0331, -0.0027,  ...,  0.0042, -0.0166,  0.0251]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.0420, -5.7383, -1.0371,  ..., -4.3867,  0.3384, -3.5000]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 04:23:14 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The grass is colored green
The cloud is colored white
The soil is colored black
The frog is colored green
The parsley is colored green
The peony is colored red
The sun is colored yellow
The coal is colored
2024-07-29 04:23:14 root INFO     [order_1_approx] starting weight calculation for The peony is colored red
The cloud is colored white
The frog is colored green
The grass is colored green
The parsley is colored green
The coal is colored black
The sun is colored yellow
The soil is colored
2024-07-29 04:23:15 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-29 04:25:33 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1708, -0.0210, -0.5581,  ...,  0.1482, -0.5889,  0.0727],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.5493, -5.7109,  0.4373,  ..., -1.7305,  0.8955, -2.3418],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0410,  0.0094, -0.0084,  ...,  0.0209,  0.0076,  0.0032],
        [-0.0072,  0.0249,  0.0180,  ...,  0.0083, -0.0147, -0.0088],
        [-0.0139, -0.0070,  0.0357,  ...,  0.0197,  0.0029,  0.0118],
        ...,
        [ 0.0070, -0.0163,  0.0144,  ...,  0.0448, -0.0076, -0.0143],
        [-0.0019,  0.0296,  0.0066,  ...,  0.0054,  0.0326,  0.0045],
        [-0.0056, -0.0176, -0.0056,  ...,  0.0002, -0.0195,  0.0156]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.6851, -5.4609,  0.4512,  ..., -1.6172,  0.7920, -2.1777]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 04:25:34 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The peony is colored red
The cloud is colored white
The frog is colored green
The grass is colored green
The parsley is colored green
The coal is colored black
The sun is colored yellow
The soil is colored
2024-07-29 04:25:34 root INFO     [order_1_approx] starting weight calculation for The soil is colored black
The frog is colored green
The peony is colored red
The parsley is colored green
The coal is colored black
The sun is colored yellow
The grass is colored green
The cloud is colored
2024-07-29 04:25:34 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-29 04:27:56 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1083, -0.1038,  0.0339,  ..., -0.0670, -0.2666, -0.0674],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.9805, -3.7598,  1.3740,  ..., -2.2539, -0.1851, -0.7080],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0677,  0.0151, -0.0020,  ...,  0.0008,  0.0043,  0.0106],
        [ 0.0051,  0.0298,  0.0036,  ...,  0.0107, -0.0050, -0.0219],
        [ 0.0133,  0.0068,  0.0349,  ...,  0.0086, -0.0197,  0.0101],
        ...,
        [ 0.0165,  0.0102,  0.0074,  ...,  0.0629, -0.0018, -0.0056],
        [ 0.0111, -0.0022,  0.0036,  ...,  0.0224,  0.0380, -0.0017],
        [-0.0111,  0.0046,  0.0117,  ...,  0.0054, -0.0178,  0.0443]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.6221, -3.5020,  1.3672,  ..., -2.2344, -0.1815, -0.7954]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 04:27:57 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The soil is colored black
The frog is colored green
The peony is colored red
The parsley is colored green
The coal is colored black
The sun is colored yellow
The grass is colored green
The cloud is colored
2024-07-29 04:27:58 root INFO     [order_1_approx] starting weight calculation for The parsley is colored green
The cloud is colored white
The soil is colored black
The peony is colored red
The frog is colored green
The sun is colored yellow
The coal is colored black
The grass is colored
2024-07-29 04:27:58 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-29 04:30:18 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1853, -0.0940, -0.4641,  ..., -0.0185, -0.2002,  0.0667],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.8770, -5.9141, -2.2188,  ..., -0.6113,  0.6577, -3.7148],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0612,  0.0195,  0.0082,  ...,  0.0134, -0.0162,  0.0004],
        [ 0.0028,  0.0177, -0.0047,  ...,  0.0008,  0.0117, -0.0189],
        [-0.0170, -0.0148,  0.0530,  ..., -0.0062, -0.0142,  0.0085],
        ...,
        [ 0.0067, -0.0142,  0.0078,  ...,  0.0440, -0.0039, -0.0048],
        [ 0.0010,  0.0211,  0.0125,  ...,  0.0137,  0.0424,  0.0072],
        [ 0.0051, -0.0133, -0.0111,  ..., -0.0012, -0.0021,  0.0309]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.1973, -5.8086, -2.2109,  ..., -0.3411,  0.1821, -3.5059]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 04:30:19 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The parsley is colored green
The cloud is colored white
The soil is colored black
The peony is colored red
The frog is colored green
The sun is colored yellow
The coal is colored black
The grass is colored
2024-07-29 04:30:19 root INFO     [order_1_approx] starting weight calculation for The cloud is colored white
The sun is colored yellow
The parsley is colored green
The coal is colored black
The grass is colored green
The soil is colored black
The peony is colored red
The frog is colored
2024-07-29 04:30:20 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-29 04:32:39 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2908,  0.2054,  0.0685,  ..., -0.2153, -0.3621,  0.2690],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.3320, -2.7344,  1.0791,  ...,  0.6587, -0.6523,  1.4189],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0704, -0.0053,  0.0183,  ..., -0.0010,  0.0054, -0.0062],
        [-0.0051,  0.0451, -0.0079,  ..., -0.0078,  0.0015, -0.0129],
        [ 0.0047,  0.0117,  0.0472,  ...,  0.0051, -0.0122,  0.0142],
        ...,
        [ 0.0074,  0.0142,  0.0023,  ...,  0.0747,  0.0061,  0.0055],
        [ 0.0092,  0.0058, -0.0029,  ...,  0.0296,  0.0185,  0.0012],
        [-0.0027,  0.0030,  0.0055,  ...,  0.0101, -0.0162,  0.0428]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.1201, -3.1172,  0.6650,  ...,  0.5410, -1.1025,  1.3145]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 04:32:40 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The cloud is colored white
The sun is colored yellow
The parsley is colored green
The coal is colored black
The grass is colored green
The soil is colored black
The peony is colored red
The frog is colored
2024-07-29 04:32:40 root INFO     [order_1_approx] starting weight calculation for The peony is colored red
The sun is colored yellow
The cloud is colored white
The grass is colored green
The coal is colored black
The frog is colored green
The soil is colored black
The parsley is colored
2024-07-29 04:32:40 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-29 04:35:00 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1353, -0.1029, -0.6631,  ..., -0.3179, -0.5498, -0.0178],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.1113, -5.0547, -1.5078,  ..., -0.3831, -0.3232, -3.5156],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0900,  0.0251,  0.0059,  ..., -0.0156,  0.0195,  0.0100],
        [ 0.0193,  0.0403,  0.0161,  ..., -0.0044,  0.0269, -0.0167],
        [-0.0125, -0.0354,  0.0540,  ...,  0.0162, -0.0150,  0.0038],
        ...,
        [ 0.0177, -0.0155,  0.0278,  ...,  0.0813,  0.0050,  0.0034],
        [ 0.0112,  0.0239, -0.0051,  ..., -0.0013,  0.0642, -0.0030],
        [-0.0157, -0.0229,  0.0029,  ..., -0.0020, -0.0109,  0.0367]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.0908, -5.1250, -1.5566,  ..., -0.1853, -0.6523, -2.7969]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 04:35:01 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The peony is colored red
The sun is colored yellow
The cloud is colored white
The grass is colored green
The coal is colored black
The frog is colored green
The soil is colored black
The parsley is colored
2024-07-29 04:35:01 root INFO     total operator prediction time: 1137.8350312709808 seconds
2024-07-29 04:35:01 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on country - capital
2024-07-29 04:35:01 root INFO     building operator country - capital
2024-07-29 04:35:02 root INFO     [order_1_approx] starting weight calculation for The country with ankara as its capital is known as turkey
The country with athens as its capital is known as greece
The country with madrid as its capital is known as spain
The country with rome as its capital is known as italy
The country with islamabad as its capital is known as pakistan
The country with paris as its capital is known as france
The country with cairo as its capital is known as egypt
The country with lima as its capital is known as
2024-07-29 04:35:02 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-29 04:37:23 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1777, -0.2495, -0.1993,  ...,  0.5435, -0.0139,  0.2175],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.9023, -4.2891,  1.5596,  ..., -0.7515, -1.3496, -2.9922],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0059,  0.0089,  0.0133,  ...,  0.0066, -0.0120, -0.0135],
        [-0.0156,  0.0260,  0.0220,  ..., -0.0345,  0.0297,  0.0024],
        [ 0.0140,  0.0202,  0.0379,  ...,  0.0192, -0.0229, -0.0219],
        ...,
        [ 0.0104,  0.0090, -0.0001,  ...,  0.0484,  0.0075, -0.0072],
        [-0.0111, -0.0091,  0.0167,  ..., -0.0134,  0.0249, -0.0027],
        [-0.0034,  0.0060,  0.0302,  ...,  0.0039, -0.0111,  0.0190]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.8184, -4.5781,  1.1719,  ..., -1.1133, -1.4502, -2.6484]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 04:37:24 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country with ankara as its capital is known as turkey
The country with athens as its capital is known as greece
The country with madrid as its capital is known as spain
The country with rome as its capital is known as italy
The country with islamabad as its capital is known as pakistan
The country with paris as its capital is known as france
The country with cairo as its capital is known as egypt
The country with lima as its capital is known as
2024-07-29 04:37:24 root INFO     [order_1_approx] starting weight calculation for The country with lima as its capital is known as peru
The country with cairo as its capital is known as egypt
The country with ankara as its capital is known as turkey
The country with islamabad as its capital is known as pakistan
The country with paris as its capital is known as france
The country with rome as its capital is known as italy
The country with athens as its capital is known as greece
The country with madrid as its capital is known as
2024-07-29 04:37:24 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-29 04:39:48 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3796, -0.6250, -0.9380,  ...,  0.4541,  0.1616, -0.1169],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.1875, -4.5820, -2.0625,  ...,  1.0059,  1.2793, -5.2617],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0195,  0.0070, -0.0204,  ...,  0.0165, -0.0167,  0.0019],
        [-0.0048,  0.0292,  0.0123,  ..., -0.0249, -0.0112, -0.0060],
        [-0.0075,  0.0247,  0.0379,  ...,  0.0083,  0.0185, -0.0098],
        ...,
        [ 0.0028,  0.0214, -0.0037,  ...,  0.0317,  0.0131, -0.0058],
        [ 0.0081, -0.0168,  0.0013,  ..., -0.0087,  0.0052, -0.0123],
        [-0.0008,  0.0005,  0.0007,  ...,  0.0135, -0.0101,  0.0133]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.1152, -4.5273, -2.5723,  ...,  0.7778,  1.4121, -5.0586]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 04:39:49 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country with lima as its capital is known as peru
The country with cairo as its capital is known as egypt
The country with ankara as its capital is known as turkey
The country with islamabad as its capital is known as pakistan
The country with paris as its capital is known as france
The country with rome as its capital is known as italy
The country with athens as its capital is known as greece
The country with madrid as its capital is known as
2024-07-29 04:39:49 root INFO     [order_1_approx] starting weight calculation for The country with cairo as its capital is known as egypt
The country with athens as its capital is known as greece
The country with paris as its capital is known as france
The country with madrid as its capital is known as spain
The country with lima as its capital is known as peru
The country with ankara as its capital is known as turkey
The country with islamabad as its capital is known as pakistan
The country with rome as its capital is known as
2024-07-29 04:39:49 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-29 04:42:13 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2666, -0.3359, -0.5103,  ...,  0.2593,  0.0550, -0.0790],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.4219, -4.3750, -0.9526,  ..., -1.5205,  2.9941, -3.7227],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0233,  0.0072, -0.0110,  ...,  0.0325, -0.0017,  0.0049],
        [ 0.0073,  0.0169,  0.0092,  ..., -0.0056, -0.0174, -0.0169],
        [-0.0016,  0.0178,  0.0575,  ...,  0.0109,  0.0007, -0.0129],
        ...,
        [-0.0103, -0.0030, -0.0015,  ...,  0.0331,  0.0093, -0.0120],
        [ 0.0128, -0.0091, -0.0080,  ..., -0.0012,  0.0096,  0.0013],
        [ 0.0017,  0.0136, -0.0153,  ...,  0.0154, -0.0142,  0.0214]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.5430, -4.2656, -1.3115,  ..., -1.7344,  2.9668, -3.4941]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 04:42:14 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country with cairo as its capital is known as egypt
The country with athens as its capital is known as greece
The country with paris as its capital is known as france
The country with madrid as its capital is known as spain
The country with lima as its capital is known as peru
The country with ankara as its capital is known as turkey
The country with islamabad as its capital is known as pakistan
The country with rome as its capital is known as
2024-07-29 04:42:14 root INFO     [order_1_approx] starting weight calculation for The country with islamabad as its capital is known as pakistan
The country with lima as its capital is known as peru
The country with athens as its capital is known as greece
The country with cairo as its capital is known as egypt
The country with madrid as its capital is known as spain
The country with ankara as its capital is known as turkey
The country with rome as its capital is known as italy
The country with paris as its capital is known as
2024-07-29 04:42:14 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-29 04:44:35 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0238, -0.2200, -0.4763,  ...,  0.3416,  0.1304, -0.1981],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.9336, -5.1211,  0.3079,  ..., -1.9189,  1.1680, -3.4609],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0189, -0.0086, -0.0067,  ...,  0.0111, -0.0013,  0.0042],
        [-0.0076,  0.0147, -0.0032,  ..., -0.0139, -0.0054, -0.0152],
        [-0.0042,  0.0240,  0.0345,  ...,  0.0303,  0.0085, -0.0060],
        ...,
        [-0.0060,  0.0026, -0.0041,  ...,  0.0355,  0.0078, -0.0117],
        [ 0.0037, -0.0074,  0.0003,  ..., -0.0115,  0.0003, -0.0015],
        [-0.0081, -0.0072, -0.0048,  ...,  0.0219, -0.0104,  0.0227]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.8887, -4.9883,  0.0352,  ..., -1.9502,  1.2832, -3.0234]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 04:44:35 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country with islamabad as its capital is known as pakistan
The country with lima as its capital is known as peru
The country with athens as its capital is known as greece
The country with cairo as its capital is known as egypt
The country with madrid as its capital is known as spain
The country with ankara as its capital is known as turkey
The country with rome as its capital is known as italy
The country with paris as its capital is known as
2024-07-29 04:44:36 root INFO     [order_1_approx] starting weight calculation for The country with cairo as its capital is known as egypt
The country with paris as its capital is known as france
The country with madrid as its capital is known as spain
The country with rome as its capital is known as italy
The country with islamabad as its capital is known as pakistan
The country with lima as its capital is known as peru
The country with ankara as its capital is known as turkey
The country with athens as its capital is known as
2024-07-29 04:44:36 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-29 04:46:59 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3882, -0.2986, -0.6689,  ...,  0.1334,  0.0291, -0.2764],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.7383, -5.8398, -2.7070,  ..., -0.1602,  2.0039, -3.1367],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0257,  0.0041, -0.0058,  ...,  0.0038, -0.0042, -0.0063],
        [-0.0004,  0.0146,  0.0029,  ..., -0.0020, -0.0081, -0.0115],
        [-0.0133,  0.0215,  0.0451,  ...,  0.0117, -0.0012, -0.0128],
        ...,
        [-0.0024,  0.0036, -0.0051,  ...,  0.0284,  0.0166, -0.0070],
        [ 0.0042, -0.0080, -0.0037,  ...,  0.0027,  0.0152, -0.0083],
        [-0.0106,  0.0016, -0.0028,  ...,  0.0024, -0.0026,  0.0109]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.6641, -5.6094, -2.5449,  ..., -0.1832,  1.9209, -2.7871]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 04:47:00 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country with cairo as its capital is known as egypt
The country with paris as its capital is known as france
The country with madrid as its capital is known as spain
The country with rome as its capital is known as italy
The country with islamabad as its capital is known as pakistan
The country with lima as its capital is known as peru
The country with ankara as its capital is known as turkey
The country with athens as its capital is known as
2024-07-29 04:47:00 root INFO     [order_1_approx] starting weight calculation for The country with lima as its capital is known as peru
The country with paris as its capital is known as france
The country with cairo as its capital is known as egypt
The country with athens as its capital is known as greece
The country with rome as its capital is known as italy
The country with madrid as its capital is known as spain
The country with ankara as its capital is known as turkey
The country with islamabad as its capital is known as
2024-07-29 04:47:00 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-29 04:49:26 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0642,  0.0560, -0.3438,  ...,  0.8555, -0.2944,  0.2664],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.0508, -6.8242, -0.6006,  ..., -1.0820, -0.3354, -2.1387],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0229, -0.0055,  0.0112,  ...,  0.0039, -0.0085,  0.0034],
        [-0.0243,  0.0135, -0.0053,  ..., -0.0082, -0.0069, -0.0134],
        [ 0.0298,  0.0431,  0.0421,  ...,  0.0016, -0.0138,  0.0021],
        ...,
        [ 0.0022,  0.0015, -0.0087,  ...,  0.0343,  0.0081, -0.0066],
        [-0.0121, -0.0084, -0.0103,  ...,  0.0103,  0.0098, -0.0005],
        [ 0.0018,  0.0074, -0.0017,  ...,  0.0184, -0.0054,  0.0203]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.7227, -6.4844, -0.9790,  ..., -0.7715, -0.1907, -2.0215]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 04:49:27 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country with lima as its capital is known as peru
The country with paris as its capital is known as france
The country with cairo as its capital is known as egypt
The country with athens as its capital is known as greece
The country with rome as its capital is known as italy
The country with madrid as its capital is known as spain
The country with ankara as its capital is known as turkey
The country with islamabad as its capital is known as
2024-07-29 04:49:27 root INFO     [order_1_approx] starting weight calculation for The country with paris as its capital is known as france
The country with rome as its capital is known as italy
The country with islamabad as its capital is known as pakistan
The country with madrid as its capital is known as spain
The country with lima as its capital is known as peru
The country with athens as its capital is known as greece
The country with cairo as its capital is known as egypt
The country with ankara as its capital is known as
2024-07-29 04:49:27 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-29 04:51:52 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0419, -0.2502, -1.0488,  ...,  0.2350, -0.2114,  0.0672],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.0039, -3.8125, -1.1543,  ..., -0.0742,  2.3926, -3.1406],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0219,  0.0032, -0.0095,  ...,  0.0084, -0.0178, -0.0136],
        [ 0.0017,  0.0255,  0.0115,  ..., -0.0073, -0.0049, -0.0128],
        [-0.0167,  0.0226,  0.0273,  ...,  0.0030,  0.0078, -0.0058],
        ...,
        [ 0.0045,  0.0188, -0.0097,  ...,  0.0233, -0.0024, -0.0043],
        [-0.0065, -0.0024, -0.0096,  ...,  0.0070,  0.0273,  0.0017],
        [-0.0063,  0.0054, -0.0075,  ...,  0.0027,  0.0006,  0.0211]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.6162, -3.4141, -1.1504,  ..., -0.0419,  2.2422, -2.9707]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 04:51:54 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country with paris as its capital is known as france
The country with rome as its capital is known as italy
The country with islamabad as its capital is known as pakistan
The country with madrid as its capital is known as spain
The country with lima as its capital is known as peru
The country with athens as its capital is known as greece
The country with cairo as its capital is known as egypt
The country with ankara as its capital is known as
2024-07-29 04:51:54 root INFO     [order_1_approx] starting weight calculation for The country with ankara as its capital is known as turkey
The country with paris as its capital is known as france
The country with madrid as its capital is known as spain
The country with lima as its capital is known as peru
The country with athens as its capital is known as greece
The country with islamabad as its capital is known as pakistan
The country with rome as its capital is known as italy
The country with cairo as its capital is known as
2024-07-29 04:51:54 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-29 04:54:20 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1687,  0.0129, -0.6709,  ...,  0.4502, -0.2678,  0.1362],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.5898, -2.7344,  1.6660,  ..., -0.7700,  0.8281, -1.7061],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0202,  0.0011,  0.0028,  ...,  0.0144, -0.0207, -0.0002],
        [ 0.0076,  0.0228,  0.0169,  ..., -0.0152,  0.0066, -0.0045],
        [-0.0053,  0.0552,  0.0271,  ...,  0.0079, -0.0254, -0.0136],
        ...,
        [ 0.0031,  0.0310,  0.0077,  ...,  0.0180, -0.0105, -0.0039],
        [-0.0041, -0.0150, -0.0003,  ..., -0.0137,  0.0237,  0.0025],
        [-0.0107,  0.0030, -0.0097,  ...,  0.0186,  0.0006,  0.0230]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.5371, -2.4727,  1.2988,  ..., -0.9023,  0.9102, -1.5957]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 04:54:20 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country with ankara as its capital is known as turkey
The country with paris as its capital is known as france
The country with madrid as its capital is known as spain
The country with lima as its capital is known as peru
The country with athens as its capital is known as greece
The country with islamabad as its capital is known as pakistan
The country with rome as its capital is known as italy
The country with cairo as its capital is known as
2024-07-29 04:54:20 root INFO     total operator prediction time: 1159.1592457294464 seconds
2024-07-29 04:54:20 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on name - occupation
2024-07-29 04:54:20 root INFO     building operator name - occupation
2024-07-29 04:54:21 root INFO     [order_1_approx] starting weight calculation for andersen was known for their work as a  writer
caesar was known for their work as a  emperor
hume was known for their work as a  philosopher
stalin was known for their work as a  dictator
plato was known for their work as a  philosopher
schwarzenegger was known for their work as a  actor
hegel was known for their work as a  philosopher
rembrandt was known for their work as a 
2024-07-29 04:54:21 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-29 04:56:45 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1260, -0.2822, -0.3398,  ...,  0.1091, -0.1102, -0.2010],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.2480, -6.0156,  1.0576,  ..., -7.2891, -1.8096, -3.0117],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 3.1113e-02, -1.7357e-03,  1.2413e-02,  ...,  7.9956e-03,
         -6.6071e-03,  5.2185e-03],
        [-2.5063e-03,  2.2430e-02, -3.2635e-03,  ..., -2.8362e-03,
          5.1594e-04, -2.2240e-03],
        [ 5.6114e-03, -5.3406e-05,  3.7231e-02,  ..., -1.2360e-02,
          7.2098e-04,  3.9749e-03],
        ...,
        [ 8.4839e-03, -8.3160e-03,  3.3302e-03,  ...,  3.1403e-02,
          8.6212e-03, -8.0109e-03],
        [ 1.4887e-03, -2.4242e-03,  2.9907e-03,  ...,  3.8300e-03,
          2.0142e-02,  2.9278e-04],
        [ 3.2806e-04,  1.8272e-03, -8.5449e-03,  ..., -1.4893e-02,
         -6.3858e-03,  2.3468e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.3281, -5.7773,  1.2812,  ..., -7.1797, -1.8389, -2.9922]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 04:56:46 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for andersen was known for their work as a  writer
caesar was known for their work as a  emperor
hume was known for their work as a  philosopher
stalin was known for their work as a  dictator
plato was known for their work as a  philosopher
schwarzenegger was known for their work as a  actor
hegel was known for their work as a  philosopher
rembrandt was known for their work as a 
2024-07-29 04:56:47 root INFO     [order_1_approx] starting weight calculation for stalin was known for their work as a  dictator
plato was known for their work as a  philosopher
caesar was known for their work as a  emperor
schwarzenegger was known for their work as a  actor
andersen was known for their work as a  writer
rembrandt was known for their work as a  painter
hegel was known for their work as a  philosopher
hume was known for their work as a 
2024-07-29 04:56:47 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-29 04:59:12 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2610,  0.2494,  0.1024,  ...,  0.0745,  0.3186,  0.1343],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.1543, -3.7344,  2.7480,  ..., -6.1797,  0.7959, -2.3105],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0481, -0.0019,  0.0210,  ...,  0.0050,  0.0026, -0.0014],
        [ 0.0123,  0.0381, -0.0036,  ..., -0.0009, -0.0242, -0.0047],
        [-0.0037, -0.0209,  0.0603,  ..., -0.0168,  0.0282, -0.0078],
        ...,
        [ 0.0144,  0.0090,  0.0004,  ...,  0.0591,  0.0128,  0.0174],
        [ 0.0052,  0.0027, -0.0080,  ...,  0.0140,  0.0301, -0.0068],
        [-0.0085,  0.0091, -0.0018,  ..., -0.0126, -0.0235,  0.0479]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.1016, -4.1797,  2.7930,  ..., -6.5312,  0.5635, -2.1602]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 04:59:13 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for stalin was known for their work as a  dictator
plato was known for their work as a  philosopher
caesar was known for their work as a  emperor
schwarzenegger was known for their work as a  actor
andersen was known for their work as a  writer
rembrandt was known for their work as a  painter
hegel was known for their work as a  philosopher
hume was known for their work as a 
2024-07-29 04:59:13 root INFO     [order_1_approx] starting weight calculation for stalin was known for their work as a  dictator
hegel was known for their work as a  philosopher
hume was known for their work as a  philosopher
andersen was known for their work as a  writer
rembrandt was known for their work as a  painter
schwarzenegger was known for their work as a  actor
plato was known for their work as a  philosopher
caesar was known for their work as a 
2024-07-29 04:59:13 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-29 05:01:32 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0814,  0.0121, -0.4988,  ...,  0.2488, -0.5674,  0.3196],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.0381, -6.9023,  2.7461,  ..., -2.8945,  1.2031, -1.2188],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0528, -0.0195,  0.0021,  ..., -0.0058, -0.0227,  0.0056],
        [ 0.0010,  0.0461,  0.0030,  ..., -0.0002,  0.0041, -0.0073],
        [ 0.0018, -0.0184,  0.0659,  ..., -0.0049,  0.0048,  0.0013],
        ...,
        [ 0.0202,  0.0297,  0.0034,  ...,  0.0840,  0.0172, -0.0052],
        [ 0.0049,  0.0168,  0.0072,  ..., -0.0025,  0.0243,  0.0017],
        [-0.0010,  0.0011, -0.0007,  ..., -0.0052,  0.0027,  0.0366]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.3787, -6.8008,  2.8887,  ..., -3.0176,  0.9497, -1.2637]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 05:01:33 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for stalin was known for their work as a  dictator
hegel was known for their work as a  philosopher
hume was known for their work as a  philosopher
andersen was known for their work as a  writer
rembrandt was known for their work as a  painter
schwarzenegger was known for their work as a  actor
plato was known for their work as a  philosopher
caesar was known for their work as a 
2024-07-29 05:01:33 root INFO     [order_1_approx] starting weight calculation for stalin was known for their work as a  dictator
rembrandt was known for their work as a  painter
hegel was known for their work as a  philosopher
plato was known for their work as a  philosopher
caesar was known for their work as a  emperor
schwarzenegger was known for their work as a  actor
hume was known for their work as a  philosopher
andersen was known for their work as a 
2024-07-29 05:01:33 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-29 05:03:50 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1628,  0.0881, -0.4709,  ..., -0.0911, -0.0286,  0.1537],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.5859, -4.2031,  1.6895,  ..., -5.0508, -2.4551,  1.0264],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0648, -0.0011,  0.0228,  ..., -0.0171, -0.0204,  0.0137],
        [ 0.0012,  0.0483, -0.0041,  ..., -0.0057, -0.0153, -0.0205],
        [-0.0054,  0.0008,  0.0661,  ..., -0.0085,  0.0044, -0.0004],
        ...,
        [ 0.0177,  0.0096,  0.0080,  ...,  0.0763,  0.0008, -0.0108],
        [ 0.0016,  0.0013,  0.0044,  ...,  0.0120,  0.0341,  0.0154],
        [-0.0180,  0.0080, -0.0069,  ..., -0.0081, -0.0029,  0.0430]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.5137, -4.2227,  1.6592,  ..., -4.7969, -2.2383,  0.8745]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 05:03:51 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for stalin was known for their work as a  dictator
rembrandt was known for their work as a  painter
hegel was known for their work as a  philosopher
plato was known for their work as a  philosopher
caesar was known for their work as a  emperor
schwarzenegger was known for their work as a  actor
hume was known for their work as a  philosopher
andersen was known for their work as a 
2024-07-29 05:03:51 root INFO     [order_1_approx] starting weight calculation for hegel was known for their work as a  philosopher
hume was known for their work as a  philosopher
rembrandt was known for their work as a  painter
plato was known for their work as a  philosopher
schwarzenegger was known for their work as a  actor
andersen was known for their work as a  writer
caesar was known for their work as a  emperor
stalin was known for their work as a 
2024-07-29 05:03:51 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-29 05:06:13 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0738, -0.1432, -0.2954,  ...,  0.4771,  0.0558, -0.0232],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 5.0625, -5.0273,  2.7695,  ..., -2.1641,  0.1875, -2.5898],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0422, -0.0031,  0.0156,  ...,  0.0099, -0.0249,  0.0159],
        [-0.0114,  0.0464,  0.0056,  ..., -0.0026,  0.0091, -0.0126],
        [-0.0051, -0.0129,  0.0526,  ...,  0.0164,  0.0052,  0.0162],
        ...,
        [ 0.0030,  0.0088, -0.0137,  ...,  0.0955,  0.0062, -0.0225],
        [ 0.0059,  0.0252, -0.0018,  ...,  0.0056,  0.0118,  0.0084],
        [-0.0040,  0.0161, -0.0067,  ...,  0.0017, -0.0097,  0.0311]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.8438, -4.9102,  2.6777,  ..., -2.0352,  0.0414, -2.2246]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 05:06:14 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for hegel was known for their work as a  philosopher
hume was known for their work as a  philosopher
rembrandt was known for their work as a  painter
plato was known for their work as a  philosopher
schwarzenegger was known for their work as a  actor
andersen was known for their work as a  writer
caesar was known for their work as a  emperor
stalin was known for their work as a 
2024-07-29 05:06:15 root INFO     [order_1_approx] starting weight calculation for rembrandt was known for their work as a  painter
schwarzenegger was known for their work as a  actor
caesar was known for their work as a  emperor
hume was known for their work as a  philosopher
andersen was known for their work as a  writer
hegel was known for their work as a  philosopher
stalin was known for their work as a  dictator
plato was known for their work as a 
2024-07-29 05:06:15 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-29 05:08:31 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0530, -0.2734, -0.4893,  ...,  0.3186,  0.1749,  0.1449],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.1650, -5.4648,  1.5166,  ..., -5.4609, -1.4062, -0.1484],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0375, -0.0038,  0.0163,  ...,  0.0053, -0.0148,  0.0051],
        [-0.0021,  0.0312,  0.0033,  ..., -0.0152, -0.0045, -0.0017],
        [ 0.0166,  0.0003,  0.0338,  ..., -0.0062,  0.0107,  0.0023],
        ...,
        [ 0.0304, -0.0012,  0.0005,  ...,  0.0381,  0.0213, -0.0104],
        [ 0.0210,  0.0103,  0.0130,  ...,  0.0235,  0.0276, -0.0042],
        [-0.0017,  0.0127,  0.0001,  ..., -0.0097, -0.0094,  0.0362]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.9868, -5.3516,  1.4453,  ..., -5.2109, -1.3232,  0.0635]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 05:08:32 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for rembrandt was known for their work as a  painter
schwarzenegger was known for their work as a  actor
caesar was known for their work as a  emperor
hume was known for their work as a  philosopher
andersen was known for their work as a  writer
hegel was known for their work as a  philosopher
stalin was known for their work as a  dictator
plato was known for their work as a 
2024-07-29 05:08:32 root INFO     [order_1_approx] starting weight calculation for plato was known for their work as a  philosopher
andersen was known for their work as a  writer
schwarzenegger was known for their work as a  actor
caesar was known for their work as a  emperor
hume was known for their work as a  philosopher
rembrandt was known for their work as a  painter
stalin was known for their work as a  dictator
hegel was known for their work as a 
2024-07-29 05:08:32 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-29 05:10:45 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([0.3430, 0.1194, 0.0831,  ..., 0.3772, 0.3054, 0.0630], device='cuda:0',
       dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.7397, -6.5898,  3.6055,  ..., -4.8047, -0.2925, -2.0723],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0442,  0.0084,  0.0353,  ...,  0.0051, -0.0150,  0.0031],
        [-0.0021,  0.0316,  0.0061,  ..., -0.0011, -0.0224, -0.0124],
        [-0.0043,  0.0122,  0.0634,  ..., -0.0225, -0.0111, -0.0104],
        ...,
        [ 0.0160,  0.0252, -0.0017,  ...,  0.0811,  0.0415,  0.0234],
        [-0.0017, -0.0011, -0.0122,  ...,  0.0097,  0.0344,  0.0091],
        [-0.0062, -0.0258, -0.0013,  ..., -0.0139,  0.0191,  0.0592]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.5166, -6.0391,  3.0703,  ..., -5.0586, -0.3137, -1.7920]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 05:10:46 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for plato was known for their work as a  philosopher
andersen was known for their work as a  writer
schwarzenegger was known for their work as a  actor
caesar was known for their work as a  emperor
hume was known for their work as a  philosopher
rembrandt was known for their work as a  painter
stalin was known for their work as a  dictator
hegel was known for their work as a 
2024-07-29 05:10:46 root INFO     [order_1_approx] starting weight calculation for hume was known for their work as a  philosopher
andersen was known for their work as a  writer
hegel was known for their work as a  philosopher
rembrandt was known for their work as a  painter
caesar was known for their work as a  emperor
stalin was known for their work as a  dictator
plato was known for their work as a  philosopher
schwarzenegger was known for their work as a 
2024-07-29 05:10:46 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-29 05:13:05 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1475,  0.0413, -0.4150,  ...,  0.4080, -0.6060,  0.2886],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 6.7266, -3.4883,  4.6250,  ..., -3.8398,  1.6211, -2.0312],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0393, -0.0010,  0.0089,  ..., -0.0091, -0.0182, -0.0044],
        [-0.0037,  0.0362,  0.0040,  ...,  0.0142, -0.0014, -0.0070],
        [ 0.0085,  0.0109,  0.0338,  ..., -0.0112, -0.0049,  0.0105],
        ...,
        [ 0.0182, -0.0132, -0.0010,  ...,  0.0584, -0.0090,  0.0073],
        [ 0.0100,  0.0092,  0.0107,  ..., -0.0006,  0.0097,  0.0160],
        [ 0.0016, -0.0066, -0.0166,  ...,  0.0064,  0.0120,  0.0298]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 6.6055, -3.6133,  4.5508,  ..., -3.6836,  1.5645, -1.9629]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 05:13:06 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for hume was known for their work as a  philosopher
andersen was known for their work as a  writer
hegel was known for their work as a  philosopher
rembrandt was known for their work as a  painter
caesar was known for their work as a  emperor
stalin was known for their work as a  dictator
plato was known for their work as a  philosopher
schwarzenegger was known for their work as a 
2024-07-29 05:13:06 root INFO     total operator prediction time: 1125.0551047325134 seconds
2024-07-29 05:13:06 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on male - female
2024-07-29 05:13:06 root INFO     building operator male - female
2024-07-29 05:13:06 root INFO     [order_1_approx] starting weight calculation for A female heir is known as a heiress
A female grandfather is known as a grandmother
A female sir is known as a madam
A female hero is known as a heroine
A female stepfather is known as a stepmother
A female businessman is known as a businesswoman
A female son is known as a daughter
A female chairman is known as a
2024-07-29 05:13:06 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-29 05:15:25 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.6963,  0.0519, -0.6572,  ...,  0.2524, -0.4731,  0.0195],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.5898, -3.2852,  2.4902,  ...,  0.1787, -4.8203, -2.2520],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0434, -0.0184,  0.0136,  ...,  0.0049, -0.0175, -0.0014],
        [ 0.0044,  0.0543,  0.0040,  ...,  0.0115,  0.0313, -0.0066],
        [-0.0109, -0.0037,  0.0342,  ..., -0.0198, -0.0211,  0.0155],
        ...,
        [-0.0071,  0.0287,  0.0182,  ...,  0.0498,  0.0216, -0.0274],
        [-0.0070,  0.0073,  0.0016,  ..., -0.0191,  0.0145, -0.0172],
        [ 0.0165, -0.0079,  0.0193,  ..., -0.0063,  0.0232,  0.0313]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.4336, -3.0801,  2.0781,  ...,  0.3838, -4.9336, -1.5000]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 05:15:26 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A female heir is known as a heiress
A female grandfather is known as a grandmother
A female sir is known as a madam
A female hero is known as a heroine
A female stepfather is known as a stepmother
A female businessman is known as a businesswoman
A female son is known as a daughter
A female chairman is known as a
2024-07-29 05:15:26 root INFO     [order_1_approx] starting weight calculation for A female sir is known as a madam
A female stepfather is known as a stepmother
A female grandfather is known as a grandmother
A female hero is known as a heroine
A female businessman is known as a businesswoman
A female chairman is known as a chairwoman
A female heir is known as a heiress
A female son is known as a
2024-07-29 05:15:26 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-29 05:17:48 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1461,  0.4731,  0.1185,  ...,  0.1173, -0.1719,  0.2549],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 5.0312, -0.8115, -2.3965,  ...,  3.2109, -3.4512,  0.2588],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0493, -0.0257,  0.0297,  ..., -0.0016, -0.0136,  0.0038],
        [ 0.0086,  0.0364, -0.0186,  ...,  0.0093,  0.0094, -0.0231],
        [ 0.0019, -0.0159,  0.0428,  ..., -0.0388, -0.0195, -0.0044],
        ...,
        [-0.0060,  0.0106,  0.0024,  ...,  0.0652,  0.0171,  0.0026],
        [-0.0002,  0.0046,  0.0260,  ..., -0.0026, -0.0041,  0.0241],
        [ 0.0085,  0.0020, -0.0184,  ..., -0.0050,  0.0163,  0.0176]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.8867, -0.8936, -2.5352,  ...,  3.5488, -3.4375,  0.1499]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 05:17:51 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A female sir is known as a madam
A female stepfather is known as a stepmother
A female grandfather is known as a grandmother
A female hero is known as a heroine
A female businessman is known as a businesswoman
A female chairman is known as a chairwoman
A female heir is known as a heiress
A female son is known as a
2024-07-29 05:17:52 root INFO     [order_1_approx] starting weight calculation for A female sir is known as a madam
A female chairman is known as a chairwoman
A female son is known as a daughter
A female hero is known as a heroine
A female heir is known as a heiress
A female stepfather is known as a stepmother
A female grandfather is known as a grandmother
A female businessman is known as a
2024-07-29 05:17:52 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-29 05:20:04 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3857,  0.3792, -0.2600,  ...,  0.0981, -0.2722,  0.3291],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.0625, -1.9473,  0.1196,  ...,  1.6816, -1.8760, -1.8730],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0301, -0.0204,  0.0048,  ..., -0.0044, -0.0140, -0.0003],
        [ 0.0093,  0.0263,  0.0024,  ...,  0.0253, -0.0056,  0.0072],
        [ 0.0020,  0.0174,  0.0361,  ..., -0.0070,  0.0031, -0.0029],
        ...,
        [-0.0066,  0.0142,  0.0017,  ...,  0.0563, -0.0067, -0.0090],
        [-0.0059,  0.0101, -0.0013,  ...,  0.0099,  0.0113, -0.0010],
        [-0.0140, -0.0112,  0.0013,  ...,  0.0044, -0.0016,  0.0361]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.3047, -2.1855,  0.1821,  ...,  1.3848, -2.0117, -1.8799]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 05:20:05 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A female sir is known as a madam
A female chairman is known as a chairwoman
A female son is known as a daughter
A female hero is known as a heroine
A female heir is known as a heiress
A female stepfather is known as a stepmother
A female grandfather is known as a grandmother
A female businessman is known as a
2024-07-29 05:20:06 root INFO     [order_1_approx] starting weight calculation for A female sir is known as a madam
A female stepfather is known as a stepmother
A female grandfather is known as a grandmother
A female heir is known as a heiress
A female chairman is known as a chairwoman
A female businessman is known as a businesswoman
A female son is known as a daughter
A female hero is known as a
2024-07-29 05:20:06 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-29 05:22:20 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1192,  0.7715, -0.0048,  ..., -0.0750, -0.2537,  0.0041],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.8984, -5.5234, -0.9248,  ..., -1.3662, -3.7363,  0.1670],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0499, -0.0172,  0.0316,  ...,  0.0137,  0.0007, -0.0032],
        [ 0.0100,  0.0073, -0.0097,  ..., -0.0018,  0.0228, -0.0068],
        [ 0.0057,  0.0121,  0.0348,  ..., -0.0056, -0.0229, -0.0071],
        ...,
        [ 0.0228, -0.0187, -0.0121,  ...,  0.0532,  0.0019, -0.0111],
        [-0.0222,  0.0206,  0.0184,  ...,  0.0018,  0.0049, -0.0006],
        [ 0.0075, -0.0071, -0.0193,  ...,  0.0011,  0.0127,  0.0198]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.6309, -5.1445, -1.1543,  ..., -0.9741, -3.9902,  0.0953]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 05:22:21 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A female sir is known as a madam
A female stepfather is known as a stepmother
A female grandfather is known as a grandmother
A female heir is known as a heiress
A female chairman is known as a chairwoman
A female businessman is known as a businesswoman
A female son is known as a daughter
A female hero is known as a
2024-07-29 05:22:21 root INFO     [order_1_approx] starting weight calculation for A female heir is known as a heiress
A female grandfather is known as a grandmother
A female chairman is known as a chairwoman
A female stepfather is known as a stepmother
A female businessman is known as a businesswoman
A female hero is known as a heroine
A female son is known as a daughter
A female sir is known as a
2024-07-29 05:22:21 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-29 05:24:40 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3569,  0.2749, -0.1475,  ...,  0.2004, -0.0653,  0.6011],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.1680, -2.0918, -1.5400,  ...,  0.4961, -4.5156, -3.5137],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0481, -0.0215,  0.0398,  ...,  0.0138,  0.0224,  0.0124],
        [-0.0007,  0.0227,  0.0098,  ...,  0.0031,  0.0293,  0.0015],
        [ 0.0389, -0.0036,  0.0297,  ..., -0.0022, -0.0190,  0.0024],
        ...,
        [-0.0028,  0.0136,  0.0363,  ...,  0.0923,  0.0128, -0.0238],
        [ 0.0062,  0.0053,  0.0008,  ...,  0.0227,  0.0099,  0.0067],
        [ 0.0014, -0.0121, -0.0229,  ..., -0.0297,  0.0155,  0.0166]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.4414, -1.9922, -1.3936,  ...,  0.5620, -5.0898, -3.1582]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 05:24:41 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A female heir is known as a heiress
A female grandfather is known as a grandmother
A female chairman is known as a chairwoman
A female stepfather is known as a stepmother
A female businessman is known as a businesswoman
A female hero is known as a heroine
A female son is known as a daughter
A female sir is known as a
2024-07-29 05:24:42 root INFO     [order_1_approx] starting weight calculation for A female businessman is known as a businesswoman
A female heir is known as a heiress
A female hero is known as a heroine
A female son is known as a daughter
A female sir is known as a madam
A female chairman is known as a chairwoman
A female stepfather is known as a stepmother
A female grandfather is known as a
2024-07-29 05:24:42 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-29 05:27:01 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3079,  0.5542,  0.2546,  ...,  0.2080, -0.0125, -0.1052],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.8477, -0.0439, -0.6963,  ...,  1.0068, -3.2578, -2.4941],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0409,  0.0001,  0.0282,  ...,  0.0569, -0.0170,  0.0120],
        [ 0.0096,  0.0205, -0.0130,  ...,  0.0110,  0.0033,  0.0006],
        [-0.0062,  0.0026,  0.0404,  ...,  0.0095, -0.0054, -0.0094],
        ...,
        [ 0.0065,  0.0027, -0.0224,  ...,  0.0335,  0.0108,  0.0012],
        [-0.0100,  0.0001,  0.0249,  ...,  0.0176, -0.0021,  0.0177],
        [-0.0106, -0.0101, -0.0009,  ..., -0.0029,  0.0192,  0.0173]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.9062,  0.2429, -0.9585,  ...,  1.3945, -3.7305, -2.5391]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 05:27:10 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A female businessman is known as a businesswoman
A female heir is known as a heiress
A female hero is known as a heroine
A female son is known as a daughter
A female sir is known as a madam
A female chairman is known as a chairwoman
A female stepfather is known as a stepmother
A female grandfather is known as a
2024-07-29 05:27:10 root INFO     [order_1_approx] starting weight calculation for A female chairman is known as a chairwoman
A female son is known as a daughter
A female sir is known as a madam
A female heir is known as a heiress
A female grandfather is known as a grandmother
A female businessman is known as a businesswoman
A female hero is known as a heroine
A female stepfather is known as a
2024-07-29 05:27:10 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-29 05:29:28 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1396,  0.2433,  0.0848,  ...,  0.2361, -0.4395,  0.0584],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.9297, -0.1660, -1.5195,  ...,  1.6445, -2.6875, -0.1890],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0074,  0.0017,  0.0068,  ...,  0.0231, -0.0118,  0.0404],
        [ 0.0016,  0.0192,  0.0022,  ...,  0.0039,  0.0061,  0.0159],
        [-0.0093,  0.0091,  0.0396,  ..., -0.0041, -0.0082,  0.0063],
        ...,
        [-0.0086, -0.0041, -0.0068,  ...,  0.0300,  0.0201, -0.0141],
        [-0.0121,  0.0057,  0.0120,  ..., -0.0012,  0.0165,  0.0021],
        [-0.0039, -0.0047,  0.0074,  ..., -0.0088,  0.0109,  0.0253]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.9336, -0.0194, -1.5850,  ...,  1.9180, -2.8633, -0.3140]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 05:29:29 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A female chairman is known as a chairwoman
A female son is known as a daughter
A female sir is known as a madam
A female heir is known as a heiress
A female grandfather is known as a grandmother
A female businessman is known as a businesswoman
A female hero is known as a heroine
A female stepfather is known as a
2024-07-29 05:29:29 root INFO     [order_1_approx] starting weight calculation for A female son is known as a daughter
A female hero is known as a heroine
A female chairman is known as a chairwoman
A female sir is known as a madam
A female businessman is known as a businesswoman
A female grandfather is known as a grandmother
A female stepfather is known as a stepmother
A female heir is known as a
2024-07-29 05:29:29 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-29 05:31:49 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2529,  0.2192, -0.2961,  ..., -0.0572, -0.1233,  0.1735],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.0684, -3.0840,  2.2656,  ..., -3.1875, -5.7734,  1.5518],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0528, -0.0210,  0.0016,  ..., -0.0009,  0.0024,  0.0108],
        [ 0.0093,  0.0433,  0.0033,  ...,  0.0128,  0.0376, -0.0181],
        [-0.0240,  0.0090,  0.0629,  ..., -0.0134, -0.0087, -0.0111],
        ...,
        [ 0.0074,  0.0141, -0.0099,  ...,  0.0498,  0.0165, -0.0230],
        [-0.0031,  0.0242, -0.0099,  ...,  0.0064,  0.0408,  0.0037],
        [ 0.0157,  0.0174, -0.0146,  ..., -0.0077,  0.0232,  0.0519]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.0508, -2.7637,  1.8369,  ..., -2.9805, -5.6680,  1.6182]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 05:31:49 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A female son is known as a daughter
A female hero is known as a heroine
A female chairman is known as a chairwoman
A female sir is known as a madam
A female businessman is known as a businesswoman
A female grandfather is known as a grandmother
A female stepfather is known as a stepmother
A female heir is known as a
2024-07-29 05:31:49 root INFO     total operator prediction time: 1123.9018123149872 seconds
2024-07-29 05:31:49 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on animal - shelter
2024-07-29 05:31:49 root INFO     building operator animal - shelter
2024-07-29 05:31:50 root INFO     [order_1_approx] starting weight calculation for The place ape lives in is called grove
The place snake lives in is called nest
The place scorpion lives in is called nest
The place chinchilla lives in is called nest
The place mole lives in is called hole
The place baboon lives in is called grove
The place dog lives in is called doghouse
The place crow lives in is called
2024-07-29 05:31:50 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-29 05:34:12 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3330, -0.2336, -0.1218,  ...,  0.3687, -0.1914, -0.0325],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 6.4414, -8.1719,  1.2871,  ..., -2.9688,  0.2148, -0.7480],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0579,  0.0065,  0.0081,  ...,  0.0154, -0.0089, -0.0107],
        [ 0.0035,  0.0673,  0.0087,  ...,  0.0194,  0.0033, -0.0022],
        [-0.0081,  0.0235,  0.0621,  ...,  0.0113, -0.0060,  0.0043],
        ...,
        [-0.0044,  0.0080,  0.0164,  ...,  0.0545,  0.0204,  0.0212],
        [ 0.0006,  0.0117, -0.0209,  ..., -0.0020,  0.0374,  0.0115],
        [-0.0172, -0.0027, -0.0249,  ..., -0.0031, -0.0357,  0.0582]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 6.8203, -8.4219,  1.3652,  ..., -3.3457, -0.0613, -0.4951]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 05:34:13 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The place ape lives in is called grove
The place snake lives in is called nest
The place scorpion lives in is called nest
The place chinchilla lives in is called nest
The place mole lives in is called hole
The place baboon lives in is called grove
The place dog lives in is called doghouse
The place crow lives in is called
2024-07-29 05:34:13 root INFO     [order_1_approx] starting weight calculation for The place mole lives in is called hole
The place dog lives in is called doghouse
The place ape lives in is called grove
The place scorpion lives in is called nest
The place snake lives in is called nest
The place chinchilla lives in is called nest
The place crow lives in is called nest
The place baboon lives in is called
2024-07-29 05:34:13 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-29 05:36:35 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.5039, -0.2920, -0.0325,  ...,  0.6387, -0.9292,  0.0331],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 6.4375, -7.0469, -1.5918,  ..., -1.8281, -2.0938, -1.1104],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 1.9226e-02,  8.1558e-03, -1.6953e-02,  ...,  2.2903e-02,
          8.0872e-03,  3.3340e-03],
        [-1.3733e-02,  6.3293e-02, -6.4850e-03,  ...,  4.1138e-02,
         -9.5825e-03, -1.3161e-02],
        [-1.1856e-02,  2.0538e-02,  4.2084e-02,  ..., -1.7792e-02,
         -6.7062e-03, -3.9577e-05],
        ...,
        [-1.0986e-03,  2.3361e-02,  9.8801e-03,  ...,  6.8726e-02,
          2.0065e-02,  1.7334e-02],
        [ 2.8858e-03, -2.0203e-02, -6.1684e-03,  ..., -5.0545e-03,
          2.0844e-02, -8.5258e-04],
        [-2.0172e-02,  1.5419e-02, -1.5579e-02,  ..., -1.4618e-02,
         -1.2672e-02,  5.2399e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 6.3516, -7.0508, -1.9102,  ..., -1.5967, -2.0898, -0.9966]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 05:36:36 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The place mole lives in is called hole
The place dog lives in is called doghouse
The place ape lives in is called grove
The place scorpion lives in is called nest
The place snake lives in is called nest
The place chinchilla lives in is called nest
The place crow lives in is called nest
The place baboon lives in is called
2024-07-29 05:36:37 root INFO     [order_1_approx] starting weight calculation for The place mole lives in is called hole
The place chinchilla lives in is called nest
The place baboon lives in is called grove
The place dog lives in is called doghouse
The place scorpion lives in is called nest
The place snake lives in is called nest
The place crow lives in is called nest
The place ape lives in is called
2024-07-29 05:36:37 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-29 05:39:00 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3137, -0.1124, -0.4883,  ...,  0.2369, -0.4478, -0.1311],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.6797, -8.2031,  0.3652,  ..., -1.6104, -3.1641,  1.1729],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 1.8448e-02, -7.3051e-04, -1.4877e-02,  ...,  8.9340e-03,
         -8.5068e-03, -1.3685e-03],
        [-9.0599e-05,  3.7323e-02, -1.2608e-03,  ...,  1.2016e-03,
         -1.4778e-02, -1.5343e-02],
        [-1.4397e-02,  2.9633e-02,  4.2999e-02,  ..., -1.3939e-02,
          5.3482e-03,  2.1572e-03],
        ...,
        [ 2.0554e-02,  2.6260e-02,  1.2016e-02,  ...,  4.5044e-02,
          1.9440e-02,  1.5869e-03],
        [-1.2253e-02, -9.1934e-03, -1.5984e-03,  ...,  4.5776e-05,
          3.8361e-02,  5.8670e-03],
        [-2.4445e-02,  9.6817e-03, -5.4932e-03,  ..., -2.4078e-02,
          8.7070e-04,  4.6326e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 5.2148, -8.1016, -0.1055,  ..., -1.8613, -3.3125,  1.0488]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 05:39:01 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The place mole lives in is called hole
The place chinchilla lives in is called nest
The place baboon lives in is called grove
The place dog lives in is called doghouse
The place scorpion lives in is called nest
The place snake lives in is called nest
The place crow lives in is called nest
The place ape lives in is called
2024-07-29 05:39:01 root INFO     [order_1_approx] starting weight calculation for The place scorpion lives in is called nest
The place ape lives in is called grove
The place mole lives in is called hole
The place snake lives in is called nest
The place crow lives in is called nest
The place baboon lives in is called grove
The place chinchilla lives in is called nest
The place dog lives in is called
2024-07-29 05:39:01 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-29 05:41:22 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0250, -0.2156, -0.1387,  ...,  0.2375, -0.0028,  0.1453],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.3125, -8.0312,  1.0986,  ..., -2.7930, -0.3594, -0.3809],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0220, -0.0135, -0.0107,  ...,  0.0111, -0.0118,  0.0019],
        [-0.0002,  0.0409, -0.0143,  ..., -0.0069, -0.0055, -0.0190],
        [ 0.0034,  0.0147,  0.0431,  ...,  0.0161,  0.0136,  0.0098],
        ...,
        [ 0.0051,  0.0149,  0.0134,  ...,  0.0184,  0.0041, -0.0035],
        [ 0.0037, -0.0062, -0.0070,  ...,  0.0240,  0.0348, -0.0160],
        [ 0.0099, -0.0154, -0.0024,  ..., -0.0058, -0.0020,  0.0446]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.3027, -7.8008,  0.5757,  ..., -2.5449, -0.3652, -0.4331]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 05:41:23 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The place scorpion lives in is called nest
The place ape lives in is called grove
The place mole lives in is called hole
The place snake lives in is called nest
The place crow lives in is called nest
The place baboon lives in is called grove
The place chinchilla lives in is called nest
The place dog lives in is called
2024-07-29 05:41:23 root INFO     [order_1_approx] starting weight calculation for The place dog lives in is called doghouse
The place chinchilla lives in is called nest
The place scorpion lives in is called nest
The place baboon lives in is called grove
The place mole lives in is called hole
The place ape lives in is called grove
The place crow lives in is called nest
The place snake lives in is called
2024-07-29 05:41:24 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-29 05:43:45 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2185, -0.0195, -0.1825,  ...,  0.0700, -0.0507,  0.0076],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.1992, -6.3438, -0.1582,  ..., -1.9766, -0.1028, -1.0811],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0442,  0.0099,  0.0016,  ...,  0.0102, -0.0109, -0.0061],
        [-0.0031,  0.0538,  0.0246,  ..., -0.0028, -0.0007, -0.0116],
        [-0.0329,  0.0299,  0.0681,  ..., -0.0381,  0.0015,  0.0114],
        ...,
        [-0.0054,  0.0116, -0.0005,  ...,  0.0444,  0.0282, -0.0117],
        [ 0.0191, -0.0001,  0.0008,  ...,  0.0191,  0.0082,  0.0018],
        [-0.0087, -0.0003, -0.0061,  ..., -0.0071, -0.0076,  0.0493]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.8418, -6.3320, -0.3464,  ..., -2.2617,  0.0551, -1.2061]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 05:43:46 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The place dog lives in is called doghouse
The place chinchilla lives in is called nest
The place scorpion lives in is called nest
The place baboon lives in is called grove
The place mole lives in is called hole
The place ape lives in is called grove
The place crow lives in is called nest
The place snake lives in is called
2024-07-29 05:43:47 root INFO     [order_1_approx] starting weight calculation for The place chinchilla lives in is called nest
The place crow lives in is called nest
The place mole lives in is called hole
The place ape lives in is called grove
The place snake lives in is called nest
The place baboon lives in is called grove
The place dog lives in is called doghouse
The place scorpion lives in is called
2024-07-29 05:43:47 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-29 05:46:09 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2583, -0.2058, -0.2460,  ...,  0.1680, -0.2098, -0.1482],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.7148, -4.6445,  2.1797,  ..., -2.7305,  1.6064,  0.0752],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0198,  0.0027,  0.0060,  ...,  0.0100, -0.0062, -0.0019],
        [-0.0083,  0.0193,  0.0065,  ...,  0.0020,  0.0063,  0.0024],
        [-0.0041,  0.0167,  0.0152,  ...,  0.0013, -0.0041,  0.0072],
        ...,
        [-0.0029,  0.0031,  0.0014,  ...,  0.0116,  0.0060,  0.0055],
        [ 0.0057,  0.0008,  0.0004,  ...,  0.0045,  0.0096, -0.0049],
        [-0.0052, -0.0033, -0.0085,  ..., -0.0036, -0.0023,  0.0226]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.7812, -4.7852,  2.1309,  ..., -2.6562,  1.6328,  0.1359]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 05:46:10 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The place chinchilla lives in is called nest
The place crow lives in is called nest
The place mole lives in is called hole
The place ape lives in is called grove
The place snake lives in is called nest
The place baboon lives in is called grove
The place dog lives in is called doghouse
The place scorpion lives in is called
2024-07-29 05:46:10 root INFO     [order_1_approx] starting weight calculation for The place mole lives in is called hole
The place snake lives in is called nest
The place ape lives in is called grove
The place dog lives in is called doghouse
The place scorpion lives in is called nest
The place crow lives in is called nest
The place baboon lives in is called grove
The place chinchilla lives in is called
2024-07-29 05:46:10 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-29 05:48:32 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3164, -0.5479, -0.3235,  ...,  0.0837, -0.0144,  0.0176],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.9961, -6.4766,  1.2383,  ..., -2.0312, -0.5991,  0.5957],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0436, -0.0097, -0.0102,  ...,  0.0270, -0.0031, -0.0067],
        [-0.0141,  0.0565,  0.0135,  ...,  0.0241,  0.0040, -0.0046],
        [-0.0352,  0.0298,  0.0586,  ..., -0.0271, -0.0060,  0.0177],
        ...,
        [-0.0135, -0.0104, -0.0168,  ...,  0.0495,  0.0357, -0.0133],
        [-0.0058,  0.0196,  0.0213,  ...,  0.0233,  0.0321,  0.0061],
        [-0.0038, -0.0019,  0.0096,  ..., -0.0134, -0.0194,  0.0616]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.7656, -6.3867,  1.1885,  ..., -1.6348, -0.9346,  0.6973]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 05:48:33 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The place mole lives in is called hole
The place snake lives in is called nest
The place ape lives in is called grove
The place dog lives in is called doghouse
The place scorpion lives in is called nest
The place crow lives in is called nest
The place baboon lives in is called grove
The place chinchilla lives in is called
2024-07-29 05:48:33 root INFO     [order_1_approx] starting weight calculation for The place snake lives in is called nest
The place ape lives in is called grove
The place scorpion lives in is called nest
The place dog lives in is called doghouse
The place crow lives in is called nest
The place chinchilla lives in is called nest
The place baboon lives in is called grove
The place mole lives in is called
2024-07-29 05:48:33 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-29 05:50:53 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3813, -0.2006, -0.1366,  ...,  0.0610, -0.2052, -0.0468],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.1465, -3.0352,  1.7510,  ..., -3.2910, -0.2690,  0.0977],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 7.0435e-02, -3.2166e-02,  3.2997e-04,  ...,  3.9154e-02,
          4.4708e-03, -1.5411e-02],
        [ 1.9440e-02,  8.9417e-02,  8.0261e-03,  ..., -1.4687e-03,
          2.6123e-02, -2.1286e-02],
        [-1.8005e-02,  1.6449e-02,  6.3293e-02,  ..., -3.0350e-02,
          8.4152e-03,  1.1566e-02],
        ...,
        [-1.3458e-02,  3.4119e-02, -6.8626e-03,  ...,  5.3558e-02,
          1.6098e-02,  1.4305e-05],
        [ 1.3855e-02, -1.1703e-02, -7.4730e-03,  ...,  3.8116e-02,
          4.1687e-02,  7.4921e-03],
        [ 6.7215e-03,  1.8570e-02, -2.5520e-03,  ..., -1.5991e-02,
         -2.1683e-02,  8.8013e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.9883, -3.4277,  1.3398,  ..., -3.6055,  0.1206, -0.5132]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 05:50:54 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The place snake lives in is called nest
The place ape lives in is called grove
The place scorpion lives in is called nest
The place dog lives in is called doghouse
The place crow lives in is called nest
The place chinchilla lives in is called nest
The place baboon lives in is called grove
The place mole lives in is called
2024-07-29 05:50:54 root INFO     total operator prediction time: 1145.007163286209 seconds
2024-07-29 05:50:54 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on country - language
2024-07-29 05:50:54 root INFO     building operator country - language
2024-07-29 05:50:55 root INFO     [order_1_approx] starting weight calculation for The country of mozambique primarily speaks the language of portuguese
The country of switzerland primarily speaks the language of german
The country of jamaica primarily speaks the language of english
The country of iran primarily speaks the language of persian
The country of bangladesh primarily speaks the language of bengali
The country of palestine primarily speaks the language of arabic
The country of ethiopia primarily speaks the language of amharic
The country of chile primarily speaks the language of
2024-07-29 05:50:55 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-29 05:53:18 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0491, -0.1763, -0.5952,  ...,  0.3889, -0.1404,  0.0194],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.4866, -2.3203,  2.8438,  ...,  0.2349, -1.1602, -2.4922],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0217,  0.0056, -0.0050,  ...,  0.0125,  0.0243, -0.0284],
        [ 0.0041,  0.0355,  0.0156,  ...,  0.0046, -0.0062, -0.0031],
        [-0.0119,  0.0097,  0.0172,  ...,  0.0097,  0.0004,  0.0290],
        ...,
        [-0.0158,  0.0095,  0.0081,  ...,  0.0264,  0.0045,  0.0160],
        [ 0.0214, -0.0070,  0.0061,  ...,  0.0145,  0.0250, -0.0098],
        [ 0.0034, -0.0160, -0.0069,  ..., -0.0087, -0.0025,  0.0026]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.5942, -2.1035,  2.2656,  ...,  0.0676, -1.3262, -2.1758]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 05:53:19 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country of mozambique primarily speaks the language of portuguese
The country of switzerland primarily speaks the language of german
The country of jamaica primarily speaks the language of english
The country of iran primarily speaks the language of persian
The country of bangladesh primarily speaks the language of bengali
The country of palestine primarily speaks the language of arabic
The country of ethiopia primarily speaks the language of amharic
The country of chile primarily speaks the language of
2024-07-29 05:53:19 root INFO     [order_1_approx] starting weight calculation for The country of palestine primarily speaks the language of arabic
The country of bangladesh primarily speaks the language of bengali
The country of mozambique primarily speaks the language of portuguese
The country of switzerland primarily speaks the language of german
The country of ethiopia primarily speaks the language of amharic
The country of jamaica primarily speaks the language of english
The country of chile primarily speaks the language of spanish
The country of iran primarily speaks the language of
2024-07-29 05:53:19 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-29 05:55:42 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0054,  0.1960, -0.0030,  ...,  0.0480, -0.2539,  0.5063],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.0173, -4.4258,  0.7451,  ...,  0.7129, -1.2051, -3.0742],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0173, -0.0057,  0.0013,  ...,  0.0069,  0.0034, -0.0075],
        [-0.0095,  0.0375,  0.0101,  ...,  0.0074,  0.0036, -0.0088],
        [-0.0022,  0.0058,  0.0368,  ...,  0.0078,  0.0033,  0.0139],
        ...,
        [ 0.0085,  0.0072, -0.0010,  ...,  0.0373,  0.0024,  0.0056],
        [-0.0043,  0.0011,  0.0069,  ..., -0.0048,  0.0292, -0.0034],
        [-0.0073, -0.0007, -0.0028,  ...,  0.0041,  0.0010,  0.0136]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.1249, -4.0898,  0.4587,  ...,  0.9209, -1.1035, -2.8223]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 05:55:43 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country of palestine primarily speaks the language of arabic
The country of bangladesh primarily speaks the language of bengali
The country of mozambique primarily speaks the language of portuguese
The country of switzerland primarily speaks the language of german
The country of ethiopia primarily speaks the language of amharic
The country of jamaica primarily speaks the language of english
The country of chile primarily speaks the language of spanish
The country of iran primarily speaks the language of
2024-07-29 05:55:43 root INFO     [order_1_approx] starting weight calculation for The country of mozambique primarily speaks the language of portuguese
The country of iran primarily speaks the language of persian
The country of bangladesh primarily speaks the language of bengali
The country of switzerland primarily speaks the language of german
The country of ethiopia primarily speaks the language of amharic
The country of jamaica primarily speaks the language of english
The country of chile primarily speaks the language of spanish
The country of palestine primarily speaks the language of
2024-07-29 05:55:43 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-29 05:58:06 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0366, -0.0981, -0.2417,  ...,  0.3110, -0.4836,  0.1343],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.3022, -4.5039,  0.3320,  ..., -1.2715,  0.8721, -0.7476],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0195, -0.0087,  0.0044,  ...,  0.0112, -0.0016, -0.0070],
        [ 0.0062,  0.0228,  0.0103,  ..., -0.0145,  0.0019, -0.0136],
        [-0.0021,  0.0067,  0.0278,  ..., -0.0046, -0.0059,  0.0082],
        ...,
        [-0.0090,  0.0040, -0.0091,  ...,  0.0300,  0.0034,  0.0053],
        [ 0.0025,  0.0027,  0.0086,  ...,  0.0031,  0.0084,  0.0028],
        [-0.0022, -0.0006, -0.0026,  ...,  0.0049, -0.0015,  0.0134]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.1292, -4.4180,  0.2200,  ..., -1.1465,  0.9048, -0.6782]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 05:58:07 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country of mozambique primarily speaks the language of portuguese
The country of iran primarily speaks the language of persian
The country of bangladesh primarily speaks the language of bengali
The country of switzerland primarily speaks the language of german
The country of ethiopia primarily speaks the language of amharic
The country of jamaica primarily speaks the language of english
The country of chile primarily speaks the language of spanish
The country of palestine primarily speaks the language of
2024-07-29 05:58:07 root INFO     [order_1_approx] starting weight calculation for The country of palestine primarily speaks the language of arabic
The country of chile primarily speaks the language of spanish
The country of iran primarily speaks the language of persian
The country of switzerland primarily speaks the language of german
The country of mozambique primarily speaks the language of portuguese
The country of ethiopia primarily speaks the language of amharic
The country of jamaica primarily speaks the language of english
The country of bangladesh primarily speaks the language of
2024-07-29 05:58:07 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-29 06:00:31 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2048,  0.0193, -0.4114,  ...,  0.3628, -0.6265,  0.3718],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.8730, -2.8945,  0.3540,  ..., -0.7051, -2.7148, -2.5391],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0139, -0.0102,  0.0045,  ...,  0.0073, -0.0023, -0.0118],
        [-0.0070,  0.0156,  0.0074,  ..., -0.0083, -0.0021, -0.0094],
        [-0.0084,  0.0084,  0.0237,  ...,  0.0033,  0.0020, -0.0015],
        ...,
        [-0.0005,  0.0028, -0.0029,  ...,  0.0152,  0.0051,  0.0067],
        [ 0.0007, -0.0023,  0.0022,  ..., -0.0020,  0.0110,  0.0018],
        [-0.0072, -0.0089, -0.0049,  ..., -0.0085, -0.0072,  0.0014]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.9160, -2.8164,  0.2642,  ..., -0.5923, -2.4922, -2.4219]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 06:00:32 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country of palestine primarily speaks the language of arabic
The country of chile primarily speaks the language of spanish
The country of iran primarily speaks the language of persian
The country of switzerland primarily speaks the language of german
The country of mozambique primarily speaks the language of portuguese
The country of ethiopia primarily speaks the language of amharic
The country of jamaica primarily speaks the language of english
The country of bangladesh primarily speaks the language of
2024-07-29 06:00:32 root INFO     [order_1_approx] starting weight calculation for The country of mozambique primarily speaks the language of portuguese
The country of palestine primarily speaks the language of arabic
The country of chile primarily speaks the language of spanish
The country of iran primarily speaks the language of persian
The country of switzerland primarily speaks the language of german
The country of bangladesh primarily speaks the language of bengali
The country of ethiopia primarily speaks the language of amharic
The country of jamaica primarily speaks the language of
2024-07-29 06:00:32 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-29 06:02:55 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1107,  0.0474, -0.3364,  ...,  0.2363, -0.3335, -0.1016],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.4766,  0.0664,  2.1680,  ...,  1.1914,  0.8594, -1.9463],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0281,  0.0099,  0.0137,  ...,  0.0103, -0.0061, -0.0187],
        [ 0.0119,  0.0253,  0.0020,  ...,  0.0026, -0.0075, -0.0145],
        [-0.0104,  0.0108,  0.0373,  ...,  0.0017,  0.0111,  0.0083],
        ...,
        [-0.0063,  0.0050, -0.0027,  ...,  0.0148,  0.0021,  0.0175],
        [-0.0072,  0.0078,  0.0049,  ..., -0.0009,  0.0292,  0.0179],
        [ 0.0047, -0.0023, -0.0089,  ...,  0.0004, -0.0079,  0.0100]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.6777,  0.3113,  1.8047,  ...,  0.9194,  0.8184, -1.5674]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 06:02:56 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country of mozambique primarily speaks the language of portuguese
The country of palestine primarily speaks the language of arabic
The country of chile primarily speaks the language of spanish
The country of iran primarily speaks the language of persian
The country of switzerland primarily speaks the language of german
The country of bangladesh primarily speaks the language of bengali
The country of ethiopia primarily speaks the language of amharic
The country of jamaica primarily speaks the language of
2024-07-29 06:02:56 root INFO     [order_1_approx] starting weight calculation for The country of switzerland primarily speaks the language of german
The country of palestine primarily speaks the language of arabic
The country of ethiopia primarily speaks the language of amharic
The country of jamaica primarily speaks the language of english
The country of bangladesh primarily speaks the language of bengali
The country of iran primarily speaks the language of persian
The country of chile primarily speaks the language of spanish
The country of mozambique primarily speaks the language of
2024-07-29 06:02:56 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-29 06:05:21 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1749, -0.0752, -0.5518,  ...,  0.3489, -0.3406, -0.1741],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.7920, -3.9629,  2.1777,  ...,  0.4937, -0.1543, -0.2634],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0061,  0.0009, -0.0103,  ..., -0.0011,  0.0016, -0.0045],
        [ 0.0026,  0.0177,  0.0161,  ...,  0.0022, -0.0106, -0.0096],
        [-0.0049,  0.0029,  0.0253,  ...,  0.0070, -0.0023,  0.0101],
        ...,
        [ 0.0061,  0.0088,  0.0068,  ...,  0.0118,  0.0071,  0.0032],
        [-0.0028,  0.0053,  0.0077,  ...,  0.0009,  0.0079,  0.0042],
        [-0.0009,  0.0045, -0.0006,  ..., -0.0016, -0.0002,  0.0007]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.7754, -4.0859,  1.8340,  ...,  0.6143, -0.1043, -0.3132]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 06:05:22 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country of switzerland primarily speaks the language of german
The country of palestine primarily speaks the language of arabic
The country of ethiopia primarily speaks the language of amharic
The country of jamaica primarily speaks the language of english
The country of bangladesh primarily speaks the language of bengali
The country of iran primarily speaks the language of persian
The country of chile primarily speaks the language of spanish
The country of mozambique primarily speaks the language of
2024-07-29 06:05:22 root INFO     [order_1_approx] starting weight calculation for The country of mozambique primarily speaks the language of portuguese
The country of iran primarily speaks the language of persian
The country of bangladesh primarily speaks the language of bengali
The country of jamaica primarily speaks the language of english
The country of switzerland primarily speaks the language of german
The country of palestine primarily speaks the language of arabic
The country of chile primarily speaks the language of spanish
The country of ethiopia primarily speaks the language of
2024-07-29 06:05:22 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-29 06:07:44 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0596, -0.1155, -0.1860,  ...,  0.1049, -0.3677,  0.0742],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.6348, -2.3887,  3.9590,  ..., -2.1172, -1.4727, -3.8047],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0115, -0.0028,  0.0074,  ...,  0.0051, -0.0060, -0.0132],
        [ 0.0044,  0.0244,  0.0177,  ..., -0.0016, -0.0111, -0.0079],
        [-0.0024,  0.0056,  0.0301,  ...,  0.0031, -0.0058,  0.0084],
        ...,
        [ 0.0040,  0.0001, -0.0019,  ...,  0.0138,  0.0035,  0.0043],
        [ 0.0008, -0.0021, -0.0074,  ...,  0.0019,  0.0182,  0.0066],
        [-0.0015,  0.0066,  0.0069,  ..., -0.0063, -0.0076, -0.0034]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.5269, -2.2148,  3.7871,  ..., -1.9863, -1.5645, -3.5156]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 06:07:51 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country of mozambique primarily speaks the language of portuguese
The country of iran primarily speaks the language of persian
The country of bangladesh primarily speaks the language of bengali
The country of jamaica primarily speaks the language of english
The country of switzerland primarily speaks the language of german
The country of palestine primarily speaks the language of arabic
The country of chile primarily speaks the language of spanish
The country of ethiopia primarily speaks the language of
2024-07-29 06:07:54 root INFO     [order_1_approx] starting weight calculation for The country of bangladesh primarily speaks the language of bengali
The country of chile primarily speaks the language of spanish
The country of palestine primarily speaks the language of arabic
The country of jamaica primarily speaks the language of english
The country of ethiopia primarily speaks the language of amharic
The country of iran primarily speaks the language of persian
The country of mozambique primarily speaks the language of portuguese
The country of switzerland primarily speaks the language of
2024-07-29 06:07:54 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-29 06:10:18 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4595, -0.0727, -0.2272,  ...,  0.5171,  0.0773,  0.3994],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.5977, -7.2617, -0.1533,  ..., -0.4504, -0.0635, -0.5928],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0240, -0.0039, -0.0006,  ..., -0.0014,  0.0127, -0.0059],
        [ 0.0098,  0.0270,  0.0204,  ..., -0.0126,  0.0159, -0.0161],
        [-0.0046,  0.0042,  0.0136,  ...,  0.0215, -0.0051,  0.0154],
        ...,
        [-0.0140,  0.0027,  0.0011,  ...,  0.0375,  0.0054, -0.0042],
        [ 0.0118,  0.0039,  0.0117,  ...,  0.0123,  0.0201, -0.0148],
        [-0.0090, -0.0136, -0.0129,  ..., -0.0063, -0.0050,  0.0181]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.1689, -6.5352, -0.6616,  ..., -0.5430,  0.2263, -0.4600]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 06:10:19 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country of bangladesh primarily speaks the language of bengali
The country of chile primarily speaks the language of spanish
The country of palestine primarily speaks the language of arabic
The country of jamaica primarily speaks the language of english
The country of ethiopia primarily speaks the language of amharic
The country of iran primarily speaks the language of persian
The country of mozambique primarily speaks the language of portuguese
The country of switzerland primarily speaks the language of
2024-07-29 06:10:19 root INFO     total operator prediction time: 1164.1050164699554 seconds
2024-07-29 06:10:19 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on name - nationality
2024-07-29 06:10:19 root INFO     building operator name - nationality
2024-07-29 06:10:19 root INFO     [order_1_approx] starting weight calculation for hume was scottish
fermi was italian
kant was german
balzac was french
napoleon was french
plato was greek
truman was american
tchaikovsky was
2024-07-29 06:10:19 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-29 06:12:40 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1052, -0.3789, -0.4121,  ...,  0.1619, -0.1558, -0.1237],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.6113, -2.9961, -0.6831,  ..., -6.0391,  0.0117, -2.6035],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0395, -0.0088, -0.0005,  ..., -0.0220, -0.0110, -0.0177],
        [ 0.0089,  0.0308,  0.0145,  ...,  0.0017,  0.0083, -0.0033],
        [ 0.0129,  0.0025,  0.0369,  ...,  0.0162, -0.0083,  0.0216],
        ...,
        [ 0.0093, -0.0054, -0.0121,  ...,  0.0241, -0.0098, -0.0053],
        [ 0.0162,  0.0101,  0.0012,  ...,  0.0017,  0.0280, -0.0019],
        [-0.0117,  0.0006, -0.0130,  ..., -0.0008, -0.0138,  0.0430]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.7676, -2.8164, -0.8931,  ..., -5.7852, -0.0402, -2.9160]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 06:12:41 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for hume was scottish
fermi was italian
kant was german
balzac was french
napoleon was french
plato was greek
truman was american
tchaikovsky was
2024-07-29 06:12:41 root INFO     [order_1_approx] starting weight calculation for fermi was italian
balzac was french
hume was scottish
kant was german
truman was american
tchaikovsky was russian
plato was greek
napoleon was
2024-07-29 06:12:41 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-29 06:15:03 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0980, -0.0392, -0.1423,  ...,  0.1718, -0.0909,  0.0780],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.2832, -4.1484, -0.3306,  ..., -1.2402, -0.4150,  0.6309],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0508,  0.0005, -0.0031,  ..., -0.0064, -0.0041, -0.0098],
        [-0.0091,  0.0505,  0.0233,  ...,  0.0065, -0.0009, -0.0031],
        [ 0.0242,  0.0041,  0.0754,  ...,  0.0077,  0.0129,  0.0224],
        ...,
        [ 0.0100,  0.0105,  0.0154,  ...,  0.0818,  0.0006,  0.0175],
        [ 0.0102,  0.0140, -0.0003,  ..., -0.0020,  0.0303,  0.0120],
        [-0.0215,  0.0059, -0.0188,  ..., -0.0116, -0.0056,  0.0482]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.2949, -4.3750, -0.4341,  ..., -1.1475, -0.4927,  0.6934]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 06:15:04 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for fermi was italian
balzac was french
hume was scottish
kant was german
truman was american
tchaikovsky was russian
plato was greek
napoleon was
2024-07-29 06:15:04 root INFO     [order_1_approx] starting weight calculation for tchaikovsky was russian
hume was scottish
napoleon was french
fermi was italian
kant was german
balzac was french
plato was greek
truman was
2024-07-29 06:15:04 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-29 06:17:27 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2443,  0.1345, -0.2123,  ...,  0.2905, -0.2949,  0.2908],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.0234, -2.4453,  1.1836,  ..., -3.2285,  2.4512, -0.9121],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0358, -0.0014, -0.0097,  ..., -0.0400, -0.0056, -0.0038],
        [ 0.0006,  0.0519, -0.0007,  ...,  0.0215, -0.0048,  0.0299],
        [ 0.0135,  0.0219,  0.0710,  ..., -0.0378, -0.0055,  0.0375],
        ...,
        [ 0.0218, -0.0041, -0.0003,  ...,  0.1147, -0.0077,  0.0145],
        [ 0.0157,  0.0224, -0.0057,  ...,  0.0137,  0.0390, -0.0071],
        [ 0.0068,  0.0306,  0.0213,  ..., -0.0164, -0.0317,  0.0919]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 5.1016, -3.9922,  0.6899,  ..., -3.9941,  2.6348, -1.3691]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 06:17:28 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for tchaikovsky was russian
hume was scottish
napoleon was french
fermi was italian
kant was german
balzac was french
plato was greek
truman was
2024-07-29 06:17:28 root INFO     [order_1_approx] starting weight calculation for napoleon was french
hume was scottish
fermi was italian
truman was american
tchaikovsky was russian
balzac was french
plato was greek
kant was
2024-07-29 06:17:28 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-29 06:19:50 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0013, -0.3174, -0.3286,  ...,  0.1573,  0.1671,  0.1560],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.2217, -4.3984,  1.8057,  ..., -3.0156, -1.3613, -2.0547],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 5.2643e-02,  2.6131e-04, -1.1330e-02,  ..., -1.4626e-02,
          7.5912e-03, -1.2177e-02],
        [ 7.3738e-03,  3.1219e-02,  1.4359e-02,  ...,  9.5215e-03,
         -6.7711e-04, -3.6659e-03],
        [ 1.5152e-02, -4.9973e-03,  7.6721e-02,  ...,  1.2154e-02,
          3.1948e-03,  2.2903e-02],
        ...,
        [-1.1375e-02,  7.2784e-03,  2.5314e-02,  ...,  6.7749e-02,
         -5.7602e-04, -1.1238e-02],
        [ 7.5912e-03, -3.0994e-03,  1.3184e-02,  ..., -3.2715e-02,
          4.7882e-02, -1.8148e-03],
        [-1.9073e-05, -1.5472e-02,  3.7727e-03,  ...,  1.1009e-02,
         -2.0569e-02,  8.3069e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.2207, -4.1289,  1.3984,  ..., -2.9277, -1.0537, -2.0527]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 06:19:50 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for napoleon was french
hume was scottish
fermi was italian
truman was american
tchaikovsky was russian
balzac was french
plato was greek
kant was
2024-07-29 06:19:51 root INFO     [order_1_approx] starting weight calculation for fermi was italian
napoleon was french
plato was greek
tchaikovsky was russian
hume was scottish
truman was american
kant was german
balzac was
2024-07-29 06:19:51 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-29 06:22:13 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1516, -0.1399, -0.5547,  ...,  0.0511, -0.0956, -0.1643],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.3672, -3.1172,  2.1367,  ..., -4.0391, -0.1465,  1.1436],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0736, -0.0482, -0.0145,  ..., -0.0405,  0.0248, -0.0483],
        [ 0.0140,  0.0900,  0.0191,  ...,  0.0492, -0.0145,  0.0371],
        [ 0.0051, -0.0111,  0.0710,  ...,  0.0181,  0.0278,  0.0133],
        ...,
        [ 0.0185,  0.0208, -0.0057,  ...,  0.0706, -0.0147,  0.0075],
        [ 0.0195,  0.0055,  0.0184,  ...,  0.0259,  0.0520,  0.0225],
        [-0.0144,  0.0348, -0.0015,  ...,  0.0244, -0.0098,  0.0984]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.4766, -3.1914,  1.7969,  ..., -3.8906, -0.3020,  0.7207]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 06:22:14 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for fermi was italian
napoleon was french
plato was greek
tchaikovsky was russian
hume was scottish
truman was american
kant was german
balzac was
2024-07-29 06:22:14 root INFO     [order_1_approx] starting weight calculation for napoleon was french
hume was scottish
truman was american
tchaikovsky was russian
balzac was french
fermi was italian
kant was german
plato was
2024-07-29 06:22:14 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-29 06:24:37 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0994, -0.2439, -0.5742,  ...,  0.3486,  0.0695,  0.2028],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.2266, -3.9355,  0.2922,  ..., -4.5391, -0.9058, -1.0645],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0638, -0.0211, -0.0071,  ..., -0.0071, -0.0127,  0.0087],
        [ 0.0063,  0.0498,  0.0134,  ...,  0.0265, -0.0104, -0.0196],
        [ 0.0220,  0.0090,  0.0624,  ...,  0.0122,  0.0007,  0.0032],
        ...,
        [ 0.0165, -0.0022,  0.0025,  ...,  0.0349,  0.0313, -0.0416],
        [ 0.0266,  0.0117,  0.0078,  ...,  0.0042,  0.0518, -0.0128],
        [-0.0087,  0.0027, -0.0115,  ...,  0.0127, -0.0233,  0.0596]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.9219, -3.7090,  0.1738,  ..., -4.5625, -0.8833, -1.5957]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 06:24:38 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for napoleon was french
hume was scottish
truman was american
tchaikovsky was russian
balzac was french
fermi was italian
kant was german
plato was
2024-07-29 06:24:38 root INFO     [order_1_approx] starting weight calculation for kant was german
tchaikovsky was russian
plato was greek
truman was american
fermi was italian
balzac was french
napoleon was french
hume was
2024-07-29 06:24:38 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-29 06:27:03 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.4683,  0.1840, -0.1045,  ...,  0.1633,  0.1884,  0.2188],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.0430, -2.1348,  1.8311,  ..., -3.5254, -1.0752, -1.7168],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0699,  0.0060, -0.0129,  ...,  0.0091,  0.0125, -0.0053],
        [-0.0044,  0.0537,  0.0062,  ...,  0.0435,  0.0170,  0.0085],
        [-0.0057, -0.0137,  0.0538,  ...,  0.0061,  0.0035,  0.0131],
        ...,
        [ 0.0138,  0.0067,  0.0052,  ...,  0.0753,  0.0320, -0.0039],
        [ 0.0303, -0.0137, -0.0073,  ..., -0.0068,  0.0574,  0.0027],
        [ 0.0064,  0.0266, -0.0150,  ...,  0.0092, -0.0274,  0.0764]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.9375, -2.6426,  1.6689,  ..., -3.7266, -1.1543, -2.0801]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 06:27:04 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for kant was german
tchaikovsky was russian
plato was greek
truman was american
fermi was italian
balzac was french
napoleon was french
hume was
2024-07-29 06:27:04 root INFO     [order_1_approx] starting weight calculation for truman was american
hume was scottish
napoleon was french
kant was german
tchaikovsky was russian
balzac was french
plato was greek
fermi was
2024-07-29 06:27:04 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-29 06:29:27 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0875,  0.0741, -0.0181,  ...,  0.3152, -0.1747,  0.7432],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.5430, -4.0664, -0.6060,  ..., -1.2598, -0.8623,  0.6631],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0600,  0.0136, -0.0241,  ..., -0.0022, -0.0084, -0.0328],
        [ 0.0397,  0.0688,  0.0173,  ...,  0.0548, -0.0069,  0.0291],
        [ 0.0077, -0.0040,  0.0743,  ...,  0.0154,  0.0173,  0.0164],
        ...,
        [ 0.0036,  0.0073,  0.0033,  ...,  0.0599,  0.0121,  0.0193],
        [ 0.0008, -0.0071, -0.0101,  ..., -0.0215,  0.0586, -0.0305],
        [ 0.0007,  0.0071,  0.0496,  ...,  0.0185, -0.0080,  0.1288]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.8105, -4.4922, -0.2451,  ..., -1.2871, -0.5864,  0.1768]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 06:29:28 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for truman was american
hume was scottish
napoleon was french
kant was german
tchaikovsky was russian
balzac was french
plato was greek
fermi was
2024-07-29 06:29:28 root INFO     total operator prediction time: 1148.9493355751038 seconds
2024-07-29 06:29:28 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on UK_city - county
2024-07-29 06:29:28 root INFO     building operator UK_city - county
2024-07-29 06:29:28 root INFO     [order_1_approx] starting weight calculation for In the United Kingdom, the city of bradford is in the county of yorkshire
In the United Kingdom, the city of reading is in the county of berkshire
In the United Kingdom, the city of wakefield is in the county of yorkshire
In the United Kingdom, the city of liverpool is in the county of lancashire
In the United Kingdom, the city of norwich is in the county of norfolk
In the United Kingdom, the city of cardiff is in the county of glamorgan
In the United Kingdom, the city of dundee is in the county of lowlands
In the United Kingdom, the city of exeter is in the county of
2024-07-29 06:29:28 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-29 06:32:23 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2002, -0.2021, -0.2751,  ...,  0.6382, -0.2576, -0.1406],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.8203, -6.2188,  2.9180,  ..., -5.0039,  0.4824, -3.3340],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0119,  0.0045, -0.0052,  ...,  0.0136, -0.0117,  0.0015],
        [-0.0139,  0.0089, -0.0044,  ...,  0.0056, -0.0196, -0.0042],
        [-0.0192,  0.0296,  0.0244,  ...,  0.0248,  0.0007, -0.0206],
        ...,
        [ 0.0297, -0.0134,  0.0114,  ...,  0.0439,  0.0324, -0.0161],
        [-0.0078, -0.0214,  0.0066,  ...,  0.0122,  0.0013,  0.0039],
        [ 0.0069,  0.0084,  0.0047,  ...,  0.0082,  0.0048, -0.0149]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.7500, -6.2305,  2.5176,  ..., -4.9414,  0.6562, -3.3184]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 06:32:24 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for In the United Kingdom, the city of bradford is in the county of yorkshire
In the United Kingdom, the city of reading is in the county of berkshire
In the United Kingdom, the city of wakefield is in the county of yorkshire
In the United Kingdom, the city of liverpool is in the county of lancashire
In the United Kingdom, the city of norwich is in the county of norfolk
In the United Kingdom, the city of cardiff is in the county of glamorgan
In the United Kingdom, the city of dundee is in the county of lowlands
In the United Kingdom, the city of exeter is in the county of
2024-07-29 06:32:24 root INFO     [order_1_approx] starting weight calculation for In the United Kingdom, the city of dundee is in the county of lowlands
In the United Kingdom, the city of cardiff is in the county of glamorgan
In the United Kingdom, the city of liverpool is in the county of lancashire
In the United Kingdom, the city of wakefield is in the county of yorkshire
In the United Kingdom, the city of bradford is in the county of yorkshire
In the United Kingdom, the city of exeter is in the county of devon
In the United Kingdom, the city of norwich is in the county of norfolk
In the United Kingdom, the city of reading is in the county of
2024-07-29 06:32:24 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-29 06:35:10 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1553, -0.2451, -0.3523,  ...,  0.6675, -0.3496, -0.0739],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.9414, -6.3906,  2.5723,  ..., -3.3281,  2.6172, -3.4609],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0107, -0.0018,  0.0173,  ...,  0.0098,  0.0051, -0.0105],
        [-0.0243, -0.0018,  0.0185,  ..., -0.0071, -0.0114,  0.0148],
        [-0.0085,  0.0077,  0.0440,  ..., -0.0166, -0.0110, -0.0059],
        ...,
        [ 0.0056,  0.0033,  0.0005,  ...,  0.0366,  0.0131, -0.0092],
        [ 0.0064, -0.0010,  0.0141,  ...,  0.0129,  0.0194, -0.0065],
        [-0.0155,  0.0090,  0.0110,  ..., -0.0011, -0.0041,  0.0113]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.7852, -6.4375,  2.2520,  ..., -3.0332,  2.6758, -3.4688]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 06:35:11 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for In the United Kingdom, the city of dundee is in the county of lowlands
In the United Kingdom, the city of cardiff is in the county of glamorgan
In the United Kingdom, the city of liverpool is in the county of lancashire
In the United Kingdom, the city of wakefield is in the county of yorkshire
In the United Kingdom, the city of bradford is in the county of yorkshire
In the United Kingdom, the city of exeter is in the county of devon
In the United Kingdom, the city of norwich is in the county of norfolk
In the United Kingdom, the city of reading is in the county of
2024-07-29 06:35:12 root INFO     [order_1_approx] starting weight calculation for In the United Kingdom, the city of bradford is in the county of yorkshire
In the United Kingdom, the city of dundee is in the county of lowlands
In the United Kingdom, the city of reading is in the county of berkshire
In the United Kingdom, the city of norwich is in the county of norfolk
In the United Kingdom, the city of liverpool is in the county of lancashire
In the United Kingdom, the city of exeter is in the county of devon
In the United Kingdom, the city of cardiff is in the county of glamorgan
In the United Kingdom, the city of wakefield is in the county of
2024-07-29 06:35:12 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-29 06:38:05 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3345, -0.1591, -0.8481,  ...,  0.3696, -0.5664,  0.5171],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.4902, -5.5391, -0.9170,  ..., -2.3828,  0.7549, -1.0449],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0132,  0.0143,  0.0129,  ..., -0.0069,  0.0100, -0.0177],
        [ 0.0064,  0.0080,  0.0062,  ..., -0.0130,  0.0069, -0.0139],
        [-0.0041,  0.0002,  0.0242,  ...,  0.0115, -0.0028, -0.0110],
        ...,
        [ 0.0235,  0.0134, -0.0080,  ...,  0.0320,  0.0014, -0.0037],
        [ 0.0074, -0.0035,  0.0071,  ...,  0.0326, -0.0003,  0.0138],
        [-0.0102,  0.0100, -0.0333,  ..., -0.0058, -0.0065,  0.0110]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.4473, -5.5234, -0.8267,  ..., -2.1543,  0.8906, -1.1807]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 06:38:06 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for In the United Kingdom, the city of bradford is in the county of yorkshire
In the United Kingdom, the city of dundee is in the county of lowlands
In the United Kingdom, the city of reading is in the county of berkshire
In the United Kingdom, the city of norwich is in the county of norfolk
In the United Kingdom, the city of liverpool is in the county of lancashire
In the United Kingdom, the city of exeter is in the county of devon
In the United Kingdom, the city of cardiff is in the county of glamorgan
In the United Kingdom, the city of wakefield is in the county of
2024-07-29 06:38:07 root INFO     [order_1_approx] starting weight calculation for In the United Kingdom, the city of wakefield is in the county of yorkshire
In the United Kingdom, the city of bradford is in the county of yorkshire
In the United Kingdom, the city of reading is in the county of berkshire
In the United Kingdom, the city of liverpool is in the county of lancashire
In the United Kingdom, the city of cardiff is in the county of glamorgan
In the United Kingdom, the city of exeter is in the county of devon
In the United Kingdom, the city of dundee is in the county of lowlands
In the United Kingdom, the city of norwich is in the county of
2024-07-29 06:38:07 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-29 06:40:52 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2988, -0.3508, -0.1005,  ...,  0.2590, -0.1304,  0.0951],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.1797, -4.5859,  2.0508,  ..., -4.2109, -1.2227, -1.7637],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0082, -0.0101,  0.0162,  ...,  0.0014, -0.0072, -0.0056],
        [ 0.0097,  0.0229,  0.0073,  ...,  0.0033, -0.0075, -0.0123],
        [-0.0206,  0.0210,  0.0257,  ...,  0.0100,  0.0247, -0.0146],
        ...,
        [ 0.0398,  0.0211, -0.0160,  ...,  0.0407,  0.0240,  0.0041],
        [ 0.0054, -0.0248,  0.0136,  ...,  0.0090,  0.0004,  0.0063],
        [-0.0101,  0.0087, -0.0001,  ..., -0.0068, -0.0021,  0.0013]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.1406, -4.6992,  1.7441,  ..., -4.2891, -1.0176, -1.4326]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 06:40:54 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for In the United Kingdom, the city of wakefield is in the county of yorkshire
In the United Kingdom, the city of bradford is in the county of yorkshire
In the United Kingdom, the city of reading is in the county of berkshire
In the United Kingdom, the city of liverpool is in the county of lancashire
In the United Kingdom, the city of cardiff is in the county of glamorgan
In the United Kingdom, the city of exeter is in the county of devon
In the United Kingdom, the city of dundee is in the county of lowlands
In the United Kingdom, the city of norwich is in the county of
2024-07-29 06:40:54 root INFO     [order_1_approx] starting weight calculation for In the United Kingdom, the city of cardiff is in the county of glamorgan
In the United Kingdom, the city of liverpool is in the county of lancashire
In the United Kingdom, the city of norwich is in the county of norfolk
In the United Kingdom, the city of reading is in the county of berkshire
In the United Kingdom, the city of exeter is in the county of devon
In the United Kingdom, the city of wakefield is in the county of yorkshire
In the United Kingdom, the city of dundee is in the county of lowlands
In the United Kingdom, the city of bradford is in the county of
2024-07-29 06:40:54 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-29 06:43:42 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3970,  0.3276, -0.3845,  ...,  0.5151, -0.5635,  0.5000],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.3848, -7.2305, -0.4651,  ..., -3.5625,  1.0732, -1.1777],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0028, -0.0047,  0.0029,  ..., -0.0005,  0.0008, -0.0179],
        [ 0.0017,  0.0077, -0.0004,  ..., -0.0139,  0.0021, -0.0084],
        [-0.0224,  0.0076,  0.0212,  ...,  0.0264,  0.0023, -0.0054],
        ...,
        [ 0.0206,  0.0205, -0.0104,  ...,  0.0308,  0.0168, -0.0071],
        [-0.0042, -0.0038, -0.0009,  ...,  0.0039,  0.0105,  0.0042],
        [ 0.0055,  0.0121, -0.0251,  ..., -0.0127, -0.0045,  0.0128]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.5684, -7.3320, -0.4646,  ..., -3.3574,  1.0088, -1.2891]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 06:43:42 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for In the United Kingdom, the city of cardiff is in the county of glamorgan
In the United Kingdom, the city of liverpool is in the county of lancashire
In the United Kingdom, the city of norwich is in the county of norfolk
In the United Kingdom, the city of reading is in the county of berkshire
In the United Kingdom, the city of exeter is in the county of devon
In the United Kingdom, the city of wakefield is in the county of yorkshire
In the United Kingdom, the city of dundee is in the county of lowlands
In the United Kingdom, the city of bradford is in the county of
2024-07-29 06:43:43 root INFO     [order_1_approx] starting weight calculation for In the United Kingdom, the city of liverpool is in the county of lancashire
In the United Kingdom, the city of reading is in the county of berkshire
In the United Kingdom, the city of norwich is in the county of norfolk
In the United Kingdom, the city of bradford is in the county of yorkshire
In the United Kingdom, the city of exeter is in the county of devon
In the United Kingdom, the city of wakefield is in the county of yorkshire
In the United Kingdom, the city of cardiff is in the county of glamorgan
In the United Kingdom, the city of dundee is in the county of
2024-07-29 06:43:43 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-29 06:46:34 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1576,  0.0103, -0.0139,  ...,  0.5703, -0.2334,  0.0380],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.1348, -1.0156,  0.3345,  ..., -2.5293, -4.1641, -0.8110],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0004, -0.0136,  0.0180,  ...,  0.0225, -0.0092, -0.0068],
        [ 0.0031,  0.0047,  0.0161,  ...,  0.0078, -0.0073, -0.0100],
        [-0.0061,  0.0165,  0.0351,  ...,  0.0081,  0.0098, -0.0107],
        ...,
        [ 0.0179,  0.0023,  0.0097,  ...,  0.0142,  0.0160, -0.0106],
        [-0.0078,  0.0032, -0.0114,  ...,  0.0051,  0.0082,  0.0179],
        [-0.0018,  0.0007, -0.0085,  ..., -0.0039, -0.0072,  0.0150]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.0664, -0.9468,  0.3879,  ..., -2.1348, -4.1797, -0.5264]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 06:46:35 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for In the United Kingdom, the city of liverpool is in the county of lancashire
In the United Kingdom, the city of reading is in the county of berkshire
In the United Kingdom, the city of norwich is in the county of norfolk
In the United Kingdom, the city of bradford is in the county of yorkshire
In the United Kingdom, the city of exeter is in the county of devon
In the United Kingdom, the city of wakefield is in the county of yorkshire
In the United Kingdom, the city of cardiff is in the county of glamorgan
In the United Kingdom, the city of dundee is in the county of
2024-07-29 06:46:35 root INFO     [order_1_approx] starting weight calculation for In the United Kingdom, the city of reading is in the county of berkshire
In the United Kingdom, the city of dundee is in the county of lowlands
In the United Kingdom, the city of bradford is in the county of yorkshire
In the United Kingdom, the city of wakefield is in the county of yorkshire
In the United Kingdom, the city of liverpool is in the county of lancashire
In the United Kingdom, the city of norwich is in the county of norfolk
In the United Kingdom, the city of exeter is in the county of devon
In the United Kingdom, the city of cardiff is in the county of
2024-07-29 06:46:35 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-29 06:49:23 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3518, -0.3921, -0.6343,  ...,  0.3765,  0.0137,  0.2974],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 6.1211, -7.1211,  1.6992,  ..., -4.2422,  0.7314, -1.2412],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0077, -0.0026, -0.0033,  ...,  0.0032, -0.0117, -0.0025],
        [ 0.0062, -0.0075,  0.0020,  ...,  0.0014, -0.0104, -0.0121],
        [-0.0121,  0.0084,  0.0403,  ...,  0.0132,  0.0066, -0.0185],
        ...,
        [ 0.0138, -0.0099,  0.0032,  ...,  0.0257, -0.0001, -0.0083],
        [ 0.0033, -0.0211,  0.0093,  ...,  0.0031,  0.0080,  0.0003],
        [-0.0032,  0.0121,  0.0092,  ..., -0.0175, -0.0016,  0.0018]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 6.1250, -6.9805,  1.4932,  ..., -3.9844,  0.8457, -1.3105]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 06:49:26 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for In the United Kingdom, the city of reading is in the county of berkshire
In the United Kingdom, the city of dundee is in the county of lowlands
In the United Kingdom, the city of bradford is in the county of yorkshire
In the United Kingdom, the city of wakefield is in the county of yorkshire
In the United Kingdom, the city of liverpool is in the county of lancashire
In the United Kingdom, the city of norwich is in the county of norfolk
In the United Kingdom, the city of exeter is in the county of devon
In the United Kingdom, the city of cardiff is in the county of
2024-07-29 06:49:28 root INFO     [order_1_approx] starting weight calculation for In the United Kingdom, the city of reading is in the county of berkshire
In the United Kingdom, the city of wakefield is in the county of yorkshire
In the United Kingdom, the city of cardiff is in the county of glamorgan
In the United Kingdom, the city of exeter is in the county of devon
In the United Kingdom, the city of bradford is in the county of yorkshire
In the United Kingdom, the city of norwich is in the county of norfolk
In the United Kingdom, the city of dundee is in the county of lowlands
In the United Kingdom, the city of liverpool is in the county of
2024-07-29 06:49:28 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-29 06:52:15 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4763, -0.1367, -0.0598,  ...,  0.4814, -0.2578,  0.2163],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.0000, -6.8125,  1.4590,  ..., -5.5781,  0.2266, -3.7930],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0103,  0.0085,  0.0130,  ...,  0.0149, -0.0091, -0.0223],
        [ 0.0063, -0.0116,  0.0093,  ..., -0.0045, -0.0012,  0.0185],
        [-0.0332,  0.0227,  0.0165,  ...,  0.0139,  0.0106, -0.0006],
        ...,
        [ 0.0155, -0.0122, -0.0104,  ...,  0.0182,  0.0026,  0.0078],
        [ 0.0066, -0.0237,  0.0103,  ...,  0.0025, -0.0008, -0.0010],
        [ 0.0061, -0.0127, -0.0183,  ..., -0.0060, -0.0161,  0.0129]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.8320, -6.8438,  1.1484,  ..., -5.6562,  0.3833, -3.4492]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 06:52:16 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for In the United Kingdom, the city of reading is in the county of berkshire
In the United Kingdom, the city of wakefield is in the county of yorkshire
In the United Kingdom, the city of cardiff is in the county of glamorgan
In the United Kingdom, the city of exeter is in the county of devon
In the United Kingdom, the city of bradford is in the county of yorkshire
In the United Kingdom, the city of norwich is in the county of norfolk
In the United Kingdom, the city of dundee is in the county of lowlands
In the United Kingdom, the city of liverpool is in the county of
2024-07-29 06:52:16 root INFO     total operator prediction time: 1368.1839265823364 seconds
2024-07-29 06:52:16 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on verb+ment_irreg
2024-07-29 06:52:16 root INFO     building operator verb+ment_irreg
2024-07-29 06:52:16 root INFO     [order_1_approx] starting weight calculation for To disagree results in a disagreement
To displace results in a displacement
To fulfil results in a fulfilment
To fulfill results in a fulfillment
To announce results in a announcement
To arrange results in a arrangement
To agree results in a agreement
To invest results in a
2024-07-29 06:52:16 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-29 06:54:40 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0725,  0.0020, -0.4697,  ..., -0.0917, -0.1469, -0.2954],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.2910, -3.7422, -1.0059,  ...,  0.4370, -0.8638, -2.4336],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0530,  0.0118, -0.0192,  ..., -0.0031,  0.0094,  0.0120],
        [-0.0003,  0.0466,  0.0093,  ...,  0.0350,  0.0298,  0.0233],
        [-0.0044,  0.0012,  0.0532,  ..., -0.0133, -0.0116,  0.0192],
        ...,
        [ 0.0031, -0.0015, -0.0096,  ...,  0.0605,  0.0019,  0.0027],
        [-0.0027,  0.0193,  0.0269,  ..., -0.0049,  0.0391, -0.0299],
        [ 0.0008, -0.0026, -0.0067,  ..., -0.0048, -0.0097,  0.0425]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.7422, -2.8418, -0.8823,  ...,  0.5547, -1.1436, -2.4199]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 06:54:41 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To disagree results in a disagreement
To displace results in a displacement
To fulfil results in a fulfilment
To fulfill results in a fulfillment
To announce results in a announcement
To arrange results in a arrangement
To agree results in a agreement
To invest results in a
2024-07-29 06:54:42 root INFO     [order_1_approx] starting weight calculation for To fulfil results in a fulfilment
To displace results in a displacement
To disagree results in a disagreement
To agree results in a agreement
To announce results in a announcement
To invest results in a investment
To fulfill results in a fulfillment
To arrange results in a
2024-07-29 06:54:42 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-29 06:57:03 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2798,  0.4263, -0.4033,  ..., -0.3179, -0.2668, -0.1339],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.6172, -4.2109, -0.6294,  ...,  2.4258,  0.3262, -3.6953],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 7.2815e-02, -3.3493e-03,  1.2337e-02,  ...,  6.6833e-03,
         -4.2610e-03,  2.7802e-02],
        [-7.1287e-05,  4.5959e-02,  3.1166e-03,  ...,  1.1688e-02,
          4.5624e-03,  2.3766e-03],
        [ 1.0414e-03, -5.1193e-03,  4.4891e-02,  ...,  1.5343e-02,
          5.3215e-03,  9.0027e-03],
        ...,
        [ 1.7548e-02, -6.9656e-03, -5.2338e-03,  ...,  5.2795e-02,
          3.5477e-03, -9.8419e-04],
        [-7.6485e-03,  2.1240e-02,  1.8768e-02,  ..., -1.1597e-02,
          4.6631e-02, -1.5991e-02],
        [ 3.4409e-03, -1.4282e-02, -5.9128e-03,  ..., -5.2338e-03,
          2.0477e-02,  4.0405e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.5449, -3.9492, -0.2910,  ...,  2.1836,  0.2318, -3.4219]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 06:57:04 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To fulfil results in a fulfilment
To displace results in a displacement
To disagree results in a disagreement
To agree results in a agreement
To announce results in a announcement
To invest results in a investment
To fulfill results in a fulfillment
To arrange results in a
2024-07-29 06:57:04 root INFO     [order_1_approx] starting weight calculation for To disagree results in a disagreement
To fulfil results in a fulfilment
To arrange results in a arrangement
To invest results in a investment
To fulfill results in a fulfillment
To displace results in a displacement
To agree results in a agreement
To announce results in a
2024-07-29 06:57:04 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-29 06:59:26 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0486,  0.5908, -0.2776,  ..., -0.0407, -0.3877,  0.0076],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.4590, -4.7422,  1.4385,  ...,  2.1309, -1.9121,  0.1924],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0453,  0.0047,  0.0078,  ..., -0.0049, -0.0132,  0.0272],
        [-0.0127,  0.0374, -0.0021,  ...,  0.0090,  0.0207,  0.0021],
        [-0.0011, -0.0244,  0.0066,  ..., -0.0024, -0.0158, -0.0039],
        ...,
        [ 0.0139, -0.0078, -0.0126,  ...,  0.0267,  0.0059,  0.0052],
        [-0.0089,  0.0150, -0.0022,  ...,  0.0010,  0.0228, -0.0194],
        [ 0.0151, -0.0102,  0.0001,  ..., -0.0069, -0.0181,  0.0356]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.3438, -4.2578,  1.3779,  ...,  1.8027, -1.6973, -0.4165]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 06:59:27 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To disagree results in a disagreement
To fulfil results in a fulfilment
To arrange results in a arrangement
To invest results in a investment
To fulfill results in a fulfillment
To displace results in a displacement
To agree results in a agreement
To announce results in a
2024-07-29 06:59:27 root INFO     [order_1_approx] starting weight calculation for To disagree results in a disagreement
To announce results in a announcement
To arrange results in a arrangement
To invest results in a investment
To fulfill results in a fulfillment
To displace results in a displacement
To agree results in a agreement
To fulfil results in a
2024-07-29 06:59:27 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-29 07:01:48 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2374,  0.3774, -0.6602,  ..., -0.2128, -0.4075,  0.0532],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.2500, -3.9141,  2.6875,  ...,  0.0747, -3.1719, -1.6641],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0529,  0.0040,  0.0069,  ..., -0.0063, -0.0114,  0.0016],
        [-0.0155,  0.0411, -0.0091,  ...,  0.0123,  0.0249, -0.0099],
        [-0.0266, -0.0220,  0.0373,  ...,  0.0015, -0.0159, -0.0010],
        ...,
        [-0.0324, -0.0346, -0.0159,  ...,  0.0641,  0.0307,  0.0122],
        [-0.0121,  0.0348, -0.0008,  ..., -0.0127,  0.0446, -0.0040],
        [ 0.0013, -0.0095, -0.0061,  ..., -0.0099, -0.0084,  0.0514]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.9414, -3.4590,  2.6406,  ...,  0.5312, -3.0586, -1.8496]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 07:01:49 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To disagree results in a disagreement
To announce results in a announcement
To arrange results in a arrangement
To invest results in a investment
To fulfill results in a fulfillment
To displace results in a displacement
To agree results in a agreement
To fulfil results in a
2024-07-29 07:01:49 root INFO     [order_1_approx] starting weight calculation for To announce results in a announcement
To disagree results in a disagreement
To agree results in a agreement
To displace results in a displacement
To invest results in a investment
To arrange results in a arrangement
To fulfil results in a fulfilment
To fulfill results in a
2024-07-29 07:01:49 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-29 07:04:12 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2642, -0.2482, -0.3665,  ..., -0.4795, -0.1300,  0.2032],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.6562, -2.8633,  2.6016,  ...,  0.4165, -3.1406, -2.4434],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 4.1443e-02,  2.6306e-02,  1.6083e-02,  ...,  6.5727e-03,
         -1.9588e-03, -7.6904e-03],
        [-1.0986e-02,  2.3605e-02, -1.3046e-02,  ...,  1.3168e-02,
          1.5961e-02, -1.7548e-02],
        [-2.0828e-02, -1.6495e-02,  2.2064e-02,  ...,  1.1261e-02,
         -1.3380e-03,  4.2114e-03],
        ...,
        [-1.1429e-02, -2.8900e-02, -2.2934e-02,  ...,  2.6825e-02,
          3.0380e-02,  3.2368e-03],
        [-4.9820e-03,  7.0190e-03, -1.9180e-02,  ..., -6.3210e-03,
          3.6591e-02, -2.6703e-05],
        [-3.3855e-03, -1.3458e-02,  7.8583e-04,  ..., -1.7643e-03,
          1.1299e-02,  2.9861e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.7539, -2.3730,  2.4551,  ...,  0.4158, -2.9902, -2.4805]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 07:04:13 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To announce results in a announcement
To disagree results in a disagreement
To agree results in a agreement
To displace results in a displacement
To invest results in a investment
To arrange results in a arrangement
To fulfil results in a fulfilment
To fulfill results in a
2024-07-29 07:04:13 root INFO     [order_1_approx] starting weight calculation for To announce results in a announcement
To displace results in a displacement
To fulfill results in a fulfillment
To agree results in a agreement
To invest results in a investment
To fulfil results in a fulfilment
To arrange results in a arrangement
To disagree results in a
2024-07-29 07:04:13 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-29 07:06:35 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.3384,  0.5220, -0.5708,  ...,  0.2039, -0.3906, -0.0496],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.5273, -4.6641,  2.2773,  ..., -0.3308,  1.4072, -1.5303],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0296,  0.0035, -0.0011,  ..., -0.0107, -0.0036, -0.0046],
        [-0.0035,  0.0350,  0.0031,  ...,  0.0005,  0.0176,  0.0168],
        [ 0.0002, -0.0130,  0.0111,  ...,  0.0041, -0.0005, -0.0024],
        ...,
        [-0.0065,  0.0006,  0.0010,  ...,  0.0349, -0.0018,  0.0143],
        [ 0.0005, -0.0062, -0.0075,  ..., -0.0010,  0.0309, -0.0253],
        [-0.0019, -0.0035,  0.0117,  ...,  0.0060, -0.0276,  0.0324]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.3984, -4.3438,  2.0938,  ..., -0.1125,  1.1328, -1.5664]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 07:06:36 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To announce results in a announcement
To displace results in a displacement
To fulfill results in a fulfillment
To agree results in a agreement
To invest results in a investment
To fulfil results in a fulfilment
To arrange results in a arrangement
To disagree results in a
2024-07-29 07:06:36 root INFO     [order_1_approx] starting weight calculation for To fulfil results in a fulfilment
To fulfill results in a fulfillment
To disagree results in a disagreement
To invest results in a investment
To arrange results in a arrangement
To displace results in a displacement
To announce results in a announcement
To agree results in a
2024-07-29 07:06:36 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-29 07:08:57 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.3955,  0.3018, -0.4976,  ..., -0.0728, -0.4207, -0.1310],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.2520, -3.5898,  0.9746,  ...,  0.8784, -1.0234, -0.2920],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0475,  0.0201,  0.0077,  ..., -0.0050, -0.0002,  0.0167],
        [ 0.0070,  0.0360,  0.0144,  ...,  0.0109,  0.0227,  0.0179],
        [-0.0075, -0.0191,  0.0144,  ...,  0.0070, -0.0246,  0.0053],
        ...,
        [-0.0086, -0.0115, -0.0149,  ...,  0.0402,  0.0090, -0.0003],
        [-0.0067,  0.0201,  0.0063,  ...,  0.0006,  0.0219, -0.0233],
        [ 0.0111, -0.0087,  0.0003,  ..., -0.0014, -0.0188,  0.0479]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.2852, -3.4219,  0.9971,  ...,  1.1250, -1.3828, -0.6587]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 07:08:58 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To fulfil results in a fulfilment
To fulfill results in a fulfillment
To disagree results in a disagreement
To invest results in a investment
To arrange results in a arrangement
To displace results in a displacement
To announce results in a announcement
To agree results in a
2024-07-29 07:08:58 root INFO     [order_1_approx] starting weight calculation for To invest results in a investment
To disagree results in a disagreement
To fulfill results in a fulfillment
To agree results in a agreement
To arrange results in a arrangement
To fulfil results in a fulfilment
To announce results in a announcement
To displace results in a
2024-07-29 07:08:58 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-29 07:11:19 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0441,  0.2415, -0.6270,  ...,  0.3340, -0.0813,  0.4199],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.0469, -3.8047, -0.4170,  ...,  2.5781, -1.1084, -0.5391],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0919,  0.0020, -0.0042,  ..., -0.0213, -0.0160,  0.0242],
        [-0.0311,  0.0507,  0.0028,  ...,  0.0607, -0.0013,  0.0073],
        [ 0.0210, -0.0119,  0.0133,  ..., -0.0314,  0.0086, -0.0185],
        ...,
        [ 0.0181,  0.0468,  0.0034,  ...,  0.0864,  0.0193,  0.0341],
        [ 0.0237,  0.0294,  0.0170,  ..., -0.0255,  0.0320, -0.0144],
        [ 0.0206,  0.0294,  0.0157,  ..., -0.0077, -0.0033,  0.0876]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.9375, -3.8496, -0.1688,  ...,  2.0938, -0.8369, -1.1426]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 07:11:20 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To invest results in a investment
To disagree results in a disagreement
To fulfill results in a fulfillment
To agree results in a agreement
To arrange results in a arrangement
To fulfil results in a fulfilment
To announce results in a announcement
To displace results in a
2024-07-29 07:11:20 root INFO     total operator prediction time: 1144.114250421524 seconds
2024-07-29 07:11:20 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on noun+less_reg
2024-07-29 07:11:20 root INFO     building operator noun+less_reg
2024-07-29 07:11:20 root INFO     [order_1_approx] starting weight calculation for Something without friction is frictionless
Something without soul is soulless
Something without heir is heirless
Something without guilt is guiltless
Something without money is moneyless
Something without speech is speechless
Something without arm is armless
Something without sleeve is
2024-07-29 07:11:20 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-29 07:13:40 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0112, -0.2671,  0.0855,  ..., -0.2402, -0.1802, -0.1392],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.8574, -3.7090, -2.1074,  ...,  0.0841, -1.6611, -0.1758],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 2.3315e-02,  1.2741e-02,  1.3138e-02,  ...,  3.2578e-03,
         -7.6485e-04, -7.5760e-03],
        [-9.8705e-04,  8.3618e-03, -8.0032e-03,  ...,  3.2187e-04,
          6.2637e-03, -2.4048e-02],
        [ 9.1705e-03,  8.9836e-04,  1.6953e-02,  ..., -2.2221e-04,
         -9.5673e-03,  9.2010e-03],
        ...,
        [ 1.5930e-02,  1.6769e-02,  8.8196e-03,  ...,  2.4963e-02,
          2.0325e-02,  1.4435e-02],
        [-1.2989e-03,  1.3840e-02,  4.1962e-03,  ...,  4.5700e-03,
          2.9343e-02, -5.3558e-03],
        [ 3.5191e-03,  9.8953e-03,  8.9645e-05,  ...,  1.5465e-02,
          2.6932e-03,  7.9193e-03]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.6172, -3.5938, -2.3145,  ..., -0.0206, -1.7549, -0.0693]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 07:13:41 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Something without friction is frictionless
Something without soul is soulless
Something without heir is heirless
Something without guilt is guiltless
Something without money is moneyless
Something without speech is speechless
Something without arm is armless
Something without sleeve is
2024-07-29 07:13:41 root INFO     [order_1_approx] starting weight calculation for Something without friction is frictionless
Something without speech is speechless
Something without guilt is guiltless
Something without heir is heirless
Something without soul is soulless
Something without money is moneyless
Something without sleeve is sleeveless
Something without arm is
2024-07-29 07:13:41 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-29 07:16:04 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1448, -0.1849,  0.2607,  ..., -0.3091, -0.1743, -0.0530],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.3701, -4.5508, -2.2500,  ...,  0.3047, -2.1738, -1.6719],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0104, -0.0239, -0.0051,  ..., -0.0107, -0.0253, -0.0309],
        [-0.0032,  0.0294, -0.0097,  ..., -0.0005,  0.0175, -0.0093],
        [ 0.0120,  0.0156,  0.0207,  ..., -0.0328, -0.0099, -0.0146],
        ...,
        [ 0.0013,  0.0233,  0.0095,  ...,  0.0406,  0.0264,  0.0095],
        [ 0.0015,  0.0121,  0.0133,  ...,  0.0156,  0.0286, -0.0104],
        [ 0.0148,  0.0172,  0.0289,  ...,  0.0079,  0.0140,  0.0374]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.5781, -4.2539, -2.3594,  ...,  0.2844, -2.5430, -1.9248]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 07:16:05 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Something without friction is frictionless
Something without speech is speechless
Something without guilt is guiltless
Something without heir is heirless
Something without soul is soulless
Something without money is moneyless
Something without sleeve is sleeveless
Something without arm is
2024-07-29 07:16:05 root INFO     [order_1_approx] starting weight calculation for Something without speech is speechless
Something without heir is heirless
Something without sleeve is sleeveless
Something without money is moneyless
Something without guilt is guiltless
Something without friction is frictionless
Something without arm is armless
Something without soul is
2024-07-29 07:16:05 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-29 07:18:29 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2771, -0.4973, -0.1201,  ..., -0.0762, -0.1506,  0.2664],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.3027, -1.3311,  0.6255,  ..., -3.6758, -2.7734,  0.2344],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0434,  0.0062,  0.0051,  ..., -0.0138,  0.0197, -0.0039],
        [ 0.0225,  0.0501,  0.0020,  ..., -0.0014, -0.0062,  0.0167],
        [ 0.0016, -0.0105,  0.0248,  ...,  0.0164, -0.0178,  0.0125],
        ...,
        [ 0.0104,  0.0222,  0.0007,  ...,  0.0401, -0.0163,  0.0027],
        [-0.0055,  0.0181,  0.0067,  ..., -0.0178,  0.0656, -0.0389],
        [ 0.0213,  0.0327,  0.0100,  ..., -0.0031, -0.0065,  0.0454]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.9473, -1.4639,  0.3176,  ..., -2.9121, -2.8984, -0.0071]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 07:18:30 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Something without speech is speechless
Something without heir is heirless
Something without sleeve is sleeveless
Something without money is moneyless
Something without guilt is guiltless
Something without friction is frictionless
Something without arm is armless
Something without soul is
2024-07-29 07:18:30 root INFO     [order_1_approx] starting weight calculation for Something without arm is armless
Something without heir is heirless
Something without guilt is guiltless
Something without soul is soulless
Something without money is moneyless
Something without sleeve is sleeveless
Something without speech is speechless
Something without friction is
2024-07-29 07:18:30 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-29 07:20:54 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2966, -0.5112, -0.3923,  ..., -0.0975,  0.2905,  0.2122],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.6797, -1.8086,  1.6543,  ..., -1.8955, -3.0527,  0.3438],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0340, -0.0033,  0.0033,  ..., -0.0051,  0.0216, -0.0053],
        [-0.0030,  0.0341,  0.0175,  ...,  0.0140, -0.0225,  0.0208],
        [-0.0029,  0.0159,  0.0268,  ..., -0.0223,  0.0093, -0.0117],
        ...,
        [ 0.0114,  0.0128,  0.0040,  ...,  0.0672,  0.0072,  0.0163],
        [-0.0072,  0.0080, -0.0048,  ..., -0.0193,  0.0476, -0.0072],
        [ 0.0196,  0.0067, -0.0052,  ...,  0.0130,  0.0243,  0.0423]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.2930, -2.0078,  1.4365,  ..., -1.7188, -2.7402,  0.4939]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 07:20:55 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Something without arm is armless
Something without heir is heirless
Something without guilt is guiltless
Something without soul is soulless
Something without money is moneyless
Something without sleeve is sleeveless
Something without speech is speechless
Something without friction is
2024-07-29 07:20:55 root INFO     [order_1_approx] starting weight calculation for Something without sleeve is sleeveless
Something without arm is armless
Something without friction is frictionless
Something without heir is heirless
Something without soul is soulless
Something without guilt is guiltless
Something without speech is speechless
Something without money is
2024-07-29 07:20:55 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-29 07:23:17 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1714, -0.3394, -0.1981,  ..., -0.0945, -0.1581,  0.0870],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.5908, -2.6250, -1.0049,  ..., -2.9160, -3.7598,  0.2451],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0463,  0.0117,  0.0042,  ..., -0.0083, -0.0030,  0.0178],
        [-0.0138,  0.0193, -0.0012,  ..., -0.0124, -0.0037, -0.0170],
        [ 0.0143,  0.0250,  0.0390,  ..., -0.0062,  0.0158,  0.0324],
        ...,
        [ 0.0164,  0.0052, -0.0011,  ...,  0.0255,  0.0104,  0.0096],
        [ 0.0002,  0.0229, -0.0003,  ...,  0.0217,  0.0512, -0.0129],
        [ 0.0083,  0.0100,  0.0090,  ...,  0.0176,  0.0145,  0.0066]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.6797, -2.4824, -1.5303,  ..., -2.9004, -3.6680,  0.1473]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 07:23:18 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Something without sleeve is sleeveless
Something without arm is armless
Something without friction is frictionless
Something without heir is heirless
Something without soul is soulless
Something without guilt is guiltless
Something without speech is speechless
Something without money is
2024-07-29 07:23:18 root INFO     [order_1_approx] starting weight calculation for Something without guilt is guiltless
Something without soul is soulless
Something without sleeve is sleeveless
Something without money is moneyless
Something without heir is heirless
Something without arm is armless
Something without friction is frictionless
Something without speech is
2024-07-29 07:23:18 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-29 07:25:41 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1384, -0.2450,  0.0553,  ...,  0.0330, -0.1148,  0.2173],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.0918, -3.1758,  0.0327,  ...,  0.3110, -1.4219, -0.2344],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0081, -0.0159,  0.0034,  ..., -0.0075,  0.0042, -0.0119],
        [ 0.0050,  0.0566,  0.0227,  ...,  0.0026, -0.0010,  0.0208],
        [ 0.0220, -0.0043,  0.0381,  ...,  0.0050, -0.0156,  0.0092],
        ...,
        [-0.0053,  0.0159, -0.0054,  ...,  0.0164,  0.0121, -0.0028],
        [-0.0075,  0.0024,  0.0017,  ..., -0.0194,  0.0300, -0.0255],
        [-0.0144,  0.0130,  0.0071,  ..., -0.0106,  0.0047,  0.0149]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.3682, -3.5801, -0.7446,  ...,  0.0361, -1.6211, -0.4683]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 07:25:43 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Something without guilt is guiltless
Something without soul is soulless
Something without sleeve is sleeveless
Something without money is moneyless
Something without heir is heirless
Something without arm is armless
Something without friction is frictionless
Something without speech is
2024-07-29 07:25:43 root INFO     [order_1_approx] starting weight calculation for Something without friction is frictionless
Something without speech is speechless
Something without sleeve is sleeveless
Something without guilt is guiltless
Something without money is moneyless
Something without soul is soulless
Something without arm is armless
Something without heir is
2024-07-29 07:25:43 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-29 07:28:08 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0093, -0.1943, -0.2146,  ..., -0.2998, -0.0797,  0.0068],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.2197, -1.3359, -0.7183,  ..., -2.8574, -3.7402, -3.5684],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0257, -0.0178,  0.0017,  ...,  0.0151, -0.0069, -0.0118],
        [ 0.0020,  0.0271, -0.0024,  ..., -0.0005,  0.0060, -0.0110],
        [-0.0057,  0.0122,  0.0457,  ...,  0.0095, -0.0030,  0.0094],
        ...,
        [ 0.0071,  0.0169, -0.0108,  ...,  0.0121,  0.0101, -0.0021],
        [-0.0128,  0.0140, -0.0122,  ..., -0.0044,  0.0323, -0.0174],
        [ 0.0054,  0.0247,  0.0054,  ...,  0.0038,  0.0047,  0.0156]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.4351, -1.5400, -1.0400,  ..., -2.8438, -3.3828, -3.6230]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 07:28:10 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Something without friction is frictionless
Something without speech is speechless
Something without sleeve is sleeveless
Something without guilt is guiltless
Something without money is moneyless
Something without soul is soulless
Something without arm is armless
Something without heir is
2024-07-29 07:28:10 root INFO     [order_1_approx] starting weight calculation for Something without money is moneyless
Something without soul is soulless
Something without arm is armless
Something without friction is frictionless
Something without speech is speechless
Something without heir is heirless
Something without sleeve is sleeveless
Something without guilt is
2024-07-29 07:28:10 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-29 07:30:33 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0107, -0.2144, -0.3252,  ...,  0.1191, -0.1486,  0.3801],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.0977, -3.0684,  1.0000,  ..., -2.6953, -1.6934, -1.5957],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0186, -0.0109,  0.0004,  ...,  0.0097, -0.0087,  0.0123],
        [ 0.0005,  0.0256,  0.0031,  ...,  0.0106, -0.0010, -0.0031],
        [ 0.0072, -0.0141,  0.0204,  ...,  0.0021,  0.0013, -0.0031],
        ...,
        [ 0.0133,  0.0147, -0.0079,  ...,  0.0123,  0.0174,  0.0047],
        [ 0.0104,  0.0090,  0.0177,  ..., -0.0230,  0.0306, -0.0013],
        [ 0.0293,  0.0032, -0.0032,  ..., -0.0015,  0.0073,  0.0298]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.2559, -3.0469,  0.4976,  ..., -2.2832, -2.5645, -1.2432]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 07:30:34 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Something without money is moneyless
Something without soul is soulless
Something without arm is armless
Something without friction is frictionless
Something without speech is speechless
Something without heir is heirless
Something without sleeve is sleeveless
Something without guilt is
2024-07-29 07:30:34 root INFO     total operator prediction time: 1153.8673467636108 seconds
2024-07-29 07:30:34 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on adj+ness_reg
2024-07-29 07:30:34 root INFO     building operator adj+ness_reg
2024-07-29 07:30:34 root INFO     [order_1_approx] starting weight calculation for The state of being innovative is innovativeness
The state of being distinct is distinctness
The state of being nice is niceness
The state of being odd is oddness
The state of being reasonable is reasonableness
The state of being competitive is competitiveness
The state of being prepared is preparedness
The state of being careful is
2024-07-29 07:30:34 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-29 07:32:54 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.6694, -0.1454, -0.3110,  ..., -0.0259, -0.2195,  0.7480],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.8730, -4.4688,  0.0740,  ..., -2.6953, -2.1504, -1.4053],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0482, -0.0049, -0.0143,  ...,  0.0046,  0.0099, -0.0028],
        [ 0.0011,  0.0355,  0.0205,  ...,  0.0282,  0.0211,  0.0214],
        [-0.0104, -0.0091,  0.0207,  ..., -0.0003, -0.0026,  0.0111],
        ...,
        [-0.0033,  0.0211,  0.0233,  ...,  0.0295, -0.0090, -0.0122],
        [-0.0045,  0.0051,  0.0071,  ..., -0.0091,  0.0178, -0.0190],
        [-0.0160, -0.0080,  0.0195,  ...,  0.0110,  0.0013,  0.0143]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.0098, -4.6016, -0.0603,  ..., -2.5859, -2.3516, -1.1855]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 07:32:55 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The state of being innovative is innovativeness
The state of being distinct is distinctness
The state of being nice is niceness
The state of being odd is oddness
The state of being reasonable is reasonableness
The state of being competitive is competitiveness
The state of being prepared is preparedness
The state of being careful is
2024-07-29 07:32:55 root INFO     [order_1_approx] starting weight calculation for The state of being distinct is distinctness
The state of being competitive is competitiveness
The state of being careful is carefulness
The state of being reasonable is reasonableness
The state of being nice is niceness
The state of being innovative is innovativeness
The state of being odd is oddness
The state of being prepared is
2024-07-29 07:32:55 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-29 07:35:17 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0690, -0.2791, -0.4043,  ..., -0.0265, -0.3296,  0.2145],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 5.2734, -5.4375, -1.7207,  ...,  0.3345, -2.4277, -2.7383],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0573, -0.0161, -0.0088,  ...,  0.0026,  0.0073,  0.0130],
        [ 0.0002,  0.0411, -0.0074,  ...,  0.0174,  0.0103,  0.0060],
        [-0.0098, -0.0020,  0.0448,  ...,  0.0153, -0.0074,  0.0201],
        ...,
        [ 0.0055,  0.0118,  0.0051,  ...,  0.0386,  0.0035,  0.0029],
        [-0.0026,  0.0189,  0.0101,  ..., -0.0110,  0.0485, -0.0233],
        [-0.0043,  0.0026, -0.0151,  ..., -0.0031, -0.0069,  0.0470]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 5.5430, -5.4219, -1.6387,  ...,  0.2820, -2.6230, -2.8477]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 07:35:18 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The state of being distinct is distinctness
The state of being competitive is competitiveness
The state of being careful is carefulness
The state of being reasonable is reasonableness
The state of being nice is niceness
The state of being innovative is innovativeness
The state of being odd is oddness
The state of being prepared is
2024-07-29 07:35:19 root INFO     [order_1_approx] starting weight calculation for The state of being careful is carefulness
The state of being distinct is distinctness
The state of being competitive is competitiveness
The state of being reasonable is reasonableness
The state of being innovative is innovativeness
The state of being odd is oddness
The state of being prepared is preparedness
The state of being nice is
2024-07-29 07:35:19 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-29 07:37:40 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0464,  0.0750,  0.0192,  ...,  0.1243, -0.4653,  0.2671],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.1797, -0.3320, -3.8320,  ..., -0.8535, -7.0156, -1.9082],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 5.7922e-02, -1.5015e-02,  3.1738e-03,  ..., -1.9394e-02,
          1.4832e-02,  2.3834e-02],
        [ 4.4365e-03,  4.8553e-02,  4.2801e-03,  ...,  4.0924e-02,
          1.8951e-02,  1.5686e-02],
        [ 1.5381e-02, -2.6642e-02,  4.4617e-02,  ...,  1.0216e-02,
         -1.2924e-02, -5.9319e-04],
        ...,
        [ 1.5526e-02, -6.4316e-03, -6.7215e-03,  ...,  5.6488e-02,
          4.4899e-03,  1.5087e-03],
        [-1.7891e-03,  3.1677e-02,  2.4933e-02,  ...,  3.0518e-05,
          2.9419e-02, -1.8341e-02],
        [ 3.7909e-04, -3.8567e-03,  1.8053e-03,  ...,  1.7944e-02,
         -2.1042e-02,  3.1403e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.3047, -0.6914, -4.9062,  ..., -0.8662, -6.8164, -1.8887]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 07:37:41 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The state of being careful is carefulness
The state of being distinct is distinctness
The state of being competitive is competitiveness
The state of being reasonable is reasonableness
The state of being innovative is innovativeness
The state of being odd is oddness
The state of being prepared is preparedness
The state of being nice is
2024-07-29 07:37:41 root INFO     [order_1_approx] starting weight calculation for The state of being competitive is competitiveness
The state of being innovative is innovativeness
The state of being reasonable is reasonableness
The state of being nice is niceness
The state of being prepared is preparedness
The state of being distinct is distinctness
The state of being careful is carefulness
The state of being odd is
2024-07-29 07:37:41 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-29 07:40:03 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0343, -0.0186,  0.0114,  ...,  0.0792, -0.2778,  0.2097],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.7656, -3.7129, -2.7422,  ..., -3.4062, -4.9531, -1.9453],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0517, -0.0010, -0.0056,  ...,  0.0030,  0.0101, -0.0021],
        [-0.0023,  0.0215, -0.0058,  ...,  0.0120, -0.0012, -0.0005],
        [ 0.0316, -0.0024,  0.0469,  ..., -0.0077,  0.0007,  0.0005],
        ...,
        [ 0.0155,  0.0263,  0.0035,  ...,  0.0272, -0.0029, -0.0021],
        [-0.0002,  0.0227,  0.0185,  ..., -0.0046,  0.0200,  0.0004],
        [ 0.0205,  0.0084, -0.0070,  ...,  0.0061,  0.0112,  0.0043]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.8271, -3.5527, -3.0938,  ..., -3.1289, -5.4375, -1.7715]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 07:40:04 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The state of being competitive is competitiveness
The state of being innovative is innovativeness
The state of being reasonable is reasonableness
The state of being nice is niceness
The state of being prepared is preparedness
The state of being distinct is distinctness
The state of being careful is carefulness
The state of being odd is
2024-07-29 07:40:04 root INFO     [order_1_approx] starting weight calculation for The state of being reasonable is reasonableness
The state of being competitive is competitiveness
The state of being innovative is innovativeness
The state of being prepared is preparedness
The state of being careful is carefulness
The state of being odd is oddness
The state of being nice is niceness
The state of being distinct is
2024-07-29 07:40:04 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-29 07:42:25 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2925, -0.0692, -0.2534,  ...,  0.3274, -0.3384,  0.0731],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.1533, -2.2500, -0.8491,  ..., -2.9609, -5.3086, -1.1367],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0302, -0.0023, -0.0163,  ..., -0.0013,  0.0170,  0.0067],
        [-0.0014,  0.0374, -0.0058,  ...,  0.0263,  0.0055,  0.0104],
        [ 0.0122, -0.0103,  0.0391,  ..., -0.0043, -0.0030, -0.0073],
        ...,
        [ 0.0075,  0.0131,  0.0019,  ...,  0.0430,  0.0009, -0.0003],
        [ 0.0002, -0.0048,  0.0287,  ..., -0.0198,  0.0338, -0.0167],
        [ 0.0108,  0.0163, -0.0046,  ...,  0.0213, -0.0033,  0.0316]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.2891, -2.3047, -0.8496,  ..., -2.4570, -6.0664, -1.0283]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 07:42:26 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The state of being reasonable is reasonableness
The state of being competitive is competitiveness
The state of being innovative is innovativeness
The state of being prepared is preparedness
The state of being careful is carefulness
The state of being odd is oddness
The state of being nice is niceness
The state of being distinct is
2024-07-29 07:42:26 root INFO     [order_1_approx] starting weight calculation for The state of being competitive is competitiveness
The state of being nice is niceness
The state of being careful is carefulness
The state of being odd is oddness
The state of being prepared is preparedness
The state of being innovative is innovativeness
The state of being distinct is distinctness
The state of being reasonable is
2024-07-29 07:42:26 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-29 07:44:49 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3655, -0.1638, -0.2444,  ..., -0.3726, -0.3296, -0.1151],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.3574, -2.1328, -1.4023,  ..., -3.5273, -5.9688, -3.2188],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0371, -0.0022, -0.0012,  ...,  0.0036, -0.0133,  0.0161],
        [-0.0216,  0.0380,  0.0056,  ...,  0.0137,  0.0203, -0.0004],
        [ 0.0121, -0.0132,  0.0480,  ..., -0.0138,  0.0003,  0.0168],
        ...,
        [ 0.0196,  0.0219,  0.0152,  ...,  0.0304,  0.0083, -0.0016],
        [ 0.0122,  0.0257,  0.0201,  ..., -0.0017,  0.0424, -0.0092],
        [ 0.0012,  0.0132,  0.0076,  ..., -0.0016, -0.0156,  0.0090]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.8296, -1.8115, -1.0557,  ..., -3.1797, -6.0703, -3.0254]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 07:44:50 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The state of being competitive is competitiveness
The state of being nice is niceness
The state of being careful is carefulness
The state of being odd is oddness
The state of being prepared is preparedness
The state of being innovative is innovativeness
The state of being distinct is distinctness
The state of being reasonable is
2024-07-29 07:44:50 root INFO     [order_1_approx] starting weight calculation for The state of being odd is oddness
The state of being reasonable is reasonableness
The state of being distinct is distinctness
The state of being careful is carefulness
The state of being innovative is innovativeness
The state of being prepared is preparedness
The state of being nice is niceness
The state of being competitive is
2024-07-29 07:44:50 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-29 07:47:10 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3552,  0.0170, -0.4429,  ..., -0.0421, -0.6118,  0.1377],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.5576, -4.7109, -1.4697,  ..., -0.8711, -0.1708, -1.0977],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 2.2476e-02,  5.1308e-03,  9.9487e-03,  ..., -9.7122e-03,
         -1.6418e-02,  1.8143e-02],
        [ 5.5656e-03,  4.5197e-02,  1.2550e-02,  ...,  2.1408e-02,
          1.2283e-02,  1.2733e-02],
        [-2.9488e-03, -1.3824e-02,  2.1713e-02,  ..., -1.0269e-02,
          3.1853e-03, -3.8261e-03],
        ...,
        [-3.0518e-03, -2.9106e-03,  4.8828e-03,  ...,  2.2003e-02,
         -3.7441e-03, -1.5854e-02],
        [-8.4782e-04,  2.6703e-03, -1.3161e-03,  ..., -7.1220e-03,
          3.6041e-02, -2.6001e-02],
        [ 5.7220e-06, -1.6739e-02, -8.4076e-03,  ..., -3.3092e-03,
         -1.1909e-02,  2.4490e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.6572, -4.5039, -1.4775,  ..., -0.5244, -0.4492, -1.0508]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 07:47:11 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The state of being odd is oddness
The state of being reasonable is reasonableness
The state of being distinct is distinctness
The state of being careful is carefulness
The state of being innovative is innovativeness
The state of being prepared is preparedness
The state of being nice is niceness
The state of being competitive is
2024-07-29 07:47:11 root INFO     [order_1_approx] starting weight calculation for The state of being competitive is competitiveness
The state of being reasonable is reasonableness
The state of being careful is carefulness
The state of being nice is niceness
The state of being distinct is distinctness
The state of being odd is oddness
The state of being prepared is preparedness
The state of being innovative is
2024-07-29 07:47:11 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-29 07:49:34 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0591, -0.0950, -0.5146,  ...,  0.0465, -0.4360, -0.0601],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.0146, -3.2363, -0.8096,  ...,  2.2832, -0.9092, -2.4023],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 3.4027e-02, -2.4700e-03,  1.8433e-02,  ...,  4.5471e-03,
          1.3237e-02,  1.9104e-02],
        [-2.3193e-02,  3.4637e-02,  2.7313e-03,  ...,  1.0078e-02,
          1.8860e-02, -7.9193e-03],
        [ 9.1400e-03, -2.2598e-02,  5.0842e-02,  ...,  9.9106e-03,
          7.6714e-03, -1.0948e-02],
        ...,
        [ 2.0828e-02,  1.2772e-02, -2.4071e-03,  ...,  3.5034e-02,
         -4.2572e-03,  5.4932e-03],
        [ 1.5793e-02,  2.8000e-02, -2.3842e-05,  ..., -5.3482e-03,
          1.3115e-02, -4.6082e-03],
        [ 1.4565e-02, -1.5732e-02,  6.2065e-03,  ..., -6.7444e-03,
         -3.4008e-03,  1.1642e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.9810, -3.2363, -1.0938,  ...,  2.5059, -1.2070, -2.3340]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 07:49:34 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The state of being competitive is competitiveness
The state of being reasonable is reasonableness
The state of being careful is carefulness
The state of being nice is niceness
The state of being distinct is distinctness
The state of being odd is oddness
The state of being prepared is preparedness
The state of being innovative is
2024-07-29 07:49:34 root INFO     total operator prediction time: 1140.7412686347961 seconds
2024-07-29 07:49:35 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on re+verb_reg
2024-07-29 07:49:35 root INFO     building operator re+verb_reg
2024-07-29 07:49:35 root INFO     [order_1_approx] starting weight calculation for To grow again is to regrow
To solve again is to resolve
To acquire again is to reacquire
To emerge again is to reemerge
To distribute again is to redistribute
To confirm again is to reconfirm
To define again is to redefine
To configure again is to
2024-07-29 07:49:35 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-29 07:51:58 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2388,  0.1653, -0.6338,  ...,  0.1404, -0.1575,  0.2043],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.9795, -2.1113,  1.8164,  ...,  3.3223, -2.7285, -3.6348],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0560, -0.0075,  0.0194,  ..., -0.0066,  0.0055,  0.0191],
        [-0.0006,  0.0465,  0.0038,  ...,  0.0131,  0.0090,  0.0093],
        [ 0.0139,  0.0325,  0.0306,  ..., -0.0098,  0.0104, -0.0038],
        ...,
        [ 0.0097, -0.0071, -0.0136,  ...,  0.0491,  0.0025, -0.0033],
        [ 0.0036,  0.0061, -0.0211,  ..., -0.0234,  0.0299, -0.0212],
        [-0.0142, -0.0111, -0.0135,  ..., -0.0056, -0.0090,  0.0349]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-2.0586, -2.3242,  1.9102,  ...,  3.5156, -2.7070, -3.3809]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 07:51:59 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To grow again is to regrow
To solve again is to resolve
To acquire again is to reacquire
To emerge again is to reemerge
To distribute again is to redistribute
To confirm again is to reconfirm
To define again is to redefine
To configure again is to
2024-07-29 07:51:59 root INFO     [order_1_approx] starting weight calculation for To solve again is to resolve
To grow again is to regrow
To distribute again is to redistribute
To define again is to redefine
To acquire again is to reacquire
To configure again is to reconfigure
To confirm again is to reconfirm
To emerge again is to
2024-07-29 07:51:59 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-29 07:54:20 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0951, -0.0190, -0.4856,  ...,  0.1538, -0.1553,  0.2981],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.0957, -0.9668, -1.7520,  ...,  2.4961, -3.5527, -4.2969],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0355,  0.0007,  0.0112,  ..., -0.0047,  0.0029,  0.0028],
        [ 0.0091,  0.0329,  0.0064,  ...,  0.0027, -0.0004,  0.0079],
        [ 0.0037,  0.0087,  0.0209,  ...,  0.0023,  0.0011, -0.0193],
        ...,
        [ 0.0101,  0.0102,  0.0051,  ...,  0.0396, -0.0043,  0.0046],
        [-0.0167,  0.0180, -0.0148,  ..., -0.0010,  0.0315, -0.0162],
        [ 0.0062,  0.0008,  0.0125,  ..., -0.0109, -0.0157,  0.0461]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.1045, -0.8857, -1.6299,  ...,  2.5605, -3.8652, -4.3320]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 07:54:21 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To solve again is to resolve
To grow again is to regrow
To distribute again is to redistribute
To define again is to redefine
To acquire again is to reacquire
To configure again is to reconfigure
To confirm again is to reconfirm
To emerge again is to
2024-07-29 07:54:21 root INFO     [order_1_approx] starting weight calculation for To define again is to redefine
To grow again is to regrow
To emerge again is to reemerge
To confirm again is to reconfirm
To configure again is to reconfigure
To acquire again is to reacquire
To solve again is to resolve
To distribute again is to
2024-07-29 07:54:21 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-29 07:56:42 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4773,  0.3794,  0.0113,  ...,  0.3140, -0.2401,  0.0019],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.0864, -3.8535, -0.4866,  ...,  0.2510, -6.9609, -4.6172],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0522, -0.0029,  0.0103,  ..., -0.0083, -0.0060,  0.0173],
        [ 0.0040,  0.0522, -0.0096,  ..., -0.0016,  0.0126,  0.0002],
        [ 0.0238,  0.0027,  0.0274,  ..., -0.0192,  0.0014, -0.0042],
        ...,
        [ 0.0193,  0.0012, -0.0146,  ...,  0.0528, -0.0032, -0.0015],
        [-0.0124,  0.0104, -0.0049,  ..., -0.0144,  0.0344, -0.0054],
        [-0.0032, -0.0005,  0.0062,  ..., -0.0100, -0.0236,  0.0442]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.1398, -3.9824, -0.1648,  ...,  0.6406, -6.7383, -4.9609]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 07:56:44 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To define again is to redefine
To grow again is to regrow
To emerge again is to reemerge
To confirm again is to reconfirm
To configure again is to reconfigure
To acquire again is to reacquire
To solve again is to resolve
To distribute again is to
2024-07-29 07:56:44 root INFO     [order_1_approx] starting weight calculation for To configure again is to reconfigure
To acquire again is to reacquire
To emerge again is to reemerge
To distribute again is to redistribute
To solve again is to resolve
To grow again is to regrow
To confirm again is to reconfirm
To define again is to
2024-07-29 07:56:44 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-29 07:59:03 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1814,  0.1241, -0.0818,  ...,  0.0897, -0.1043, -0.1095],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.8633, -3.4141,  1.6904,  ...,  1.9014, -3.9395, -4.4023],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0392, -0.0081, -0.0035,  ..., -0.0135,  0.0073,  0.0079],
        [ 0.0100,  0.0325,  0.0050,  ...,  0.0021, -0.0011,  0.0028],
        [-0.0199,  0.0096,  0.0326,  ...,  0.0122, -0.0014, -0.0015],
        ...,
        [ 0.0139, -0.0069, -0.0081,  ...,  0.0475,  0.0156,  0.0056],
        [ 0.0154,  0.0042, -0.0155,  ...,  0.0032,  0.0320, -0.0181],
        [-0.0083, -0.0032,  0.0004,  ..., -0.0094, -0.0134,  0.0429]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-2.0273, -3.1719,  1.3311,  ...,  2.2168, -4.0117, -4.2031]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 07:59:04 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To configure again is to reconfigure
To acquire again is to reacquire
To emerge again is to reemerge
To distribute again is to redistribute
To solve again is to resolve
To grow again is to regrow
To confirm again is to reconfirm
To define again is to
2024-07-29 07:59:04 root INFO     [order_1_approx] starting weight calculation for To distribute again is to redistribute
To configure again is to reconfigure
To define again is to redefine
To solve again is to resolve
To emerge again is to reemerge
To acquire again is to reacquire
To grow again is to regrow
To confirm again is to
2024-07-29 07:59:04 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-29 08:01:26 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0039,  0.1371, -0.1162,  ...,  0.3140, -0.3589,  0.0451],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.0303, -2.6953,  1.2236,  ...,  2.7500, -3.3672, -2.7461],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0446, -0.0276,  0.0135,  ..., -0.0052,  0.0031,  0.0303],
        [ 0.0041,  0.0468, -0.0011,  ...,  0.0210, -0.0050,  0.0065],
        [ 0.0039,  0.0150,  0.0328,  ..., -0.0186, -0.0033,  0.0033],
        ...,
        [ 0.0061, -0.0079, -0.0069,  ...,  0.0583,  0.0165,  0.0188],
        [ 0.0024,  0.0357, -0.0020,  ..., -0.0124,  0.0287,  0.0013],
        [-0.0109,  0.0058, -0.0024,  ..., -0.0208, -0.0241,  0.0132]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.9395, -2.7734,  0.8701,  ...,  3.0137, -3.5742, -2.7695]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 08:01:27 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To distribute again is to redistribute
To configure again is to reconfigure
To define again is to redefine
To solve again is to resolve
To emerge again is to reemerge
To acquire again is to reacquire
To grow again is to regrow
To confirm again is to
2024-07-29 08:01:27 root INFO     [order_1_approx] starting weight calculation for To solve again is to resolve
To acquire again is to reacquire
To distribute again is to redistribute
To emerge again is to reemerge
To confirm again is to reconfirm
To define again is to redefine
To configure again is to reconfigure
To grow again is to
2024-07-29 08:01:27 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-29 08:03:51 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0261, -0.0425, -0.5474,  ..., -0.1968, -0.2205,  0.0954],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.0984, -2.2656, -0.5728,  ...,  0.1787, -3.6992, -5.0664],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0431, -0.0089,  0.0215,  ...,  0.0212, -0.0039,  0.0144],
        [ 0.0087,  0.0233,  0.0101,  ...,  0.0118,  0.0041,  0.0065],
        [ 0.0111,  0.0050,  0.0380,  ..., -0.0003, -0.0029, -0.0080],
        ...,
        [-0.0049, -0.0018, -0.0113,  ...,  0.0479, -0.0076, -0.0004],
        [-0.0019,  0.0105,  0.0039,  ..., -0.0127,  0.0277, -0.0121],
        [ 0.0127,  0.0005,  0.0003,  ...,  0.0003, -0.0087,  0.0265]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.2627, -2.5742, -0.6011,  ...,  0.4338, -3.5156, -4.9688]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 08:03:51 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To solve again is to resolve
To acquire again is to reacquire
To distribute again is to redistribute
To emerge again is to reemerge
To confirm again is to reconfirm
To define again is to redefine
To configure again is to reconfigure
To grow again is to
2024-07-29 08:03:51 root INFO     [order_1_approx] starting weight calculation for To define again is to redefine
To distribute again is to redistribute
To configure again is to reconfigure
To confirm again is to reconfirm
To emerge again is to reemerge
To grow again is to regrow
To acquire again is to reacquire
To solve again is to
2024-07-29 08:03:52 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-29 08:06:13 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1857,  0.3530, -0.2837,  ..., -0.1545, -0.4751,  0.3315],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.5020, -1.7988, -1.4385,  ...,  1.4023, -5.9531, -1.1621],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0522, -0.0021,  0.0190,  ...,  0.0015,  0.0036,  0.0259],
        [ 0.0003,  0.0242, -0.0003,  ...,  0.0132, -0.0036,  0.0111],
        [-0.0059, -0.0026,  0.0281,  ...,  0.0088,  0.0159,  0.0034],
        ...,
        [ 0.0126, -0.0015,  0.0070,  ...,  0.0538,  0.0169,  0.0080],
        [-0.0218,  0.0205, -0.0021,  ..., -0.0227,  0.0246, -0.0283],
        [ 0.0028, -0.0122,  0.0227,  ...,  0.0100, -0.0028,  0.0526]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.3701, -1.8818, -1.5703,  ...,  1.4727, -6.0195, -1.1797]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 08:06:14 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To define again is to redefine
To distribute again is to redistribute
To configure again is to reconfigure
To confirm again is to reconfirm
To emerge again is to reemerge
To grow again is to regrow
To acquire again is to reacquire
To solve again is to
2024-07-29 08:06:14 root INFO     [order_1_approx] starting weight calculation for To define again is to redefine
To grow again is to regrow
To solve again is to resolve
To confirm again is to reconfirm
To emerge again is to reemerge
To distribute again is to redistribute
To configure again is to reconfigure
To acquire again is to
2024-07-29 08:06:14 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-29 08:08:36 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1848,  0.7437, -0.3494,  ...,  0.1571, -0.2803,  0.0525],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.6802, -2.3223, -0.9512,  ...,  2.0996, -5.8672, -3.3242],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0345,  0.0027,  0.0220,  ...,  0.0029,  0.0082,  0.0163],
        [ 0.0058,  0.0374, -0.0021,  ...,  0.0095,  0.0020,  0.0056],
        [ 0.0141,  0.0011,  0.0272,  ..., -0.0094,  0.0097, -0.0028],
        ...,
        [ 0.0130, -0.0026, -0.0060,  ...,  0.0360,  0.0046,  0.0019],
        [-0.0045,  0.0085, -0.0091,  ..., -0.0057,  0.0290, -0.0149],
        [-0.0047, -0.0068, -0.0060,  ..., -0.0112, -0.0073,  0.0232]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.6260, -2.5840, -0.8184,  ...,  2.0977, -5.6094, -3.3340]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 08:08:37 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To define again is to redefine
To grow again is to regrow
To solve again is to resolve
To confirm again is to reconfirm
To emerge again is to reemerge
To distribute again is to redistribute
To configure again is to reconfigure
To acquire again is to
2024-07-29 08:08:37 root INFO     total operator prediction time: 1142.3852920532227 seconds
2024-07-29 08:08:37 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on un+adj_reg
2024-07-29 08:08:37 root INFO     building operator un+adj_reg
2024-07-29 08:08:37 root INFO     [order_1_approx] starting weight calculation for The opposite of published is unpublished
The opposite of sustainable is unsustainable
The opposite of authorized is unauthorized
The opposite of able is unable
The opposite of fortunate is unfortunate
The opposite of interrupted is uninterrupted
The opposite of paid is unpaid
The opposite of usual is
2024-07-29 08:08:37 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-29 08:11:01 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2003, -0.2303, -0.1794,  ..., -0.4326, -0.4607, -0.0813],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.1191, -1.6826,  1.6465,  ..., -1.7520, -1.7812, -2.6875],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0276, -0.0137,  0.0066,  ..., -0.0094,  0.0040,  0.0305],
        [-0.0216,  0.0823, -0.0119,  ...,  0.0021, -0.0082,  0.0017],
        [ 0.0123,  0.0053,  0.0421,  ...,  0.0130,  0.0044,  0.0112],
        ...,
        [ 0.0207,  0.0199,  0.0073,  ...,  0.0423,  0.0151, -0.0124],
        [ 0.0099,  0.0217, -0.0082,  ...,  0.0292,  0.0311,  0.0003],
        [ 0.0300, -0.0035, -0.0244,  ...,  0.0245, -0.0117,  0.0256]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.2246, -1.6846,  1.3652,  ..., -1.1611, -2.2715, -2.8750]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 08:11:02 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of published is unpublished
The opposite of sustainable is unsustainable
The opposite of authorized is unauthorized
The opposite of able is unable
The opposite of fortunate is unfortunate
The opposite of interrupted is uninterrupted
The opposite of paid is unpaid
The opposite of usual is
2024-07-29 08:11:02 root INFO     [order_1_approx] starting weight calculation for The opposite of sustainable is unsustainable
The opposite of paid is unpaid
The opposite of fortunate is unfortunate
The opposite of authorized is unauthorized
The opposite of able is unable
The opposite of usual is unusual
The opposite of interrupted is uninterrupted
The opposite of published is
2024-07-29 08:11:02 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-29 08:13:25 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1755,  0.0725,  0.0211,  ..., -0.1010, -0.1731,  0.2494],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.9189, -1.6299,  0.6660,  ..., -1.9785, -2.2266,  1.9736],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0481,  0.0063, -0.0067,  ...,  0.0417,  0.0061,  0.0310],
        [-0.0095,  0.0676, -0.0017,  ...,  0.0215,  0.0016,  0.0103],
        [-0.0208, -0.0172,  0.0427,  ...,  0.0355, -0.0018, -0.0418],
        ...,
        [ 0.0123,  0.0150, -0.0017,  ...,  0.0115,  0.0050,  0.0002],
        [-0.0082, -0.0267,  0.0155,  ...,  0.0064,  0.0658, -0.0165],
        [ 0.0066,  0.0282, -0.0204,  ..., -0.0146,  0.0079,  0.0356]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.9585, -1.5596,  0.7422,  ..., -1.6572, -2.0840,  1.4512]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 08:13:26 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of sustainable is unsustainable
The opposite of paid is unpaid
The opposite of fortunate is unfortunate
The opposite of authorized is unauthorized
The opposite of able is unable
The opposite of usual is unusual
The opposite of interrupted is uninterrupted
The opposite of published is
2024-07-29 08:13:26 root INFO     [order_1_approx] starting weight calculation for The opposite of authorized is unauthorized
The opposite of usual is unusual
The opposite of sustainable is unsustainable
The opposite of paid is unpaid
The opposite of published is unpublished
The opposite of interrupted is uninterrupted
The opposite of able is unable
The opposite of fortunate is
2024-07-29 08:13:26 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-29 08:15:48 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2932,  0.5635, -0.4146,  ..., -0.2119, -0.1864,  0.3110],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.9150, -0.0298,  0.0205,  ..., -1.4707, -0.3877, -4.5859],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0227, -0.0063, -0.0092,  ...,  0.0089, -0.0431,  0.0107],
        [-0.0047,  0.0316,  0.0041,  ...,  0.0201, -0.0001,  0.0178],
        [ 0.0229, -0.0269,  0.0277,  ..., -0.0022, -0.0091, -0.0077],
        ...,
        [ 0.0308,  0.0238,  0.0063,  ...,  0.0128, -0.0035,  0.0083],
        [ 0.0327, -0.0035,  0.0362,  ..., -0.0085,  0.0647, -0.0084],
        [ 0.0129, -0.0053, -0.0307,  ...,  0.0123, -0.0046,  0.0466]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.8184, -0.4226,  0.0796,  ..., -1.0684, -0.3831, -4.4766]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 08:15:49 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of authorized is unauthorized
The opposite of usual is unusual
The opposite of sustainable is unsustainable
The opposite of paid is unpaid
The opposite of published is unpublished
The opposite of interrupted is uninterrupted
The opposite of able is unable
The opposite of fortunate is
2024-07-29 08:15:50 root INFO     [order_1_approx] starting weight calculation for The opposite of interrupted is uninterrupted
The opposite of published is unpublished
The opposite of sustainable is unsustainable
The opposite of usual is unusual
The opposite of paid is unpaid
The opposite of authorized is unauthorized
The opposite of fortunate is unfortunate
The opposite of able is
2024-07-29 08:15:50 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-29 08:18:12 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0812,  0.0608, -0.2822,  ..., -0.8013, -0.0347,  0.2062],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.3018, -5.7578,  2.6309,  ...,  0.9028, -2.2031, -1.9287],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0227, -0.0036, -0.0040,  ...,  0.0329, -0.0413,  0.0153],
        [-0.0139,  0.0414, -0.0044,  ...,  0.0259,  0.0238, -0.0012],
        [-0.0013, -0.0210,  0.0048,  ..., -0.0122,  0.0003,  0.0106],
        ...,
        [-0.0006,  0.0235, -0.0229,  ..., -0.0058,  0.0422, -0.0119],
        [-0.0110, -0.0323,  0.0256,  ..., -0.0124,  0.0473, -0.0207],
        [ 0.0042,  0.0009, -0.0404,  ...,  0.0026,  0.0215,  0.0409]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.3877, -4.6680,  2.1367,  ...,  1.5586, -2.5508, -2.2344]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 08:18:13 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of interrupted is uninterrupted
The opposite of published is unpublished
The opposite of sustainable is unsustainable
The opposite of usual is unusual
The opposite of paid is unpaid
The opposite of authorized is unauthorized
The opposite of fortunate is unfortunate
The opposite of able is
2024-07-29 08:18:13 root INFO     [order_1_approx] starting weight calculation for The opposite of sustainable is unsustainable
The opposite of paid is unpaid
The opposite of fortunate is unfortunate
The opposite of usual is unusual
The opposite of authorized is unauthorized
The opposite of able is unable
The opposite of published is unpublished
The opposite of interrupted is
2024-07-29 08:18:13 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-29 08:20:33 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2190,  0.0956, -0.1116,  ..., -0.1075, -0.2925,  0.3008],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.7852,  0.1875,  1.1699,  ...,  0.3496, -2.8477, -0.9248],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0440,  0.0386, -0.0241,  ...,  0.0197, -0.0163,  0.0308],
        [-0.0116,  0.0392, -0.0114,  ...,  0.0331,  0.0095, -0.0169],
        [ 0.0148, -0.0190,  0.0296,  ..., -0.0002,  0.0061,  0.0363],
        ...,
        [ 0.0003,  0.0414,  0.0153,  ...,  0.0405,  0.0114, -0.0142],
        [-0.0044, -0.0161,  0.0203,  ..., -0.0195,  0.0471, -0.0313],
        [ 0.0170,  0.0086, -0.0117,  ...,  0.0008,  0.0365,  0.0631]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.0801,  0.1760,  1.0137,  ...,  0.4993, -3.1367, -1.3643]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 08:20:34 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of sustainable is unsustainable
The opposite of paid is unpaid
The opposite of fortunate is unfortunate
The opposite of usual is unusual
The opposite of authorized is unauthorized
The opposite of able is unable
The opposite of published is unpublished
The opposite of interrupted is
2024-07-29 08:20:34 root INFO     [order_1_approx] starting weight calculation for The opposite of authorized is unauthorized
The opposite of able is unable
The opposite of interrupted is uninterrupted
The opposite of paid is unpaid
The opposite of fortunate is unfortunate
The opposite of usual is unusual
The opposite of published is unpublished
The opposite of sustainable is
2024-07-29 08:20:35 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-29 08:22:57 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2059, -0.0218, -0.4299,  ..., -0.3826, -0.1814,  0.1204],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.8232, -3.5098,  0.6440,  ..., -2.4902, -2.7188, -0.7197],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0305,  0.0086, -0.0104,  ...,  0.0196, -0.0130, -0.0117],
        [-0.0281,  0.0258,  0.0168,  ...,  0.0199,  0.0436,  0.0308],
        [-0.0050, -0.0106,  0.0220,  ...,  0.0117, -0.0231, -0.0059],
        ...,
        [ 0.0127,  0.0215, -0.0132,  ..., -0.0026,  0.0108, -0.0169],
        [-0.0035,  0.0280,  0.0126,  ..., -0.0058,  0.0333,  0.0156],
        [-0.0004, -0.0058, -0.0090,  ..., -0.0091,  0.0182,  0.0226]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.7783, -3.2578,  1.3076,  ..., -1.9004, -2.2969, -0.7500]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 08:22:58 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of authorized is unauthorized
The opposite of able is unable
The opposite of interrupted is uninterrupted
The opposite of paid is unpaid
The opposite of fortunate is unfortunate
The opposite of usual is unusual
The opposite of published is unpublished
The opposite of sustainable is
2024-07-29 08:22:58 root INFO     [order_1_approx] starting weight calculation for The opposite of authorized is unauthorized
The opposite of published is unpublished
The opposite of able is unable
The opposite of interrupted is uninterrupted
The opposite of sustainable is unsustainable
The opposite of usual is unusual
The opposite of fortunate is unfortunate
The opposite of paid is
2024-07-29 08:22:58 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-29 08:25:22 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3418, -0.4028, -0.2925,  ..., -0.1177, -0.4944, -0.0169],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.9678, -4.1055,  0.8652,  ..., -4.3164, -3.6699, -1.6436],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0433, -0.0307, -0.0183,  ..., -0.0071, -0.0348,  0.0392],
        [-0.0173,  0.0607, -0.0103,  ..., -0.0056, -0.0134, -0.0385],
        [-0.0206,  0.0027,  0.0505,  ...,  0.0271,  0.0300,  0.0069],
        ...,
        [ 0.0225,  0.0381, -0.0143,  ...,  0.0345,  0.0361, -0.0315],
        [-0.0143, -0.0260,  0.0115,  ...,  0.0238,  0.0571, -0.0153],
        [ 0.0123, -0.0052, -0.0482,  ..., -0.0212,  0.0409,  0.0708]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.7021, -3.9648,  0.8394,  ..., -3.7539, -4.3242, -1.5547]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 08:25:23 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of authorized is unauthorized
The opposite of published is unpublished
The opposite of able is unable
The opposite of interrupted is uninterrupted
The opposite of sustainable is unsustainable
The opposite of usual is unusual
The opposite of fortunate is unfortunate
The opposite of paid is
2024-07-29 08:25:23 root INFO     [order_1_approx] starting weight calculation for The opposite of paid is unpaid
The opposite of published is unpublished
The opposite of sustainable is unsustainable
The opposite of usual is unusual
The opposite of interrupted is uninterrupted
The opposite of able is unable
The opposite of fortunate is unfortunate
The opposite of authorized is
2024-07-29 08:25:23 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-29 08:27:45 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0030, -0.1426, -0.3140,  ..., -0.4980, -0.3027,  0.1021],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.2695, -2.7852,  2.2051,  ..., -0.0813, -1.0215, -1.0977],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0453, -0.0003,  0.0030,  ...,  0.0133, -0.0253,  0.0001],
        [-0.0006,  0.0485,  0.0063,  ...,  0.0071,  0.0058, -0.0042],
        [-0.0231,  0.0071,  0.0389,  ...,  0.0380,  0.0008,  0.0130],
        ...,
        [ 0.0210,  0.0303,  0.0099,  ...,  0.0111, -0.0191, -0.0201],
        [ 0.0067, -0.0060,  0.0087,  ..., -0.0138,  0.0663, -0.0323],
        [ 0.0231, -0.0196, -0.0186,  ..., -0.0149, -0.0003,  0.0475]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.0747, -2.6387,  2.0977,  ..., -0.1274, -1.1104, -1.4961]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 08:27:46 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of paid is unpaid
The opposite of published is unpublished
The opposite of sustainable is unsustainable
The opposite of usual is unusual
The opposite of interrupted is uninterrupted
The opposite of able is unable
The opposite of fortunate is unfortunate
The opposite of authorized is
2024-07-29 08:27:46 root INFO     total operator prediction time: 1149.4098341464996 seconds
2024-07-29 08:27:46 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on verb+able_reg
2024-07-29 08:27:46 root INFO     building operator verb+able_reg
2024-07-29 08:27:47 root INFO     [order_1_approx] starting weight calculation for If you can inflate something, that thing is inflatable
If you can admire something, that thing is admirable
If you can prevent something, that thing is preventable
If you can sustain something, that thing is sustainable
If you can afford something, that thing is affordable
If you can renew something, that thing is renewable
If you can recommend something, that thing is recommendable
If you can expand something, that thing is
2024-07-29 08:27:47 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-29 08:30:10 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0817, -0.0133, -0.4746,  ...,  0.0265, -0.1484,  0.1487],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.2666, -0.7578, -0.1760,  ..., -1.8936, -7.1875, -2.8613],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0373, -0.0032, -0.0274,  ...,  0.0459, -0.0128,  0.0267],
        [ 0.0009,  0.0633,  0.0031,  ...,  0.0028, -0.0105, -0.0047],
        [ 0.0150, -0.0216,  0.0361,  ...,  0.0098, -0.0044,  0.0005],
        ...,
        [ 0.0380,  0.0197, -0.0071,  ...,  0.0500, -0.0037,  0.0174],
        [-0.0002,  0.0012, -0.0086,  ..., -0.0175,  0.0392,  0.0026],
        [-0.0147,  0.0019, -0.0074,  ..., -0.0069, -0.0088,  0.0385]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.2505, -0.8696,  0.0791,  ..., -2.1758, -7.1836, -2.8184]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 08:30:11 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you can inflate something, that thing is inflatable
If you can admire something, that thing is admirable
If you can prevent something, that thing is preventable
If you can sustain something, that thing is sustainable
If you can afford something, that thing is affordable
If you can renew something, that thing is renewable
If you can recommend something, that thing is recommendable
If you can expand something, that thing is
2024-07-29 08:30:11 root INFO     [order_1_approx] starting weight calculation for If you can recommend something, that thing is recommendable
If you can admire something, that thing is admirable
If you can expand something, that thing is expandable
If you can inflate something, that thing is inflatable
If you can sustain something, that thing is sustainable
If you can prevent something, that thing is preventable
If you can afford something, that thing is affordable
If you can renew something, that thing is
2024-07-29 08:30:11 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-29 08:32:35 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.3123,  0.1196, -0.7002,  ..., -0.2729, -0.3828,  0.1576],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-3.4961, -2.3750, -0.3984,  ..., -3.6562, -5.5273, -2.8203],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0380, -0.0152,  0.0121,  ...,  0.0483, -0.0010,  0.0157],
        [-0.0106,  0.0633,  0.0109,  ...,  0.0201, -0.0079, -0.0115],
        [ 0.0146, -0.0222,  0.0576,  ..., -0.0071,  0.0093, -0.0135],
        ...,
        [ 0.0184,  0.0040,  0.0063,  ...,  0.0588, -0.0008,  0.0135],
        [ 0.0109,  0.0119,  0.0057,  ..., -0.0246,  0.0453, -0.0090],
        [-0.0186,  0.0135, -0.0026,  ..., -0.0336, -0.0120,  0.0237]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-3.3047, -2.7852, -0.4575,  ..., -3.4043, -5.6094, -3.1523]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 08:32:36 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you can recommend something, that thing is recommendable
If you can admire something, that thing is admirable
If you can expand something, that thing is expandable
If you can inflate something, that thing is inflatable
If you can sustain something, that thing is sustainable
If you can prevent something, that thing is preventable
If you can afford something, that thing is affordable
If you can renew something, that thing is
2024-07-29 08:32:36 root INFO     [order_1_approx] starting weight calculation for If you can inflate something, that thing is inflatable
If you can recommend something, that thing is recommendable
If you can admire something, that thing is admirable
If you can afford something, that thing is affordable
If you can expand something, that thing is expandable
If you can prevent something, that thing is preventable
If you can renew something, that thing is renewable
If you can sustain something, that thing is
2024-07-29 08:32:36 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-29 08:35:00 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2327,  0.5337, -0.1232,  ...,  0.0073, -0.0876,  0.2065],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.3105, -1.9268, -1.5146,  ..., -3.9395, -5.3516, -1.9082],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0159, -0.0009, -0.0155,  ...,  0.0048,  0.0181, -0.0065],
        [-0.0127,  0.0324,  0.0054,  ..., -0.0081, -0.0005,  0.0040],
        [ 0.0055, -0.0127,  0.0388,  ...,  0.0080, -0.0021, -0.0013],
        ...,
        [ 0.0251,  0.0218, -0.0028,  ...,  0.0240,  0.0068,  0.0027],
        [ 0.0027,  0.0027, -0.0025,  ..., -0.0107,  0.0049, -0.0087],
        [ 0.0070, -0.0065, -0.0093,  ..., -0.0168, -0.0201,  0.0182]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.1504, -2.1562, -1.4219,  ..., -3.6934, -5.3516, -1.9707]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 08:35:01 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you can inflate something, that thing is inflatable
If you can recommend something, that thing is recommendable
If you can admire something, that thing is admirable
If you can afford something, that thing is affordable
If you can expand something, that thing is expandable
If you can prevent something, that thing is preventable
If you can renew something, that thing is renewable
If you can sustain something, that thing is
2024-07-29 08:35:01 root INFO     [order_1_approx] starting weight calculation for If you can prevent something, that thing is preventable
If you can recommend something, that thing is recommendable
If you can afford something, that thing is affordable
If you can admire something, that thing is admirable
If you can expand something, that thing is expandable
If you can sustain something, that thing is sustainable
If you can renew something, that thing is renewable
If you can inflate something, that thing is
2024-07-29 08:35:01 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-29 08:37:19 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0462, -0.0619, -0.6826,  ..., -0.0203,  0.1744,  0.4597],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.5508, -1.2197,  0.7383,  ..., -1.7471, -4.9492, -0.9492],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 3.7781e-02, -2.5101e-03, -1.1383e-02,  ...,  3.9368e-03,
          1.0696e-02, -2.0027e-03],
        [-8.7891e-03,  3.6072e-02,  1.1963e-02,  ..., -2.1896e-03,
         -1.9791e-02, -8.2321e-03],
        [ 6.8665e-05,  2.1088e-02,  2.7756e-02,  ...,  1.0757e-02,
         -7.0572e-04, -1.7151e-02],
        ...,
        [ 2.0416e-02,  2.6703e-03, -5.3406e-05,  ...,  3.5217e-02,
         -3.5267e-03,  7.9155e-04],
        [ 2.4185e-02,  1.2695e-02,  3.5191e-04,  ..., -1.2466e-02,
          5.1849e-02, -1.2909e-02],
        [ 1.1757e-02,  3.1143e-02,  1.3214e-02,  ..., -3.3264e-03,
         -1.7929e-02,  2.9007e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.7539, -1.2080,  0.7222,  ..., -1.4414, -4.7578, -0.8643]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 08:37:20 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you can prevent something, that thing is preventable
If you can recommend something, that thing is recommendable
If you can afford something, that thing is affordable
If you can admire something, that thing is admirable
If you can expand something, that thing is expandable
If you can sustain something, that thing is sustainable
If you can renew something, that thing is renewable
If you can inflate something, that thing is
2024-07-29 08:37:20 root INFO     [order_1_approx] starting weight calculation for If you can sustain something, that thing is sustainable
If you can admire something, that thing is admirable
If you can recommend something, that thing is recommendable
If you can expand something, that thing is expandable
If you can inflate something, that thing is inflatable
If you can renew something, that thing is renewable
If you can afford something, that thing is affordable
If you can prevent something, that thing is
2024-07-29 08:37:20 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-29 08:39:43 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0740,  0.2208, -0.3057,  ..., -0.1890, -0.0783, -0.0264],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.4785, -1.2764, -1.5449,  ..., -2.0918, -6.7344, -3.3359],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0418,  0.0120, -0.0138,  ...,  0.0235, -0.0074,  0.0050],
        [-0.0068,  0.0527,  0.0118,  ...,  0.0165,  0.0062, -0.0063],
        [ 0.0007, -0.0367,  0.0270,  ..., -0.0035, -0.0147, -0.0013],
        ...,
        [ 0.0216, -0.0010, -0.0107,  ...,  0.0432, -0.0046,  0.0181],
        [ 0.0002, -0.0246,  0.0021,  ..., -0.0161,  0.0319, -0.0257],
        [ 0.0077, -0.0145,  0.0153,  ..., -0.0069, -0.0101,  0.0126]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.5518, -1.6553, -1.5039,  ..., -2.0977, -6.7656, -3.2441]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 08:39:44 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you can sustain something, that thing is sustainable
If you can admire something, that thing is admirable
If you can recommend something, that thing is recommendable
If you can expand something, that thing is expandable
If you can inflate something, that thing is inflatable
If you can renew something, that thing is renewable
If you can afford something, that thing is affordable
If you can prevent something, that thing is
2024-07-29 08:39:44 root INFO     [order_1_approx] starting weight calculation for If you can inflate something, that thing is inflatable
If you can renew something, that thing is renewable
If you can expand something, that thing is expandable
If you can admire something, that thing is admirable
If you can sustain something, that thing is sustainable
If you can afford something, that thing is affordable
If you can prevent something, that thing is preventable
If you can recommend something, that thing is
2024-07-29 08:39:44 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-29 08:42:07 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2234,  0.5684,  0.0291,  ...,  0.3975, -0.2169, -0.3252],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.7188,  0.4844, -0.7954,  ..., -1.1279, -7.9727, -3.9453],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0263,  0.0145, -0.0130,  ...,  0.0397, -0.0133,  0.0318],
        [-0.0028,  0.0399,  0.0050,  ...,  0.0266,  0.0018,  0.0209],
        [ 0.0210,  0.0026,  0.0327,  ...,  0.0204, -0.0130,  0.0089],
        ...,
        [ 0.0066,  0.0202, -0.0054,  ...,  0.0604,  0.0173,  0.0169],
        [ 0.0235,  0.0003,  0.0085,  ..., -0.0179,  0.0201, -0.0138],
        [-0.0053, -0.0116,  0.0037,  ..., -0.0104, -0.0057,  0.0175]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.9482,  0.6738, -1.2861,  ..., -0.9062, -8.0312, -4.1367]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 08:42:09 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you can inflate something, that thing is inflatable
If you can renew something, that thing is renewable
If you can expand something, that thing is expandable
If you can admire something, that thing is admirable
If you can sustain something, that thing is sustainable
If you can afford something, that thing is affordable
If you can prevent something, that thing is preventable
If you can recommend something, that thing is
2024-07-29 08:42:09 root INFO     [order_1_approx] starting weight calculation for If you can inflate something, that thing is inflatable
If you can sustain something, that thing is sustainable
If you can renew something, that thing is renewable
If you can recommend something, that thing is recommendable
If you can afford something, that thing is affordable
If you can prevent something, that thing is preventable
If you can expand something, that thing is expandable
If you can admire something, that thing is
2024-07-29 08:42:09 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-29 08:44:32 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0744,  0.0923,  0.0044,  ...,  0.3147, -0.2083,  0.1768],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 5.2188, -0.1562, -1.5498,  ..., -1.6836, -6.4727, -1.4844],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0241,  0.0223, -0.0158,  ..., -0.0004, -0.0160,  0.0077],
        [-0.0118,  0.0297,  0.0116,  ...,  0.0253,  0.0122, -0.0114],
        [ 0.0162, -0.0065,  0.0483,  ...,  0.0098,  0.0057,  0.0030],
        ...,
        [ 0.0276,  0.0240, -0.0258,  ...,  0.0261,  0.0117, -0.0095],
        [-0.0081, -0.0091,  0.0201,  ..., -0.0007,  0.0123,  0.0128],
        [-0.0002,  0.0078, -0.0107,  ..., -0.0116, -0.0149,  0.0087]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 5.2188, -0.1782, -1.9404,  ..., -1.3340, -6.6523, -1.6084]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 08:44:33 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you can inflate something, that thing is inflatable
If you can sustain something, that thing is sustainable
If you can renew something, that thing is renewable
If you can recommend something, that thing is recommendable
If you can afford something, that thing is affordable
If you can prevent something, that thing is preventable
If you can expand something, that thing is expandable
If you can admire something, that thing is
2024-07-29 08:44:33 root INFO     [order_1_approx] starting weight calculation for If you can recommend something, that thing is recommendable
If you can renew something, that thing is renewable
If you can expand something, that thing is expandable
If you can prevent something, that thing is preventable
If you can admire something, that thing is admirable
If you can inflate something, that thing is inflatable
If you can sustain something, that thing is sustainable
If you can afford something, that thing is
2024-07-29 08:44:33 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-29 08:46:55 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2435,  0.3728, -0.0598,  ...,  0.1997,  0.3054, -0.0255],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.6904, -0.8281, -2.8438,  ..., -2.7109, -8.8281, -1.3291],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0403,  0.0199,  0.0094,  ...,  0.0039,  0.0082,  0.0063],
        [-0.0194,  0.0381,  0.0145,  ...,  0.0117, -0.0068, -0.0133],
        [ 0.0119, -0.0189,  0.0367,  ...,  0.0216, -0.0121, -0.0102],
        ...,
        [ 0.0104,  0.0182, -0.0039,  ...,  0.0458,  0.0244,  0.0141],
        [ 0.0095,  0.0030,  0.0111,  ..., -0.0106,  0.0236, -0.0193],
        [-0.0245, -0.0186, -0.0030,  ..., -0.0091, -0.0057,  0.0195]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.2900, -0.9106, -2.8535,  ..., -2.4062, -8.2891, -1.2988]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 08:46:56 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you can recommend something, that thing is recommendable
If you can renew something, that thing is renewable
If you can expand something, that thing is expandable
If you can prevent something, that thing is preventable
If you can admire something, that thing is admirable
If you can inflate something, that thing is inflatable
If you can sustain something, that thing is sustainable
If you can afford something, that thing is
2024-07-29 08:46:56 root INFO     total operator prediction time: 1149.975219488144 seconds
2024-07-29 08:46:56 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on verb+tion_irreg
2024-07-29 08:46:56 root INFO     building operator verb+tion_irreg
2024-07-29 08:46:57 root INFO     [order_1_approx] starting weight calculation for To expire results in expiration
To declare results in declaration
To derive results in derivation
To civilize results in civilization
To allege results in allegation
To improvize results in improvization
To standardize results in standardization
To modernize results in
2024-07-29 08:46:57 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-29 08:49:19 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3071,  0.4795, -0.5073,  ..., -0.3457, -0.3672, -0.0331],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.6162, -3.8574,  0.2266,  ..., -0.0449, -2.2578, -0.4551],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0200, -0.0078,  0.0077,  ..., -0.0075,  0.0012,  0.0144],
        [-0.0005,  0.0303,  0.0043,  ...,  0.0099,  0.0065,  0.0024],
        [-0.0036, -0.0080,  0.0330,  ...,  0.0122,  0.0060,  0.0010],
        ...,
        [-0.0069,  0.0027,  0.0095,  ...,  0.0375, -0.0025, -0.0111],
        [ 0.0048,  0.0121,  0.0001,  ...,  0.0158,  0.0346, -0.0113],
        [-0.0020, -0.0074,  0.0004,  ..., -0.0061, -0.0144,  0.0190]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.3740, -3.9258,  0.2603,  ...,  0.0097, -2.5664, -0.5513]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 08:49:20 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To expire results in expiration
To declare results in declaration
To derive results in derivation
To civilize results in civilization
To allege results in allegation
To improvize results in improvization
To standardize results in standardization
To modernize results in
2024-07-29 08:49:20 root INFO     [order_1_approx] starting weight calculation for To expire results in expiration
To modernize results in modernization
To civilize results in civilization
To declare results in declaration
To improvize results in improvization
To allege results in allegation
To derive results in derivation
To standardize results in
2024-07-29 08:49:20 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-29 08:51:42 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1445, -0.0222, -0.6807,  ..., -0.2367, -0.3997, -0.3054],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.4839, -3.8477,  0.9224,  ...,  1.4424, -1.8848, -3.2168],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0569, -0.0047, -0.0140,  ..., -0.0073,  0.0097,  0.0018],
        [-0.0127,  0.0441,  0.0173,  ...,  0.0030, -0.0042,  0.0162],
        [-0.0073,  0.0027,  0.0312,  ...,  0.0135,  0.0017, -0.0077],
        ...,
        [-0.0323,  0.0025,  0.0183,  ...,  0.0576, -0.0115,  0.0062],
        [-0.0095,  0.0188,  0.0112,  ...,  0.0266,  0.0411,  0.0017],
        [-0.0240,  0.0064,  0.0110,  ..., -0.0064, -0.0242,  0.0517]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.3555, -3.0254,  1.0801,  ...,  2.3184, -2.2402, -2.5352]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 08:51:43 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To expire results in expiration
To modernize results in modernization
To civilize results in civilization
To declare results in declaration
To improvize results in improvization
To allege results in allegation
To derive results in derivation
To standardize results in
2024-07-29 08:51:43 root INFO     [order_1_approx] starting weight calculation for To modernize results in modernization
To standardize results in standardization
To improvize results in improvization
To derive results in derivation
To declare results in declaration
To expire results in expiration
To civilize results in civilization
To allege results in
2024-07-29 08:51:43 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-29 08:54:05 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2135,  0.2366, -0.4993,  ..., -0.2798, -0.6851,  0.1758],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.4131, -5.4375,  0.5898,  ...,  2.8613, -1.9268, -0.2617],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0623, -0.0139, -0.0198,  ..., -0.0188, -0.0123,  0.0056],
        [-0.0141,  0.0761,  0.0085,  ...,  0.0444,  0.0142,  0.0063],
        [-0.0011, -0.0323,  0.0420,  ...,  0.0013, -0.0093,  0.0059],
        ...,
        [-0.0249,  0.0109,  0.0129,  ...,  0.0553, -0.0042,  0.0033],
        [ 0.0054, -0.0080,  0.0092,  ...,  0.0047,  0.0538, -0.0039],
        [-0.0082,  0.0018,  0.0097,  ...,  0.0202, -0.0210,  0.0657]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.7988, -4.4023,  0.6396,  ...,  3.3125, -1.5137, -0.6475]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 08:54:07 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To modernize results in modernization
To standardize results in standardization
To improvize results in improvization
To derive results in derivation
To declare results in declaration
To expire results in expiration
To civilize results in civilization
To allege results in
2024-07-29 08:54:07 root INFO     [order_1_approx] starting weight calculation for To declare results in declaration
To expire results in expiration
To allege results in allegation
To improvize results in improvization
To standardize results in standardization
To civilize results in civilization
To modernize results in modernization
To derive results in
2024-07-29 08:54:07 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-29 08:56:30 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0486, -0.0885, -0.0400,  ..., -0.2944, -0.3899,  0.2583],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.6191, -3.5527,  2.8008,  ...,  0.4343, -1.9404, -1.6729],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0467,  0.0009, -0.0183,  ..., -0.0375, -0.0140, -0.0116],
        [ 0.0145,  0.0969,  0.0494,  ...,  0.0522,  0.0113,  0.0193],
        [-0.0014, -0.0097,  0.0692,  ...,  0.0145, -0.0084, -0.0101],
        ...,
        [ 0.0220,  0.0271,  0.0096,  ...,  0.0834,  0.0188,  0.0034],
        [-0.0215, -0.0199, -0.0267,  ..., -0.0114,  0.0327, -0.0119],
        [ 0.0381,  0.0057,  0.0291,  ...,  0.0287, -0.0226,  0.0922]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.3545, -3.3184,  2.6543,  ...,  0.9688, -2.4336, -1.7529]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 08:56:31 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To declare results in declaration
To expire results in expiration
To allege results in allegation
To improvize results in improvization
To standardize results in standardization
To civilize results in civilization
To modernize results in modernization
To derive results in
2024-07-29 08:56:31 root INFO     [order_1_approx] starting weight calculation for To allege results in allegation
To modernize results in modernization
To standardize results in standardization
To improvize results in improvization
To derive results in derivation
To civilize results in civilization
To expire results in expiration
To declare results in
2024-07-29 08:56:31 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-29 08:58:53 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3645,  0.0903, -0.3792,  ..., -0.0413, -0.4543,  0.0191],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.3965, -5.2578,  4.6406,  ...,  1.8955, -3.0781,  1.0684],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0308, -0.0316, -0.0269,  ..., -0.0082, -0.0124,  0.0104],
        [ 0.0334,  0.0916,  0.0238,  ...,  0.0237,  0.0073,  0.0098],
        [-0.0037, -0.0370,  0.0255,  ...,  0.0004, -0.0247, -0.0281],
        ...,
        [ 0.0094,  0.0299, -0.0005,  ...,  0.0699, -0.0087,  0.0249],
        [-0.0059,  0.0177,  0.0100,  ...,  0.0160,  0.0596, -0.0074],
        [ 0.0266, -0.0084, -0.0113,  ..., -0.0059, -0.0258,  0.0530]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.0361, -4.0352,  3.6250,  ...,  1.5078, -3.0195,  0.3232]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 08:58:54 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To allege results in allegation
To modernize results in modernization
To standardize results in standardization
To improvize results in improvization
To derive results in derivation
To civilize results in civilization
To expire results in expiration
To declare results in
2024-07-29 08:58:54 root INFO     [order_1_approx] starting weight calculation for To expire results in expiration
To allege results in allegation
To improvize results in improvization
To declare results in declaration
To derive results in derivation
To modernize results in modernization
To standardize results in standardization
To civilize results in
2024-07-29 08:58:54 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-29 09:01:17 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4297,  0.4868, -0.7651,  ..., -0.3770, -0.2856,  0.0817],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.9443, -2.1230,  3.3164,  ...,  0.2871, -0.7153, -1.5039],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0369, -0.0094,  0.0111,  ..., -0.0157, -0.0059,  0.0150],
        [ 0.0059,  0.0384,  0.0134,  ...,  0.0154, -0.0052, -0.0020],
        [-0.0098, -0.0153,  0.0328,  ...,  0.0051, -0.0129,  0.0020],
        ...,
        [ 0.0075,  0.0015, -0.0128,  ...,  0.0499,  0.0100, -0.0097],
        [-0.0021,  0.0079, -0.0064,  ...,  0.0128,  0.0341, -0.0043],
        [ 0.0006, -0.0052,  0.0025,  ..., -0.0033, -0.0061,  0.0447]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-2.2383, -2.0645,  2.9355,  ...,  0.4385, -1.3066, -0.9570]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 09:01:18 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To expire results in expiration
To allege results in allegation
To improvize results in improvization
To declare results in declaration
To derive results in derivation
To modernize results in modernization
To standardize results in standardization
To civilize results in
2024-07-29 09:01:18 root INFO     [order_1_approx] starting weight calculation for To standardize results in standardization
To civilize results in civilization
To allege results in allegation
To expire results in expiration
To declare results in declaration
To derive results in derivation
To modernize results in modernization
To improvize results in
2024-07-29 09:01:18 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-29 09:03:41 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2812,  0.4910, -0.5244,  ..., -0.3618, -0.2439,  0.2913],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.2041, -2.3828,  1.4434,  ...,  3.0312, -1.5479, -2.1055],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0591, -0.0075, -0.0206,  ..., -0.0140, -0.0071,  0.0166],
        [ 0.0024,  0.0447,  0.0199,  ...,  0.0302, -0.0018,  0.0010],
        [-0.0121, -0.0044,  0.0440,  ...,  0.0145,  0.0140,  0.0067],
        ...,
        [ 0.0019,  0.0048,  0.0181,  ...,  0.0711,  0.0011, -0.0093],
        [ 0.0028,  0.0085, -0.0062,  ..., -0.0018,  0.0498, -0.0059],
        [ 0.0131, -0.0002,  0.0129,  ..., -0.0054, -0.0246,  0.0436]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.5483, -2.0391,  1.6299,  ...,  3.1641, -1.4258, -2.0684]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 09:03:42 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To standardize results in standardization
To civilize results in civilization
To allege results in allegation
To expire results in expiration
To declare results in declaration
To derive results in derivation
To modernize results in modernization
To improvize results in
2024-07-29 09:03:42 root INFO     [order_1_approx] starting weight calculation for To improvize results in improvization
To declare results in declaration
To derive results in derivation
To standardize results in standardization
To modernize results in modernization
To allege results in allegation
To civilize results in civilization
To expire results in
2024-07-29 09:03:42 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-29 09:06:04 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.3618,  0.0568, -0.9058,  ..., -0.2766, -0.2817, -0.1538],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.5449, -3.9219,  1.6855,  ..., -0.0073, -2.0195, -2.3848],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0384,  0.0053, -0.0038,  ..., -0.0105, -0.0026, -0.0121],
        [ 0.0076,  0.0510, -0.0043,  ...,  0.0238,  0.0089,  0.0273],
        [ 0.0050, -0.0013,  0.0294,  ...,  0.0099, -0.0184,  0.0102],
        ...,
        [ 0.0267,  0.0175,  0.0026,  ...,  0.0790, -0.0044,  0.0173],
        [ 0.0172, -0.0085,  0.0059,  ...,  0.0199,  0.0465,  0.0143],
        [ 0.0185, -0.0181,  0.0019,  ...,  0.0269, -0.0224,  0.0804]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.1123, -3.6270,  1.3408,  ..., -0.2617, -1.8389, -2.3242]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 09:06:05 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To improvize results in improvization
To declare results in declaration
To derive results in derivation
To standardize results in standardization
To modernize results in modernization
To allege results in allegation
To civilize results in civilization
To expire results in
2024-07-29 09:06:05 root INFO     total operator prediction time: 1148.7590878009796 seconds
2024-07-29 09:06:05 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on adj+ly_reg
2024-07-29 09:06:05 root INFO     building operator adj+ly_reg
2024-07-29 09:06:05 root INFO     [order_1_approx] starting weight calculation for The adjective form of immediate is immediately
The adjective form of serious is seriously
The adjective form of cultural is culturally
The adjective form of historical is historically
The adjective form of unique is uniquely
The adjective form of rare is rarely
The adjective form of environmental is environmentally
The adjective form of extensive is
2024-07-29 09:06:05 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-29 09:08:29 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2949,  0.0186, -0.5479,  ..., -0.3916, -0.3359,  0.1415],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.7070, -1.1436, -1.5283,  ..., -2.1445, -1.4531, -4.3281],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0654, -0.0260, -0.0167,  ...,  0.0171, -0.0017,  0.0196],
        [ 0.0080,  0.0877,  0.0118,  ...,  0.0038, -0.0052, -0.0005],
        [ 0.0248, -0.0371,  0.0403,  ...,  0.0037,  0.0141,  0.0232],
        ...,
        [ 0.0534, -0.0016,  0.0285,  ...,  0.0710,  0.0158, -0.0032],
        [-0.0011,  0.0222, -0.0063,  ..., -0.0013,  0.0451, -0.0112],
        [ 0.0157,  0.0345, -0.0003,  ..., -0.0037,  0.0061,  0.0194]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.5723, -1.7305, -1.3145,  ..., -2.0391, -0.9888, -4.3203]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 09:08:30 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The adjective form of immediate is immediately
The adjective form of serious is seriously
The adjective form of cultural is culturally
The adjective form of historical is historically
The adjective form of unique is uniquely
The adjective form of rare is rarely
The adjective form of environmental is environmentally
The adjective form of extensive is
2024-07-29 09:08:30 root INFO     [order_1_approx] starting weight calculation for The adjective form of environmental is environmentally
The adjective form of unique is uniquely
The adjective form of immediate is immediately
The adjective form of historical is historically
The adjective form of cultural is culturally
The adjective form of serious is seriously
The adjective form of extensive is extensively
The adjective form of rare is
2024-07-29 09:08:30 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-29 09:10:54 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1350, -0.0433, -0.4883,  ..., -0.2180,  0.1102, -0.0438],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-2.1211, -3.1602, -0.8267,  ..., -4.3867, -3.6914, -4.3867],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 6.4331e-02,  1.8425e-03,  1.7761e-02,  ...,  9.1076e-04,
          1.6754e-02,  2.5284e-02],
        [ 1.2703e-02,  6.5491e-02,  2.3041e-02,  ...,  2.5009e-02,
          2.5330e-02,  9.0714e-03],
        [ 1.3504e-02, -2.4445e-02,  5.4962e-02,  ..., -2.4433e-03,
          8.4457e-03,  1.7075e-02],
        ...,
        [ 3.6743e-02,  5.8044e-02, -5.3635e-03,  ...,  6.8481e-02,
          1.0857e-02, -8.0872e-03],
        [-8.9035e-03,  1.5610e-02,  1.1215e-02,  ..., -9.9030e-03,
          2.4475e-02, -1.8936e-02],
        [ 7.3471e-03,  3.7262e-02, -8.1253e-04,  ..., -2.9640e-03,
          3.0875e-05,  2.8748e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.9980, -3.5547, -0.7451,  ..., -4.5195, -3.5078, -4.5156]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 09:10:55 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The adjective form of environmental is environmentally
The adjective form of unique is uniquely
The adjective form of immediate is immediately
The adjective form of historical is historically
The adjective form of cultural is culturally
The adjective form of serious is seriously
The adjective form of extensive is extensively
The adjective form of rare is
2024-07-29 09:10:55 root INFO     [order_1_approx] starting weight calculation for The adjective form of cultural is culturally
The adjective form of serious is seriously
The adjective form of unique is uniquely
The adjective form of immediate is immediately
The adjective form of rare is rarely
The adjective form of extensive is extensively
The adjective form of environmental is environmentally
The adjective form of historical is
2024-07-29 09:10:55 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-29 09:13:19 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1938, -0.0406, -0.4355,  ..., -0.5679, -0.5342,  0.0840],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.5737, -1.5156,  0.9351,  ..., -3.4277, -2.8418, -2.1270],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0574, -0.0376, -0.0090,  ...,  0.0047, -0.0034,  0.0214],
        [ 0.0099,  0.0861,  0.0162,  ...,  0.0396,  0.0044, -0.0095],
        [ 0.0196, -0.0282,  0.0526,  ...,  0.0243, -0.0074,  0.0012],
        ...,
        [ 0.0291,  0.0310, -0.0168,  ...,  0.0470,  0.0189,  0.0100],
        [-0.0032,  0.0319, -0.0011,  ..., -0.0131,  0.0524, -0.0139],
        [ 0.0243,  0.0143, -0.0026,  ...,  0.0208, -0.0145,  0.0269]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.5879, -1.8125,  0.9292,  ..., -3.3848, -2.7070, -2.7012]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 09:13:20 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The adjective form of cultural is culturally
The adjective form of serious is seriously
The adjective form of unique is uniquely
The adjective form of immediate is immediately
The adjective form of rare is rarely
The adjective form of extensive is extensively
The adjective form of environmental is environmentally
The adjective form of historical is
2024-07-29 09:13:20 root INFO     [order_1_approx] starting weight calculation for The adjective form of cultural is culturally
The adjective form of extensive is extensively
The adjective form of environmental is environmentally
The adjective form of serious is seriously
The adjective form of immediate is immediately
The adjective form of rare is rarely
The adjective form of historical is historically
The adjective form of unique is
2024-07-29 09:13:20 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-29 09:15:44 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1198, -0.0699, -0.4827,  ..., -0.2236, -0.2639,  0.2747],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.3074, -1.8057,  0.9062,  ..., -2.5371, -2.9219, -1.6172],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0729, -0.0195,  0.0118,  ...,  0.0050,  0.0091,  0.0327],
        [ 0.0006,  0.0682, -0.0058,  ...,  0.0366,  0.0175,  0.0100],
        [-0.0097, -0.0168,  0.0575,  ..., -0.0043,  0.0082, -0.0081],
        ...,
        [ 0.0191,  0.0201,  0.0013,  ...,  0.0487,  0.0094,  0.0007],
        [ 0.0235,  0.0174,  0.0148,  ..., -0.0020,  0.0304, -0.0249],
        [ 0.0120, -0.0107, -0.0111,  ..., -0.0038, -0.0190,  0.0375]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.1689, -2.1211,  1.1660,  ..., -2.6348, -3.0410, -2.0156]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 09:15:44 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The adjective form of cultural is culturally
The adjective form of extensive is extensively
The adjective form of environmental is environmentally
The adjective form of serious is seriously
The adjective form of immediate is immediately
The adjective form of rare is rarely
The adjective form of historical is historically
The adjective form of unique is
2024-07-29 09:15:45 root INFO     [order_1_approx] starting weight calculation for The adjective form of extensive is extensively
The adjective form of historical is historically
The adjective form of cultural is culturally
The adjective form of rare is rarely
The adjective form of environmental is environmentally
The adjective form of unique is uniquely
The adjective form of immediate is immediately
The adjective form of serious is
2024-07-29 09:15:45 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-29 09:18:09 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2546, -0.0244, -0.5776,  ..., -0.1418, -0.7285,  0.2905],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.5869, -1.9844, -0.3318,  ..., -3.0195, -0.5415, -5.0273],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0881, -0.0263, -0.0016,  ...,  0.0193,  0.0224,  0.0121],
        [ 0.0103,  0.0505,  0.0121,  ...,  0.0123,  0.0061, -0.0103],
        [ 0.0058, -0.0082,  0.0549,  ...,  0.0097, -0.0004,  0.0120],
        ...,
        [ 0.0331,  0.0389,  0.0125,  ...,  0.0728,  0.0294,  0.0197],
        [-0.0298,  0.0291,  0.0036,  ..., -0.0062,  0.0592, -0.0161],
        [ 0.0281,  0.0019,  0.0195,  ...,  0.0135, -0.0180,  0.0458]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.3418, -1.8574, -0.3516,  ..., -2.7441, -0.4648, -4.9336]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 09:18:10 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The adjective form of extensive is extensively
The adjective form of historical is historically
The adjective form of cultural is culturally
The adjective form of rare is rarely
The adjective form of environmental is environmentally
The adjective form of unique is uniquely
The adjective form of immediate is immediately
The adjective form of serious is
2024-07-29 09:18:10 root INFO     [order_1_approx] starting weight calculation for The adjective form of environmental is environmentally
The adjective form of serious is seriously
The adjective form of rare is rarely
The adjective form of immediate is immediately
The adjective form of extensive is extensively
The adjective form of unique is uniquely
The adjective form of historical is historically
The adjective form of cultural is
2024-07-29 09:18:10 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-29 09:20:33 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4473,  0.0081, -0.3828,  ..., -0.5547, -0.7222,  0.1595],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.1030, -0.5430,  2.7266,  ..., -1.8027,  0.2832,  0.8066],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0626, -0.0231, -0.0031,  ...,  0.0161, -0.0060,  0.0132],
        [ 0.0035,  0.0845,  0.0394,  ...,  0.0284,  0.0176, -0.0003],
        [-0.0061, -0.0108,  0.0593,  ...,  0.0072, -0.0295,  0.0023],
        ...,
        [ 0.0255, -0.0008,  0.0019,  ...,  0.0602,  0.0218,  0.0155],
        [-0.0131,  0.0031, -0.0152,  ..., -0.0169,  0.0600, -0.0095],
        [ 0.0098, -0.0078,  0.0004,  ...,  0.0269,  0.0084,  0.0536]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.0806, -0.3682,  2.5566,  ..., -1.6572, -0.0708,  0.7939]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 09:20:34 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The adjective form of environmental is environmentally
The adjective form of serious is seriously
The adjective form of rare is rarely
The adjective form of immediate is immediately
The adjective form of extensive is extensively
The adjective form of unique is uniquely
The adjective form of historical is historically
The adjective form of cultural is
2024-07-29 09:20:34 root INFO     [order_1_approx] starting weight calculation for The adjective form of extensive is extensively
The adjective form of cultural is culturally
The adjective form of rare is rarely
The adjective form of environmental is environmentally
The adjective form of serious is seriously
The adjective form of unique is uniquely
The adjective form of historical is historically
The adjective form of immediate is
2024-07-29 09:20:34 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-29 09:22:56 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3828,  0.0160, -0.4844,  ..., -0.3650, -0.6948,  0.4744],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.0273, -2.0762, -1.2285,  ..., -1.6855, -1.7119, -4.5078],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0731, -0.0287,  0.0063,  ...,  0.0201, -0.0011,  0.0304],
        [ 0.0390,  0.0494,  0.0341,  ...,  0.0490, -0.0091,  0.0050],
        [ 0.0229, -0.0167,  0.0244,  ...,  0.0015,  0.0153,  0.0182],
        ...,
        [ 0.0191,  0.0530,  0.0124,  ...,  0.0764,  0.0079,  0.0130],
        [ 0.0102,  0.0300, -0.0068,  ...,  0.0101,  0.0489, -0.0200],
        [ 0.0033,  0.0135,  0.0139,  ..., -0.0200, -0.0220,  0.0468]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.9473, -2.6816, -1.2979,  ..., -1.4766, -1.4648, -4.6211]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 09:22:58 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The adjective form of extensive is extensively
The adjective form of cultural is culturally
The adjective form of rare is rarely
The adjective form of environmental is environmentally
The adjective form of serious is seriously
The adjective form of unique is uniquely
The adjective form of historical is historically
The adjective form of immediate is
2024-07-29 09:22:58 root INFO     [order_1_approx] starting weight calculation for The adjective form of serious is seriously
The adjective form of extensive is extensively
The adjective form of historical is historically
The adjective form of immediate is immediately
The adjective form of cultural is culturally
The adjective form of unique is uniquely
The adjective form of rare is rarely
The adjective form of environmental is
2024-07-29 09:22:58 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-29 09:25:20 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4067, -0.2075, -0.3047,  ..., -0.3391, -0.6167, -0.0269],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.4224, -0.2588, -0.1836,  ..., -2.6914, -1.9092, -3.5723],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0254, -0.0056,  0.0071,  ..., -0.0107, -0.0004,  0.0182],
        [ 0.0005,  0.0739,  0.0237,  ...,  0.0294, -0.0292, -0.0191],
        [-0.0009,  0.0121,  0.0566,  ...,  0.0266, -0.0001,  0.0075],
        ...,
        [ 0.0150,  0.0325, -0.0288,  ...,  0.0261,  0.0082,  0.0085],
        [ 0.0049,  0.0056, -0.0360,  ..., -0.0353,  0.0678, -0.0236],
        [ 0.0152,  0.0045,  0.0023,  ...,  0.0373, -0.0357,  0.0417]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.4348, -0.4932, -0.4021,  ..., -2.4863, -2.2461, -3.7559]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 09:25:21 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The adjective form of serious is seriously
The adjective form of extensive is extensively
The adjective form of historical is historically
The adjective form of immediate is immediately
The adjective form of cultural is culturally
The adjective form of unique is uniquely
The adjective form of rare is rarely
The adjective form of environmental is
2024-07-29 09:25:21 root INFO     total operator prediction time: 1156.064171075821 seconds
2024-07-29 09:25:21 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on over+adj_reg
2024-07-29 09:25:21 root INFO     building operator over+adj_reg
2024-07-29 09:25:21 root INFO     [order_1_approx] starting weight calculation for If something is too subscribed, it is oversubscribed
If something is too grown, it is overgrown
If something is too shadowed, it is overshadowed
If something is too filled, it is overfilled
If something is too spent, it is overspent
If something is too protective, it is overprotective
If something is too saturated, it is oversaturated
If something is too confident, it is
2024-07-29 09:25:21 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
2024-07-29 09:27:44 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0353,  0.2269, -0.4604,  ...,  0.3569, -0.3291, -0.0319],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.6670, -4.2031,  2.1992,  ...,  1.8926, -1.8047, -0.6475],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0573, -0.0028, -0.0043,  ...,  0.0019,  0.0032,  0.0103],
        [ 0.0094,  0.0395,  0.0086,  ..., -0.0030,  0.0028,  0.0051],
        [ 0.0016,  0.0016,  0.0492,  ..., -0.0025,  0.0036,  0.0141],
        ...,
        [ 0.0110,  0.0084,  0.0017,  ...,  0.0575,  0.0059,  0.0074],
        [ 0.0079,  0.0098,  0.0242,  ..., -0.0017,  0.0378, -0.0201],
        [ 0.0002, -0.0042,  0.0040,  ...,  0.0060, -0.0004,  0.0312]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.9756, -4.1719,  1.8857,  ...,  1.9941, -1.7002, -0.5801]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 09:27:45 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is too subscribed, it is oversubscribed
If something is too grown, it is overgrown
If something is too shadowed, it is overshadowed
If something is too filled, it is overfilled
If something is too spent, it is overspent
If something is too protective, it is overprotective
If something is too saturated, it is oversaturated
If something is too confident, it is
2024-07-29 09:27:46 root INFO     [order_1_approx] starting weight calculation for If something is too grown, it is overgrown
If something is too shadowed, it is overshadowed
If something is too saturated, it is oversaturated
If something is too filled, it is overfilled
If something is too subscribed, it is oversubscribed
If something is too confident, it is overconfident
If something is too spent, it is overspent
If something is too protective, it is
2024-07-29 09:27:46 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.11
