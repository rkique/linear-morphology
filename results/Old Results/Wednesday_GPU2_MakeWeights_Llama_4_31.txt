2024-07-31 17:11:32 root INFO     loading model + tokenizer
2024-07-31 17:11:35 root INFO     model + tokenizer loaded
2024-07-31 17:11:35 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on meronyms - part
2024-07-31 17:11:35 root INFO     building operator meronyms - part
2024-07-31 17:11:36 root INFO     [order_1_approx] starting weight calculation for A part of a orthography is a hyphenation
A part of a harbor is a dock
A part of a tripod is a leg
A part of a shirt is a button
A part of a dollar is a cent
A part of a door is a hinge
A part of a poem is a stanza
A part of a jail is a
2024-07-31 17:11:36 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-07-31 17:14:41 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0963,  0.1798, -0.0699,  ..., -0.0002, -0.0931,  0.0187],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.8887, -5.2891,  0.6602,  ...,  1.2656, -0.1826,  1.3828],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0267, -0.0154, -0.0080,  ...,  0.0131,  0.0434, -0.0158],
        [ 0.0212, -0.0068,  0.0015,  ...,  0.0219,  0.0046, -0.0072],
        [ 0.0043, -0.0079,  0.0396,  ..., -0.0191, -0.0263,  0.0186],
        ...,
        [ 0.0259,  0.0125,  0.0817,  ..., -0.0091,  0.0151, -0.0304],
        [-0.0208,  0.0011, -0.0238,  ..., -0.0252,  0.0020,  0.0476],
        [ 0.0060,  0.0065,  0.0050,  ..., -0.0359,  0.0030,  0.0038]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.7783, -5.0547,  0.6831,  ...,  1.8770, -0.0718,  1.4990]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 17:14:42 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A part of a orthography is a hyphenation
A part of a harbor is a dock
A part of a tripod is a leg
A part of a shirt is a button
A part of a dollar is a cent
A part of a door is a hinge
A part of a poem is a stanza
A part of a jail is a
2024-07-31 17:14:42 root INFO     [order_1_approx] starting weight calculation for A part of a door is a hinge
A part of a tripod is a leg
A part of a dollar is a cent
A part of a jail is a cell
A part of a shirt is a button
A part of a poem is a stanza
A part of a orthography is a hyphenation
A part of a harbor is a
2024-07-31 17:14:42 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-07-31 17:17:45 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1582,  0.0359, -0.0994,  ..., -0.0824,  0.0505,  0.0096],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.4106, -6.7734,  1.1484,  ...,  2.5195, -1.9111,  1.7168],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 2.5024e-02, -2.2583e-03,  5.9433e-03,  ..., -2.2068e-03,
         -3.0350e-02, -1.6739e-02],
        [-1.2238e-02, -1.2955e-02, -2.2552e-02,  ...,  4.7302e-04,
         -3.4332e-03, -2.4368e-02],
        [-2.3098e-03,  3.3997e-02,  3.0869e-02,  ..., -2.3682e-02,
         -3.8223e-03,  2.4109e-02],
        ...,
        [-1.1505e-02, -5.8990e-02,  4.8180e-03,  ...,  1.7517e-02,
         -1.0849e-02, -6.0234e-03],
        [-3.2902e-03,  1.2749e-02, -3.3020e-02,  ..., -2.9221e-02,
         -1.1864e-02, -1.4320e-02],
        [-2.1622e-02, -9.4070e-03, -8.3923e-05,  ...,  3.2257e-02,
         -2.3849e-02,  8.9874e-03]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.4446, -6.3203,  1.3145,  ...,  2.9883, -1.9902,  1.8408]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 17:17:46 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A part of a door is a hinge
A part of a tripod is a leg
A part of a dollar is a cent
A part of a jail is a cell
A part of a shirt is a button
A part of a poem is a stanza
A part of a orthography is a hyphenation
A part of a harbor is a
2024-07-31 17:17:46 root INFO     [order_1_approx] starting weight calculation for A part of a dollar is a cent
A part of a harbor is a dock
A part of a tripod is a leg
A part of a shirt is a button
A part of a poem is a stanza
A part of a door is a hinge
A part of a jail is a cell
A part of a orthography is a
2024-07-31 17:17:46 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-07-31 17:20:52 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1289,  0.1074,  0.1182,  ..., -0.0677,  0.1221, -0.0931],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.7075, -2.5117,  1.1289,  ...,  3.1367, -1.2793, -1.2373],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0405, -0.0236, -0.0082,  ..., -0.0189,  0.0337, -0.0093],
        [ 0.0750,  0.0319, -0.0130,  ...,  0.0054, -0.0189, -0.0084],
        [-0.0052,  0.0018, -0.0017,  ...,  0.0015,  0.0250, -0.0015],
        ...,
        [ 0.0804,  0.0151,  0.0617,  ...,  0.0234, -0.0330, -0.0137],
        [-0.0093, -0.0089, -0.0400,  ...,  0.0252,  0.0040,  0.0204],
        [ 0.0114,  0.0006,  0.0103,  ..., -0.0099, -0.0329, -0.0040]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.6763, -2.3809,  0.7734,  ...,  2.9629, -1.4102, -1.0645]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 17:20:53 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A part of a dollar is a cent
A part of a harbor is a dock
A part of a tripod is a leg
A part of a shirt is a button
A part of a poem is a stanza
A part of a door is a hinge
A part of a jail is a cell
A part of a orthography is a
2024-07-31 17:20:53 root INFO     [order_1_approx] starting weight calculation for A part of a jail is a cell
A part of a tripod is a leg
A part of a dollar is a cent
A part of a orthography is a hyphenation
A part of a door is a hinge
A part of a harbor is a dock
A part of a shirt is a button
A part of a poem is a
2024-07-31 17:20:53 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-07-31 17:23:56 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1068,  0.1793, -0.0632,  ...,  0.0383, -0.1039, -0.0030],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.0078, -4.8906,  4.5430,  ...,  6.6172, -1.1748, -2.3008],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0409, -0.0248,  0.0069,  ...,  0.0025,  0.0184, -0.0057],
        [-0.0290, -0.0212,  0.0129,  ..., -0.0067,  0.0066,  0.0108],
        [-0.0035,  0.0170,  0.0323,  ..., -0.0167, -0.0007, -0.0018],
        ...,
        [-0.0013, -0.0024,  0.0234,  ...,  0.0115, -0.0010,  0.0224],
        [ 0.0118,  0.0263, -0.0214,  ..., -0.0086,  0.0106, -0.0033],
        [-0.0237, -0.0068,  0.0016,  ..., -0.0018, -0.0084,  0.0227]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.1777, -4.1484,  4.3164,  ...,  6.7266, -1.7773, -1.6973]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 17:23:57 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A part of a jail is a cell
A part of a tripod is a leg
A part of a dollar is a cent
A part of a orthography is a hyphenation
A part of a door is a hinge
A part of a harbor is a dock
A part of a shirt is a button
A part of a poem is a
2024-07-31 17:23:57 root INFO     [order_1_approx] starting weight calculation for A part of a orthography is a hyphenation
A part of a shirt is a button
A part of a jail is a cell
A part of a harbor is a dock
A part of a poem is a stanza
A part of a tripod is a leg
A part of a dollar is a cent
A part of a door is a
2024-07-31 17:23:57 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-07-31 17:26:55 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0421, -0.0227, -0.1438,  ..., -0.1851, -0.0774, -0.1274],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.9810, -2.7227,  1.0459,  ...,  1.2246, -0.9375,  0.2104],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0124, -0.0192,  0.0080,  ...,  0.0156,  0.0132, -0.0657],
        [-0.0160,  0.0083, -0.0204,  ..., -0.0189,  0.0131, -0.0224],
        [ 0.0328,  0.0131, -0.0024,  ...,  0.0264, -0.0345,  0.0303],
        ...,
        [ 0.0183,  0.0055,  0.0269,  ...,  0.0046,  0.0067,  0.0040],
        [ 0.0056,  0.0159, -0.0012,  ..., -0.0162,  0.0161,  0.0165],
        [ 0.0273, -0.0002,  0.0041,  ..., -0.0002, -0.0137, -0.0099]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.3564, -1.8262,  0.7061,  ...,  1.0850, -0.7734,  0.5488]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 17:26:56 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A part of a orthography is a hyphenation
A part of a shirt is a button
A part of a jail is a cell
A part of a harbor is a dock
A part of a poem is a stanza
A part of a tripod is a leg
A part of a dollar is a cent
A part of a door is a
2024-07-31 17:26:57 root INFO     [order_1_approx] starting weight calculation for A part of a orthography is a hyphenation
A part of a poem is a stanza
A part of a dollar is a cent
A part of a tripod is a leg
A part of a door is a hinge
A part of a harbor is a dock
A part of a jail is a cell
A part of a shirt is a
2024-07-31 17:26:57 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-07-31 17:29:57 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0917, -0.1327, -0.0649,  ...,  0.1353, -0.1655,  0.0151],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.8896, -1.9277, -0.2422,  ...,  1.3730,  3.7461,  1.6709],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0054, -0.0135, -0.0160,  ...,  0.0031,  0.0453, -0.0269],
        [ 0.0136,  0.0038, -0.0184,  ...,  0.0222, -0.0048,  0.0145],
        [ 0.0056, -0.0150,  0.0102,  ...,  0.0084, -0.0144,  0.0060],
        ...,
        [ 0.0227,  0.0150,  0.0235,  ...,  0.0041,  0.0187, -0.0217],
        [ 0.0341, -0.0152, -0.0042,  ..., -0.0651,  0.0339, -0.0014],
        [-0.0295, -0.0097, -0.0047,  ...,  0.0225, -0.0188,  0.0102]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.5176, -1.7227, -0.0314,  ...,  1.3408,  4.5039,  1.7549]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 17:29:58 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A part of a orthography is a hyphenation
A part of a poem is a stanza
A part of a dollar is a cent
A part of a tripod is a leg
A part of a door is a hinge
A part of a harbor is a dock
A part of a jail is a cell
A part of a shirt is a
2024-07-31 17:29:59 root INFO     [order_1_approx] starting weight calculation for A part of a tripod is a leg
A part of a door is a hinge
A part of a orthography is a hyphenation
A part of a shirt is a button
A part of a harbor is a dock
A part of a jail is a cell
A part of a poem is a stanza
A part of a dollar is a
2024-07-31 17:29:59 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-07-31 17:33:05 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0372,  0.0101, -0.0160,  ..., -0.0302, -0.0742,  0.0364],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.1562, -0.9307, -0.6338,  ..., -0.2842,  0.8364, -0.7212],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0575, -0.0042, -0.0230,  ..., -0.0267, -0.0493,  0.0871],
        [ 0.0164,  0.0009, -0.0079,  ...,  0.0197,  0.0235, -0.0285],
        [ 0.0005,  0.0028,  0.0692,  ...,  0.0184,  0.0507, -0.0335],
        ...,
        [-0.0278, -0.0382, -0.0300,  ...,  0.0957,  0.0226, -0.0390],
        [-0.0049,  0.0244,  0.0101,  ...,  0.0100,  0.0281, -0.0217],
        [ 0.0067, -0.0143, -0.0331,  ...,  0.0433,  0.0080, -0.0038]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.9194, -0.8926, -0.9521,  ...,  0.0518,  0.6704, -1.1768]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 17:33:06 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A part of a tripod is a leg
A part of a door is a hinge
A part of a orthography is a hyphenation
A part of a shirt is a button
A part of a harbor is a dock
A part of a jail is a cell
A part of a poem is a stanza
A part of a dollar is a
2024-07-31 17:33:06 root INFO     [order_1_approx] starting weight calculation for A part of a shirt is a button
A part of a door is a hinge
A part of a poem is a stanza
A part of a harbor is a dock
A part of a dollar is a cent
A part of a jail is a cell
A part of a orthography is a hyphenation
A part of a tripod is a
2024-07-31 17:33:06 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-07-31 17:36:08 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1385, -0.0051,  0.0708,  ..., -0.0698,  0.0886, -0.0667],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.1240, -5.2422,  0.1787,  ...,  0.8330, -3.5664, -1.2363],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0311, -0.0311, -0.0274,  ...,  0.0770,  0.0392, -0.0920],
        [ 0.0904, -0.0295, -0.0298,  ..., -0.0881, -0.0616,  0.0606],
        [-0.0055,  0.0540,  0.0126,  ..., -0.0834, -0.0432, -0.0191],
        ...,
        [-0.0133, -0.0262, -0.0070,  ...,  0.0963,  0.0085, -0.0213],
        [ 0.0113,  0.0298, -0.0418,  ...,  0.0893,  0.0166, -0.0129],
        [ 0.0074, -0.0672,  0.0403,  ..., -0.0045, -0.0035, -0.0369]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.7178, -5.1211,  0.2803,  ...,  0.8530, -4.1289, -1.0625]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 17:36:09 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A part of a shirt is a button
A part of a door is a hinge
A part of a poem is a stanza
A part of a harbor is a dock
A part of a dollar is a cent
A part of a jail is a cell
A part of a orthography is a hyphenation
A part of a tripod is a
2024-07-31 17:36:09 root INFO     total operator prediction time: 1473.791247844696 seconds
2024-07-31 17:36:09 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on synonyms - exact
2024-07-31 17:36:09 root INFO     building operator synonyms - exact
2024-07-31 17:36:09 root INFO     [order_1_approx] starting weight calculation for Another word for railway is railroad
Another word for spouse is partner
Another word for baby is infant
Another word for reasonable is sensible
Another word for father is dad
Another word for help is aid
Another word for mesh is gauze
Another word for snake is
2024-07-31 17:36:09 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-07-31 17:39:11 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1211,  0.1259, -0.0525,  ..., -0.0360, -0.0924,  0.0143],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.0967, -5.9883,  2.5898,  ..., -0.6016, -1.6338, -0.3748],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0438,  0.0057, -0.0061,  ..., -0.0369,  0.0013,  0.0272],
        [ 0.0464, -0.0197,  0.0430,  ...,  0.0058, -0.0153,  0.0003],
        [-0.0281,  0.0465,  0.0696,  ..., -0.0425, -0.0454,  0.0054],
        ...,
        [ 0.0475,  0.0256, -0.0299,  ...,  0.0497, -0.0234, -0.0377],
        [-0.0137, -0.0165, -0.0115,  ..., -0.0340,  0.0332,  0.0427],
        [ 0.0249, -0.0112,  0.0063,  ...,  0.0542, -0.0011, -0.0080]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.8647, -5.9023,  1.8809,  ..., -0.8359, -1.7949, -0.6875]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 17:39:12 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Another word for railway is railroad
Another word for spouse is partner
Another word for baby is infant
Another word for reasonable is sensible
Another word for father is dad
Another word for help is aid
Another word for mesh is gauze
Another word for snake is
2024-07-31 17:39:12 root INFO     [order_1_approx] starting weight calculation for Another word for father is dad
Another word for help is aid
Another word for baby is infant
Another word for snake is serpent
Another word for reasonable is sensible
Another word for mesh is gauze
Another word for spouse is partner
Another word for railway is
2024-07-31 17:39:12 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-07-31 17:42:18 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0412,  0.1599,  0.0758,  ..., -0.1251,  0.1422, -0.0642],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.0615, -5.5078,  3.4590,  ...,  2.4102, -0.9834, -2.6191],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0649, -0.0891,  0.0240,  ..., -0.0281,  0.0306,  0.1464],
        [-0.0008,  0.0235,  0.0277,  ..., -0.0113,  0.0361, -0.0324],
        [ 0.0073,  0.0131,  0.0065,  ...,  0.0168, -0.0409,  0.0130],
        ...,
        [ 0.0379, -0.0119, -0.0076,  ..., -0.0038,  0.0085, -0.0741],
        [-0.0372,  0.0284,  0.0028,  ...,  0.0322,  0.0333,  0.0079],
        [ 0.0108,  0.0345,  0.0813,  ..., -0.0458,  0.0338, -0.0311]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.2012, -5.4141,  3.5273,  ...,  1.9785, -0.6606, -1.9766]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 17:42:19 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Another word for father is dad
Another word for help is aid
Another word for baby is infant
Another word for snake is serpent
Another word for reasonable is sensible
Another word for mesh is gauze
Another word for spouse is partner
Another word for railway is
2024-07-31 17:42:20 root INFO     [order_1_approx] starting weight calculation for Another word for snake is serpent
Another word for railway is railroad
Another word for baby is infant
Another word for help is aid
Another word for reasonable is sensible
Another word for father is dad
Another word for spouse is partner
Another word for mesh is
2024-07-31 17:42:20 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-07-31 17:45:21 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1364,  0.1042,  0.0192,  ...,  0.1512, -0.2284, -0.1136],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.3857, -1.5918,  1.9053,  ...,  0.9595, -2.8164,  1.4590],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0712, -0.0083,  0.0151,  ..., -0.0118,  0.0225,  0.0452],
        [-0.0318,  0.0073,  0.0285,  ...,  0.0283,  0.0079, -0.0029],
        [-0.0133,  0.0182,  0.0314,  ...,  0.0133, -0.0532, -0.0573],
        ...,
        [ 0.0085,  0.0085,  0.0275,  ...,  0.0955, -0.0468,  0.0287],
        [ 0.0238, -0.0074, -0.0228,  ...,  0.0015, -0.0151, -0.0407],
        [-0.0324, -0.0182, -0.0654,  ..., -0.0576,  0.0206,  0.0332]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.2480, -1.2363,  1.0430,  ...,  1.0010, -2.5156,  1.2275]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 17:45:21 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Another word for snake is serpent
Another word for railway is railroad
Another word for baby is infant
Another word for help is aid
Another word for reasonable is sensible
Another word for father is dad
Another word for spouse is partner
Another word for mesh is
2024-07-31 17:45:22 root INFO     [order_1_approx] starting weight calculation for Another word for snake is serpent
Another word for mesh is gauze
Another word for spouse is partner
Another word for baby is infant
Another word for help is aid
Another word for reasonable is sensible
Another word for railway is railroad
Another word for father is
2024-07-31 17:45:22 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-07-31 17:48:26 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1606, -0.1105, -0.1005,  ..., -0.0206, -0.0871, -0.1594],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.5127, -2.3438, -0.0757,  ...,  0.6914, -2.6855, -2.0781],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0778,  0.0301, -0.0518,  ..., -0.0241,  0.0394, -0.0032],
        [ 0.0092,  0.0019,  0.0242,  ..., -0.0189,  0.0568,  0.0276],
        [-0.0300, -0.0212,  0.0134,  ...,  0.0234,  0.0128, -0.0030],
        ...,
        [-0.0167, -0.0244,  0.0069,  ...,  0.0388, -0.0475,  0.0009],
        [ 0.0373,  0.0207, -0.0604,  ..., -0.0334,  0.0215, -0.0324],
        [ 0.0378,  0.0271, -0.0328,  ..., -0.0253,  0.0049, -0.0323]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.9131, -2.3984,  0.8066,  ..., -0.0024, -2.2773, -1.7793]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 17:48:27 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Another word for snake is serpent
Another word for mesh is gauze
Another word for spouse is partner
Another word for baby is infant
Another word for help is aid
Another word for reasonable is sensible
Another word for railway is railroad
Another word for father is
2024-07-31 17:48:27 root INFO     [order_1_approx] starting weight calculation for Another word for help is aid
Another word for baby is infant
Another word for snake is serpent
Another word for father is dad
Another word for railway is railroad
Another word for mesh is gauze
Another word for spouse is partner
Another word for reasonable is
2024-07-31 17:48:27 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-07-31 17:51:30 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0773,  0.1443, -0.1388,  ..., -0.0511, -0.1427,  0.0607],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.3086,  1.3379, -1.5566,  ..., -3.9570, -8.8906, -1.1309],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0988, -0.0706,  0.0289,  ..., -0.0539,  0.0241,  0.0196],
        [-0.0945,  0.0308,  0.0250,  ...,  0.0944, -0.0090,  0.0538],
        [ 0.0789,  0.0068,  0.0207,  ..., -0.0367,  0.0280, -0.0215],
        ...,
        [ 0.0422, -0.0540,  0.0293,  ..., -0.0248,  0.0607, -0.0082],
        [ 0.0190,  0.0130,  0.0610,  ..., -0.0858,  0.0390, -0.0458],
        [-0.0372, -0.0286,  0.0465,  ...,  0.0567, -0.0223, -0.0092]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.4844,  1.4844, -1.2363,  ..., -3.3711, -8.9766, -0.9521]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 17:51:31 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Another word for help is aid
Another word for baby is infant
Another word for snake is serpent
Another word for father is dad
Another word for railway is railroad
Another word for mesh is gauze
Another word for spouse is partner
Another word for reasonable is
2024-07-31 17:51:31 root INFO     [order_1_approx] starting weight calculation for Another word for snake is serpent
Another word for railway is railroad
Another word for help is aid
Another word for reasonable is sensible
Another word for mesh is gauze
Another word for father is dad
Another word for spouse is partner
Another word for baby is
2024-07-31 17:51:31 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-07-31 17:54:37 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0495, -0.1166,  0.0492,  ..., -0.0264, -0.3279, -0.0348],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.2793, -4.8984, -1.5693,  ..., -0.5088, -3.2305,  2.1094],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0792,  0.0125, -0.0068,  ..., -0.0721,  0.0623, -0.0285],
        [ 0.0204,  0.0001,  0.0529,  ...,  0.0081, -0.0149,  0.0330],
        [ 0.0237, -0.0240, -0.0009,  ..., -0.0695,  0.0273, -0.0074],
        ...,
        [ 0.0166, -0.0031,  0.0154,  ...,  0.0195, -0.0164, -0.0077],
        [-0.0130,  0.0086, -0.0248,  ...,  0.0110,  0.0054, -0.0539],
        [ 0.0490, -0.0023,  0.0247,  ..., -0.0345,  0.0080,  0.0267]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.9336, -5.2930, -0.8096,  ..., -1.1289, -2.5742,  1.4102]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 17:54:38 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Another word for snake is serpent
Another word for railway is railroad
Another word for help is aid
Another word for reasonable is sensible
Another word for mesh is gauze
Another word for father is dad
Another word for spouse is partner
Another word for baby is
2024-07-31 17:54:38 root INFO     [order_1_approx] starting weight calculation for Another word for baby is infant
Another word for railway is railroad
Another word for reasonable is sensible
Another word for snake is serpent
Another word for help is aid
Another word for father is dad
Another word for mesh is gauze
Another word for spouse is
2024-07-31 17:54:38 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-07-31 17:57:38 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0442,  0.1633,  0.0004,  ...,  0.1440, -0.0087, -0.0382],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.5420, -1.5342,  1.8789,  ...,  1.1836, -0.8506,  1.8438],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0646,  0.0028,  0.0090,  ..., -0.0265, -0.0320,  0.0055],
        [-0.0329,  0.0276,  0.0687,  ...,  0.0028,  0.0270,  0.0220],
        [ 0.0302, -0.0100,  0.0843,  ..., -0.0654,  0.0221, -0.0327],
        ...,
        [-0.0094,  0.0471,  0.0089,  ...,  0.0115,  0.0022,  0.0332],
        [ 0.0243,  0.0032,  0.0471,  ..., -0.0259,  0.0013, -0.0104],
        [-0.0038,  0.0414, -0.0343,  ..., -0.0085,  0.0125, -0.0041]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.5264, -1.7461,  2.3789,  ...,  1.6113, -0.8467,  1.8760]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 17:57:39 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Another word for baby is infant
Another word for railway is railroad
Another word for reasonable is sensible
Another word for snake is serpent
Another word for help is aid
Another word for father is dad
Another word for mesh is gauze
Another word for spouse is
2024-07-31 17:57:39 root INFO     [order_1_approx] starting weight calculation for Another word for reasonable is sensible
Another word for baby is infant
Another word for snake is serpent
Another word for railway is railroad
Another word for mesh is gauze
Another word for spouse is partner
Another word for father is dad
Another word for help is
2024-07-31 17:57:39 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-07-31 18:00:45 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1395, -0.0640,  0.0319,  ...,  0.0676, -0.1085, -0.0572],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 5.5430, -6.7344,  1.6680,  ...,  2.3320, -3.4551, -1.2402],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0192, -0.0085, -0.0145,  ...,  0.0508, -0.0008,  0.0102],
        [-0.0045,  0.0080,  0.0168,  ...,  0.0243,  0.0214,  0.0186],
        [ 0.0264, -0.0272, -0.0068,  ..., -0.0148, -0.0313,  0.0022],
        ...,
        [-0.0176,  0.0049,  0.0055,  ...,  0.0063, -0.0243, -0.0030],
        [ 0.0203, -0.0172,  0.0018,  ..., -0.0344, -0.0316, -0.0042],
        [ 0.0276,  0.0060,  0.0027,  ...,  0.0225,  0.0147,  0.0207]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 5.7070, -6.4375,  1.7578,  ...,  2.3965, -3.7852, -0.7910]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 18:00:46 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Another word for reasonable is sensible
Another word for baby is infant
Another word for snake is serpent
Another word for railway is railroad
Another word for mesh is gauze
Another word for spouse is partner
Another word for father is dad
Another word for help is
2024-07-31 18:00:46 root INFO     total operator prediction time: 1476.592383146286 seconds
2024-07-31 18:00:46 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on hypernyms - misc
2024-07-31 18:00:46 root INFO     building operator hypernyms - misc
2024-07-31 18:00:46 root INFO     [order_1_approx] starting weight calculation for The plum falls into the category of fruit
The cake falls into the category of dessert
The tub falls into the category of container
The denim falls into the category of fabric
The shirt falls into the category of clothes
The shelf falls into the category of furniture
The stapler falls into the category of device
The brooch falls into the category of
2024-07-31 18:00:46 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-07-31 18:03:51 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0762,  0.1538, -0.0947,  ...,  0.2180,  0.1160, -0.0791],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.1172, -7.4062, -3.1211,  ..., -0.8701, -5.5312,  2.1797],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0479, -0.0241,  0.0022,  ...,  0.0061,  0.0136,  0.0189],
        [-0.0236,  0.0574, -0.0006,  ...,  0.0181, -0.0486, -0.0329],
        [-0.0154, -0.0411, -0.0206,  ..., -0.0047, -0.0339,  0.0168],
        ...,
        [ 0.0001, -0.0175,  0.0066,  ...,  0.0124, -0.0323, -0.0435],
        [-0.0435,  0.0066, -0.0050,  ...,  0.0143, -0.0006, -0.0021],
        [ 0.0127,  0.0112, -0.0237,  ...,  0.0023,  0.0137,  0.0127]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.9395, -6.9805, -2.9805,  ..., -0.9741, -6.0000,  2.3887]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 18:03:52 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plum falls into the category of fruit
The cake falls into the category of dessert
The tub falls into the category of container
The denim falls into the category of fabric
The shirt falls into the category of clothes
The shelf falls into the category of furniture
The stapler falls into the category of device
The brooch falls into the category of
2024-07-31 18:03:53 root INFO     [order_1_approx] starting weight calculation for The denim falls into the category of fabric
The stapler falls into the category of device
The shelf falls into the category of furniture
The brooch falls into the category of jewelry
The shirt falls into the category of clothes
The plum falls into the category of fruit
The tub falls into the category of container
The cake falls into the category of
2024-07-31 18:03:53 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-07-31 18:06:54 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0455,  0.1102, -0.0892,  ...,  0.0646, -0.1393, -0.0381],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.6484, -5.6367,  0.5820,  ..., -3.7598, -4.0703,  0.3672],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0028, -0.0088, -0.0482,  ..., -0.0148,  0.0262,  0.0034],
        [ 0.0269,  0.0246, -0.0081,  ..., -0.0273, -0.0503,  0.0609],
        [-0.0047, -0.0168,  0.0071,  ..., -0.0103, -0.0167,  0.0049],
        ...,
        [ 0.0175,  0.0212, -0.0051,  ...,  0.0110, -0.0128,  0.0246],
        [-0.0058,  0.0014, -0.0084,  ..., -0.0294,  0.0099, -0.0022],
        [ 0.0244,  0.0145,  0.0062,  ..., -0.0087,  0.0121,  0.0048]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.3125, -5.0273,  0.5576,  ..., -3.9258, -4.0586,  0.3364]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 18:06:55 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The denim falls into the category of fabric
The stapler falls into the category of device
The shelf falls into the category of furniture
The brooch falls into the category of jewelry
The shirt falls into the category of clothes
The plum falls into the category of fruit
The tub falls into the category of container
The cake falls into the category of
2024-07-31 18:06:56 root INFO     [order_1_approx] starting weight calculation for The tub falls into the category of container
The shelf falls into the category of furniture
The plum falls into the category of fruit
The cake falls into the category of dessert
The stapler falls into the category of device
The denim falls into the category of fabric
The brooch falls into the category of jewelry
The shirt falls into the category of
2024-07-31 18:06:56 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-07-31 18:09:59 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0511, -0.1213, -0.1345,  ...,  0.1699, -0.1470, -0.0043],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.5059, -5.5469, -0.3748,  ...,  0.7046, -3.0352, -0.0947],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0056,  0.0053, -0.0018,  ..., -0.0218, -0.0043,  0.0128],
        [ 0.0021, -0.0181, -0.0276,  ...,  0.0092, -0.0039,  0.0243],
        [ 0.0036,  0.0159,  0.0468,  ..., -0.0112, -0.0175, -0.0205],
        ...,
        [ 0.0294, -0.0185, -0.0097,  ..., -0.0026, -0.0088, -0.0203],
        [-0.0151, -0.0212, -0.0014,  ..., -0.0034,  0.0060,  0.0210],
        [ 0.0060, -0.0204,  0.0162,  ...,  0.0300,  0.0224,  0.0255]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.2305, -5.1133, -0.1859,  ...,  0.8105, -3.0234,  0.1416]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 18:10:00 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The tub falls into the category of container
The shelf falls into the category of furniture
The plum falls into the category of fruit
The cake falls into the category of dessert
The stapler falls into the category of device
The denim falls into the category of fabric
The brooch falls into the category of jewelry
The shirt falls into the category of
2024-07-31 18:10:00 root INFO     [order_1_approx] starting weight calculation for The cake falls into the category of dessert
The denim falls into the category of fabric
The plum falls into the category of fruit
The brooch falls into the category of jewelry
The stapler falls into the category of device
The shirt falls into the category of clothes
The tub falls into the category of container
The shelf falls into the category of
2024-07-31 18:10:00 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-07-31 18:13:04 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1685, -0.0931, -0.1934,  ...,  0.0889, -0.0396, -0.0556],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.8906, -2.2734,  4.0898,  ..., -0.7822, -4.3594,  0.8252],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0435,  0.0102, -0.0661,  ...,  0.0431, -0.0191, -0.0256],
        [-0.0073, -0.0201,  0.0038,  ..., -0.0144,  0.0013,  0.0265],
        [ 0.0184, -0.0021,  0.0086,  ..., -0.0175, -0.0018, -0.0228],
        ...,
        [-0.0079,  0.0035,  0.0193,  ..., -0.0258,  0.0060,  0.0071],
        [ 0.0025, -0.0215, -0.0223,  ...,  0.0389,  0.0156, -0.0152],
        [ 0.0421,  0.0042, -0.0014,  ..., -0.0005,  0.0365,  0.0080]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.1514, -1.6055,  3.2305,  ..., -0.6499, -4.1133,  0.7407]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 18:13:05 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The cake falls into the category of dessert
The denim falls into the category of fabric
The plum falls into the category of fruit
The brooch falls into the category of jewelry
The stapler falls into the category of device
The shirt falls into the category of clothes
The tub falls into the category of container
The shelf falls into the category of
2024-07-31 18:13:05 root INFO     [order_1_approx] starting weight calculation for The denim falls into the category of fabric
The stapler falls into the category of device
The shelf falls into the category of furniture
The shirt falls into the category of clothes
The plum falls into the category of fruit
The brooch falls into the category of jewelry
The cake falls into the category of dessert
The tub falls into the category of
2024-07-31 18:13:06 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-07-31 18:16:06 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0396, -0.0638,  0.0928,  ..., -0.0662, -0.1213, -0.0040],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.4536, -2.0840,  2.9121,  ..., -2.7520, -2.0547,  1.1553],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0665,  0.0105, -0.0138,  ...,  0.0474, -0.0480,  0.0081],
        [-0.0010,  0.0565, -0.0118,  ..., -0.0140,  0.0009,  0.0228],
        [-0.0137, -0.0095, -0.0216,  ...,  0.0121, -0.0375,  0.0387],
        ...,
        [-0.0042,  0.0649, -0.0305,  ..., -0.0302,  0.0144, -0.0331],
        [ 0.0098, -0.0045, -0.0376,  ..., -0.0052,  0.0025,  0.0049],
        [ 0.0396,  0.0260, -0.0191,  ...,  0.0113,  0.0605,  0.0215]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.4089, -2.0488,  2.8125,  ..., -2.9375, -1.6074,  0.7080]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 18:16:07 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The denim falls into the category of fabric
The stapler falls into the category of device
The shelf falls into the category of furniture
The shirt falls into the category of clothes
The plum falls into the category of fruit
The brooch falls into the category of jewelry
The cake falls into the category of dessert
The tub falls into the category of
2024-07-31 18:16:07 root INFO     [order_1_approx] starting weight calculation for The cake falls into the category of dessert
The plum falls into the category of fruit
The shelf falls into the category of furniture
The tub falls into the category of container
The stapler falls into the category of device
The shirt falls into the category of clothes
The brooch falls into the category of jewelry
The denim falls into the category of
2024-07-31 18:16:07 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-07-31 18:19:09 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1317,  0.0143, -0.2268,  ...,  0.2554, -0.0100,  0.1188],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.1641, -5.6055,  2.6367,  ..., -0.6226, -2.8438,  1.0928],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0256,  0.0065, -0.0187,  ...,  0.0255, -0.0050,  0.0013],
        [-0.0111,  0.0071, -0.0141,  ...,  0.0068,  0.0008,  0.0262],
        [-0.0054,  0.0039,  0.0236,  ..., -0.0090, -0.0254, -0.0009],
        ...,
        [ 0.0132, -0.0156,  0.0187,  ...,  0.0237, -0.0053, -0.0402],
        [-0.0169,  0.0012,  0.0072,  ..., -0.0086,  0.0316,  0.0063],
        [ 0.0185,  0.0203, -0.0088,  ..., -0.0305, -0.0132,  0.0410]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.1758, -5.6719,  2.7090,  ..., -0.6724, -2.8320,  1.2461]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 18:19:10 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The cake falls into the category of dessert
The plum falls into the category of fruit
The shelf falls into the category of furniture
The tub falls into the category of container
The stapler falls into the category of device
The shirt falls into the category of clothes
The brooch falls into the category of jewelry
The denim falls into the category of
2024-07-31 18:19:10 root INFO     [order_1_approx] starting weight calculation for The shirt falls into the category of clothes
The tub falls into the category of container
The cake falls into the category of dessert
The denim falls into the category of fabric
The brooch falls into the category of jewelry
The stapler falls into the category of device
The shelf falls into the category of furniture
The plum falls into the category of
2024-07-31 18:19:10 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-07-31 18:22:15 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-8.4229e-02, -3.1006e-01, -2.9785e-01,  ...,  1.4160e-01,
        -1.5259e-04, -1.5356e-01], device='cuda:1', dtype=torch.float16,
       grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.7983, -4.7344,  2.0117,  ..., -2.7734, -1.1982, -1.7842],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0366, -0.0281, -0.0564,  ..., -0.0281, -0.0081,  0.0210],
        [ 0.0227, -0.0745,  0.1940,  ...,  0.0695,  0.0006,  0.0487],
        [-0.0043,  0.0470, -0.1025,  ..., -0.0493, -0.0806, -0.0460],
        ...,
        [ 0.0712, -0.0629,  0.0983,  ...,  0.0571,  0.0389,  0.0396],
        [ 0.0255,  0.0150, -0.1022,  ..., -0.0260,  0.0236, -0.0341],
        [-0.0212, -0.0225,  0.1460,  ...,  0.0437,  0.0443,  0.0265]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.8535, -3.3789,  0.9238,  ..., -1.7363, -1.7344, -0.7158]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 18:22:16 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The shirt falls into the category of clothes
The tub falls into the category of container
The cake falls into the category of dessert
The denim falls into the category of fabric
The brooch falls into the category of jewelry
The stapler falls into the category of device
The shelf falls into the category of furniture
The plum falls into the category of
2024-07-31 18:22:16 root INFO     [order_1_approx] starting weight calculation for The shelf falls into the category of furniture
The cake falls into the category of dessert
The denim falls into the category of fabric
The brooch falls into the category of jewelry
The shirt falls into the category of clothes
The tub falls into the category of container
The plum falls into the category of fruit
The stapler falls into the category of
2024-07-31 18:22:16 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-07-31 18:25:15 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1769, -0.0212, -0.1702,  ...,  0.0197,  0.0767, -0.2294],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.0645, -4.5664,  2.0977,  ..., -2.5898, -3.5352, -0.5469],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0081, -0.0101, -0.0171,  ...,  0.0138,  0.0180, -0.0009],
        [-0.0207,  0.0093, -0.0056,  ...,  0.0025,  0.0092, -0.0418],
        [-0.0369, -0.0181, -0.0313,  ..., -0.0324,  0.0122,  0.0071],
        ...,
        [-0.0205, -0.0163, -0.0092,  ..., -0.0130,  0.0085, -0.0262],
        [ 0.0037,  0.0216, -0.0133,  ..., -0.0265, -0.0020, -0.0207],
        [-0.0045,  0.0135,  0.0303,  ...,  0.0069,  0.0098,  0.0118]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.2148, -4.5898,  2.0762,  ..., -2.1484, -3.7363, -0.4536]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 18:25:16 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The shelf falls into the category of furniture
The cake falls into the category of dessert
The denim falls into the category of fabric
The brooch falls into the category of jewelry
The shirt falls into the category of clothes
The tub falls into the category of container
The plum falls into the category of fruit
The stapler falls into the category of
2024-07-31 18:25:16 root INFO     total operator prediction time: 1470.6536433696747 seconds
2024-07-31 18:25:16 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on meronyms - substance
2024-07-31 18:25:16 root INFO     building operator meronyms - substance
2024-07-31 18:25:17 root INFO     [order_1_approx] starting weight calculation for A body is made up of flesh
A roof is made up of shingles
A ocean is made up of water
A plastic is made up of polymer
A desk is made up of wood
A sea is made up of water
A water is made up of oxygen
A wine is made up of
2024-07-31 18:25:17 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-07-31 18:28:17 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0354,  0.1512, -0.1104,  ..., -0.0787,  0.0602, -0.0993],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.8164, -5.8984, -0.1882,  ..., -3.9805,  1.2588, -2.8457],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0480, -0.0027, -0.0742,  ..., -0.0991,  0.0944,  0.0226],
        [ 0.0632, -0.0050,  0.0356,  ...,  0.0557, -0.0685,  0.0107],
        [-0.0070,  0.0086,  0.0258,  ...,  0.0189,  0.0081,  0.0126],
        ...,
        [ 0.0400, -0.0013,  0.0287,  ...,  0.0557, -0.0565, -0.0002],
        [-0.0818, -0.0181, -0.0719,  ..., -0.0798,  0.0692,  0.0092],
        [ 0.0740, -0.0214,  0.0314,  ...,  0.0449, -0.0525,  0.0268]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.9902, -6.0352, -0.3669,  ..., -4.0938,  1.6504, -2.4844]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 18:28:18 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A body is made up of flesh
A roof is made up of shingles
A ocean is made up of water
A plastic is made up of polymer
A desk is made up of wood
A sea is made up of water
A water is made up of oxygen
A wine is made up of
2024-07-31 18:28:19 root INFO     [order_1_approx] starting weight calculation for A wine is made up of grapes
A desk is made up of wood
A ocean is made up of water
A plastic is made up of polymer
A sea is made up of water
A water is made up of oxygen
A body is made up of flesh
A roof is made up of
2024-07-31 18:28:19 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-07-31 18:31:24 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0184, -0.0869,  0.0014,  ..., -0.0919, -0.0760, -0.0132],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 5.4102, -7.4453,  1.7402,  ..., -2.1621, -0.3311, -1.8828],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0339, -0.0088,  0.0008,  ...,  0.0378,  0.0074, -0.0033],
        [ 0.0203,  0.0299, -0.0114,  ...,  0.0279, -0.0183, -0.0115],
        [-0.0651, -0.0062,  0.0011,  ..., -0.0324,  0.0122,  0.0238],
        ...,
        [ 0.0320, -0.0093, -0.0109,  ...,  0.0178,  0.0266, -0.0181],
        [-0.0516,  0.0088, -0.0083,  ..., -0.0344,  0.0159,  0.0218],
        [ 0.0673, -0.0428,  0.0287,  ...,  0.0445, -0.0223, -0.0122]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 5.8594, -7.2188,  1.5312,  ..., -1.7500, -0.8823, -1.1055]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 18:31:25 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A wine is made up of grapes
A desk is made up of wood
A ocean is made up of water
A plastic is made up of polymer
A sea is made up of water
A water is made up of oxygen
A body is made up of flesh
A roof is made up of
2024-07-31 18:31:25 root INFO     [order_1_approx] starting weight calculation for A roof is made up of shingles
A wine is made up of grapes
A sea is made up of water
A water is made up of oxygen
A plastic is made up of polymer
A desk is made up of wood
A body is made up of flesh
A ocean is made up of
2024-07-31 18:31:25 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-07-31 18:34:30 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1920,  0.0828, -0.0895,  ...,  0.1144, -0.0681, -0.0933],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.0625, -4.5078,  2.0762,  ..., -5.2109,  2.5820, -0.4727],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 1.4496e-02, -1.1520e-03,  1.0979e-02,  ..., -6.3553e-03,
          1.9455e-03,  9.8877e-03],
        [ 4.9744e-02, -9.4986e-03,  3.1525e-02,  ...,  5.9624e-03,
         -1.8936e-02, -2.2812e-02],
        [ 2.4414e-02,  8.1100e-03,  4.3915e-02,  ..., -1.5259e-05,
          4.3869e-03, -3.3550e-03],
        ...,
        [ 6.9199e-03,  8.7357e-03, -5.4436e-03,  ...,  5.0049e-03,
          1.0719e-02, -4.5700e-03],
        [-1.8982e-02, -9.3842e-03, -1.3092e-02,  ..., -4.7531e-03,
          3.3321e-03,  3.4370e-03],
        [ 1.8280e-02, -5.3558e-02,  5.9853e-03,  ..., -2.2049e-03,
         -9.2697e-04,  2.9694e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.1992, -3.6680,  1.9150,  ..., -5.3281,  2.6934, -0.0552]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 18:34:31 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A roof is made up of shingles
A wine is made up of grapes
A sea is made up of water
A water is made up of oxygen
A plastic is made up of polymer
A desk is made up of wood
A body is made up of flesh
A ocean is made up of
2024-07-31 18:34:31 root INFO     [order_1_approx] starting weight calculation for A wine is made up of grapes
A desk is made up of wood
A body is made up of flesh
A roof is made up of shingles
A water is made up of oxygen
A ocean is made up of water
A sea is made up of water
A plastic is made up of
2024-07-31 18:34:31 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-07-31 18:37:31 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0837,  0.0272,  0.0068,  ..., -0.0483,  0.1547,  0.0479],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.3594, -5.4844,  1.8926,  ..., -4.9727,  2.1094,  2.7949],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0019, -0.0003, -0.0140,  ..., -0.0213,  0.0071, -0.0042],
        [-0.0106,  0.0295, -0.0122,  ...,  0.0071,  0.0143,  0.0272],
        [ 0.0125,  0.0082,  0.0330,  ...,  0.0022,  0.0224, -0.0566],
        ...,
        [-0.0332, -0.0146, -0.0057,  ..., -0.0007,  0.0049,  0.0192],
        [ 0.0452,  0.0035,  0.0289,  ..., -0.0155,  0.0141, -0.0906],
        [ 0.0016,  0.0003, -0.0257,  ..., -0.0023,  0.0076,  0.0452]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.3477, -5.5938,  1.8672,  ..., -5.1289,  2.2031,  2.6816]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 18:37:32 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A wine is made up of grapes
A desk is made up of wood
A body is made up of flesh
A roof is made up of shingles
A water is made up of oxygen
A ocean is made up of water
A sea is made up of water
A plastic is made up of
2024-07-31 18:37:32 root INFO     [order_1_approx] starting weight calculation for A plastic is made up of polymer
A sea is made up of water
A desk is made up of wood
A roof is made up of shingles
A ocean is made up of water
A body is made up of flesh
A wine is made up of grapes
A water is made up of
2024-07-31 18:37:32 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-07-31 18:40:38 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1115,  0.1346, -0.0385,  ..., -0.0144, -0.1775, -0.1088],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.1475, -3.1367,  0.9229,  ..., -4.1250,  1.3125,  1.5312],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0047,  0.0177, -0.0161,  ...,  0.0097,  0.0549,  0.0406],
        [-0.0163, -0.0092, -0.0042,  ...,  0.0152, -0.0571, -0.0457],
        [ 0.0167,  0.0245, -0.0095,  ..., -0.0069,  0.0039,  0.0192],
        ...,
        [-0.0146,  0.0065,  0.0264,  ...,  0.0116, -0.0080, -0.0371],
        [-0.0238, -0.0375, -0.0138,  ...,  0.0044,  0.0300,  0.0228],
        [ 0.0061, -0.0183, -0.0078,  ..., -0.0035,  0.0079,  0.0074]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.0166, -2.9902,  0.4434,  ..., -3.8516,  1.5205,  1.8389]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 18:40:39 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A plastic is made up of polymer
A sea is made up of water
A desk is made up of wood
A roof is made up of shingles
A ocean is made up of water
A body is made up of flesh
A wine is made up of grapes
A water is made up of
2024-07-31 18:40:39 root INFO     [order_1_approx] starting weight calculation for A sea is made up of water
A wine is made up of grapes
A water is made up of oxygen
A roof is made up of shingles
A plastic is made up of polymer
A ocean is made up of water
A body is made up of flesh
A desk is made up of
2024-07-31 18:40:39 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-07-31 18:43:44 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0174, -0.0720, -0.2004,  ...,  0.0362, -0.1926, -0.1068],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.9902, -4.2695,  2.5684,  ..., -5.3203, -0.6172, -0.2891],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0249,  0.0162,  0.0072,  ...,  0.0287, -0.0059,  0.0323],
        [ 0.0028,  0.0101, -0.0247,  ..., -0.0186,  0.0083, -0.0237],
        [ 0.0208,  0.0163, -0.0191,  ...,  0.0087,  0.0132, -0.0107],
        ...,
        [-0.0013, -0.0319, -0.0277,  ..., -0.0208, -0.0014, -0.0114],
        [-0.0007,  0.0043, -0.0287,  ..., -0.0083,  0.0056,  0.0093],
        [ 0.0020, -0.0174,  0.0386,  ...,  0.0090,  0.0037,  0.0245]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.1660, -4.3594,  2.8066,  ..., -5.5156, -0.7183, -0.4307]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 18:43:45 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A sea is made up of water
A wine is made up of grapes
A water is made up of oxygen
A roof is made up of shingles
A plastic is made up of polymer
A ocean is made up of water
A body is made up of flesh
A desk is made up of
2024-07-31 18:43:45 root INFO     [order_1_approx] starting weight calculation for A sea is made up of water
A wine is made up of grapes
A water is made up of oxygen
A roof is made up of shingles
A plastic is made up of polymer
A desk is made up of wood
A ocean is made up of water
A body is made up of
2024-07-31 18:43:45 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-07-31 18:46:53 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0286,  0.0662, -0.0418,  ...,  0.0031, -0.0867, -0.1399],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.6875, -7.1680,  2.2715,  ..., -4.7266, -4.1250,  1.2012],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0267, -0.0112,  0.0044,  ...,  0.0080, -0.0040,  0.0072],
        [-0.0244,  0.0072,  0.0036,  ..., -0.0058, -0.0029, -0.0070],
        [ 0.0198,  0.0049, -0.0101,  ...,  0.0021, -0.0280, -0.0039],
        ...,
        [-0.0034,  0.0084, -0.0174,  ...,  0.0162,  0.0075, -0.0222],
        [-0.0094, -0.0524,  0.0018,  ..., -0.0146,  0.0074,  0.0203],
        [ 0.0123, -0.0126, -0.0044,  ..., -0.0220, -0.0036,  0.0195]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.5566, -7.3672,  2.3223,  ..., -4.8086, -4.0391,  1.6396]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 18:46:54 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A sea is made up of water
A wine is made up of grapes
A water is made up of oxygen
A roof is made up of shingles
A plastic is made up of polymer
A desk is made up of wood
A ocean is made up of water
A body is made up of
2024-07-31 18:46:54 root INFO     [order_1_approx] starting weight calculation for A body is made up of flesh
A ocean is made up of water
A plastic is made up of polymer
A water is made up of oxygen
A desk is made up of wood
A roof is made up of shingles
A wine is made up of grapes
A sea is made up of
2024-07-31 18:46:54 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-07-31 18:50:03 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0154, -0.0177, -0.0321,  ..., -0.0808, -0.1486,  0.0768],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.7041, -4.0664,  1.0361,  ..., -5.1211,  2.6445, -0.4551],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-5.3436e-02, -5.3528e-02, -3.9673e-04,  ..., -4.1443e-02,
          6.1432e-02,  1.0309e-01],
        [ 4.9133e-02, -7.0343e-03, -7.6294e-06,  ...,  6.4850e-03,
         -4.3701e-02, -3.7994e-02],
        [ 3.0121e-02,  1.3405e-02,  5.8350e-02,  ..., -1.2207e-04,
          1.3435e-02,  3.8483e-02],
        ...,
        [ 4.9469e-02,  6.2637e-03,  2.9068e-02,  ...,  4.1168e-02,
         -3.0685e-02, -4.4800e-02],
        [-5.3833e-02, -5.0140e-02,  1.2207e-04,  ..., -1.3306e-02,
          1.0925e-02,  4.7333e-02],
        [ 3.5004e-02, -2.5085e-02,  2.2537e-02,  ...,  2.9648e-02,
         -1.7891e-03,  2.1118e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.8037, -4.2266,  1.2148,  ..., -5.4297,  3.3203, -0.5762]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 18:50:04 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A body is made up of flesh
A ocean is made up of water
A plastic is made up of polymer
A water is made up of oxygen
A desk is made up of wood
A roof is made up of shingles
A wine is made up of grapes
A sea is made up of
2024-07-31 18:50:04 root INFO     total operator prediction time: 1487.1653254032135 seconds
2024-07-31 18:50:04 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on synonyms - intensity
2024-07-31 18:50:04 root INFO     building operator synonyms - intensity
2024-07-31 18:50:04 root INFO     [order_1_approx] starting weight calculation for A more intense word for pony is horse
A more intense word for well is flourishing
A more intense word for happy is ecstatic
A more intense word for angry is furious
A more intense word for tasty is delicious
A more intense word for bad is awful
A more intense word for jog is run
A more intense word for hungry is
2024-07-31 18:50:04 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-07-31 18:53:06 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0319, -0.1917, -0.1205,  ...,  0.0457, -0.0882,  0.0604],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.2383, -3.5293,  1.9629,  ..., -0.7666, -3.1172, -0.7793],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0418,  0.0027, -0.0003,  ...,  0.0084,  0.0237, -0.0068],
        [ 0.0193,  0.0375,  0.0348,  ..., -0.0083, -0.0179, -0.0243],
        [-0.0195,  0.0225,  0.0213,  ..., -0.0069, -0.0169, -0.0191],
        ...,
        [ 0.0323, -0.0228,  0.0530,  ...,  0.0124,  0.0088, -0.0140],
        [-0.0215,  0.0163, -0.0034,  ..., -0.0321,  0.0231, -0.0105],
        [ 0.0289, -0.0218,  0.0154,  ..., -0.0009, -0.0203,  0.0037]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.4141, -3.1797,  2.0625,  ..., -0.7539, -3.0977, -0.7036]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 18:53:07 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more intense word for pony is horse
A more intense word for well is flourishing
A more intense word for happy is ecstatic
A more intense word for angry is furious
A more intense word for tasty is delicious
A more intense word for bad is awful
A more intense word for jog is run
A more intense word for hungry is
2024-07-31 18:53:07 root INFO     [order_1_approx] starting weight calculation for A more intense word for jog is run
A more intense word for well is flourishing
A more intense word for tasty is delicious
A more intense word for happy is ecstatic
A more intense word for pony is horse
A more intense word for hungry is starving
A more intense word for angry is furious
A more intense word for bad is
2024-07-31 18:53:07 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-07-31 18:56:09 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0204, -0.0112, -0.0446,  ...,  0.0309, -0.0890, -0.2075],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.2656, -1.2363, -0.1279,  ...,  0.3281, -4.7148, -0.3833],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0378, -0.0037,  0.0050,  ..., -0.0170,  0.0123,  0.0089],
        [-0.0955,  0.0104,  0.0715,  ...,  0.0341, -0.0222, -0.0212],
        [-0.0140, -0.0021, -0.0105,  ...,  0.0432, -0.0205, -0.0108],
        ...,
        [ 0.0061, -0.0109,  0.0011,  ...,  0.0223,  0.0198, -0.0279],
        [-0.0144, -0.0006, -0.0178,  ...,  0.0158, -0.0558,  0.0032],
        [-0.0209,  0.0189, -0.0205,  ...,  0.0199,  0.0099, -0.0262]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.2031, -1.5527,  0.4937,  ...,  0.3911, -5.0078,  0.0100]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 18:56:10 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more intense word for jog is run
A more intense word for well is flourishing
A more intense word for tasty is delicious
A more intense word for happy is ecstatic
A more intense word for pony is horse
A more intense word for hungry is starving
A more intense word for angry is furious
A more intense word for bad is
2024-07-31 18:56:10 root INFO     [order_1_approx] starting weight calculation for A more intense word for pony is horse
A more intense word for hungry is starving
A more intense word for bad is awful
A more intense word for tasty is delicious
A more intense word for happy is ecstatic
A more intense word for jog is run
A more intense word for well is flourishing
A more intense word for angry is
2024-07-31 18:56:10 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-07-31 18:59:14 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0464,  0.0980, -0.1678,  ...,  0.1153, -0.1284, -0.0494],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.9355, -5.9023, -1.4746,  ..., -2.8516, -1.7461,  0.9219],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0060, -0.0120,  0.0072,  ...,  0.0028, -0.0277,  0.0091],
        [ 0.0023, -0.0133,  0.0242,  ...,  0.0089, -0.0024, -0.0133],
        [-0.0325, -0.0243,  0.0541,  ..., -0.0012, -0.0339, -0.0166],
        ...,
        [ 0.0297,  0.0126,  0.0064,  ..., -0.0078,  0.0082, -0.0292],
        [-0.0103,  0.0067, -0.0047,  ...,  0.0208, -0.0043, -0.0285],
        [ 0.0054,  0.0113, -0.0147,  ...,  0.0234, -0.0108,  0.0074]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.1543, -5.3008, -0.4521,  ..., -2.7227, -1.7920,  0.8062]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 18:59:15 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more intense word for pony is horse
A more intense word for hungry is starving
A more intense word for bad is awful
A more intense word for tasty is delicious
A more intense word for happy is ecstatic
A more intense word for jog is run
A more intense word for well is flourishing
A more intense word for angry is
2024-07-31 18:59:15 root INFO     [order_1_approx] starting weight calculation for A more intense word for jog is run
A more intense word for happy is ecstatic
A more intense word for tasty is delicious
A more intense word for angry is furious
A more intense word for bad is awful
A more intense word for hungry is starving
A more intense word for well is flourishing
A more intense word for pony is
2024-07-31 18:59:15 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-07-31 19:02:20 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0325, -0.1004, -0.0961,  ..., -0.0643,  0.0198, -0.0234],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.0146, -3.8594, -1.2812,  ...,  2.0254, -3.6445, -1.1084],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0350,  0.0238,  0.0205,  ..., -0.0137,  0.0182,  0.0359],
        [ 0.0468,  0.0848,  0.0011,  ..., -0.0176,  0.0205,  0.0165],
        [ 0.0023, -0.0362,  0.0403,  ..., -0.0340, -0.0175, -0.0122],
        ...,
        [ 0.0516, -0.0180,  0.0130,  ...,  0.0029,  0.0184, -0.0293],
        [-0.0231, -0.0553, -0.0166,  ..., -0.0096, -0.0433,  0.0284],
        [ 0.0362, -0.0083,  0.0323,  ..., -0.0155, -0.0342,  0.0094]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.0176, -3.3945, -1.4502,  ...,  1.9531, -3.9941, -1.0449]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 19:02:21 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more intense word for jog is run
A more intense word for happy is ecstatic
A more intense word for tasty is delicious
A more intense word for angry is furious
A more intense word for bad is awful
A more intense word for hungry is starving
A more intense word for well is flourishing
A more intense word for pony is
2024-07-31 19:02:21 root INFO     [order_1_approx] starting weight calculation for A more intense word for tasty is delicious
A more intense word for angry is furious
A more intense word for bad is awful
A more intense word for pony is horse
A more intense word for hungry is starving
A more intense word for happy is ecstatic
A more intense word for jog is run
A more intense word for well is
2024-07-31 19:02:21 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-07-31 19:05:26 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0220, -0.0341,  0.1070,  ..., -0.0079, -0.1239, -0.0819],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.9062, -0.6206,  1.5039,  ..., -2.6562, -5.0430, -2.2344],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0021, -0.0076, -0.0370,  ..., -0.0042, -0.0319, -0.0295],
        [ 0.0070, -0.0255,  0.1324,  ...,  0.0875,  0.0184,  0.1168],
        [ 0.0055, -0.0483, -0.0258,  ...,  0.0303, -0.0090, -0.0018],
        ...,
        [-0.0414, -0.0342,  0.0264,  ...,  0.0523, -0.0189,  0.0138],
        [ 0.0197, -0.0103, -0.1448,  ..., -0.0161,  0.1188, -0.1317],
        [-0.0788, -0.0356,  0.0392,  ...,  0.0527, -0.0179,  0.0533]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.3320, -1.6387,  2.2148,  ..., -1.9336, -5.1445, -1.4746]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 19:05:27 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more intense word for tasty is delicious
A more intense word for angry is furious
A more intense word for bad is awful
A more intense word for pony is horse
A more intense word for hungry is starving
A more intense word for happy is ecstatic
A more intense word for jog is run
A more intense word for well is
2024-07-31 19:05:27 root INFO     [order_1_approx] starting weight calculation for A more intense word for happy is ecstatic
A more intense word for jog is run
A more intense word for well is flourishing
A more intense word for pony is horse
A more intense word for bad is awful
A more intense word for hungry is starving
A more intense word for angry is furious
A more intense word for tasty is
2024-07-31 19:05:27 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-07-31 19:08:30 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0057,  0.0603,  0.0787,  ..., -0.0209, -0.1818, -0.1190],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.6758, -3.6875, -0.9805,  ..., -2.8594, -8.7109, -1.9707],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0003, -0.0243,  0.0024,  ..., -0.0101, -0.0192, -0.0060],
        [ 0.0284,  0.0312,  0.0026,  ..., -0.0034, -0.0280,  0.0191],
        [-0.0186,  0.0129,  0.0295,  ...,  0.0071, -0.0081, -0.0204],
        ...,
        [ 0.0253,  0.0460,  0.0025,  ...,  0.0356,  0.0093,  0.0082],
        [ 0.0163, -0.0038,  0.0579,  ...,  0.0458,  0.0025,  0.0082],
        [-0.0161, -0.0015, -0.0121,  ..., -0.0052,  0.0015,  0.0043]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 5.1172, -4.0547, -0.9409,  ..., -3.1621, -8.5234, -1.5586]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 19:08:31 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more intense word for happy is ecstatic
A more intense word for jog is run
A more intense word for well is flourishing
A more intense word for pony is horse
A more intense word for bad is awful
A more intense word for hungry is starving
A more intense word for angry is furious
A more intense word for tasty is
2024-07-31 19:08:31 root INFO     [order_1_approx] starting weight calculation for A more intense word for pony is horse
A more intense word for happy is ecstatic
A more intense word for tasty is delicious
A more intense word for well is flourishing
A more intense word for hungry is starving
A more intense word for bad is awful
A more intense word for angry is furious
A more intense word for jog is
2024-07-31 19:08:31 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-07-31 19:11:36 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0978, -0.0963, -0.0053,  ..., -0.1060, -0.0702, -0.0608],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.5000, -6.1250,  2.2383,  ...,  3.5625, -3.4805, -1.0234],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0163, -0.0440,  0.0240,  ..., -0.0562,  0.0338, -0.0764],
        [-0.0341,  0.0021,  0.0318,  ..., -0.0270,  0.0110, -0.0195],
        [-0.0460,  0.0401,  0.0372,  ...,  0.0827,  0.0200,  0.0024],
        ...,
        [ 0.0353, -0.0131,  0.0379,  ..., -0.0006, -0.0128,  0.0047],
        [ 0.0142, -0.0035,  0.0248,  ..., -0.0380, -0.0443,  0.0472],
        [-0.0121,  0.0043, -0.0169,  ..., -0.0687,  0.0177,  0.0089]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.5273, -5.4766,  2.2949,  ...,  2.8770, -4.1484, -0.5371]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 19:11:37 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more intense word for pony is horse
A more intense word for happy is ecstatic
A more intense word for tasty is delicious
A more intense word for well is flourishing
A more intense word for hungry is starving
A more intense word for bad is awful
A more intense word for angry is furious
A more intense word for jog is
2024-07-31 19:11:37 root INFO     [order_1_approx] starting weight calculation for A more intense word for hungry is starving
A more intense word for pony is horse
A more intense word for angry is furious
A more intense word for bad is awful
A more intense word for jog is run
A more intense word for well is flourishing
A more intense word for tasty is delicious
A more intense word for happy is
2024-07-31 19:11:37 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-07-31 19:14:43 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0247,  0.0426, -0.0494,  ...,  0.0069, -0.1989, -0.0769],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.5117, -0.2517,  4.1094,  ...,  1.0742, -6.4297, -0.2422],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0086, -0.0022, -0.0125,  ..., -0.0271,  0.0100, -0.0150],
        [ 0.0364,  0.0215,  0.0453,  ...,  0.0078,  0.0264, -0.0063],
        [-0.0277, -0.0053,  0.0240,  ...,  0.0327, -0.0165, -0.0063],
        ...,
        [ 0.0445, -0.0035,  0.0322,  ...,  0.0393, -0.0073,  0.0098],
        [-0.0284,  0.0093, -0.0011,  ...,  0.0150, -0.0041, -0.0060],
        [-0.0074,  0.0046,  0.0033,  ...,  0.0173,  0.0114,  0.0056]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.1289, -0.4363,  4.6289,  ...,  1.2207, -5.9062,  0.1758]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 19:14:44 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more intense word for hungry is starving
A more intense word for pony is horse
A more intense word for angry is furious
A more intense word for bad is awful
A more intense word for jog is run
A more intense word for well is flourishing
A more intense word for tasty is delicious
A more intense word for happy is
2024-07-31 19:14:44 root INFO     total operator prediction time: 1480.2852668762207 seconds
2024-07-31 19:14:44 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on hypernyms - animals
2024-07-31 19:14:44 root INFO     building operator hypernyms - animals
2024-07-31 19:14:44 root INFO     [order_1_approx] starting weight calculation for The rattlesnake falls into the category of snake
The duck falls into the category of fowl
The owl falls into the category of raptor
The hawk falls into the category of raptor
The jaguar falls into the category of feline
The butterfly falls into the category of insect
The beaver falls into the category of rodent
The gorilla falls into the category of
2024-07-31 19:14:44 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-07-31 19:17:48 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0748, -0.0932, -0.1860,  ..., -0.0323, -0.1384,  0.0337],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.7949, -5.3008,  0.8691,  ..., -3.3477, -7.7812,  0.9844],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 1.8829e-02, -2.2232e-02, -1.5327e-02,  ...,  1.0864e-02,
          1.4809e-02,  1.5879e-03],
        [ 5.6992e-03, -8.7433e-03,  6.0616e-03,  ...,  4.7989e-03,
         -8.8577e-03,  3.1052e-03],
        [-5.2299e-03,  7.7209e-03,  8.8272e-03,  ..., -7.8278e-03,
         -7.2479e-05, -3.1471e-04],
        ...,
        [-3.9005e-04, -1.0834e-02,  7.7438e-04,  ..., -1.9836e-02,
         -4.0588e-03,  7.8964e-04],
        [ 1.3828e-03,  5.6000e-03, -2.6428e-02,  ...,  8.1635e-03,
          9.8724e-03,  6.7406e-03],
        [-2.6703e-05, -8.8806e-03,  4.9973e-03,  ...,  6.7329e-03,
         -6.6605e-03,  1.1810e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.0371, -4.9766,  0.8369,  ..., -3.0254, -8.1094,  1.3350]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 19:17:49 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The rattlesnake falls into the category of snake
The duck falls into the category of fowl
The owl falls into the category of raptor
The hawk falls into the category of raptor
The jaguar falls into the category of feline
The butterfly falls into the category of insect
The beaver falls into the category of rodent
The gorilla falls into the category of
2024-07-31 19:17:49 root INFO     [order_1_approx] starting weight calculation for The beaver falls into the category of rodent
The hawk falls into the category of raptor
The jaguar falls into the category of feline
The owl falls into the category of raptor
The duck falls into the category of fowl
The gorilla falls into the category of primate
The rattlesnake falls into the category of snake
The butterfly falls into the category of
2024-07-31 19:17:49 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-07-31 19:20:52 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1473,  0.1331, -0.1396,  ..., -0.0489, -0.0508, -0.0732],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.5078, -2.3027,  3.1562,  ..., -2.0703, -2.5215, -2.3047],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0126, -0.0103,  0.0037,  ...,  0.0044,  0.0031,  0.0177],
        [ 0.0226, -0.0316,  0.0137,  ..., -0.0396, -0.0046,  0.0235],
        [-0.0156,  0.0125,  0.0033,  ...,  0.0392, -0.0018, -0.0147],
        ...,
        [-0.0214,  0.0165,  0.0047,  ...,  0.0153, -0.0157, -0.0197],
        [-0.0213,  0.0314,  0.0121,  ...,  0.0269,  0.0004, -0.0165],
        [ 0.0144, -0.0254,  0.0031,  ..., -0.0499,  0.0104,  0.0238]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.6240, -1.8740,  3.0625,  ..., -1.9482, -2.6660, -1.8906]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 19:20:53 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The beaver falls into the category of rodent
The hawk falls into the category of raptor
The jaguar falls into the category of feline
The owl falls into the category of raptor
The duck falls into the category of fowl
The gorilla falls into the category of primate
The rattlesnake falls into the category of snake
The butterfly falls into the category of
2024-07-31 19:20:53 root INFO     [order_1_approx] starting weight calculation for The butterfly falls into the category of insect
The duck falls into the category of fowl
The rattlesnake falls into the category of snake
The owl falls into the category of raptor
The hawk falls into the category of raptor
The gorilla falls into the category of primate
The beaver falls into the category of rodent
The jaguar falls into the category of
2024-07-31 19:20:53 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-07-31 19:23:58 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0926,  0.0672, -0.1514,  ..., -0.0269, -0.1372, -0.1163],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.7686, -5.1953, -2.1348,  ..., -2.2910, -6.6250, -2.3555],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0008, -0.0150, -0.0023,  ...,  0.0032, -0.0042,  0.0238],
        [-0.0105,  0.0084,  0.0027,  ..., -0.0194, -0.0081,  0.0125],
        [-0.0042, -0.0077,  0.0123,  ..., -0.0141, -0.0032,  0.0126],
        ...,
        [ 0.0004,  0.0038, -0.0079,  ..., -0.0051, -0.0101, -0.0029],
        [ 0.0109,  0.0097, -0.0202,  ...,  0.0087,  0.0126, -0.0069],
        [-0.0046, -0.0014,  0.0031,  ..., -0.0073, -0.0118,  0.0180]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.9863, -4.9102, -2.0664,  ..., -2.2598, -6.9219, -2.0664]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 19:23:59 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The butterfly falls into the category of insect
The duck falls into the category of fowl
The rattlesnake falls into the category of snake
The owl falls into the category of raptor
The hawk falls into the category of raptor
The gorilla falls into the category of primate
The beaver falls into the category of rodent
The jaguar falls into the category of
2024-07-31 19:24:00 root INFO     [order_1_approx] starting weight calculation for The butterfly falls into the category of insect
The duck falls into the category of fowl
The jaguar falls into the category of feline
The rattlesnake falls into the category of snake
The owl falls into the category of raptor
The gorilla falls into the category of primate
The hawk falls into the category of raptor
The beaver falls into the category of
2024-07-31 19:24:00 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-07-31 19:27:04 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0121, -0.0270, -0.1613,  ...,  0.0779, -0.0199,  0.0533],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.5059, -4.4609,  1.6426,  ..., -1.1182, -6.4102, -1.4014],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0123,  0.0092, -0.0119,  ...,  0.0061, -0.0074,  0.0053],
        [ 0.0577, -0.0323, -0.0513,  ...,  0.0301, -0.0275,  0.0082],
        [-0.0533,  0.0590,  0.0702,  ..., -0.0255, -0.0060, -0.0116],
        ...,
        [ 0.0323, -0.0294,  0.0241,  ...,  0.0515, -0.0021,  0.0275],
        [ 0.0140,  0.0185, -0.0281,  ..., -0.0251,  0.0131, -0.0035],
        [ 0.0277, -0.0232,  0.0056,  ..., -0.0044, -0.0089,  0.0254]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.5156, -3.9434,  1.1816,  ..., -0.5874, -6.2344, -1.4023]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 19:27:05 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The butterfly falls into the category of insect
The duck falls into the category of fowl
The jaguar falls into the category of feline
The rattlesnake falls into the category of snake
The owl falls into the category of raptor
The gorilla falls into the category of primate
The hawk falls into the category of raptor
The beaver falls into the category of
2024-07-31 19:27:06 root INFO     [order_1_approx] starting weight calculation for The beaver falls into the category of rodent
The jaguar falls into the category of feline
The gorilla falls into the category of primate
The owl falls into the category of raptor
The duck falls into the category of fowl
The butterfly falls into the category of insect
The hawk falls into the category of raptor
The rattlesnake falls into the category of
2024-07-31 19:27:06 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-07-31 19:30:09 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0257,  0.1270, -0.2335,  ..., -0.0370,  0.0604, -0.1069],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.6465, -3.9062,  1.3223,  ..., -2.8027, -2.3730, -0.7271],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0051,  0.0018, -0.0077,  ..., -0.0022,  0.0010,  0.0024],
        [-0.0037, -0.0148,  0.0050,  ...,  0.0117, -0.0095,  0.0135],
        [ 0.0031,  0.0145,  0.0183,  ..., -0.0349, -0.0108,  0.0110],
        ...,
        [ 0.0192,  0.0098, -0.0134,  ...,  0.0029,  0.0003,  0.0034],
        [-0.0248,  0.0022, -0.0118,  ...,  0.0037,  0.0381, -0.0098],
        [ 0.0028, -0.0280,  0.0103,  ..., -0.0010, -0.0051,  0.0293]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.6299, -3.6133,  1.2656,  ..., -2.7500, -2.2324, -0.5229]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 19:30:11 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The beaver falls into the category of rodent
The jaguar falls into the category of feline
The gorilla falls into the category of primate
The owl falls into the category of raptor
The duck falls into the category of fowl
The butterfly falls into the category of insect
The hawk falls into the category of raptor
The rattlesnake falls into the category of
2024-07-31 19:30:11 root INFO     [order_1_approx] starting weight calculation for The duck falls into the category of fowl
The rattlesnake falls into the category of snake
The butterfly falls into the category of insect
The gorilla falls into the category of primate
The owl falls into the category of raptor
The beaver falls into the category of rodent
The jaguar falls into the category of feline
The hawk falls into the category of
2024-07-31 19:30:11 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-07-31 19:33:15 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0381,  0.1282, -0.1565,  ..., -0.2593, -0.0914, -0.0407],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.8164, -2.4727,  2.4785,  ..., -1.4111, -6.0117,  1.3965],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0186, -0.0051, -0.0055,  ...,  0.0149, -0.0085,  0.0024],
        [ 0.0071, -0.0026,  0.0106,  ...,  0.0015, -0.0031, -0.0049],
        [ 0.0029, -0.0115,  0.0154,  ...,  0.0104, -0.0124, -0.0121],
        ...,
        [-0.0104, -0.0066, -0.0090,  ...,  0.0101,  0.0010, -0.0070],
        [ 0.0006,  0.0034, -0.0180,  ...,  0.0268,  0.0349,  0.0093],
        [ 0.0015,  0.0143,  0.0003,  ..., -0.0272, -0.0110,  0.0027]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.9746, -2.2559,  2.5488,  ..., -1.3027, -6.2734,  1.4941]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 19:33:16 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The duck falls into the category of fowl
The rattlesnake falls into the category of snake
The butterfly falls into the category of insect
The gorilla falls into the category of primate
The owl falls into the category of raptor
The beaver falls into the category of rodent
The jaguar falls into the category of feline
The hawk falls into the category of
2024-07-31 19:33:16 root INFO     [order_1_approx] starting weight calculation for The jaguar falls into the category of feline
The gorilla falls into the category of primate
The beaver falls into the category of rodent
The butterfly falls into the category of insect
The owl falls into the category of raptor
The hawk falls into the category of raptor
The rattlesnake falls into the category of snake
The duck falls into the category of
2024-07-31 19:33:17 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-07-31 19:36:21 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0856, -0.1675, -0.0597,  ..., -0.1639, -0.0668, -0.1039],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.8691, -0.9932,  4.0039,  ..., -1.2910, -7.9766,  0.8945],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0204, -0.0128, -0.0129,  ...,  0.0355,  0.0137, -0.0019],
        [ 0.0268,  0.0025, -0.0055,  ...,  0.0029,  0.0059,  0.0482],
        [-0.0356, -0.0081,  0.0022,  ...,  0.0079, -0.0136, -0.0395],
        ...,
        [-0.0076, -0.0219, -0.0011,  ..., -0.0066, -0.0077, -0.0093],
        [ 0.0050,  0.0025, -0.0562,  ..., -0.0019, -0.0035,  0.0002],
        [ 0.0317,  0.0003,  0.0191,  ...,  0.0088, -0.0049,  0.0287]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.0566, -0.4644,  3.7246,  ..., -1.0742, -8.0234,  0.9082]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 19:36:22 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The jaguar falls into the category of feline
The gorilla falls into the category of primate
The beaver falls into the category of rodent
The butterfly falls into the category of insect
The owl falls into the category of raptor
The hawk falls into the category of raptor
The rattlesnake falls into the category of snake
The duck falls into the category of
2024-07-31 19:36:23 root INFO     [order_1_approx] starting weight calculation for The hawk falls into the category of raptor
The duck falls into the category of fowl
The gorilla falls into the category of primate
The beaver falls into the category of rodent
The rattlesnake falls into the category of snake
The butterfly falls into the category of insect
The jaguar falls into the category of feline
The owl falls into the category of
2024-07-31 19:36:23 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-07-31 19:39:26 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0025,  0.0442, -0.1056,  ..., -0.1891, -0.1609,  0.0895],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.0000, -2.1035,  0.8193,  ..., -2.7305, -4.1641,  1.8135],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0232, -0.0109,  0.0073,  ...,  0.0152, -0.0170,  0.0032],
        [ 0.0049,  0.0090,  0.0205,  ...,  0.0257,  0.0048,  0.0038],
        [ 0.0018,  0.0164,  0.0150,  ..., -0.0153, -0.0244, -0.0310],
        ...,
        [ 0.0045,  0.0100, -0.0023,  ...,  0.0071, -0.0062, -0.0117],
        [-0.0147, -0.0197, -0.0079,  ...,  0.0442,  0.0307, -0.0064],
        [ 0.0056,  0.0118,  0.0030,  ..., -0.0347, -0.0113,  0.0242]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.9395, -2.2871,  0.9434,  ..., -2.6016, -4.5352,  1.9629]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 19:39:27 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The hawk falls into the category of raptor
The duck falls into the category of fowl
The gorilla falls into the category of primate
The beaver falls into the category of rodent
The rattlesnake falls into the category of snake
The butterfly falls into the category of insect
The jaguar falls into the category of feline
The owl falls into the category of
2024-07-31 19:39:27 root INFO     total operator prediction time: 1483.225888967514 seconds
2024-07-31 19:39:27 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on hyponyms - misc
2024-07-31 19:39:27 root INFO     building operator hyponyms - misc
2024-07-31 19:39:27 root INFO     [order_1_approx] starting weight calculation for A more specific term for a drum is tambourine
A more specific term for a dress is gown
A more specific term for a citrus is lemon
A more specific term for a cloud is thundercloud
A more specific term for a railway is monorail
A more specific term for a painting is watercolor
A more specific term for a church is chapel
A more specific term for a brush is
2024-07-31 19:39:27 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-07-31 19:42:30 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0909, -0.1323, -0.0089,  ...,  0.0314, -0.1140,  0.1038],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.4844, -2.2578, -1.6777,  ...,  2.1562, -2.0371, -0.9185],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0389, -0.0164,  0.0025,  ...,  0.0185, -0.0148, -0.0095],
        [ 0.0128,  0.0486,  0.0593,  ..., -0.0476,  0.0547, -0.0515],
        [ 0.0005, -0.0291, -0.0208,  ..., -0.0781,  0.0407, -0.0044],
        ...,
        [ 0.0242,  0.0340,  0.0256,  ...,  0.0360,  0.0145, -0.0312],
        [-0.0247, -0.0116,  0.0084,  ..., -0.0139,  0.0266, -0.0474],
        [-0.0035,  0.0405, -0.0214,  ...,  0.0200, -0.0080, -0.0061]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.2324, -1.9805, -1.4785,  ...,  2.1406, -2.3086, -0.8232]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 19:42:31 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more specific term for a drum is tambourine
A more specific term for a dress is gown
A more specific term for a citrus is lemon
A more specific term for a cloud is thundercloud
A more specific term for a railway is monorail
A more specific term for a painting is watercolor
A more specific term for a church is chapel
A more specific term for a brush is
2024-07-31 19:42:31 root INFO     [order_1_approx] starting weight calculation for A more specific term for a brush is toothbrush
A more specific term for a citrus is lemon
A more specific term for a painting is watercolor
A more specific term for a cloud is thundercloud
A more specific term for a railway is monorail
A more specific term for a dress is gown
A more specific term for a church is chapel
A more specific term for a drum is
2024-07-31 19:42:31 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-07-31 19:45:33 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0863,  0.0659, -0.0101,  ..., -0.1378, -0.1627,  0.0627],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.7812, -5.7227, -0.8750,  ...,  1.3574, -0.0190,  1.0791],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0194, -0.0276,  0.0032,  ..., -0.0294,  0.0359, -0.0224],
        [ 0.0438,  0.0165, -0.0153,  ...,  0.0243,  0.0167,  0.0108],
        [ 0.0173, -0.0203, -0.0271,  ..., -0.0346,  0.0144, -0.0201],
        ...,
        [ 0.0147,  0.0228,  0.0109,  ...,  0.0287, -0.0275, -0.0178],
        [-0.0042,  0.0292,  0.0612,  ..., -0.0016,  0.0481,  0.0120],
        [-0.0021, -0.0013,  0.0245,  ..., -0.0240,  0.0098,  0.0247]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.5879, -5.4648, -0.3921,  ...,  1.4385, -0.2194,  1.0957]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 19:45:34 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more specific term for a brush is toothbrush
A more specific term for a citrus is lemon
A more specific term for a painting is watercolor
A more specific term for a cloud is thundercloud
A more specific term for a railway is monorail
A more specific term for a dress is gown
A more specific term for a church is chapel
A more specific term for a drum is
2024-07-31 19:45:34 root INFO     [order_1_approx] starting weight calculation for A more specific term for a church is chapel
A more specific term for a painting is watercolor
A more specific term for a railway is monorail
A more specific term for a cloud is thundercloud
A more specific term for a drum is tambourine
A more specific term for a citrus is lemon
A more specific term for a brush is toothbrush
A more specific term for a dress is
2024-07-31 19:45:34 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-07-31 19:48:40 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0360, -0.1483, -0.0886,  ...,  0.1790, -0.0408, -0.0275],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.8418, -4.9336, -0.7061,  ...,  2.2129, -1.9961,  3.1719],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0192, -0.0499,  0.0452,  ..., -0.0081,  0.0102, -0.0238],
        [ 0.0037,  0.0219,  0.0408,  ..., -0.0104,  0.0174, -0.0365],
        [ 0.0139, -0.0013,  0.0147,  ..., -0.0179, -0.0402, -0.0102],
        ...,
        [-0.0063,  0.0128,  0.0035,  ..., -0.0022,  0.0386, -0.0011],
        [ 0.0003,  0.0222,  0.0111,  ..., -0.0136,  0.0285, -0.0130],
        [-0.0098, -0.0046,  0.0239,  ..., -0.0227,  0.0142, -0.0010]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.1592, -4.3477, -1.0703,  ...,  2.1191, -1.7637,  3.3438]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 19:48:41 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more specific term for a church is chapel
A more specific term for a painting is watercolor
A more specific term for a railway is monorail
A more specific term for a cloud is thundercloud
A more specific term for a drum is tambourine
A more specific term for a citrus is lemon
A more specific term for a brush is toothbrush
A more specific term for a dress is
2024-07-31 19:48:41 root INFO     [order_1_approx] starting weight calculation for A more specific term for a citrus is lemon
A more specific term for a railway is monorail
A more specific term for a dress is gown
A more specific term for a cloud is thundercloud
A more specific term for a church is chapel
A more specific term for a brush is toothbrush
A more specific term for a drum is tambourine
A more specific term for a painting is
2024-07-31 19:48:41 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-07-31 19:51:45 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0020,  0.0436,  0.0155,  ...,  0.0651, -0.0530, -0.0158],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.4512, -4.1250,  0.7227,  ...,  0.6060, -2.2539,  1.0566],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0107, -0.0302,  0.0253,  ...,  0.0124,  0.0358,  0.0172],
        [-0.0171,  0.0044, -0.0101,  ..., -0.0028,  0.0146, -0.0289],
        [ 0.0266,  0.0238,  0.0320,  ..., -0.0285, -0.0159,  0.0112],
        ...,
        [ 0.0058,  0.0092, -0.0105,  ...,  0.0502, -0.0141, -0.0217],
        [-0.0310,  0.0021,  0.0044,  ..., -0.0081, -0.0023, -0.0308],
        [ 0.0142, -0.0105, -0.0173,  ..., -0.0102, -0.0292,  0.0235]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.8242, -3.3457,  0.4385,  ...,  0.4775, -1.8320,  1.5332]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 19:51:46 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more specific term for a citrus is lemon
A more specific term for a railway is monorail
A more specific term for a dress is gown
A more specific term for a cloud is thundercloud
A more specific term for a church is chapel
A more specific term for a brush is toothbrush
A more specific term for a drum is tambourine
A more specific term for a painting is
2024-07-31 19:51:47 root INFO     [order_1_approx] starting weight calculation for A more specific term for a dress is gown
A more specific term for a brush is toothbrush
A more specific term for a citrus is lemon
A more specific term for a painting is watercolor
A more specific term for a drum is tambourine
A more specific term for a church is chapel
A more specific term for a railway is monorail
A more specific term for a cloud is
2024-07-31 19:51:47 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-07-31 19:54:47 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0229, -0.0156, -0.0708,  ..., -0.0530, -0.0268, -0.1140],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.8843, -3.2617,  4.4062,  ...,  0.0283, -1.0469,  2.2637],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0333, -0.0450,  0.0503,  ...,  0.0222, -0.0019,  0.0294],
        [ 0.0482, -0.0059,  0.0166,  ...,  0.0148, -0.0444,  0.0274],
        [ 0.0097,  0.0067,  0.0425,  ..., -0.0071, -0.0091,  0.0004],
        ...,
        [ 0.0157, -0.0229,  0.0116,  ...,  0.0284, -0.0168, -0.0221],
        [-0.0078,  0.0202,  0.0181,  ..., -0.0331,  0.0304,  0.0440],
        [ 0.0137,  0.0164, -0.0082,  ...,  0.0156, -0.0014,  0.0234]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.0869, -3.3438,  4.3164,  ...,  0.1056, -0.8428,  2.3105]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 19:54:48 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more specific term for a dress is gown
A more specific term for a brush is toothbrush
A more specific term for a citrus is lemon
A more specific term for a painting is watercolor
A more specific term for a drum is tambourine
A more specific term for a church is chapel
A more specific term for a railway is monorail
A more specific term for a cloud is
2024-07-31 19:54:48 root INFO     [order_1_approx] starting weight calculation for A more specific term for a painting is watercolor
A more specific term for a citrus is lemon
A more specific term for a railway is monorail
A more specific term for a drum is tambourine
A more specific term for a brush is toothbrush
A more specific term for a dress is gown
A more specific term for a cloud is thundercloud
A more specific term for a church is
2024-07-31 19:54:48 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-07-31 19:57:50 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0600, -0.0679, -0.0970,  ...,  0.0729, -0.1497, -0.0192],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.6621, -5.4844,  4.0156,  ..., -0.6504, -0.1836,  2.0723],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0145, -0.0468,  0.0011,  ..., -0.0106,  0.0139, -0.0226],
        [-0.0010, -0.0022,  0.0201,  ...,  0.0012,  0.0113,  0.0034],
        [-0.0095,  0.0121,  0.0250,  ..., -0.0243, -0.0087, -0.0077],
        ...,
        [ 0.0179,  0.0267,  0.0198,  ..., -0.0094,  0.0215, -0.0031],
        [-0.0113, -0.0156, -0.0034,  ..., -0.0082,  0.0352, -0.0218],
        [-0.0022,  0.0457,  0.0013,  ...,  0.0008, -0.0195,  0.0172]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.8574, -5.5508,  3.9043,  ..., -0.6318,  0.1272,  1.7949]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 19:57:51 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more specific term for a painting is watercolor
A more specific term for a citrus is lemon
A more specific term for a railway is monorail
A more specific term for a drum is tambourine
A more specific term for a brush is toothbrush
A more specific term for a dress is gown
A more specific term for a cloud is thundercloud
A more specific term for a church is
2024-07-31 19:57:51 root INFO     [order_1_approx] starting weight calculation for A more specific term for a brush is toothbrush
A more specific term for a citrus is lemon
A more specific term for a cloud is thundercloud
A more specific term for a dress is gown
A more specific term for a drum is tambourine
A more specific term for a church is chapel
A more specific term for a painting is watercolor
A more specific term for a railway is
2024-07-31 19:57:52 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-07-31 20:00:56 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0690,  0.1853,  0.0302,  ..., -0.0903,  0.1265, -0.0487],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-2.5820, -6.7266,  1.8457,  ...,  3.7305, -0.5684,  0.6328],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0382, -0.0262,  0.0069,  ...,  0.0042, -0.0207,  0.0307],
        [ 0.0301, -0.0099,  0.0228,  ...,  0.0028,  0.0048,  0.0267],
        [ 0.0220,  0.0282,  0.0115,  ..., -0.0224,  0.0260,  0.0053],
        ...,
        [ 0.0229,  0.0189, -0.0141,  ...,  0.0130,  0.0100, -0.0166],
        [-0.0079, -0.0164,  0.0432,  ...,  0.0254,  0.0724, -0.0095],
        [ 0.0091,  0.0281,  0.0338,  ..., -0.0137,  0.0197,  0.0350]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-2.3652, -6.9805,  1.9316,  ...,  3.7930, -0.0920,  0.9399]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 20:00:56 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more specific term for a brush is toothbrush
A more specific term for a citrus is lemon
A more specific term for a cloud is thundercloud
A more specific term for a dress is gown
A more specific term for a drum is tambourine
A more specific term for a church is chapel
A more specific term for a painting is watercolor
A more specific term for a railway is
2024-07-31 20:00:57 root INFO     [order_1_approx] starting weight calculation for A more specific term for a church is chapel
A more specific term for a cloud is thundercloud
A more specific term for a drum is tambourine
A more specific term for a painting is watercolor
A more specific term for a railway is monorail
A more specific term for a brush is toothbrush
A more specific term for a dress is gown
A more specific term for a citrus is
2024-07-31 20:00:57 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-07-31 20:03:58 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1525, -0.2382,  0.0231,  ..., -0.0605, -0.1447, -0.0770],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.1250, -5.9023, -1.9609,  ..., -0.3926, -6.2031, -2.5977],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 5.5359e-02, -1.4191e-02,  1.1520e-02,  ..., -2.3636e-02,
          4.0283e-02,  2.4017e-02],
        [ 1.9836e-02,  7.8125e-03, -1.5869e-02,  ...,  1.8219e-02,
         -2.0142e-02, -1.5278e-03],
        [ 2.2278e-02,  7.8049e-03,  2.7054e-02,  ...,  2.8717e-02,
         -2.0447e-02,  1.8677e-02],
        ...,
        [ 2.7771e-02,  1.1654e-03, -3.3752e-02,  ...,  2.1072e-02,
          9.2468e-03, -4.2725e-03],
        [ 4.1199e-04,  4.4250e-03,  3.0792e-02,  ...,  2.4414e-03,
          2.2827e-02, -8.3923e-03],
        [ 5.8044e-02, -2.0096e-02, -6.9656e-03,  ..., -2.7542e-03,
         -3.4561e-03,  6.4850e-05]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.8242, -5.8398, -1.8330,  ..., -0.6138, -6.3086, -2.5098]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 20:04:00 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more specific term for a church is chapel
A more specific term for a cloud is thundercloud
A more specific term for a drum is tambourine
A more specific term for a painting is watercolor
A more specific term for a railway is monorail
A more specific term for a brush is toothbrush
A more specific term for a dress is gown
A more specific term for a citrus is
2024-07-31 20:04:00 root INFO     total operator prediction time: 1472.4219846725464 seconds
2024-07-31 20:04:00 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on antonyms - binary
2024-07-31 20:04:00 root INFO     building operator antonyms - binary
2024-07-31 20:04:00 root INFO     [order_1_approx] starting weight calculation for The opposite of toward is away
The opposite of before is after
The opposite of anterior is posterior
The opposite of in is out
The opposite of rise is sink
The opposite of inhale is exhale
The opposite of true is false
The opposite of internal is
2024-07-31 20:04:00 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-07-31 20:07:05 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0466, -0.1924,  0.0421,  ...,  0.0369, -0.0847, -0.0776],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.5723, -0.1316,  1.5234,  ..., -2.2715, -0.2046, -5.2500],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0104,  0.0013, -0.1058,  ...,  0.0117,  0.0726,  0.0368],
        [-0.0296,  0.0197, -0.0067,  ...,  0.0016,  0.0577, -0.0393],
        [ 0.0653, -0.0066, -0.0043,  ...,  0.0045, -0.0084,  0.0414],
        ...,
        [-0.0256,  0.0576,  0.0145,  ..., -0.0447,  0.0335,  0.0011],
        [ 0.0876, -0.1331, -0.0528,  ..., -0.0035, -0.0022, -0.0353],
        [-0.0590,  0.0087, -0.0587,  ...,  0.0895,  0.0436,  0.0377]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.1606,  0.4807,  1.6826,  ..., -2.1328, -0.3069, -5.2227]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 20:07:06 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of toward is away
The opposite of before is after
The opposite of anterior is posterior
The opposite of in is out
The opposite of rise is sink
The opposite of inhale is exhale
The opposite of true is false
The opposite of internal is
2024-07-31 20:07:06 root INFO     [order_1_approx] starting weight calculation for The opposite of true is false
The opposite of before is after
The opposite of anterior is posterior
The opposite of inhale is exhale
The opposite of toward is away
The opposite of rise is sink
The opposite of internal is external
The opposite of in is
2024-07-31 20:07:06 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-07-31 20:10:11 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0609,  0.0036, -0.0287,  ...,  0.0662, -0.0173, -0.1416],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.1504, -3.9785,  2.2812,  ..., -3.6445,  0.2228, -5.2188],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0157,  0.1255,  0.0317,  ...,  0.0181, -0.0902,  0.0770],
        [ 0.0944,  0.0681,  0.0909,  ...,  0.0216, -0.0704,  0.0774],
        [-0.0219, -0.0063, -0.0208,  ..., -0.0115, -0.0374, -0.0333],
        ...,
        [ 0.1157, -0.0900, -0.0542,  ..., -0.0126,  0.0031,  0.0455],
        [-0.0903, -0.1475, -0.0289,  ...,  0.0677,  0.0967, -0.0838],
        [ 0.0861,  0.0841,  0.0693,  ...,  0.0330, -0.0389, -0.0070]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.2126, -3.7539,  2.4844,  ..., -3.4336, -0.2939, -4.5820]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 20:10:12 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of true is false
The opposite of before is after
The opposite of anterior is posterior
The opposite of inhale is exhale
The opposite of toward is away
The opposite of rise is sink
The opposite of internal is external
The opposite of in is
2024-07-31 20:10:12 root INFO     [order_1_approx] starting weight calculation for The opposite of true is false
The opposite of before is after
The opposite of toward is away
The opposite of anterior is posterior
The opposite of internal is external
The opposite of in is out
The opposite of inhale is exhale
The opposite of rise is
2024-07-31 20:10:12 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-07-31 20:13:15 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1672, -0.1047, -0.0770,  ...,  0.0305, -0.1526, -0.1071],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.8428, -0.6602,  2.0098,  ..., -1.4736, -2.3066, -2.4082],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-2.9488e-03,  6.9313e-03, -1.1978e-02,  ...,  4.8126e-02,
          2.7039e-02, -2.1149e-02],
        [-1.8707e-02,  1.1848e-02,  3.6407e-02,  ..., -3.2227e-02,
         -5.5054e-02, -1.9302e-03],
        [ 1.0971e-02,  2.8946e-02, -4.7455e-02,  ..., -6.5956e-03,
         -1.0468e-02, -2.0279e-02],
        ...,
        [-1.9012e-02, -3.5156e-02,  2.5665e-02,  ...,  1.2268e-02,
          5.8594e-03,  1.8829e-02],
        [-1.3443e-02, -1.8127e-02,  9.9182e-05,  ...,  6.1035e-05,
         -4.7485e-02,  2.4139e-02],
        [-4.8401e-02, -3.5919e-02,  2.1561e-02,  ...,  7.6111e-02,
          1.2573e-01,  4.2877e-03]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.8877, -1.1914,  2.3926,  ..., -1.1914, -2.4453, -1.2871]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 20:13:16 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of true is false
The opposite of before is after
The opposite of toward is away
The opposite of anterior is posterior
The opposite of internal is external
The opposite of in is out
The opposite of inhale is exhale
The opposite of rise is
2024-07-31 20:13:16 root INFO     [order_1_approx] starting weight calculation for The opposite of in is out
The opposite of rise is sink
The opposite of before is after
The opposite of anterior is posterior
The opposite of internal is external
The opposite of inhale is exhale
The opposite of toward is away
The opposite of true is
2024-07-31 20:13:16 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-07-31 20:16:16 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0364,  0.0099,  0.0894,  ..., -0.0440, -0.1031, -0.0545],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.0586, -2.0273,  0.1333,  ...,  1.2441, -1.9785, -2.3867],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0405, -0.0439,  0.0040,  ...,  0.0003,  0.0317,  0.0448],
        [ 0.0148,  0.0356, -0.0132,  ...,  0.0316, -0.0070, -0.0231],
        [-0.0464,  0.0042,  0.0183,  ..., -0.0316,  0.0360,  0.0187],
        ...,
        [ 0.0356, -0.0285, -0.0084,  ...,  0.0142, -0.0114,  0.0033],
        [-0.0414,  0.0731,  0.0030,  ...,  0.0519,  0.0025, -0.0411],
        [ 0.0098,  0.0052, -0.0172,  ..., -0.0413,  0.0108,  0.0512]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.2969, -2.6621,  0.6577,  ...,  0.7324, -3.6992, -2.0840]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 20:16:17 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of in is out
The opposite of rise is sink
The opposite of before is after
The opposite of anterior is posterior
The opposite of internal is external
The opposite of inhale is exhale
The opposite of toward is away
The opposite of true is
2024-07-31 20:16:17 root INFO     [order_1_approx] starting weight calculation for The opposite of true is false
The opposite of inhale is exhale
The opposite of toward is away
The opposite of internal is external
The opposite of anterior is posterior
The opposite of in is out
The opposite of rise is sink
The opposite of before is
2024-07-31 20:16:17 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-07-31 20:19:14 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0879, -0.0822, -0.0979,  ..., -0.0453, -0.1641, -0.0790],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.0781, -1.5693, -0.8779,  ..., -0.0554, -1.7861, -3.1250],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0019,  0.0136,  0.0185,  ..., -0.0013, -0.0138, -0.0153],
        [-0.0181,  0.0224,  0.0088,  ...,  0.0348, -0.0419, -0.0429],
        [-0.0307,  0.0495, -0.0386,  ...,  0.0020, -0.0146, -0.0272],
        ...,
        [ 0.0468, -0.0282, -0.0410,  ..., -0.0034, -0.0173, -0.0279],
        [-0.0546, -0.0120,  0.0184,  ...,  0.0273, -0.0342, -0.0155],
        [-0.0325,  0.0067, -0.0217,  ...,  0.0467,  0.0246, -0.0496]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.8711, -0.6675,  0.0317,  ..., -0.0714, -0.9609, -2.3477]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 20:19:15 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of true is false
The opposite of inhale is exhale
The opposite of toward is away
The opposite of internal is external
The opposite of anterior is posterior
The opposite of in is out
The opposite of rise is sink
The opposite of before is
2024-07-31 20:19:15 root INFO     [order_1_approx] starting weight calculation for The opposite of anterior is posterior
The opposite of in is out
The opposite of true is false
The opposite of toward is away
The opposite of internal is external
The opposite of before is after
The opposite of rise is sink
The opposite of inhale is
2024-07-31 20:19:15 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-07-31 20:22:22 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0733,  0.0033, -0.0331,  ..., -0.1370, -0.2174, -0.0452],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.1309, -2.0449,  2.1953,  ..., -2.1680,  0.3232,  1.1406],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0580, -0.0753,  0.0247,  ...,  0.0662,  0.0653,  0.0550],
        [ 0.0054, -0.0287, -0.0260,  ..., -0.0210, -0.0098, -0.0253],
        [-0.0228, -0.0103, -0.0085,  ..., -0.0145, -0.0028, -0.0440],
        ...,
        [ 0.0115, -0.0332, -0.0242,  ..., -0.0303, -0.0057, -0.0200],
        [ 0.0322, -0.0782, -0.0388,  ..., -0.0103, -0.0227, -0.0047],
        [ 0.0062, -0.0056,  0.0103,  ..., -0.0011, -0.0046,  0.0166]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.0605, -2.2012,  2.1758,  ..., -1.6484,  0.5752,  1.2422]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 20:22:23 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of anterior is posterior
The opposite of in is out
The opposite of true is false
The opposite of toward is away
The opposite of internal is external
The opposite of before is after
The opposite of rise is sink
The opposite of inhale is
2024-07-31 20:22:24 root INFO     [order_1_approx] starting weight calculation for The opposite of rise is sink
The opposite of true is false
The opposite of inhale is exhale
The opposite of anterior is posterior
The opposite of internal is external
The opposite of in is out
The opposite of before is after
The opposite of toward is
2024-07-31 20:22:24 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-07-31 20:25:31 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0198, -0.0471, -0.0392,  ..., -0.0966,  0.0265,  0.0460],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.8193, -3.1172,  1.1182,  ..., -1.2021, -0.1743, -4.3125],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0422, -0.0370, -0.0899,  ...,  0.1105,  0.0456,  0.0508],
        [-0.0242,  0.0452,  0.0261,  ...,  0.0175,  0.0097, -0.0263],
        [ 0.0136,  0.0435,  0.0359,  ...,  0.0157,  0.0298, -0.0432],
        ...,
        [ 0.0342,  0.0091, -0.0099,  ...,  0.0356, -0.0232, -0.0107],
        [-0.0054, -0.0311,  0.0823,  ...,  0.0703,  0.0348, -0.0138],
        [-0.0413,  0.0320, -0.0567,  ...,  0.0746, -0.0049, -0.0076]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.7061, -2.6582,  1.0654,  ..., -0.3535, -0.3599, -3.3379]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 20:25:32 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of rise is sink
The opposite of true is false
The opposite of inhale is exhale
The opposite of anterior is posterior
The opposite of internal is external
The opposite of in is out
The opposite of before is after
The opposite of toward is
2024-07-31 20:25:32 root INFO     [order_1_approx] starting weight calculation for The opposite of true is false
The opposite of in is out
The opposite of internal is external
The opposite of rise is sink
The opposite of before is after
The opposite of inhale is exhale
The opposite of toward is away
The opposite of anterior is
2024-07-31 20:25:32 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-07-31 20:28:36 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1121, -0.0162,  0.0252,  ..., -0.0854, -0.0911, -0.0975],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.5420, -2.4961,  2.7930,  ..., -3.8828, -2.2891, -4.6289],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0504,  0.0608, -0.0141,  ...,  0.0450, -0.0067, -0.0124],
        [ 0.0277,  0.0456, -0.0889,  ..., -0.0164,  0.0693,  0.0085],
        [ 0.0707, -0.0117,  0.0241,  ..., -0.0089,  0.0546, -0.0189],
        ...,
        [-0.0503,  0.0385, -0.0839,  ..., -0.0320, -0.0213,  0.0020],
        [ 0.0303, -0.0562, -0.0018,  ...,  0.0334,  0.0588, -0.0344],
        [-0.0774,  0.1017, -0.0877,  ...,  0.0271, -0.0242,  0.0128]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.8931, -2.3066,  3.3203,  ..., -3.3301, -2.1289, -4.5312]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 20:28:37 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of true is false
The opposite of in is out
The opposite of internal is external
The opposite of rise is sink
The opposite of before is after
The opposite of inhale is exhale
The opposite of toward is away
The opposite of anterior is
2024-07-31 20:28:37 root INFO     total operator prediction time: 1477.8118560314178 seconds
2024-07-31 20:28:37 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on meronyms - member
2024-07-31 20:28:37 root INFO     building operator meronyms - member
2024-07-31 20:28:38 root INFO     [order_1_approx] starting weight calculation for A elephant is a member of a herd
A calf is a member of a cattle
A soldier is a member of a army
A secretary is a member of a staff
A listener is a member of a audience
A flower is a member of a bouquet
A sheep is a member of a flock
A wolf is a member of a
2024-07-31 20:28:38 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-07-31 20:31:42 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1603, -0.0159, -0.1083,  ..., -0.1465, -0.1140, -0.0767],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 7.5625, -5.8477,  2.0801,  ..., -2.9961, -1.5469,  0.5576],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0163, -0.0532,  0.0423,  ...,  0.0104, -0.0032,  0.0197],
        [-0.0191, -0.0056, -0.0176,  ..., -0.0017,  0.0274,  0.0137],
        [-0.0027, -0.0341,  0.0302,  ...,  0.0020,  0.0218,  0.0039],
        ...,
        [ 0.0466, -0.0082, -0.0063,  ...,  0.0489,  0.0089, -0.0040],
        [-0.0321, -0.0264, -0.0191,  ..., -0.0177,  0.0281,  0.0550],
        [-0.0131,  0.0189,  0.0020,  ..., -0.0237,  0.0210, -0.0096]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 7.9648, -5.6797,  2.1719,  ..., -2.9980, -0.6655,  0.3958]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 20:31:43 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A elephant is a member of a herd
A calf is a member of a cattle
A soldier is a member of a army
A secretary is a member of a staff
A listener is a member of a audience
A flower is a member of a bouquet
A sheep is a member of a flock
A wolf is a member of a
2024-07-31 20:31:43 root INFO     [order_1_approx] starting weight calculation for A soldier is a member of a army
A secretary is a member of a staff
A listener is a member of a audience
A elephant is a member of a herd
A calf is a member of a cattle
A sheep is a member of a flock
A wolf is a member of a pack
A flower is a member of a
2024-07-31 20:31:44 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-07-31 20:34:48 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0167,  0.1326, -0.3018,  ..., -0.0479,  0.0097, -0.0350],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.0293, -4.6562,  0.2974,  ...,  0.9170, -3.1055, -2.8125],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0572, -0.0060,  0.0012,  ...,  0.0296, -0.0146,  0.0332],
        [-0.0365,  0.0116,  0.0457,  ..., -0.0427, -0.0022, -0.0517],
        [ 0.0168,  0.0191,  0.0235,  ..., -0.0185, -0.0264, -0.0019],
        ...,
        [ 0.0362,  0.0035,  0.0026,  ...,  0.0143, -0.0038, -0.0247],
        [-0.0050, -0.0146, -0.0210,  ...,  0.0132,  0.0325,  0.0048],
        [-0.0199, -0.0168,  0.0241,  ..., -0.0014, -0.0080,  0.0069]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.4219, -4.7734,  0.2007,  ...,  0.8462, -2.9316, -2.9492]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 20:34:49 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A soldier is a member of a army
A secretary is a member of a staff
A listener is a member of a audience
A elephant is a member of a herd
A calf is a member of a cattle
A sheep is a member of a flock
A wolf is a member of a pack
A flower is a member of a
2024-07-31 20:34:49 root INFO     [order_1_approx] starting weight calculation for A wolf is a member of a pack
A soldier is a member of a army
A secretary is a member of a staff
A elephant is a member of a herd
A listener is a member of a audience
A calf is a member of a cattle
A flower is a member of a bouquet
A sheep is a member of a
2024-07-31 20:34:49 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-07-31 20:37:55 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0115,  0.0259, -0.0669,  ..., -0.0030, -0.0162,  0.0760],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.3711, -1.3770,  3.8027,  ..., -1.7002, -1.7930, -0.3877],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 4.3640e-02, -3.3752e-02,  1.5289e-02,  ...,  5.4474e-02,
          1.0208e-02,  2.2736e-03],
        [ 4.5395e-03,  1.4133e-03,  1.1963e-02,  ..., -4.6539e-03,
          3.0548e-02,  1.0094e-02],
        [-5.0125e-03, -3.4302e-02,  3.1769e-02,  ..., -4.1962e-05,
         -1.7059e-02, -2.3766e-03],
        ...,
        [ 8.5907e-03,  2.9724e-02, -3.3722e-02,  ...,  6.0516e-02,
         -3.3932e-03,  5.0735e-03],
        [ 1.3237e-03, -2.1973e-02, -1.0147e-02,  ..., -6.7596e-03,
          4.4464e-02,  1.2894e-02],
        [-2.9907e-03, -2.4277e-02,  3.1204e-02,  ..., -1.7929e-02,
          1.8890e-02, -1.1627e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.9453, -0.7109,  3.3770,  ..., -1.4336, -2.1094, -0.5674]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 20:37:56 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A wolf is a member of a pack
A soldier is a member of a army
A secretary is a member of a staff
A elephant is a member of a herd
A listener is a member of a audience
A calf is a member of a cattle
A flower is a member of a bouquet
A sheep is a member of a
2024-07-31 20:37:56 root INFO     [order_1_approx] starting weight calculation for A calf is a member of a cattle
A wolf is a member of a pack
A soldier is a member of a army
A elephant is a member of a herd
A flower is a member of a bouquet
A sheep is a member of a flock
A listener is a member of a audience
A secretary is a member of a
2024-07-31 20:37:56 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-07-31 20:41:03 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0644, -0.0605, -0.1616,  ...,  0.1104, -0.0472,  0.0488],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.0391, -4.7148,  3.1992,  ..., -1.2109, -0.2227, -3.5547],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0077, -0.0118,  0.0152,  ...,  0.0112, -0.0041, -0.0053],
        [ 0.0126, -0.0033, -0.0084,  ...,  0.0115, -0.0326, -0.0081],
        [-0.0125,  0.0087,  0.0151,  ..., -0.0017, -0.0170, -0.0354],
        ...,
        [ 0.0258,  0.0033,  0.0366,  ...,  0.0081,  0.0330, -0.0069],
        [-0.0117,  0.0348, -0.0581,  ...,  0.0301, -0.0067, -0.0138],
        [ 0.0430, -0.0318, -0.0126,  ...,  0.0025,  0.0114,  0.0346]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.2344, -4.9023,  3.3652,  ..., -1.2920,  0.2773, -3.5488]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 20:41:03 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A calf is a member of a cattle
A wolf is a member of a pack
A soldier is a member of a army
A elephant is a member of a herd
A flower is a member of a bouquet
A sheep is a member of a flock
A listener is a member of a audience
A secretary is a member of a
2024-07-31 20:41:04 root INFO     [order_1_approx] starting weight calculation for A secretary is a member of a staff
A listener is a member of a audience
A wolf is a member of a pack
A flower is a member of a bouquet
A calf is a member of a cattle
A sheep is a member of a flock
A soldier is a member of a army
A elephant is a member of a
2024-07-31 20:41:04 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-07-31 20:44:08 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0762,  0.0704, -0.1533,  ..., -0.0582, -0.1819, -0.0938],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 7.2188, -5.3438,  2.7930,  ..., -2.3047, -2.3770, -2.0430],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0372,  0.1130, -0.0903,  ..., -0.0869, -0.0325,  0.0205],
        [-0.0301, -0.0347,  0.0457,  ...,  0.0463,  0.0039, -0.0009],
        [ 0.0026,  0.0085, -0.0143,  ..., -0.0235, -0.0042,  0.0100],
        ...,
        [-0.0189, -0.0527,  0.0340,  ...,  0.0453,  0.0188, -0.0156],
        [ 0.0001,  0.0460, -0.0545,  ..., -0.0443, -0.0070,  0.0125],
        [-0.0290, -0.0586,  0.0455,  ...,  0.0503,  0.0135, -0.0060]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 5.7109, -4.4141,  2.6562,  ..., -1.6357, -2.7266, -1.1484]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 20:44:09 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A secretary is a member of a staff
A listener is a member of a audience
A wolf is a member of a pack
A flower is a member of a bouquet
A calf is a member of a cattle
A sheep is a member of a flock
A soldier is a member of a army
A elephant is a member of a
2024-07-31 20:44:09 root INFO     [order_1_approx] starting weight calculation for A wolf is a member of a pack
A elephant is a member of a herd
A sheep is a member of a flock
A soldier is a member of a army
A secretary is a member of a staff
A listener is a member of a audience
A flower is a member of a bouquet
A calf is a member of a
2024-07-31 20:44:09 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-07-31 20:47:15 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1637,  0.0441,  0.0201,  ..., -0.1735, -0.0752,  0.0031],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 5.6094, -1.6426,  1.6152,  ..., -1.2871,  1.7148, -1.7119],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0171,  0.0298,  0.0529,  ...,  0.0262, -0.0385, -0.0563],
        [-0.0063,  0.0059,  0.0215,  ...,  0.0051, -0.0037,  0.0001],
        [-0.0153, -0.0299,  0.0273,  ..., -0.0204, -0.0214,  0.0279],
        ...,
        [ 0.0174, -0.0167, -0.0143,  ...,  0.0225,  0.0100, -0.0038],
        [ 0.0201,  0.0354,  0.0011,  ...,  0.0188,  0.0656, -0.0060],
        [ 0.0055, -0.0190, -0.0079,  ..., -0.0332, -0.0391, -0.0122]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 5.8438, -1.3672,  1.7949,  ..., -1.2998,  1.6641, -1.4766]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 20:47:16 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A wolf is a member of a pack
A elephant is a member of a herd
A sheep is a member of a flock
A soldier is a member of a army
A secretary is a member of a staff
A listener is a member of a audience
A flower is a member of a bouquet
A calf is a member of a
2024-07-31 20:47:17 root INFO     [order_1_approx] starting weight calculation for A soldier is a member of a army
A elephant is a member of a herd
A flower is a member of a bouquet
A calf is a member of a cattle
A sheep is a member of a flock
A wolf is a member of a pack
A secretary is a member of a staff
A listener is a member of a
2024-07-31 20:47:17 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-07-31 20:50:21 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0263, -0.0857, -0.1219,  ...,  0.0351,  0.0191, -0.1068],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.8018, -4.8750,  2.8008,  ...,  1.3242, -1.8828, -3.1582],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0112, -0.0234, -0.0030,  ...,  0.0435,  0.0012,  0.0285],
        [-0.0431,  0.0728, -0.0011,  ...,  0.0141,  0.0136, -0.0160],
        [-0.0067, -0.0033, -0.0025,  ..., -0.0152,  0.0173,  0.0198],
        ...,
        [ 0.0160,  0.0077, -0.0079,  ...,  0.0287,  0.0135, -0.0152],
        [-0.0077, -0.0006, -0.0190,  ..., -0.0247,  0.0285,  0.0158],
        [ 0.0369, -0.0144, -0.0238,  ..., -0.0192, -0.0012, -0.0222]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.9375, -4.7695,  2.7207,  ...,  1.2002, -1.6904, -3.4062]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 20:50:22 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A soldier is a member of a army
A elephant is a member of a herd
A flower is a member of a bouquet
A calf is a member of a cattle
A sheep is a member of a flock
A wolf is a member of a pack
A secretary is a member of a staff
A listener is a member of a
2024-07-31 20:50:22 root INFO     [order_1_approx] starting weight calculation for A calf is a member of a cattle
A flower is a member of a bouquet
A sheep is a member of a flock
A secretary is a member of a staff
A listener is a member of a audience
A wolf is a member of a pack
A elephant is a member of a herd
A soldier is a member of a
2024-07-31 20:50:22 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-07-31 20:53:28 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1509,  0.1160, -0.2627,  ...,  0.0208, -0.1096,  0.1047],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.9795, -6.4023,  3.0508,  ..., -2.6230,  2.1680, -4.6250],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0181, -0.0075, -0.0141,  ...,  0.0115, -0.0071, -0.0235],
        [-0.0031,  0.0047,  0.0017,  ..., -0.0042,  0.0309, -0.0003],
        [-0.0151, -0.0097,  0.0149,  ..., -0.0155,  0.0036, -0.0090],
        ...,
        [ 0.0287,  0.0167,  0.0042,  ...,  0.0125,  0.0340, -0.0038],
        [-0.0054,  0.0210,  0.0005,  ..., -0.0054, -0.0236,  0.0099],
        [ 0.0096, -0.0191, -0.0007,  ..., -0.0136,  0.0191, -0.0009]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.0752, -6.0938,  3.1621,  ..., -2.3984,  2.1660, -4.4961]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 20:53:30 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A calf is a member of a cattle
A flower is a member of a bouquet
A sheep is a member of a flock
A secretary is a member of a staff
A listener is a member of a audience
A wolf is a member of a pack
A elephant is a member of a herd
A soldier is a member of a
2024-07-31 20:53:30 root INFO     total operator prediction time: 1492.326248884201 seconds
2024-07-31 20:53:30 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on noun - plural_irreg
2024-07-31 20:53:30 root INFO     building operator noun - plural_irreg
2024-07-31 20:53:30 root INFO     [order_1_approx] starting weight calculation for The plural form of county is counties
The plural form of activity is activities
The plural form of wife is wives
The plural form of ability is abilities
The plural form of business is businesses
The plural form of security is securities
The plural form of opportunity is opportunities
The plural form of secretary is
2024-07-31 20:53:30 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-07-31 20:56:36 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0689, -0.1038, -0.1631,  ...,  0.0652, -0.0475,  0.0251],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.4336, -1.2275,  2.8320,  ..., -1.2500, -1.2266, -3.4980],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0438, -0.0468, -0.0535,  ...,  0.0524,  0.0702, -0.0297],
        [ 0.0456, -0.0109, -0.0926,  ...,  0.0764,  0.0555, -0.0673],
        [ 0.0578, -0.0087, -0.0219,  ...,  0.0227, -0.0221, -0.0476],
        ...,
        [ 0.0152, -0.0014, -0.0533,  ...,  0.0832,  0.0676, -0.1113],
        [-0.0321,  0.0598,  0.0236,  ..., -0.0717, -0.0548,  0.0364],
        [ 0.0933, -0.0715, -0.0748,  ...,  0.1285,  0.0953, -0.1567]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.9531,  0.5518,  2.9102,  ...,  0.4336, -2.5547, -0.9570]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 20:56:36 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of county is counties
The plural form of activity is activities
The plural form of wife is wives
The plural form of ability is abilities
The plural form of business is businesses
The plural form of security is securities
The plural form of opportunity is opportunities
The plural form of secretary is
2024-07-31 20:56:37 root INFO     [order_1_approx] starting weight calculation for The plural form of wife is wives
The plural form of opportunity is opportunities
The plural form of secretary is secretaries
The plural form of county is counties
The plural form of ability is abilities
The plural form of business is businesses
The plural form of activity is activities
The plural form of security is
2024-07-31 20:56:37 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-07-31 20:59:36 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0652,  0.0133,  0.0553,  ...,  0.0665,  0.0042, -0.0194],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.1011, -1.7598,  1.5635,  ...,  0.4160, -2.5508, -4.9219],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0136, -0.0261, -0.0106,  ..., -0.0452, -0.0576, -0.0065],
        [-0.0058, -0.0068,  0.0370,  ...,  0.0099,  0.0362,  0.0340],
        [ 0.0588,  0.0130,  0.0033,  ..., -0.0230,  0.0146,  0.0185],
        ...,
        [ 0.0068,  0.0319,  0.0135,  ..., -0.0131, -0.0241, -0.0229],
        [-0.0118,  0.0455,  0.0313,  ...,  0.0026,  0.0221, -0.0336],
        [ 0.0209, -0.0833, -0.0024,  ...,  0.0486, -0.0205, -0.0156]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.1636, -0.7295,  1.9424,  ..., -0.1606, -3.2148, -3.6504]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 20:59:37 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of wife is wives
The plural form of opportunity is opportunities
The plural form of secretary is secretaries
The plural form of county is counties
The plural form of ability is abilities
The plural form of business is businesses
The plural form of activity is activities
The plural form of security is
2024-07-31 20:59:37 root INFO     [order_1_approx] starting weight calculation for The plural form of opportunity is opportunities
The plural form of wife is wives
The plural form of county is counties
The plural form of secretary is secretaries
The plural form of security is securities
The plural form of ability is abilities
The plural form of business is businesses
The plural form of activity is
2024-07-31 20:59:37 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-07-31 21:02:44 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0582,  0.0257, -0.0970,  ..., -0.0107, -0.1656, -0.1171],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.4121, -0.4790,  1.2676,  ..., -0.3044, -0.1543, -2.2441],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0306,  0.0111, -0.0602,  ...,  0.0143, -0.0021,  0.0612],
        [-0.0294,  0.0275,  0.0232,  ...,  0.0432, -0.0155,  0.0224],
        [-0.0464,  0.0047, -0.0271,  ...,  0.0097, -0.0079, -0.0175],
        ...,
        [-0.0011, -0.0141,  0.0539,  ...,  0.0421,  0.0612, -0.0935],
        [-0.0328, -0.0185, -0.1051,  ..., -0.0400, -0.0392,  0.0193],
        [ 0.0049, -0.0184,  0.0154,  ...,  0.0001,  0.0022, -0.0261]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.3008, -0.3906,  1.3105,  ...,  0.4226, -1.2246, -1.6465]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 21:02:45 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of opportunity is opportunities
The plural form of wife is wives
The plural form of county is counties
The plural form of secretary is secretaries
The plural form of security is securities
The plural form of ability is abilities
The plural form of business is businesses
The plural form of activity is
2024-07-31 21:02:45 root INFO     [order_1_approx] starting weight calculation for The plural form of activity is activities
The plural form of security is securities
The plural form of ability is abilities
The plural form of opportunity is opportunities
The plural form of secretary is secretaries
The plural form of county is counties
The plural form of business is businesses
The plural form of wife is
2024-07-31 21:02:45 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-07-31 21:05:52 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0577,  0.0577, -0.1335,  ..., -0.0504, -0.0344, -0.1143],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.6562, -3.1914,  1.7354,  ..., -0.9438, -0.1201,  1.4600],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0187,  0.0013, -0.0191,  ..., -0.0411,  0.0187, -0.0122],
        [ 0.0054, -0.0217,  0.0257,  ...,  0.0421,  0.0253,  0.0088],
        [ 0.0176,  0.0009,  0.0367,  ...,  0.0135,  0.0623,  0.0250],
        ...,
        [ 0.0101,  0.0505,  0.0072,  ...,  0.0165,  0.0061, -0.0187],
        [-0.0521,  0.0419, -0.0207,  ..., -0.0320,  0.0078,  0.0051],
        [ 0.0125, -0.0034,  0.0019,  ...,  0.0315, -0.0009, -0.0209]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.9082, -2.3457,  1.8467,  ..., -1.1396, -0.9897,  1.2461]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 21:05:53 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of activity is activities
The plural form of security is securities
The plural form of ability is abilities
The plural form of opportunity is opportunities
The plural form of secretary is secretaries
The plural form of county is counties
The plural form of business is businesses
The plural form of wife is
2024-07-31 21:05:53 root INFO     [order_1_approx] starting weight calculation for The plural form of wife is wives
The plural form of county is counties
The plural form of security is securities
The plural form of activity is activities
The plural form of business is businesses
The plural form of secretary is secretaries
The plural form of ability is abilities
The plural form of opportunity is
2024-07-31 21:05:53 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-07-31 21:08:59 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0206,  0.0304,  0.1256,  ...,  0.0336, -0.0804, -0.0502],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.2246,  0.4866, -0.5601,  ..., -0.2310, -1.5947, -0.3047],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0027, -0.0061, -0.0013,  ..., -0.0020,  0.0055, -0.0128],
        [ 0.0063,  0.0394,  0.0193,  ...,  0.0262, -0.0379,  0.0203],
        [ 0.0150,  0.0025, -0.0198,  ..., -0.0403,  0.0127, -0.0522],
        ...,
        [-0.0135,  0.0163, -0.0056,  ...,  0.0108, -0.0232, -0.0055],
        [ 0.0017, -0.0021,  0.0045,  ...,  0.0085,  0.0083,  0.0317],
        [ 0.0089, -0.0292,  0.0312,  ...,  0.0215, -0.0073,  0.0099]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.2240,  0.3057,  0.3047,  ..., -0.7139, -2.4688, -0.6782]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 21:09:00 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of wife is wives
The plural form of county is counties
The plural form of security is securities
The plural form of activity is activities
The plural form of business is businesses
The plural form of secretary is secretaries
The plural form of ability is abilities
The plural form of opportunity is
2024-07-31 21:09:00 root INFO     [order_1_approx] starting weight calculation for The plural form of ability is abilities
The plural form of wife is wives
The plural form of secretary is secretaries
The plural form of activity is activities
The plural form of opportunity is opportunities
The plural form of business is businesses
The plural form of security is securities
The plural form of county is
2024-07-31 21:09:00 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-07-31 21:12:06 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0073,  0.0310, -0.0867,  ..., -0.0728,  0.0566, -0.0404],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.4258, -4.3594,  3.0312,  ..., -2.2227,  2.6992, -3.3086],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0232, -0.0649,  0.0469,  ...,  0.0796,  0.0405,  0.0165],
        [-0.0574,  0.0203, -0.0384,  ...,  0.0477,  0.0129,  0.0172],
        [ 0.0031,  0.0222, -0.0283,  ...,  0.0333, -0.0249,  0.0208],
        ...,
        [-0.0234,  0.0764, -0.0737,  ..., -0.0193,  0.0052,  0.0037],
        [-0.0016,  0.0056, -0.0115,  ..., -0.0950, -0.0178, -0.0285],
        [-0.0393,  0.0098,  0.0082,  ...,  0.0990,  0.0301,  0.0212]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.0156, -3.7324,  2.8301,  ..., -2.9414,  0.9785, -1.9053]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 21:12:07 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of ability is abilities
The plural form of wife is wives
The plural form of secretary is secretaries
The plural form of activity is activities
The plural form of opportunity is opportunities
The plural form of business is businesses
The plural form of security is securities
The plural form of county is
2024-07-31 21:12:07 root INFO     [order_1_approx] starting weight calculation for The plural form of county is counties
The plural form of opportunity is opportunities
The plural form of secretary is secretaries
The plural form of activity is activities
The plural form of business is businesses
The plural form of security is securities
The plural form of wife is wives
The plural form of ability is
2024-07-31 21:12:07 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-07-31 21:15:12 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0049,  0.0700,  0.1067,  ..., -0.0472, -0.0593, -0.0803],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.0000, -0.9897,  0.9321,  ..., -0.7104, -2.5430, -1.1074],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-5.5603e-02, -3.0090e-02, -6.8893e-03,  ..., -1.2329e-02,
          2.2522e-02,  6.9160e-03],
        [-1.8616e-03,  7.3425e-02, -4.1885e-03,  ..., -1.3901e-02,
          5.2612e-02,  3.9490e-02],
        [ 5.1117e-03,  1.2245e-02,  4.8706e-02,  ..., -1.5747e-02,
         -4.2023e-02, -7.8918e-02],
        ...,
        [ 1.7914e-02,  7.1228e-02,  5.7800e-02,  ..., -4.6921e-03,
          3.6224e-02,  2.2621e-03],
        [ 6.7017e-02, -7.3910e-06,  6.0669e-02,  ...,  2.9114e-02,
          6.0272e-04, -9.7778e-02],
        [ 1.2680e-02, -2.8259e-02,  8.0750e-02,  ...,  1.0303e-01,
          3.0487e-02, -1.2866e-01]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.5137, -0.8584,  1.6855,  ..., -1.2725, -2.3457,  0.3135]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 21:15:13 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of county is counties
The plural form of opportunity is opportunities
The plural form of secretary is secretaries
The plural form of activity is activities
The plural form of business is businesses
The plural form of security is securities
The plural form of wife is wives
The plural form of ability is
2024-07-31 21:15:13 root INFO     [order_1_approx] starting weight calculation for The plural form of opportunity is opportunities
The plural form of activity is activities
The plural form of secretary is secretaries
The plural form of ability is abilities
The plural form of wife is wives
The plural form of county is counties
The plural form of security is securities
The plural form of business is
2024-07-31 21:15:13 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-07-31 21:18:18 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0339, -0.0097, -0.0004,  ..., -0.0348, -0.0276, -0.1191],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.5078, -2.1484, -0.6401,  ...,  0.5737,  0.2903, -2.0391],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0312, -0.0133, -0.0066,  ...,  0.0113, -0.0070, -0.0166],
        [ 0.0023, -0.0037,  0.0264,  ...,  0.0310, -0.0100,  0.0078],
        [-0.0016, -0.0008, -0.0045,  ...,  0.0184, -0.0090, -0.0156],
        ...,
        [ 0.0038,  0.0226, -0.0050,  ...,  0.0245, -0.0167, -0.0193],
        [-0.0099, -0.0078, -0.0243,  ..., -0.0384,  0.0553,  0.0266],
        [-0.0144,  0.0029,  0.0106,  ...,  0.0502, -0.0114, -0.0070]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.3711, -1.9746, -0.2839,  ...,  0.6401, -0.5361, -1.5332]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 21:18:19 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of opportunity is opportunities
The plural form of activity is activities
The plural form of secretary is secretaries
The plural form of ability is abilities
The plural form of wife is wives
The plural form of county is counties
The plural form of security is securities
The plural form of business is
2024-07-31 21:18:19 root INFO     total operator prediction time: 1489.2059967517853 seconds
2024-07-31 21:18:19 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on Ving - verb_inf
2024-07-31 21:18:19 root INFO     building operator Ving - verb_inf
2024-07-31 21:18:19 root INFO     [order_1_approx] starting weight calculation for spending is the active form of spend
following is the active form of follow
enjoying is the active form of enjoy
expecting is the active form of expect
representing is the active form of represent
achieving is the active form of achieve
remaining is the active form of remain
appearing is the active form of
2024-07-31 21:18:19 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-07-31 21:21:27 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0500,  0.1307, -0.0014,  ..., -0.0710,  0.1396, -0.0426],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.1543, -3.4902, -0.4697,  ...,  4.2656, -3.1367, -2.5410],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0074, -0.0141, -0.0024,  ...,  0.0048,  0.0018,  0.0142],
        [-0.0089,  0.0320, -0.0178,  ..., -0.0061,  0.0335, -0.0233],
        [-0.0083, -0.0034,  0.0154,  ...,  0.0196, -0.0175, -0.0153],
        ...,
        [ 0.0043, -0.0154, -0.0051,  ..., -0.0058, -0.0039, -0.0100],
        [ 0.0302, -0.0103, -0.0073,  ..., -0.0195, -0.0006, -0.0003],
        [ 0.0083, -0.0116, -0.0193,  ...,  0.0004,  0.0123,  0.0030]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.5293, -3.4277, -0.4856,  ...,  4.4883, -3.1875, -2.3828]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 21:21:28 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for spending is the active form of spend
following is the active form of follow
enjoying is the active form of enjoy
expecting is the active form of expect
representing is the active form of represent
achieving is the active form of achieve
remaining is the active form of remain
appearing is the active form of
2024-07-31 21:21:28 root INFO     [order_1_approx] starting weight calculation for achieving is the active form of achieve
representing is the active form of represent
appearing is the active form of appear
following is the active form of follow
expecting is the active form of expect
enjoying is the active form of enjoy
remaining is the active form of remain
spending is the active form of
2024-07-31 21:21:28 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-07-31 21:24:30 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0124,  0.1090,  0.0864,  ...,  0.0529, -0.1096, -0.0591],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.8838, -2.2109, -3.0254,  ...,  0.8833, -0.9316, -2.2695],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0089, -0.0058, -0.0040,  ..., -0.0270, -0.0149, -0.0205],
        [-0.0010,  0.0348, -0.0038,  ..., -0.0139,  0.0031,  0.0007],
        [ 0.0047, -0.0081,  0.0103,  ..., -0.0103, -0.0080,  0.0012],
        ...,
        [-0.0062, -0.0117, -0.0107,  ...,  0.0183, -0.0018,  0.0214],
        [ 0.0339,  0.0148,  0.0035,  ..., -0.0210,  0.0032,  0.0053],
        [-0.0002,  0.0031, -0.0063,  ..., -0.0100,  0.0159, -0.0043]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.5137, -1.8945, -2.9180,  ...,  1.0645, -0.4761, -2.2480]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 21:24:31 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for achieving is the active form of achieve
representing is the active form of represent
appearing is the active form of appear
following is the active form of follow
expecting is the active form of expect
enjoying is the active form of enjoy
remaining is the active form of remain
spending is the active form of
2024-07-31 21:24:32 root INFO     [order_1_approx] starting weight calculation for appearing is the active form of appear
spending is the active form of spend
representing is the active form of represent
achieving is the active form of achieve
enjoying is the active form of enjoy
following is the active form of follow
remaining is the active form of remain
expecting is the active form of
2024-07-31 21:24:32 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-07-31 21:27:35 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0964,  0.1876, -0.0408,  ..., -0.0428, -0.1895, -0.0139],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.9199, -3.4199, -1.4648,  ...,  0.7026, -2.2578, -3.0371],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-1.2184e-02, -8.1863e-03,  2.4963e-02,  ..., -6.5308e-03,
         -7.1907e-03,  2.3590e-02],
        [ 3.6812e-03,  3.0457e-02, -1.1124e-02,  ...,  1.1375e-02,
          2.7924e-02, -3.6713e-02],
        [ 8.4534e-03, -1.2121e-03, -2.0416e-02,  ..., -1.5244e-02,
         -1.9547e-02,  2.3327e-03],
        ...,
        [ 1.8120e-05, -1.0178e-02,  2.2537e-02,  ...,  1.3802e-02,
         -7.1945e-03,  1.5259e-05],
        [ 2.3285e-02, -5.2681e-03, -2.4689e-02,  ..., -1.3229e-02,
          6.2294e-03, -3.1403e-02],
        [-3.0174e-03,  1.6623e-03, -9.5978e-03,  ..., -1.6737e-04,
          4.0627e-04, -7.9269e-03]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.9414, -3.3555, -1.4678,  ...,  0.5469, -2.3066, -3.2441]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 21:27:36 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for appearing is the active form of appear
spending is the active form of spend
representing is the active form of represent
achieving is the active form of achieve
enjoying is the active form of enjoy
following is the active form of follow
remaining is the active form of remain
expecting is the active form of
2024-07-31 21:27:37 root INFO     [order_1_approx] starting weight calculation for remaining is the active form of remain
following is the active form of follow
spending is the active form of spend
appearing is the active form of appear
expecting is the active form of expect
representing is the active form of represent
achieving is the active form of achieve
enjoying is the active form of
2024-07-31 21:27:37 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-07-31 21:30:38 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1609,  0.1650, -0.1064,  ...,  0.0537, -0.1194,  0.0174],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.2168, -3.0859, -1.0234,  ...,  0.8755, -1.7695, -2.7051],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0104, -0.0019, -0.0071,  ..., -0.0182,  0.0207,  0.0035],
        [-0.0129,  0.0126, -0.0248,  ...,  0.0008,  0.0067, -0.0122],
        [ 0.0212, -0.0032,  0.0016,  ..., -0.0126, -0.0087, -0.0084],
        ...,
        [-0.0063, -0.0093, -0.0126,  ..., -0.0006,  0.0025, -0.0050],
        [ 0.0117,  0.0006, -0.0078,  ..., -0.0035, -0.0200,  0.0078],
        [ 0.0037,  0.0035, -0.0012,  ...,  0.0004,  0.0014, -0.0042]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.1111, -2.8320, -1.1875,  ...,  0.7905, -1.8701, -2.9355]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 21:30:39 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for remaining is the active form of remain
following is the active form of follow
spending is the active form of spend
appearing is the active form of appear
expecting is the active form of expect
representing is the active form of represent
achieving is the active form of achieve
enjoying is the active form of
2024-07-31 21:30:40 root INFO     [order_1_approx] starting weight calculation for representing is the active form of represent
enjoying is the active form of enjoy
appearing is the active form of appear
spending is the active form of spend
expecting is the active form of expect
achieving is the active form of achieve
remaining is the active form of remain
following is the active form of
2024-07-31 21:30:40 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-07-31 21:33:41 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1855,  0.0362,  0.0578,  ..., -0.0176,  0.0155,  0.0265],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.9570, -3.3008,  1.7578,  ...,  1.8350, -2.4219, -2.3027],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0072, -0.0092,  0.0008,  ...,  0.0078,  0.0077,  0.0127],
        [-0.0220,  0.0236,  0.0114,  ...,  0.0146, -0.0055, -0.0055],
        [-0.0015,  0.0027,  0.0022,  ..., -0.0132, -0.0165, -0.0060],
        ...,
        [-0.0028, -0.0302, -0.0121,  ...,  0.0006, -0.0087,  0.0108],
        [ 0.0246, -0.0121,  0.0075,  ...,  0.0253, -0.0132, -0.0327],
        [ 0.0082, -0.0018, -0.0055,  ..., -0.0186, -0.0017,  0.0016]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.9219, -3.2656,  1.6865,  ...,  1.9199, -2.4219, -2.6562]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 21:33:42 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for representing is the active form of represent
enjoying is the active form of enjoy
appearing is the active form of appear
spending is the active form of spend
expecting is the active form of expect
achieving is the active form of achieve
remaining is the active form of remain
following is the active form of
2024-07-31 21:33:42 root INFO     [order_1_approx] starting weight calculation for enjoying is the active form of enjoy
expecting is the active form of expect
representing is the active form of represent
following is the active form of follow
remaining is the active form of remain
spending is the active form of spend
appearing is the active form of appear
achieving is the active form of
2024-07-31 21:33:42 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-07-31 21:36:49 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1228,  0.3098, -0.1000,  ...,  0.0724, -0.1571,  0.1343],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.9727, -2.2988, -0.9526,  ...,  0.5967, -2.8887, -2.6680],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0019, -0.0098, -0.0146,  ..., -0.0129, -0.0075,  0.0246],
        [ 0.0121,  0.0226, -0.0098,  ...,  0.0101, -0.0058, -0.0179],
        [ 0.0048,  0.0132,  0.0081,  ..., -0.0046, -0.0117, -0.0079],
        ...,
        [ 0.0189, -0.0066, -0.0096,  ...,  0.0435,  0.0206, -0.0082],
        [ 0.0403,  0.0135,  0.0243,  ..., -0.0088,  0.0282, -0.0258],
        [ 0.0038, -0.0030, -0.0028,  ..., -0.0010, -0.0100,  0.0023]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.8105, -2.1094, -1.0234,  ...,  0.7949, -2.4785, -2.6328]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 21:36:50 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for enjoying is the active form of enjoy
expecting is the active form of expect
representing is the active form of represent
following is the active form of follow
remaining is the active form of remain
spending is the active form of spend
appearing is the active form of appear
achieving is the active form of
2024-07-31 21:36:50 root INFO     [order_1_approx] starting weight calculation for spending is the active form of spend
expecting is the active form of expect
appearing is the active form of appear
following is the active form of follow
enjoying is the active form of enjoy
achieving is the active form of achieve
remaining is the active form of remain
representing is the active form of
2024-07-31 21:36:50 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-07-31 21:39:55 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1135,  0.1462, -0.1396,  ...,  0.0618, -0.0239, -0.0875],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.1680, -3.0332,  1.4365,  ...,  1.8496, -2.7148, -3.2676],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0053, -0.0071, -0.0181,  ..., -0.0305,  0.0140,  0.0220],
        [-0.0151,  0.0100,  0.0256,  ...,  0.0217, -0.0040, -0.0063],
        [-0.0060,  0.0099, -0.0098,  ..., -0.0104,  0.0011, -0.0165],
        ...,
        [ 0.0242, -0.0090, -0.0075,  ...,  0.0445, -0.0247,  0.0055],
        [ 0.0269,  0.0154, -0.0323,  ..., -0.0293,  0.0077, -0.0092],
        [ 0.0114, -0.0021, -0.0151,  ...,  0.0046, -0.0067,  0.0083]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.0176, -2.7246,  1.7002,  ...,  1.8535, -3.4551, -3.4355]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 21:39:56 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for spending is the active form of spend
expecting is the active form of expect
appearing is the active form of appear
following is the active form of follow
enjoying is the active form of enjoy
achieving is the active form of achieve
remaining is the active form of remain
representing is the active form of
2024-07-31 21:39:56 root INFO     [order_1_approx] starting weight calculation for representing is the active form of represent
spending is the active form of spend
appearing is the active form of appear
expecting is the active form of expect
enjoying is the active form of enjoy
achieving is the active form of achieve
following is the active form of follow
remaining is the active form of
2024-07-31 21:39:56 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-07-31 21:43:04 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1538,  0.0910,  0.1514,  ..., -0.1504, -0.1285, -0.0682],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.6201, -3.5820, -0.8154,  ..., -1.1289, -0.3184, -2.8750],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0084, -0.0125, -0.0121,  ...,  0.0076,  0.0214,  0.0170],
        [-0.0153,  0.0183,  0.0086,  ...,  0.0135,  0.0236, -0.0111],
        [-0.0143,  0.0003,  0.0095,  ..., -0.0175, -0.0255,  0.0083],
        ...,
        [ 0.0014, -0.0126,  0.0029,  ...,  0.0217, -0.0171,  0.0270],
        [ 0.0224, -0.0044, -0.0085,  ...,  0.0084,  0.0065, -0.0128],
        [ 0.0061, -0.0107, -0.0258,  ..., -0.0144, -0.0226,  0.0026]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.6094, -3.1934, -0.9419,  ..., -1.0752, -0.2817, -3.2891]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 21:43:05 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for representing is the active form of represent
spending is the active form of spend
appearing is the active form of appear
expecting is the active form of expect
enjoying is the active form of enjoy
achieving is the active form of achieve
following is the active form of follow
remaining is the active form of
2024-07-31 21:43:05 root INFO     total operator prediction time: 1486.063467502594 seconds
2024-07-31 21:43:05 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on verb_Ving - Ved
2024-07-31 21:43:05 root INFO     building operator verb_Ving - Ved
2024-07-31 21:43:05 root INFO     [order_1_approx] starting weight calculation for After something is becoming, it has became
After something is requiring, it has required
After something is publishing, it has published
After something is uniting, it has united
After something is describing, it has described
After something is appearing, it has appeared
After something is applying, it has applied
After something is performing, it has
2024-07-31 21:43:05 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-07-31 21:46:12 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0909, -0.0414,  0.0434,  ...,  0.0089, -0.1094, -0.1116],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.0225, -1.0645,  3.5117,  ..., -2.5371, -2.3848, -0.9053],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0011,  0.0450,  0.0079,  ..., -0.0251, -0.0201,  0.0326],
        [-0.0274,  0.0582, -0.0579,  ...,  0.0050,  0.0402,  0.0258],
        [ 0.0366,  0.0100, -0.0167,  ..., -0.0333, -0.0203, -0.0055],
        ...,
        [-0.0116, -0.0291, -0.0139,  ..., -0.0674,  0.0699, -0.0090],
        [ 0.0640,  0.0020,  0.0300,  ..., -0.0050,  0.0507,  0.0100],
        [-0.0081, -0.0258, -0.0390,  ...,  0.0477,  0.0173, -0.0659]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.4111, -1.1289,  3.9160,  ..., -2.6367, -2.1172, -1.5830]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 21:46:13 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for After something is becoming, it has became
After something is requiring, it has required
After something is publishing, it has published
After something is uniting, it has united
After something is describing, it has described
After something is appearing, it has appeared
After something is applying, it has applied
After something is performing, it has
2024-07-31 21:46:14 root INFO     [order_1_approx] starting weight calculation for After something is publishing, it has published
After something is performing, it has performed
After something is uniting, it has united
After something is requiring, it has required
After something is applying, it has applied
After something is appearing, it has appeared
After something is becoming, it has became
After something is describing, it has
2024-07-31 21:46:14 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-07-31 21:49:16 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0405,  0.0620,  0.1482,  ...,  0.0609,  0.1689, -0.0575],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.8184, -2.1816,  5.1875,  ...,  0.0190, -1.6006, -3.3750],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0219, -0.0097, -0.0304,  ..., -0.0059,  0.0154, -0.0032],
        [ 0.0178,  0.0379, -0.0360,  ...,  0.0064,  0.0393,  0.0061],
        [ 0.0368,  0.0190,  0.0149,  ..., -0.0223, -0.0747, -0.0187],
        ...,
        [ 0.0125,  0.0071, -0.0336,  ...,  0.0446,  0.0617, -0.0154],
        [ 0.0867, -0.0531, -0.0425,  ...,  0.0265,  0.0802,  0.0256],
        [-0.0112, -0.0419, -0.0095,  ...,  0.0130, -0.0215,  0.0067]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.2109, -2.4922,  5.4531,  ..., -0.2837, -2.2812, -3.7070]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 21:49:17 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for After something is publishing, it has published
After something is performing, it has performed
After something is uniting, it has united
After something is requiring, it has required
After something is applying, it has applied
After something is appearing, it has appeared
After something is becoming, it has became
After something is describing, it has
2024-07-31 21:49:17 root INFO     [order_1_approx] starting weight calculation for After something is becoming, it has became
After something is performing, it has performed
After something is describing, it has described
After something is applying, it has applied
After something is uniting, it has united
After something is appearing, it has appeared
After something is publishing, it has published
After something is requiring, it has
2024-07-31 21:49:17 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-07-31 21:52:22 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0530,  0.0115, -0.0161,  ...,  0.0499, -0.0490, -0.1232],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.0234, -0.0879,  1.7930,  ..., -1.7852, -2.4023, -1.5762],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0020, -0.0069, -0.0039,  ...,  0.0060,  0.0447,  0.0042],
        [-0.0981, -0.0162, -0.0505,  ..., -0.0013, -0.0069,  0.0461],
        [ 0.0213,  0.0236,  0.0144,  ..., -0.0374, -0.0004,  0.0321],
        ...,
        [ 0.0258, -0.0213, -0.0450,  ..., -0.0301,  0.0624,  0.0112],
        [ 0.1561, -0.0181,  0.0522,  ...,  0.0047,  0.0775,  0.0436],
        [-0.1021,  0.0816,  0.0581,  ...,  0.0105, -0.0718,  0.0143]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.9404, -0.3289,  2.0898,  ..., -1.6348, -2.5996, -2.7266]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 21:52:23 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for After something is becoming, it has became
After something is performing, it has performed
After something is describing, it has described
After something is applying, it has applied
After something is uniting, it has united
After something is appearing, it has appeared
After something is publishing, it has published
After something is requiring, it has
2024-07-31 21:52:23 root INFO     [order_1_approx] starting weight calculation for After something is uniting, it has united
After something is performing, it has performed
After something is appearing, it has appeared
After something is describing, it has described
After something is applying, it has applied
After something is becoming, it has became
After something is requiring, it has required
After something is publishing, it has
2024-07-31 21:52:23 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-07-31 21:55:27 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([0.1044, 0.0695, 0.0940,  ..., 0.0463, 0.0360, 0.1107], device='cuda:1',
       dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.8672, -3.1523,  0.7612,  ..., -2.6699, -2.0508,  0.7012],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 1.7731e-02,  3.8818e-02, -5.9967e-03,  ...,  1.2764e-02,
          1.9684e-02,  3.5706e-02],
        [ 1.7452e-03, -1.1658e-02, -1.7365e-02,  ...,  3.7689e-02,
          4.7089e-02,  4.9927e-02],
        [ 5.5481e-02, -1.3542e-04, -3.5248e-02,  ...,  1.5182e-03,
         -6.9458e-02,  2.0981e-05],
        ...,
        [-5.8533e-02,  1.3275e-02, -1.3733e-02,  ..., -6.1798e-02,
         -7.5722e-03, -6.2988e-02],
        [ 1.3538e-01, -1.2932e-02, -5.7190e-02,  ...,  7.2021e-02,
          4.2816e-02,  7.3669e-02],
        [-9.0515e-02,  6.7688e-02,  1.8005e-02,  ..., -2.7390e-03,
         -9.4727e-02, -9.8328e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.3418, -2.5918,  0.6006,  ..., -2.4062, -1.3984, -0.4209]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 21:55:28 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for After something is uniting, it has united
After something is performing, it has performed
After something is appearing, it has appeared
After something is describing, it has described
After something is applying, it has applied
After something is becoming, it has became
After something is requiring, it has required
After something is publishing, it has
2024-07-31 21:55:28 root INFO     [order_1_approx] starting weight calculation for After something is becoming, it has became
After something is describing, it has described
After something is applying, it has applied
After something is requiring, it has required
After something is performing, it has performed
After something is publishing, it has published
After something is uniting, it has united
After something is appearing, it has
2024-07-31 21:55:28 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-07-31 21:58:33 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0241,  0.0397,  0.0863,  ...,  0.0668,  0.0782, -0.1454],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.8135,  0.2291,  1.5137,  ...,  0.1650, -1.8096,  1.1875],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0345, -0.0462, -0.0130,  ...,  0.0793,  0.0834,  0.0293],
        [-0.0635,  0.0885,  0.0171,  ..., -0.0030, -0.0305, -0.0301],
        [ 0.0640,  0.0164,  0.0161,  ..., -0.0044, -0.0144, -0.0263],
        ...,
        [-0.0835,  0.0423, -0.0500,  ..., -0.0275, -0.0138, -0.0265],
        [ 0.1154, -0.0553,  0.0310,  ...,  0.0617,  0.0374, -0.0059],
        [-0.0495,  0.0093,  0.0074,  ...,  0.0244, -0.0511,  0.0221]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.2334, -0.2089,  1.5996,  ...,  0.2581, -1.6719,  0.5498]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 21:58:34 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for After something is becoming, it has became
After something is describing, it has described
After something is applying, it has applied
After something is requiring, it has required
After something is performing, it has performed
After something is publishing, it has published
After something is uniting, it has united
After something is appearing, it has
2024-07-31 21:58:34 root INFO     [order_1_approx] starting weight calculation for After something is becoming, it has became
After something is publishing, it has published
After something is performing, it has performed
After something is requiring, it has required
After something is uniting, it has united
After something is appearing, it has appeared
After something is describing, it has described
After something is applying, it has
2024-07-31 21:58:34 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-07-31 22:01:37 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0237, -0.0512,  0.1090,  ...,  0.1622,  0.0427, -0.0468],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.1660, -0.3486,  0.6289,  ..., -1.3125, -1.6562, -0.0684],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-2.1469e-02, -1.6388e-02,  4.0833e-02,  ..., -2.5558e-03,
         -1.5701e-02,  7.7438e-03],
        [ 1.9531e-02,  4.1321e-02,  3.7384e-04,  ..., -1.7624e-02,
          7.0679e-02,  2.0233e-02],
        [ 1.8631e-02,  3.4302e-02, -1.6785e-02,  ..., -4.5837e-02,
          2.3453e-02,  1.2810e-02],
        ...,
        [-7.6599e-03, -1.9012e-02, -4.6921e-03,  ..., -1.0017e-02,
         -9.1553e-05,  4.9934e-03],
        [ 4.9927e-02,  2.0233e-02, -1.2741e-02,  ...,  4.6509e-02,
          4.8950e-02,  1.0658e-02],
        [-1.6479e-02, -1.3969e-02,  3.8528e-03,  ...,  2.7481e-02,
         -4.2419e-02, -2.7908e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.0930, -0.2764,  0.9951,  ..., -1.1699, -1.5850, -0.8237]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 22:01:38 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for After something is becoming, it has became
After something is publishing, it has published
After something is performing, it has performed
After something is requiring, it has required
After something is uniting, it has united
After something is appearing, it has appeared
After something is describing, it has described
After something is applying, it has
2024-07-31 22:01:39 root INFO     [order_1_approx] starting weight calculation for After something is applying, it has applied
After something is publishing, it has published
After something is requiring, it has required
After something is describing, it has described
After something is appearing, it has appeared
After something is uniting, it has united
After something is performing, it has performed
After something is becoming, it has
2024-07-31 22:01:39 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-07-31 22:04:46 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0193,  0.0435,  0.0474,  ...,  0.1093,  0.0513, -0.0258],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.3457,  0.0312,  2.8242,  ..., -0.4585,  0.9751, -1.4062],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0391,  0.0408,  0.0186,  ...,  0.0585,  0.0956,  0.0019],
        [-0.0162,  0.0504,  0.0152,  ..., -0.0488, -0.0214,  0.0134],
        [-0.0059, -0.0107, -0.0310,  ..., -0.0308, -0.0291,  0.0093],
        ...,
        [-0.0197, -0.0065, -0.0445,  ..., -0.0390, -0.0266,  0.0037],
        [ 0.0170,  0.0160,  0.0211,  ..., -0.0066, -0.0103, -0.0423],
        [-0.0035, -0.0008, -0.0145,  ...,  0.0734,  0.0050, -0.0471]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.0586,  0.1711,  2.6719,  ..., -0.3940,  0.6187, -1.6650]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 22:04:46 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for After something is applying, it has applied
After something is publishing, it has published
After something is requiring, it has required
After something is describing, it has described
After something is appearing, it has appeared
After something is uniting, it has united
After something is performing, it has performed
After something is becoming, it has
2024-07-31 22:04:47 root INFO     [order_1_approx] starting weight calculation for After something is publishing, it has published
After something is becoming, it has became
After something is requiring, it has required
After something is performing, it has performed
After something is applying, it has applied
After something is appearing, it has appeared
After something is describing, it has described
After something is uniting, it has
2024-07-31 22:04:47 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-07-31 22:07:50 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1406, -0.0131, -0.0146,  ...,  0.1226, -0.0835,  0.0057],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.8774, -0.6846,  3.5430,  ..., -0.6826, -0.0439, -0.4678],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0496, -0.0111, -0.0134,  ...,  0.0539,  0.0011,  0.0069],
        [-0.0297,  0.0143,  0.0257,  ..., -0.0374, -0.0197, -0.0119],
        [ 0.0275, -0.0307, -0.0584,  ..., -0.0053, -0.0308, -0.0620],
        ...,
        [ 0.0006,  0.0211,  0.0119,  ..., -0.0673, -0.0073,  0.0325],
        [ 0.0418,  0.0352,  0.0302,  ...,  0.0365,  0.0318,  0.0032],
        [ 0.0111,  0.0350, -0.0056,  ...,  0.0195,  0.0125,  0.0019]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.5908, -0.8228,  3.6992,  ..., -0.6011,  0.3792, -0.5342]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 22:07:51 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for After something is publishing, it has published
After something is becoming, it has became
After something is requiring, it has required
After something is performing, it has performed
After something is applying, it has applied
After something is appearing, it has appeared
After something is describing, it has described
After something is uniting, it has
2024-07-31 22:07:51 root INFO     total operator prediction time: 1485.6143808364868 seconds
2024-07-31 22:07:51 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on verb_inf - Ved
2024-07-31 22:07:51 root INFO     building operator verb_inf - Ved
2024-07-31 22:07:51 root INFO     [order_1_approx] starting weight calculation for If the present form is marry, the past form is married
If the present form is attend, the past form is attended
If the present form is allow, the past form is allowed
If the present form is locate, the past form is located
If the present form is require, the past form is required
If the present form is accept, the past form is accepted
If the present form is achieve, the past form is achieved
If the present form is announce, the past form is
2024-07-31 22:07:51 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-07-31 22:10:57 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0989,  0.2073, -0.0381,  ..., -0.0847, -0.2327, -0.1473],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.4844,  0.0653,  2.6895,  ...,  0.2197, -2.6602,  0.6133],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0424, -0.0240,  0.0056,  ...,  0.0446, -0.0052,  0.0221],
        [-0.0186,  0.0180, -0.0292,  ..., -0.0073, -0.0120, -0.0232],
        [ 0.0067, -0.0230, -0.0254,  ..., -0.0178, -0.0189, -0.0075],
        ...,
        [ 0.0085, -0.0302, -0.0414,  ...,  0.0002, -0.0032,  0.0179],
        [ 0.0060, -0.0227, -0.0110,  ...,  0.0068, -0.0150,  0.0130],
        [ 0.0039,  0.0114,  0.0567,  ...,  0.0098,  0.0196, -0.0014]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.9092,  0.1285,  2.8379,  ...,  0.2512, -2.3438,  0.5723]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 22:10:58 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If the present form is marry, the past form is married
If the present form is attend, the past form is attended
If the present form is allow, the past form is allowed
If the present form is locate, the past form is located
If the present form is require, the past form is required
If the present form is accept, the past form is accepted
If the present form is achieve, the past form is achieved
If the present form is announce, the past form is
2024-07-31 22:10:58 root INFO     [order_1_approx] starting weight calculation for If the present form is locate, the past form is located
If the present form is announce, the past form is announced
If the present form is allow, the past form is allowed
If the present form is marry, the past form is married
If the present form is require, the past form is required
If the present form is accept, the past form is accepted
If the present form is achieve, the past form is achieved
If the present form is attend, the past form is
2024-07-31 22:10:58 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-07-31 22:14:03 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0903,  0.2220, -0.2925,  ..., -0.0273, -0.1156, -0.0134],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.9375,  2.2402,  0.0178,  ..., -0.9014, -4.4688, -0.8906],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-5.9357e-03, -3.5919e-02, -2.1851e-02,  ..., -1.6724e-02,
          2.2919e-02, -6.9656e-03],
        [-1.5022e-02,  3.2410e-02,  2.0645e-02,  ..., -1.7273e-02,
          6.9153e-02,  2.5177e-02],
        [ 2.9617e-02,  8.5602e-03, -3.1342e-02,  ..., -4.1351e-02,
         -4.5410e-02, -8.2703e-03],
        ...,
        [ 1.3626e-02, -2.1637e-02, -2.8343e-03,  ...,  5.2452e-05,
          3.4256e-03, -1.8860e-02],
        [ 3.7048e-02, -1.4008e-02, -3.8971e-02,  ..., -4.9553e-03,
         -9.2407e-02, -5.3467e-02],
        [ 6.4209e-02,  2.2949e-02, -1.8829e-02,  ...,  2.2278e-02,
          2.3346e-02, -4.4373e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.8408,  2.2148,  0.1373,  ..., -0.8086, -4.2070, -0.5508]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 22:14:04 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If the present form is locate, the past form is located
If the present form is announce, the past form is announced
If the present form is allow, the past form is allowed
If the present form is marry, the past form is married
If the present form is require, the past form is required
If the present form is accept, the past form is accepted
If the present form is achieve, the past form is achieved
If the present form is attend, the past form is
2024-07-31 22:14:04 root INFO     [order_1_approx] starting weight calculation for If the present form is attend, the past form is attended
If the present form is locate, the past form is located
If the present form is allow, the past form is allowed
If the present form is require, the past form is required
If the present form is announce, the past form is announced
If the present form is achieve, the past form is achieved
If the present form is accept, the past form is accepted
If the present form is marry, the past form is
2024-07-31 22:14:04 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-07-31 22:17:09 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0804,  0.0184, -0.0504,  ..., -0.0225, -0.1517,  0.1107],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.4121, -2.4609,  1.8721,  ..., -1.1758, -2.5586, -1.0547],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0472,  0.0014,  0.0211,  ...,  0.0140,  0.0305, -0.0088],
        [-0.0316,  0.0315,  0.0016,  ...,  0.0352,  0.0507,  0.0132],
        [-0.0293, -0.0006,  0.0029,  ..., -0.0426, -0.0397, -0.0379],
        ...,
        [ 0.0208,  0.0013,  0.0075,  ...,  0.0025,  0.0051,  0.0273],
        [-0.0282,  0.0016, -0.0149,  ...,  0.0015, -0.0426,  0.0321],
        [-0.0170,  0.0009, -0.0017,  ...,  0.0174,  0.0060,  0.0294]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.7148, -2.7520,  1.6426,  ..., -1.2754, -2.5410, -1.4238]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 22:17:11 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If the present form is attend, the past form is attended
If the present form is locate, the past form is located
If the present form is allow, the past form is allowed
If the present form is require, the past form is required
If the present form is announce, the past form is announced
If the present form is achieve, the past form is achieved
If the present form is accept, the past form is accepted
If the present form is marry, the past form is
2024-07-31 22:17:11 root INFO     [order_1_approx] starting weight calculation for If the present form is achieve, the past form is achieved
If the present form is attend, the past form is attended
If the present form is allow, the past form is allowed
If the present form is require, the past form is required
If the present form is announce, the past form is announced
If the present form is accept, the past form is accepted
If the present form is marry, the past form is married
If the present form is locate, the past form is
2024-07-31 22:17:11 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-07-31 22:20:14 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0099,  0.1301, -0.1670,  ..., -0.0088, -0.0392, -0.0401],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.1401, -1.4609, -1.3086,  ..., -2.2305, -2.1875, -2.0645],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0286, -0.0293, -0.0208,  ...,  0.0279,  0.0531,  0.0226],
        [ 0.0163,  0.0164, -0.0125,  ...,  0.0345,  0.0166, -0.0023],
        [ 0.0591,  0.0064, -0.0115,  ..., -0.0369, -0.0144, -0.0117],
        ...,
        [ 0.0201, -0.0141, -0.0095,  ..., -0.0075,  0.0425,  0.0106],
        [-0.0031,  0.0144, -0.0218,  ..., -0.0430, -0.0549,  0.0098],
        [-0.0017,  0.0609,  0.0320,  ...,  0.0198,  0.0159,  0.0107]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.2859, -1.3457, -1.4629,  ..., -2.0801, -2.0156, -1.8486]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 22:20:15 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If the present form is achieve, the past form is achieved
If the present form is attend, the past form is attended
If the present form is allow, the past form is allowed
If the present form is require, the past form is required
If the present form is announce, the past form is announced
If the present form is accept, the past form is accepted
If the present form is marry, the past form is married
If the present form is locate, the past form is
2024-07-31 22:20:15 root INFO     [order_1_approx] starting weight calculation for If the present form is achieve, the past form is achieved
If the present form is marry, the past form is married
If the present form is announce, the past form is announced
If the present form is accept, the past form is accepted
If the present form is attend, the past form is attended
If the present form is require, the past form is required
If the present form is locate, the past form is located
If the present form is allow, the past form is
2024-07-31 22:20:15 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-07-31 22:23:18 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0780,  0.0701,  0.0349,  ..., -0.0646, -0.0742, -0.1268],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.4277, -2.9102, -0.6426,  ..., -0.7676, -2.7930,  1.1709],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0017, -0.0226, -0.0293,  ...,  0.0006,  0.0142, -0.0525],
        [-0.0011, -0.0167, -0.0296,  ...,  0.0361, -0.0187,  0.0095],
        [ 0.0474, -0.0378, -0.0323,  ..., -0.0138, -0.0333,  0.0504],
        ...,
        [ 0.0433, -0.0271,  0.0175,  ..., -0.0142, -0.0127,  0.0167],
        [ 0.0614, -0.0043, -0.0728,  ...,  0.0299, -0.0016,  0.0845],
        [-0.0024, -0.0017, -0.0053,  ...,  0.0098,  0.0174, -0.0665]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.1895, -2.9785, -0.6738,  ..., -0.6470, -2.9531,  1.8672]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 22:23:18 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If the present form is achieve, the past form is achieved
If the present form is marry, the past form is married
If the present form is announce, the past form is announced
If the present form is accept, the past form is accepted
If the present form is attend, the past form is attended
If the present form is require, the past form is required
If the present form is locate, the past form is located
If the present form is allow, the past form is
2024-07-31 22:23:19 root INFO     [order_1_approx] starting weight calculation for If the present form is announce, the past form is announced
If the present form is marry, the past form is married
If the present form is allow, the past form is allowed
If the present form is attend, the past form is attended
If the present form is require, the past form is required
If the present form is accept, the past form is accepted
If the present form is locate, the past form is located
If the present form is achieve, the past form is
2024-07-31 22:23:19 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-07-31 22:26:22 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0456,  0.0853, -0.1089,  ...,  0.1345, -0.1923,  0.0291],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.1055,  1.3379, -0.4209,  ..., -2.6289, -1.7578, -0.4619],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0590,  0.0131, -0.0307,  ...,  0.0009,  0.0695,  0.0050],
        [-0.0456,  0.0173,  0.0153,  ...,  0.0308, -0.0077,  0.0037],
        [-0.0468,  0.0105, -0.0305,  ..., -0.0500, -0.0327, -0.0235],
        ...,
        [-0.0126,  0.0276, -0.0327,  ..., -0.0301, -0.0066,  0.0275],
        [-0.0462,  0.1062, -0.0775,  ..., -0.0428, -0.0130, -0.0416],
        [-0.0130, -0.0070,  0.0202,  ...,  0.0795, -0.0126, -0.0272]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.2805,  1.1465, -1.1270,  ..., -3.0547, -2.9746, -0.6670]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 22:26:23 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If the present form is announce, the past form is announced
If the present form is marry, the past form is married
If the present form is allow, the past form is allowed
If the present form is attend, the past form is attended
If the present form is require, the past form is required
If the present form is accept, the past form is accepted
If the present form is locate, the past form is located
If the present form is achieve, the past form is
2024-07-31 22:26:23 root INFO     [order_1_approx] starting weight calculation for If the present form is marry, the past form is married
If the present form is attend, the past form is attended
If the present form is locate, the past form is located
If the present form is achieve, the past form is achieved
If the present form is accept, the past form is accepted
If the present form is allow, the past form is allowed
If the present form is announce, the past form is announced
If the present form is require, the past form is
2024-07-31 22:26:23 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-07-31 22:29:28 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0718,  0.0603, -0.1154,  ..., -0.0213, -0.0712, -0.1638],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.7764,  0.8047,  1.3291,  ..., -1.4551, -3.3984, -1.1875],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0446,  0.0307, -0.0113,  ...,  0.0427,  0.0692, -0.0681],
        [-0.0504, -0.0086,  0.0014,  ..., -0.0157, -0.0717, -0.0307],
        [ 0.0201,  0.0015, -0.0003,  ..., -0.0434, -0.0512,  0.0232],
        ...,
        [ 0.0439,  0.0099, -0.0111,  ...,  0.0135,  0.0589,  0.0446],
        [ 0.0598,  0.0022, -0.0103,  ..., -0.0381, -0.0121,  0.0643],
        [-0.0231,  0.0096, -0.0047,  ...,  0.0079, -0.0388, -0.0328]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.7129,  0.4739,  1.4902,  ..., -1.6016, -3.5938, -1.0928]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 22:29:29 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If the present form is marry, the past form is married
If the present form is attend, the past form is attended
If the present form is locate, the past form is located
If the present form is achieve, the past form is achieved
If the present form is accept, the past form is accepted
If the present form is allow, the past form is allowed
If the present form is announce, the past form is announced
If the present form is require, the past form is
2024-07-31 22:29:29 root INFO     [order_1_approx] starting weight calculation for If the present form is announce, the past form is announced
If the present form is marry, the past form is married
If the present form is require, the past form is required
If the present form is achieve, the past form is achieved
If the present form is allow, the past form is allowed
If the present form is attend, the past form is attended
If the present form is locate, the past form is located
If the present form is accept, the past form is
2024-07-31 22:29:29 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-07-31 22:32:34 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0040,  0.1071, -0.1722,  ...,  0.0487, -0.0534, -0.0739],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.8877,  0.8384, -0.8774,  ..., -0.9033, -2.6602,  1.2793],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0497, -0.0397,  0.0382,  ...,  0.0039,  0.0358,  0.0185],
        [-0.0079,  0.0216,  0.0026,  ..., -0.0195, -0.0307, -0.0019],
        [ 0.0500, -0.0075, -0.0267,  ..., -0.0392, -0.0421,  0.0019],
        ...,
        [ 0.0599, -0.0469, -0.0049,  ...,  0.0241,  0.0127, -0.0066],
        [ 0.0591,  0.0077, -0.0663,  ...,  0.0222,  0.0138, -0.0004],
        [ 0.0441, -0.0284,  0.0085,  ...,  0.0099, -0.0086, -0.0708]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.0938,  0.9658, -1.1143,  ..., -0.9004, -3.0938,  1.4717]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 22:32:35 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If the present form is announce, the past form is announced
If the present form is marry, the past form is married
If the present form is require, the past form is required
If the present form is achieve, the past form is achieved
If the present form is allow, the past form is allowed
If the present form is attend, the past form is attended
If the present form is locate, the past form is located
If the present form is accept, the past form is
2024-07-31 22:32:35 root INFO     total operator prediction time: 1483.9530549049377 seconds
2024-07-31 22:32:35 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on verb_inf - 3pSg
2024-07-31 22:32:35 root INFO     building operator verb_inf - 3pSg
2024-07-31 22:32:35 root INFO     [order_1_approx] starting weight calculation for I suggest, he suggests
I prevent, he prevents
I ensure, he ensures
I include, he includes
I agree, he agrees
I remain, he remains
I remember, he remembers
I believe, he
2024-07-31 22:32:35 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-07-31 22:35:38 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0486,  0.2847,  0.0134,  ...,  0.0170, -0.0701,  0.1185],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.2344, -5.3359,  1.0312,  ...,  0.3896, -4.5078,  0.1387],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0232, -0.0044,  0.0091,  ..., -0.0403, -0.0634,  0.0472],
        [-0.0248,  0.0183, -0.0059,  ...,  0.0192,  0.0239, -0.0140],
        [ 0.0107, -0.0064, -0.0259,  ..., -0.0514, -0.0246,  0.0405],
        ...,
        [-0.0045, -0.0074,  0.0369,  ...,  0.0233,  0.0158,  0.0056],
        [-0.0126, -0.0210,  0.0273,  ..., -0.0523, -0.0265, -0.0427],
        [ 0.0100, -0.0264,  0.0398,  ..., -0.0347, -0.0427, -0.0166]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.6641, -5.5039,  0.9609,  ...,  0.3452, -4.7500, -0.1882]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 22:35:39 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for I suggest, he suggests
I prevent, he prevents
I ensure, he ensures
I include, he includes
I agree, he agrees
I remain, he remains
I remember, he remembers
I believe, he
2024-07-31 22:35:39 root INFO     [order_1_approx] starting weight calculation for I suggest, he suggests
I include, he includes
I believe, he believes
I prevent, he prevents
I ensure, he ensures
I remember, he remembers
I agree, he agrees
I remain, he
2024-07-31 22:35:39 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-07-31 22:38:44 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1318,  0.0743,  0.0432,  ..., -0.1252, -0.0399,  0.0276],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.9219, -4.6172, -0.4121,  ..., -2.5820, -3.3848, -0.7305],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0211, -0.0243, -0.0054,  ...,  0.0121,  0.0214,  0.0050],
        [-0.0206,  0.0522,  0.0028,  ...,  0.0170, -0.0067,  0.0222],
        [-0.0104, -0.0083,  0.0164,  ..., -0.0266, -0.0203, -0.0116],
        ...,
        [ 0.0166, -0.0348,  0.0210,  ...,  0.0149, -0.0077,  0.0667],
        [ 0.0490,  0.0391, -0.0137,  ...,  0.0020, -0.0514,  0.0622],
        [ 0.0412,  0.0150,  0.0270,  ...,  0.0087,  0.0008, -0.0014]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.6562, -4.4297, -0.3506,  ..., -2.1250, -2.7793, -0.4385]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 22:38:44 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for I suggest, he suggests
I include, he includes
I believe, he believes
I prevent, he prevents
I ensure, he ensures
I remember, he remembers
I agree, he agrees
I remain, he
2024-07-31 22:38:45 root INFO     [order_1_approx] starting weight calculation for I remember, he remembers
I remain, he remains
I ensure, he ensures
I prevent, he prevents
I believe, he believes
I include, he includes
I agree, he agrees
I suggest, he
2024-07-31 22:38:45 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-07-31 22:41:52 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0415,  0.0950,  0.0644,  ...,  0.0394, -0.0551, -0.0590],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 5.4922, -2.9043, -1.7910,  ...,  0.5518, -6.1133,  1.3633],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0248, -0.0546,  0.0866,  ..., -0.1283, -0.0848, -0.0742],
        [-0.0242,  0.0171, -0.0194,  ..., -0.0225, -0.0356,  0.0029],
        [-0.0456,  0.0222, -0.0097,  ..., -0.0514,  0.0238, -0.0424],
        ...,
        [-0.0287, -0.0511, -0.0005,  ..., -0.0478,  0.0233,  0.0486],
        [-0.0673,  0.1691, -0.0544,  ...,  0.0341, -0.0605,  0.0475],
        [ 0.0251,  0.0761,  0.0396,  ...,  0.0160, -0.0606, -0.0146]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.4844, -3.0234, -2.4590,  ...,  1.1689, -5.9609,  1.5146]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 22:41:53 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for I remember, he remembers
I remain, he remains
I ensure, he ensures
I prevent, he prevents
I believe, he believes
I include, he includes
I agree, he agrees
I suggest, he
2024-07-31 22:41:53 root INFO     [order_1_approx] starting weight calculation for I remember, he remembers
I agree, he agrees
I believe, he believes
I include, he includes
I remain, he remains
I prevent, he prevents
I suggest, he suggests
I ensure, he
2024-07-31 22:41:53 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-07-31 22:44:58 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0237,  0.1660, -0.0617,  ...,  0.1770, -0.0433, -0.1676],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.3340, -2.8398, -0.6582,  ..., -0.5767, -7.6016, -1.1475],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0742, -0.0549,  0.0499,  ...,  0.0403,  0.0009,  0.0029],
        [-0.0585,  0.0115,  0.0130,  ..., -0.0132, -0.0180,  0.0086],
        [ 0.0725,  0.0180, -0.0107,  ...,  0.0424,  0.0191, -0.0267],
        ...,
        [-0.1159, -0.0546, -0.0312,  ..., -0.0096, -0.0361,  0.0323],
        [ 0.0081,  0.0288,  0.0686,  ...,  0.0303,  0.0111,  0.0060],
        [ 0.2048,  0.0981,  0.1554,  ...,  0.0438,  0.0544, -0.0063]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.9531, -3.3574,  0.0615,  ..., -2.0117, -7.0469,  1.9248]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 22:44:59 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for I remember, he remembers
I agree, he agrees
I believe, he believes
I include, he includes
I remain, he remains
I prevent, he prevents
I suggest, he suggests
I ensure, he
2024-07-31 22:44:59 root INFO     [order_1_approx] starting weight calculation for I believe, he believes
I prevent, he prevents
I suggest, he suggests
I ensure, he ensures
I remain, he remains
I agree, he agrees
I include, he includes
I remember, he
2024-07-31 22:45:00 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-07-31 22:48:05 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1210,  0.1493, -0.0270,  ...,  0.0969, -0.0271,  0.0580],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.4619, -3.2383, -1.2871,  ..., -0.9893, -5.4102, -1.6533],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0337, -0.0344,  0.0383,  ...,  0.0208,  0.0017,  0.0153],
        [-0.0196,  0.0057,  0.0087,  ..., -0.0194,  0.0255,  0.0143],
        [ 0.0064, -0.0073, -0.0359,  ..., -0.0293,  0.0046,  0.0274],
        ...,
        [-0.0018, -0.0199,  0.0419,  ..., -0.0183,  0.0058,  0.0018],
        [ 0.0039, -0.0007, -0.0524,  ..., -0.0048, -0.0052,  0.0317],
        [ 0.0107,  0.0139, -0.0392,  ..., -0.0001,  0.0175, -0.0406]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.4331, -3.0059, -1.0586,  ..., -1.0703, -5.3164, -1.6465]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 22:48:06 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for I believe, he believes
I prevent, he prevents
I suggest, he suggests
I ensure, he ensures
I remain, he remains
I agree, he agrees
I include, he includes
I remember, he
2024-07-31 22:48:06 root INFO     [order_1_approx] starting weight calculation for I remember, he remembers
I agree, he agrees
I believe, he believes
I ensure, he ensures
I include, he includes
I suggest, he suggests
I remain, he remains
I prevent, he
2024-07-31 22:48:06 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-07-31 22:51:11 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0672,  0.1500,  0.0519,  ...,  0.0951, -0.0549, -0.0039],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.1484, -2.6055, -1.7080,  ..., -0.2456, -7.3633, -2.0938],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0393, -0.0032, -0.0886,  ..., -0.0308, -0.1031,  0.0203],
        [-0.0490,  0.0428,  0.0021,  ...,  0.0220,  0.0250,  0.0233],
        [-0.0522, -0.0337, -0.0532,  ..., -0.0070, -0.0174, -0.0444],
        ...,
        [-0.0381, -0.0333, -0.0986,  ..., -0.0257, -0.0927,  0.0241],
        [ 0.1246,  0.0291,  0.0822,  ...,  0.0371,  0.0822, -0.0414],
        [ 0.0381,  0.0013,  0.0266,  ...,  0.0607,  0.0844, -0.0334]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.9385, -2.4004, -2.2969,  ..., -1.5840, -5.5938, -1.6211]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 22:51:12 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for I remember, he remembers
I agree, he agrees
I believe, he believes
I ensure, he ensures
I include, he includes
I suggest, he suggests
I remain, he remains
I prevent, he
2024-07-31 22:51:12 root INFO     [order_1_approx] starting weight calculation for I suggest, he suggests
I remember, he remembers
I ensure, he ensures
I include, he includes
I prevent, he prevents
I remain, he remains
I believe, he believes
I agree, he
2024-07-31 22:51:12 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-07-31 22:54:18 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0043,  0.0135,  0.0076,  ...,  0.0356, -0.0325,  0.0909],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.6973, -5.0547,  0.6055,  ..., -0.0576, -5.3750,  1.9844],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0098, -0.0091, -0.0022,  ...,  0.0092,  0.0148,  0.0016],
        [ 0.0042,  0.0267,  0.0491,  ..., -0.0016, -0.0053, -0.0111],
        [-0.0046,  0.0364,  0.0062,  ..., -0.0215, -0.0188, -0.0274],
        ...,
        [-0.0133, -0.0226, -0.0478,  ...,  0.0020,  0.0105,  0.0291],
        [ 0.0347,  0.0350, -0.0245,  ...,  0.0134,  0.0338, -0.0024],
        [ 0.0177,  0.0116,  0.0014,  ...,  0.0203,  0.0226,  0.0002]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.9727, -4.8359,  0.9355,  ...,  0.0435, -5.1992,  1.4336]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 22:54:19 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for I suggest, he suggests
I remember, he remembers
I ensure, he ensures
I include, he includes
I prevent, he prevents
I remain, he remains
I believe, he believes
I agree, he
2024-07-31 22:54:19 root INFO     [order_1_approx] starting weight calculation for I ensure, he ensures
I believe, he believes
I remember, he remembers
I suggest, he suggests
I prevent, he prevents
I agree, he agrees
I remain, he remains
I include, he
2024-07-31 22:54:19 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-07-31 22:57:23 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0411,  0.0927,  0.0737,  ...,  0.1351,  0.0502, -0.0062],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.4629, -2.6758, -0.1211,  ..., -0.4658, -6.4219, -1.5557],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0372, -0.0009,  0.0289,  ...,  0.0224, -0.0048, -0.0428],
        [ 0.1719,  0.0038,  0.0160,  ..., -0.0264,  0.0966,  0.1077],
        [ 0.0237,  0.0099, -0.0253,  ..., -0.0533, -0.0386,  0.0087],
        ...,
        [ 0.0085, -0.0582,  0.0241,  ..., -0.0229, -0.0009,  0.0034],
        [ 0.1949,  0.0496,  0.0578,  ..., -0.0137,  0.1046,  0.0968],
        [ 0.3933,  0.0386,  0.0646,  ...,  0.0386,  0.2100,  0.1896]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.7363, -1.7031,  0.5244,  ..., -1.1621, -5.2734,  0.7900]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 22:57:24 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for I ensure, he ensures
I believe, he believes
I remember, he remembers
I suggest, he suggests
I prevent, he prevents
I agree, he agrees
I remain, he remains
I include, he
2024-07-31 22:57:24 root INFO     total operator prediction time: 1489.7864694595337 seconds
2024-07-31 22:57:24 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on verb_Ving - 3pSg
2024-07-31 22:57:24 root INFO     building operator verb_Ving - 3pSg
2024-07-31 22:57:25 root INFO     [order_1_approx] starting weight calculation for When something is requiring, it requires
When something is performing, it performs
When something is involving, it involves
When something is understanding, it understands
When something is promoting, it promotes
When something is occurring, it occurs
When something is applying, it applies
When something is receiving, it
2024-07-31 22:57:25 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-07-31 23:00:27 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0562,  0.2720,  0.0245,  ...,  0.0007, -0.1804, -0.1310],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.1133, -1.3262, -1.7441,  ..., -1.7188, -4.9375, -3.5156],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0030, -0.0107,  0.0263,  ...,  0.0056,  0.0338,  0.0609],
        [-0.0250,  0.0064,  0.0231,  ...,  0.0146,  0.0529,  0.0756],
        [ 0.0251, -0.0027, -0.0204,  ..., -0.0263, -0.0069, -0.0322],
        ...,
        [ 0.0395, -0.0176,  0.0333,  ..., -0.0204,  0.0408,  0.0642],
        [ 0.0182,  0.0185, -0.0356,  ..., -0.0249, -0.0464, -0.0401],
        [ 0.0002,  0.0099, -0.0139,  ...,  0.0294,  0.0232, -0.0109]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.1202, -0.9502, -1.8613,  ..., -1.4756, -5.3242, -3.6328]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 23:00:28 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When something is requiring, it requires
When something is performing, it performs
When something is involving, it involves
When something is understanding, it understands
When something is promoting, it promotes
When something is occurring, it occurs
When something is applying, it applies
When something is receiving, it
2024-07-31 23:00:28 root INFO     [order_1_approx] starting weight calculation for When something is occurring, it occurs
When something is performing, it performs
When something is applying, it applies
When something is receiving, it receives
When something is involving, it involves
When something is promoting, it promotes
When something is understanding, it understands
When something is requiring, it
2024-07-31 23:00:28 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-07-31 23:03:35 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0575,  0.0791, -0.0106,  ...,  0.0970, -0.0699, -0.1553],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.8203, -2.7930,  2.3789,  ..., -0.9824, -6.2812, -0.3125],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-2.0355e-02, -8.0643e-03, -4.6616e-03,  ...,  7.9803e-03,
         -1.3718e-02,  3.6224e-02],
        [ 1.1078e-02, -3.7750e-02, -3.4668e-02,  ..., -4.1992e-02,
          1.4185e-01,  3.8147e-02],
        [ 4.7607e-03,  5.7129e-02,  1.2871e-02,  ...,  3.3264e-02,
         -1.0852e-01, -4.1199e-02],
        ...,
        [ 1.0046e-01, -5.3162e-02,  7.0984e-02,  ..., -4.4556e-02,
          1.1719e-01,  3.8879e-02],
        [-4.9652e-02,  4.9896e-02,  4.8523e-02,  ...,  4.5776e-05,
         -1.3916e-01, -1.9730e-02],
        [-3.3295e-02,  3.7872e-02, -2.4582e-02,  ...,  7.6050e-02,
         -7.2632e-02, -4.3427e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.1055, -1.5078,  1.7617,  ..., -0.1079, -8.4375, -1.1533]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 23:03:36 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When something is occurring, it occurs
When something is performing, it performs
When something is applying, it applies
When something is receiving, it receives
When something is involving, it involves
When something is promoting, it promotes
When something is understanding, it understands
When something is requiring, it
2024-07-31 23:03:36 root INFO     [order_1_approx] starting weight calculation for When something is involving, it involves
When something is performing, it performs
When something is promoting, it promotes
When something is receiving, it receives
When something is requiring, it requires
When something is applying, it applies
When something is occurring, it occurs
When something is understanding, it
2024-07-31 23:03:36 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-07-31 23:06:41 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0663,  0.1667, -0.0326,  ...,  0.2268, -0.0260, -0.1587],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.7852, -1.5537,  1.5879,  ..., -0.3301, -6.0586,  1.5332],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0087, -0.0086,  0.0104,  ..., -0.0031, -0.0207, -0.0003],
        [ 0.0257,  0.0230, -0.0102,  ...,  0.0262,  0.0327,  0.0116],
        [ 0.0812,  0.0250, -0.0182,  ...,  0.0296,  0.0042,  0.0183],
        ...,
        [ 0.0190, -0.0003,  0.0225,  ...,  0.0043,  0.0052,  0.0068],
        [ 0.0011,  0.0267,  0.0325,  ..., -0.0493, -0.0186,  0.0149],
        [-0.0241,  0.0076,  0.0182,  ...,  0.0125, -0.0208, -0.0061]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.2207, -1.4346,  2.0000,  ...,  0.2788, -6.0078,  1.1885]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 23:06:42 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When something is involving, it involves
When something is performing, it performs
When something is promoting, it promotes
When something is receiving, it receives
When something is requiring, it requires
When something is applying, it applies
When something is occurring, it occurs
When something is understanding, it
2024-07-31 23:06:42 root INFO     [order_1_approx] starting weight calculation for When something is performing, it performs
When something is involving, it involves
When something is understanding, it understands
When something is applying, it applies
When something is promoting, it promotes
When something is requiring, it requires
When something is receiving, it receives
When something is occurring, it
2024-07-31 23:06:42 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-07-31 23:09:48 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0551, -0.0498,  0.1345,  ...,  0.0474, -0.0197, -0.1309],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.0840, -4.3359,  0.6543,  ..., -1.2666, -3.0586,  0.3203],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0279,  0.0446,  0.0281,  ...,  0.0209,  0.0807,  0.0382],
        [-0.0047,  0.0329,  0.0046,  ..., -0.0030,  0.0289,  0.0111],
        [ 0.0032, -0.0079, -0.0231,  ..., -0.0085, -0.0482, -0.0437],
        ...,
        [ 0.0275, -0.0300,  0.0110,  ..., -0.0197, -0.0169,  0.0324],
        [ 0.0378, -0.0351, -0.0268,  ...,  0.0003, -0.0714,  0.0173],
        [-0.0036,  0.0228, -0.0303,  ...,  0.0264, -0.0160,  0.0135]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.5371, -3.9570,  0.3958,  ..., -1.2549, -3.6562,  0.0332]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 23:09:49 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When something is performing, it performs
When something is involving, it involves
When something is understanding, it understands
When something is applying, it applies
When something is promoting, it promotes
When something is requiring, it requires
When something is receiving, it receives
When something is occurring, it
2024-07-31 23:09:49 root INFO     [order_1_approx] starting weight calculation for When something is promoting, it promotes
When something is requiring, it requires
When something is understanding, it understands
When something is involving, it involves
When something is receiving, it receives
When something is performing, it performs
When something is occurring, it occurs
When something is applying, it
2024-07-31 23:09:49 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-07-31 23:12:51 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0205,  0.0281,  0.0919,  ...,  0.1252, -0.0018, -0.0040],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.9395, -2.4824,  0.0156,  ..., -0.5469, -6.1641, -0.8223],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0051,  0.0057,  0.0261,  ..., -0.0080, -0.0493,  0.0522],
        [ 0.1506, -0.0115,  0.0091,  ..., -0.0080,  0.1052, -0.0404],
        [ 0.0081,  0.0490,  0.0090,  ..., -0.0322, -0.0427,  0.0296],
        ...,
        [ 0.0786,  0.0136,  0.0024,  ..., -0.0230,  0.0482,  0.0054],
        [-0.1118,  0.0653, -0.0412,  ..., -0.0291, -0.0338, -0.0218],
        [-0.0680, -0.0088,  0.0281,  ...,  0.0525, -0.0560, -0.0488]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.3115, -1.0752, -0.2493,  ...,  0.2476, -7.0742, -1.3652]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 23:12:52 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When something is promoting, it promotes
When something is requiring, it requires
When something is understanding, it understands
When something is involving, it involves
When something is receiving, it receives
When something is performing, it performs
When something is occurring, it occurs
When something is applying, it
2024-07-31 23:12:52 root INFO     [order_1_approx] starting weight calculation for When something is requiring, it requires
When something is performing, it performs
When something is understanding, it understands
When something is applying, it applies
When something is occurring, it occurs
When something is receiving, it receives
When something is involving, it involves
When something is promoting, it
2024-07-31 23:12:52 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-07-31 23:15:59 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0690,  0.1321, -0.0475,  ...,  0.1178,  0.0254, -0.0393],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.7812, -3.6250, -0.0312,  ..., -0.1777, -7.5859, -0.1543],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0052, -0.0074,  0.0091,  ...,  0.0030, -0.0557,  0.0349],
        [ 0.0201,  0.0039, -0.0281,  ...,  0.0400,  0.0867, -0.0426],
        [ 0.0416,  0.0163,  0.0029,  ..., -0.0077, -0.0317, -0.0311],
        ...,
        [ 0.0233, -0.0131, -0.0462,  ...,  0.0101,  0.0088,  0.0230],
        [-0.0889,  0.0473,  0.0015,  ..., -0.0345, -0.0956,  0.0232],
        [-0.0245,  0.0233,  0.0149,  ..., -0.0069, -0.0321,  0.0136]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.4531, -3.0664,  0.3264,  ..., -0.3081, -8.1562, -0.4644]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 23:16:00 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When something is requiring, it requires
When something is performing, it performs
When something is understanding, it understands
When something is applying, it applies
When something is occurring, it occurs
When something is receiving, it receives
When something is involving, it involves
When something is promoting, it
2024-07-31 23:16:00 root INFO     [order_1_approx] starting weight calculation for When something is promoting, it promotes
When something is applying, it applies
When something is receiving, it receives
When something is performing, it performs
When something is requiring, it requires
When something is understanding, it understands
When something is occurring, it occurs
When something is involving, it
2024-07-31 23:16:00 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-07-31 23:19:06 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0754,  0.0641,  0.0063,  ...,  0.1467, -0.0212, -0.0985],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.4668, -0.8857,  3.4746,  ...,  0.0928, -2.8828, -3.3730],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0861, -0.0061, -0.0209,  ...,  0.0571, -0.0519,  0.0766],
        [ 0.0744,  0.0118,  0.0850,  ...,  0.0245,  0.0601, -0.0392],
        [-0.0960,  0.0596, -0.0942,  ...,  0.0295, -0.0562, -0.0086],
        ...,
        [ 0.0759, -0.0258,  0.0005,  ..., -0.0446, -0.0327, -0.0119],
        [-0.1533,  0.0632, -0.0209,  ...,  0.0025, -0.0724,  0.0359],
        [-0.0140, -0.0020,  0.0030,  ...,  0.0602, -0.0434, -0.0131]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.2383, -0.5029,  2.5957,  ...,  0.2622, -4.3281, -3.3848]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 23:19:06 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When something is promoting, it promotes
When something is applying, it applies
When something is receiving, it receives
When something is performing, it performs
When something is requiring, it requires
When something is understanding, it understands
When something is occurring, it occurs
When something is involving, it
2024-07-31 23:19:07 root INFO     [order_1_approx] starting weight calculation for When something is involving, it involves
When something is promoting, it promotes
When something is requiring, it requires
When something is receiving, it receives
When something is occurring, it occurs
When something is applying, it applies
When something is understanding, it understands
When something is performing, it
2024-07-31 23:19:07 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-07-31 23:22:08 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1475,  0.0640,  0.0767,  ...,  0.0245, -0.1018, -0.0728],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.4883, -4.6992,  0.9648,  ..., -1.1572, -6.0859, -2.0098],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0349, -0.0108, -0.0015,  ..., -0.0157, -0.0834, -0.0084],
        [ 0.0215,  0.0230,  0.0269,  ..., -0.0464,  0.1592,  0.0743],
        [ 0.0164,  0.0205, -0.0292,  ...,  0.0118, -0.1248, -0.0196],
        ...,
        [-0.0138, -0.0290,  0.0341,  ..., -0.0447,  0.0249,  0.0299],
        [ 0.0467, -0.0057, -0.0136,  ...,  0.0397, -0.0719, -0.0637],
        [-0.0108,  0.0068, -0.0314,  ...,  0.0464,  0.0023, -0.0581]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.0215, -2.5371,  0.2480,  ..., -0.3237, -6.5820, -2.2891]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 23:22:09 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When something is involving, it involves
When something is promoting, it promotes
When something is requiring, it requires
When something is receiving, it receives
When something is occurring, it occurs
When something is applying, it applies
When something is understanding, it understands
When something is performing, it
2024-07-31 23:22:09 root INFO     total operator prediction time: 1484.5998957157135 seconds
2024-07-31 23:22:09 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on noun - plural_reg
2024-07-31 23:22:09 root INFO     building operator noun - plural_reg
2024-07-31 23:22:09 root INFO     [order_1_approx] starting weight calculation for The plural form of department is departments
The plural form of fact is facts
The plural form of version is versions
The plural form of event is events
The plural form of street is streets
The plural form of period is periods
The plural form of car is cars
The plural form of road is
2024-07-31 23:22:09 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-07-31 23:25:13 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0316,  0.0543,  0.0757,  ..., -0.0458,  0.0179, -0.0450],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.4580, -5.2188, -1.9150,  ..., -0.4321, -0.5156, -2.4004],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0238, -0.0208,  0.0257,  ..., -0.0006,  0.0089,  0.0174],
        [ 0.0055,  0.0116,  0.0173,  ...,  0.0118, -0.0160,  0.0239],
        [-0.0497,  0.0019,  0.0018,  ...,  0.0103, -0.0170,  0.0372],
        ...,
        [-0.0101, -0.0100,  0.0172,  ..., -0.0072,  0.0230, -0.0257],
        [ 0.0041,  0.0023, -0.0232,  ...,  0.0089, -0.0103, -0.0275],
        [-0.0171,  0.0120,  0.0141,  ...,  0.0200,  0.0107,  0.0210]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.3223, -5.7227, -0.8584,  ...,  0.2983, -1.3633, -1.8477]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 23:25:14 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of department is departments
The plural form of fact is facts
The plural form of version is versions
The plural form of event is events
The plural form of street is streets
The plural form of period is periods
The plural form of car is cars
The plural form of road is
2024-07-31 23:25:14 root INFO     [order_1_approx] starting weight calculation for The plural form of department is departments
The plural form of road is roads
The plural form of car is cars
The plural form of fact is facts
The plural form of period is periods
The plural form of street is streets
The plural form of event is events
The plural form of version is
2024-07-31 23:25:14 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-07-31 23:28:19 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0101, -0.0233,  0.0428,  ..., -0.0195,  0.1293, -0.0547],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.8198, -4.1406, -0.9102,  ..., -1.7695, -1.8242, -1.5713],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0156,  0.0116,  0.1175,  ..., -0.0194, -0.0984, -0.0707],
        [ 0.0071,  0.0295, -0.0931,  ...,  0.0534,  0.0678,  0.0750],
        [ 0.0501, -0.0036, -0.0324,  ...,  0.0139,  0.0625,  0.0572],
        ...,
        [ 0.0256,  0.0240, -0.0900,  ...,  0.0024,  0.0349,  0.0673],
        [-0.0632, -0.0063,  0.0843,  ..., -0.0452, -0.0707, -0.0126],
        [ 0.0664, -0.0077, -0.0946,  ...,  0.0414,  0.0186,  0.0457]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.9849, -2.5312, -0.2178,  ..., -0.5283, -3.0742, -0.2061]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 23:28:20 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of department is departments
The plural form of road is roads
The plural form of car is cars
The plural form of fact is facts
The plural form of period is periods
The plural form of street is streets
The plural form of event is events
The plural form of version is
2024-07-31 23:28:20 root INFO     [order_1_approx] starting weight calculation for The plural form of road is roads
The plural form of car is cars
The plural form of version is versions
The plural form of event is events
The plural form of street is streets
The plural form of fact is facts
The plural form of period is periods
The plural form of department is
2024-07-31 23:28:20 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-07-31 23:31:26 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1378,  0.0430, -0.0160,  ...,  0.0520,  0.0159, -0.0656],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.0293, -3.0371,  2.8438,  ..., -1.1357,  1.3613, -2.6719],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0239,  0.0115, -0.0093,  ...,  0.0207, -0.0284, -0.0150],
        [-0.0469, -0.0554, -0.0232,  ..., -0.0081,  0.0482,  0.0781],
        [ 0.0016,  0.0348, -0.0241,  ..., -0.0179, -0.0195,  0.0165],
        ...,
        [-0.0064,  0.0046, -0.0168,  ...,  0.0284, -0.0249, -0.0206],
        [-0.0179,  0.0370,  0.0051,  ..., -0.0232, -0.0604, -0.0809],
        [-0.0142, -0.0596, -0.0065,  ...,  0.0404,  0.0342,  0.0340]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.8740, -1.6846,  2.9180,  ..., -0.1401,  0.5181, -1.3789]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 23:31:27 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of road is roads
The plural form of car is cars
The plural form of version is versions
The plural form of event is events
The plural form of street is streets
The plural form of fact is facts
The plural form of period is periods
The plural form of department is
2024-07-31 23:31:27 root INFO     [order_1_approx] starting weight calculation for The plural form of car is cars
The plural form of road is roads
The plural form of street is streets
The plural form of version is versions
The plural form of event is events
The plural form of period is periods
The plural form of department is departments
The plural form of fact is
2024-07-31 23:31:28 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-07-31 23:34:33 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0032,  0.0612, -0.1317,  ..., -0.0952,  0.0183, -0.0865],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.0371, -3.3457,  1.8066,  ...,  0.6831, -1.4287, -1.9990],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0452, -0.0433,  0.0414,  ..., -0.0191,  0.0284,  0.0156],
        [-0.0367,  0.0520,  0.0008,  ..., -0.0088, -0.0302,  0.0079],
        [ 0.0059, -0.0141, -0.0125,  ..., -0.0033,  0.0196, -0.0106],
        ...,
        [-0.0146, -0.0179,  0.0214,  ...,  0.0359,  0.0004, -0.0099],
        [-0.0046, -0.0165, -0.0300,  ...,  0.0522, -0.0137, -0.0085],
        [ 0.0208,  0.0069, -0.0051,  ...,  0.0196, -0.0330,  0.0112]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.9482, -3.0957,  1.8047,  ...,  0.6313, -2.1211, -1.8770]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 23:34:34 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of car is cars
The plural form of road is roads
The plural form of street is streets
The plural form of version is versions
The plural form of event is events
The plural form of period is periods
The plural form of department is departments
The plural form of fact is
2024-07-31 23:34:34 root INFO     [order_1_approx] starting weight calculation for The plural form of car is cars
The plural form of road is roads
The plural form of period is periods
The plural form of department is departments
The plural form of fact is facts
The plural form of street is streets
The plural form of version is versions
The plural form of event is
2024-07-31 23:34:34 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-07-31 23:37:41 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1731,  0.0897,  0.0764,  ..., -0.1388,  0.0287, -0.2124],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.9648, -1.6201, -0.2454,  ...,  0.0309, -1.5762, -2.1348],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 2.5604e-02, -2.3575e-02,  1.3733e-02,  ..., -1.5335e-03,
         -6.9504e-03, -2.1606e-02],
        [-2.6535e-02,  1.5869e-03,  2.5043e-03,  ...,  2.7924e-02,
          2.6413e-02, -4.7874e-03],
        [ 2.9739e-02,  1.3840e-02,  2.1194e-02,  ...,  1.2192e-02,
          1.1040e-02, -1.6220e-02],
        ...,
        [-8.3447e-05,  2.6798e-04, -3.6926e-03,  ...,  3.2349e-02,
         -2.3682e-02, -1.8524e-02],
        [ 6.6681e-03,  1.3115e-02, -7.0923e-02,  ...,  1.4374e-02,
         -3.9490e-02,  2.1744e-02],
        [-1.8799e-02, -2.0981e-03,  2.5024e-02,  ..., -6.3934e-03,
          5.1910e-02, -1.3260e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.7715, -1.0332,  0.4353,  ..., -0.0759, -2.8984, -1.0830]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 23:37:42 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of car is cars
The plural form of road is roads
The plural form of period is periods
The plural form of department is departments
The plural form of fact is facts
The plural form of street is streets
The plural form of version is versions
The plural form of event is
2024-07-31 23:37:42 root INFO     [order_1_approx] starting weight calculation for The plural form of department is departments
The plural form of version is versions
The plural form of road is roads
The plural form of car is cars
The plural form of period is periods
The plural form of event is events
The plural form of fact is facts
The plural form of street is
2024-07-31 23:37:42 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-07-31 23:40:47 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0614,  0.0931,  0.0605,  ..., -0.1445,  0.0350,  0.0536],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.6719, -4.1016, -0.8887,  ...,  0.7324, -0.1787, -2.7988],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-1.1536e-02,  3.9032e-02, -1.9699e-02,  ...,  2.2797e-02,
          3.2837e-02,  2.2888e-05],
        [ 4.1885e-03, -9.5673e-03, -2.4078e-02,  ...,  9.1324e-03,
          5.9418e-02,  2.5696e-02],
        [-5.7678e-03,  2.6459e-02, -1.7715e-02,  ...,  2.1057e-02,
          1.6418e-02, -7.9803e-03],
        ...,
        [ 2.1988e-02,  3.9444e-03, -4.7150e-03,  ..., -8.8120e-03,
          2.8412e-02, -2.5116e-02],
        [-3.9856e-02, -6.1264e-03, -6.3721e-02,  ...,  5.0079e-02,
          2.0569e-02, -5.1086e-02],
        [-1.8501e-03, -5.4260e-02, -4.2084e-02,  ...,  3.2990e-02,
          2.7115e-02,  4.7852e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.9326, -3.7012, -0.5674,  ...,  0.8032, -0.7056, -1.4863]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 23:40:48 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of department is departments
The plural form of version is versions
The plural form of road is roads
The plural form of car is cars
The plural form of period is periods
The plural form of event is events
The plural form of fact is facts
The plural form of street is
2024-07-31 23:40:48 root INFO     [order_1_approx] starting weight calculation for The plural form of version is versions
The plural form of street is streets
The plural form of event is events
The plural form of fact is facts
The plural form of department is departments
The plural form of road is roads
The plural form of period is periods
The plural form of car is
2024-07-31 23:40:48 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-07-31 23:43:46 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0256, -0.0148, -0.0355,  ...,  0.0059, -0.0163, -0.1230],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.7480, -4.3984,  1.1289,  ..., -2.4746,  1.1523, -0.4473],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0597,  0.0750,  0.0768,  ..., -0.0244, -0.0281, -0.0617],
        [-0.0803, -0.0570, -0.0732,  ...,  0.0364,  0.0365,  0.0648],
        [-0.0153,  0.0062,  0.0363,  ..., -0.0231, -0.0180,  0.0102],
        ...,
        [-0.0120, -0.0398, -0.0524,  ..., -0.0044, -0.0001,  0.0126],
        [-0.0138,  0.0908,  0.0575,  ...,  0.0024,  0.0344, -0.0305],
        [-0.0270, -0.0287, -0.0212,  ...,  0.0141, -0.0102,  0.0064]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-2.0918, -3.6465,  0.8066,  ..., -2.0469,  0.3838, -0.3022]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 23:43:47 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of version is versions
The plural form of street is streets
The plural form of event is events
The plural form of fact is facts
The plural form of department is departments
The plural form of road is roads
The plural form of period is periods
The plural form of car is
2024-07-31 23:43:47 root INFO     [order_1_approx] starting weight calculation for The plural form of fact is facts
The plural form of event is events
The plural form of street is streets
The plural form of version is versions
The plural form of department is departments
The plural form of road is roads
The plural form of car is cars
The plural form of period is
2024-07-31 23:43:47 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-07-31 23:46:51 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0376, -0.0671, -0.0603,  ..., -0.0366, -0.0964, -0.1686],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.1345, -3.2070,  2.0293,  ..., -0.9385, -0.1919, -0.9097],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0003, -0.0238,  0.0224,  ..., -0.0007, -0.0187,  0.0106],
        [-0.0273,  0.0399,  0.0116,  ...,  0.0470,  0.0446,  0.0410],
        [ 0.0088,  0.0269, -0.0377,  ...,  0.0148, -0.0117,  0.0087],
        ...,
        [-0.0037,  0.0273,  0.0234,  ...,  0.0334, -0.0059, -0.0273],
        [-0.0630,  0.0031,  0.0005,  ..., -0.0080, -0.0769, -0.0118],
        [-0.0129, -0.0082, -0.0088,  ...,  0.0528,  0.0597,  0.0136]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.5918, -1.6543,  1.9785,  ..., -1.0586, -1.7598,  0.6011]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 23:46:52 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of fact is facts
The plural form of event is events
The plural form of street is streets
The plural form of version is versions
The plural form of department is departments
The plural form of road is roads
The plural form of car is cars
The plural form of period is
2024-07-31 23:46:52 root INFO     total operator prediction time: 1483.2045028209686 seconds
2024-07-31 23:46:52 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on verb_3pSg - Ved
2024-07-31 23:46:52 root INFO     building operator verb_3pSg - Ved
2024-07-31 23:46:52 root INFO     [order_1_approx] starting weight calculation for When he tells something, something has been told
When he decides something, something has been decided
When he hears something, something has been heard
When he receives something, something has been received
When he fails something, something has been failed
When he spends something, something has been spent
When he proposes something, something has been proposed
When he remains something, something has been
2024-07-31 23:46:52 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-07-31 23:49:54 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1068,  0.0424,  0.0264,  ..., -0.0288, -0.1621,  0.0018],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.8105, -0.3406,  1.0146,  ..., -2.5020, -2.0254, -1.4199],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0196,  0.0128,  0.0224,  ...,  0.0361,  0.0013,  0.0145],
        [-0.0573,  0.0398,  0.0220,  ..., -0.0123, -0.0156,  0.0229],
        [ 0.0428, -0.0375, -0.0639,  ..., -0.0149, -0.0291, -0.0278],
        ...,
        [ 0.0136,  0.0180,  0.0122,  ..., -0.0143, -0.0271,  0.0501],
        [-0.0373,  0.0024, -0.0512,  ...,  0.0088, -0.0232, -0.0028],
        [-0.0047,  0.0107,  0.0396,  ...,  0.0226,  0.0284, -0.0200]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.6934, -0.7036,  0.6699,  ..., -2.4434, -1.6572, -1.2900]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 23:49:55 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When he tells something, something has been told
When he decides something, something has been decided
When he hears something, something has been heard
When he receives something, something has been received
When he fails something, something has been failed
When he spends something, something has been spent
When he proposes something, something has been proposed
When he remains something, something has been
2024-07-31 23:49:56 root INFO     [order_1_approx] starting weight calculation for When he remains something, something has been remained
When he decides something, something has been decided
When he hears something, something has been heard
When he receives something, something has been received
When he proposes something, something has been proposed
When he fails something, something has been failed
When he tells something, something has been told
When he spends something, something has been
2024-07-31 23:49:56 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-07-31 23:53:00 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1128,  0.0375,  0.0300,  ...,  0.0281, -0.1328, -0.0762],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.0000, -0.8203, -1.8027,  ..., -1.6318, -3.5391, -0.6953],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0096, -0.0228,  0.0340,  ..., -0.0503,  0.0104,  0.0056],
        [-0.0184,  0.0305,  0.0033,  ...,  0.0067, -0.0137,  0.0047],
        [ 0.0327, -0.0243, -0.0430,  ..., -0.0318,  0.0337, -0.0222],
        ...,
        [-0.0012, -0.0164, -0.0193,  ...,  0.0043,  0.0123,  0.0126],
        [-0.0066, -0.0163, -0.0128,  ..., -0.0028,  0.0055, -0.0240],
        [-0.0224,  0.0005,  0.0277,  ...,  0.0118,  0.0296, -0.0051]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.6914, -1.0312, -1.5850,  ..., -1.5410, -3.4434, -0.5527]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 23:53:01 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When he remains something, something has been remained
When he decides something, something has been decided
When he hears something, something has been heard
When he receives something, something has been received
When he proposes something, something has been proposed
When he fails something, something has been failed
When he tells something, something has been told
When he spends something, something has been
2024-07-31 23:53:01 root INFO     [order_1_approx] starting weight calculation for When he tells something, something has been told
When he decides something, something has been decided
When he remains something, something has been remained
When he fails something, something has been failed
When he hears something, something has been heard
When he spends something, something has been spent
When he receives something, something has been received
When he proposes something, something has been
2024-07-31 23:53:01 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-07-31 23:56:02 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0690, -0.0021, -0.0964,  ...,  0.0174, -0.1250, -0.0061],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.9336, -2.0742,  0.7222,  ...,  0.0088, -2.9199,  1.3281],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0100, -0.0052,  0.0196,  ...,  0.0068, -0.0236,  0.0266],
        [ 0.0037,  0.0009,  0.0140,  ..., -0.0037,  0.0021,  0.0367],
        [ 0.0249, -0.0055, -0.0268,  ..., -0.0234,  0.0217, -0.0216],
        ...,
        [ 0.0034, -0.0103, -0.0096,  ...,  0.0047, -0.0054, -0.0132],
        [-0.0218,  0.0093, -0.0181,  ..., -0.0151, -0.0215,  0.0078],
        [ 0.0002, -0.0013, -0.0095,  ...,  0.0051, -0.0483,  0.0006]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.8789, -1.8057,  0.6699,  ..., -0.1715, -2.7363,  0.9102]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 23:56:03 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When he tells something, something has been told
When he decides something, something has been decided
When he remains something, something has been remained
When he fails something, something has been failed
When he hears something, something has been heard
When he spends something, something has been spent
When he receives something, something has been received
When he proposes something, something has been
2024-07-31 23:56:03 root INFO     [order_1_approx] starting weight calculation for When he spends something, something has been spent
When he remains something, something has been remained
When he fails something, something has been failed
When he hears something, something has been heard
When he proposes something, something has been proposed
When he receives something, something has been received
When he tells something, something has been told
When he decides something, something has been
2024-07-31 23:56:04 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-07-31 23:59:08 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0908,  0.0571, -0.0424,  ...,  0.1046, -0.1604, -0.1282],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.4004, -1.4199,  1.3926,  ...,  0.1599, -3.3398,  0.6855],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0174, -0.0621,  0.0519,  ..., -0.0067,  0.0122,  0.0389],
        [-0.0267,  0.0443, -0.0482,  ...,  0.0070, -0.0196,  0.0100],
        [ 0.0099,  0.0356, -0.0065,  ..., -0.0123, -0.0109, -0.0339],
        ...,
        [ 0.0025,  0.0035,  0.0175,  ..., -0.0260,  0.0043,  0.0125],
        [ 0.0130,  0.0565, -0.0222,  ..., -0.0016, -0.0105, -0.0019],
        [ 0.0164, -0.0282,  0.0070,  ...,  0.0298, -0.0064, -0.0048]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.8242, -1.1562,  1.5273,  ..., -0.0031, -2.9258,  0.5752]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 23:59:09 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When he spends something, something has been spent
When he remains something, something has been remained
When he fails something, something has been failed
When he hears something, something has been heard
When he proposes something, something has been proposed
When he receives something, something has been received
When he tells something, something has been told
When he decides something, something has been
2024-07-31 23:59:09 root INFO     [order_1_approx] starting weight calculation for When he receives something, something has been received
When he spends something, something has been spent
When he decides something, something has been decided
When he proposes something, something has been proposed
When he hears something, something has been heard
When he remains something, something has been remained
When he fails something, something has been failed
When he tells something, something has been
2024-07-31 23:59:09 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-08-01 00:02:14 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0102,  0.0063,  0.0244,  ..., -0.0005, -0.0636, -0.0974],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.5195,  0.3887,  4.4844,  ...,  2.7812, -4.8711, -1.4648],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0061,  0.0056, -0.0142,  ..., -0.0019,  0.0101,  0.0448],
        [-0.0359, -0.0005,  0.0040,  ..., -0.0252, -0.0342, -0.0214],
        [ 0.0338, -0.0315, -0.0556,  ..., -0.0189,  0.0026,  0.0037],
        ...,
        [-0.0009, -0.0161, -0.0207,  ..., -0.0449, -0.0206,  0.0266],
        [ 0.0083,  0.0303, -0.0044,  ...,  0.0276, -0.0068,  0.0218],
        [ 0.0057,  0.0366, -0.0048,  ...,  0.0267,  0.0394, -0.0164]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.4297,  0.3186,  4.1602,  ...,  2.6660, -5.0859, -1.7002]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 00:02:15 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When he receives something, something has been received
When he spends something, something has been spent
When he decides something, something has been decided
When he proposes something, something has been proposed
When he hears something, something has been heard
When he remains something, something has been remained
When he fails something, something has been failed
When he tells something, something has been
2024-08-01 00:02:15 root INFO     [order_1_approx] starting weight calculation for When he remains something, something has been remained
When he tells something, something has been told
When he receives something, something has been received
When he proposes something, something has been proposed
When he spends something, something has been spent
When he decides something, something has been decided
When he fails something, something has been failed
When he hears something, something has been
2024-08-01 00:02:15 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-08-01 00:05:19 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0303,  0.1129,  0.0646,  ..., -0.0859, -0.1865,  0.0230],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.8652, -0.0889,  1.4502,  ...,  0.4814, -6.1328, -2.4258],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0334, -0.0075, -0.0056,  ...,  0.0195,  0.0276,  0.0223],
        [-0.0204,  0.0377,  0.0135,  ...,  0.0144, -0.0193,  0.0159],
        [ 0.0330, -0.0065, -0.0082,  ...,  0.0079,  0.0226, -0.0041],
        ...,
        [ 0.0341,  0.0125, -0.0314,  ..., -0.0097, -0.0003,  0.0081],
        [ 0.0167,  0.0138, -0.0224,  ..., -0.0013,  0.0193,  0.0161],
        [ 0.0016,  0.0240,  0.0117,  ...,  0.0189,  0.0614,  0.0088]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.0576, -0.1671,  1.3818,  ...,  0.3975, -5.8633, -2.5742]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 00:05:20 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When he remains something, something has been remained
When he tells something, something has been told
When he receives something, something has been received
When he proposes something, something has been proposed
When he spends something, something has been spent
When he decides something, something has been decided
When he fails something, something has been failed
When he hears something, something has been
2024-08-01 00:05:20 root INFO     [order_1_approx] starting weight calculation for When he decides something, something has been decided
When he proposes something, something has been proposed
When he hears something, something has been heard
When he fails something, something has been failed
When he tells something, something has been told
When he remains something, something has been remained
When he spends something, something has been spent
When he receives something, something has been
2024-08-01 00:05:20 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-08-01 00:08:23 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0227,  0.1539, -0.0671,  ..., -0.0721, -0.2189, -0.1339],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.0527,  0.0576, -1.0225,  ..., -2.8984, -2.9297, -0.8271],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0022, -0.0025,  0.0138,  ...,  0.0001,  0.0373,  0.0642],
        [-0.0432,  0.0105,  0.0051,  ...,  0.0079, -0.0206,  0.0283],
        [ 0.0595, -0.0240, -0.0662,  ..., -0.0293,  0.0176, -0.0430],
        ...,
        [ 0.0432, -0.0133,  0.0315,  ..., -0.0147,  0.0371,  0.0326],
        [ 0.0433,  0.0032, -0.0050,  ..., -0.0635,  0.0119, -0.0256],
        [-0.0248, -0.0197, -0.0033,  ...,  0.0331,  0.0595,  0.0193]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.3918,  0.2949, -0.7715,  ..., -2.4668, -2.7871, -0.3389]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 00:08:25 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When he decides something, something has been decided
When he proposes something, something has been proposed
When he hears something, something has been heard
When he fails something, something has been failed
When he tells something, something has been told
When he remains something, something has been remained
When he spends something, something has been spent
When he receives something, something has been
2024-08-01 00:08:25 root INFO     [order_1_approx] starting weight calculation for When he hears something, something has been heard
When he receives something, something has been received
When he decides something, something has been decided
When he remains something, something has been remained
When he proposes something, something has been proposed
When he spends something, something has been spent
When he tells something, something has been told
When he fails something, something has been
2024-08-01 00:08:25 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-08-01 00:11:26 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0144, -0.0191, -0.0591,  ..., -0.0754, -0.0123, -0.0583],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.1016, -0.5625,  3.3125,  ..., -0.7598, -2.3711, -1.6133],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-4.3579e-02, -3.1281e-02,  6.9336e-02,  ...,  3.9062e-02,
          1.2497e-02, -2.4231e-02],
        [ 1.9016e-03,  4.5807e-02, -3.8086e-02,  ...,  8.8577e-03,
          1.3832e-02,  2.0584e-02],
        [ 8.1329e-03,  9.0332e-03, -6.4514e-02,  ..., -6.4316e-03,
         -1.5236e-02, -2.0523e-03],
        ...,
        [-3.0518e-04,  7.2098e-03, -5.5359e-02,  ...,  2.6436e-03,
         -4.6921e-03,  6.8588e-03],
        [ 1.5884e-02,  9.2346e-02, -5.5695e-02,  ..., -2.2827e-02,
         -3.5034e-02, -5.2376e-03],
        [-1.3084e-02,  3.8910e-02,  2.8229e-02,  ..., -5.5313e-05,
         -8.9874e-03, -5.3558e-03]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.3516, -0.3757,  3.1660,  ..., -0.7852, -2.8711, -1.7314]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 00:11:27 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When he hears something, something has been heard
When he receives something, something has been received
When he decides something, something has been decided
When he remains something, something has been remained
When he proposes something, something has been proposed
When he spends something, something has been spent
When he tells something, something has been told
When he fails something, something has been
2024-08-01 00:11:27 root INFO     total operator prediction time: 1474.915311574936 seconds
2024-08-01 00:11:27 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on adj - superlative
2024-08-01 00:11:27 root INFO     building operator adj - superlative
2024-08-01 00:11:27 root INFO     [order_1_approx] starting weight calculation for If something is the most happy, it is happiest
If something is the most tasty, it is tastiest
If something is the most dense, it is densest
If something is the most rude, it is rudest
If something is the most merry, it is merriest
If something is the most harsh, it is harshest
If something is the most noisy, it is noisiest
If something is the most lucky, it is
2024-08-01 00:11:27 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-08-01 00:14:32 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0994,  0.1097,  0.1039,  ...,  0.1702,  0.0793, -0.1262],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.6572, -3.0703, -3.3125,  ..., -0.1787, -1.5625, -1.9102],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0219, -0.0003, -0.0031,  ...,  0.0068,  0.0059, -0.0097],
        [ 0.0039,  0.0060, -0.0161,  ...,  0.0031,  0.0054,  0.0150],
        [-0.0008, -0.0119, -0.0072,  ...,  0.0171, -0.0280, -0.0202],
        ...,
        [ 0.0452, -0.0043,  0.0276,  ..., -0.0004,  0.0057,  0.0129],
        [ 0.0122,  0.0025,  0.0031,  ...,  0.0188, -0.0028, -0.0125],
        [ 0.0011,  0.0024,  0.0145,  ...,  0.0268,  0.0037, -0.0101]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.7607, -3.0312, -3.3711,  ..., -0.2458, -1.7314, -1.8770]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 00:14:33 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is the most happy, it is happiest
If something is the most tasty, it is tastiest
If something is the most dense, it is densest
If something is the most rude, it is rudest
If something is the most merry, it is merriest
If something is the most harsh, it is harshest
If something is the most noisy, it is noisiest
If something is the most lucky, it is
2024-08-01 00:14:33 root INFO     [order_1_approx] starting weight calculation for If something is the most dense, it is densest
If something is the most lucky, it is luckiest
If something is the most tasty, it is tastiest
If something is the most harsh, it is harshest
If something is the most noisy, it is noisiest
If something is the most happy, it is happiest
If something is the most merry, it is merriest
If something is the most rude, it is
2024-08-01 00:14:34 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-08-01 00:17:39 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2170,  0.0160,  0.0700,  ..., -0.1406,  0.0710, -0.0872],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-2.1055, -4.7031,  0.3074,  ..., -2.0410, -1.8027, -1.6328],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0334, -0.0225,  0.0385,  ...,  0.0124,  0.0067, -0.0002],
        [ 0.0261, -0.0411,  0.0026,  ..., -0.0370, -0.0294,  0.0449],
        [ 0.0318, -0.0055,  0.0362,  ...,  0.0064, -0.0728, -0.0112],
        ...,
        [ 0.0593, -0.0193,  0.0075,  ..., -0.0349, -0.0356,  0.0037],
        [ 0.0134,  0.0165, -0.0213,  ...,  0.0133,  0.0073, -0.0227],
        [ 0.0196, -0.0137,  0.0133,  ...,  0.0092,  0.0255, -0.0063]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-2.2422, -4.4023,  0.2690,  ..., -1.9590, -1.4902, -1.6592]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 00:17:40 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is the most dense, it is densest
If something is the most lucky, it is luckiest
If something is the most tasty, it is tastiest
If something is the most harsh, it is harshest
If something is the most noisy, it is noisiest
If something is the most happy, it is happiest
If something is the most merry, it is merriest
If something is the most rude, it is
2024-08-01 00:17:40 root INFO     [order_1_approx] starting weight calculation for If something is the most happy, it is happiest
If something is the most tasty, it is tastiest
If something is the most lucky, it is luckiest
If something is the most noisy, it is noisiest
If something is the most rude, it is rudest
If something is the most merry, it is merriest
If something is the most harsh, it is harshest
If something is the most dense, it is
2024-08-01 00:17:40 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-08-01 00:20:46 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1477,  0.1108,  0.0627,  ..., -0.1129,  0.0453, -0.0361],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.7559, -3.8945,  0.3682,  ..., -4.8320, -4.3047, -2.4492],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 1.9569e-03, -1.1871e-02, -1.8753e-02,  ..., -2.7206e-02,
          6.4575e-02,  2.7451e-02],
        [ 1.1749e-02,  2.3788e-02, -8.2092e-03,  ...,  2.3804e-02,
         -7.1716e-04, -1.4069e-02],
        [ 2.5848e-02, -1.6479e-02,  2.0477e-02,  ..., -1.6678e-02,
         -3.1677e-02, -4.4189e-02],
        ...,
        [-7.0953e-04, -1.8864e-03,  8.8425e-03,  ...,  1.1330e-03,
          9.6893e-03, -2.4261e-03],
        [ 2.5558e-03, -1.1475e-02,  8.9645e-03,  ..., -5.1498e-05,
          5.6122e-02,  1.6632e-02],
        [-1.5076e-02, -2.9572e-02, -1.6022e-02,  ...,  3.6774e-02,
          6.0730e-02, -3.3600e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.4824, -3.3516,  0.5654,  ..., -4.4805, -3.8926, -1.8496]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 00:20:47 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is the most happy, it is happiest
If something is the most tasty, it is tastiest
If something is the most lucky, it is luckiest
If something is the most noisy, it is noisiest
If something is the most rude, it is rudest
If something is the most merry, it is merriest
If something is the most harsh, it is harshest
If something is the most dense, it is
2024-08-01 00:20:47 root INFO     [order_1_approx] starting weight calculation for If something is the most harsh, it is harshest
If something is the most noisy, it is noisiest
If something is the most merry, it is merriest
If something is the most rude, it is rudest
If something is the most lucky, it is luckiest
If something is the most dense, it is densest
If something is the most happy, it is happiest
If something is the most tasty, it is
2024-08-01 00:20:47 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-08-01 00:23:53 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0723, -0.0141,  0.1277,  ..., -0.1259, -0.0931, -0.1370],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.9873, -5.5781, -3.1914,  ..., -0.4531, -6.7422, -1.8623],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0278,  0.0173,  0.0049,  ...,  0.0116,  0.0028, -0.0007],
        [-0.0063,  0.0236,  0.0058,  ..., -0.0168, -0.0187,  0.0078],
        [-0.0094, -0.0016,  0.0031,  ...,  0.0157, -0.0231, -0.0049],
        ...,
        [ 0.0145,  0.0060, -0.0089,  ..., -0.0104,  0.0198,  0.0020],
        [ 0.0237,  0.0129,  0.0294,  ...,  0.0152,  0.0117,  0.0076],
        [ 0.0011, -0.0037, -0.0039,  ...,  0.0019,  0.0095, -0.0076]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.2129, -5.6641, -2.9473,  ..., -0.8423, -6.6172, -1.7480]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 00:23:54 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is the most harsh, it is harshest
If something is the most noisy, it is noisiest
If something is the most merry, it is merriest
If something is the most rude, it is rudest
If something is the most lucky, it is luckiest
If something is the most dense, it is densest
If something is the most happy, it is happiest
If something is the most tasty, it is
2024-08-01 00:23:55 root INFO     [order_1_approx] starting weight calculation for If something is the most dense, it is densest
If something is the most noisy, it is noisiest
If something is the most harsh, it is harshest
If something is the most lucky, it is luckiest
If something is the most tasty, it is tastiest
If something is the most merry, it is merriest
If something is the most rude, it is rudest
If something is the most happy, it is
2024-08-01 00:23:55 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-08-01 00:26:57 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0106,  0.1008,  0.0397,  ..., -0.0687, -0.1302, -0.0502],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.0850, -3.6660, -0.1064,  ...,  0.7329, -2.5781, -0.9268],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0285, -0.0145,  0.0262,  ...,  0.0050,  0.0434, -0.0178],
        [ 0.0119,  0.0126,  0.0132,  ...,  0.0027,  0.0361,  0.0161],
        [ 0.0043, -0.0428,  0.0052,  ...,  0.0079, -0.0193,  0.0058],
        ...,
        [ 0.0050,  0.0091, -0.0098,  ..., -0.0225,  0.0036, -0.0224],
        [ 0.0460,  0.0312,  0.0001,  ...,  0.0020, -0.0107, -0.0096],
        [ 0.0170, -0.0117,  0.0122,  ...,  0.0399,  0.0067, -0.0058]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.3328, -3.7031, -0.2578,  ...,  0.8735, -2.2422, -1.0059]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 00:26:58 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is the most dense, it is densest
If something is the most noisy, it is noisiest
If something is the most harsh, it is harshest
If something is the most lucky, it is luckiest
If something is the most tasty, it is tastiest
If something is the most merry, it is merriest
If something is the most rude, it is rudest
If something is the most happy, it is
2024-08-01 00:26:58 root INFO     [order_1_approx] starting weight calculation for If something is the most tasty, it is tastiest
If something is the most harsh, it is harshest
If something is the most merry, it is merriest
If something is the most happy, it is happiest
If something is the most dense, it is densest
If something is the most lucky, it is luckiest
If something is the most rude, it is rudest
If something is the most noisy, it is
2024-08-01 00:26:58 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-08-01 00:30:02 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0856, -0.0349,  0.1190,  ...,  0.0750,  0.0219,  0.0098],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-4.6484, -3.8457, -1.1191,  ..., -1.0986, -2.3574,  0.0132],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0090, -0.0001,  0.0242,  ..., -0.0028,  0.0104,  0.0141],
        [-0.0008,  0.0007,  0.0164,  ...,  0.0177,  0.0007,  0.0093],
        [ 0.0117, -0.0013,  0.0029,  ...,  0.0050, -0.0131,  0.0009],
        ...,
        [-0.0015,  0.0035,  0.0129,  ...,  0.0067, -0.0159,  0.0055],
        [ 0.0134, -0.0033, -0.0314,  ...,  0.0112,  0.0088, -0.0030],
        [ 0.0142,  0.0192, -0.0009,  ..., -0.0025,  0.0026, -0.0306]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-4.5234, -3.7715, -1.0322,  ..., -1.0420, -2.2812,  0.3545]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 00:30:03 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is the most tasty, it is tastiest
If something is the most harsh, it is harshest
If something is the most merry, it is merriest
If something is the most happy, it is happiest
If something is the most dense, it is densest
If something is the most lucky, it is luckiest
If something is the most rude, it is rudest
If something is the most noisy, it is
2024-08-01 00:30:03 root INFO     [order_1_approx] starting weight calculation for If something is the most rude, it is rudest
If something is the most merry, it is merriest
If something is the most tasty, it is tastiest
If something is the most dense, it is densest
If something is the most lucky, it is luckiest
If something is the most noisy, it is noisiest
If something is the most happy, it is happiest
If something is the most harsh, it is
2024-08-01 00:30:03 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-08-01 00:33:08 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1932, -0.0683,  0.0446,  ..., -0.0923, -0.1562,  0.0263],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.6006, -4.8672, -2.9746,  ..., -1.6562, -1.5742,  0.5010],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0387, -0.0069,  0.0255,  ...,  0.0197,  0.0085,  0.0043],
        [ 0.0170, -0.0206,  0.0018,  ..., -0.0002, -0.0256,  0.0183],
        [ 0.0430, -0.0500,  0.0175,  ..., -0.0098, -0.0255, -0.0214],
        ...,
        [ 0.0344, -0.0069, -0.0165,  ..., -0.0151,  0.0121,  0.0079],
        [ 0.0046,  0.0296,  0.0048,  ...,  0.0087, -0.0221, -0.0214],
        [ 0.0261,  0.0207, -0.0086,  ...,  0.0196,  0.0061, -0.0327]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.9395, -4.7812, -2.7051,  ..., -1.4551, -1.7344,  0.3435]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 00:33:09 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is the most rude, it is rudest
If something is the most merry, it is merriest
If something is the most tasty, it is tastiest
If something is the most dense, it is densest
If something is the most lucky, it is luckiest
If something is the most noisy, it is noisiest
If something is the most happy, it is happiest
If something is the most harsh, it is
2024-08-01 00:33:09 root INFO     [order_1_approx] starting weight calculation for If something is the most lucky, it is luckiest
If something is the most happy, it is happiest
If something is the most tasty, it is tastiest
If something is the most rude, it is rudest
If something is the most harsh, it is harshest
If something is the most dense, it is densest
If something is the most noisy, it is noisiest
If something is the most merry, it is
2024-08-01 00:33:09 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-08-01 00:36:13 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1050,  0.1812,  0.0253,  ..., -0.1958, -0.0554, -0.0862],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-2.1797, -3.6719, -2.0938,  ...,  0.6997, -1.9277, -1.5371],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0084, -0.0020, -0.0101,  ..., -0.0066,  0.0358,  0.0034],
        [ 0.0051,  0.0140, -0.0183,  ...,  0.0093,  0.0239,  0.0339],
        [-0.0027,  0.0049,  0.0265,  ...,  0.0120, -0.0274, -0.0061],
        ...,
        [ 0.0179,  0.0064,  0.0043,  ...,  0.0146,  0.0022,  0.0128],
        [ 0.0023, -0.0083, -0.0101,  ...,  0.0136, -0.0100,  0.0012],
        [ 0.0236,  0.0004,  0.0019,  ..., -0.0014,  0.0348,  0.0282]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-2.5723, -3.6055, -1.9736,  ...,  0.8130, -1.7012, -1.6172]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 00:36:14 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is the most lucky, it is luckiest
If something is the most happy, it is happiest
If something is the most tasty, it is tastiest
If something is the most rude, it is rudest
If something is the most harsh, it is harshest
If something is the most dense, it is densest
If something is the most noisy, it is noisiest
If something is the most merry, it is
2024-08-01 00:36:14 root INFO     total operator prediction time: 1487.1569459438324 seconds
2024-08-01 00:36:14 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on verb+er_irreg
2024-08-01 00:36:14 root INFO     building operator verb+er_irreg
2024-08-01 00:36:15 root INFO     [order_1_approx] starting weight calculation for If you consume something, you are a consumer
If you interpret something, you are a interpreter
If you lose something, you are a loser
If you deliver something, you are a deliverer
If you entertain something, you are a entertainer
If you develop something, you are a developer
If you organise something, you are a organiser
If you preach something, you are a
2024-08-01 00:36:15 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-08-01 00:39:17 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1760, -0.0427,  0.0276,  ...,  0.0081, -0.0599,  0.0590],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 5.8047, -5.5391,  4.6367,  ...,  1.0947, -2.7852, -1.3750],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0065, -0.0027,  0.0041,  ..., -0.0126, -0.0021,  0.0068],
        [-0.0082,  0.0318,  0.0176,  ...,  0.0006,  0.0292,  0.0023],
        [ 0.0016, -0.0006, -0.0129,  ..., -0.0009, -0.0201, -0.0284],
        ...,
        [ 0.0289, -0.0001,  0.0243,  ...,  0.0568,  0.0240, -0.0090],
        [ 0.0188, -0.0003, -0.0048,  ...,  0.0166, -0.0201,  0.0051],
        [ 0.0063,  0.0249,  0.0039,  ...,  0.0332,  0.0126,  0.0008]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.9297, -5.0000,  4.8672,  ...,  1.3750, -2.9004, -1.2832]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 00:39:18 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you consume something, you are a consumer
If you interpret something, you are a interpreter
If you lose something, you are a loser
If you deliver something, you are a deliverer
If you entertain something, you are a entertainer
If you develop something, you are a developer
If you organise something, you are a organiser
If you preach something, you are a
2024-08-01 00:39:18 root INFO     [order_1_approx] starting weight calculation for If you develop something, you are a developer
If you interpret something, you are a interpreter
If you preach something, you are a preacher
If you lose something, you are a loser
If you entertain something, you are a entertainer
If you organise something, you are a organiser
If you deliver something, you are a deliverer
If you consume something, you are a
2024-08-01 00:39:18 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-08-01 00:42:24 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1226,  0.1037, -0.0303,  ...,  0.2375, -0.0906, -0.0807],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.1133,  0.9033,  2.2148,  ..., -1.6094, -2.1309, -1.1182],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0102,  0.0071,  0.0007,  ..., -0.0235,  0.0297, -0.0099],
        [-0.0596,  0.0493, -0.0003,  ...,  0.0211, -0.0140, -0.0117],
        [ 0.0287, -0.0029, -0.0185,  ..., -0.0265, -0.0094, -0.0376],
        ...,
        [ 0.0015,  0.0290,  0.0023,  ..., -0.0117,  0.0038, -0.0316],
        [ 0.0270,  0.0252, -0.0123,  ..., -0.0201, -0.0402,  0.0164],
        [ 0.0425, -0.0006,  0.0141,  ...,  0.0151, -0.0086, -0.0122]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.9258,  1.0293,  2.1914,  ..., -1.7754, -1.8359, -1.0059]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 00:42:25 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you develop something, you are a developer
If you interpret something, you are a interpreter
If you preach something, you are a preacher
If you lose something, you are a loser
If you entertain something, you are a entertainer
If you organise something, you are a organiser
If you deliver something, you are a deliverer
If you consume something, you are a
2024-08-01 00:42:25 root INFO     [order_1_approx] starting weight calculation for If you consume something, you are a consumer
If you organise something, you are a organiser
If you preach something, you are a preacher
If you develop something, you are a developer
If you entertain something, you are a entertainer
If you deliver something, you are a deliverer
If you interpret something, you are a interpreter
If you lose something, you are a
2024-08-01 00:42:25 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-08-01 00:45:31 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0618,  0.1759,  0.0529,  ..., -0.0497, -0.0072, -0.0829],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.4336, -1.4805,  0.0850,  ..., -1.2773, -2.7266,  0.5508],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0112, -0.0029, -0.0075,  ..., -0.0078,  0.0028,  0.0110],
        [-0.0096,  0.0031,  0.0039,  ...,  0.0199,  0.0073, -0.0090],
        [ 0.0156,  0.0081,  0.0083,  ..., -0.0075, -0.0019,  0.0333],
        ...,
        [ 0.0243, -0.0149, -0.0330,  ..., -0.0252, -0.0010, -0.0081],
        [ 0.0233,  0.0434, -0.0403,  ...,  0.0100, -0.0502,  0.0146],
        [ 0.0017,  0.0185,  0.0019,  ...,  0.0145,  0.0003, -0.0307]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.4453, -1.4707, -0.1249,  ..., -1.2686, -2.9160,  0.4221]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 00:45:32 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you consume something, you are a consumer
If you organise something, you are a organiser
If you preach something, you are a preacher
If you develop something, you are a developer
If you entertain something, you are a entertainer
If you deliver something, you are a deliverer
If you interpret something, you are a interpreter
If you lose something, you are a
2024-08-01 00:45:32 root INFO     [order_1_approx] starting weight calculation for If you deliver something, you are a deliverer
If you develop something, you are a developer
If you organise something, you are a organiser
If you entertain something, you are a entertainer
If you preach something, you are a preacher
If you lose something, you are a loser
If you consume something, you are a consumer
If you interpret something, you are a
2024-08-01 00:45:32 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-08-01 00:48:34 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0614,  0.1059,  0.0659,  ...,  0.0774, -0.0540,  0.0364],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.3672, -3.5723,  4.0078,  ..., -1.7129, -3.8906, -3.5547],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0708, -0.0282,  0.0365,  ..., -0.0429, -0.1093,  0.0033],
        [ 0.0059,  0.0359,  0.0120,  ...,  0.0250,  0.0687,  0.0313],
        [ 0.0310, -0.0103, -0.0319,  ..., -0.0177, -0.0156, -0.0170],
        ...,
        [-0.0411, -0.0284,  0.0197,  ..., -0.0393, -0.0265, -0.0211],
        [ 0.0536,  0.0206, -0.0422,  ..., -0.0181, -0.0416, -0.0084],
        [ 0.0767,  0.0390,  0.0287,  ...,  0.0711,  0.0789,  0.0039]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.1719, -3.3711,  4.0625,  ..., -1.7314, -4.0781, -3.2422]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 00:48:35 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you deliver something, you are a deliverer
If you develop something, you are a developer
If you organise something, you are a organiser
If you entertain something, you are a entertainer
If you preach something, you are a preacher
If you lose something, you are a loser
If you consume something, you are a consumer
If you interpret something, you are a
2024-08-01 00:48:36 root INFO     [order_1_approx] starting weight calculation for If you consume something, you are a consumer
If you develop something, you are a developer
If you interpret something, you are a interpreter
If you entertain something, you are a entertainer
If you organise something, you are a organiser
If you lose something, you are a loser
If you preach something, you are a preacher
If you deliver something, you are a
2024-08-01 00:48:36 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-08-01 00:51:41 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0054,  0.1177,  0.0250,  ..., -0.0780, -0.0822, -0.0236],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 6.6797, -4.1953,  2.3555,  ..., -0.1436, -4.0469, -2.0625],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0254,  0.0189, -0.0238,  ...,  0.0249, -0.1023, -0.0253],
        [-0.0310,  0.0469,  0.0039,  ..., -0.0028,  0.0699,  0.0150],
        [ 0.0225, -0.0442, -0.0130,  ...,  0.0038, -0.1182, -0.0159],
        ...,
        [-0.0268, -0.0569, -0.0282,  ...,  0.0128, -0.0603,  0.0468],
        [ 0.0763,  0.0435,  0.0437,  ..., -0.0456,  0.0697, -0.0256],
        [ 0.0044, -0.0267, -0.0335,  ...,  0.0436,  0.0016,  0.0005]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 6.1836, -3.8027,  2.0547,  ..., -0.3032, -3.6113, -2.4141]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 00:51:42 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you consume something, you are a consumer
If you develop something, you are a developer
If you interpret something, you are a interpreter
If you entertain something, you are a entertainer
If you organise something, you are a organiser
If you lose something, you are a loser
If you preach something, you are a preacher
If you deliver something, you are a
2024-08-01 00:51:42 root INFO     [order_1_approx] starting weight calculation for If you lose something, you are a loser
If you consume something, you are a consumer
If you deliver something, you are a deliverer
If you interpret something, you are a interpreter
If you preach something, you are a preacher
If you entertain something, you are a entertainer
If you develop something, you are a developer
If you organise something, you are a
2024-08-01 00:51:42 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-08-01 00:54:45 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0719,  0.3210, -0.0339,  ..., -0.0632, -0.0253, -0.0402],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.6074, -3.2891,  0.7246,  ...,  0.4834, -2.7695, -5.4766],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 1.0269e-02, -8.9264e-03,  9.3765e-03,  ..., -1.3115e-02,
          1.3824e-02, -1.6937e-03],
        [-2.2720e-02,  2.2552e-02,  2.8183e-02,  ...,  4.8676e-02,
          4.3579e-02, -1.4008e-02],
        [ 1.4023e-02, -2.0065e-02, -1.5736e-03,  ..., -1.1444e-05,
          1.6174e-02, -1.8631e-02],
        ...,
        [ 7.6103e-03,  1.0185e-02,  4.9934e-03,  ..., -5.6458e-02,
         -8.3542e-03,  3.3508e-02],
        [ 8.2092e-03, -5.7220e-03, -2.1942e-02,  ..., -4.4220e-02,
         -1.6403e-02,  3.0853e-02],
        [ 2.0638e-03,  4.1504e-02,  1.9104e-02,  ...,  3.2501e-02,
         -2.6031e-02, -1.6373e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.5410, -2.6504,  0.7490,  ...,  0.2759, -3.2969, -5.5508]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 00:54:46 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you lose something, you are a loser
If you consume something, you are a consumer
If you deliver something, you are a deliverer
If you interpret something, you are a interpreter
If you preach something, you are a preacher
If you entertain something, you are a entertainer
If you develop something, you are a developer
If you organise something, you are a
2024-08-01 00:54:46 root INFO     [order_1_approx] starting weight calculation for If you develop something, you are a developer
If you consume something, you are a consumer
If you interpret something, you are a interpreter
If you preach something, you are a preacher
If you lose something, you are a loser
If you deliver something, you are a deliverer
If you organise something, you are a organiser
If you entertain something, you are a
2024-08-01 00:54:46 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-08-01 00:57:49 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1942,  0.0245, -0.1360,  ..., -0.0623,  0.0031, -0.1498],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.0156, -2.0273,  1.3799,  ...,  0.2939, -1.6738, -4.3906],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0854, -0.0138, -0.0597,  ..., -0.0663, -0.0227, -0.0149],
        [-0.0533, -0.0085, -0.0164,  ...,  0.0039,  0.0028, -0.0263],
        [ 0.0687,  0.0119, -0.0218,  ...,  0.0300,  0.0073,  0.0027],
        ...,
        [ 0.0246, -0.0034, -0.0458,  ..., -0.0699,  0.0064,  0.0367],
        [ 0.0483,  0.0578,  0.0200,  ..., -0.0233, -0.0123,  0.0303],
        [ 0.0737,  0.0759,  0.0389,  ...,  0.0665,  0.0024, -0.0142]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.1562, -2.2383,  1.7725,  ...,  0.6968, -1.1152, -4.3281]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 00:57:50 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you develop something, you are a developer
If you consume something, you are a consumer
If you interpret something, you are a interpreter
If you preach something, you are a preacher
If you lose something, you are a loser
If you deliver something, you are a deliverer
If you organise something, you are a organiser
If you entertain something, you are a
2024-08-01 00:57:50 root INFO     [order_1_approx] starting weight calculation for If you deliver something, you are a deliverer
If you lose something, you are a loser
If you consume something, you are a consumer
If you entertain something, you are a entertainer
If you preach something, you are a preacher
If you interpret something, you are a interpreter
If you organise something, you are a organiser
If you develop something, you are a
2024-08-01 00:57:50 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-08-01 01:00:50 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0301,  0.1179,  0.0171,  ..., -0.1147,  0.0782, -0.0835],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 5.9219, -4.0781,  3.1250,  ...,  1.9785, -3.0000, -2.7656],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0070, -0.0281, -0.0182,  ..., -0.0226, -0.0665,  0.0007],
        [-0.0322,  0.0269,  0.0110,  ...,  0.0068,  0.0052,  0.0057],
        [ 0.0064, -0.0344,  0.0008,  ..., -0.0134, -0.0281,  0.0048],
        ...,
        [ 0.0344, -0.0303, -0.0136,  ...,  0.0040, -0.0108,  0.0115],
        [-0.0097,  0.0234,  0.0156,  ..., -0.0125,  0.0143, -0.0121],
        [-0.0041,  0.0054, -0.0013,  ...,  0.0490, -0.0206,  0.0042]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 5.1602, -4.1758,  3.2812,  ...,  2.2480, -2.4180, -3.3320]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 01:00:51 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you deliver something, you are a deliverer
If you lose something, you are a loser
If you consume something, you are a consumer
If you entertain something, you are a entertainer
If you preach something, you are a preacher
If you interpret something, you are a interpreter
If you organise something, you are a organiser
If you develop something, you are a
2024-08-01 01:00:51 root INFO     total operator prediction time: 1476.8999128341675 seconds
2024-08-01 01:00:51 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on over+adj_reg
2024-08-01 01:00:51 root INFO     building operator over+adj_reg
2024-08-01 01:00:51 root INFO     [order_1_approx] starting weight calculation for If something is too stated, it is overstated
If something is too stocked, it is overstocked
If something is too paid, it is overpaid
If something is too stretched, it is overstretched
If something is too dressed, it is overdressed
If something is too sized, it is oversized
If something is too arching, it is overarching
If something is too zealous, it is
2024-08-01 01:00:51 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-08-01 01:03:55 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2358, -0.0450,  0.0014,  ...,  0.0559, -0.0994, -0.0002],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.8340, -5.6094,  0.4600,  ..., -0.2922, -0.8833, -1.3574],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0003,  0.0141,  0.0118,  ..., -0.0213,  0.0221,  0.0045],
        [ 0.0674, -0.0149,  0.0171,  ...,  0.0481, -0.0137,  0.0032],
        [ 0.0737, -0.0178,  0.0527,  ..., -0.0018, -0.0099, -0.0516],
        ...,
        [ 0.0169,  0.0323,  0.0315,  ..., -0.0010,  0.0483,  0.0127],
        [ 0.0717, -0.0294,  0.0694,  ...,  0.0299, -0.0216, -0.0453],
        [ 0.0308, -0.0025,  0.0437,  ...,  0.0411, -0.0331, -0.0491]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.3203, -4.8594,  0.6294,  ..., -0.0658,  0.0000, -1.5371]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 01:03:56 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is too stated, it is overstated
If something is too stocked, it is overstocked
If something is too paid, it is overpaid
If something is too stretched, it is overstretched
If something is too dressed, it is overdressed
If something is too sized, it is oversized
If something is too arching, it is overarching
If something is too zealous, it is
2024-08-01 01:03:56 root INFO     [order_1_approx] starting weight calculation for If something is too stretched, it is overstretched
If something is too dressed, it is overdressed
If something is too zealous, it is overzealous
If something is too sized, it is oversized
If something is too arching, it is overarching
If something is too stocked, it is overstocked
If something is too stated, it is overstated
If something is too paid, it is
2024-08-01 01:03:56 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-08-01 01:07:02 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0340, -0.1094, -0.0248,  ..., -0.0370, -0.1638, -0.0653],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.7090, -3.5898, -0.1294,  ..., -0.9146, -2.2734, -3.2637],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0290,  0.0286, -0.0050,  ...,  0.0182, -0.0151, -0.0250],
        [ 0.0027, -0.0061, -0.0076,  ...,  0.0048,  0.0146,  0.0022],
        [ 0.0350, -0.0215,  0.0297,  ...,  0.0002, -0.0100, -0.0049],
        ...,
        [ 0.0013, -0.0591,  0.0067,  ...,  0.0139,  0.0453, -0.0437],
        [-0.0035, -0.0009,  0.0010,  ..., -0.0217,  0.0030,  0.0466],
        [-0.0110, -0.0131, -0.0150,  ...,  0.0060,  0.0061,  0.0294]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.4590, -3.3926, -0.3938,  ..., -0.8662, -1.6855, -2.9297]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 01:07:03 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is too stretched, it is overstretched
If something is too dressed, it is overdressed
If something is too zealous, it is overzealous
If something is too sized, it is oversized
If something is too arching, it is overarching
If something is too stocked, it is overstocked
If something is too stated, it is overstated
If something is too paid, it is
2024-08-01 01:07:03 root INFO     [order_1_approx] starting weight calculation for If something is too stocked, it is overstocked
If something is too dressed, it is overdressed
If something is too sized, it is oversized
If something is too paid, it is overpaid
If something is too arching, it is overarching
If something is too zealous, it is overzealous
If something is too stretched, it is overstretched
If something is too stated, it is
2024-08-01 01:07:03 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-08-01 01:10:07 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0058, -0.1135,  0.0774,  ..., -0.1012, -0.1362, -0.0264],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.6953, -2.3262,  0.5840,  ...,  0.7422, -1.5566, -1.7266],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0252,  0.0461, -0.0148,  ...,  0.0186,  0.0177,  0.0097],
        [ 0.0115,  0.0920,  0.0201,  ...,  0.0061, -0.0202,  0.0226],
        [ 0.0424,  0.0002,  0.0426,  ..., -0.0308, -0.0189,  0.0080],
        ...,
        [ 0.0174,  0.0130, -0.0396,  ...,  0.0128, -0.0211, -0.0026],
        [-0.0171, -0.0046, -0.0244,  ..., -0.0329, -0.0239, -0.0141],
        [ 0.0457,  0.0272,  0.0766,  ..., -0.0344, -0.0895, -0.0210]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.7363, -2.1621,  1.2275,  ...,  1.1406, -1.6836, -1.6777]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 01:10:07 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is too stocked, it is overstocked
If something is too dressed, it is overdressed
If something is too sized, it is oversized
If something is too paid, it is overpaid
If something is too arching, it is overarching
If something is too zealous, it is overzealous
If something is too stretched, it is overstretched
If something is too stated, it is
2024-08-01 01:10:08 root INFO     [order_1_approx] starting weight calculation for If something is too stretched, it is overstretched
If something is too stocked, it is overstocked
If something is too stated, it is overstated
If something is too paid, it is overpaid
If something is too zealous, it is overzealous
If something is too arching, it is overarching
If something is too sized, it is oversized
If something is too dressed, it is
2024-08-01 01:10:08 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-08-01 01:13:12 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0900, -0.1364, -0.0583,  ...,  0.0300, -0.0478,  0.0393],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.4790, -4.2734, -0.9907,  ...,  1.4766, -3.9805, -2.0820],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0266, -0.0187, -0.0041,  ...,  0.0017, -0.0025, -0.0008],
        [ 0.0091,  0.0139, -0.0278,  ..., -0.0103, -0.0196,  0.0193],
        [ 0.0005,  0.0211,  0.0524,  ...,  0.0057, -0.0180, -0.0352],
        ...,
        [ 0.0054,  0.0075, -0.0089,  ...,  0.0032,  0.0181, -0.0447],
        [-0.0002,  0.0057,  0.0112,  ...,  0.0061,  0.0293, -0.0064],
        [-0.0129,  0.0162,  0.0251,  ...,  0.0185,  0.0205, -0.0288]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.2917, -4.0820, -1.3906,  ...,  1.5166, -3.7305, -2.0273]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 01:13:13 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is too stretched, it is overstretched
If something is too stocked, it is overstocked
If something is too stated, it is overstated
If something is too paid, it is overpaid
If something is too zealous, it is overzealous
If something is too arching, it is overarching
If something is too sized, it is oversized
If something is too dressed, it is
2024-08-01 01:13:13 root INFO     [order_1_approx] starting weight calculation for If something is too dressed, it is overdressed
If something is too stated, it is overstated
If something is too arching, it is overarching
If something is too sized, it is oversized
If something is too stocked, it is overstocked
If something is too zealous, it is overzealous
If something is too paid, it is overpaid
If something is too stretched, it is
2024-08-01 01:13:13 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-08-01 01:16:17 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0372, -0.0132,  0.0097,  ..., -0.0723, -0.0398,  0.0634],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.5488, -3.4746,  0.9668,  ...,  0.0889, -0.1775, -2.6348],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0033,  0.0160,  0.0199,  ...,  0.0029,  0.0111, -0.0009],
        [-0.0026,  0.0018, -0.0067,  ...,  0.0069,  0.0154,  0.0135],
        [ 0.0114, -0.0027,  0.0621,  ...,  0.0102, -0.0042,  0.0189],
        ...,
        [ 0.0056, -0.0253, -0.0187,  ..., -0.0105,  0.0119,  0.0063],
        [-0.0022,  0.0101,  0.0082,  ..., -0.0035, -0.0141, -0.0039],
        [ 0.0073, -0.0060,  0.0341,  ...,  0.0311,  0.0014,  0.0348]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.5508, -3.4160,  0.5547,  ...,  0.7222, -0.4219, -2.7129]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 01:16:18 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is too dressed, it is overdressed
If something is too stated, it is overstated
If something is too arching, it is overarching
If something is too sized, it is oversized
If something is too stocked, it is overstocked
If something is too zealous, it is overzealous
If something is too paid, it is overpaid
If something is too stretched, it is
2024-08-01 01:16:18 root INFO     [order_1_approx] starting weight calculation for If something is too stated, it is overstated
If something is too zealous, it is overzealous
If something is too arching, it is overarching
If something is too paid, it is overpaid
If something is too dressed, it is overdressed
If something is too stretched, it is overstretched
If something is too sized, it is oversized
If something is too stocked, it is
2024-08-01 01:16:18 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-08-01 01:19:24 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1252,  0.0298,  0.0552,  ...,  0.0583,  0.0279, -0.0556],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.0156, -2.5391,  0.1545,  ..., -0.2517, -1.9658, -1.7812],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0088, -0.0011,  0.0465,  ..., -0.0430, -0.0068,  0.0010],
        [ 0.0221,  0.0535, -0.0243,  ...,  0.0261, -0.0421,  0.0254],
        [ 0.0197, -0.0376,  0.0419,  ..., -0.0101,  0.0400, -0.0016],
        ...,
        [ 0.0044,  0.0392,  0.0025,  ...,  0.0127, -0.0205, -0.0252],
        [ 0.0139,  0.0205, -0.0186,  ...,  0.0327, -0.0330, -0.0248],
        [-0.0346, -0.0124,  0.0160,  ...,  0.0224,  0.0226,  0.0309]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.6934, -2.2734,  0.0753,  ..., -0.0771, -1.5713, -1.6133]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 01:19:25 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is too stated, it is overstated
If something is too zealous, it is overzealous
If something is too arching, it is overarching
If something is too paid, it is overpaid
If something is too dressed, it is overdressed
If something is too stretched, it is overstretched
If something is too sized, it is oversized
If something is too stocked, it is
2024-08-01 01:19:25 root INFO     [order_1_approx] starting weight calculation for If something is too dressed, it is overdressed
If something is too zealous, it is overzealous
If something is too paid, it is overpaid
If something is too stated, it is overstated
If something is too sized, it is oversized
If something is too stretched, it is overstretched
If something is too stocked, it is overstocked
If something is too arching, it is
2024-08-01 01:19:25 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-08-01 01:22:25 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0190, -0.1348,  0.0285,  ...,  0.0604, -0.0587, -0.2000],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.3926, -3.1504,  2.9707,  ...,  1.3213, -1.9287, -2.7793],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0470, -0.0082,  0.0119,  ..., -0.0110,  0.0183, -0.0346],
        [ 0.0049,  0.0587, -0.0376,  ...,  0.0596,  0.0289, -0.0399],
        [ 0.0712,  0.0110,  0.0543,  ...,  0.0376,  0.0151, -0.0745],
        ...,
        [ 0.0111,  0.0041,  0.0223,  ...,  0.0274,  0.0296, -0.0046],
        [ 0.0305, -0.0003,  0.0221,  ..., -0.0012, -0.0174, -0.0194],
        [-0.0364,  0.0278,  0.0243,  ...,  0.0288,  0.0225, -0.0023]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.4736, -3.2891,  3.0195,  ...,  1.3398, -1.2100, -3.1426]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 01:22:26 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is too dressed, it is overdressed
If something is too zealous, it is overzealous
If something is too paid, it is overpaid
If something is too stated, it is overstated
If something is too sized, it is oversized
If something is too stretched, it is overstretched
If something is too stocked, it is overstocked
If something is too arching, it is
2024-08-01 01:22:26 root INFO     [order_1_approx] starting weight calculation for If something is too paid, it is overpaid
If something is too dressed, it is overdressed
If something is too zealous, it is overzealous
If something is too stated, it is overstated
If something is too stocked, it is overstocked
If something is too arching, it is overarching
If something is too stretched, it is overstretched
If something is too sized, it is
2024-08-01 01:22:26 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-08-01 01:25:27 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0262, -0.1105, -0.1117,  ..., -0.0337, -0.0380, -0.1331],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.2988, -2.4688, -1.4131,  ...,  0.4014, -3.1113,  0.0664],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0297, -0.0321,  0.0363,  ..., -0.0180,  0.0198, -0.0188],
        [-0.0287,  0.0326,  0.0025,  ...,  0.0160,  0.0112,  0.0149],
        [ 0.0508, -0.0080,  0.0380,  ...,  0.0027,  0.0316, -0.0187],
        ...,
        [-0.0085, -0.0373, -0.0251,  ...,  0.0091,  0.0020,  0.0659],
        [ 0.0083,  0.0002, -0.0049,  ...,  0.0025, -0.0017, -0.0384],
        [ 0.0047, -0.0173,  0.0018,  ...,  0.0013, -0.0092,  0.0167]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.2705, -2.4492, -1.4131,  ...,  0.5264, -2.7051, -0.0560]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 01:25:28 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is too paid, it is overpaid
If something is too dressed, it is overdressed
If something is too zealous, it is overzealous
If something is too stated, it is overstated
If something is too stocked, it is overstocked
If something is too arching, it is overarching
If something is too stretched, it is overstretched
If something is too sized, it is
2024-08-01 01:25:28 root INFO     total operator prediction time: 1476.5355546474457 seconds
2024-08-01 01:25:28 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on adj+ly_reg
2024-08-01 01:25:28 root INFO     building operator adj+ly_reg
2024-08-01 01:25:28 root INFO     [order_1_approx] starting weight calculation for The adjective form of clinical is clinically
The adjective form of cultural is culturally
The adjective form of apparent is apparently
The adjective form of significant is significantly
The adjective form of nice is nicely
The adjective form of virtual is virtually
The adjective form of political is politically
The adjective form of interesting is
2024-08-01 01:25:28 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-08-01 01:28:26 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0190,  0.0528,  0.0336,  ...,  0.1404, -0.1582, -0.0954],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.3457, -1.6465,  1.2451,  ..., -1.8984, -2.4453, -1.4365],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0150,  0.0167, -0.0106,  ...,  0.0149,  0.0143, -0.0326],
        [-0.0428, -0.0437,  0.0166,  ..., -0.0502, -0.0404, -0.0204],
        [ 0.0152,  0.0332,  0.0080,  ...,  0.0183,  0.0440, -0.0335],
        ...,
        [ 0.0003, -0.0400, -0.0255,  ..., -0.0322, -0.0292,  0.0214],
        [ 0.0072,  0.0393,  0.0024,  ...,  0.0746,  0.0978, -0.0077],
        [ 0.0269, -0.0061,  0.0092,  ...,  0.0246,  0.0174, -0.0142]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.8926, -1.3740,  1.9590,  ..., -2.3750, -1.4170, -0.6572]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 01:28:27 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The adjective form of clinical is clinically
The adjective form of cultural is culturally
The adjective form of apparent is apparently
The adjective form of significant is significantly
The adjective form of nice is nicely
The adjective form of virtual is virtually
The adjective form of political is politically
The adjective form of interesting is
2024-08-01 01:28:28 root INFO     [order_1_approx] starting weight calculation for The adjective form of political is politically
The adjective form of apparent is apparently
The adjective form of nice is nicely
The adjective form of significant is significantly
The adjective form of interesting is interestingly
The adjective form of clinical is clinically
The adjective form of cultural is culturally
The adjective form of virtual is
2024-08-01 01:28:28 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-08-01 01:31:29 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1451, -0.0614,  0.1482,  ..., -0.0008,  0.0268, -0.0656],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.7251, -3.2578, -0.4922,  ..., -3.5820, -0.6240, -0.4854],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0134, -0.1024,  0.1007,  ..., -0.0680,  0.1009,  0.0095],
        [-0.0184,  0.0095, -0.0124,  ..., -0.0259, -0.0166, -0.0068],
        [ 0.0474, -0.0383, -0.0035,  ..., -0.0219, -0.0426, -0.0491],
        ...,
        [-0.0096,  0.0354, -0.1165,  ...,  0.0762, -0.0493, -0.0074],
        [ 0.0345,  0.0900, -0.0280,  ...,  0.0735,  0.0023,  0.0339],
        [-0.0036,  0.0537, -0.0761,  ...,  0.0375, -0.0710, -0.0162]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.1855, -2.3418, -0.5605,  ..., -4.1562, -1.5430, -0.9658]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 01:31:29 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The adjective form of political is politically
The adjective form of apparent is apparently
The adjective form of nice is nicely
The adjective form of significant is significantly
The adjective form of interesting is interestingly
The adjective form of clinical is clinically
The adjective form of cultural is culturally
The adjective form of virtual is
2024-08-01 01:31:30 root INFO     [order_1_approx] starting weight calculation for The adjective form of nice is nicely
The adjective form of interesting is interestingly
The adjective form of clinical is clinically
The adjective form of apparent is apparently
The adjective form of political is politically
The adjective form of significant is significantly
The adjective form of virtual is virtually
The adjective form of cultural is
2024-08-01 01:31:30 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-08-01 01:34:30 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0622,  0.0250, -0.1074,  ...,  0.0098, -0.1398,  0.0547],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.3936, -0.3738,  2.6348,  ..., -1.1631,  0.4297,  1.2090],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0074,  0.0064,  0.0334,  ...,  0.0029,  0.0343, -0.0382],
        [ 0.0003,  0.0031,  0.0187,  ..., -0.0243,  0.0123, -0.0260],
        [ 0.0573, -0.0152, -0.0043,  ..., -0.0066, -0.0463, -0.0080],
        ...,
        [ 0.0315, -0.0328, -0.0111,  ...,  0.0243,  0.0648,  0.0091],
        [-0.0070,  0.0041, -0.0350,  ...,  0.0084,  0.0656, -0.0094],
        [ 0.0328, -0.0239, -0.0170,  ...,  0.0226, -0.0089, -0.0331]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.5859, -0.7158,  3.0840,  ..., -0.9336,  0.3667,  0.9248]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 01:34:31 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The adjective form of nice is nicely
The adjective form of interesting is interestingly
The adjective form of clinical is clinically
The adjective form of apparent is apparently
The adjective form of political is politically
The adjective form of significant is significantly
The adjective form of virtual is virtually
The adjective form of cultural is
2024-08-01 01:34:32 root INFO     [order_1_approx] starting weight calculation for The adjective form of virtual is virtually
The adjective form of cultural is culturally
The adjective form of interesting is interestingly
The adjective form of significant is significantly
The adjective form of political is politically
The adjective form of clinical is clinically
The adjective form of apparent is apparently
The adjective form of nice is
2024-08-01 01:34:32 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-08-01 01:37:33 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0048, -0.0569,  0.0905,  ..., -0.0418,  0.0389, -0.0056],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.8018, -2.2207, -1.7773,  ..., -0.7559, -6.9141, -1.3984],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.1166, -0.0986,  0.0599,  ...,  0.1670,  0.0074,  0.0443],
        [ 0.0276, -0.0581,  0.0447,  ...,  0.1068, -0.0257, -0.0382],
        [ 0.0380, -0.0592,  0.0110,  ...,  0.1029, -0.0056,  0.0309],
        ...,
        [ 0.0676, -0.0592,  0.0191,  ...,  0.1310,  0.0995,  0.0782],
        [ 0.0533,  0.0996, -0.0095,  ...,  0.1306,  0.1197,  0.0823],
        [-0.0087,  0.0089,  0.0708,  ...,  0.1127,  0.0355, -0.0150]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.1328, -1.3496, -1.4961,  ...,  0.0918, -6.5469, -0.5273]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 01:37:33 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The adjective form of virtual is virtually
The adjective form of cultural is culturally
The adjective form of interesting is interestingly
The adjective form of significant is significantly
The adjective form of political is politically
The adjective form of clinical is clinically
The adjective form of apparent is apparently
The adjective form of nice is
2024-08-01 01:37:34 root INFO     [order_1_approx] starting weight calculation for The adjective form of apparent is apparently
The adjective form of cultural is culturally
The adjective form of nice is nicely
The adjective form of political is politically
The adjective form of significant is significantly
The adjective form of interesting is interestingly
The adjective form of virtual is virtually
The adjective form of clinical is
2024-08-01 01:37:34 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-08-01 01:40:38 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2664, -0.0555, -0.0776,  ..., -0.0877, -0.0726, -0.1323],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.3418, -0.4543, -0.4910,  ..., -1.1260,  1.1836, -0.7773],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0210,  0.0048, -0.0113,  ..., -0.0001, -0.0030, -0.0073],
        [-0.0030, -0.0140, -0.0133,  ...,  0.0071, -0.0133,  0.0108],
        [-0.0319,  0.0277, -0.0048,  ...,  0.0426,  0.0074, -0.0411],
        ...,
        [ 0.0523, -0.0073, -0.0080,  ..., -0.0123,  0.0040,  0.0499],
        [-0.0139,  0.0490, -0.0373,  ..., -0.0415, -0.0142,  0.0113],
        [ 0.0215, -0.0464, -0.0303,  ...,  0.0194, -0.0167, -0.0109]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.5410, -0.4463, -0.1389,  ..., -0.7734,  0.5674, -0.2290]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 01:40:39 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The adjective form of apparent is apparently
The adjective form of cultural is culturally
The adjective form of nice is nicely
The adjective form of political is politically
The adjective form of significant is significantly
The adjective form of interesting is interestingly
The adjective form of virtual is virtually
The adjective form of clinical is
2024-08-01 01:40:39 root INFO     [order_1_approx] starting weight calculation for The adjective form of nice is nicely
The adjective form of virtual is virtually
The adjective form of significant is significantly
The adjective form of apparent is apparently
The adjective form of clinical is clinically
The adjective form of interesting is interestingly
The adjective form of cultural is culturally
The adjective form of political is
2024-08-01 01:40:39 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-08-01 01:43:44 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-6.5491e-02,  8.3008e-02, -1.8311e-04,  ...,  2.0679e-01,
        -8.5266e-02,  1.4618e-02], device='cuda:1', dtype=torch.float16,
       grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.4795, -2.1094,  0.7637,  ..., -3.0508, -0.1182,  0.5176],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0102, -0.0351,  0.0061,  ...,  0.0137,  0.0168, -0.0100],
        [-0.0349, -0.0150, -0.0090,  ..., -0.0336,  0.0110,  0.0059],
        [-0.0130, -0.0061, -0.0076,  ...,  0.0218, -0.0219, -0.0173],
        ...,
        [ 0.0044,  0.0296, -0.0152,  ..., -0.0124,  0.0024, -0.0038],
        [ 0.0122, -0.0128,  0.0054,  ...,  0.0024,  0.0275, -0.0118],
        [-0.0132,  0.0280, -0.0290,  ..., -0.0256,  0.0104, -0.0216]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.7461, -2.1230,  0.9502,  ..., -3.5352, -0.0938,  0.3022]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 01:43:45 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The adjective form of nice is nicely
The adjective form of virtual is virtually
The adjective form of significant is significantly
The adjective form of apparent is apparently
The adjective form of clinical is clinically
The adjective form of interesting is interestingly
The adjective form of cultural is culturally
The adjective form of political is
2024-08-01 01:43:45 root INFO     [order_1_approx] starting weight calculation for The adjective form of political is politically
The adjective form of clinical is clinically
The adjective form of interesting is interestingly
The adjective form of nice is nicely
The adjective form of virtual is virtually
The adjective form of significant is significantly
The adjective form of cultural is culturally
The adjective form of apparent is
2024-08-01 01:43:45 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-08-01 01:46:49 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1288,  0.1763,  0.0753,  ...,  0.0403, -0.1580, -0.0181],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.9150, -1.3311, -0.6016,  ...,  0.2305, -1.7148,  0.0938],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.1069, -0.0379,  0.0197,  ...,  0.0656,  0.0592,  0.0434],
        [-0.0270,  0.0259, -0.0511,  ...,  0.0026,  0.0091, -0.0499],
        [ 0.0429, -0.0537, -0.0183,  ...,  0.0053, -0.0149, -0.0386],
        ...,
        [-0.1121, -0.0121, -0.1311,  ..., -0.0042, -0.1395, -0.0056],
        [ 0.0846, -0.0040,  0.0922,  ...,  0.0113,  0.1284, -0.0309],
        [-0.0917, -0.0015, -0.0941,  ...,  0.0308, -0.0185, -0.0040]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.9746, -0.9717, -0.3145,  ..., -0.6294, -1.8281,  0.1470]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 01:46:50 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The adjective form of political is politically
The adjective form of clinical is clinically
The adjective form of interesting is interestingly
The adjective form of nice is nicely
The adjective form of virtual is virtually
The adjective form of significant is significantly
The adjective form of cultural is culturally
The adjective form of apparent is
2024-08-01 01:46:50 root INFO     [order_1_approx] starting weight calculation for The adjective form of cultural is culturally
The adjective form of nice is nicely
The adjective form of clinical is clinically
The adjective form of apparent is apparently
The adjective form of political is politically
The adjective form of virtual is virtually
The adjective form of interesting is interestingly
The adjective form of significant is
2024-08-01 01:46:50 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-08-01 01:49:57 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0770,  0.0526, -0.1306,  ..., -0.0836,  0.0663, -0.1321],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.0332,  0.7075, -1.0947,  ..., -4.8281, -0.7534, -2.8320],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-1.2230e-02, -1.6525e-02, -2.8259e-02,  ..., -4.0649e-02,
          1.4351e-02,  2.3544e-02],
        [-3.1708e-02, -1.4008e-02,  3.1494e-02,  ..., -4.0649e-02,
         -2.4536e-02, -8.1711e-03],
        [ 1.9409e-02,  2.4628e-02,  1.0643e-02,  ..., -1.5320e-02,
          7.6294e-05, -1.6184e-03],
        ...,
        [-1.2062e-02, -3.9330e-03, -4.3427e-02,  ...,  9.4223e-03,
          2.9114e-02,  6.4087e-02],
        [ 2.7161e-02,  1.8921e-02, -2.5452e-02,  ...,  2.0203e-02,
          4.7974e-02,  2.3743e-02],
        [ 2.3468e-02,  1.4290e-02,  1.9989e-03,  ...,  3.2898e-02,
          1.3947e-02,  1.3863e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.4668,  0.2976, -0.5542,  ..., -4.2891, -0.5488, -2.2676]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 01:49:58 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The adjective form of cultural is culturally
The adjective form of nice is nicely
The adjective form of clinical is clinically
The adjective form of apparent is apparently
The adjective form of political is politically
The adjective form of virtual is virtually
The adjective form of interesting is interestingly
The adjective form of significant is
2024-08-01 01:49:58 root INFO     total operator prediction time: 1470.178966999054 seconds
2024-08-01 01:49:58 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on verb+tion_irreg
2024-08-01 01:49:58 root INFO     building operator verb+tion_irreg
2024-08-01 01:49:58 root INFO     [order_1_approx] starting weight calculation for To stabilize results in stabilization
To expire results in expiration
To admire results in admiration
To prepare results in preparation
To utilize results in utilization
To install results in installation
To privatize results in privatization
To colonize results in
2024-08-01 01:49:58 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-08-01 01:53:06 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0704,  0.0441,  0.0668,  ..., -0.0952,  0.2058, -0.1038],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-3.0254, -1.9209,  3.4258,  ..., -0.2379, -1.2539, -2.4180],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.1355, -0.0061,  0.0692,  ...,  0.1368,  0.0752, -0.0447],
        [-0.0096,  0.0315, -0.0019,  ...,  0.0199, -0.0064,  0.0064],
        [-0.0145, -0.0210, -0.0224,  ...,  0.0048, -0.0259,  0.0064],
        ...,
        [ 0.0084,  0.0169,  0.0071,  ..., -0.0129,  0.0401, -0.0070],
        [-0.0055, -0.0017, -0.0238,  ..., -0.0262, -0.0195,  0.0201],
        [ 0.0864,  0.0030,  0.0573,  ...,  0.0900,  0.0325, -0.0174]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-2.3223, -1.7129,  3.2500,  ...,  0.0582, -1.3379, -1.9688]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 01:53:07 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To stabilize results in stabilization
To expire results in expiration
To admire results in admiration
To prepare results in preparation
To utilize results in utilization
To install results in installation
To privatize results in privatization
To colonize results in
2024-08-01 01:53:07 root INFO     [order_1_approx] starting weight calculation for To privatize results in privatization
To admire results in admiration
To prepare results in preparation
To stabilize results in stabilization
To install results in installation
To expire results in expiration
To colonize results in colonization
To utilize results in
2024-08-01 01:53:07 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-08-01 01:56:11 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0519,  0.0548,  0.0472,  ...,  0.0164, -0.1132,  0.0348],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.6172, -1.8145,  0.8091,  ...,  0.4607, -3.4375, -1.8418],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0426, -0.0043,  0.0540,  ..., -0.0316, -0.0541, -0.0114],
        [-0.0446,  0.0114, -0.0144,  ...,  0.0350,  0.0256,  0.0022],
        [ 0.0185,  0.0083,  0.0082,  ...,  0.0190, -0.0240, -0.0169],
        ...,
        [-0.0296, -0.0046, -0.0231,  ...,  0.0221,  0.0338,  0.0163],
        [ 0.0109, -0.0004, -0.0183,  ...,  0.0112, -0.0168, -0.0092],
        [-0.0221, -0.0048,  0.0044,  ...,  0.0134,  0.0135,  0.0030]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.6978, -2.0801,  0.9229,  ...,  0.1953, -3.6270, -1.7920]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 01:56:12 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To privatize results in privatization
To admire results in admiration
To prepare results in preparation
To stabilize results in stabilization
To install results in installation
To expire results in expiration
To colonize results in colonization
To utilize results in
2024-08-01 01:56:12 root INFO     [order_1_approx] starting weight calculation for To privatize results in privatization
To expire results in expiration
To stabilize results in stabilization
To prepare results in preparation
To colonize results in colonization
To utilize results in utilization
To install results in installation
To admire results in
2024-08-01 01:56:12 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-08-01 01:59:20 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0285,  0.0619,  0.0188,  ..., -0.0280,  0.0450,  0.0022],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.7246, -1.9668, -0.4023,  ...,  1.8369, -1.8115, -0.6357],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0435,  0.1257, -0.0629,  ...,  0.0086, -0.1192,  0.0435],
        [-0.0564, -0.0616,  0.0327,  ...,  0.0113,  0.0539, -0.0294],
        [ 0.0154,  0.0186,  0.0193,  ...,  0.0171, -0.0473, -0.0070],
        ...,
        [-0.0302, -0.0537,  0.0090,  ...,  0.0221,  0.0951, -0.0116],
        [ 0.0296,  0.0226, -0.0328,  ...,  0.0087, -0.0116, -0.0090],
        [-0.0105, -0.0129,  0.0199,  ...,  0.0474,  0.0233, -0.0103]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.0215, -2.0859, -0.5312,  ...,  1.9824, -1.8047, -0.7119]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 01:59:21 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To privatize results in privatization
To expire results in expiration
To stabilize results in stabilization
To prepare results in preparation
To colonize results in colonization
To utilize results in utilization
To install results in installation
To admire results in
2024-08-01 01:59:21 root INFO     [order_1_approx] starting weight calculation for To install results in installation
To admire results in admiration
To expire results in expiration
To privatize results in privatization
To colonize results in colonization
To prepare results in preparation
To utilize results in utilization
To stabilize results in
2024-08-01 01:59:21 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-08-01 02:02:27 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0773,  0.1045, -0.2854,  ..., -0.0250,  0.0746,  0.1448],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.0332, -2.6152,  0.3940,  ..., -0.5586, -3.6250, -2.6582],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0014, -0.0157,  0.0152,  ...,  0.0223, -0.0146,  0.0219],
        [-0.0181, -0.0056, -0.0207,  ...,  0.0058,  0.0136, -0.0290],
        [ 0.0112, -0.0071,  0.0035,  ...,  0.0165, -0.0111,  0.0092],
        ...,
        [-0.0023,  0.0133, -0.0033,  ..., -0.0305,  0.0229,  0.0068],
        [-0.0011,  0.0025, -0.0090,  ..., -0.0175, -0.0116, -0.0387],
        [-0.0033, -0.0131, -0.0222,  ...,  0.0010,  0.0198, -0.0091]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.0635, -2.5703,  0.3535,  ..., -0.5718, -3.8340, -2.5312]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 02:02:28 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To install results in installation
To admire results in admiration
To expire results in expiration
To privatize results in privatization
To colonize results in colonization
To prepare results in preparation
To utilize results in utilization
To stabilize results in
2024-08-01 02:02:28 root INFO     [order_1_approx] starting weight calculation for To colonize results in colonization
To admire results in admiration
To install results in installation
To utilize results in utilization
To prepare results in preparation
To privatize results in privatization
To stabilize results in stabilization
To expire results in
2024-08-01 02:02:28 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-08-01 02:05:33 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0412,  0.0956,  0.0427,  ..., -0.0624, -0.0518, -0.0538],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.4727, -3.2402,  0.4150,  ..., -0.5278, -1.6074, -1.8223],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0279,  0.0693, -0.1039,  ..., -0.0275, -0.0739, -0.0074],
        [-0.0267, -0.0469,  0.0936,  ...,  0.0403,  0.0623,  0.0208],
        [ 0.0184,  0.0286, -0.0351,  ..., -0.0035, -0.0401, -0.0096],
        ...,
        [-0.0400, -0.0238,  0.0807,  ...,  0.0354,  0.0232,  0.0658],
        [ 0.0016,  0.0190, -0.0143,  ...,  0.0070, -0.0167,  0.0130],
        [-0.0205,  0.0042,  0.0507,  ...,  0.0095, -0.0206,  0.0543]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.1729, -2.7441,  0.1428,  ..., -0.5630, -1.8525, -1.9814]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 02:05:34 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To colonize results in colonization
To admire results in admiration
To install results in installation
To utilize results in utilization
To prepare results in preparation
To privatize results in privatization
To stabilize results in stabilization
To expire results in
2024-08-01 02:05:34 root INFO     [order_1_approx] starting weight calculation for To expire results in expiration
To colonize results in colonization
To admire results in admiration
To privatize results in privatization
To utilize results in utilization
To stabilize results in stabilization
To install results in installation
To prepare results in
2024-08-01 02:05:34 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-08-01 02:08:39 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1547, -0.0136, -0.0867,  ..., -0.0088,  0.0845,  0.0643],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.9922, -5.4453,  0.2495,  ...,  2.4863, -2.8066, -3.1191],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0045,  0.0090,  0.0428,  ..., -0.0079, -0.0635, -0.0013],
        [-0.0092, -0.0426, -0.0132,  ...,  0.0663,  0.0884,  0.0735],
        [ 0.0219,  0.0021,  0.0018,  ...,  0.0124, -0.0239, -0.0028],
        ...,
        [-0.0313,  0.0221,  0.0064,  ..., -0.0038, -0.0044,  0.0045],
        [-0.0075,  0.0333,  0.0445,  ..., -0.0220,  0.0216, -0.0479],
        [ 0.0553, -0.0614,  0.0332,  ...,  0.0566,  0.0832,  0.1029]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.0469, -3.7656,  0.2065,  ...,  2.5469, -3.8789, -1.4600]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 02:08:40 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To expire results in expiration
To colonize results in colonization
To admire results in admiration
To privatize results in privatization
To utilize results in utilization
To stabilize results in stabilization
To install results in installation
To prepare results in
2024-08-01 02:08:41 root INFO     [order_1_approx] starting weight calculation for To prepare results in preparation
To admire results in admiration
To expire results in expiration
To utilize results in utilization
To privatize results in privatization
To colonize results in colonization
To stabilize results in stabilization
To install results in
2024-08-01 02:08:41 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-08-01 02:11:44 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0606, -0.0440, -0.0190,  ...,  0.0943, -0.0434, -0.0592],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.3223, -3.1680,  1.8936,  ...,  2.2891, -4.7344, -2.1855],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0117, -0.0642,  0.0049,  ...,  0.0855,  0.0157,  0.0632],
        [ 0.0676, -0.0477,  0.0841,  ...,  0.1071,  0.0947, -0.0272],
        [ 0.0462, -0.0095, -0.0016,  ...,  0.0085, -0.0153,  0.0151],
        ...,
        [-0.0315,  0.0010,  0.0259,  ..., -0.0098, -0.0432, -0.0314],
        [ 0.0514, -0.0046,  0.0063,  ...,  0.0268,  0.0605,  0.0013],
        [-0.0043, -0.0110, -0.0027,  ...,  0.0674, -0.0185,  0.0120]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.2148, -1.2793,  2.5957,  ...,  2.0371, -4.1250, -1.8184]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 02:11:45 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To prepare results in preparation
To admire results in admiration
To expire results in expiration
To utilize results in utilization
To privatize results in privatization
To colonize results in colonization
To stabilize results in stabilization
To install results in
2024-08-01 02:11:46 root INFO     [order_1_approx] starting weight calculation for To expire results in expiration
To prepare results in preparation
To utilize results in utilization
To admire results in admiration
To install results in installation
To stabilize results in stabilization
To colonize results in colonization
To privatize results in
2024-08-01 02:11:46 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-08-01 02:14:51 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0220,  0.0953, -0.1665,  ..., -0.0039, -0.0684,  0.1019],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-2.1836, -3.1133,  2.1445,  ..., -0.9077, -0.2349, -1.8018],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0009,  0.0076,  0.0347,  ..., -0.0037, -0.0168,  0.0138],
        [-0.0220, -0.0074, -0.0356,  ...,  0.0294,  0.0343, -0.0152],
        [ 0.0089,  0.0070,  0.0220,  ...,  0.0050, -0.0267, -0.0052],
        ...,
        [-0.0089, -0.0102, -0.0358,  ..., -0.0109,  0.0555,  0.0071],
        [ 0.0249,  0.0120,  0.0144,  ...,  0.0015, -0.0310, -0.0078],
        [-0.0048, -0.0129, -0.0005,  ...,  0.0180,  0.0106,  0.0010]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-2.2656, -3.0352,  2.0312,  ..., -0.4973, -0.4204, -1.7490]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 02:14:52 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To expire results in expiration
To prepare results in preparation
To utilize results in utilization
To admire results in admiration
To install results in installation
To stabilize results in stabilization
To colonize results in colonization
To privatize results in
2024-08-01 02:14:52 root INFO     total operator prediction time: 1493.8109953403473 seconds
2024-08-01 02:14:52 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on verb+able_reg
2024-08-01 02:14:52 root INFO     building operator verb+able_reg
2024-08-01 02:14:52 root INFO     [order_1_approx] starting weight calculation for If you can achieve something, that thing is achieveable
If you can avoid something, that thing is avoidable
If you can observe something, that thing is observable
If you can admire something, that thing is admirable
If you can improve something, that thing is improvable
If you can manage something, that thing is manageable
If you can recognize something, that thing is recognizable
If you can edit something, that thing is
2024-08-01 02:14:52 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-08-01 02:17:59 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1046,  0.1373, -0.1155,  ...,  0.0006, -0.0213,  0.0427],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.5762, -0.1211, -1.9258,  ..., -3.4297, -7.8438, -4.1016],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0182, -0.0227,  0.0192,  ...,  0.0298,  0.0276,  0.0394],
        [-0.0154,  0.0180,  0.0084,  ...,  0.0042, -0.0029,  0.0107],
        [ 0.0374, -0.0235,  0.0229,  ...,  0.0125, -0.0053, -0.0118],
        ...,
        [ 0.0455, -0.0087,  0.0228,  ..., -0.0254,  0.0227, -0.0426],
        [ 0.0388, -0.0283, -0.0057,  ..., -0.0285,  0.0676,  0.0128],
        [ 0.0595,  0.0069, -0.0031,  ..., -0.0157,  0.0312,  0.0589]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.2051, -0.1807, -1.8447,  ..., -3.2461, -6.6562, -3.3730]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 02:18:00 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you can achieve something, that thing is achieveable
If you can avoid something, that thing is avoidable
If you can observe something, that thing is observable
If you can admire something, that thing is admirable
If you can improve something, that thing is improvable
If you can manage something, that thing is manageable
If you can recognize something, that thing is recognizable
If you can edit something, that thing is
2024-08-01 02:18:00 root INFO     [order_1_approx] starting weight calculation for If you can achieve something, that thing is achieveable
If you can edit something, that thing is editable
If you can avoid something, that thing is avoidable
If you can manage something, that thing is manageable
If you can admire something, that thing is admirable
If you can improve something, that thing is improvable
If you can recognize something, that thing is recognizable
If you can observe something, that thing is
2024-08-01 02:18:00 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-08-01 02:21:02 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0436,  0.1826, -0.0081,  ...,  0.1288, -0.0944, -0.1812],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.7656, -1.3145, -1.3711,  ..., -4.3125, -5.3906, -0.8101],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0654,  0.0222,  0.0470,  ...,  0.0859,  0.0964,  0.0438],
        [-0.0584,  0.0452, -0.0243,  ..., -0.0095,  0.0460,  0.0343],
        [-0.0020, -0.0430, -0.0397,  ...,  0.0265, -0.0659, -0.0164],
        ...,
        [ 0.0064, -0.0185, -0.0178,  ..., -0.0662, -0.0582, -0.0448],
        [ 0.0409, -0.0392, -0.0519,  ...,  0.0329, -0.0268,  0.0084],
        [ 0.0114,  0.0289,  0.0116,  ...,  0.0554,  0.0516, -0.0428]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.8320, -0.8359, -1.8594,  ..., -4.5430, -5.1719, -0.5791]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 02:21:04 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you can achieve something, that thing is achieveable
If you can edit something, that thing is editable
If you can avoid something, that thing is avoidable
If you can manage something, that thing is manageable
If you can admire something, that thing is admirable
If you can improve something, that thing is improvable
If you can recognize something, that thing is recognizable
If you can observe something, that thing is
2024-08-01 02:21:04 root INFO     [order_1_approx] starting weight calculation for If you can avoid something, that thing is avoidable
If you can edit something, that thing is editable
If you can observe something, that thing is observable
If you can achieve something, that thing is achieveable
If you can admire something, that thing is admirable
If you can manage something, that thing is manageable
If you can recognize something, that thing is recognizable
If you can improve something, that thing is
2024-08-01 02:21:04 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-08-01 02:24:06 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0095,  0.0675,  0.1333,  ...,  0.1110,  0.0191,  0.0570],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.3477, -0.6812, -0.2134,  ..., -2.7930, -7.2266, -2.9648],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0145, -0.0542,  0.0238,  ..., -0.0447,  0.0108,  0.0134],
        [-0.0269,  0.0105, -0.0120,  ..., -0.0089,  0.0011,  0.0264],
        [ 0.0456,  0.0490, -0.0309,  ...,  0.0265,  0.0088, -0.0139],
        ...,
        [-0.0047, -0.0193,  0.0275,  ..., -0.0424, -0.0064, -0.0156],
        [ 0.0196,  0.0258, -0.0098,  ...,  0.0237, -0.0245, -0.0233],
        [ 0.0041, -0.0392,  0.0258,  ...,  0.0033, -0.0258, -0.0160]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.1387, -0.4194, -0.1006,  ..., -2.9492, -6.7812, -3.0859]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 02:24:07 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you can avoid something, that thing is avoidable
If you can edit something, that thing is editable
If you can observe something, that thing is observable
If you can achieve something, that thing is achieveable
If you can admire something, that thing is admirable
If you can manage something, that thing is manageable
If you can recognize something, that thing is recognizable
If you can improve something, that thing is
2024-08-01 02:24:07 root INFO     [order_1_approx] starting weight calculation for If you can avoid something, that thing is avoidable
If you can edit something, that thing is editable
If you can improve something, that thing is improvable
If you can achieve something, that thing is achieveable
If you can manage something, that thing is manageable
If you can admire something, that thing is admirable
If you can observe something, that thing is observable
If you can recognize something, that thing is
2024-08-01 02:24:07 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-08-01 02:27:09 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0563,  0.1329,  0.0103,  ...,  0.1345,  0.0144, -0.1172],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-3.0312,  1.6348, -0.2300,  ..., -4.0273, -6.9297, -1.0195],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0213, -0.0630,  0.0409,  ...,  0.0526,  0.0641,  0.0596],
        [-0.0496,  0.0186, -0.0394,  ..., -0.0285, -0.0543,  0.0798],
        [ 0.0396, -0.0066, -0.0367,  ..., -0.0320, -0.0367, -0.0194],
        ...,
        [ 0.0153, -0.0457,  0.0271,  ..., -0.0242,  0.0025,  0.0145],
        [-0.0098,  0.0077, -0.0340,  ...,  0.0122, -0.0247, -0.0311],
        [ 0.0457, -0.0066, -0.0364,  ...,  0.0555,  0.0175, -0.0309]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-2.5195,  1.3066, -0.4282,  ..., -3.8691, -6.9336, -1.1543]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 02:27:10 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you can avoid something, that thing is avoidable
If you can edit something, that thing is editable
If you can improve something, that thing is improvable
If you can achieve something, that thing is achieveable
If you can manage something, that thing is manageable
If you can admire something, that thing is admirable
If you can observe something, that thing is observable
If you can recognize something, that thing is
2024-08-01 02:27:10 root INFO     [order_1_approx] starting weight calculation for If you can admire something, that thing is admirable
If you can observe something, that thing is observable
If you can recognize something, that thing is recognizable
If you can edit something, that thing is editable
If you can improve something, that thing is improvable
If you can manage something, that thing is manageable
If you can avoid something, that thing is avoidable
If you can achieve something, that thing is
2024-08-01 02:27:10 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-08-01 02:30:11 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0040,  0.1237, -0.0890,  ...,  0.1777, -0.1447,  0.0066],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.0586,  0.1727, -1.8770,  ..., -3.8457, -8.2344, -3.5918],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0130, -0.0123, -0.0042,  ...,  0.0170,  0.0345,  0.0183],
        [-0.0431,  0.0279, -0.0426,  ..., -0.0075, -0.0302,  0.0144],
        [ 0.0472, -0.0152,  0.0036,  ...,  0.0034, -0.0353,  0.0006],
        ...,
        [ 0.0009,  0.0227,  0.0584,  ..., -0.0275,  0.0049, -0.0326],
        [ 0.1006,  0.0239, -0.0023,  ..., -0.0471,  0.0314,  0.0220],
        [ 0.0088,  0.0036, -0.0159,  ...,  0.0455,  0.0140, -0.0197]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.1279, -0.5352, -2.0156,  ..., -3.9473, -7.5195, -3.6621]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 02:30:12 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you can admire something, that thing is admirable
If you can observe something, that thing is observable
If you can recognize something, that thing is recognizable
If you can edit something, that thing is editable
If you can improve something, that thing is improvable
If you can manage something, that thing is manageable
If you can avoid something, that thing is avoidable
If you can achieve something, that thing is
2024-08-01 02:30:12 root INFO     [order_1_approx] starting weight calculation for If you can edit something, that thing is editable
If you can improve something, that thing is improvable
If you can observe something, that thing is observable
If you can recognize something, that thing is recognizable
If you can achieve something, that thing is achieveable
If you can manage something, that thing is manageable
If you can admire something, that thing is admirable
If you can avoid something, that thing is
2024-08-01 02:30:12 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-08-01 02:33:18 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1675,  0.0579, -0.0424,  ...,  0.0871, -0.0126,  0.0501],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.7793, -0.2871, -2.8730,  ..., -1.6475, -6.3516, -1.9814],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0428, -0.0930,  0.0146,  ...,  0.0495,  0.0549,  0.0369],
        [-0.0271,  0.0043, -0.0209,  ..., -0.0199,  0.0353,  0.0329],
        [ 0.0402, -0.0115,  0.0225,  ...,  0.0155,  0.0570, -0.0098],
        ...,
        [ 0.0013,  0.0005,  0.0498,  ..., -0.0098,  0.0289, -0.0104],
        [ 0.0799,  0.0502, -0.0428,  ..., -0.0019,  0.0123,  0.0059],
        [ 0.0408,  0.0288,  0.0256,  ...,  0.0117,  0.0167, -0.0776]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.0063,  0.1213, -2.3164,  ..., -1.7354, -6.0117, -1.3379]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 02:33:19 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you can edit something, that thing is editable
If you can improve something, that thing is improvable
If you can observe something, that thing is observable
If you can recognize something, that thing is recognizable
If you can achieve something, that thing is achieveable
If you can manage something, that thing is manageable
If you can admire something, that thing is admirable
If you can avoid something, that thing is
2024-08-01 02:33:19 root INFO     [order_1_approx] starting weight calculation for If you can avoid something, that thing is avoidable
If you can edit something, that thing is editable
If you can manage something, that thing is manageable
If you can improve something, that thing is improvable
If you can observe something, that thing is observable
If you can recognize something, that thing is recognizable
If you can achieve something, that thing is achieveable
If you can admire something, that thing is
2024-08-01 02:33:19 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-08-01 02:36:20 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([0.0328, 0.1597, 0.0443,  ..., 0.0255, 0.1197, 0.0033], device='cuda:1',
       dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.9668, -0.3184, -2.8086,  ..., -2.5684, -5.5938, -1.3750],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0009,  0.0171, -0.0424,  ...,  0.0031, -0.0307,  0.0307],
        [-0.0414,  0.0120,  0.0109,  ..., -0.0297,  0.0172,  0.0041],
        [-0.0131,  0.0358,  0.0228,  ..., -0.0096, -0.0209, -0.0043],
        ...,
        [-0.0142,  0.0122, -0.0447,  ..., -0.0313, -0.0095,  0.0167],
        [ 0.0331, -0.0294,  0.0152,  ..., -0.0155, -0.0091,  0.0067],
        [ 0.0035,  0.0337, -0.0343,  ..., -0.0066, -0.0133,  0.0141]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.6758, -1.0430, -2.9746,  ..., -3.0039, -4.7500, -2.0449]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 02:36:21 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you can avoid something, that thing is avoidable
If you can edit something, that thing is editable
If you can manage something, that thing is manageable
If you can improve something, that thing is improvable
If you can observe something, that thing is observable
If you can recognize something, that thing is recognizable
If you can achieve something, that thing is achieveable
If you can admire something, that thing is
2024-08-01 02:36:21 root INFO     [order_1_approx] starting weight calculation for If you can recognize something, that thing is recognizable
If you can admire something, that thing is admirable
If you can edit something, that thing is editable
If you can avoid something, that thing is avoidable
If you can observe something, that thing is observable
If you can achieve something, that thing is achieveable
If you can improve something, that thing is improvable
If you can manage something, that thing is
2024-08-01 02:36:21 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-08-01 02:39:27 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0172,  0.2566,  0.0904,  ...,  0.1188, -0.0811, -0.0846],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.1279, -0.4404,  0.2373,  ..., -3.9062, -4.9141, -2.1484],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0157, -0.0375,  0.0124,  ...,  0.0127,  0.0014,  0.0162],
        [ 0.0264, -0.0208, -0.0354,  ...,  0.0006,  0.0242,  0.0307],
        [-0.0128, -0.0072,  0.0200,  ...,  0.0050, -0.0134, -0.0325],
        ...,
        [ 0.0122, -0.0027,  0.0184,  ..., -0.0058,  0.0161, -0.0053],
        [-0.0069,  0.0089, -0.0310,  ..., -0.0152,  0.0381,  0.0325],
        [ 0.0071,  0.0030, -0.0295,  ...,  0.0088, -0.0083, -0.0252]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.9883, -0.7842,  0.4180,  ..., -3.7598, -4.5742, -2.1133]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 02:39:28 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you can recognize something, that thing is recognizable
If you can admire something, that thing is admirable
If you can edit something, that thing is editable
If you can avoid something, that thing is avoidable
If you can observe something, that thing is observable
If you can achieve something, that thing is achieveable
If you can improve something, that thing is improvable
If you can manage something, that thing is
2024-08-01 02:39:28 root INFO     total operator prediction time: 1476.5563819408417 seconds
2024-08-01 02:39:28 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on un+adj_reg
2024-08-01 02:39:28 root INFO     building operator un+adj_reg
2024-08-01 02:39:29 root INFO     [order_1_approx] starting weight calculation for The opposite of restricted is unrestricted
The opposite of specified is unspecified
The opposite of believable is unbelievable
The opposite of available is unavailable
The opposite of intended is unintended
The opposite of veiled is unveiled
The opposite of happy is unhappy
The opposite of employed is
2024-08-01 02:39:29 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-08-01 02:42:36 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0810, -0.1028, -0.0994,  ...,  0.0867, -0.0756, -0.0698],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.6172, -0.4800, -0.8042,  ...,  0.1450,  0.8789, -2.2930],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0229, -0.0025, -0.0052,  ..., -0.0152,  0.0170,  0.0355],
        [-0.0312, -0.0097,  0.0418,  ...,  0.0165,  0.0532,  0.0013],
        [ 0.0180,  0.0345, -0.0086,  ..., -0.0274,  0.0233,  0.0434],
        ...,
        [ 0.0022, -0.0395, -0.0460,  ...,  0.0056, -0.0660, -0.0256],
        [ 0.0114, -0.0047,  0.0059,  ...,  0.0558,  0.0145,  0.0005],
        [-0.0395, -0.0186, -0.0191,  ...,  0.0496, -0.0120, -0.0652]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.1841, -0.9355, -0.1587,  ..., -0.3037,  0.4844, -2.6289]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 02:42:37 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of restricted is unrestricted
The opposite of specified is unspecified
The opposite of believable is unbelievable
The opposite of available is unavailable
The opposite of intended is unintended
The opposite of veiled is unveiled
The opposite of happy is unhappy
The opposite of employed is
2024-08-01 02:42:38 root INFO     [order_1_approx] starting weight calculation for The opposite of veiled is unveiled
The opposite of happy is unhappy
The opposite of believable is unbelievable
The opposite of available is unavailable
The opposite of employed is unemployed
The opposite of intended is unintended
The opposite of restricted is unrestricted
The opposite of specified is
2024-08-01 02:42:38 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-08-01 02:45:38 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0474, -0.0096, -0.0692,  ..., -0.0061, -0.0533, -0.1160],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.5537,  1.6748, -0.3418,  ...,  1.5254,  0.7129,  0.0957],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0118,  0.0307,  0.0071,  ...,  0.0166,  0.0393,  0.0244],
        [-0.0160,  0.0287,  0.0862,  ...,  0.0294, -0.0106, -0.0175],
        [-0.0132,  0.0351,  0.0077,  ..., -0.0135,  0.0147,  0.0266],
        ...,
        [ 0.0053, -0.0057,  0.0311,  ..., -0.0103, -0.0094, -0.0734],
        [-0.0067, -0.0284, -0.0135,  ...,  0.0289, -0.0299,  0.0339],
        [-0.0104,  0.0632,  0.0208,  ..., -0.0226,  0.1059, -0.0584]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.2339,  2.8477, -0.0276,  ...,  2.1484, -0.0186,  0.6064]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 02:45:39 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of veiled is unveiled
The opposite of happy is unhappy
The opposite of believable is unbelievable
The opposite of available is unavailable
The opposite of employed is unemployed
The opposite of intended is unintended
The opposite of restricted is unrestricted
The opposite of specified is
2024-08-01 02:45:40 root INFO     [order_1_approx] starting weight calculation for The opposite of restricted is unrestricted
The opposite of intended is unintended
The opposite of specified is unspecified
The opposite of happy is unhappy
The opposite of believable is unbelievable
The opposite of available is unavailable
The opposite of employed is unemployed
The opposite of veiled is
2024-08-01 02:45:40 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-08-01 02:48:46 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2610, -0.2203, -0.0320,  ...,  0.0955,  0.0149,  0.1530],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.4243,  0.7080,  0.0234,  ...,  3.1973, -2.5215, -0.2979],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0573, -0.0365,  0.0023,  ..., -0.0165,  0.0163,  0.0003],
        [ 0.0020,  0.0352, -0.0078,  ..., -0.0199,  0.0155, -0.0315],
        [ 0.0363, -0.0875,  0.0187,  ..., -0.0187, -0.0106, -0.0390],
        ...,
        [ 0.0468, -0.0123, -0.0461,  ...,  0.0249, -0.0283,  0.0116],
        [-0.0089, -0.0013,  0.0020,  ...,  0.0117, -0.0067, -0.0226],
        [-0.0319,  0.0263, -0.0259,  ...,  0.0047, -0.0544,  0.0402]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.5181,  0.8594, -0.0486,  ...,  2.8086, -2.9453, -0.6504]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 02:48:47 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of restricted is unrestricted
The opposite of intended is unintended
The opposite of specified is unspecified
The opposite of happy is unhappy
The opposite of believable is unbelievable
The opposite of available is unavailable
The opposite of employed is unemployed
The opposite of veiled is
2024-08-01 02:48:48 root INFO     [order_1_approx] starting weight calculation for The opposite of restricted is unrestricted
The opposite of specified is unspecified
The opposite of happy is unhappy
The opposite of employed is unemployed
The opposite of available is unavailable
The opposite of believable is unbelievable
The opposite of veiled is unveiled
The opposite of intended is
2024-08-01 02:48:48 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-08-01 02:51:50 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0650,  0.0981, -0.0184,  ..., -0.0159, -0.0768, -0.0295],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.4844, -0.0899, -0.2324,  ...,  0.7080,  0.8359, -3.7500],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0182, -0.0064,  0.0287,  ...,  0.0451,  0.0054,  0.0285],
        [-0.0537,  0.0457, -0.0025,  ...,  0.0057,  0.0328, -0.0411],
        [-0.0147, -0.0011,  0.0272,  ..., -0.0033, -0.0526,  0.0290],
        ...,
        [-0.0051,  0.0587, -0.0250,  ..., -0.0509, -0.0303, -0.0233],
        [-0.0085,  0.0314, -0.0013,  ..., -0.0826, -0.0040,  0.0187],
        [-0.0091,  0.0137,  0.0187,  ...,  0.0925,  0.0471, -0.0146]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.8682, -0.3201, -0.5327,  ...,  0.8467,  0.2720, -3.3594]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 02:51:51 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of restricted is unrestricted
The opposite of specified is unspecified
The opposite of happy is unhappy
The opposite of employed is unemployed
The opposite of available is unavailable
The opposite of believable is unbelievable
The opposite of veiled is unveiled
The opposite of intended is
2024-08-01 02:51:51 root INFO     [order_1_approx] starting weight calculation for The opposite of intended is unintended
The opposite of available is unavailable
The opposite of happy is unhappy
The opposite of specified is unspecified
The opposite of veiled is unveiled
The opposite of restricted is unrestricted
The opposite of employed is unemployed
The opposite of believable is
2024-08-01 02:51:52 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-08-01 02:54:52 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0541,  0.0927,  0.1923,  ..., -0.0753, -0.1501, -0.0208],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.4297, -3.5059,  0.4678,  ..., -2.1094, -1.7930, -3.2812],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0085, -0.0416,  0.0124,  ..., -0.0388,  0.0260,  0.0358],
        [ 0.0148,  0.0326,  0.0048,  ...,  0.0465,  0.0163, -0.0096],
        [ 0.0034, -0.0081,  0.0370,  ...,  0.0156, -0.0221, -0.0084],
        ...,
        [ 0.0190, -0.0106, -0.0320,  ..., -0.0225,  0.0206,  0.0300],
        [-0.0100,  0.0362, -0.0314,  ...,  0.0535, -0.0158, -0.0251],
        [-0.0328,  0.0676,  0.0027,  ...,  0.0229,  0.0165, -0.0193]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.3105, -3.8711,  0.9565,  ..., -1.5459, -1.6260, -2.8027]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 02:54:53 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of intended is unintended
The opposite of available is unavailable
The opposite of happy is unhappy
The opposite of specified is unspecified
The opposite of veiled is unveiled
The opposite of restricted is unrestricted
The opposite of employed is unemployed
The opposite of believable is
2024-08-01 02:54:53 root INFO     [order_1_approx] starting weight calculation for The opposite of employed is unemployed
The opposite of specified is unspecified
The opposite of restricted is unrestricted
The opposite of believable is unbelievable
The opposite of happy is unhappy
The opposite of veiled is unveiled
The opposite of intended is unintended
The opposite of available is
2024-08-01 02:54:53 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-08-01 02:57:59 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0025, -0.0430,  0.0129,  ..., -0.0177, -0.0351, -0.1570],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.7358, -1.5195,  1.2070,  ..., -1.0771, -0.8721, -1.1367],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0352,  0.0111, -0.0258,  ...,  0.0092, -0.0048,  0.0142],
        [-0.0695, -0.0392, -0.0187,  ..., -0.0446,  0.0804,  0.0661],
        [-0.0042,  0.0824,  0.0461,  ...,  0.0244, -0.0228, -0.0077],
        ...,
        [ 0.0007,  0.0042, -0.0199,  ..., -0.0480,  0.0207,  0.0273],
        [-0.0363,  0.0366,  0.0245,  ...,  0.0750,  0.0044, -0.0197],
        [ 0.0017,  0.0174,  0.0230,  ...,  0.0025,  0.0227,  0.0229]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.1538,  0.0820,  0.8452,  ..., -0.0684, -1.0957,  0.4834]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 02:58:00 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of employed is unemployed
The opposite of specified is unspecified
The opposite of restricted is unrestricted
The opposite of believable is unbelievable
The opposite of happy is unhappy
The opposite of veiled is unveiled
The opposite of intended is unintended
The opposite of available is
2024-08-01 02:58:00 root INFO     [order_1_approx] starting weight calculation for The opposite of restricted is unrestricted
The opposite of available is unavailable
The opposite of intended is unintended
The opposite of believable is unbelievable
The opposite of employed is unemployed
The opposite of specified is unspecified
The opposite of veiled is unveiled
The opposite of happy is
2024-08-01 02:58:00 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-08-01 03:01:03 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0109, -0.0135, -0.0384,  ..., -0.0477, -0.1793,  0.0400],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.3066, -1.8926,  1.4287,  ..., -2.7871, -2.1719, -1.7168],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0632,  0.0542, -0.0268,  ..., -0.0275,  0.0395,  0.0007],
        [-0.0184, -0.0546,  0.0382,  ...,  0.0434, -0.0243, -0.0477],
        [-0.0167,  0.0007, -0.0079,  ..., -0.0114, -0.0294,  0.0176],
        ...,
        [ 0.0229, -0.0574, -0.0124,  ..., -0.0165, -0.0169,  0.0042],
        [-0.0381, -0.0072, -0.0425,  ...,  0.0377, -0.0409, -0.0226],
        [-0.0091, -0.0285, -0.0272,  ...,  0.0322,  0.0030, -0.0236]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.8613, -1.6748,  1.3926,  ..., -2.7461, -2.2773, -1.8594]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 03:01:04 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of restricted is unrestricted
The opposite of available is unavailable
The opposite of intended is unintended
The opposite of believable is unbelievable
The opposite of employed is unemployed
The opposite of specified is unspecified
The opposite of veiled is unveiled
The opposite of happy is
2024-08-01 03:01:04 root INFO     [order_1_approx] starting weight calculation for The opposite of available is unavailable
The opposite of specified is unspecified
The opposite of intended is unintended
The opposite of happy is unhappy
The opposite of believable is unbelievable
The opposite of veiled is unveiled
The opposite of employed is unemployed
The opposite of restricted is
2024-08-01 03:01:04 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-08-01 03:04:07 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0450,  0.0357, -0.1489,  ...,  0.0802,  0.0635, -0.0057],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.9834,  0.1299,  1.7549,  ...,  0.7334, -1.0830, -1.7959],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0117, -0.0035,  0.0035,  ...,  0.0193,  0.0583,  0.0188],
        [-0.0211,  0.0068,  0.0298,  ..., -0.0233, -0.0185,  0.0031],
        [ 0.0464, -0.0338,  0.0359,  ...,  0.0025, -0.0328, -0.0280],
        ...,
        [ 0.0304,  0.0133, -0.0118,  ..., -0.0006, -0.0330,  0.0059],
        [-0.0089, -0.0445, -0.0227,  ...,  0.0141, -0.0419, -0.0058],
        [-0.0530,  0.0417,  0.0007,  ...,  0.0142,  0.0312,  0.0214]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.3867, -0.3389,  1.3389,  ...,  1.1484, -1.2129, -1.5967]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 03:04:08 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of available is unavailable
The opposite of specified is unspecified
The opposite of intended is unintended
The opposite of happy is unhappy
The opposite of believable is unbelievable
The opposite of veiled is unveiled
The opposite of employed is unemployed
The opposite of restricted is
2024-08-01 03:04:08 root INFO     total operator prediction time: 1479.8468189239502 seconds
2024-08-01 03:04:08 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on re+verb_reg
2024-08-01 03:04:08 root INFO     building operator re+verb_reg
2024-08-01 03:04:08 root INFO     [order_1_approx] starting weight calculation for To establish again is to reestablish
To consider again is to reconsider
To occur again is to reoccur
To define again is to redefine
To adjust again is to readjust
To distribute again is to redistribute
To decorate again is to redecorate
To write again is to
2024-08-01 03:04:08 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-08-01 03:07:16 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0574,  0.1249, -0.0432,  ..., -0.0904, -0.1120,  0.0421],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.0352, -3.0762,  0.4629,  ...,  1.9639, -4.6562, -2.5469],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0063,  0.0054,  0.0283,  ..., -0.0023,  0.0008, -0.0129],
        [ 0.0090, -0.0624, -0.0362,  ...,  0.0795,  0.0642,  0.0461],
        [-0.0005,  0.0227,  0.0040,  ..., -0.0298, -0.0154, -0.0053],
        ...,
        [ 0.0176, -0.1218, -0.0138,  ...,  0.0901,  0.0709,  0.0724],
        [ 0.0018,  0.0497, -0.0175,  ..., -0.0661, -0.0205, -0.0201],
        [ 0.0108,  0.0219, -0.0110,  ...,  0.0046, -0.0065, -0.0138]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.9443, -2.2656, -0.1470,  ...,  3.2832, -4.9062, -3.0898]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 03:07:17 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To establish again is to reestablish
To consider again is to reconsider
To occur again is to reoccur
To define again is to redefine
To adjust again is to readjust
To distribute again is to redistribute
To decorate again is to redecorate
To write again is to
2024-08-01 03:07:17 root INFO     [order_1_approx] starting weight calculation for To distribute again is to redistribute
To decorate again is to redecorate
To write again is to rewrite
To adjust again is to readjust
To establish again is to reestablish
To occur again is to reoccur
To consider again is to reconsider
To define again is to
2024-08-01 03:07:17 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-08-01 03:10:23 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1780,  0.0822, -0.0663,  ...,  0.0231,  0.0886, -0.1067],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.7334, -2.8828,  2.1094,  ...,  1.7090, -3.6113, -2.9355],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0987,  0.0142,  0.0168,  ..., -0.0249,  0.0203,  0.0237],
        [ 0.0558, -0.0668, -0.0545,  ...,  0.0701,  0.0616, -0.0751],
        [-0.0786,  0.0735,  0.0617,  ..., -0.0292, -0.1459,  0.1290],
        ...,
        [ 0.0042, -0.0390, -0.0168,  ...,  0.0434,  0.0491, -0.0610],
        [ 0.0427,  0.0511,  0.0029,  ..., -0.0519, -0.0309,  0.0897],
        [-0.0706, -0.0015,  0.0255,  ...,  0.0588, -0.0775,  0.0450]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.4043, -2.5234,  0.8613,  ...,  1.5840, -3.2715, -3.5625]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 03:10:24 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To distribute again is to redistribute
To decorate again is to redecorate
To write again is to rewrite
To adjust again is to readjust
To establish again is to reestablish
To occur again is to reoccur
To consider again is to reconsider
To define again is to
2024-08-01 03:10:24 root INFO     [order_1_approx] starting weight calculation for To decorate again is to redecorate
To define again is to redefine
To consider again is to reconsider
To distribute again is to redistribute
To write again is to rewrite
To establish again is to reestablish
To occur again is to reoccur
To adjust again is to
2024-08-01 03:10:24 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-08-01 03:13:29 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0149,  0.1602, -0.1257,  ..., -0.0264, -0.0106,  0.0017],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.0754, -2.2539, -1.9805,  ...,  1.8594, -3.9883, -3.5000],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0010, -0.0536, -0.0026,  ...,  0.0050,  0.0161,  0.0215],
        [-0.0246, -0.0038, -0.0356,  ..., -0.0025, -0.0131, -0.0002],
        [-0.0192,  0.0138,  0.0197,  ...,  0.0059, -0.0373,  0.0058],
        ...,
        [-0.0134, -0.0217,  0.0095,  ...,  0.0202,  0.0170,  0.0075],
        [-0.0571,  0.0471, -0.0207,  ..., -0.0348, -0.0155, -0.0286],
        [ 0.0695,  0.0318,  0.0074,  ..., -0.0104, -0.0056,  0.0070]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.0900, -2.3555, -2.7891,  ...,  1.3848, -3.7227, -2.9160]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 03:13:30 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To decorate again is to redecorate
To define again is to redefine
To consider again is to reconsider
To distribute again is to redistribute
To write again is to rewrite
To establish again is to reestablish
To occur again is to reoccur
To adjust again is to
2024-08-01 03:13:30 root INFO     [order_1_approx] starting weight calculation for To occur again is to reoccur
To define again is to redefine
To adjust again is to readjust
To establish again is to reestablish
To consider again is to reconsider
To write again is to rewrite
To distribute again is to redistribute
To decorate again is to
2024-08-01 03:13:31 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-08-01 03:16:37 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0586,  0.0501, -0.0878,  ..., -0.0281,  0.0170,  0.0429],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-2.4844, -3.1387,  0.1798,  ...,  1.8359, -4.1562, -2.8711],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 1.9180e-02, -1.6937e-02,  5.2948e-03,  ..., -1.9882e-02,
         -1.2619e-02,  7.6294e-03],
        [ 1.0437e-02, -1.8219e-02,  1.7899e-02,  ...,  2.6154e-02,
          3.3081e-02, -1.7410e-02],
        [ 3.4809e-05,  2.8793e-02, -4.6631e-02,  ..., -2.3987e-02,
         -2.5146e-02,  1.0284e-02],
        ...,
        [-3.8872e-03,  5.2490e-03,  1.2154e-02,  ..., -1.1398e-02,
          9.7656e-03, -5.2795e-03],
        [-5.0659e-03,  2.3087e-02, -1.8997e-02,  ..., -5.6992e-03,
         -1.9562e-02, -2.5673e-03],
        [-8.1253e-03,  3.9520e-02, -1.7990e-02,  ...,  9.6893e-03,
         -3.1006e-02, -3.0403e-03]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-2.8145, -2.2383, -0.5176,  ...,  1.8096, -4.4531, -3.4375]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 03:16:38 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To occur again is to reoccur
To define again is to redefine
To adjust again is to readjust
To establish again is to reestablish
To consider again is to reconsider
To write again is to rewrite
To distribute again is to redistribute
To decorate again is to
2024-08-01 03:16:38 root INFO     [order_1_approx] starting weight calculation for To write again is to rewrite
To adjust again is to readjust
To distribute again is to redistribute
To establish again is to reestablish
To define again is to redefine
To consider again is to reconsider
To decorate again is to redecorate
To occur again is to
2024-08-01 03:16:38 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-08-01 03:19:43 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0645,  0.0540,  0.0381,  ..., -0.1692, -0.0318, -0.0878],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-2.2109, -3.1855,  1.0703,  ...,  1.0898, -2.9082, -0.5732],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0277, -0.0075,  0.0267,  ..., -0.0090, -0.0056,  0.0181],
        [ 0.1036,  0.0427,  0.0709,  ..., -0.0019, -0.0102,  0.0085],
        [-0.0080,  0.0016, -0.0315,  ..., -0.0600, -0.0048, -0.0307],
        ...,
        [ 0.1073,  0.0295,  0.1500,  ...,  0.0262,  0.0056,  0.0311],
        [-0.1274, -0.0889, -0.1704,  ...,  0.0228,  0.0094, -0.0166],
        [-0.0197, -0.0048, -0.1410,  ..., -0.0454, -0.0414,  0.0210]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-2.3574, -1.9092,  0.7539,  ...,  2.5859, -5.0547, -0.9258]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 03:19:44 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To write again is to rewrite
To adjust again is to readjust
To distribute again is to redistribute
To establish again is to reestablish
To define again is to redefine
To consider again is to reconsider
To decorate again is to redecorate
To occur again is to
2024-08-01 03:19:44 root INFO     [order_1_approx] starting weight calculation for To distribute again is to redistribute
To define again is to redefine
To adjust again is to readjust
To decorate again is to redecorate
To consider again is to reconsider
To occur again is to reoccur
To write again is to rewrite
To establish again is to
2024-08-01 03:19:44 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-08-01 03:22:51 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0266,  0.1632, -0.2196,  ...,  0.0708, -0.0029, -0.0155],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.8848, -5.1641,  1.1123,  ...,  1.4316, -4.2969, -3.1270],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0417, -0.0464,  0.0161,  ...,  0.0197,  0.0131, -0.0009],
        [ 0.0178,  0.0283, -0.0075,  ...,  0.0443,  0.0281,  0.0281],
        [-0.0533,  0.0578,  0.0054,  ..., -0.0798, -0.0632, -0.0148],
        ...,
        [ 0.0324, -0.0190, -0.0108,  ...,  0.0296,  0.0488,  0.0153],
        [ 0.0333,  0.0644,  0.0265,  ...,  0.0382,  0.0709,  0.0415],
        [-0.0123,  0.0127, -0.0036,  ...,  0.0043, -0.0261,  0.0069]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.4834, -4.6719,  0.7256,  ...,  1.6318, -3.5625, -3.5723]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 03:22:52 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To distribute again is to redistribute
To define again is to redefine
To adjust again is to readjust
To decorate again is to redecorate
To consider again is to reconsider
To occur again is to reoccur
To write again is to rewrite
To establish again is to
2024-08-01 03:22:52 root INFO     [order_1_approx] starting weight calculation for To define again is to redefine
To decorate again is to redecorate
To write again is to rewrite
To occur again is to reoccur
To distribute again is to redistribute
To establish again is to reestablish
To adjust again is to readjust
To consider again is to
2024-08-01 03:22:52 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-08-01 03:25:56 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0825,  0.1039, -0.0690,  ...,  0.1218,  0.0923,  0.0199],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.2793, -4.1914,  1.3945,  ...,  0.4429, -2.6289, -2.9766],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0878,  0.0427,  0.0341,  ..., -0.0659, -0.0544,  0.0057],
        [-0.0295, -0.0700, -0.0117,  ...,  0.0986,  0.0271,  0.0215],
        [ 0.0482,  0.0175,  0.0522,  ..., -0.1453, -0.0534,  0.0596],
        ...,
        [-0.0728, -0.0403, -0.0536,  ...,  0.1593,  0.1342, -0.0214],
        [ 0.0630,  0.0459, -0.0003,  ..., -0.1338, -0.0485,  0.0165],
        [ 0.0141, -0.0272,  0.0150,  ..., -0.0034, -0.0014, -0.0043]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.4150, -3.2246,  0.1260,  ...,  2.3750, -3.5938, -3.1250]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 03:25:57 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To define again is to redefine
To decorate again is to redecorate
To write again is to rewrite
To occur again is to reoccur
To distribute again is to redistribute
To establish again is to reestablish
To adjust again is to readjust
To consider again is to
2024-08-01 03:25:57 root INFO     [order_1_approx] starting weight calculation for To occur again is to reoccur
To consider again is to reconsider
To adjust again is to readjust
To establish again is to reestablish
To define again is to redefine
To decorate again is to redecorate
To write again is to rewrite
To distribute again is to
2024-08-01 03:25:57 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-08-01 03:29:05 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0781,  0.1931, -0.0712,  ..., -0.0118,  0.0141,  0.2505],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.1580, -3.2246,  0.0942,  ...,  0.5972, -4.5781, -3.0117],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0402, -0.0088,  0.0093,  ..., -0.0386, -0.0779, -0.0170],
        [-0.0140,  0.0075, -0.0022,  ...,  0.0487,  0.0870,  0.0089],
        [ 0.0213,  0.0056,  0.0020,  ..., -0.0475, -0.0536, -0.0207],
        ...,
        [-0.0131, -0.0181, -0.0045,  ...,  0.0613,  0.0727,  0.0208],
        [-0.0151,  0.0126, -0.0051,  ..., -0.0129, -0.0361, -0.0079],
        [ 0.0229,  0.0147,  0.0155,  ...,  0.0387, -0.0506,  0.0352]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.5283, -2.4570,  0.0595,  ...,  1.1826, -4.5547, -3.1953]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 03:29:06 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To occur again is to reoccur
To consider again is to reconsider
To adjust again is to readjust
To establish again is to reestablish
To define again is to redefine
To decorate again is to redecorate
To write again is to rewrite
To distribute again is to
2024-08-01 03:29:06 root INFO     total operator prediction time: 1497.565795660019 seconds
2024-08-01 03:29:06 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on adj+ness_reg
2024-08-01 03:29:06 root INFO     building operator adj+ness_reg
2024-08-01 03:29:06 root INFO     [order_1_approx] starting weight calculation for The state of being interesting is interestingness
The state of being hidden is hiddenness
The state of being odd is oddness
The state of being marked is markedness
The state of being innovative is innovativeness
The state of being distinctive is distinctiveness
The state of being vast is vastness
The state of being same is
2024-08-01 03:29:06 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-08-01 03:32:10 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0840, -0.0051, -0.0043,  ..., -0.0516, -0.0800, -0.0201],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.4844, -4.9375, -1.9658,  ..., -5.7422, -6.6719, -1.1104],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 5.0964e-02,  1.2024e-02,  2.7573e-02,  ..., -4.8256e-03,
          1.2619e-02,  4.4441e-03],
        [ 1.6876e-02,  1.2321e-02, -1.8806e-03,  ..., -4.9561e-02,
          7.8430e-03, -8.5678e-03],
        [ 1.5404e-02,  3.7537e-02, -2.7115e-02,  ...,  1.0681e-04,
         -4.4708e-03,  2.9083e-02],
        ...,
        [ 5.8594e-03, -3.0014e-02, -7.4997e-03,  ..., -2.8137e-02,
         -6.5063e-02,  5.5046e-03],
        [-6.1829e-02,  3.1708e-02,  1.2372e-01,  ...,  1.2512e-02,
          6.0669e-02,  4.6997e-03],
        [ 7.4707e-02,  3.0762e-02, -2.4841e-02,  ...,  1.7517e-02,
         -6.1127e-02,  3.3722e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.3203, -3.6641, -1.1074,  ..., -5.2383, -8.5469,  0.0957]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 03:32:11 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The state of being interesting is interestingness
The state of being hidden is hiddenness
The state of being odd is oddness
The state of being marked is markedness
The state of being innovative is innovativeness
The state of being distinctive is distinctiveness
The state of being vast is vastness
The state of being same is
2024-08-01 03:32:11 root INFO     [order_1_approx] starting weight calculation for The state of being distinctive is distinctiveness
The state of being hidden is hiddenness
The state of being interesting is interestingness
The state of being vast is vastness
The state of being marked is markedness
The state of being innovative is innovativeness
The state of being same is sameness
The state of being odd is
2024-08-01 03:32:11 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-08-01 03:35:18 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0799,  0.2078,  0.0968,  ..., -0.0163, -0.0107, -0.0659],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.9067, -3.3477, -2.7129,  ..., -3.0488, -5.0312, -1.0820],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0393, -0.0075,  0.0011,  ..., -0.0265, -0.0173, -0.0161],
        [ 0.0150, -0.0074, -0.0157,  ..., -0.0227,  0.0114, -0.0110],
        [ 0.0245, -0.0190,  0.0102,  ...,  0.0097, -0.0320, -0.0055],
        ...,
        [-0.0055, -0.0104,  0.0293,  ..., -0.0370, -0.0446, -0.0040],
        [ 0.0225,  0.0400,  0.0290,  ...,  0.0541,  0.0093, -0.0279],
        [ 0.0097,  0.0058, -0.0122,  ...,  0.0271,  0.0172, -0.0005]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.3481, -2.7109, -1.8633,  ..., -2.8926, -7.4062, -0.8174]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 03:35:19 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The state of being distinctive is distinctiveness
The state of being hidden is hiddenness
The state of being interesting is interestingness
The state of being vast is vastness
The state of being marked is markedness
The state of being innovative is innovativeness
The state of being same is sameness
The state of being odd is
2024-08-01 03:35:19 root INFO     [order_1_approx] starting weight calculation for The state of being odd is oddness
The state of being interesting is interestingness
The state of being innovative is innovativeness
The state of being hidden is hiddenness
The state of being marked is markedness
The state of being distinctive is distinctiveness
The state of being same is sameness
The state of being vast is
2024-08-01 03:35:19 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-08-01 03:38:27 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0605,  0.0211,  0.1359,  ...,  0.0612,  0.0084, -0.1320],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.1992, -3.7656, -2.3047,  ..., -4.3672, -5.6250, -1.3164],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 5.7182e-03,  1.1688e-02, -2.7954e-02,  ..., -3.4882e-02,
          1.4000e-02,  4.4632e-03],
        [ 9.0027e-04, -5.0415e-02,  5.4321e-02,  ..., -3.1921e-02,
         -2.4689e-02,  5.6488e-02],
        [ 7.4005e-03, -2.3041e-02,  1.2617e-03,  ..., -2.3926e-02,
          1.8219e-02,  6.0730e-03],
        ...,
        [-2.6672e-02,  2.0813e-02,  3.1250e-02,  ...,  3.3932e-03,
          3.4695e-03, -1.2878e-02],
        [ 2.7466e-03,  3.1372e-02, -2.1927e-02,  ...,  1.1633e-01,
         -6.1340e-03, -6.3599e-02],
        [-7.6294e-05,  3.4790e-02,  2.2919e-02,  ..., -1.0597e-02,
          6.1874e-03, -1.0773e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.6816, -2.8730, -1.7207,  ..., -4.3711, -7.3555, -0.9409]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 03:38:28 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The state of being odd is oddness
The state of being interesting is interestingness
The state of being innovative is innovativeness
The state of being hidden is hiddenness
The state of being marked is markedness
The state of being distinctive is distinctiveness
The state of being same is sameness
The state of being vast is
2024-08-01 03:38:28 root INFO     [order_1_approx] starting weight calculation for The state of being hidden is hiddenness
The state of being odd is oddness
The state of being vast is vastness
The state of being innovative is innovativeness
The state of being interesting is interestingness
The state of being same is sameness
The state of being marked is markedness
The state of being distinctive is
2024-08-01 03:38:28 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-08-01 03:41:35 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0461,  0.0490,  0.0110,  ...,  0.0474,  0.0640,  0.0490],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.1523, -2.2891, -0.9683,  ..., -1.7266, -4.3672, -0.4609],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0222, -0.0005,  0.0091,  ..., -0.0208, -0.0120,  0.0125],
        [ 0.0045, -0.0203,  0.0028,  ..., -0.0006,  0.0238,  0.0015],
        [ 0.0222,  0.0047,  0.0119,  ..., -0.0099,  0.0062, -0.0051],
        ...,
        [-0.0296,  0.0077, -0.0055,  ..., -0.0053,  0.0111, -0.0033],
        [-0.0038,  0.0459, -0.0179,  ...,  0.0109, -0.0306,  0.0028],
        [-0.0077,  0.0233,  0.0177,  ...,  0.0215,  0.0212, -0.0078]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.5049, -2.3438, -0.8389,  ..., -1.8594, -5.2031, -0.3691]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 03:41:36 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The state of being hidden is hiddenness
The state of being odd is oddness
The state of being vast is vastness
The state of being innovative is innovativeness
The state of being interesting is interestingness
The state of being same is sameness
The state of being marked is markedness
The state of being distinctive is
2024-08-01 03:41:36 root INFO     [order_1_approx] starting weight calculation for The state of being interesting is interestingness
The state of being same is sameness
The state of being hidden is hiddenness
The state of being innovative is innovativeness
The state of being odd is oddness
The state of being vast is vastness
The state of being distinctive is distinctiveness
The state of being marked is
2024-08-01 03:41:36 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-08-01 03:44:38 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0719,  0.0455,  0.0621,  ...,  0.0920,  0.0596, -0.0611],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.5469, -4.1328, -2.4922,  ..., -3.2500, -1.8672, -1.2393],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 5.3406e-02, -5.0049e-02,  7.2136e-03,  ..., -2.8397e-02,
          3.4912e-02,  6.9214e-02],
        [ 1.0474e-01, -1.5717e-02, -5.9387e-02,  ..., -4.1901e-02,
          9.3750e-02,  7.2144e-02],
        [ 6.8420e-02, -2.6512e-03, -6.1951e-02,  ..., -1.9455e-02,
          7.9163e-02,  8.4534e-02],
        ...,
        [ 9.0790e-04, -4.0771e-02, -9.6130e-03,  ...,  1.1963e-02,
         -4.7684e-05, -1.3504e-02],
        [-1.7615e-01,  4.2297e-02,  1.4832e-01,  ...,  9.4666e-02,
         -1.8787e-01, -1.0718e-01],
        [ 1.2164e-01, -3.0624e-02, -1.5759e-01,  ..., -2.5299e-02,
          1.4832e-01,  6.9580e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.1758, -2.4219, -1.7324,  ..., -2.6934, -3.9023,  0.4551]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 03:44:39 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The state of being interesting is interestingness
The state of being same is sameness
The state of being hidden is hiddenness
The state of being innovative is innovativeness
The state of being odd is oddness
The state of being vast is vastness
The state of being distinctive is distinctiveness
The state of being marked is
2024-08-01 03:44:39 root INFO     [order_1_approx] starting weight calculation for The state of being odd is oddness
The state of being interesting is interestingness
The state of being marked is markedness
The state of being same is sameness
The state of being hidden is hiddenness
The state of being vast is vastness
The state of being distinctive is distinctiveness
The state of being innovative is
2024-08-01 03:44:39 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-08-01 03:47:42 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0041,  0.0418,  0.0864,  ...,  0.0038, -0.0531, -0.0920],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.2168, -3.5957, -0.8530,  ...,  0.8203, -1.3154, -1.9902],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 2.0981e-05,  1.6937e-02, -6.9351e-03,  ...,  1.2016e-03,
         -5.1041e-03,  3.9558e-03],
        [-9.4528e-03, -1.8539e-02,  1.8814e-02,  ..., -1.3794e-02,
          2.1915e-03, -2.0428e-03],
        [-1.1154e-02, -3.6430e-04, -2.1191e-03,  ...,  4.4098e-03,
         -5.5618e-03,  4.5319e-03],
        ...,
        [-3.7575e-04,  6.4430e-03,  8.0872e-03,  ..., -1.2569e-03,
          3.3588e-03,  4.2229e-03],
        [-4.7455e-03,  3.6133e-02, -1.9440e-02,  ...,  3.2745e-02,
         -5.5733e-03, -6.0577e-03],
        [ 7.9575e-03, -1.8768e-02,  1.4107e-02,  ..., -1.0986e-03,
         -2.6398e-03, -4.1246e-05]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.1187, -3.5020, -1.0459,  ...,  0.7256, -1.7920, -1.8076]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 03:47:43 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The state of being odd is oddness
The state of being interesting is interestingness
The state of being marked is markedness
The state of being same is sameness
The state of being hidden is hiddenness
The state of being vast is vastness
The state of being distinctive is distinctiveness
The state of being innovative is
2024-08-01 03:47:43 root INFO     [order_1_approx] starting weight calculation for The state of being odd is oddness
The state of being same is sameness
The state of being hidden is hiddenness
The state of being vast is vastness
The state of being marked is markedness
The state of being distinctive is distinctiveness
The state of being innovative is innovativeness
The state of being interesting is
2024-08-01 03:47:43 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-08-01 03:50:49 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1060,  0.0977,  0.1980,  ...,  0.1526, -0.1044, -0.1140],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.3252, -2.5938, -0.5918,  ..., -1.3438, -3.5938, -1.7783],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0010,  0.0284, -0.0227,  ..., -0.0026,  0.0093, -0.0189],
        [-0.0233,  0.0222,  0.0159,  ..., -0.0100, -0.0199, -0.0210],
        [ 0.0148,  0.0140,  0.0014,  ...,  0.0030,  0.0069, -0.0050],
        ...,
        [-0.0041, -0.0189,  0.0042,  ..., -0.0301,  0.0123,  0.0345],
        [ 0.0201, -0.0244, -0.0179,  ...,  0.0268,  0.0323, -0.0210],
        [ 0.0048,  0.0146,  0.0011,  ...,  0.0164, -0.0097, -0.0108]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.4514, -2.3516, -0.2107,  ..., -1.1787, -4.0039, -1.7725]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 03:50:50 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The state of being odd is oddness
The state of being same is sameness
The state of being hidden is hiddenness
The state of being vast is vastness
The state of being marked is markedness
The state of being distinctive is distinctiveness
The state of being innovative is innovativeness
The state of being interesting is
2024-08-01 03:50:50 root INFO     [order_1_approx] starting weight calculation for The state of being interesting is interestingness
The state of being same is sameness
The state of being marked is markedness
The state of being vast is vastness
The state of being distinctive is distinctiveness
The state of being innovative is innovativeness
The state of being odd is oddness
The state of being hidden is
2024-08-01 03:50:50 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-08-01 03:53:55 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0347, -0.0623,  0.1223,  ..., -0.0489, -0.0845,  0.0107],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-2.5410, -1.2051, -0.1582,  ..., -2.9414, -3.4219,  0.2480],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0694,  0.0149,  0.0116,  ..., -0.0049,  0.0854,  0.0557],
        [ 0.0253,  0.0171,  0.0219,  ...,  0.0607,  0.0964,  0.0265],
        [ 0.0274, -0.0196, -0.0190,  ...,  0.0292, -0.0026, -0.0013],
        ...,
        [ 0.0230,  0.0157,  0.0310,  ..., -0.0176,  0.0202, -0.0214],
        [-0.0362, -0.0225, -0.0056,  ..., -0.0294, -0.0804, -0.0248],
        [-0.0284,  0.0216, -0.0341,  ..., -0.0022, -0.0592, -0.0113]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.6689,  0.1299,  0.2522,  ..., -2.7578, -4.6758, -1.2822]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 03:53:56 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The state of being interesting is interestingness
The state of being same is sameness
The state of being marked is markedness
The state of being vast is vastness
The state of being distinctive is distinctiveness
The state of being innovative is innovativeness
The state of being odd is oddness
The state of being hidden is
2024-08-01 03:53:56 root INFO     total operator prediction time: 1490.4306037425995 seconds
2024-08-01 03:53:56 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on noun+less_reg
2024-08-01 03:53:56 root INFO     building operator noun+less_reg
2024-08-01 03:53:56 root INFO     [order_1_approx] starting weight calculation for Something without life is lifeless
Something without mirth is mirthless
Something without hair is hairless
Something without carbon is carbonless
Something without expression is expressionless
Something without guile is guileless
Something without emotion is emotionless
Something without art is
2024-08-01 03:53:57 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-08-01 03:57:04 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0730, -0.0142,  0.1440,  ..., -0.1440, -0.0377, -0.0704],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.7285, -3.6055,  1.4922,  ..., -1.7969, -4.6914,  0.2930],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0182,  0.1170,  0.0228,  ...,  0.0009, -0.1141,  0.0307],
        [ 0.0375, -0.1168, -0.0084,  ...,  0.0043,  0.1130, -0.0365],
        [-0.0003,  0.0287, -0.0085,  ...,  0.0162, -0.0582, -0.0193],
        ...,
        [ 0.0328, -0.0839, -0.0010,  ..., -0.0176,  0.1068, -0.0008],
        [ 0.0105, -0.0496,  0.0073,  ..., -0.0192,  0.0992,  0.0244],
        [ 0.0215, -0.0582, -0.0117,  ...,  0.0229,  0.0955, -0.0386]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.5781, -2.2402,  0.8521,  ..., -0.9199, -4.0117,  0.7153]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 03:57:05 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Something without life is lifeless
Something without mirth is mirthless
Something without hair is hairless
Something without carbon is carbonless
Something without expression is expressionless
Something without guile is guileless
Something without emotion is emotionless
Something without art is
2024-08-01 03:57:05 root INFO     [order_1_approx] starting weight calculation for Something without carbon is carbonless
Something without emotion is emotionless
Something without life is lifeless
Something without guile is guileless
Something without hair is hairless
Something without art is artless
Something without mirth is mirthless
Something without expression is
2024-08-01 03:57:06 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-08-01 04:00:12 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1498,  0.0468,  0.0814,  ...,  0.0252, -0.0972, -0.0222],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.3496, -2.6484,  0.9302,  ..., -2.5918, -2.8457, -2.0859],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0219,  0.0116, -0.0080,  ..., -0.0265, -0.0299,  0.0126],
        [ 0.0075,  0.0138, -0.0151,  ...,  0.0117,  0.0324, -0.0050],
        [ 0.0183,  0.0124, -0.0050,  ..., -0.0020, -0.0008, -0.0347],
        ...,
        [ 0.0396, -0.0240, -0.0044,  ..., -0.0136, -0.0080, -0.0205],
        [ 0.0125,  0.0011, -0.0251,  ..., -0.0035,  0.0153, -0.0079],
        [ 0.0115, -0.0210,  0.0046,  ...,  0.0561,  0.0145, -0.0388]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.7827, -1.9316,  0.6597,  ..., -2.1875, -2.8848, -1.6914]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 04:00:13 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Something without carbon is carbonless
Something without emotion is emotionless
Something without life is lifeless
Something without guile is guileless
Something without hair is hairless
Something without art is artless
Something without mirth is mirthless
Something without expression is
2024-08-01 04:00:13 root INFO     [order_1_approx] starting weight calculation for Something without expression is expressionless
Something without guile is guileless
Something without emotion is emotionless
Something without hair is hairless
Something without carbon is carbonless
Something without life is lifeless
Something without art is artless
Something without mirth is
2024-08-01 04:00:13 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-08-01 04:03:15 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0010,  0.1088,  0.0832,  ...,  0.0914, -0.0790, -0.0552],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.3496, -1.9980, -0.7969,  ..., -1.0508, -3.9688, -1.7861],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0369,  0.0009, -0.0495,  ...,  0.0240, -0.0027, -0.0419],
        [ 0.0931,  0.0047,  0.0986,  ..., -0.0674,  0.0003,  0.0493],
        [-0.0234,  0.0103,  0.0296,  ...,  0.0310, -0.0001, -0.0209],
        ...,
        [ 0.0619, -0.0065,  0.0505,  ..., -0.0634,  0.0114,  0.0378],
        [ 0.0069,  0.0135,  0.0194,  ..., -0.0333,  0.0209,  0.0211],
        [ 0.0812, -0.0008,  0.0589,  ..., -0.0188,  0.0141,  0.0346]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.2266, -0.3750, -0.5352,  ..., -0.1616, -3.4531, -0.7939]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 04:03:16 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Something without expression is expressionless
Something without guile is guileless
Something without emotion is emotionless
Something without hair is hairless
Something without carbon is carbonless
Something without life is lifeless
Something without art is artless
Something without mirth is
2024-08-01 04:03:17 root INFO     [order_1_approx] starting weight calculation for Something without guile is guileless
Something without emotion is emotionless
Something without hair is hairless
Something without mirth is mirthless
Something without expression is expressionless
Something without art is artless
Something without life is lifeless
Something without carbon is
2024-08-01 04:03:17 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-08-01 04:06:22 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0789, -0.0764, -0.2050,  ..., -0.3186, -0.0862, -0.0177],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.4858, -2.7090,  2.1289,  ..., -4.1914, -3.2617, -1.0615],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0463,  0.1534,  0.0049,  ...,  0.0224, -0.1404,  0.0499],
        [-0.0551, -0.1220, -0.0131,  ...,  0.0288,  0.1387, -0.0374],
        [ 0.0367,  0.0766, -0.0042,  ..., -0.0337, -0.0248, -0.0029],
        ...,
        [-0.0323, -0.0703,  0.0031,  ..., -0.0129,  0.0847, -0.0337],
        [ 0.0242,  0.0133,  0.0250,  ..., -0.0085,  0.0405,  0.0333],
        [ 0.0317, -0.0200,  0.0176,  ...,  0.0321,  0.0172, -0.0465]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.0449, -1.4688,  2.0176,  ..., -3.2930, -2.9570, -0.7017]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 04:06:23 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Something without guile is guileless
Something without emotion is emotionless
Something without hair is hairless
Something without mirth is mirthless
Something without expression is expressionless
Something without art is artless
Something without life is lifeless
Something without carbon is
2024-08-01 04:06:24 root INFO     [order_1_approx] starting weight calculation for Something without carbon is carbonless
Something without expression is expressionless
Something without hair is hairless
Something without emotion is emotionless
Something without mirth is mirthless
Something without guile is guileless
Something without art is artless
Something without life is
2024-08-01 04:06:24 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-08-01 04:09:28 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1216,  0.0120, -0.0214,  ...,  0.0011, -0.0555, -0.1813],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.4185, -3.8613,  0.6992,  ..., -2.4902, -3.6289, -0.5088],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0157,  0.0229,  0.0274,  ..., -0.0149, -0.0062, -0.0002],
        [ 0.0028, -0.0030, -0.0444,  ...,  0.0385,  0.0189, -0.0193],
        [-0.0002,  0.0124,  0.0049,  ..., -0.0063, -0.0056,  0.0058],
        ...,
        [ 0.0011,  0.0191, -0.0148,  ..., -0.0001,  0.0070, -0.0117],
        [-0.0084,  0.0002,  0.0097,  ..., -0.0350, -0.0042,  0.0023],
        [ 0.0019,  0.0094,  0.0091,  ...,  0.0348,  0.0108, -0.0359]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.1860, -2.7734,  0.6191,  ..., -2.1523, -4.0156, -0.5029]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 04:09:29 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Something without carbon is carbonless
Something without expression is expressionless
Something without hair is hairless
Something without emotion is emotionless
Something without mirth is mirthless
Something without guile is guileless
Something without art is artless
Something without life is
2024-08-01 04:09:30 root INFO     [order_1_approx] starting weight calculation for Something without life is lifeless
Something without carbon is carbonless
Something without hair is hairless
Something without mirth is mirthless
Something without expression is expressionless
Something without art is artless
Something without guile is guileless
Something without emotion is
2024-08-01 04:09:30 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-08-01 04:12:38 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-7.8552e-02,  5.7861e-02, -7.4280e-02,  ...,  4.5776e-05,
        -3.2593e-01,  1.4758e-01], device='cuda:1', dtype=torch.float16,
       grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.4473e+00, -1.2334e+00,  9.7656e-04,  ..., -2.5312e+00,
        -2.1680e+00, -3.7461e+00], device='cuda:1', dtype=torch.float16,
       grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0035,  0.0151, -0.0103,  ..., -0.0103, -0.0120,  0.0085],
        [-0.0004, -0.0094,  0.0441,  ...,  0.0059,  0.0037, -0.0155],
        [-0.0036, -0.0013, -0.0016,  ...,  0.0120, -0.0042, -0.0328],
        ...,
        [ 0.0211, -0.0070,  0.0381,  ..., -0.0289,  0.0228,  0.0253],
        [-0.0031,  0.0355, -0.0289,  ..., -0.0126,  0.0035, -0.0006],
        [ 0.0079, -0.0193,  0.0176,  ...,  0.0127,  0.0229, -0.0083]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.8750, -0.8174, -0.0158,  ..., -1.2188, -2.4414, -2.6016]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 04:12:38 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Something without life is lifeless
Something without carbon is carbonless
Something without hair is hairless
Something without mirth is mirthless
Something without expression is expressionless
Something without art is artless
Something without guile is guileless
Something without emotion is
2024-08-01 04:12:39 root INFO     [order_1_approx] starting weight calculation for Something without mirth is mirthless
Something without hair is hairless
Something without emotion is emotionless
Something without art is artless
Something without carbon is carbonless
Something without expression is expressionless
Something without life is lifeless
Something without guile is
2024-08-01 04:12:39 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-08-01 04:15:39 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 3.9246e-02, -7.2144e-02,  6.2927e-02,  ..., -1.8692e-02,
        -1.2207e-04,  1.5015e-01], device='cuda:1', dtype=torch.float16,
       grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.1816, -2.1016,  0.8135,  ...,  0.3752, -2.6582, -0.5000],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-2.0660e-02,  2.8671e-02, -3.7292e-02,  ..., -3.9978e-03,
         -2.1942e-02,  7.6294e-06],
        [ 1.4355e-01, -1.1737e-01, -3.8719e-03,  ..., -1.1147e-02,
         -1.6663e-02,  3.6407e-02],
        [-3.5038e-03, -2.9411e-03,  4.2969e-02,  ...,  1.5327e-02,
         -2.4384e-02, -3.7720e-02],
        ...,
        [-6.5125e-02,  9.7534e-02,  3.6926e-03,  ...,  7.2784e-03,
          2.9999e-02, -1.5625e-02],
        [ 1.3962e-02,  2.2095e-02,  8.7158e-02,  ...,  4.2328e-02,
          3.6224e-02, -2.2644e-02],
        [ 4.1046e-02, -4.3945e-02,  9.6069e-02,  ...,  3.3783e-02,
          1.8616e-02, -4.0955e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.4365, -0.0547,  0.7031,  ..., -0.9385, -1.9209, -0.2993]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 04:15:40 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Something without mirth is mirthless
Something without hair is hairless
Something without emotion is emotionless
Something without art is artless
Something without carbon is carbonless
Something without expression is expressionless
Something without life is lifeless
Something without guile is
2024-08-01 04:15:40 root INFO     [order_1_approx] starting weight calculation for Something without art is artless
Something without expression is expressionless
Something without life is lifeless
Something without carbon is carbonless
Something without mirth is mirthless
Something without emotion is emotionless
Something without guile is guileless
Something without hair is
2024-08-01 04:15:40 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-08-01 04:18:43 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0291, -0.0024, -0.1000,  ..., -0.0427,  0.1181,  0.0303],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.4990, -3.5273, -1.1025,  ..., -2.9766, -4.7031, -1.8545],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0008,  0.0179, -0.0210,  ..., -0.0490,  0.0028,  0.0399],
        [ 0.0605, -0.0136,  0.0398,  ...,  0.0031,  0.0753,  0.0209],
        [ 0.0247, -0.0235,  0.0059,  ..., -0.0332,  0.0693,  0.0452],
        ...,
        [ 0.0261,  0.0120,  0.0117,  ..., -0.0290,  0.0741, -0.0212],
        [ 0.0215,  0.0161,  0.0238,  ...,  0.0066,  0.0614, -0.0029],
        [ 0.0236, -0.0090,  0.0367,  ...,  0.0171,  0.0055, -0.0270]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.2783, -1.4902, -0.1768,  ..., -2.0625, -4.3047, -1.1758]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 04:18:44 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Something without art is artless
Something without expression is expressionless
Something without life is lifeless
Something without carbon is carbonless
Something without mirth is mirthless
Something without emotion is emotionless
Something without guile is guileless
Something without hair is
2024-08-01 04:18:44 root INFO     total operator prediction time: 1487.6741631031036 seconds
2024-08-01 04:18:44 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on verb+ment_irreg
2024-08-01 04:18:44 root INFO     building operator verb+ment_irreg
2024-08-01 04:18:44 root INFO     [order_1_approx] starting weight calculation for To assign results in a assignment
To fulfil results in a fulfilment
To entertain results in a entertainment
To accomplish results in a accomplishment
To infringe results in a infringement
To amuse results in a amusement
To fulfill results in a fulfillment
To reinforce results in a
2024-08-01 04:18:44 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-08-01 04:21:41 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0353, -0.0154, -0.0075,  ...,  0.0515,  0.0745,  0.1375],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.6909, -2.4414,  2.4746,  ...,  3.0918, -2.1699, -3.9609],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0508, -0.0145,  0.0176,  ...,  0.0607, -0.0199,  0.0106],
        [ 0.0368,  0.0688, -0.0053,  ...,  0.0815,  0.0185, -0.0538],
        [ 0.0674,  0.0051,  0.0106,  ...,  0.0133, -0.0220, -0.0379],
        ...,
        [-0.0644, -0.0319, -0.0126,  ..., -0.0375, -0.0075,  0.0064],
        [ 0.0854,  0.0684,  0.0390,  ...,  0.0136,  0.0119, -0.0174],
        [ 0.0845,  0.0102,  0.0133,  ...,  0.1026, -0.0212, -0.0065]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.1504, -1.5801,  2.6504,  ...,  1.9248, -1.1855, -2.7969]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 04:21:42 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To assign results in a assignment
To fulfil results in a fulfilment
To entertain results in a entertainment
To accomplish results in a accomplishment
To infringe results in a infringement
To amuse results in a amusement
To fulfill results in a fulfillment
To reinforce results in a
2024-08-01 04:21:42 root INFO     [order_1_approx] starting weight calculation for To assign results in a assignment
To entertain results in a entertainment
To fulfil results in a fulfilment
To amuse results in a amusement
To reinforce results in a reinforcement
To infringe results in a infringement
To accomplish results in a accomplishment
To fulfill results in a
2024-08-01 04:21:42 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-08-01 04:24:39 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0758,  0.0901, -0.1726,  ...,  0.0686, -0.1301,  0.0280],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.2344, -2.7402,  2.1797,  ...,  0.7100, -3.4102, -1.6943],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 1.9257e-02,  1.7670e-02,  5.7411e-03,  ...,  9.4604e-02,
          3.2440e-02,  2.1347e-02],
        [-6.2805e-02,  9.0332e-03, -1.6129e-02,  ..., -4.4403e-02,
          2.1317e-02,  7.7934e-03],
        [-2.4872e-02, -3.5309e-02,  8.2245e-03,  ..., -4.5532e-02,
         -2.2079e-02, -3.8116e-02],
        ...,
        [-1.6602e-02, -5.7220e-05, -2.5757e-02,  ..., -2.4216e-02,
          4.3243e-02,  1.0086e-02],
        [ 4.3030e-02,  3.2257e-02, -6.4011e-03,  ..., -1.1673e-02,
         -4.5471e-03, -5.7800e-02],
        [-1.8845e-02, -1.3283e-02,  1.1497e-02,  ..., -1.1238e-02,
         -2.7161e-03,  5.2490e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 5.2227, -2.8125,  1.8320,  ...,  0.3542, -3.0664, -1.5840]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 04:24:39 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To assign results in a assignment
To entertain results in a entertainment
To fulfil results in a fulfilment
To amuse results in a amusement
To reinforce results in a reinforcement
To infringe results in a infringement
To accomplish results in a accomplishment
To fulfill results in a
2024-08-01 04:24:40 root INFO     [order_1_approx] starting weight calculation for To accomplish results in a accomplishment
To infringe results in a infringement
To fulfil results in a fulfilment
To entertain results in a entertainment
To reinforce results in a reinforcement
To amuse results in a amusement
To fulfill results in a fulfillment
To assign results in a
2024-08-01 04:24:40 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-08-01 04:27:44 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1121,  0.2206, -0.1920,  ..., -0.0922,  0.0080, -0.1201],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.5801, -4.2617,  1.1572,  ...,  3.1758, -1.0293, -2.3594],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0367, -0.0374, -0.0597,  ...,  0.0496,  0.0311,  0.0516],
        [ 0.0983, -0.0715,  0.1630,  ...,  0.3608,  0.1591,  0.0804],
        [ 0.0674, -0.0272,  0.0203,  ...,  0.0771,  0.0713,  0.0017],
        ...,
        [-0.0687,  0.0499, -0.0355,  ..., -0.0986, -0.0015, -0.0395],
        [ 0.0174,  0.0186,  0.0345,  ...,  0.0263,  0.0221,  0.0036],
        [ 0.0627, -0.0301,  0.0771,  ...,  0.1246,  0.0295,  0.0503]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.3047, -1.2188,  2.0566,  ...,  2.2402, -0.6582, -1.1357]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 04:27:45 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To accomplish results in a accomplishment
To infringe results in a infringement
To fulfil results in a fulfilment
To entertain results in a entertainment
To reinforce results in a reinforcement
To amuse results in a amusement
To fulfill results in a fulfillment
To assign results in a
2024-08-01 04:27:45 root INFO     [order_1_approx] starting weight calculation for To infringe results in a infringement
To entertain results in a entertainment
To fulfil results in a fulfilment
To fulfill results in a fulfillment
To reinforce results in a reinforcement
To accomplish results in a accomplishment
To assign results in a assignment
To amuse results in a
2024-08-01 04:27:45 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-08-01 04:30:48 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1313,  0.0410, -0.1449,  ...,  0.0158,  0.0619,  0.0231],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.9531, -1.8301,  1.3574,  ...,  2.1523, -0.9414, -1.7598],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0209, -0.0044,  0.0698,  ...,  0.1550, -0.0018, -0.0690],
        [-0.0091,  0.0204,  0.0165,  ..., -0.0479,  0.0199,  0.0338],
        [ 0.0365, -0.0052,  0.0489,  ...,  0.0332, -0.0061, -0.0354],
        ...,
        [-0.0378,  0.0325, -0.0341,  ..., -0.0355,  0.0334,  0.0146],
        [ 0.1497, -0.0068,  0.1196,  ..., -0.0011,  0.0007, -0.0287],
        [ 0.0082,  0.0290, -0.0008,  ...,  0.0435, -0.0016,  0.0302]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.0430, -1.0527,  0.9971,  ...,  1.5576,  1.5742, -1.9434]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 04:30:49 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To infringe results in a infringement
To entertain results in a entertainment
To fulfil results in a fulfilment
To fulfill results in a fulfillment
To reinforce results in a reinforcement
To accomplish results in a accomplishment
To assign results in a assignment
To amuse results in a
2024-08-01 04:30:49 root INFO     [order_1_approx] starting weight calculation for To fulfil results in a fulfilment
To infringe results in a infringement
To fulfill results in a fulfillment
To accomplish results in a accomplishment
To amuse results in a amusement
To reinforce results in a reinforcement
To assign results in a assignment
To entertain results in a
2024-08-01 04:30:49 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-08-01 04:33:55 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1921,  0.0969, -0.2583,  ..., -0.1150,  0.0605, -0.1309],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.8438, -3.4355,  1.6934,  ...,  1.4512, -0.5811, -2.5801],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0071, -0.0200, -0.0629,  ...,  0.0281, -0.0008, -0.0066],
        [-0.0043,  0.0157,  0.0116,  ...,  0.0178,  0.0266, -0.0213],
        [ 0.0563, -0.0018,  0.0156,  ...,  0.0503,  0.0158, -0.0145],
        ...,
        [-0.0271, -0.0196,  0.0105,  ..., -0.0533, -0.0057,  0.0012],
        [ 0.0238,  0.0135, -0.0119,  ..., -0.0742, -0.0374,  0.0067],
        [ 0.0248,  0.0221,  0.0047,  ..., -0.0150,  0.0045, -0.0174]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.5527, -2.4297,  2.1582,  ...,  1.6309, -0.7402, -2.3984]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 04:33:56 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To fulfil results in a fulfilment
To infringe results in a infringement
To fulfill results in a fulfillment
To accomplish results in a accomplishment
To amuse results in a amusement
To reinforce results in a reinforcement
To assign results in a assignment
To entertain results in a
2024-08-01 04:33:57 root INFO     [order_1_approx] starting weight calculation for To fulfil results in a fulfilment
To entertain results in a entertainment
To reinforce results in a reinforcement
To assign results in a assignment
To amuse results in a amusement
To accomplish results in a accomplishment
To fulfill results in a fulfillment
To infringe results in a
2024-08-01 04:33:57 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-08-01 04:37:03 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0179,  0.0748,  0.0380,  ...,  0.1221, -0.1102, -0.0526],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.2012, -5.7695,  1.3955,  ...,  1.2139, -1.3887, -0.4663],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0050, -0.0017,  0.0339,  ...,  0.0143,  0.0078,  0.0140],
        [-0.0274,  0.0201,  0.0526,  ...,  0.0135,  0.0452, -0.0177],
        [-0.0051,  0.0019, -0.0078,  ...,  0.0055,  0.0053, -0.0274],
        ...,
        [-0.0051,  0.0156,  0.0163,  ...,  0.0100,  0.0029,  0.0115],
        [-0.0057, -0.0077,  0.0341,  ...,  0.0026,  0.0046,  0.0067],
        [ 0.0154,  0.0021, -0.0464,  ...,  0.0093, -0.0438,  0.0160]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.6133, -4.6719,  1.4922,  ...,  1.2549, -1.0342, -1.7734]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 04:37:04 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To fulfil results in a fulfilment
To entertain results in a entertainment
To reinforce results in a reinforcement
To assign results in a assignment
To amuse results in a amusement
To accomplish results in a accomplishment
To fulfill results in a fulfillment
To infringe results in a
2024-08-01 04:37:04 root INFO     [order_1_approx] starting weight calculation for To amuse results in a amusement
To assign results in a assignment
To reinforce results in a reinforcement
To fulfil results in a fulfilment
To fulfill results in a fulfillment
To entertain results in a entertainment
To infringe results in a infringement
To accomplish results in a
2024-08-01 04:37:04 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-08-01 04:40:07 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0672,  0.2275, -0.1053,  ...,  0.1743, -0.1869,  0.0203],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.3379, -4.4609, -0.5166,  ...,  1.2012, -1.1133, -0.9375],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.1099, -0.0144,  0.0386,  ...,  0.1044,  0.0363,  0.0173],
        [ 0.0705,  0.0110, -0.0188,  ...,  0.0808,  0.0559, -0.0776],
        [ 0.1886, -0.0959, -0.0102,  ...,  0.0533, -0.0086, -0.0604],
        ...,
        [-0.0875,  0.0389, -0.0381,  ..., -0.0662,  0.0019,  0.0008],
        [ 0.0228,  0.0731,  0.0137,  ..., -0.0634, -0.0219,  0.0071],
        [ 0.0458,  0.0204,  0.0457,  ...,  0.0668,  0.0342, -0.0169]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.0547, -3.3164,  0.6729,  ...,  1.3291, -1.0225, -0.4644]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 04:40:08 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To amuse results in a amusement
To assign results in a assignment
To reinforce results in a reinforcement
To fulfil results in a fulfilment
To fulfill results in a fulfillment
To entertain results in a entertainment
To infringe results in a infringement
To accomplish results in a
2024-08-01 04:40:08 root INFO     [order_1_approx] starting weight calculation for To amuse results in a amusement
To fulfill results in a fulfillment
To entertain results in a entertainment
To accomplish results in a accomplishment
To assign results in a assignment
To reinforce results in a reinforcement
To infringe results in a infringement
To fulfil results in a
2024-08-01 04:40:09 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-08-01 04:43:15 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0634,  0.1785, -0.1111,  ...,  0.0638, -0.0405,  0.1060],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 5.0781, -4.1797,  2.9648,  ...,  1.4150, -4.5391, -1.2168],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0024, -0.0451,  0.0489,  ...,  0.0701, -0.0045, -0.0039],
        [-0.0230,  0.0050,  0.0236,  ...,  0.0670,  0.0500,  0.0167],
        [ 0.0158, -0.0452, -0.0199,  ..., -0.0010, -0.0173, -0.0102],
        ...,
        [-0.0186,  0.0356, -0.0165,  ..., -0.0134,  0.0289,  0.0028],
        [ 0.0072,  0.0155, -0.0093,  ..., -0.0413, -0.0323,  0.0126],
        [-0.0004, -0.0055,  0.0232,  ...,  0.0627, -0.0239,  0.0366]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 5.6953, -3.3926,  2.5879,  ...,  1.0537, -4.7188, -0.5791]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 04:43:16 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To amuse results in a amusement
To fulfill results in a fulfillment
To entertain results in a entertainment
To accomplish results in a accomplishment
To assign results in a assignment
To reinforce results in a reinforcement
To infringe results in a infringement
To fulfil results in a
2024-08-01 04:43:16 root INFO     total operator prediction time: 1471.83908867836 seconds
2024-08-01 04:43:16 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on name - nationality
2024-08-01 04:43:16 root INFO     building operator name - nationality
2024-08-01 04:43:16 root INFO     [order_1_approx] starting weight calculation for hegel was german
beethoven was german
descartes was french
plato was greek
newton was english
maxwell was scottish
machiavelli was italian
confucius was
2024-08-01 04:43:16 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-08-01 04:46:22 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0262, -0.0137, -0.1836,  ...,  0.1615, -0.0494, -0.0299],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.8740, -1.0195,  2.3320,  ..., -4.6016,  0.0215,  1.2051],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0072, -0.0034,  0.0001,  ..., -0.0241, -0.0098,  0.0077],
        [ 0.0124,  0.0135,  0.0093,  ..., -0.0001,  0.0293,  0.0185],
        [-0.0010,  0.0010,  0.0002,  ...,  0.0100, -0.0175, -0.0081],
        ...,
        [ 0.0074, -0.0075,  0.0056,  ...,  0.0191,  0.0038,  0.0208],
        [ 0.0114, -0.0057, -0.0274,  ...,  0.0238,  0.0101,  0.0119],
        [-0.0045, -0.0011,  0.0153,  ...,  0.0182, -0.0195, -0.0085]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.2012, -1.1777,  2.3340,  ..., -4.6914,  0.1680,  1.1621]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 04:46:23 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for hegel was german
beethoven was german
descartes was french
plato was greek
newton was english
maxwell was scottish
machiavelli was italian
confucius was
2024-08-01 04:46:23 root INFO     [order_1_approx] starting weight calculation for maxwell was scottish
newton was english
beethoven was german
confucius was chinese
hegel was german
plato was greek
descartes was french
machiavelli was
2024-08-01 04:46:23 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-08-01 04:49:32 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1573, -0.0116, -0.0907,  ..., -0.0214,  0.0472, -0.0406],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.9668, -3.4609,  0.7520,  ..., -1.0166, -1.7129,  1.1211],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0019,  0.0051, -0.0115,  ..., -0.0119, -0.0037, -0.0144],
        [-0.0065, -0.0032,  0.0172,  ...,  0.0010, -0.0080,  0.0078],
        [ 0.0051,  0.0112,  0.0392,  ..., -0.0137, -0.0012,  0.0133],
        ...,
        [ 0.0307, -0.0143,  0.0085,  ...,  0.0191, -0.0023,  0.0261],
        [ 0.0072,  0.0051, -0.0223,  ..., -0.0059,  0.0173,  0.0366],
        [-0.0176, -0.0041,  0.0353,  ..., -0.0098,  0.0047,  0.0257]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.3086, -3.1602,  0.8403,  ..., -0.8887, -1.2432,  1.7617]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 04:49:33 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for maxwell was scottish
newton was english
beethoven was german
confucius was chinese
hegel was german
plato was greek
descartes was french
machiavelli was
2024-08-01 04:49:33 root INFO     [order_1_approx] starting weight calculation for machiavelli was italian
maxwell was scottish
beethoven was german
plato was greek
confucius was chinese
hegel was german
descartes was french
newton was
2024-08-01 04:49:33 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-08-01 04:52:39 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2397,  0.1593,  0.0310,  ..., -0.0487,  0.1190,  0.0641],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.5781, -0.9458, -0.7671,  ..., -4.0312, -1.0898, -3.0957],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0217, -0.0029, -0.0112,  ..., -0.0220,  0.0063, -0.0189],
        [ 0.0231,  0.0356,  0.0010,  ...,  0.0050,  0.0326, -0.0038],
        [-0.0021, -0.0093,  0.0184,  ...,  0.0149, -0.0182,  0.0171],
        ...,
        [-0.0149,  0.0070, -0.0041,  ...,  0.0157,  0.0202,  0.0359],
        [-0.0001, -0.0114,  0.0285,  ..., -0.0063, -0.0021,  0.0127],
        [ 0.0042,  0.0198,  0.0195,  ...,  0.0161, -0.0062,  0.0168]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.7090, -0.9092, -0.5967,  ..., -3.9102, -1.0625, -2.8965]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 04:52:40 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for machiavelli was italian
maxwell was scottish
beethoven was german
plato was greek
confucius was chinese
hegel was german
descartes was french
newton was
2024-08-01 04:52:40 root INFO     [order_1_approx] starting weight calculation for confucius was chinese
descartes was french
plato was greek
newton was english
hegel was german
machiavelli was italian
maxwell was scottish
beethoven was
2024-08-01 04:52:40 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-08-01 04:55:46 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0706,  0.0999, -0.1793,  ..., -0.0587,  0.1023,  0.0578],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.9590, -5.7500,  0.1084,  ..., -2.0078, -0.8438, -1.9258],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0042, -0.0143, -0.0123,  ..., -0.0209,  0.0211,  0.0082],
        [ 0.0050,  0.0025, -0.0166,  ...,  0.0103,  0.0339,  0.0158],
        [ 0.0031,  0.0114,  0.0116,  ..., -0.0151, -0.0413, -0.0155],
        ...,
        [-0.0001,  0.0179, -0.0147,  ...,  0.0032, -0.0106,  0.0215],
        [-0.0046,  0.0028,  0.0034,  ...,  0.0031, -0.0099,  0.0026],
        [-0.0091,  0.0047,  0.0066,  ..., -0.0138, -0.0240, -0.0020]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.9824, -5.4648,  0.4719,  ..., -1.6318, -0.6777, -1.6152]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 04:55:47 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for confucius was chinese
descartes was french
plato was greek
newton was english
hegel was german
machiavelli was italian
maxwell was scottish
beethoven was
2024-08-01 04:55:47 root INFO     [order_1_approx] starting weight calculation for newton was english
maxwell was scottish
beethoven was german
plato was greek
descartes was french
machiavelli was italian
confucius was chinese
hegel was
2024-08-01 04:55:47 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-08-01 04:58:54 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0102, -0.0108,  0.0467,  ...,  0.1113,  0.0272,  0.0607],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.1328, -4.6797,  0.0874,  ..., -2.6113, -1.3018, -0.5850],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0235, -0.0272, -0.0130,  ...,  0.0231, -0.0157,  0.0102],
        [ 0.0353,  0.0148,  0.0024,  ..., -0.0232, -0.0421, -0.0047],
        [-0.0092,  0.0087,  0.0319,  ...,  0.0183, -0.0147, -0.0295],
        ...,
        [ 0.0035,  0.0006,  0.0468,  ...,  0.0091, -0.0027,  0.0152],
        [-0.0014,  0.0025, -0.0043,  ...,  0.0506,  0.0163, -0.0175],
        [ 0.0304,  0.0471,  0.0044,  ..., -0.0375,  0.0196, -0.0026]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.5771, -4.4844,  0.1423,  ..., -2.6191, -1.1572, -0.1340]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 04:58:55 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for newton was english
maxwell was scottish
beethoven was german
plato was greek
descartes was french
machiavelli was italian
confucius was chinese
hegel was
2024-08-01 04:58:55 root INFO     [order_1_approx] starting weight calculation for plato was greek
newton was english
beethoven was german
hegel was german
descartes was french
machiavelli was italian
confucius was chinese
maxwell was
2024-08-01 04:58:55 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-08-01 05:02:03 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0762, -0.0462, -0.0762,  ...,  0.0637,  0.1218, -0.0622],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.4883, -3.1250, -0.6558,  ..., -3.7285, -0.7041, -1.4346],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0386, -0.0352,  0.0670,  ..., -0.0092,  0.0279, -0.0045],
        [ 0.0197, -0.0079,  0.0005,  ...,  0.0542,  0.0371,  0.0323],
        [-0.0467, -0.0090,  0.0097,  ...,  0.0531, -0.0322,  0.0126],
        ...,
        [-0.0023, -0.0300, -0.0110,  ...,  0.0941,  0.0218,  0.0208],
        [ 0.0199,  0.0006,  0.0426,  ..., -0.0090,  0.0166, -0.0055],
        [-0.0256,  0.0027, -0.0385,  ...,  0.0533,  0.0053,  0.0385]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.2441, -2.7539, -0.5244,  ..., -3.3809, -0.4951, -1.2178]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 05:02:04 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for plato was greek
newton was english
beethoven was german
hegel was german
descartes was french
machiavelli was italian
confucius was chinese
maxwell was
2024-08-01 05:02:04 root INFO     [order_1_approx] starting weight calculation for descartes was french
confucius was chinese
hegel was german
machiavelli was italian
maxwell was scottish
beethoven was german
newton was english
plato was
2024-08-01 05:02:05 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-08-01 05:05:05 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0793, -0.2695, -0.4729,  ...,  0.0590,  0.0692, -0.1943],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.1680, -4.3516, -0.1608,  ..., -4.6445, -0.3730, -0.9492],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0209, -0.0119, -0.0059,  ...,  0.0100,  0.0040, -0.0036],
        [ 0.0475,  0.0242,  0.0219,  ...,  0.0018, -0.0239, -0.0036],
        [-0.0408,  0.0036, -0.0061,  ..., -0.0164, -0.0163,  0.0572],
        ...,
        [-0.0097, -0.0021,  0.0672,  ...,  0.0303, -0.0053,  0.0198],
        [-0.0057, -0.0083,  0.0060,  ..., -0.0053, -0.0142,  0.0037],
        [ 0.0127,  0.0481, -0.0464,  ..., -0.0260, -0.0253,  0.0073]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.3066, -4.1875, -0.3894,  ..., -3.8379,  0.2090, -0.9307]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 05:05:06 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for descartes was french
confucius was chinese
hegel was german
machiavelli was italian
maxwell was scottish
beethoven was german
newton was english
plato was
2024-08-01 05:05:06 root INFO     [order_1_approx] starting weight calculation for plato was greek
maxwell was scottish
newton was english
beethoven was german
confucius was chinese
hegel was german
machiavelli was italian
descartes was
2024-08-01 05:05:06 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-08-01 05:08:09 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0083, -0.0200, -0.0800,  ...,  0.2031,  0.1008,  0.0201],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.3594, -3.4961,  1.5342,  ..., -4.2031, -1.2520, -0.1140],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0244, -0.0072, -0.0242,  ..., -0.0009,  0.0022, -0.0296],
        [ 0.0237,  0.0100,  0.0084,  ...,  0.0181,  0.0217,  0.0012],
        [-0.0057,  0.0113, -0.0042,  ..., -0.0010, -0.0005,  0.0168],
        ...,
        [ 0.0327,  0.0164,  0.0149,  ...,  0.0476,  0.0142,  0.0471],
        [-0.0230,  0.0004, -0.0232,  ...,  0.0106, -0.0106, -0.0157],
        [ 0.0180,  0.0203,  0.0008,  ..., -0.0055, -0.0190, -0.0197]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.2969, -3.8203,  1.7061,  ..., -4.3633, -0.6230,  0.0846]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 05:08:10 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for plato was greek
maxwell was scottish
newton was english
beethoven was german
confucius was chinese
hegel was german
machiavelli was italian
descartes was
2024-08-01 05:08:10 root INFO     total operator prediction time: 1494.4819004535675 seconds
2024-08-01 05:08:10 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on country - language
2024-08-01 05:08:10 root INFO     building operator country - language
2024-08-01 05:08:10 root INFO     [order_1_approx] starting weight calculation for The country of moldova primarily speaks the language of moldovan
The country of australia primarily speaks the language of english
The country of cuba primarily speaks the language of spanish
The country of taiwan primarily speaks the language of chinese
The country of ecuador primarily speaks the language of spanish
The country of ireland primarily speaks the language of english
The country of kazakhstan primarily speaks the language of kazak
The country of peru primarily speaks the language of
2024-08-01 05:08:10 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-08-01 05:11:12 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1584, -0.0203, -0.0748,  ..., -0.1014, -0.0382, -0.0056],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.0197, -3.8281,  2.1602,  ...,  0.2974, -0.4297, -0.5332],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0028,  0.0094, -0.0177,  ..., -0.0027,  0.0200, -0.0181],
        [-0.0082,  0.0201,  0.0012,  ...,  0.0199,  0.0128, -0.0113],
        [ 0.0113, -0.0135,  0.0259,  ..., -0.0292, -0.0145,  0.0126],
        ...,
        [ 0.0022,  0.0212, -0.0159,  ...,  0.0173,  0.0031, -0.0192],
        [-0.0069,  0.0117, -0.0133,  ...,  0.0086,  0.0275,  0.0082],
        [ 0.0006,  0.0015,  0.0059,  ...,  0.0010, -0.0309,  0.0464]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.1309, -3.8789,  2.1816,  ...,  0.5278, -0.5625, -0.5273]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 05:11:13 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country of moldova primarily speaks the language of moldovan
The country of australia primarily speaks the language of english
The country of cuba primarily speaks the language of spanish
The country of taiwan primarily speaks the language of chinese
The country of ecuador primarily speaks the language of spanish
The country of ireland primarily speaks the language of english
The country of kazakhstan primarily speaks the language of kazak
The country of peru primarily speaks the language of
2024-08-01 05:11:13 root INFO     [order_1_approx] starting weight calculation for The country of ireland primarily speaks the language of english
The country of kazakhstan primarily speaks the language of kazak
The country of australia primarily speaks the language of english
The country of taiwan primarily speaks the language of chinese
The country of peru primarily speaks the language of spanish
The country of cuba primarily speaks the language of spanish
The country of ecuador primarily speaks the language of spanish
The country of moldova primarily speaks the language of
2024-08-01 05:11:13 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-08-01 05:14:17 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0598, -0.2269, -0.1797,  ...,  0.1022, -0.0178, -0.0889],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.9521, -5.0273, -0.7607,  ..., -4.6055, -0.1602, -1.2656],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0107, -0.0216,  0.0618,  ...,  0.0412, -0.0105, -0.0356],
        [ 0.0161, -0.0120,  0.0411,  ...,  0.0288, -0.0004, -0.0389],
        [ 0.0042,  0.0152, -0.0424,  ..., -0.0391, -0.0106,  0.0343],
        ...,
        [ 0.0072, -0.0078,  0.0106,  ...,  0.0098, -0.0074, -0.0092],
        [-0.0090, -0.0034, -0.0058,  ..., -0.0137,  0.0071,  0.0345],
        [-0.0115, -0.0338,  0.0185,  ...,  0.0192, -0.0189, -0.0286]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.7705, -4.7812, -1.3496,  ..., -4.4883, -0.1388, -0.8438]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 05:14:18 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country of ireland primarily speaks the language of english
The country of kazakhstan primarily speaks the language of kazak
The country of australia primarily speaks the language of english
The country of taiwan primarily speaks the language of chinese
The country of peru primarily speaks the language of spanish
The country of cuba primarily speaks the language of spanish
The country of ecuador primarily speaks the language of spanish
The country of moldova primarily speaks the language of
2024-08-01 05:14:18 root INFO     [order_1_approx] starting weight calculation for The country of taiwan primarily speaks the language of chinese
The country of ireland primarily speaks the language of english
The country of peru primarily speaks the language of spanish
The country of cuba primarily speaks the language of spanish
The country of ecuador primarily speaks the language of spanish
The country of moldova primarily speaks the language of moldovan
The country of kazakhstan primarily speaks the language of kazak
The country of australia primarily speaks the language of
2024-08-01 05:14:18 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-08-01 05:17:20 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0098,  0.0607, -0.0110,  ...,  0.0483, -0.0257,  0.0490],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.3486, -2.1543,  2.2598,  ...,  0.0146, -1.6973, -2.1250],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0192, -0.0115,  0.0002,  ...,  0.0114,  0.0096, -0.0109],
        [-0.0224,  0.0114, -0.0086,  ...,  0.0201,  0.0182, -0.0113],
        [ 0.0293,  0.0043,  0.0088,  ..., -0.0260, -0.0069,  0.0284],
        ...,
        [ 0.0299,  0.0060, -0.0068,  ..., -0.0031, -0.0060,  0.0149],
        [-0.0353, -0.0015,  0.0030,  ...,  0.0468,  0.0284, -0.0230],
        [-0.0224, -0.0204, -0.0171,  ...,  0.0158,  0.0128, -0.0030]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.3057, -2.2871,  2.1406,  ..., -0.0118, -1.3496, -2.1387]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 05:17:21 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country of taiwan primarily speaks the language of chinese
The country of ireland primarily speaks the language of english
The country of peru primarily speaks the language of spanish
The country of cuba primarily speaks the language of spanish
The country of ecuador primarily speaks the language of spanish
The country of moldova primarily speaks the language of moldovan
The country of kazakhstan primarily speaks the language of kazak
The country of australia primarily speaks the language of
2024-08-01 05:17:21 root INFO     [order_1_approx] starting weight calculation for The country of peru primarily speaks the language of spanish
The country of kazakhstan primarily speaks the language of kazak
The country of australia primarily speaks the language of english
The country of ecuador primarily speaks the language of spanish
The country of moldova primarily speaks the language of moldovan
The country of ireland primarily speaks the language of english
The country of taiwan primarily speaks the language of chinese
The country of cuba primarily speaks the language of
2024-08-01 05:17:21 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-08-01 05:20:26 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0372, -0.1730,  0.0917,  ..., -0.0994, -0.0479, -0.0330],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.0449, -3.0312,  1.5869,  ...,  1.0850, -0.2637, -1.7637],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0050, -0.0073,  0.0322,  ...,  0.0092,  0.0280,  0.0042],
        [ 0.0308,  0.0048,  0.0180,  ...,  0.0035,  0.0147,  0.0038],
        [-0.0697,  0.0527, -0.0424,  ..., -0.0645, -0.0151,  0.0006],
        ...,
        [-0.0779,  0.0673, -0.0815,  ..., -0.0589, -0.0284, -0.0101],
        [ 0.0118, -0.0247,  0.0224,  ...,  0.0349,  0.0342,  0.0074],
        [-0.0389,  0.0260, -0.0798,  ..., -0.0325, -0.0048, -0.0104]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.5547, -2.6660,  0.9854,  ..., -0.0859,  0.1316, -2.1523]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 05:20:27 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country of peru primarily speaks the language of spanish
The country of kazakhstan primarily speaks the language of kazak
The country of australia primarily speaks the language of english
The country of ecuador primarily speaks the language of spanish
The country of moldova primarily speaks the language of moldovan
The country of ireland primarily speaks the language of english
The country of taiwan primarily speaks the language of chinese
The country of cuba primarily speaks the language of
2024-08-01 05:20:28 root INFO     [order_1_approx] starting weight calculation for The country of kazakhstan primarily speaks the language of kazak
The country of australia primarily speaks the language of english
The country of cuba primarily speaks the language of spanish
The country of ireland primarily speaks the language of english
The country of moldova primarily speaks the language of moldovan
The country of taiwan primarily speaks the language of chinese
The country of peru primarily speaks the language of spanish
The country of ecuador primarily speaks the language of
2024-08-01 05:20:28 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-08-01 05:23:32 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0070,  0.0101, -0.1237,  ...,  0.0267,  0.1097,  0.0660],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.1597, -0.3916,  1.4746,  ...,  0.6357, -0.9902, -1.0146],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0405,  0.0318,  0.0859,  ...,  0.0343,  0.0621, -0.0113],
        [ 0.0064,  0.0169, -0.0152,  ...,  0.0386,  0.0294, -0.0131],
        [-0.0034, -0.0222, -0.0439,  ..., -0.0249, -0.0356, -0.0032],
        ...,
        [-0.0475, -0.0036, -0.0349,  ..., -0.0314, -0.0460,  0.0019],
        [-0.0079,  0.0047,  0.0067,  ...,  0.0370,  0.0504, -0.0309],
        [ 0.0306, -0.0227,  0.0367,  ...,  0.0040, -0.0421,  0.0395]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.8979,  0.0649,  0.7227,  ..., -0.1479, -1.2764, -0.4272]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 05:23:33 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country of kazakhstan primarily speaks the language of kazak
The country of australia primarily speaks the language of english
The country of cuba primarily speaks the language of spanish
The country of ireland primarily speaks the language of english
The country of moldova primarily speaks the language of moldovan
The country of taiwan primarily speaks the language of chinese
The country of peru primarily speaks the language of spanish
The country of ecuador primarily speaks the language of
2024-08-01 05:23:33 root INFO     [order_1_approx] starting weight calculation for The country of australia primarily speaks the language of english
The country of ireland primarily speaks the language of english
The country of ecuador primarily speaks the language of spanish
The country of moldova primarily speaks the language of moldovan
The country of peru primarily speaks the language of spanish
The country of taiwan primarily speaks the language of chinese
The country of cuba primarily speaks the language of spanish
The country of kazakhstan primarily speaks the language of
2024-08-01 05:23:33 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-08-01 05:26:38 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0675, -0.1403, -0.0684,  ..., -0.0189, -0.1466,  0.1703],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.2109, -3.9062, -0.6021,  ..., -2.1055, -2.5352, -1.5254],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0118, -0.0191,  0.0200,  ...,  0.0278,  0.0097, -0.0081],
        [ 0.0088,  0.0003, -0.0029,  ...,  0.0019, -0.0024,  0.0024],
        [ 0.0068,  0.0071, -0.0096,  ..., -0.0114, -0.0140,  0.0024],
        ...,
        [ 0.0065,  0.0116, -0.0141,  ..., -0.0180, -0.0084,  0.0058],
        [-0.0066, -0.0111,  0.0074,  ...,  0.0112,  0.0097, -0.0040],
        [-0.0149, -0.0147,  0.0069,  ...,  0.0150, -0.0127, -0.0029]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.9297, -4.0039, -0.7319,  ..., -2.3145, -2.4375, -1.2812]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 05:26:40 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country of australia primarily speaks the language of english
The country of ireland primarily speaks the language of english
The country of ecuador primarily speaks the language of spanish
The country of moldova primarily speaks the language of moldovan
The country of peru primarily speaks the language of spanish
The country of taiwan primarily speaks the language of chinese
The country of cuba primarily speaks the language of spanish
The country of kazakhstan primarily speaks the language of
2024-08-01 05:26:40 root INFO     [order_1_approx] starting weight calculation for The country of cuba primarily speaks the language of spanish
The country of australia primarily speaks the language of english
The country of ireland primarily speaks the language of english
The country of kazakhstan primarily speaks the language of kazak
The country of ecuador primarily speaks the language of spanish
The country of moldova primarily speaks the language of moldovan
The country of peru primarily speaks the language of spanish
The country of taiwan primarily speaks the language of
2024-08-01 05:26:40 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-08-01 05:29:45 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0342, -0.1904,  0.0031,  ...,  0.1633,  0.0043,  0.0087],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.4512, -2.3770,  2.8711,  ..., -0.1460, -3.5391, -0.2964],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0028,  0.0123,  0.0094,  ...,  0.0315,  0.0316, -0.0048],
        [-0.0182,  0.0115,  0.0173,  ...,  0.0073, -0.0074, -0.0096],
        [ 0.0186,  0.0067,  0.0201,  ..., -0.0302, -0.0332,  0.0137],
        ...,
        [-0.0081, -0.0050, -0.0123,  ..., -0.0090, -0.0186,  0.0214],
        [-0.0393, -0.0216,  0.0016,  ...,  0.0072,  0.0071,  0.0004],
        [-0.0274, -0.0091, -0.0127,  ...,  0.0288,  0.0043, -0.0036]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.4023, -2.1719,  2.7910,  ...,  0.0292, -3.3613, -0.1002]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 05:29:46 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country of cuba primarily speaks the language of spanish
The country of australia primarily speaks the language of english
The country of ireland primarily speaks the language of english
The country of kazakhstan primarily speaks the language of kazak
The country of ecuador primarily speaks the language of spanish
The country of moldova primarily speaks the language of moldovan
The country of peru primarily speaks the language of spanish
The country of taiwan primarily speaks the language of
2024-08-01 05:29:46 root INFO     [order_1_approx] starting weight calculation for The country of kazakhstan primarily speaks the language of kazak
The country of australia primarily speaks the language of english
The country of taiwan primarily speaks the language of chinese
The country of cuba primarily speaks the language of spanish
The country of moldova primarily speaks the language of moldovan
The country of ecuador primarily speaks the language of spanish
The country of peru primarily speaks the language of spanish
The country of ireland primarily speaks the language of
2024-08-01 05:29:46 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-08-01 05:32:50 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0102,  0.0630, -0.0889,  ...,  0.1230,  0.1354, -0.0012],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.0869, -2.5195,  0.0403,  ...,  1.2607,  0.5527, -2.7012],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0268, -0.0303,  0.0260,  ...,  0.0385, -0.0500, -0.0251],
        [-0.0329, -0.0087, -0.0170,  ...,  0.0176, -0.0143,  0.0028],
        [ 0.0260,  0.0251, -0.0037,  ..., -0.0055,  0.0257, -0.0042],
        ...,
        [ 0.0277,  0.0244, -0.0238,  ..., -0.0028,  0.0247, -0.0014],
        [-0.0290, -0.0168,  0.0109,  ...,  0.0183, -0.0119, -0.0022],
        [-0.0221, -0.0381,  0.0050,  ...,  0.0179, -0.0520, -0.0078]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.7007, -1.9082, -0.4978,  ...,  0.8877,  0.8730, -2.2793]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 05:32:51 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country of kazakhstan primarily speaks the language of kazak
The country of australia primarily speaks the language of english
The country of taiwan primarily speaks the language of chinese
The country of cuba primarily speaks the language of spanish
The country of moldova primarily speaks the language of moldovan
The country of ecuador primarily speaks the language of spanish
The country of peru primarily speaks the language of spanish
The country of ireland primarily speaks the language of
2024-08-01 05:32:51 root INFO     total operator prediction time: 1481.1827249526978 seconds
2024-08-01 05:32:51 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on animal - shelter
2024-08-01 05:32:51 root INFO     building operator animal - shelter
2024-08-01 05:32:52 root INFO     [order_1_approx] starting weight calculation for The place fox lives in is called den
The place raven lives in is called nest
The place bear lives in is called den
The place lion lives in is called den
The place spider lives in is called web
The place snake lives in is called nest
The place whale lives in is called sea
The place hedgehog lives in is called
2024-08-01 05:32:52 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-08-01 05:35:57 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0234,  0.1174, -0.0031,  ...,  0.0770, -0.1024, -0.0716],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.2637, -4.5547, -0.6606,  ..., -1.3848,  2.0547,  0.3203],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 3.6030e-03, -8.7128e-03, -1.5747e-02,  ..., -1.0712e-02,
         -1.1452e-02, -7.0114e-03],
        [-5.3253e-03,  8.5983e-03,  4.9324e-03,  ..., -1.5930e-02,
          6.0272e-03,  5.9814e-03],
        [-3.0613e-03,  1.2634e-02,  1.5259e-02,  ...,  5.9280e-03,
         -7.6256e-03,  1.3977e-02],
        ...,
        [-1.0078e-02, -9.2087e-03,  4.4136e-03,  ...,  4.3716e-03,
          3.1471e-05,  7.1640e-03],
        [ 8.2550e-03,  5.8937e-03,  7.4005e-03,  ...,  1.8417e-02,
          1.5549e-02, -1.5049e-03],
        [ 4.6844e-03, -4.7760e-03,  1.0010e-02,  ...,  1.8616e-03,
          8.1539e-04,  2.2430e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.6055, -4.4062, -0.9653,  ..., -1.3574,  2.1523,  0.1353]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 05:35:58 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The place fox lives in is called den
The place raven lives in is called nest
The place bear lives in is called den
The place lion lives in is called den
The place spider lives in is called web
The place snake lives in is called nest
The place whale lives in is called sea
The place hedgehog lives in is called
2024-08-01 05:35:58 root INFO     [order_1_approx] starting weight calculation for The place snake lives in is called nest
The place fox lives in is called den
The place hedgehog lives in is called nest
The place spider lives in is called web
The place raven lives in is called nest
The place lion lives in is called den
The place bear lives in is called den
The place whale lives in is called
2024-08-01 05:35:58 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-08-01 05:39:02 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0356, -0.1005, -0.1174,  ..., -0.1438, -0.0100, -0.1312],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.4023, -3.9453, -1.7529,  ..., -1.5752, -0.9521,  1.0820],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0164, -0.0464, -0.0047,  ...,  0.0054, -0.0266,  0.0011],
        [ 0.0289, -0.0336,  0.0356,  ...,  0.0031, -0.0067,  0.0154],
        [ 0.0117,  0.0144,  0.0038,  ..., -0.0165,  0.0109,  0.0228],
        ...,
        [ 0.0089, -0.0102,  0.0198,  ..., -0.0046, -0.0041,  0.0058],
        [-0.0443,  0.0347, -0.0307,  ...,  0.0279,  0.0251,  0.0113],
        [-0.0090, -0.0600,  0.0237,  ...,  0.0065, -0.0245,  0.0043]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.5000, -3.8984, -1.8408,  ..., -1.4893, -1.5264,  1.3818]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 05:39:03 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The place snake lives in is called nest
The place fox lives in is called den
The place hedgehog lives in is called nest
The place spider lives in is called web
The place raven lives in is called nest
The place lion lives in is called den
The place bear lives in is called den
The place whale lives in is called
2024-08-01 05:39:03 root INFO     [order_1_approx] starting weight calculation for The place fox lives in is called den
The place snake lives in is called nest
The place lion lives in is called den
The place whale lives in is called sea
The place bear lives in is called den
The place spider lives in is called web
The place hedgehog lives in is called nest
The place raven lives in is called
2024-08-01 05:39:03 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-08-01 05:42:09 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0020, -0.0778, -0.0107,  ...,  0.0208, -0.0750,  0.0203],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 6.1836, -7.6953,  0.4414,  ..., -1.2266,  0.6890, -2.1699],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0255, -0.0116, -0.0377,  ..., -0.0192, -0.0140, -0.0163],
        [ 0.0101, -0.0074, -0.0166,  ..., -0.0419,  0.0126,  0.0428],
        [-0.0262, -0.0427,  0.0295,  ..., -0.0255, -0.0054, -0.0516],
        ...,
        [-0.0153, -0.0269,  0.0253,  ...,  0.0182,  0.0991,  0.0202],
        [ 0.0201, -0.0227,  0.0210,  ...,  0.0745,  0.0518,  0.0115],
        [-0.0347, -0.0276,  0.0205,  ..., -0.0829, -0.0285, -0.0072]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 6.0430, -7.3125,  0.5205,  ..., -1.3428,  0.4189, -1.4141]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 05:42:10 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The place fox lives in is called den
The place snake lives in is called nest
The place lion lives in is called den
The place whale lives in is called sea
The place bear lives in is called den
The place spider lives in is called web
The place hedgehog lives in is called nest
The place raven lives in is called
2024-08-01 05:42:10 root INFO     [order_1_approx] starting weight calculation for The place spider lives in is called web
The place bear lives in is called den
The place fox lives in is called den
The place whale lives in is called sea
The place snake lives in is called nest
The place hedgehog lives in is called nest
The place raven lives in is called nest
The place lion lives in is called
2024-08-01 05:42:10 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-08-01 05:45:14 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2544, -0.0426, -0.1071,  ..., -0.1305,  0.0192,  0.1305],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([  5.8398, -10.9141,  -0.5234,  ...,  -1.0996,   0.5356,  -2.5234],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0309, -0.0237,  0.0127,  ...,  0.0075, -0.0123, -0.0027],
        [-0.0084, -0.0021, -0.0180,  ...,  0.0165, -0.0034,  0.0123],
        [ 0.0011, -0.0264,  0.0146,  ..., -0.0056,  0.0014,  0.0033],
        ...,
        [-0.0163,  0.0053, -0.0211,  ...,  0.0097,  0.0271,  0.0168],
        [ 0.0042, -0.0103,  0.0127,  ...,  0.0201, -0.0062, -0.0170],
        [-0.0004, -0.0327,  0.0132,  ...,  0.0024, -0.0040,  0.0144]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[  5.8945, -10.7578,  -0.2554,  ...,  -0.9189,   0.4229,  -2.4180]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 05:45:15 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The place spider lives in is called web
The place bear lives in is called den
The place fox lives in is called den
The place whale lives in is called sea
The place snake lives in is called nest
The place hedgehog lives in is called nest
The place raven lives in is called nest
The place lion lives in is called
2024-08-01 05:45:15 root INFO     [order_1_approx] starting weight calculation for The place raven lives in is called nest
The place whale lives in is called sea
The place snake lives in is called nest
The place fox lives in is called den
The place hedgehog lives in is called nest
The place spider lives in is called web
The place lion lives in is called den
The place bear lives in is called
2024-08-01 05:45:15 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-08-01 05:48:18 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1353,  0.0328, -0.0609,  ..., -0.0977, -0.2607, -0.1317],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.5078, -9.1016, -1.6738,  ..., -3.2207, -0.4990, -1.2363],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0157, -0.0422,  0.0161,  ...,  0.0271, -0.0169,  0.0062],
        [ 0.0794, -0.0275, -0.0572,  ..., -0.0025, -0.0283,  0.1293],
        [ 0.0269,  0.0196, -0.0012,  ..., -0.0319,  0.0273,  0.0174],
        ...,
        [-0.0022, -0.0382,  0.0137,  ..., -0.0208, -0.0304,  0.0343],
        [-0.0356,  0.0418,  0.0550,  ...,  0.0226,  0.0643, -0.0621],
        [ 0.0307, -0.1236, -0.0154,  ..., -0.0197, -0.0320,  0.0765]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.0469, -7.2969, -1.4873,  ..., -2.6191, -0.6592,  0.8652]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 05:48:19 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The place raven lives in is called nest
The place whale lives in is called sea
The place snake lives in is called nest
The place fox lives in is called den
The place hedgehog lives in is called nest
The place spider lives in is called web
The place lion lives in is called den
The place bear lives in is called
2024-08-01 05:48:20 root INFO     [order_1_approx] starting weight calculation for The place whale lives in is called sea
The place bear lives in is called den
The place snake lives in is called nest
The place fox lives in is called den
The place hedgehog lives in is called nest
The place lion lives in is called den
The place raven lives in is called nest
The place spider lives in is called
2024-08-01 05:48:20 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-08-01 05:51:26 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0835,  0.1078, -0.0027,  ...,  0.0042, -0.0178, -0.0284],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.3857, -6.0391,  1.4639,  ..., -1.4072, -1.1504, -0.6660],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0088, -0.0058,  0.0090,  ...,  0.0077,  0.0041, -0.0012],
        [-0.0381,  0.0053, -0.0514,  ...,  0.0228,  0.0120, -0.0029],
        [ 0.0142,  0.0100,  0.0275,  ..., -0.0121, -0.0173, -0.0041],
        ...,
        [ 0.0141,  0.0054, -0.0104,  ...,  0.0112,  0.0131,  0.0176],
        [ 0.0082, -0.0218,  0.0067,  ...,  0.0202, -0.0076,  0.0039],
        [-0.0110, -0.0104,  0.0012,  ...,  0.0109,  0.0177,  0.0212]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.7275, -5.6367,  0.9893,  ..., -1.6035, -1.1113, -0.2515]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 05:51:27 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The place whale lives in is called sea
The place bear lives in is called den
The place snake lives in is called nest
The place fox lives in is called den
The place hedgehog lives in is called nest
The place lion lives in is called den
The place raven lives in is called nest
The place spider lives in is called
2024-08-01 05:51:27 root INFO     [order_1_approx] starting weight calculation for The place bear lives in is called den
The place spider lives in is called web
The place hedgehog lives in is called nest
The place whale lives in is called sea
The place raven lives in is called nest
The place lion lives in is called den
The place snake lives in is called nest
The place fox lives in is called
2024-08-01 05:51:27 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-08-01 05:54:36 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1337,  0.0335,  0.0006,  ..., -0.1299,  0.0339, -0.0925],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.9219, -7.6445, -0.9297,  ..., -2.0352, -0.1675,  2.0000],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0293,  0.0032,  0.0019,  ...,  0.0133,  0.0031, -0.0112],
        [-0.0408,  0.0077, -0.0352,  ...,  0.0425, -0.0320,  0.0068],
        [-0.0047,  0.0232,  0.0377,  ..., -0.0186,  0.0170,  0.0239],
        ...,
        [ 0.0061, -0.0250, -0.0035,  ...,  0.0330,  0.0211,  0.0152],
        [ 0.0191, -0.0072, -0.0040,  ...,  0.0294,  0.0526,  0.0188],
        [-0.0584, -0.0382,  0.0101,  ..., -0.0075, -0.0204, -0.0072]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.7344, -7.2422, -0.9375,  ..., -1.8164, -0.1493,  1.9990]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 05:54:37 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The place bear lives in is called den
The place spider lives in is called web
The place hedgehog lives in is called nest
The place whale lives in is called sea
The place raven lives in is called nest
The place lion lives in is called den
The place snake lives in is called nest
The place fox lives in is called
2024-08-01 05:54:37 root INFO     [order_1_approx] starting weight calculation for The place fox lives in is called den
The place whale lives in is called sea
The place hedgehog lives in is called nest
The place lion lives in is called den
The place raven lives in is called nest
The place bear lives in is called den
The place spider lives in is called web
The place snake lives in is called
2024-08-01 05:54:37 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-08-01 05:57:46 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1075,  0.1494, -0.0992,  ..., -0.0477, -0.0916, -0.0955],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.7480, -5.8281, -0.1240,  ..., -0.8584, -0.3108, -1.4688],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0433,  0.0097, -0.0013,  ...,  0.0114, -0.0129, -0.0254],
        [ 0.0243,  0.0087, -0.0003,  ...,  0.0327,  0.0069,  0.0441],
        [ 0.0111,  0.0114,  0.0573,  ...,  0.0098, -0.0217,  0.0168],
        ...,
        [ 0.0067, -0.0231, -0.0145,  ...,  0.0177, -0.0024,  0.0360],
        [ 0.0151,  0.0190, -0.0057,  ..., -0.0029, -0.0027,  0.0161],
        [-0.0067, -0.0568,  0.0191,  ..., -0.0041,  0.0201,  0.0285]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.4961, -5.0859, -0.2783,  ..., -0.6821, -0.4395, -0.7534]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 05:57:47 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The place fox lives in is called den
The place whale lives in is called sea
The place hedgehog lives in is called nest
The place lion lives in is called den
The place raven lives in is called nest
The place bear lives in is called den
The place spider lives in is called web
The place snake lives in is called
2024-08-01 05:57:47 root INFO     total operator prediction time: 1495.1671421527863 seconds
2024-08-01 05:57:47 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on male - female
2024-08-01 05:57:47 root INFO     building operator male - female
2024-08-01 05:57:47 root INFO     [order_1_approx] starting weight calculation for A female stepfather is known as a stepmother
A female tiger is known as a tigress
A female nephew is known as a niece
A female grandpa is known as a grandma
A female boy is known as a girl
A female daddy is known as a mommy
A female bull is known as a cow
A female buck is known as a
2024-08-01 05:57:47 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-08-01 06:00:49 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([0.2778, 0.0073, 0.0219,  ..., 0.0388, 0.0026, 0.0875], device='cuda:1',
       dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.1367, -2.4883, -0.8193,  ...,  0.7173, -3.5938, -0.7798],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0090,  0.0442,  0.0417,  ...,  0.0233,  0.0714, -0.0348],
        [-0.0010,  0.0163, -0.0155,  ...,  0.0427, -0.0192,  0.0529],
        [ 0.0557, -0.0750,  0.0334,  ..., -0.0448, -0.0414,  0.0315],
        ...,
        [ 0.0111, -0.0314, -0.0483,  ..., -0.0102, -0.0187,  0.0132],
        [ 0.0393,  0.0031,  0.0326,  ..., -0.0304,  0.0487, -0.0171],
        [-0.0002,  0.0075, -0.0061,  ..., -0.0381,  0.0316, -0.0390]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.7500, -2.4746,  0.0786,  ...,  1.6172, -2.9980, -0.4741]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 06:00:50 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A female stepfather is known as a stepmother
A female tiger is known as a tigress
A female nephew is known as a niece
A female grandpa is known as a grandma
A female boy is known as a girl
A female daddy is known as a mommy
A female bull is known as a cow
A female buck is known as a
2024-08-01 06:00:51 root INFO     [order_1_approx] starting weight calculation for A female stepfather is known as a stepmother
A female daddy is known as a mommy
A female boy is known as a girl
A female buck is known as a doe
A female nephew is known as a niece
A female grandpa is known as a grandma
A female tiger is known as a tigress
A female bull is known as a
2024-08-01 06:00:51 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-08-01 06:03:52 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1975, -0.0712, -0.0147,  ..., -0.0422,  0.0104,  0.0578],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.9551, -3.8066, -0.3184,  ..., -0.0361,  0.4453,  0.8516],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0235,  0.0218,  0.0693,  ...,  0.0612,  0.0330, -0.0378],
        [ 0.0089,  0.0117, -0.0013,  ...,  0.0524, -0.0333,  0.0407],
        [ 0.0253, -0.0601,  0.0290,  ...,  0.0051,  0.0259,  0.0296],
        ...,
        [-0.0484,  0.0273,  0.0399,  ..., -0.0322,  0.0003, -0.0956],
        [-0.0677,  0.0826, -0.0273,  ..., -0.0018, -0.0442, -0.0601],
        [ 0.0261,  0.0049, -0.0352,  ..., -0.0051,  0.0011, -0.0254]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.5938, -3.1582,  0.7578,  ..., -0.8125, -0.4956,  0.2891]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 06:03:53 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A female stepfather is known as a stepmother
A female daddy is known as a mommy
A female boy is known as a girl
A female buck is known as a doe
A female nephew is known as a niece
A female grandpa is known as a grandma
A female tiger is known as a tigress
A female bull is known as a
2024-08-01 06:03:53 root INFO     [order_1_approx] starting weight calculation for A female grandpa is known as a grandma
A female daddy is known as a mommy
A female stepfather is known as a stepmother
A female buck is known as a doe
A female boy is known as a girl
A female tiger is known as a tigress
A female bull is known as a cow
A female nephew is known as a
2024-08-01 06:03:53 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-08-01 06:06:53 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0569,  0.1365, -0.1212,  ...,  0.1322,  0.0811,  0.0378],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.5098, -1.5879, -0.4375,  ...,  0.2520, -3.1035, -2.2227],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0338, -0.0137, -0.0236,  ..., -0.0174,  0.0018,  0.0094],
        [ 0.0413,  0.0162,  0.0251,  ...,  0.0206,  0.0101,  0.0158],
        [ 0.0421, -0.0032,  0.0305,  ...,  0.0049,  0.0010, -0.0059],
        ...,
        [ 0.0005,  0.0060, -0.0106,  ..., -0.0047, -0.0081,  0.0093],
        [-0.0566, -0.0287, -0.0397,  ..., -0.0190, -0.0264,  0.0150],
        [ 0.0168, -0.0005, -0.0207,  ...,  0.0043, -0.0082, -0.0111]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.1270, -1.0967, -0.2708,  ...,  0.1759, -3.3555, -2.0273]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 06:06:54 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A female grandpa is known as a grandma
A female daddy is known as a mommy
A female stepfather is known as a stepmother
A female buck is known as a doe
A female boy is known as a girl
A female tiger is known as a tigress
A female bull is known as a cow
A female nephew is known as a
2024-08-01 06:06:54 root INFO     [order_1_approx] starting weight calculation for A female buck is known as a doe
A female tiger is known as a tigress
A female nephew is known as a niece
A female bull is known as a cow
A female boy is known as a girl
A female grandpa is known as a grandma
A female daddy is known as a mommy
A female stepfather is known as a
2024-08-01 06:06:54 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-08-01 06:09:54 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0839, -0.1183, -0.0579,  ...,  0.0510,  0.0208,  0.0762],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.8672, -1.1172, -2.1895,  ...,  1.7656, -2.3398, -0.2505],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0131, -0.0434,  0.0089,  ..., -0.0937, -0.0627,  0.0345],
        [-0.0014, -0.0014,  0.0128,  ..., -0.0363, -0.0004,  0.0047],
        [-0.0085,  0.0213,  0.0373,  ..., -0.0107,  0.0252,  0.0047],
        ...,
        [-0.0019,  0.0134, -0.0249,  ...,  0.0236,  0.0004, -0.0090],
        [ 0.0274, -0.0215, -0.0036,  ..., -0.0197,  0.0007, -0.0022],
        [-0.0126,  0.0182,  0.0113,  ..., -0.0135,  0.0005, -0.0099]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.1914, -1.0469, -2.3262,  ...,  1.8721, -2.2422, -0.0570]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 06:09:55 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A female buck is known as a doe
A female tiger is known as a tigress
A female nephew is known as a niece
A female bull is known as a cow
A female boy is known as a girl
A female grandpa is known as a grandma
A female daddy is known as a mommy
A female stepfather is known as a
2024-08-01 06:09:55 root INFO     [order_1_approx] starting weight calculation for A female stepfather is known as a stepmother
A female boy is known as a girl
A female bull is known as a cow
A female buck is known as a doe
A female tiger is known as a tigress
A female nephew is known as a niece
A female grandpa is known as a grandma
A female daddy is known as a
2024-08-01 06:09:55 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-08-01 06:13:00 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0039, -0.1165, -0.1588,  ..., -0.0076, -0.1133, -0.0132],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.2891, -2.5273, -2.3730,  ...,  2.0586, -3.8574, -1.6152],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0100,  0.0148, -0.0131,  ..., -0.0043, -0.0332, -0.0051],
        [-0.0137, -0.0060,  0.0198,  ..., -0.0395,  0.0436,  0.0024],
        [ 0.0018,  0.0006,  0.0286,  ...,  0.0220,  0.0151, -0.0094],
        ...,
        [-0.0093,  0.0221, -0.0100,  ..., -0.0176,  0.0227, -0.0191],
        [ 0.0186, -0.0014, -0.0158,  ..., -0.0184,  0.0065, -0.0115],
        [-0.0170, -0.0172, -0.0097,  ...,  0.0014, -0.0106,  0.0257]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.3281, -2.0645, -2.3672,  ...,  1.9941, -3.7422, -1.6250]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 06:13:01 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A female stepfather is known as a stepmother
A female boy is known as a girl
A female bull is known as a cow
A female buck is known as a doe
A female tiger is known as a tigress
A female nephew is known as a niece
A female grandpa is known as a grandma
A female daddy is known as a
2024-08-01 06:13:02 root INFO     [order_1_approx] starting weight calculation for A female boy is known as a girl
A female nephew is known as a niece
A female stepfather is known as a stepmother
A female buck is known as a doe
A female daddy is known as a mommy
A female grandpa is known as a grandma
A female bull is known as a cow
A female tiger is known as a
2024-08-01 06:13:02 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-08-01 06:16:08 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1782,  0.1858, -0.1278,  ...,  0.0726, -0.1652, -0.0214],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.6250, -6.5547, -1.6006,  ..., -0.3701, -2.0898, -0.0264],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0496, -0.0175, -0.0030,  ..., -0.0026,  0.0235, -0.0100],
        [ 0.0302, -0.0289, -0.0231,  ...,  0.0124,  0.0075,  0.0511],
        [-0.0054,  0.0175,  0.0432,  ...,  0.0120,  0.0200, -0.0130],
        ...,
        [-0.0070,  0.0261,  0.0095,  ...,  0.0036,  0.0188, -0.0266],
        [ 0.0101, -0.0116, -0.0123,  ...,  0.0231,  0.0023,  0.0264],
        [ 0.0300,  0.0370,  0.0273,  ..., -0.0180, -0.0035, -0.0005]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.6035, -6.0156, -1.3486,  ..., -0.4500, -2.2578, -0.6450]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 06:16:09 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A female boy is known as a girl
A female nephew is known as a niece
A female stepfather is known as a stepmother
A female buck is known as a doe
A female daddy is known as a mommy
A female grandpa is known as a grandma
A female bull is known as a cow
A female tiger is known as a
2024-08-01 06:16:09 root INFO     [order_1_approx] starting weight calculation for A female buck is known as a doe
A female daddy is known as a mommy
A female bull is known as a cow
A female tiger is known as a tigress
A female stepfather is known as a stepmother
A female boy is known as a girl
A female nephew is known as a niece
A female grandpa is known as a
2024-08-01 06:16:09 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-08-01 06:19:13 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0674, -0.0614, -0.0167,  ..., -0.0469,  0.0215,  0.0516],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.9414, -1.6846, -0.7627,  ...,  0.8057, -3.1680, -2.6191],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0050, -0.0183,  0.0440,  ..., -0.0096, -0.0593, -0.0124],
        [-0.0065,  0.0124, -0.0013,  ..., -0.0207,  0.0146,  0.0086],
        [-0.0127, -0.0075,  0.0283,  ..., -0.0060, -0.0006, -0.0123],
        ...,
        [ 0.0249,  0.0059, -0.0355,  ...,  0.0283,  0.0163,  0.0181],
        [ 0.0088,  0.0168,  0.0077,  ..., -0.0298, -0.0002,  0.0088],
        [ 0.0015,  0.0210,  0.0070,  ...,  0.0006, -0.0051, -0.0125]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.0156, -1.3682, -0.9102,  ...,  0.4319, -2.8359, -2.3457]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 06:19:15 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A female buck is known as a doe
A female daddy is known as a mommy
A female bull is known as a cow
A female tiger is known as a tigress
A female stepfather is known as a stepmother
A female boy is known as a girl
A female nephew is known as a niece
A female grandpa is known as a
2024-08-01 06:19:15 root INFO     [order_1_approx] starting weight calculation for A female stepfather is known as a stepmother
A female nephew is known as a niece
A female bull is known as a cow
A female daddy is known as a mommy
A female grandpa is known as a grandma
A female buck is known as a doe
A female tiger is known as a tigress
A female boy is known as a
2024-08-01 06:19:15 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-08-01 06:22:17 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1283, -0.0210, -0.0098,  ...,  0.0536, -0.1499, -0.0750],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.0195, -1.1807, -3.4277,  ...,  3.4648, -1.1484,  1.1660],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0300, -0.0208,  0.0018,  ...,  0.0046, -0.0074,  0.0362],
        [-0.0123, -0.0342,  0.0073,  ...,  0.0099,  0.0094,  0.0261],
        [ 0.0117, -0.0089, -0.0209,  ...,  0.0108, -0.0166,  0.0188],
        ...,
        [-0.0165,  0.0253,  0.0249,  ...,  0.0290,  0.0103,  0.0043],
        [-0.0023, -0.0146,  0.0392,  ...,  0.0299, -0.0206, -0.0208],
        [ 0.0121, -0.0193, -0.0227,  ..., -0.0382,  0.0043,  0.0052]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.0469, -1.2939, -3.1055,  ...,  3.2812, -0.9570,  1.2578]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 06:22:18 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A female stepfather is known as a stepmother
A female nephew is known as a niece
A female bull is known as a cow
A female daddy is known as a mommy
A female grandpa is known as a grandma
A female buck is known as a doe
A female tiger is known as a tigress
A female boy is known as a
2024-08-01 06:22:18 root INFO     total operator prediction time: 1471.4432263374329 seconds
2024-08-01 06:22:18 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on name - occupation
2024-08-01 06:22:18 root INFO     building operator name - occupation
2024-08-01 06:22:18 root INFO     [order_1_approx] starting weight calculation for aristotle was known for their work as a  philosopher
andersen was known for their work as a  writer
raphael was known for their work as a  painter
beethoven was known for their work as a  composer
mencius was known for their work as a  philosopher
confucius was known for their work as a  philosopher
strauss was known for their work as a  composer
jolie was known for their work as a 
2024-08-01 06:22:18 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-08-01 06:25:23 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0113,  0.1451, -0.0607,  ...,  0.1106, -0.0213,  0.0194],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.9395, -3.4785,  2.6680,  ..., -3.4062, -1.6084,  1.2588],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0007, -0.0013, -0.0053,  ...,  0.0077, -0.0148,  0.0105],
        [-0.0208,  0.0274,  0.0050,  ..., -0.0049,  0.0192, -0.0141],
        [ 0.0063,  0.0101,  0.0043,  ...,  0.0005, -0.0098,  0.0029],
        ...,
        [ 0.0275,  0.0039, -0.0002,  ..., -0.0064,  0.0004, -0.0073],
        [-0.0086, -0.0431,  0.0208,  ...,  0.0162, -0.0498,  0.0085],
        [ 0.0010,  0.0211, -0.0182,  ..., -0.0064,  0.0312,  0.0107]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.9785, -3.5781,  2.6191,  ..., -3.4375, -1.6006,  1.2109]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 06:25:24 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for aristotle was known for their work as a  philosopher
andersen was known for their work as a  writer
raphael was known for their work as a  painter
beethoven was known for their work as a  composer
mencius was known for their work as a  philosopher
confucius was known for their work as a  philosopher
strauss was known for their work as a  composer
jolie was known for their work as a 
2024-08-01 06:25:25 root INFO     [order_1_approx] starting weight calculation for beethoven was known for their work as a  composer
strauss was known for their work as a  composer
confucius was known for their work as a  philosopher
aristotle was known for their work as a  philosopher
jolie was known for their work as a  actress
raphael was known for their work as a  painter
andersen was known for their work as a  writer
mencius was known for their work as a 
2024-08-01 06:25:25 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-08-01 06:28:29 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1158,  0.0340, -0.2032,  ...,  0.1375, -0.1095, -0.1492],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.4238, -5.3867,  3.8262,  ..., -8.6719,  1.4414,  1.8018],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0256,  0.0006, -0.0163,  ...,  0.0029,  0.0115,  0.0047],
        [ 0.0029,  0.0151, -0.0063,  ..., -0.0079, -0.0247, -0.0163],
        [ 0.0081, -0.0064,  0.0065,  ..., -0.0160, -0.0039,  0.0133],
        ...,
        [-0.0111, -0.0018,  0.0098,  ...,  0.0530, -0.0591, -0.0379],
        [ 0.0105,  0.0020, -0.0176,  ..., -0.0022, -0.0139, -0.0027],
        [-0.0278, -0.0080,  0.0092,  ..., -0.0144,  0.0135,  0.0141]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.3184, -5.3320,  3.8730,  ..., -8.7422,  1.5020,  1.8506]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 06:28:30 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for beethoven was known for their work as a  composer
strauss was known for their work as a  composer
confucius was known for their work as a  philosopher
aristotle was known for their work as a  philosopher
jolie was known for their work as a  actress
raphael was known for their work as a  painter
andersen was known for their work as a  writer
mencius was known for their work as a 
2024-08-01 06:28:30 root INFO     [order_1_approx] starting weight calculation for mencius was known for their work as a  philosopher
andersen was known for their work as a  writer
confucius was known for their work as a  philosopher
strauss was known for their work as a  composer
jolie was known for their work as a  actress
aristotle was known for their work as a  philosopher
beethoven was known for their work as a  composer
raphael was known for their work as a 
2024-08-01 06:28:30 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-08-01 06:31:36 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2639, -0.0669,  0.0400,  ...,  0.0089,  0.0146, -0.0009],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.4492, -7.6719,  2.7148,  ..., -6.0039, -1.2500, -2.0742],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 2.1561e-02,  1.3908e-02, -1.9440e-02,  ...,  3.9940e-03,
         -1.6403e-03, -1.0376e-02],
        [-1.9699e-02,  6.0463e-04,  5.7098e-02,  ..., -1.2939e-02,
          8.8501e-03,  1.2274e-03],
        [ 1.3412e-02, -4.3755e-03,  3.7689e-03,  ..., -2.9755e-03,
          6.9809e-03, -4.1809e-03],
        ...,
        [-3.4332e-05,  9.2010e-03,  1.5930e-02,  ...,  1.0460e-02,
          2.2736e-02,  1.0750e-02],
        [-1.0902e-02, -1.0300e-02,  2.0844e-02,  ...,  2.1149e-02,
          3.0350e-02,  1.1963e-02],
        [ 2.6989e-03,  4.7760e-03, -1.1444e-05,  ..., -1.1692e-03,
         -2.0027e-04,  1.0307e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.3164, -7.5977,  2.6641,  ..., -5.9766, -0.9707, -1.8926]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 06:31:37 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for mencius was known for their work as a  philosopher
andersen was known for their work as a  writer
confucius was known for their work as a  philosopher
strauss was known for their work as a  composer
jolie was known for their work as a  actress
aristotle was known for their work as a  philosopher
beethoven was known for their work as a  composer
raphael was known for their work as a 
2024-08-01 06:31:37 root INFO     [order_1_approx] starting weight calculation for strauss was known for their work as a  composer
beethoven was known for their work as a  composer
mencius was known for their work as a  philosopher
andersen was known for their work as a  writer
aristotle was known for their work as a  philosopher
raphael was known for their work as a  painter
jolie was known for their work as a  actress
confucius was known for their work as a 
2024-08-01 06:31:37 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-08-01 06:34:44 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0750, -0.0673, -0.2133,  ...,  0.1812, -0.1085, -0.0446],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.2197, -4.9336,  3.8574,  ..., -7.5156,  1.0801,  1.0469],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 8.5297e-03, -2.3079e-04,  3.5858e-03,  ...,  1.2619e-02,
         -1.8349e-03, -4.6616e-03],
        [ 2.7962e-03,  3.5686e-03, -4.5929e-03,  ...,  4.7607e-03,
          6.2485e-03,  9.3079e-03],
        [-2.3289e-03, -4.4465e-04,  1.6449e-02,  ...,  2.4872e-03,
         -3.4294e-03,  3.0594e-03],
        ...,
        [ 8.7814e-03, -1.1635e-02, -5.8975e-03,  ...,  8.7357e-03,
         -2.1042e-02, -3.1395e-03],
        [-5.4703e-03, -2.8439e-03,  9.2626e-05,  ..., -3.3951e-04,
          2.6150e-03,  2.4796e-05],
        [-3.7212e-03, -1.2932e-03,  7.5760e-03,  ..., -8.2474e-03,
          5.2185e-03, -1.7366e-03]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.1431, -4.9453,  3.8301,  ..., -7.3594,  1.1172,  0.9990]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 06:34:45 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for strauss was known for their work as a  composer
beethoven was known for their work as a  composer
mencius was known for their work as a  philosopher
andersen was known for their work as a  writer
aristotle was known for their work as a  philosopher
raphael was known for their work as a  painter
jolie was known for their work as a  actress
confucius was known for their work as a 
2024-08-01 06:34:45 root INFO     [order_1_approx] starting weight calculation for confucius was known for their work as a  philosopher
andersen was known for their work as a  writer
mencius was known for their work as a  philosopher
raphael was known for their work as a  painter
strauss was known for their work as a  composer
aristotle was known for their work as a  philosopher
jolie was known for their work as a  actress
beethoven was known for their work as a 
2024-08-01 06:34:45 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-08-01 06:37:48 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0517,  0.0865, -0.1853,  ..., -0.0379,  0.0861,  0.0225],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.2598, -6.4219,  1.2832,  ..., -2.4473,  1.2197, -2.0293],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-3.2043e-03,  4.9324e-03, -1.4296e-03,  ..., -8.7738e-03,
          9.1553e-04, -8.9951e-03],
        [ 2.1706e-03,  2.2087e-03,  1.9196e-02,  ...,  2.0569e-02,
         -5.0011e-03,  1.0117e-02],
        [-7.8559e-05,  4.5586e-04, -2.1019e-03,  ..., -5.5504e-03,
          2.3136e-03,  1.0643e-02],
        ...,
        [ 1.1078e-02, -2.0618e-03,  7.0686e-03,  ...,  1.7868e-02,
         -1.2146e-02,  9.1705e-03],
        [-2.9011e-03,  9.0179e-03, -8.0414e-03,  ..., -1.2238e-02,
         -4.6158e-04, -1.7227e-02],
        [-8.6594e-04, -1.2955e-02,  2.9755e-03,  ...,  1.8814e-02,
         -1.1158e-03,  2.0203e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.1152, -6.3984,  1.2705,  ..., -2.2441,  1.2646, -1.9766]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 06:37:49 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for confucius was known for their work as a  philosopher
andersen was known for their work as a  writer
mencius was known for their work as a  philosopher
raphael was known for their work as a  painter
strauss was known for their work as a  composer
aristotle was known for their work as a  philosopher
jolie was known for their work as a  actress
beethoven was known for their work as a 
2024-08-01 06:37:49 root INFO     [order_1_approx] starting weight calculation for confucius was known for their work as a  philosopher
jolie was known for their work as a  actress
andersen was known for their work as a  writer
beethoven was known for their work as a  composer
mencius was known for their work as a  philosopher
raphael was known for their work as a  painter
strauss was known for their work as a  composer
aristotle was known for their work as a 
2024-08-01 06:37:49 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-08-01 06:40:53 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0750, -0.0203, -0.2534,  ...,  0.0466, -0.0506,  0.0883],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.8018, -5.4609,  2.2910,  ..., -7.2344, -0.9258, -1.9980],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0022,  0.0042, -0.0107,  ...,  0.0106,  0.0109,  0.0063],
        [-0.0006,  0.0202,  0.0081,  ...,  0.0090, -0.0107, -0.0135],
        [-0.0120, -0.0021, -0.0098,  ...,  0.0014,  0.0079,  0.0084],
        ...,
        [ 0.0068,  0.0116,  0.0107,  ...,  0.0146, -0.0142, -0.0163],
        [ 0.0005, -0.0097, -0.0033,  ..., -0.0134,  0.0069,  0.0047],
        [ 0.0046,  0.0125,  0.0063,  ...,  0.0102, -0.0089, -0.0127]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.7100, -5.3203,  2.1680,  ..., -6.9492, -0.9590, -1.8320]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 06:40:54 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for confucius was known for their work as a  philosopher
jolie was known for their work as a  actress
andersen was known for their work as a  writer
beethoven was known for their work as a  composer
mencius was known for their work as a  philosopher
raphael was known for their work as a  painter
strauss was known for their work as a  composer
aristotle was known for their work as a 
2024-08-01 06:40:54 root INFO     [order_1_approx] starting weight calculation for strauss was known for their work as a  composer
jolie was known for their work as a  actress
beethoven was known for their work as a  composer
mencius was known for their work as a  philosopher
confucius was known for their work as a  philosopher
aristotle was known for their work as a  philosopher
raphael was known for their work as a  painter
andersen was known for their work as a 
2024-08-01 06:40:55 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-08-01 06:43:58 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1570,  0.0867, -0.2493,  ...,  0.1805,  0.0758, -0.1102],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.5928, -4.4609,  2.0820,  ..., -3.8633, -2.8359,  1.1768],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0335, -0.0400,  0.0086,  ...,  0.0352, -0.0086, -0.0136],
        [-0.0065,  0.0002, -0.0294,  ..., -0.0041,  0.0011, -0.0219],
        [ 0.0254, -0.0107, -0.0051,  ..., -0.0023,  0.0083,  0.0094],
        ...,
        [ 0.0231, -0.0237, -0.0070,  ...,  0.0287, -0.0124, -0.0028],
        [ 0.0189, -0.0412, -0.0316,  ...,  0.0148,  0.0066,  0.0149],
        [-0.0252,  0.0033, -0.0017,  ...,  0.0070, -0.0125, -0.0033]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.3691, -4.4805,  2.0547,  ..., -3.6211, -2.8457,  0.9775]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 06:43:59 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for strauss was known for their work as a  composer
jolie was known for their work as a  actress
beethoven was known for their work as a  composer
mencius was known for their work as a  philosopher
confucius was known for their work as a  philosopher
aristotle was known for their work as a  philosopher
raphael was known for their work as a  painter
andersen was known for their work as a 
2024-08-01 06:44:00 root INFO     [order_1_approx] starting weight calculation for mencius was known for their work as a  philosopher
beethoven was known for their work as a  composer
raphael was known for their work as a  painter
confucius was known for their work as a  philosopher
aristotle was known for their work as a  philosopher
jolie was known for their work as a  actress
andersen was known for their work as a  writer
strauss was known for their work as a 
2024-08-01 06:44:00 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-08-01 06:47:05 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1968,  0.0334,  0.0176,  ...,  0.1329,  0.0215, -0.1506],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.1025, -5.2812,  3.1914,  ..., -2.5918, -0.1587, -3.4805],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0419, -0.0312, -0.0140,  ..., -0.0085, -0.0271, -0.0105],
        [-0.1146,  0.0282,  0.1245,  ...,  0.0092, -0.0095,  0.0009],
        [ 0.2238,  0.0432, -0.1532,  ..., -0.0697,  0.0158, -0.0835],
        ...,
        [-0.0253, -0.0019,  0.0442,  ...,  0.1415, -0.0056,  0.0299],
        [-0.1614, -0.0021,  0.0678,  ...,  0.0318, -0.0119,  0.0438],
        [-0.3091,  0.0131,  0.0958,  ...,  0.0034, -0.0196,  0.1323]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.4165, -4.7383,  2.0176,  ..., -2.8105,  0.7808, -1.7236]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 06:47:06 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for mencius was known for their work as a  philosopher
beethoven was known for their work as a  composer
raphael was known for their work as a  painter
confucius was known for their work as a  philosopher
aristotle was known for their work as a  philosopher
jolie was known for their work as a  actress
andersen was known for their work as a  writer
strauss was known for their work as a 
2024-08-01 06:47:06 root INFO     total operator prediction time: 1488.171816110611 seconds
2024-08-01 06:47:06 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on country - capital
2024-08-01 06:47:06 root INFO     building operator country - capital
2024-08-01 06:47:07 root INFO     [order_1_approx] starting weight calculation for The country with belgrade as its capital is known as serbia
The country with santiago as its capital is known as chile
The country with hanoi as its capital is known as vietnam
The country with vienna as its capital is known as austria
The country with tbilisi as its capital is known as georgia
The country with abuja as its capital is known as nigeria
The country with brussels as its capital is known as belgium
The country with moscow as its capital is known as
2024-08-01 06:47:07 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-08-01 06:50:11 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0707, -0.0748, -0.1155,  ...,  0.1516, -0.0819, -0.1688],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.4109, -5.0781, -2.8926,  ..., -2.0898, -0.0381, -4.2539],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-3.1090e-03, -1.8875e-02, -2.9259e-03,  ...,  1.4229e-02,
          3.8300e-03,  2.2034e-02],
        [ 2.1591e-02,  1.3931e-02,  3.6907e-03,  ..., -7.3433e-03,
          9.5825e-03,  1.9026e-03],
        [-5.3291e-03, -1.6708e-02,  1.1955e-02,  ..., -4.1962e-05,
         -5.2032e-03,  6.9771e-03],
        ...,
        [ 1.8326e-02,  2.2369e-02, -4.0436e-03,  ..., -1.9806e-02,
         -1.4999e-02, -2.2156e-02],
        [-4.6158e-03, -2.9297e-02, -1.8127e-02,  ...,  3.3398e-03,
          1.6708e-02,  2.5116e-02],
        [-1.3687e-02, -1.1452e-02, -1.1612e-02,  ...,  1.1505e-02,
         -3.2288e-02, -1.7944e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.3621, -5.1602, -2.7969,  ..., -2.0938,  0.1383, -4.1367]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 06:50:12 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country with belgrade as its capital is known as serbia
The country with santiago as its capital is known as chile
The country with hanoi as its capital is known as vietnam
The country with vienna as its capital is known as austria
The country with tbilisi as its capital is known as georgia
The country with abuja as its capital is known as nigeria
The country with brussels as its capital is known as belgium
The country with moscow as its capital is known as
2024-08-01 06:50:12 root INFO     [order_1_approx] starting weight calculation for The country with brussels as its capital is known as belgium
The country with tbilisi as its capital is known as georgia
The country with hanoi as its capital is known as vietnam
The country with belgrade as its capital is known as serbia
The country with moscow as its capital is known as russia
The country with vienna as its capital is known as austria
The country with abuja as its capital is known as nigeria
The country with santiago as its capital is known as
2024-08-01 06:50:12 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-08-01 06:53:17 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0619, -0.0795, -0.1316,  ...,  0.2161,  0.0955, -0.0342],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.8594, -0.6216, -0.1210,  ...,  0.1326, -0.3223, -2.9043],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0301,  0.0164, -0.0288,  ...,  0.0061, -0.0520, -0.0623],
        [-0.0219,  0.0280, -0.0615,  ..., -0.0210,  0.0055,  0.0609],
        [ 0.0199,  0.0487,  0.0109,  ...,  0.0359, -0.0002, -0.0126],
        ...,
        [-0.0463, -0.0067,  0.0036,  ..., -0.0028,  0.0125, -0.0264],
        [ 0.0234, -0.0326,  0.0036,  ...,  0.0347, -0.0186, -0.0057],
        [ 0.0260, -0.0116, -0.0389,  ..., -0.0040, -0.0016, -0.0241]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.8320, -0.2432, -0.4629,  ...,  0.0428, -0.4424, -3.0234]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 06:53:18 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country with brussels as its capital is known as belgium
The country with tbilisi as its capital is known as georgia
The country with hanoi as its capital is known as vietnam
The country with belgrade as its capital is known as serbia
The country with moscow as its capital is known as russia
The country with vienna as its capital is known as austria
The country with abuja as its capital is known as nigeria
The country with santiago as its capital is known as
2024-08-01 06:53:19 root INFO     [order_1_approx] starting weight calculation for The country with moscow as its capital is known as russia
The country with hanoi as its capital is known as vietnam
The country with brussels as its capital is known as belgium
The country with santiago as its capital is known as chile
The country with vienna as its capital is known as austria
The country with belgrade as its capital is known as serbia
The country with abuja as its capital is known as nigeria
The country with tbilisi as its capital is known as
2024-08-01 06:53:19 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-08-01 06:56:22 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0542, -0.1318, -0.1930,  ...,  0.1929, -0.1265,  0.0891],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.9375, -5.5000, -0.9893,  ..., -2.9238,  0.2773, -2.8613],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0107, -0.0005,  0.0107,  ...,  0.0280,  0.0145,  0.0053],
        [ 0.0221,  0.0158, -0.0060,  ...,  0.0256, -0.0068,  0.0185],
        [-0.0059,  0.0079, -0.0061,  ..., -0.0071, -0.0141, -0.0049],
        ...,
        [ 0.0214,  0.0054, -0.0162,  ...,  0.0148,  0.0053,  0.0148],
        [ 0.0137, -0.0114,  0.0085,  ...,  0.0255,  0.0107, -0.0150],
        [ 0.0138,  0.0012, -0.0083,  ...,  0.0157,  0.0151,  0.0109]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.7852, -5.5898, -0.8677,  ..., -2.9121,  0.2915, -2.7070]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 06:56:23 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country with moscow as its capital is known as russia
The country with hanoi as its capital is known as vietnam
The country with brussels as its capital is known as belgium
The country with santiago as its capital is known as chile
The country with vienna as its capital is known as austria
The country with belgrade as its capital is known as serbia
The country with abuja as its capital is known as nigeria
The country with tbilisi as its capital is known as
2024-08-01 06:56:23 root INFO     [order_1_approx] starting weight calculation for The country with belgrade as its capital is known as serbia
The country with moscow as its capital is known as russia
The country with vienna as its capital is known as austria
The country with santiago as its capital is known as chile
The country with abuja as its capital is known as nigeria
The country with hanoi as its capital is known as vietnam
The country with tbilisi as its capital is known as georgia
The country with brussels as its capital is known as
2024-08-01 06:56:23 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-08-01 06:59:28 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1312, -0.0507, -0.2109,  ...,  0.1674,  0.1809,  0.1448],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.7520, -6.4375, -1.2773,  ..., -0.5747,  0.7773, -4.8438],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0044,  0.0087,  0.0176,  ...,  0.0264, -0.0067, -0.0093],
        [-0.0145, -0.0200, -0.0083,  ...,  0.0039,  0.0124,  0.0148],
        [ 0.0090, -0.0031, -0.0113,  ..., -0.0069, -0.0059, -0.0020],
        ...,
        [ 0.0235,  0.0033, -0.0115,  ..., -0.0092, -0.0171,  0.0000],
        [ 0.0015, -0.0063,  0.0044,  ...,  0.0062, -0.0035,  0.0024],
        [-0.0113, -0.0102, -0.0242,  ...,  0.0008, -0.0022,  0.0045]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.7158, -6.3477, -1.2725,  ..., -0.6050,  0.8208, -4.7305]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 06:59:29 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country with belgrade as its capital is known as serbia
The country with moscow as its capital is known as russia
The country with vienna as its capital is known as austria
The country with santiago as its capital is known as chile
The country with abuja as its capital is known as nigeria
The country with hanoi as its capital is known as vietnam
The country with tbilisi as its capital is known as georgia
The country with brussels as its capital is known as
2024-08-01 06:59:29 root INFO     [order_1_approx] starting weight calculation for The country with hanoi as its capital is known as vietnam
The country with abuja as its capital is known as nigeria
The country with moscow as its capital is known as russia
The country with brussels as its capital is known as belgium
The country with santiago as its capital is known as chile
The country with tbilisi as its capital is known as georgia
The country with vienna as its capital is known as austria
The country with belgrade as its capital is known as
2024-08-01 06:59:29 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-08-01 07:02:30 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1261, -0.0475, -0.1578,  ...,  0.1768,  0.0597, -0.1617],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.1045, -6.3672, -1.8867,  ..., -2.5371,  1.3037, -2.8711],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0039,  0.0099, -0.0029,  ...,  0.0301,  0.0181, -0.0117],
        [ 0.0485,  0.0210,  0.0337,  ...,  0.0159,  0.0235,  0.0036],
        [-0.0002, -0.0057, -0.0113,  ..., -0.0040, -0.0026, -0.0229],
        ...,
        [ 0.0033,  0.0170, -0.0154,  ...,  0.0250, -0.0156,  0.0003],
        [-0.0215, -0.0221,  0.0072,  ..., -0.0056, -0.0004,  0.0096],
        [ 0.0079,  0.0326, -0.0010,  ...,  0.0102,  0.0107, -0.0379]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.3916, -6.4961, -1.8076,  ..., -2.6152,  1.4814, -2.8125]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 07:02:31 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country with hanoi as its capital is known as vietnam
The country with abuja as its capital is known as nigeria
The country with moscow as its capital is known as russia
The country with brussels as its capital is known as belgium
The country with santiago as its capital is known as chile
The country with tbilisi as its capital is known as georgia
The country with vienna as its capital is known as austria
The country with belgrade as its capital is known as
2024-08-01 07:02:31 root INFO     [order_1_approx] starting weight calculation for The country with belgrade as its capital is known as serbia
The country with vienna as its capital is known as austria
The country with tbilisi as its capital is known as georgia
The country with moscow as its capital is known as russia
The country with brussels as its capital is known as belgium
The country with abuja as its capital is known as nigeria
The country with santiago as its capital is known as chile
The country with hanoi as its capital is known as
2024-08-01 07:02:31 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-08-01 07:05:35 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0861, -0.1836, -0.1400,  ...,  0.0659, -0.1247, -0.0349],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.8154, -5.6250,  0.2268,  ..., -1.7617, -2.5078, -3.2773],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 1.8406e-03, -2.9793e-03, -2.2678e-03,  ...,  1.6144e-02,
          3.8147e-06, -1.1589e-02],
        [-6.2256e-03, -1.0223e-03, -1.1940e-02,  ...,  4.5433e-03,
         -4.0703e-03, -2.1729e-02],
        [ 1.8005e-03, -5.9776e-03,  3.1769e-02,  ..., -1.7456e-02,
          1.8406e-03, -4.8981e-03],
        ...,
        [-8.3084e-03,  8.2541e-04, -2.1027e-02,  ..., -9.7198e-03,
          9.2010e-03, -1.0391e-02],
        [-6.1951e-03, -8.0643e-03, -1.6296e-02,  ..., -1.1230e-02,
         -3.5343e-03, -2.3651e-03],
        [-1.9821e-02, -1.5480e-02, -2.0813e-02,  ..., -1.1383e-02,
          1.5472e-02, -1.3176e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.9268, -5.5469,  0.3740,  ..., -1.7500, -2.4082, -3.0566]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 07:05:36 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country with belgrade as its capital is known as serbia
The country with vienna as its capital is known as austria
The country with tbilisi as its capital is known as georgia
The country with moscow as its capital is known as russia
The country with brussels as its capital is known as belgium
The country with abuja as its capital is known as nigeria
The country with santiago as its capital is known as chile
The country with hanoi as its capital is known as
2024-08-01 07:05:37 root INFO     [order_1_approx] starting weight calculation for The country with hanoi as its capital is known as vietnam
The country with abuja as its capital is known as nigeria
The country with moscow as its capital is known as russia
The country with belgrade as its capital is known as serbia
The country with brussels as its capital is known as belgium
The country with santiago as its capital is known as chile
The country with tbilisi as its capital is known as georgia
The country with vienna as its capital is known as
2024-08-01 07:05:37 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-08-01 07:08:43 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1268, -0.1011, -0.0121,  ...,  0.1282,  0.0206, -0.1087],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.4570, -5.5625, -0.6606,  ...,  0.2798,  0.7002, -2.8672],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 3.7670e-03,  1.1154e-02,  5.7268e-04,  ...,  1.8600e-02,
          3.0960e-02,  3.7170e-02],
        [ 4.0131e-02, -2.0981e-03,  1.2939e-02,  ...,  1.3763e-02,
         -1.0063e-02, -2.0203e-02],
        [-9.0561e-03,  6.3553e-03, -1.3321e-02,  ..., -3.1982e-02,
         -1.3535e-02, -5.9433e-03],
        ...,
        [-6.9618e-03,  3.4149e-02, -1.1101e-03,  ...,  3.1952e-02,
         -9.6207e-03, -2.4094e-02],
        [ 4.2191e-03, -1.2093e-02, -6.5918e-03,  ...,  1.4435e-02,
          6.5994e-04,  3.0701e-02],
        [ 4.3030e-03, -8.4758e-05,  6.2180e-03,  ...,  9.7809e-03,
         -1.6006e-02, -7.2784e-03]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.0439, -5.1875, -0.3367,  ...,  0.4316,  0.5312, -2.7324]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 07:08:44 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country with hanoi as its capital is known as vietnam
The country with abuja as its capital is known as nigeria
The country with moscow as its capital is known as russia
The country with belgrade as its capital is known as serbia
The country with brussels as its capital is known as belgium
The country with santiago as its capital is known as chile
The country with tbilisi as its capital is known as georgia
The country with vienna as its capital is known as
2024-08-01 07:08:44 root INFO     [order_1_approx] starting weight calculation for The country with tbilisi as its capital is known as georgia
The country with santiago as its capital is known as chile
The country with moscow as its capital is known as russia
The country with brussels as its capital is known as belgium
The country with belgrade as its capital is known as serbia
The country with vienna as its capital is known as austria
The country with hanoi as its capital is known as vietnam
The country with abuja as its capital is known as
2024-08-01 07:08:44 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-08-01 07:11:47 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0310,  0.0463, -0.0610,  ...,  0.1818,  0.0298,  0.0076],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.1035, -4.1680, -1.0898,  ..., -1.3496, -0.6431, -2.1074],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0423, -0.0255,  0.0072,  ...,  0.0541, -0.0082,  0.0114],
        [ 0.0388,  0.0340,  0.0343,  ..., -0.0130, -0.0349,  0.0066],
        [-0.0212,  0.0097,  0.0356,  ..., -0.0477, -0.0039, -0.0139],
        ...,
        [ 0.0472, -0.0065,  0.0425,  ...,  0.0476, -0.0197,  0.0063],
        [-0.0230,  0.0310, -0.0386,  ...,  0.0024,  0.0237, -0.0495],
        [ 0.0473, -0.0415, -0.0030,  ...,  0.0009, -0.0045,  0.0156]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.0508, -4.3359, -1.2236,  ..., -1.7539, -0.6543, -2.1367]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 07:11:48 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country with tbilisi as its capital is known as georgia
The country with santiago as its capital is known as chile
The country with moscow as its capital is known as russia
The country with brussels as its capital is known as belgium
The country with belgrade as its capital is known as serbia
The country with vienna as its capital is known as austria
The country with hanoi as its capital is known as vietnam
The country with abuja as its capital is known as
2024-08-01 07:11:48 root INFO     total operator prediction time: 1481.7445590496063 seconds
2024-08-01 07:11:48 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on things - color
2024-08-01 07:11:48 root INFO     building operator things - color
2024-08-01 07:11:48 root INFO     [order_1_approx] starting weight calculation for The tea is colored black
The fridge is colored white
The cabbage is colored green
The rose is colored red
The snow is colored white
The blackboard is colored black
The salt is colored white
The sugar is colored
2024-08-01 07:11:48 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-08-01 07:14:50 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0933,  0.0662, -0.0938,  ...,  0.0782, -0.0451, -0.1163],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.5859, -5.4023,  1.1396,  ..., -2.3086, -1.0684, -1.2441],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0179, -0.0074, -0.0055,  ..., -0.0090,  0.0198,  0.0108],
        [-0.0067,  0.0431, -0.0333,  ..., -0.0378,  0.0130,  0.0112],
        [ 0.0237,  0.0207,  0.0246,  ..., -0.0223, -0.0029, -0.0174],
        ...,
        [-0.0061, -0.0356, -0.0053,  ...,  0.0181,  0.0086, -0.0020],
        [ 0.0043, -0.0081, -0.0403,  ...,  0.0045, -0.0229,  0.0036],
        [-0.0002, -0.0363,  0.0240,  ...,  0.0533, -0.0108, -0.0146]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.5967, -5.0664,  0.9839,  ..., -2.4336, -0.6797, -1.6035]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 07:14:51 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The tea is colored black
The fridge is colored white
The cabbage is colored green
The rose is colored red
The snow is colored white
The blackboard is colored black
The salt is colored white
The sugar is colored
2024-08-01 07:14:52 root INFO     [order_1_approx] starting weight calculation for The tea is colored black
The snow is colored white
The sugar is colored white
The blackboard is colored black
The fridge is colored white
The rose is colored red
The salt is colored white
The cabbage is colored
2024-08-01 07:14:52 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-08-01 07:17:57 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0042,  0.1153, -0.2489,  ..., -0.0404, -0.0079, -0.0156],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.3296, -5.5039, -1.2852,  ..., -0.3916,  0.3350, -2.2871],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0050, -0.0013,  0.0225,  ..., -0.0406,  0.0141,  0.0085],
        [-0.0207,  0.0259, -0.0273,  ..., -0.0003,  0.0297,  0.0230],
        [ 0.0081, -0.0005, -0.0018,  ..., -0.0069,  0.0141, -0.0020],
        ...,
        [-0.0023, -0.0153, -0.0490,  ...,  0.0717,  0.0233, -0.0021],
        [-0.0014, -0.0121, -0.0046,  ..., -0.0119, -0.0007,  0.0132],
        [ 0.0019, -0.0021, -0.0076,  ...,  0.0262, -0.0084, -0.0039]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.3201, -5.2422, -1.3887,  ..., -0.4214, -0.0571, -1.9180]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 07:17:58 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The tea is colored black
The snow is colored white
The sugar is colored white
The blackboard is colored black
The fridge is colored white
The rose is colored red
The salt is colored white
The cabbage is colored
2024-08-01 07:17:58 root INFO     [order_1_approx] starting weight calculation for The salt is colored white
The tea is colored black
The cabbage is colored green
The fridge is colored white
The snow is colored white
The sugar is colored white
The blackboard is colored black
The rose is colored
2024-08-01 07:17:59 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-08-01 07:21:00 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0209, -0.0439, -0.2074,  ..., -0.0643, -0.0150, -0.2136],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-2.9277, -6.9844,  0.8862,  ..., -2.5508,  0.7295, -0.1865],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0132,  0.0036,  0.0138,  ..., -0.0008,  0.0013,  0.0202],
        [ 0.0216,  0.0049,  0.0275,  ..., -0.0039, -0.0115, -0.0187],
        [ 0.0279,  0.0044, -0.0138,  ..., -0.0280,  0.0157,  0.0012],
        ...,
        [ 0.0243, -0.0107,  0.0022,  ...,  0.0114, -0.0108, -0.0116],
        [-0.0082,  0.0059, -0.0226,  ..., -0.0235, -0.0030, -0.0107],
        [-0.0261, -0.0013,  0.0095,  ...,  0.0070, -0.0187, -0.0102]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-2.5273, -7.0664,  0.7222,  ..., -2.3613,  1.0400, -0.4368]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 07:21:01 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The salt is colored white
The tea is colored black
The cabbage is colored green
The fridge is colored white
The snow is colored white
The sugar is colored white
The blackboard is colored black
The rose is colored
2024-08-01 07:21:02 root INFO     [order_1_approx] starting weight calculation for The fridge is colored white
The snow is colored white
The sugar is colored white
The tea is colored black
The rose is colored red
The salt is colored white
The cabbage is colored green
The blackboard is colored
2024-08-01 07:21:02 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-08-01 07:24:06 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1455, -0.1252, -0.0927,  ..., -0.0290,  0.0749, -0.0710],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.0703, -4.2930,  2.7891,  ...,  0.0386, -0.9111, -2.7461],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 1.6052e-02, -1.6479e-03, -8.1940e-03,  ..., -5.4436e-03,
          1.5884e-02, -1.0437e-02],
        [ 9.7046e-03,  2.6596e-02, -3.0319e-02,  ..., -2.7802e-02,
         -6.4774e-03,  4.0192e-02],
        [-8.0719e-03,  1.4816e-02, -8.5373e-03,  ..., -2.2736e-02,
         -2.6245e-02, -3.6106e-03],
        ...,
        [ 1.3824e-02, -4.2358e-02, -3.3722e-02,  ...,  9.6741e-03,
         -2.3590e-02,  2.4887e-02],
        [-3.8147e-05, -1.6876e-02,  2.3376e-02,  ...,  2.4933e-02,
          3.2776e-02, -1.8234e-02],
        [-5.2032e-03, -2.9633e-02, -1.9501e-02,  ...,  1.4694e-02,
         -3.6804e-02,  1.4816e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.0918, -4.1914,  2.7695,  ...,  0.4568, -0.8438, -2.6602]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 07:24:07 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The fridge is colored white
The snow is colored white
The sugar is colored white
The tea is colored black
The rose is colored red
The salt is colored white
The cabbage is colored green
The blackboard is colored
2024-08-01 07:24:07 root INFO     [order_1_approx] starting weight calculation for The rose is colored red
The tea is colored black
The salt is colored white
The snow is colored white
The cabbage is colored green
The sugar is colored white
The blackboard is colored black
The fridge is colored
2024-08-01 07:24:07 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-08-01 07:27:09 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1312,  0.0212, -0.0344,  ..., -0.0122, -0.1331, -0.0867],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.3918, -8.2031,  0.3684,  ...,  0.7969, -3.1250, -1.8828],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0114, -0.0075,  0.0077,  ..., -0.0053, -0.0078,  0.0042],
        [ 0.0146,  0.0364, -0.0338,  ...,  0.0313,  0.0062,  0.0124],
        [ 0.0001, -0.0061,  0.0335,  ..., -0.0116, -0.0086,  0.0113],
        ...,
        [-0.0022, -0.0148, -0.0402,  ...,  0.0243,  0.0137, -0.0166],
        [ 0.0103, -0.0070, -0.0125,  ..., -0.0015, -0.0113, -0.0141],
        [ 0.0100,  0.0092, -0.0154,  ...,  0.0014,  0.0138,  0.0040]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.3284, -8.1797,  0.4351,  ...,  0.6650, -2.7363, -2.1309]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 07:27:10 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The rose is colored red
The tea is colored black
The salt is colored white
The snow is colored white
The cabbage is colored green
The sugar is colored white
The blackboard is colored black
The fridge is colored
2024-08-01 07:27:10 root INFO     [order_1_approx] starting weight calculation for The cabbage is colored green
The blackboard is colored black
The sugar is colored white
The snow is colored white
The rose is colored red
The fridge is colored white
The tea is colored black
The salt is colored
2024-08-01 07:27:10 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-08-01 07:30:18 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0584,  0.1392, -0.1301,  ..., -0.0925, -0.2163, -0.0535],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.1143, -3.4922, -0.8760,  ..., -5.0000, -0.7012, -3.0508],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0123, -0.0124,  0.0023,  ..., -0.0210,  0.0041,  0.0152],
        [-0.0129,  0.0030, -0.0402,  ..., -0.0522, -0.0055,  0.0259],
        [ 0.0035,  0.0373, -0.0022,  ..., -0.0053, -0.0002, -0.0103],
        ...,
        [-0.0278, -0.0466, -0.0215,  ..., -0.0354,  0.0245,  0.0090],
        [ 0.0244, -0.0130, -0.0300,  ...,  0.0270, -0.0027, -0.0044],
        [-0.0336, -0.0151,  0.0065,  ..., -0.0159,  0.0170, -0.0069]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.0166, -3.6523, -1.0527,  ..., -4.9297, -0.5098, -3.1484]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 07:30:18 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The cabbage is colored green
The blackboard is colored black
The sugar is colored white
The snow is colored white
The rose is colored red
The fridge is colored white
The tea is colored black
The salt is colored
2024-08-01 07:30:19 root INFO     [order_1_approx] starting weight calculation for The salt is colored white
The rose is colored red
The sugar is colored white
The cabbage is colored green
The snow is colored white
The fridge is colored white
The blackboard is colored black
The tea is colored
2024-08-01 07:30:19 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-08-01 07:33:26 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0999, -0.0330, -0.0992,  ..., -0.0779,  0.0327, -0.0691],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.5078, -2.3633, -1.5176,  ..., -3.9512, -0.6626, -0.3086],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0073,  0.0036, -0.0112,  ..., -0.0265, -0.0076,  0.0165],
        [ 0.0050,  0.0260, -0.0140,  ..., -0.0257, -0.0052,  0.0191],
        [ 0.0181,  0.0148,  0.0021,  ...,  0.0199,  0.0003, -0.0204],
        ...,
        [-0.0069, -0.0285,  0.0145,  ...,  0.0629, -0.0104, -0.0230],
        [ 0.0047, -0.0111, -0.0161,  ...,  0.0073, -0.0333,  0.0001],
        [ 0.0197, -0.0088,  0.0234,  ...,  0.0246, -0.0026, -0.0046]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.0117, -2.6504, -1.6582,  ..., -3.9492, -0.1240, -0.8970]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 07:33:27 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The salt is colored white
The rose is colored red
The sugar is colored white
The cabbage is colored green
The snow is colored white
The fridge is colored white
The blackboard is colored black
The tea is colored
2024-08-01 07:33:27 root INFO     [order_1_approx] starting weight calculation for The salt is colored white
The fridge is colored white
The tea is colored black
The sugar is colored white
The rose is colored red
The blackboard is colored black
The cabbage is colored green
The snow is colored
2024-08-01 07:33:27 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-08-01 07:36:33 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1785,  0.1990, -0.1575,  ..., -0.0684, -0.0428, -0.1296],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.7949, -4.9922, -0.3257,  ..., -4.7891, -1.2178, -3.6816],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0225, -0.0219,  0.0010,  ...,  0.0028, -0.0111, -0.0135],
        [ 0.0265,  0.0224, -0.0359,  ..., -0.0157,  0.0204,  0.0219],
        [-0.0060, -0.0191, -0.0199,  ..., -0.0155,  0.0236,  0.0282],
        ...,
        [-0.0022, -0.0094,  0.0024,  ...,  0.0297,  0.0191, -0.0286],
        [ 0.0020, -0.0170, -0.0173,  ...,  0.0091,  0.0087,  0.0189],
        [-0.0128, -0.0114,  0.0386,  ...,  0.0219,  0.0177, -0.0267]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.3594, -5.1992, -0.2380,  ..., -4.7617, -1.0742, -3.5312]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 07:36:34 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The salt is colored white
The fridge is colored white
The tea is colored black
The sugar is colored white
The rose is colored red
The blackboard is colored black
The cabbage is colored green
The snow is colored
2024-08-01 07:36:34 root INFO     total operator prediction time: 1485.850994348526 seconds
2024-08-01 07:36:34 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on animal - sound
2024-08-01 07:36:34 root INFO     building operator animal - sound
2024-08-01 07:36:34 root INFO     [order_1_approx] starting weight calculation for The sound that a dog makes is called a bark
The sound that a cicada makes is called a buzz
The sound that a deer makes is called a bellow
The sound that a mule makes is called a bray
The sound that a goat makes is called a bleat
The sound that a wasp makes is called a buzz
The sound that a monkey makes is called a chatter
The sound that a duck makes is called a
2024-08-01 07:36:34 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-08-01 07:39:40 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0982, -0.0726, -0.0216,  ..., -0.1174, -0.0143, -0.0478],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.2983, -4.9023,  3.3164,  ...,  0.6387, -3.8750,  2.6094],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0261, -0.0042,  0.0062,  ...,  0.0046, -0.0047, -0.0128],
        [-0.0427,  0.0037, -0.0186,  ...,  0.0092,  0.0288,  0.0029],
        [-0.0119, -0.0100,  0.0260,  ..., -0.0162, -0.0197, -0.0039],
        ...,
        [-0.0304,  0.0185, -0.0332,  ...,  0.0345, -0.0102, -0.0001],
        [-0.0298, -0.0023, -0.0315,  ...,  0.0087,  0.0327, -0.0027],
        [ 0.0014, -0.0197,  0.0054,  ..., -0.0552,  0.0073, -0.0111]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.2256, -5.0312,  3.3203,  ...,  0.4453, -3.9785,  2.7852]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 07:39:41 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The sound that a dog makes is called a bark
The sound that a cicada makes is called a buzz
The sound that a deer makes is called a bellow
The sound that a mule makes is called a bray
The sound that a goat makes is called a bleat
The sound that a wasp makes is called a buzz
The sound that a monkey makes is called a chatter
The sound that a duck makes is called a
2024-08-01 07:39:41 root INFO     [order_1_approx] starting weight calculation for The sound that a dog makes is called a bark
The sound that a mule makes is called a bray
The sound that a deer makes is called a bellow
The sound that a wasp makes is called a buzz
The sound that a duck makes is called a quack
The sound that a goat makes is called a bleat
The sound that a cicada makes is called a buzz
The sound that a monkey makes is called a
2024-08-01 07:39:41 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-08-01 07:42:46 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0795, -0.0865, -0.0642,  ..., -0.0047, -0.2321, -0.0377],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.0469, -3.3164,  1.6299,  ..., -1.2119, -1.7471,  0.5156],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0540, -0.0178, -0.0140,  ..., -0.0380, -0.0197,  0.0024],
        [-0.0362,  0.0295,  0.0032,  ...,  0.0086, -0.0091,  0.0017],
        [-0.0364,  0.0423, -0.0023,  ..., -0.0226, -0.0031, -0.0184],
        ...,
        [ 0.0117,  0.0070, -0.0546,  ...,  0.0179, -0.0028, -0.0017],
        [ 0.0252, -0.0154,  0.0520,  ...,  0.0093, -0.0038,  0.0396],
        [ 0.0127, -0.0093, -0.0142,  ..., -0.0456,  0.0088,  0.0163]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.8379, -3.4570,  1.4727,  ..., -0.9697, -1.8027,  0.3896]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 07:42:47 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The sound that a dog makes is called a bark
The sound that a mule makes is called a bray
The sound that a deer makes is called a bellow
The sound that a wasp makes is called a buzz
The sound that a duck makes is called a quack
The sound that a goat makes is called a bleat
The sound that a cicada makes is called a buzz
The sound that a monkey makes is called a
2024-08-01 07:42:47 root INFO     [order_1_approx] starting weight calculation for The sound that a wasp makes is called a buzz
The sound that a mule makes is called a bray
The sound that a dog makes is called a bark
The sound that a duck makes is called a quack
The sound that a deer makes is called a bellow
The sound that a cicada makes is called a buzz
The sound that a monkey makes is called a chatter
The sound that a goat makes is called a
2024-08-01 07:42:47 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-08-01 07:45:51 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0427, -0.1241, -0.0348,  ..., -0.0341,  0.0738,  0.0158],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.1504, -3.6641,  2.9258,  ..., -0.9023, -0.8379,  0.2773],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0126,  0.0044, -0.0172,  ...,  0.0142,  0.0040,  0.0279],
        [-0.0533,  0.0412, -0.0311,  ...,  0.0227,  0.0095,  0.0321],
        [-0.0096,  0.0314,  0.0274,  ..., -0.0438, -0.0105, -0.0233],
        ...,
        [-0.0211,  0.0747, -0.0317,  ..., -0.0121, -0.0050, -0.0150],
        [ 0.0040,  0.0196, -0.0440,  ...,  0.0080,  0.0484,  0.0072],
        [ 0.0253, -0.0265,  0.0070,  ..., -0.0396,  0.0222, -0.0021]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.8711, -3.8867,  2.7969,  ..., -2.0293, -0.8091,  0.4431]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 07:45:52 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The sound that a wasp makes is called a buzz
The sound that a mule makes is called a bray
The sound that a dog makes is called a bark
The sound that a duck makes is called a quack
The sound that a deer makes is called a bellow
The sound that a cicada makes is called a buzz
The sound that a monkey makes is called a chatter
The sound that a goat makes is called a
2024-08-01 07:45:52 root INFO     [order_1_approx] starting weight calculation for The sound that a wasp makes is called a buzz
The sound that a dog makes is called a bark
The sound that a monkey makes is called a chatter
The sound that a goat makes is called a bleat
The sound that a duck makes is called a quack
The sound that a cicada makes is called a buzz
The sound that a deer makes is called a bellow
The sound that a mule makes is called a
2024-08-01 07:45:52 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-08-01 07:48:58 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2030, -0.0648,  0.0392,  ...,  0.0367,  0.0389,  0.1053],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.1768, -3.7598,  2.1387,  ..., -0.7236, -0.8911,  2.2246],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0607, -0.0204,  0.0275,  ...,  0.0345, -0.0379, -0.0230],
        [-0.0034,  0.0468, -0.0302,  ..., -0.0195, -0.0115,  0.0609],
        [-0.0117,  0.0352,  0.0554,  ..., -0.0226, -0.0838, -0.0652],
        ...,
        [ 0.0442, -0.0363, -0.0197,  ...,  0.0198,  0.0105, -0.0061],
        [ 0.0056,  0.0631, -0.0031,  ..., -0.0430,  0.0150, -0.0156],
        [ 0.0300, -0.0518,  0.0274,  ...,  0.0347, -0.0834, -0.0404]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.1865, -3.8340,  1.7764,  ..., -0.8706, -1.1553,  1.5684]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 07:48:58 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The sound that a wasp makes is called a buzz
The sound that a dog makes is called a bark
The sound that a monkey makes is called a chatter
The sound that a goat makes is called a bleat
The sound that a duck makes is called a quack
The sound that a cicada makes is called a buzz
The sound that a deer makes is called a bellow
The sound that a mule makes is called a
2024-08-01 07:48:59 root INFO     [order_1_approx] starting weight calculation for The sound that a monkey makes is called a chatter
The sound that a mule makes is called a bray
The sound that a dog makes is called a bark
The sound that a cicada makes is called a buzz
The sound that a goat makes is called a bleat
The sound that a duck makes is called a quack
The sound that a wasp makes is called a buzz
The sound that a deer makes is called a
2024-08-01 07:48:59 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-08-01 07:52:05 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0520,  0.0745, -0.0145,  ..., -0.0660, -0.0193,  0.0563],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.5068, -0.9248, -0.1309,  ...,  0.2930, -1.3164,  0.1436],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0066, -0.0375, -0.0011,  ..., -0.0099, -0.0057,  0.0053],
        [-0.0358, -0.0122, -0.0391,  ...,  0.0405,  0.0167,  0.0185],
        [-0.0370,  0.0308,  0.0718,  ..., -0.0163, -0.0168, -0.0084],
        ...,
        [-0.0109,  0.0442,  0.0123,  ...,  0.0519,  0.0170, -0.0351],
        [-0.0164,  0.0059, -0.0240,  ..., -0.0258,  0.0518, -0.0115],
        [ 0.0187,  0.0052,  0.0201,  ..., -0.0210, -0.0053,  0.0236]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.6748, -1.1934, -0.7529,  ...,  0.7490, -1.4785, -0.2571]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 07:52:06 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The sound that a monkey makes is called a chatter
The sound that a mule makes is called a bray
The sound that a dog makes is called a bark
The sound that a cicada makes is called a buzz
The sound that a goat makes is called a bleat
The sound that a duck makes is called a quack
The sound that a wasp makes is called a buzz
The sound that a deer makes is called a
2024-08-01 07:52:06 root INFO     [order_1_approx] starting weight calculation for The sound that a duck makes is called a quack
The sound that a monkey makes is called a chatter
The sound that a deer makes is called a bellow
The sound that a mule makes is called a bray
The sound that a wasp makes is called a buzz
The sound that a cicada makes is called a buzz
The sound that a goat makes is called a bleat
The sound that a dog makes is called a
2024-08-01 07:52:06 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-08-01 07:55:11 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0716, -0.0299, -0.0214,  ...,  0.0521, -0.1014, -0.0432],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.3643, -5.6992,  1.4688,  ..., -2.7676, -0.5454,  3.7559],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0002, -0.0071,  0.0259,  ..., -0.0143,  0.0146,  0.0093],
        [ 0.0182, -0.0187, -0.0300,  ...,  0.0111, -0.0066, -0.0019],
        [-0.0188,  0.0226,  0.0178,  ..., -0.0093,  0.0113,  0.0065],
        ...,
        [ 0.0271, -0.0027, -0.0223,  ...,  0.0368, -0.0045, -0.0144],
        [-0.0137, -0.0265, -0.0136,  ...,  0.0040, -0.0034,  0.0154],
        [ 0.0069, -0.0197,  0.0073,  ..., -0.0204,  0.0019, -0.0048]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.0244, -6.1406,  1.5762,  ..., -2.7734, -0.5522,  3.7344]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 07:55:12 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The sound that a duck makes is called a quack
The sound that a monkey makes is called a chatter
The sound that a deer makes is called a bellow
The sound that a mule makes is called a bray
The sound that a wasp makes is called a buzz
The sound that a cicada makes is called a buzz
The sound that a goat makes is called a bleat
The sound that a dog makes is called a
2024-08-01 07:55:13 root INFO     [order_1_approx] starting weight calculation for The sound that a duck makes is called a quack
The sound that a deer makes is called a bellow
The sound that a wasp makes is called a buzz
The sound that a monkey makes is called a chatter
The sound that a dog makes is called a bark
The sound that a mule makes is called a bray
The sound that a goat makes is called a bleat
The sound that a cicada makes is called a
2024-08-01 07:55:13 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-08-01 07:58:15 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0287, -0.0089, -0.1301,  ..., -0.2607, -0.0658, -0.0220],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.8599, -1.9492,  3.9863,  ..., -0.8647, -2.0820,  1.3672],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0011, -0.0077,  0.0060,  ..., -0.0356, -0.0518, -0.0146],
        [ 0.0067, -0.0023, -0.0221,  ...,  0.0002,  0.0422,  0.0300],
        [ 0.0289,  0.0187, -0.0055,  ...,  0.0167, -0.0128,  0.0237],
        ...,
        [ 0.0322,  0.0198,  0.0162,  ...,  0.0147,  0.0259,  0.0360],
        [-0.0424,  0.0157, -0.0220,  ...,  0.0169,  0.0308,  0.0031],
        [ 0.0335,  0.0308, -0.0083,  ..., -0.0182, -0.0122, -0.0006]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.8320, -2.2617,  3.8750,  ..., -1.1670, -2.0977,  1.3828]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 07:58:16 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The sound that a duck makes is called a quack
The sound that a deer makes is called a bellow
The sound that a wasp makes is called a buzz
The sound that a monkey makes is called a chatter
The sound that a dog makes is called a bark
The sound that a mule makes is called a bray
The sound that a goat makes is called a bleat
The sound that a cicada makes is called a
2024-08-01 07:58:16 root INFO     [order_1_approx] starting weight calculation for The sound that a cicada makes is called a buzz
The sound that a duck makes is called a quack
The sound that a monkey makes is called a chatter
The sound that a deer makes is called a bellow
The sound that a goat makes is called a bleat
The sound that a dog makes is called a bark
The sound that a mule makes is called a bray
The sound that a wasp makes is called a
2024-08-01 07:58:16 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-08-01 08:01:17 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1219, -0.2231,  0.0831,  ..., -0.0493, -0.0466, -0.0506],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.0547, -2.4688,  2.9336,  ..., -0.4375, -0.7061,  2.4746],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0182,  0.0116,  0.0274,  ...,  0.0172, -0.0163, -0.0101],
        [-0.0180, -0.0066, -0.0240,  ...,  0.0030, -0.0155,  0.0036],
        [-0.0019,  0.0013,  0.0070,  ..., -0.0098, -0.0304,  0.0248],
        ...,
        [-0.0200,  0.0266,  0.0248,  ...,  0.0135, -0.0173, -0.0301],
        [ 0.0018,  0.0173,  0.0210,  ...,  0.0238,  0.0347,  0.0164],
        [-0.0098, -0.0167, -0.0027,  ..., -0.0123,  0.0152,  0.0107]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.9043, -2.7852,  2.5781,  ..., -0.7422, -0.5869,  2.8809]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 08:01:18 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The sound that a cicada makes is called a buzz
The sound that a duck makes is called a quack
The sound that a monkey makes is called a chatter
The sound that a deer makes is called a bellow
The sound that a goat makes is called a bleat
The sound that a dog makes is called a bark
The sound that a mule makes is called a bray
The sound that a wasp makes is called a
2024-08-01 08:01:18 root INFO     total operator prediction time: 1484.3566915988922 seconds
2024-08-01 08:01:18 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on animal - youth
2024-08-01 08:01:18 root INFO     building operator animal - youth
2024-08-01 08:01:18 root INFO     [order_1_approx] starting weight calculation for The offspring of a insect is referred to as a larva
The offspring of a deer is referred to as a fawn
The offspring of a panda is referred to as a cub
The offspring of a monkey is referred to as a infant
The offspring of a shark is referred to as a cub
The offspring of a tiger is referred to as a cub
The offspring of a fish is referred to as a fingerling
The offspring of a raccoon is referred to as a
2024-08-01 08:01:19 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-08-01 08:04:25 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1792, -0.0099, -0.0252,  ...,  0.0279, -0.0742, -0.0067],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.0156, -2.8633, -0.8926,  ..., -0.7383, -2.6777,  1.6455],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 1.0977e-03, -3.9291e-03,  1.2306e-02,  ...,  6.6643e-03,
         -6.7101e-03, -1.6174e-03],
        [ 2.6588e-03, -2.1572e-03,  1.4282e-02,  ...,  1.2177e-02,
         -1.4168e-02, -2.9411e-03],
        [ 4.4708e-03,  5.0087e-03,  1.3611e-02,  ..., -6.7635e-03,
         -7.8506e-03,  5.3596e-03],
        ...,
        [ 7.6027e-03,  3.3131e-03,  4.0054e-05,  ...,  2.8152e-03,
          8.8730e-03,  5.7983e-03],
        [-8.2397e-03,  4.8637e-03,  7.2327e-03,  ...,  9.4604e-03,
          9.2506e-04,  1.0727e-02],
        [ 3.8643e-03, -6.7062e-03, -1.9665e-03,  ..., -1.1169e-02,
         -1.2207e-02, -1.3855e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.7832, -2.7539, -1.0410,  ..., -0.6758, -2.5371,  1.7305]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 08:04:26 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The offspring of a insect is referred to as a larva
The offspring of a deer is referred to as a fawn
The offspring of a panda is referred to as a cub
The offspring of a monkey is referred to as a infant
The offspring of a shark is referred to as a cub
The offspring of a tiger is referred to as a cub
The offspring of a fish is referred to as a fingerling
The offspring of a raccoon is referred to as a
2024-08-01 08:04:26 root INFO     [order_1_approx] starting weight calculation for The offspring of a deer is referred to as a fawn
The offspring of a raccoon is referred to as a kit
The offspring of a panda is referred to as a cub
The offspring of a monkey is referred to as a infant
The offspring of a shark is referred to as a cub
The offspring of a fish is referred to as a fingerling
The offspring of a insect is referred to as a larva
The offspring of a tiger is referred to as a
2024-08-01 08:04:26 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-08-01 08:07:31 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1001,  0.1682, -0.1473,  ...,  0.0425, -0.1633, -0.0911],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.7266, -5.6797, -1.8193,  ...,  0.0801, -2.4316,  0.8486],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 3.9764e-02, -2.8477e-03,  1.1673e-02,  ...,  2.7420e-02,
         -7.2479e-05, -4.2450e-02],
        [-8.9741e-04,  1.2489e-02, -1.6632e-02,  ...,  2.1088e-02,
         -2.5497e-02,  2.8183e-02],
        [ 1.5442e-02, -2.3895e-02,  3.7170e-02,  ..., -7.5073e-03,
          1.2596e-02,  1.2848e-02],
        ...,
        [ 2.8976e-02,  3.1403e-02,  1.6647e-02,  ...,  1.7151e-02,
          8.1787e-03, -2.9846e-02],
        [ 8.4991e-03, -4.5044e-02, -2.3834e-02,  ..., -1.7738e-03,
         -1.8158e-02,  3.7292e-02],
        [-1.0834e-02,  1.3649e-02,  5.2612e-02,  ..., -1.2650e-02,
          1.2459e-02, -2.2247e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.4785, -5.1758, -1.7188,  ...,  0.2091, -2.7266,  0.7148]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 08:07:32 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The offspring of a deer is referred to as a fawn
The offspring of a raccoon is referred to as a kit
The offspring of a panda is referred to as a cub
The offspring of a monkey is referred to as a infant
The offspring of a shark is referred to as a cub
The offspring of a fish is referred to as a fingerling
The offspring of a insect is referred to as a larva
The offspring of a tiger is referred to as a
2024-08-01 08:07:32 root INFO     [order_1_approx] starting weight calculation for The offspring of a raccoon is referred to as a kit
The offspring of a shark is referred to as a cub
The offspring of a tiger is referred to as a cub
The offspring of a panda is referred to as a cub
The offspring of a insect is referred to as a larva
The offspring of a deer is referred to as a fawn
The offspring of a fish is referred to as a fingerling
The offspring of a monkey is referred to as a
2024-08-01 08:07:32 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-08-01 08:10:36 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1208, -0.1465, -0.0713,  ..., -0.0234, -0.2693, -0.0876],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.0078, -3.3672, -1.0361,  ..., -0.6250, -4.2148,  2.7461],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0703, -0.0067,  0.0119,  ...,  0.0060, -0.0114, -0.0174],
        [-0.0180,  0.0188,  0.0056,  ...,  0.0085, -0.0085,  0.0042],
        [-0.0243,  0.0191,  0.0213,  ..., -0.0233, -0.0014, -0.0132],
        ...,
        [ 0.0114,  0.0176, -0.0206,  ...,  0.0239, -0.0183, -0.0365],
        [-0.0054, -0.0224,  0.0239,  ...,  0.0115,  0.0354,  0.0540],
        [ 0.0092, -0.0135,  0.0185,  ..., -0.0099, -0.0238, -0.0138]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.0762, -2.9805, -1.0400,  ..., -0.5830, -4.0195,  2.7305]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 08:10:37 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The offspring of a raccoon is referred to as a kit
The offspring of a shark is referred to as a cub
The offspring of a tiger is referred to as a cub
The offspring of a panda is referred to as a cub
The offspring of a insect is referred to as a larva
The offspring of a deer is referred to as a fawn
The offspring of a fish is referred to as a fingerling
The offspring of a monkey is referred to as a
2024-08-01 08:10:37 root INFO     [order_1_approx] starting weight calculation for The offspring of a panda is referred to as a cub
The offspring of a raccoon is referred to as a kit
The offspring of a deer is referred to as a fawn
The offspring of a insect is referred to as a larva
The offspring of a monkey is referred to as a infant
The offspring of a tiger is referred to as a cub
The offspring of a shark is referred to as a cub
The offspring of a fish is referred to as a
2024-08-01 08:10:37 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-08-01 08:13:42 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0151,  0.0567, -0.0630,  ..., -0.0491, -0.1239,  0.0347],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.8760, -3.1875, -3.1992,  ..., -1.1670, -5.5898,  0.5527],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0115, -0.0056,  0.0104,  ...,  0.0089, -0.0169, -0.0134],
        [-0.0107,  0.0194, -0.0065,  ...,  0.0157,  0.0092,  0.0060],
        [ 0.0054,  0.0242,  0.0131,  ...,  0.0038, -0.0079, -0.0123],
        ...,
        [-0.0093, -0.0119,  0.0065,  ...,  0.0036,  0.0089, -0.0018],
        [ 0.0258, -0.0173,  0.0091,  ..., -0.0139, -0.0019,  0.0017],
        [ 0.0181, -0.0096,  0.0068,  ..., -0.0081, -0.0164, -0.0115]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.6416, -3.2285, -3.3789,  ..., -0.9209, -5.4531,  0.3599]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 08:13:43 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The offspring of a panda is referred to as a cub
The offspring of a raccoon is referred to as a kit
The offspring of a deer is referred to as a fawn
The offspring of a insect is referred to as a larva
The offspring of a monkey is referred to as a infant
The offspring of a tiger is referred to as a cub
The offspring of a shark is referred to as a cub
The offspring of a fish is referred to as a
2024-08-01 08:13:43 root INFO     [order_1_approx] starting weight calculation for The offspring of a insect is referred to as a larva
The offspring of a monkey is referred to as a infant
The offspring of a tiger is referred to as a cub
The offspring of a raccoon is referred to as a kit
The offspring of a fish is referred to as a fingerling
The offspring of a shark is referred to as a cub
The offspring of a panda is referred to as a cub
The offspring of a deer is referred to as a
2024-08-01 08:13:43 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-08-01 08:16:46 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0591,  0.0213, -0.0366,  ..., -0.0652, -0.0403,  0.0061],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.4629e+00, -3.3223e+00, -2.7070e+00,  ..., -3.9062e-03,
        -5.2266e+00, -8.3301e-01], device='cuda:1', dtype=torch.float16,
       grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0356, -0.0278,  0.0241,  ...,  0.0104, -0.0191, -0.0094],
        [ 0.0021,  0.0219,  0.0051,  ..., -0.0013, -0.0107,  0.0067],
        [-0.0036,  0.0107,  0.0063,  ...,  0.0110,  0.0042, -0.0052],
        ...,
        [ 0.0125,  0.0172,  0.0108,  ...,  0.0255,  0.0025,  0.0092],
        [-0.0093, -0.0023, -0.0190,  ..., -0.0051,  0.0215,  0.0104],
        [ 0.0318, -0.0094,  0.0082,  ..., -0.0023, -0.0104,  0.0111]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.6621, -3.3184, -2.6719,  ...,  0.1367, -5.1680, -1.1855]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 08:16:46 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The offspring of a insect is referred to as a larva
The offspring of a monkey is referred to as a infant
The offspring of a tiger is referred to as a cub
The offspring of a raccoon is referred to as a kit
The offspring of a fish is referred to as a fingerling
The offspring of a shark is referred to as a cub
The offspring of a panda is referred to as a cub
The offspring of a deer is referred to as a
2024-08-01 08:16:47 root INFO     [order_1_approx] starting weight calculation for The offspring of a fish is referred to as a fingerling
The offspring of a raccoon is referred to as a kit
The offspring of a insect is referred to as a larva
The offspring of a panda is referred to as a cub
The offspring of a tiger is referred to as a cub
The offspring of a monkey is referred to as a infant
The offspring of a deer is referred to as a fawn
The offspring of a shark is referred to as a
2024-08-01 08:16:47 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-08-01 08:19:54 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0181,  0.1223, -0.1621,  ...,  0.0618, -0.1570, -0.0838],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.2198, -2.8008, -2.8633,  ..., -1.3730, -3.6914,  1.0303],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0066,  0.0116,  0.0019,  ...,  0.0065,  0.0038, -0.0150],
        [ 0.0101,  0.0172, -0.0104,  ...,  0.0013, -0.0118,  0.0173],
        [ 0.0224, -0.0057,  0.0077,  ...,  0.0136,  0.0070, -0.0178],
        ...,
        [-0.0126,  0.0425,  0.0012,  ...,  0.0056, -0.0206,  0.0053],
        [-0.0063, -0.0047,  0.0005,  ...,  0.0311,  0.0254,  0.0118],
        [-0.0018, -0.0060,  0.0224,  ...,  0.0054,  0.0177, -0.0022]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.3955, -2.7227, -2.7598,  ..., -1.7412, -3.8086,  0.7358]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 08:19:55 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The offspring of a fish is referred to as a fingerling
The offspring of a raccoon is referred to as a kit
The offspring of a insect is referred to as a larva
The offspring of a panda is referred to as a cub
The offspring of a tiger is referred to as a cub
The offspring of a monkey is referred to as a infant
The offspring of a deer is referred to as a fawn
The offspring of a shark is referred to as a
2024-08-01 08:19:55 root INFO     [order_1_approx] starting weight calculation for The offspring of a shark is referred to as a cub
The offspring of a tiger is referred to as a cub
The offspring of a insect is referred to as a larva
The offspring of a monkey is referred to as a infant
The offspring of a fish is referred to as a fingerling
The offspring of a deer is referred to as a fawn
The offspring of a raccoon is referred to as a kit
The offspring of a panda is referred to as a
2024-08-01 08:19:55 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-08-01 08:23:01 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0079, -0.0146, -0.1641,  ..., -0.0774, -0.1556, -0.0010],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.0195, -4.2227, -1.1982,  ..., -0.9346, -2.8008,  2.9922],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0736, -0.0319, -0.0211,  ...,  0.0469, -0.0385,  0.0253],
        [ 0.0010,  0.0321, -0.0092,  ...,  0.0381, -0.0111, -0.0083],
        [-0.0400,  0.0270,  0.0133,  ..., -0.0396,  0.0076, -0.0183],
        ...,
        [ 0.0423, -0.0209,  0.0064,  ...,  0.0471, -0.0383, -0.0103],
        [ 0.0096,  0.0143,  0.0167,  ...,  0.0126,  0.0271,  0.0307],
        [-0.0601, -0.0130,  0.0059,  ..., -0.0342, -0.0088,  0.0004]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.7783, -4.1484, -1.5039,  ..., -1.0420, -2.5977,  2.5156]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 08:23:02 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The offspring of a shark is referred to as a cub
The offspring of a tiger is referred to as a cub
The offspring of a insect is referred to as a larva
The offspring of a monkey is referred to as a infant
The offspring of a fish is referred to as a fingerling
The offspring of a deer is referred to as a fawn
The offspring of a raccoon is referred to as a kit
The offspring of a panda is referred to as a
2024-08-01 08:23:02 root INFO     [order_1_approx] starting weight calculation for The offspring of a fish is referred to as a fingerling
The offspring of a tiger is referred to as a cub
The offspring of a shark is referred to as a cub
The offspring of a raccoon is referred to as a kit
The offspring of a panda is referred to as a cub
The offspring of a deer is referred to as a fawn
The offspring of a monkey is referred to as a infant
The offspring of a insect is referred to as a
2024-08-01 08:23:02 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-08-01 08:26:07 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1053,  0.0158,  0.0120,  ...,  0.0264, -0.0895, -0.1586],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.4355, -3.0898, -0.0774,  ..., -1.3389, -2.9707,  0.7666],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0184,  0.0008, -0.0402,  ..., -0.0112, -0.0270,  0.0074],
        [-0.0577,  0.0257, -0.0231,  ..., -0.0018,  0.0011,  0.0131],
        [-0.0953,  0.0282, -0.0398,  ..., -0.0422,  0.0121,  0.0358],
        ...,
        [ 0.0143, -0.0038,  0.0277,  ...,  0.0187, -0.0085, -0.0174],
        [ 0.0190, -0.0130,  0.0087,  ...,  0.0143,  0.0218,  0.0414],
        [ 0.0171, -0.0117,  0.0027,  ...,  0.0151, -0.0116,  0.0067]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.2422, -3.3906, -0.9990,  ..., -0.9307, -3.0645,  0.8672]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 08:26:08 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The offspring of a fish is referred to as a fingerling
The offspring of a tiger is referred to as a cub
The offspring of a shark is referred to as a cub
The offspring of a raccoon is referred to as a kit
The offspring of a panda is referred to as a cub
The offspring of a deer is referred to as a fawn
The offspring of a monkey is referred to as a infant
The offspring of a insect is referred to as a
2024-08-01 08:26:08 root INFO     total operator prediction time: 1489.573068857193 seconds
2024-08-01 08:26:08 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on UK_city - county
2024-08-01 08:26:08 root INFO     building operator UK_city - county
2024-08-01 08:26:08 root INFO     [order_1_approx] starting weight calculation for In the United Kingdom, the city of chichester is in the county of sussex
In the United Kingdom, the city of stirling is in the county of stirlingshire
In the United Kingdom, the city of preston is in the county of lancashire
In the United Kingdom, the city of oxford is in the county of oxfordshire
In the United Kingdom, the city of canterbury is in the county of kent
In the United Kingdom, the city of sheffield is in the county of yorkshire
In the United Kingdom, the city of swansea is in the county of glamorgan
In the United Kingdom, the city of winchester is in the county of
2024-08-01 08:26:08 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-08-01 08:30:26 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0641, -0.1039, -0.1674,  ...,  0.1310, -0.0014,  0.0294],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.9238, -4.9805,  0.4683,  ..., -4.2695,  0.9380,  0.5386],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0027, -0.0115,  0.0619,  ...,  0.0093, -0.0213,  0.0060],
        [-0.0050,  0.0415,  0.0125,  ...,  0.0215, -0.0331,  0.0146],
        [-0.0449,  0.0359, -0.0717,  ...,  0.0469,  0.0475, -0.0331],
        ...,
        [ 0.0241,  0.0126,  0.0019,  ..., -0.0278, -0.0141, -0.0394],
        [-0.0328, -0.0670,  0.0169,  ...,  0.0676,  0.0166, -0.0123],
        [ 0.0523,  0.0247, -0.0507,  ..., -0.0106,  0.0328, -0.0063]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.0898, -5.0742,  0.2771,  ..., -4.1328,  0.6748,  0.7583]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 08:30:27 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for In the United Kingdom, the city of chichester is in the county of sussex
In the United Kingdom, the city of stirling is in the county of stirlingshire
In the United Kingdom, the city of preston is in the county of lancashire
In the United Kingdom, the city of oxford is in the county of oxfordshire
In the United Kingdom, the city of canterbury is in the county of kent
In the United Kingdom, the city of sheffield is in the county of yorkshire
In the United Kingdom, the city of swansea is in the county of glamorgan
In the United Kingdom, the city of winchester is in the county of
2024-08-01 08:30:27 root INFO     [order_1_approx] starting weight calculation for In the United Kingdom, the city of sheffield is in the county of yorkshire
In the United Kingdom, the city of swansea is in the county of glamorgan
In the United Kingdom, the city of chichester is in the county of sussex
In the United Kingdom, the city of preston is in the county of lancashire
In the United Kingdom, the city of winchester is in the county of hampshire
In the United Kingdom, the city of canterbury is in the county of kent
In the United Kingdom, the city of stirling is in the county of stirlingshire
In the United Kingdom, the city of oxford is in the county of
2024-08-01 08:30:27 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-08-01 08:34:45 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1263,  0.0959, -0.0738,  ...,  0.1000,  0.0301, -0.0576],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.7266, -4.3281, -1.3418,  ..., -0.7432, -0.3853, -2.5312],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0035,  0.0107,  0.0025,  ...,  0.0009, -0.0270, -0.0044],
        [ 0.0377,  0.0093,  0.0291,  ...,  0.0098, -0.0234, -0.0085],
        [-0.0182,  0.0007,  0.0235,  ..., -0.0152, -0.0193, -0.0113],
        ...,
        [ 0.0392, -0.0020, -0.0039,  ...,  0.0176,  0.0033, -0.0185],
        [-0.0411, -0.0191, -0.0042,  ...,  0.0182,  0.0301, -0.0003],
        [-0.0031, -0.0021, -0.0292,  ..., -0.0019, -0.0245,  0.0055]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.5879, -4.3711, -1.2441,  ..., -0.7373, -0.4714, -2.4629]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 08:34:46 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for In the United Kingdom, the city of sheffield is in the county of yorkshire
In the United Kingdom, the city of swansea is in the county of glamorgan
In the United Kingdom, the city of chichester is in the county of sussex
In the United Kingdom, the city of preston is in the county of lancashire
In the United Kingdom, the city of winchester is in the county of hampshire
In the United Kingdom, the city of canterbury is in the county of kent
In the United Kingdom, the city of stirling is in the county of stirlingshire
In the United Kingdom, the city of oxford is in the county of
2024-08-01 08:34:46 root INFO     [order_1_approx] starting weight calculation for In the United Kingdom, the city of swansea is in the county of glamorgan
In the United Kingdom, the city of canterbury is in the county of kent
In the United Kingdom, the city of sheffield is in the county of yorkshire
In the United Kingdom, the city of winchester is in the county of hampshire
In the United Kingdom, the city of oxford is in the county of oxfordshire
In the United Kingdom, the city of chichester is in the county of sussex
In the United Kingdom, the city of stirling is in the county of stirlingshire
In the United Kingdom, the city of preston is in the county of
2024-08-01 08:34:46 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-08-01 08:38:58 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0538, -0.0028, -0.2401,  ...,  0.0241,  0.0920,  0.0269],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.6582, -5.2578,  1.3320,  ..., -2.0000,  1.2334, -1.7939],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0791, -0.0155, -0.0168,  ...,  0.0881, -0.0052,  0.0168],
        [ 0.0121, -0.0396,  0.0200,  ..., -0.0098,  0.0372, -0.0786],
        [ 0.1443,  0.0440,  0.0097,  ...,  0.0721, -0.0018, -0.0274],
        ...,
        [ 0.0301, -0.0423, -0.0283,  ...,  0.0208, -0.0203, -0.0376],
        [-0.0267, -0.0775,  0.0068,  ...,  0.0187, -0.0213, -0.0381],
        [ 0.0529, -0.0527, -0.0945,  ..., -0.0387, -0.0682,  0.0358]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.3633, -5.2266,  1.4648,  ..., -1.5908,  1.5488, -1.5078]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 08:38:59 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for In the United Kingdom, the city of swansea is in the county of glamorgan
In the United Kingdom, the city of canterbury is in the county of kent
In the United Kingdom, the city of sheffield is in the county of yorkshire
In the United Kingdom, the city of winchester is in the county of hampshire
In the United Kingdom, the city of oxford is in the county of oxfordshire
In the United Kingdom, the city of chichester is in the county of sussex
In the United Kingdom, the city of stirling is in the county of stirlingshire
In the United Kingdom, the city of preston is in the county of
2024-08-01 08:39:00 root INFO     [order_1_approx] starting weight calculation for In the United Kingdom, the city of stirling is in the county of stirlingshire
In the United Kingdom, the city of chichester is in the county of sussex
In the United Kingdom, the city of preston is in the county of lancashire
In the United Kingdom, the city of swansea is in the county of glamorgan
In the United Kingdom, the city of sheffield is in the county of yorkshire
In the United Kingdom, the city of oxford is in the county of oxfordshire
In the United Kingdom, the city of winchester is in the county of hampshire
In the United Kingdom, the city of canterbury is in the county of
2024-08-01 08:39:00 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-08-01 08:43:13 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0260,  0.0034, -0.1255,  ...,  0.1041, -0.0698,  0.1794],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.9238, -2.4668, -1.7402,  ..., -2.1738,  1.2236, -1.5830],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-1.1040e-02,  2.0847e-03,  3.6377e-02,  ..., -7.9193e-03,
          3.7746e-03, -4.7684e-05],
        [ 3.4760e-02,  4.1618e-03, -1.0651e-02,  ...,  5.3062e-03,
         -2.4319e-04, -3.5248e-02],
        [-2.0050e-02, -6.0997e-03,  3.7842e-03,  ...,  1.4076e-02,
          1.4801e-02,  2.8000e-03],
        ...,
        [ 3.3600e-02,  7.7209e-03, -2.5574e-02,  ..., -1.8753e-02,
         -3.8208e-02, -4.4067e-02],
        [-1.2299e-02, -3.2471e-02,  1.1940e-02,  ...,  2.1240e-02,
          2.7069e-02,  1.0857e-02],
        [ 2.8885e-02, -2.5406e-02, -1.5839e-02,  ..., -6.8855e-03,
         -1.8204e-02,  3.0746e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.2168, -2.3750, -1.7129,  ..., -2.2148,  1.4883, -1.5811]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 08:43:14 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for In the United Kingdom, the city of stirling is in the county of stirlingshire
In the United Kingdom, the city of chichester is in the county of sussex
In the United Kingdom, the city of preston is in the county of lancashire
In the United Kingdom, the city of swansea is in the county of glamorgan
In the United Kingdom, the city of sheffield is in the county of yorkshire
In the United Kingdom, the city of oxford is in the county of oxfordshire
In the United Kingdom, the city of winchester is in the county of hampshire
In the United Kingdom, the city of canterbury is in the county of
2024-08-01 08:43:14 root INFO     [order_1_approx] starting weight calculation for In the United Kingdom, the city of swansea is in the county of glamorgan
In the United Kingdom, the city of chichester is in the county of sussex
In the United Kingdom, the city of oxford is in the county of oxfordshire
In the United Kingdom, the city of winchester is in the county of hampshire
In the United Kingdom, the city of preston is in the county of lancashire
In the United Kingdom, the city of sheffield is in the county of yorkshire
In the United Kingdom, the city of canterbury is in the county of kent
In the United Kingdom, the city of stirling is in the county of
2024-08-01 08:43:15 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-08-01 08:47:32 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0701,  0.0057, -0.2114,  ...,  0.1678, -0.0035,  0.0632],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.6250e+00, -4.0742e+00, -3.9062e-03,  ..., -3.2969e+00,
        -2.1543e+00, -1.9277e+00], device='cuda:1', dtype=torch.float16,
       grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0044, -0.0063,  0.0198,  ...,  0.0704, -0.0172, -0.0606],
        [ 0.0338, -0.0163,  0.0162,  ...,  0.0125,  0.0126, -0.0254],
        [ 0.0024,  0.0224,  0.0078,  ...,  0.0212,  0.0130,  0.0055],
        ...,
        [ 0.0506,  0.0153, -0.0719,  ...,  0.0080, -0.0394,  0.0674],
        [-0.0222, -0.0030,  0.0444,  ...,  0.0403,  0.0457, -0.0152],
        [ 0.0187,  0.0138, -0.0414,  ..., -0.0386, -0.0350,  0.0468]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.5195, -4.1836, -0.1672,  ..., -3.0352, -2.0391, -1.9209]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 08:47:33 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for In the United Kingdom, the city of swansea is in the county of glamorgan
In the United Kingdom, the city of chichester is in the county of sussex
In the United Kingdom, the city of oxford is in the county of oxfordshire
In the United Kingdom, the city of winchester is in the county of hampshire
In the United Kingdom, the city of preston is in the county of lancashire
In the United Kingdom, the city of sheffield is in the county of yorkshire
In the United Kingdom, the city of canterbury is in the county of kent
In the United Kingdom, the city of stirling is in the county of
2024-08-01 08:47:33 root INFO     [order_1_approx] starting weight calculation for In the United Kingdom, the city of winchester is in the county of hampshire
In the United Kingdom, the city of oxford is in the county of oxfordshire
In the United Kingdom, the city of sheffield is in the county of yorkshire
In the United Kingdom, the city of canterbury is in the county of kent
In the United Kingdom, the city of stirling is in the county of stirlingshire
In the United Kingdom, the city of chichester is in the county of sussex
In the United Kingdom, the city of preston is in the county of lancashire
In the United Kingdom, the city of swansea is in the county of
2024-08-01 08:47:33 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-08-01 08:51:51 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0048, -0.0143, -0.1154,  ...,  0.1045,  0.1559,  0.0542],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.4062, -4.5195,  0.6255,  ..., -2.5430, -1.9590,  1.1582],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0037,  0.0066,  0.0111,  ...,  0.0146, -0.0123,  0.0130],
        [ 0.0259,  0.0162,  0.0201,  ..., -0.0213, -0.0105, -0.0136],
        [-0.0186, -0.0184, -0.0419,  ...,  0.0353, -0.0096, -0.0386],
        ...,
        [ 0.0074,  0.0042, -0.0030,  ...,  0.0094,  0.0015, -0.0155],
        [ 0.0005, -0.0355,  0.0189,  ..., -0.0182,  0.0146,  0.0309],
        [-0.0253, -0.0231, -0.0384,  ...,  0.0325, -0.0004, -0.0209]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.4102, -4.5859,  0.5942,  ..., -2.4512, -1.7803,  1.0830]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 08:51:51 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for In the United Kingdom, the city of winchester is in the county of hampshire
In the United Kingdom, the city of oxford is in the county of oxfordshire
In the United Kingdom, the city of sheffield is in the county of yorkshire
In the United Kingdom, the city of canterbury is in the county of kent
In the United Kingdom, the city of stirling is in the county of stirlingshire
In the United Kingdom, the city of chichester is in the county of sussex
In the United Kingdom, the city of preston is in the county of lancashire
In the United Kingdom, the city of swansea is in the county of
2024-08-01 08:51:52 root INFO     [order_1_approx] starting weight calculation for In the United Kingdom, the city of stirling is in the county of stirlingshire
In the United Kingdom, the city of sheffield is in the county of yorkshire
In the United Kingdom, the city of swansea is in the county of glamorgan
In the United Kingdom, the city of preston is in the county of lancashire
In the United Kingdom, the city of canterbury is in the county of kent
In the United Kingdom, the city of winchester is in the county of hampshire
In the United Kingdom, the city of oxford is in the county of oxfordshire
In the United Kingdom, the city of chichester is in the county of
2024-08-01 08:51:52 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-08-01 08:56:05 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0870,  0.0626, -0.1078,  ...,  0.0224,  0.1678,  0.1162],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 5.1172e+00, -2.9297e+00,  7.4316e-01,  ..., -1.7520e+00,
         8.9258e-01,  4.6387e-03], device='cuda:1', dtype=torch.float16,
       grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0183, -0.0475, -0.0106,  ...,  0.0165, -0.0295, -0.0062],
        [ 0.0388,  0.0305, -0.0032,  ...,  0.0140,  0.0108,  0.0171],
        [-0.0244, -0.0114, -0.1086,  ...,  0.0097, -0.0141,  0.0161],
        ...,
        [ 0.0245,  0.0660, -0.0587,  ...,  0.0240,  0.0331,  0.0170],
        [ 0.0073, -0.0691,  0.0585,  ...,  0.0136,  0.0435, -0.0202],
        [ 0.0215,  0.0483, -0.0222,  ..., -0.0062,  0.0087,  0.0727]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 5.2461, -3.0488,  0.7148,  ..., -1.3369,  1.1602, -0.0865]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 08:56:06 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for In the United Kingdom, the city of stirling is in the county of stirlingshire
In the United Kingdom, the city of sheffield is in the county of yorkshire
In the United Kingdom, the city of swansea is in the county of glamorgan
In the United Kingdom, the city of preston is in the county of lancashire
In the United Kingdom, the city of canterbury is in the county of kent
In the United Kingdom, the city of winchester is in the county of hampshire
In the United Kingdom, the city of oxford is in the county of oxfordshire
In the United Kingdom, the city of chichester is in the county of
2024-08-01 08:56:06 root INFO     [order_1_approx] starting weight calculation for In the United Kingdom, the city of stirling is in the county of stirlingshire
In the United Kingdom, the city of winchester is in the county of hampshire
In the United Kingdom, the city of canterbury is in the county of kent
In the United Kingdom, the city of preston is in the county of lancashire
In the United Kingdom, the city of oxford is in the county of oxfordshire
In the United Kingdom, the city of chichester is in the county of sussex
In the United Kingdom, the city of swansea is in the county of glamorgan
In the United Kingdom, the city of sheffield is in the county of
2024-08-01 08:56:07 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-08-01 09:00:24 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1514, -0.0218, -0.1843,  ...,  0.0397,  0.2020,  0.0941],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.5918, -4.7734,  0.6846,  ..., -2.3379,  0.2051,  0.5254],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0079,  0.0193,  0.0515,  ...,  0.0039, -0.0078, -0.0052],
        [-0.0105,  0.0078, -0.0230,  ..., -0.0284, -0.0241,  0.0116],
        [-0.0398,  0.0144, -0.0113,  ...,  0.0209, -0.0267, -0.0346],
        ...,
        [ 0.0122,  0.0196, -0.0232,  ..., -0.0068, -0.0383, -0.0103],
        [-0.0128, -0.0140,  0.0078,  ...,  0.0638,  0.0414,  0.0028],
        [ 0.0099, -0.0275, -0.0475,  ...,  0.0003, -0.0298, -0.0047]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.4883, -5.0234,  0.6250,  ..., -2.3945,  0.5713,  0.2974]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 09:00:25 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for In the United Kingdom, the city of stirling is in the county of stirlingshire
In the United Kingdom, the city of winchester is in the county of hampshire
In the United Kingdom, the city of canterbury is in the county of kent
In the United Kingdom, the city of preston is in the county of lancashire
In the United Kingdom, the city of oxford is in the county of oxfordshire
In the United Kingdom, the city of chichester is in the county of sussex
In the United Kingdom, the city of swansea is in the county of glamorgan
In the United Kingdom, the city of sheffield is in the county of
2024-08-01 09:00:25 root INFO     total operator prediction time: 2056.7091064453125 seconds
2024-08-01 09:00:25 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on meronyms - part
2024-08-01 09:00:25 root INFO     building operator meronyms - part
2024-08-01 09:00:25 root INFO     [order_1_approx] starting weight calculation for A part of a chair is a seat
A part of a byte is a bit
A part of a car is a engine
A part of a day is a hour
A part of a teapot is a spout
A part of a bird is a feathers
A part of a church is a altar
A part of a comb is a
2024-08-01 09:00:25 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-08-01 09:03:33 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0805, -0.1921, -0.2063,  ..., -0.0453,  0.0137,  0.0405],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.6855, -1.3584, -2.5078,  ...,  1.2314,  1.5391, -1.2324],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0396,  0.0036, -0.0033,  ...,  0.0169, -0.0382, -0.0062],
        [ 0.0435,  0.0201,  0.0594,  ..., -0.0420, -0.0086,  0.0016],
        [-0.0177,  0.0085,  0.0629,  ..., -0.0223,  0.0009, -0.0149],
        ...,
        [ 0.0490, -0.0078, -0.0247,  ..., -0.0213, -0.0344,  0.0003],
        [-0.0120,  0.0083, -0.0831,  ...,  0.0215,  0.0337, -0.0417],
        [ 0.0147,  0.0084,  0.0567,  ..., -0.0401, -0.0038, -0.0343]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.3613, -0.0107, -2.4512,  ...,  1.3232,  0.5972, -0.2158]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 09:03:34 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A part of a chair is a seat
A part of a byte is a bit
A part of a car is a engine
A part of a day is a hour
A part of a teapot is a spout
A part of a bird is a feathers
A part of a church is a altar
A part of a comb is a
2024-08-01 09:03:34 root INFO     [order_1_approx] starting weight calculation for A part of a church is a altar
A part of a car is a engine
A part of a byte is a bit
A part of a teapot is a spout
A part of a chair is a seat
A part of a comb is a teeth
A part of a bird is a feathers
A part of a day is a
2024-08-01 09:03:34 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-08-01 09:06:31 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1116,  0.0163, -0.0389,  ..., -0.0329, -0.1746, -0.0601],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.7603, -4.2969,  1.6709,  ..., -0.5283,  1.1826, -1.9756],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0054,  0.0512, -0.0006,  ...,  0.1030,  0.0237, -0.0265],
        [ 0.0126,  0.0196, -0.0101,  ..., -0.0189, -0.0163, -0.0040],
        [-0.0583, -0.0519,  0.0667,  ..., -0.0569, -0.0019, -0.0034],
        ...,
        [-0.0318, -0.0244,  0.0313,  ...,  0.0482, -0.0367, -0.0258],
        [-0.0031,  0.0047, -0.0218,  ...,  0.0266,  0.0394, -0.0388],
        [-0.0117, -0.0089, -0.0226,  ...,  0.0529,  0.0104,  0.0047]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.1982, -4.0391,  0.9780,  ..., -0.6670,  1.7578, -1.5879]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 09:06:32 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A part of a church is a altar
A part of a car is a engine
A part of a byte is a bit
A part of a teapot is a spout
A part of a chair is a seat
A part of a comb is a teeth
A part of a bird is a feathers
A part of a day is a
2024-08-01 09:06:32 root INFO     [order_1_approx] starting weight calculation for A part of a bird is a feathers
A part of a teapot is a spout
A part of a car is a engine
A part of a comb is a teeth
A part of a byte is a bit
A part of a chair is a seat
A part of a day is a hour
A part of a church is a
2024-08-01 09:06:32 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-08-01 09:09:34 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0199,  0.0042, -0.0853,  ...,  0.0217, -0.1600,  0.0058],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.0547, -4.4961,  1.0605,  ...,  0.9775,  0.5322, -4.2617],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0369, -0.0322,  0.0279,  ...,  0.0115, -0.0142, -0.0476],
        [ 0.0103, -0.0203,  0.0131,  ...,  0.0630,  0.0206, -0.0014],
        [-0.0284,  0.0271,  0.0316,  ..., -0.0451, -0.0029, -0.0004],
        ...,
        [-0.0276,  0.0009, -0.0122,  ...,  0.0062,  0.0014, -0.0057],
        [-0.0438,  0.0271, -0.0333,  ..., -0.0671,  0.0193,  0.0004],
        [ 0.0381, -0.0172, -0.0130,  ...,  0.0296, -0.0047,  0.0025]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.2598, -3.4844,  0.6641,  ...,  0.5146, -0.0947, -2.8438]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 09:09:36 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A part of a bird is a feathers
A part of a teapot is a spout
A part of a car is a engine
A part of a comb is a teeth
A part of a byte is a bit
A part of a chair is a seat
A part of a day is a hour
A part of a church is a
2024-08-01 09:09:37 root INFO     [order_1_approx] starting weight calculation for A part of a teapot is a spout
A part of a chair is a seat
A part of a day is a hour
A part of a church is a altar
A part of a byte is a bit
A part of a bird is a feathers
A part of a comb is a teeth
A part of a car is a
2024-08-01 09:09:37 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-08-01 09:12:34 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0560,  0.1099, -0.0839,  ..., -0.0450, -0.0018, -0.1198],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.0176, -3.4102, -2.9766,  ...,  1.9229,  0.1111, -2.9746],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0336, -0.0239,  0.0422,  ..., -0.0130,  0.0240, -0.0116],
        [-0.0120, -0.0275,  0.0087,  ...,  0.0246,  0.0320, -0.0330],
        [ 0.0231, -0.0140,  0.0079,  ..., -0.0222, -0.0270, -0.0071],
        ...,
        [-0.0009,  0.0328, -0.0106,  ...,  0.0025, -0.0117,  0.0118],
        [-0.0336,  0.0251, -0.0055,  ..., -0.0061,  0.0127,  0.0289],
        [ 0.0047, -0.0223,  0.0226,  ..., -0.0075,  0.0327,  0.0068]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.4834, -2.8262, -2.7129,  ...,  1.6064,  0.1448, -2.5703]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 09:12:35 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A part of a teapot is a spout
A part of a chair is a seat
A part of a day is a hour
A part of a church is a altar
A part of a byte is a bit
A part of a bird is a feathers
A part of a comb is a teeth
A part of a car is a
2024-08-01 09:12:35 root INFO     [order_1_approx] starting weight calculation for A part of a car is a engine
A part of a church is a altar
A part of a byte is a bit
A part of a bird is a feathers
A part of a comb is a teeth
A part of a day is a hour
A part of a chair is a seat
A part of a teapot is a
2024-08-01 09:12:35 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-08-01 09:15:37 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2229, -0.0074,  0.0163,  ...,  0.0295,  0.0332, -0.1954],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.3672,  0.6270, -0.5244,  ..., -0.5146,  0.4167, -0.9771],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 2.0386e-02, -9.5749e-03, -4.5395e-03,  ..., -6.5842e-03,
         -1.6747e-03,  2.2827e-02],
        [-1.0269e-02,  1.9928e-02, -3.0487e-02,  ..., -1.2161e-02,
         -1.0498e-02,  1.7227e-02],
        [ 8.1711e-03,  6.0158e-03,  2.7496e-02,  ...,  2.7985e-02,
         -8.3923e-03,  1.1955e-02],
        ...,
        [ 1.2123e-02,  1.7548e-02,  1.1520e-03,  ...,  2.7023e-02,
         -2.1973e-02, -7.4959e-03],
        [-3.3936e-02, -9.0866e-03, -1.7748e-03,  ..., -1.8921e-02,
          4.2267e-02, -1.3412e-02],
        [ 6.8665e-05, -1.7181e-02, -1.9043e-02,  ...,  2.3300e-02,
          1.5488e-02,  6.2332e-03]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.4766,  0.7505, -0.5229,  ..., -0.5327,  0.2542, -0.8691]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 09:15:38 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A part of a car is a engine
A part of a church is a altar
A part of a byte is a bit
A part of a bird is a feathers
A part of a comb is a teeth
A part of a day is a hour
A part of a chair is a seat
A part of a teapot is a
2024-08-01 09:15:38 root INFO     [order_1_approx] starting weight calculation for A part of a bird is a feathers
A part of a chair is a seat
A part of a comb is a teeth
A part of a car is a engine
A part of a church is a altar
A part of a teapot is a spout
A part of a day is a hour
A part of a byte is a
2024-08-01 09:15:38 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
2024-08-01 09:18:43 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0191,  0.0234, -0.1196,  ..., -0.0906, -0.1667, -0.1171],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.1030, -3.0781, -1.2422,  ...,  0.3545, -2.2148, -0.2285],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0002,  0.0372,  0.0162,  ...,  0.0185,  0.0049, -0.0145],
        [ 0.0169, -0.0873,  0.0269,  ..., -0.0045,  0.0147, -0.0022],
        [-0.0211,  0.0136,  0.0192,  ..., -0.0359, -0.0051, -0.0143],
        ...,
        [ 0.0113,  0.0418, -0.0511,  ...,  0.0137, -0.0171,  0.0144],
        [-0.0112, -0.0107, -0.0220,  ..., -0.0282,  0.0019,  0.0110],
        [-0.0227, -0.0475, -0.0050,  ..., -0.0082,  0.0038,  0.0456]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.6665, -1.6533, -1.4180,  ..., -0.2456, -1.7148,  0.7397]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 09:18:45 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A part of a bird is a feathers
A part of a chair is a seat
A part of a comb is a teeth
A part of a car is a engine
A part of a church is a altar
A part of a teapot is a spout
A part of a day is a hour
A part of a byte is a
2024-08-01 09:18:45 root INFO     [order_1_approx] starting weight calculation for A part of a comb is a teeth
A part of a church is a altar
A part of a car is a engine
A part of a bird is a feathers
A part of a byte is a bit
A part of a teapot is a spout
A part of a day is a hour
A part of a chair is a
2024-08-01 09:18:45 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.4
