2024-07-30 09:10:11 root INFO     loading model + tokenizer
2024-07-30 09:10:15 root INFO     model + tokenizer loaded
2024-07-30 09:10:15 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on verb+ment_irreg
2024-07-30 09:10:15 root INFO     building operator verb+ment_irreg
2024-07-30 09:10:37 root INFO     loading model + tokenizer
2024-07-30 09:10:40 root INFO     model + tokenizer loaded
2024-07-30 09:10:40 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on verb+ment_irreg
2024-07-30 09:10:40 root INFO     building operator verb+ment_irreg
2024-07-30 09:10:41 root INFO     [order_1_approx] starting weight calculation for To advertise results in a advertisement
To displace results in a displacement
To enhance results in a enhancement
To amuse results in a amusement
To commit results in a commitment
To accomplish results in a accomplishment
To invest results in a investment
To appoint results in a
2024-07-30 09:10:41 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 09:13:15 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1270,  0.5361, -0.4822,  ...,  0.2408, -0.0737, -0.1542],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.1855, -3.7852, -0.2437,  ...,  3.1562, -2.0312, -3.9805],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0321, -0.0036, -0.0088,  ..., -0.0199, -0.0027, -0.0026],
        [ 0.0137,  0.0295,  0.0204,  ...,  0.0450,  0.0231,  0.0068],
        [-0.0087, -0.0150, -0.0001,  ..., -0.0255, -0.0205, -0.0188],
        ...,
        [-0.0121,  0.0367, -0.0136,  ...,  0.0407,  0.0102,  0.0320],
        [ 0.0094, -0.0206,  0.0056,  ..., -0.0024,  0.0288, -0.0055],
        [ 0.0172,  0.0083, -0.0055,  ...,  0.0075, -0.0131,  0.0374]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.1055, -2.5664, -0.6660,  ...,  3.3652, -1.7754, -3.8516]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 09:13:16 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To advertise results in a advertisement
To displace results in a displacement
To enhance results in a enhancement
To amuse results in a amusement
To commit results in a commitment
To accomplish results in a accomplishment
To invest results in a investment
To appoint results in a
2024-07-30 09:13:16 root INFO     [order_1_approx] starting weight calculation for To displace results in a displacement
To commit results in a commitment
To amuse results in a amusement
To accomplish results in a accomplishment
To advertise results in a advertisement
To appoint results in a appointment
To enhance results in a enhancement
To invest results in a
2024-07-30 09:13:16 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 09:15:49 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1870, -0.0377, -0.3311,  ..., -0.0265,  0.1942, -0.3030],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.0410, -2.8203, -1.3994,  ...,  0.7070, -1.4199, -2.7227],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 4.6539e-02,  6.5384e-03,  6.0005e-03,  ...,  9.5825e-03,
          8.4610e-03,  9.0027e-03],
        [-2.8610e-05,  8.5602e-03, -6.6233e-04,  ...,  1.3626e-02,
          3.3203e-02, -7.6675e-03],
        [ 7.7667e-03,  2.1439e-03,  3.0960e-02,  ..., -1.3237e-02,
         -1.7334e-02, -4.2496e-03],
        ...,
        [ 7.4844e-03,  1.4359e-02,  5.1727e-03,  ...,  2.0538e-02,
          7.0076e-03,  1.3184e-02],
        [-2.2095e-02,  1.2711e-02,  1.3237e-03,  ...,  2.9945e-04,
          2.0676e-02, -1.6403e-02],
        [-1.8845e-03, -9.6130e-03, -1.0895e-02,  ..., -6.1722e-03,
          4.0817e-03,  3.9795e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.1777, -1.8770, -1.4336,  ...,  1.1445, -1.7773, -2.6602]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 09:15:50 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To displace results in a displacement
To commit results in a commitment
To amuse results in a amusement
To accomplish results in a accomplishment
To advertise results in a advertisement
To appoint results in a appointment
To enhance results in a enhancement
To invest results in a
2024-07-30 09:15:51 root INFO     [order_1_approx] starting weight calculation for To displace results in a displacement
To enhance results in a enhancement
To advertise results in a advertisement
To appoint results in a appointment
To commit results in a commitment
To amuse results in a amusement
To invest results in a investment
To accomplish results in a
2024-07-30 09:15:51 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 09:18:25 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1242,  0.5625, -0.3491,  ...,  0.0229, -0.3916,  0.0918],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.8047, -4.1367, -0.7290,  ...,  1.9102, -1.2471, -1.4844],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0333,  0.0909, -0.0260,  ..., -0.0533, -0.0370,  0.0201],
        [ 0.0023,  0.0085,  0.0344,  ...,  0.0874,  0.0493,  0.0202],
        [ 0.0067,  0.0025,  0.0164,  ..., -0.0221, -0.0630, -0.0206],
        ...,
        [ 0.0313, -0.0188, -0.0253,  ...,  0.0701,  0.0511,  0.0089],
        [-0.0176,  0.0328,  0.0193,  ...,  0.0156,  0.0097, -0.0217],
        [-0.0027, -0.0269,  0.0031,  ...,  0.0167,  0.0048,  0.0444]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.6055, -2.3164, -0.9453,  ...,  3.0000, -1.4873, -1.1523]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 09:18:26 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To displace results in a displacement
To enhance results in a enhancement
To advertise results in a advertisement
To appoint results in a appointment
To commit results in a commitment
To amuse results in a amusement
To invest results in a investment
To accomplish results in a
2024-07-30 09:18:26 root INFO     [order_1_approx] starting weight calculation for To accomplish results in a accomplishment
To amuse results in a amusement
To invest results in a investment
To displace results in a displacement
To appoint results in a appointment
To enhance results in a enhancement
To commit results in a commitment
To advertise results in a
2024-07-30 09:18:26 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 09:21:00 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0481,  0.5059, -0.3501,  ...,  0.0374,  0.0964,  0.0095],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.0918, -2.3789, -0.6079,  ...,  2.4551, -2.7578, -1.8623],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 3.3356e-02,  8.6517e-03,  3.6240e-05,  ..., -8.2779e-03,
         -1.4503e-02,  1.6907e-02],
        [-1.6708e-03,  3.9581e-02, -7.8735e-03,  ...,  2.7206e-02,
          2.8870e-02, -1.3199e-02],
        [ 1.5060e-02, -2.1057e-02,  1.0292e-02,  ..., -2.1149e-02,
         -2.0676e-02, -1.1047e-02],
        ...,
        [ 6.4392e-03, -3.4904e-03, -9.5139e-03,  ...,  2.6031e-02,
         -2.4261e-03,  1.8707e-02],
        [-1.2413e-02,  7.9880e-03,  1.3702e-02,  ...,  1.5419e-02,
          4.0924e-02, -1.3199e-02],
        [-9.8419e-03, -1.9897e-02, -1.0582e-02,  ...,  1.9989e-02,
         -3.7933e-02,  3.1738e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.9980, -1.8516, -0.7656,  ...,  2.1484, -2.3926, -1.8398]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 09:21:02 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To accomplish results in a accomplishment
To amuse results in a amusement
To invest results in a investment
To displace results in a displacement
To appoint results in a appointment
To enhance results in a enhancement
To commit results in a commitment
To advertise results in a
2024-07-30 09:21:02 root INFO     [order_1_approx] starting weight calculation for To appoint results in a appointment
To displace results in a displacement
To invest results in a investment
To accomplish results in a accomplishment
To advertise results in a advertisement
To enhance results in a enhancement
To amuse results in a amusement
To commit results in a
2024-07-30 09:21:02 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 09:23:36 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0587,  0.2954, -0.5308,  ...,  0.1794, -0.0557,  0.1085],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.6367, -4.2266, -1.1895,  ..., -1.2080, -1.6074, -2.1738],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0567,  0.0217, -0.0298,  ..., -0.0117, -0.0354,  0.0186],
        [-0.0196,  0.0601,  0.0449,  ...,  0.0437,  0.0494, -0.0168],
        [ 0.0035, -0.0149,  0.0252,  ...,  0.0084, -0.0231, -0.0059],
        ...,
        [ 0.0136,  0.0247,  0.0081,  ...,  0.0613,  0.0480,  0.0009],
        [-0.0052,  0.0088,  0.0186,  ...,  0.0063,  0.0016, -0.0112],
        [ 0.0085, -0.0188,  0.0076,  ..., -0.0278,  0.0080,  0.0306]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.6758, -3.3418, -1.0947,  ..., -0.1113, -2.0684, -1.9180]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 09:23:37 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To appoint results in a appointment
To displace results in a displacement
To invest results in a investment
To accomplish results in a accomplishment
To advertise results in a advertisement
To enhance results in a enhancement
To amuse results in a amusement
To commit results in a
2024-07-30 09:23:37 root INFO     [order_1_approx] starting weight calculation for To appoint results in a appointment
To commit results in a commitment
To accomplish results in a accomplishment
To advertise results in a advertisement
To displace results in a displacement
To amuse results in a amusement
To invest results in a investment
To enhance results in a
2024-07-30 09:23:37 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 09:26:12 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2062,  0.1670, -0.2998,  ...,  0.1174, -0.0521,  0.1091],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.1797, -1.2686,  0.4463,  ...,  4.7656, -5.0820, -3.0195],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0271,  0.0283, -0.0107,  ..., -0.0103, -0.0234,  0.0251],
        [-0.0237,  0.0300, -0.0053,  ...,  0.0227,  0.0233,  0.0014],
        [-0.0048, -0.0261,  0.0257,  ...,  0.0088,  0.0182, -0.0108],
        ...,
        [ 0.0213, -0.0051, -0.0229,  ...,  0.0177, -0.0078,  0.0127],
        [-0.0104,  0.0124,  0.0240,  ...,  0.0087,  0.0334,  0.0099],
        [-0.0105, -0.0157,  0.0055,  ...,  0.0013, -0.0104,  0.0242]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.9844, -0.7236,  0.6143,  ...,  4.5781, -5.0664, -2.5957]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 09:26:13 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To appoint results in a appointment
To commit results in a commitment
To accomplish results in a accomplishment
To advertise results in a advertisement
To displace results in a displacement
To amuse results in a amusement
To invest results in a investment
To enhance results in a
2024-07-30 09:26:13 root INFO     [order_1_approx] starting weight calculation for To enhance results in a enhancement
To invest results in a investment
To appoint results in a appointment
To accomplish results in a accomplishment
To advertise results in a advertisement
To commit results in a commitment
To displace results in a displacement
To amuse results in a
2024-07-30 09:26:13 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 09:27:50 root INFO     loading model + tokenizer
2024-07-30 09:28:36 root INFO     loading model + tokenizer
2024-07-30 09:28:46 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2649,  0.6177, -0.3953,  ...,  0.3794, -0.1799, -0.0263],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.5703, -3.0430,  0.8896,  ...,  2.7852, -1.1826, -0.5977],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0486,  0.0184, -0.0038,  ..., -0.0256, -0.0047,  0.0098],
        [-0.0002,  0.0328,  0.0015,  ..., -0.0010,  0.0518,  0.0296],
        [-0.0124, -0.0480,  0.0410,  ...,  0.0188, -0.0008, -0.0274],
        ...,
        [ 0.0253, -0.0050, -0.0100,  ...,  0.0588,  0.0090, -0.0042],
        [ 0.0141,  0.0139,  0.0266,  ...,  0.0007,  0.0346,  0.0079],
        [ 0.0104, -0.0169, -0.0203,  ...,  0.0004, -0.0148,  0.0414]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.9844, -2.4512,  0.2715,  ...,  3.4082, -1.3350, -0.2493]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 09:28:47 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To enhance results in a enhancement
To invest results in a investment
To appoint results in a appointment
To accomplish results in a accomplishment
To advertise results in a advertisement
To commit results in a commitment
To displace results in a displacement
To amuse results in a
2024-07-30 09:28:48 root INFO     [order_1_approx] starting weight calculation for To commit results in a commitment
To accomplish results in a accomplishment
To enhance results in a enhancement
To advertise results in a advertisement
To amuse results in a amusement
To invest results in a investment
To appoint results in a appointment
To displace results in a
2024-07-30 09:28:48 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 09:29:07 root INFO     loading model + tokenizer
2024-07-30 09:29:24 root INFO     loading model + tokenizer
2024-07-30 09:29:27 root INFO     model + tokenizer loaded
2024-07-30 09:29:27 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on verb+ment_irreg
2024-07-30 09:29:27 root INFO     building operator verb+ment_irreg
2024-07-30 09:30:29 root INFO     loading model + tokenizer
2024-07-30 09:30:32 root INFO     model + tokenizer loaded
2024-07-30 09:30:32 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on verb+ment_irreg
2024-07-30 09:30:32 root INFO     building operator verb+ment_irreg
2024-07-30 09:30:32 root INFO     [order_1_approx] starting weight calculation for To engage results in a engagement
To encourage results in a encouragement
To advertise results in a advertisement
To endorse results in a endorsement
To accomplish results in a accomplishment
To acknowledge results in a acknowledgement
To invest results in a investment
To enhance results in a
2024-07-30 09:30:32 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 09:31:22 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0535,  0.2122, -0.6489,  ...,  0.2803, -0.1377,  0.4172],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.6055, -4.1055,  0.4165,  ...,  2.4512, -1.8379, -1.6738],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0792,  0.0285,  0.0068,  ..., -0.0101, -0.0107,  0.0310],
        [-0.0100,  0.0115,  0.0029,  ...,  0.0336,  0.0139, -0.0054],
        [ 0.0045, -0.0042,  0.0166,  ..., -0.0332,  0.0139, -0.0184],
        ...,
        [ 0.0314,  0.0537, -0.0083,  ...,  0.0426, -0.0311,  0.0190],
        [ 0.0025,  0.0058,  0.0001,  ...,  0.0181,  0.0385,  0.0075],
        [ 0.0076,  0.0220, -0.0034,  ..., -0.0182, -0.0470,  0.0621]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.8105, -3.3418,  0.3706,  ...,  2.1426, -2.1387, -2.2930]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 09:31:23 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To commit results in a commitment
To accomplish results in a accomplishment
To enhance results in a enhancement
To advertise results in a advertisement
To amuse results in a amusement
To invest results in a investment
To appoint results in a appointment
To displace results in a
2024-07-30 09:31:23 root INFO     total operator prediction time: 1242.9661412239075 seconds
2024-07-30 09:31:23 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on noun+less_reg
2024-07-30 09:31:23 root INFO     building operator noun+less_reg
2024-07-30 09:31:24 root INFO     [order_1_approx] starting weight calculation for Something without tooth is toothless
Something without mirth is mirthless
Something without emotion is emotionless
Something without expression is expressionless
Something without life is lifeless
Something without death is deathless
Something without leg is legless
Something without friend is
2024-07-30 09:31:24 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 09:33:57 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1132, -0.1600, -0.1942,  ..., -0.0734, -0.0933, -0.0654],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.3511, -1.9707,  1.5615,  ..., -0.8047, -3.8086,  0.4443],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0336, -0.0008, -0.0136,  ..., -0.0031, -0.0077,  0.0152],
        [ 0.0005,  0.0032, -0.0072,  ..., -0.0025, -0.0087, -0.0116],
        [ 0.0054, -0.0101,  0.0164,  ...,  0.0067, -0.0127, -0.0086],
        ...,
        [ 0.0055,  0.0052, -0.0117,  ...,  0.0101,  0.0123,  0.0057],
        [-0.0009, -0.0084, -0.0086,  ...,  0.0025,  0.0128, -0.0061],
        [ 0.0037,  0.0089,  0.0198,  ..., -0.0143, -0.0157,  0.0064]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.1283, -2.0625,  1.5488,  ..., -1.1016, -3.6816, -0.2090]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 09:33:57 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Something without tooth is toothless
Something without mirth is mirthless
Something without emotion is emotionless
Something without expression is expressionless
Something without life is lifeless
Something without death is deathless
Something without leg is legless
Something without friend is
2024-07-30 09:33:58 root INFO     [order_1_approx] starting weight calculation for Something without emotion is emotionless
Something without tooth is toothless
Something without mirth is mirthless
Something without death is deathless
Something without friend is friendless
Something without life is lifeless
Something without leg is legless
Something without expression is
2024-07-30 09:33:58 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 09:36:30 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0844,  0.0579, -0.0345,  ...,  0.3784, -0.0582, -0.0315],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.9014, -3.4062,  1.1211,  ..., -2.7539, -2.9648, -2.4414],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0583,  0.0224, -0.0046,  ...,  0.0081, -0.0069,  0.0181],
        [ 0.0148,  0.0596,  0.0039,  ...,  0.0047,  0.0055, -0.0072],
        [ 0.0058,  0.0003,  0.0363,  ..., -0.0267, -0.0128, -0.0037],
        ...,
        [ 0.0228,  0.0227, -0.0121,  ...,  0.0049,  0.0159,  0.0003],
        [-0.0209,  0.0114, -0.0095,  ...,  0.0002,  0.0224, -0.0116],
        [ 0.0096, -0.0236, -0.0078,  ...,  0.0246, -0.0213,  0.0155]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.8965, -3.6719,  0.8135,  ..., -2.5215, -3.0352, -2.4316]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 09:36:31 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Something without emotion is emotionless
Something without tooth is toothless
Something without mirth is mirthless
Something without death is deathless
Something without friend is friendless
Something without life is lifeless
Something without leg is legless
Something without expression is
2024-07-30 09:36:31 root INFO     [order_1_approx] starting weight calculation for Something without tooth is toothless
Something without friend is friendless
Something without life is lifeless
Something without leg is legless
Something without death is deathless
Something without mirth is mirthless
Something without expression is expressionless
Something without emotion is
2024-07-30 09:36:31 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 09:39:04 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0698, -0.0608, -0.0886,  ...,  0.0491, -0.1721,  0.4863],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.5000, -1.6094, -0.4512,  ..., -2.2949, -1.3369, -3.4121],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0259, -0.0040,  0.0091,  ..., -0.0020, -0.0124,  0.0177],
        [ 0.0116,  0.0284,  0.0055,  ..., -0.0095,  0.0105, -0.0122],
        [-0.0063,  0.0014,  0.0005,  ..., -0.0126, -0.0155, -0.0105],
        ...,
        [ 0.0074,  0.0144, -0.0157,  ...,  0.0204,  0.0023,  0.0009],
        [-0.0039,  0.0114, -0.0017,  ..., -0.0027,  0.0255, -0.0113],
        [ 0.0113, -0.0070, -0.0101,  ...,  0.0152, -0.0011,  0.0164]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.6797, -1.8799, -0.7573,  ..., -2.1641, -1.4951, -3.1406]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 09:39:05 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Something without tooth is toothless
Something without friend is friendless
Something without life is lifeless
Something without leg is legless
Something without death is deathless
Something without mirth is mirthless
Something without expression is expressionless
Something without emotion is
2024-07-30 09:39:05 root INFO     [order_1_approx] starting weight calculation for Something without life is lifeless
Something without mirth is mirthless
Something without friend is friendless
Something without expression is expressionless
Something without emotion is emotionless
Something without leg is legless
Something without tooth is toothless
Something without death is
2024-07-30 09:39:05 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 09:41:37 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2554, -0.3125,  0.0153,  ..., -0.3110, -0.3181, -0.0022],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.3604, -4.3945, -0.1284,  ..., -1.5586, -2.8691, -2.7773],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 3.8452e-02, -1.7181e-02, -6.6719e-03,  ...,  4.8950e-02,
         -9.3689e-03,  5.0735e-03],
        [ 9.2239e-03,  6.0501e-03,  3.7975e-03,  ..., -1.7502e-02,
         -1.6098e-02, -3.2730e-03],
        [ 5.2490e-03, -1.1765e-02,  5.0049e-03,  ..., -5.4741e-03,
          5.8327e-03, -3.2425e-05],
        ...,
        [-2.4834e-03, -3.2768e-03,  2.7390e-03,  ..., -1.3565e-02,
         -5.2528e-03, -1.3283e-02],
        [-3.5248e-02, -1.3847e-02,  3.1342e-02,  ..., -2.5238e-02,
          2.2614e-02, -1.5060e-02],
        [ 2.2781e-02, -1.2856e-02, -8.9645e-03,  ...,  1.8158e-02,
         -2.8961e-02, -3.1967e-03]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.8438, -4.4102, -0.1825,  ..., -1.6396, -2.9062, -2.5352]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 09:41:38 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Something without life is lifeless
Something without mirth is mirthless
Something without friend is friendless
Something without expression is expressionless
Something without emotion is emotionless
Something without leg is legless
Something without tooth is toothless
Something without death is
2024-07-30 09:41:39 root INFO     [order_1_approx] starting weight calculation for Something without emotion is emotionless
Something without leg is legless
Something without friend is friendless
Something without death is deathless
Something without tooth is toothless
Something without life is lifeless
Something without expression is expressionless
Something without mirth is
2024-07-30 09:41:39 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 09:44:12 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0468,  0.2368,  0.2360,  ...,  0.2971, -0.4541,  0.0750],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.1953, -2.0117, -0.8477,  ..., -1.6143, -3.9570, -1.6523],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0475,  0.0153, -0.0062,  ..., -0.0039,  0.0213,  0.0147],
        [ 0.0148, -0.0043,  0.0064,  ..., -0.0056, -0.0080,  0.0044],
        [ 0.0105, -0.0089,  0.0416,  ...,  0.0055, -0.0139, -0.0004],
        ...,
        [ 0.0086,  0.0272,  0.0084,  ...,  0.0148,  0.0057,  0.0068],
        [ 0.0075, -0.0219, -0.0009,  ..., -0.0174,  0.0086, -0.0068],
        [ 0.0074, -0.0079, -0.0013,  ...,  0.0095, -0.0146,  0.0294]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.2676, -2.1230, -1.1836,  ..., -1.4707, -3.5625, -1.5977]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 09:44:12 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Something without emotion is emotionless
Something without leg is legless
Something without friend is friendless
Something without death is deathless
Something without tooth is toothless
Something without life is lifeless
Something without expression is expressionless
Something without mirth is
2024-07-30 09:44:13 root INFO     [order_1_approx] starting weight calculation for Something without emotion is emotionless
Something without leg is legless
Something without friend is friendless
Something without death is deathless
Something without mirth is mirthless
Something without expression is expressionless
Something without life is lifeless
Something without tooth is
2024-07-30 09:44:13 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 09:46:46 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0891, -0.1112,  0.1650,  ..., -0.1361, -0.1533, -0.0103],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.0491, -3.7539, -2.0254,  ..., -0.5459, -5.1328, -0.8301],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 3.6377e-02, -6.8283e-03,  1.1116e-02,  ..., -2.7809e-03,
         -5.3253e-03,  1.5182e-02],
        [ 9.5978e-03,  1.4496e-03,  1.0399e-02,  ..., -8.0948e-03,
         -1.3916e-02, -1.5579e-02],
        [ 1.7059e-02, -1.9714e-02,  1.2573e-02,  ..., -1.3969e-02,
         -2.1088e-02,  8.2970e-05],
        ...,
        [ 1.9211e-02,  1.4786e-02, -9.1705e-03,  ...,  4.4342e-02,
          1.6678e-02, -3.1223e-03],
        [-4.1199e-04,  1.3123e-03,  1.8661e-02,  ..., -1.1726e-02,
          1.6876e-02, -2.1133e-02],
        [ 6.3610e-04,  1.5106e-03,  4.3716e-03,  ...,  1.5640e-02,
         -2.6337e-02,  1.1185e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.2583, -3.5547, -2.0820,  ..., -0.5869, -5.2148, -1.3242]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 09:46:47 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Something without emotion is emotionless
Something without leg is legless
Something without friend is friendless
Something without death is deathless
Something without mirth is mirthless
Something without expression is expressionless
Something without life is lifeless
Something without tooth is
2024-07-30 09:46:47 root INFO     [order_1_approx] starting weight calculation for Something without friend is friendless
Something without tooth is toothless
Something without mirth is mirthless
Something without life is lifeless
Something without expression is expressionless
Something without death is deathless
Something without emotion is emotionless
Something without leg is
2024-07-30 09:46:47 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 09:49:20 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4670, -0.3057, -0.1318,  ..., -0.0834, -0.0673, -0.3359],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.5029, -5.2070,  1.9785,  ..., -0.1938, -1.2246, -2.1621],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0229, -0.0031, -0.0044,  ..., -0.0105, -0.0123,  0.0134],
        [-0.0021,  0.0104, -0.0129,  ...,  0.0244, -0.0097, -0.0078],
        [ 0.0127, -0.0074,  0.0203,  ..., -0.0105, -0.0224,  0.0066],
        ...,
        [ 0.0152,  0.0111,  0.0013,  ...,  0.0378,  0.0087,  0.0152],
        [-0.0102,  0.0210, -0.0056,  ..., -0.0089,  0.0418, -0.0329],
        [ 0.0016,  0.0016,  0.0208,  ...,  0.0024, -0.0086,  0.0169]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.7266, -5.1680,  1.6787,  ..., -0.3394, -1.6602, -2.1816]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 09:49:21 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Something without friend is friendless
Something without tooth is toothless
Something without mirth is mirthless
Something without life is lifeless
Something without expression is expressionless
Something without death is deathless
Something without emotion is emotionless
Something without leg is
2024-07-30 09:49:21 root INFO     [order_1_approx] starting weight calculation for Something without emotion is emotionless
Something without friend is friendless
Something without leg is legless
Something without mirth is mirthless
Something without death is deathless
Something without expression is expressionless
Something without tooth is toothless
Something without life is
2024-07-30 09:49:21 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 09:51:54 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1931, -0.2644, -0.1224,  ..., -0.3640, -0.1021, -0.0189],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.4768, -3.9922,  0.5869,  ..., -2.7695, -3.2383, -0.3740],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0404,  0.0167, -0.0056,  ...,  0.0071,  0.0067,  0.0024],
        [ 0.0024, -0.0019, -0.0032,  ...,  0.0175,  0.0038, -0.0110],
        [ 0.0080, -0.0013,  0.0198,  ..., -0.0149, -0.0062, -0.0057],
        ...,
        [ 0.0079,  0.0056, -0.0121,  ..., -0.0218,  0.0016, -0.0099],
        [-0.0240, -0.0051,  0.0116,  ..., -0.0256,  0.0165, -0.0275],
        [ 0.0164, -0.0010,  0.0035,  ...,  0.0012, -0.0175,  0.0098]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.7305, -3.9277,  0.2805,  ..., -2.8691, -3.4355, -0.5005]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 09:51:55 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Something without emotion is emotionless
Something without friend is friendless
Something without leg is legless
Something without mirth is mirthless
Something without death is deathless
Something without expression is expressionless
Something without tooth is toothless
Something without life is
2024-07-30 09:51:55 root INFO     total operator prediction time: 1231.5335125923157 seconds
2024-07-30 09:51:55 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on adj+ness_reg
2024-07-30 09:51:55 root INFO     building operator adj+ness_reg
2024-07-30 09:51:55 root INFO     [order_1_approx] starting weight calculation for The state of being happy is happiness
The state of being distinct is distinctness
The state of being obvious is obviousness
The state of being mad is madness
The state of being attractive is attractiveness
The state of being situated is situatedness
The state of being sad is sadness
The state of being random is
2024-07-30 09:51:55 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 09:54:30 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.4094,  0.1147, -0.1741,  ...,  0.3145, -0.3103, -0.1293],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.2443, -1.8086, -1.3906,  ..., -1.3652, -2.9844, -5.5391],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 4.3884e-02, -5.1880e-03, -2.1011e-02,  ...,  8.5735e-04,
          2.1133e-03,  7.3814e-03],
        [-1.4587e-02,  2.7466e-02,  2.5757e-02,  ...,  1.5274e-02,
         -3.3264e-03, -2.3098e-03],
        [ 1.4198e-02, -1.9928e-02,  3.3234e-02,  ...,  5.7507e-04,
          4.5776e-03, -1.1497e-02],
        ...,
        [ 1.5182e-02,  3.8361e-02,  3.1525e-02,  ...,  1.5366e-02,
         -1.8234e-02,  5.8899e-03],
        [-7.6294e-06,  3.3508e-02,  2.3499e-02,  ..., -1.9485e-02,
          2.9724e-02, -1.0834e-02],
        [ 1.1810e-02, -6.0196e-03, -1.7227e-02,  ...,  1.2001e-02,
         -2.5848e-02,  2.7283e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.0789, -1.7793, -1.2930,  ..., -1.5596, -3.2148, -5.6367]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 09:54:30 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The state of being happy is happiness
The state of being distinct is distinctness
The state of being obvious is obviousness
The state of being mad is madness
The state of being attractive is attractiveness
The state of being situated is situatedness
The state of being sad is sadness
The state of being random is
2024-07-30 09:54:31 root INFO     [order_1_approx] starting weight calculation for The state of being sad is sadness
The state of being distinct is distinctness
The state of being happy is happiness
The state of being attractive is attractiveness
The state of being situated is situatedness
The state of being random is randomness
The state of being obvious is obviousness
The state of being mad is
2024-07-30 09:54:31 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 09:57:05 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2227, -0.1046, -0.1949,  ...,  0.1133, -0.3960,  0.2703],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.3359, -3.5879,  0.6064,  ..., -4.1484, -1.3750, -0.7944],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0557,  0.0091,  0.0006,  ..., -0.0097, -0.0063, -0.0151],
        [ 0.0054,  0.0275,  0.0005,  ..., -0.0029,  0.0081, -0.0060],
        [ 0.0146, -0.0015,  0.0430,  ..., -0.0182, -0.0028,  0.0111],
        ...,
        [ 0.0329,  0.0203, -0.0020,  ...,  0.0261, -0.0008,  0.0105],
        [-0.0117,  0.0126, -0.0008,  ...,  0.0011,  0.0213, -0.0233],
        [ 0.0065,  0.0042,  0.0054,  ...,  0.0027, -0.0085,  0.0339]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.2148, -3.4336,  0.2610,  ..., -4.2539, -1.8955, -0.7407]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 09:57:06 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The state of being sad is sadness
The state of being distinct is distinctness
The state of being happy is happiness
The state of being attractive is attractiveness
The state of being situated is situatedness
The state of being random is randomness
The state of being obvious is obviousness
The state of being mad is
2024-07-30 09:57:06 root INFO     [order_1_approx] starting weight calculation for The state of being mad is madness
The state of being sad is sadness
The state of being attractive is attractiveness
The state of being obvious is obviousness
The state of being situated is situatedness
The state of being happy is happiness
The state of being random is randomness
The state of being distinct is
2024-07-30 09:57:06 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 09:59:40 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2394,  0.0462, -0.0316,  ...,  0.3494, -0.1593,  0.0934],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.0576, -1.9121, -0.4434,  ..., -3.2266, -4.5195, -1.3701],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0316,  0.0087, -0.0201,  ...,  0.0109,  0.0187,  0.0028],
        [-0.0018,  0.0094,  0.0213,  ...,  0.0112,  0.0021, -0.0011],
        [ 0.0077, -0.0251,  0.0207,  ..., -0.0134,  0.0002, -0.0146],
        ...,
        [-0.0021,  0.0160,  0.0131,  ...,  0.0178, -0.0077, -0.0005],
        [ 0.0152, -0.0159,  0.0175,  ..., -0.0182,  0.0236, -0.0172],
        [-0.0021,  0.0188,  0.0034,  ...,  0.0086, -0.0103,  0.0273]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.7222, -1.5469, -0.0938,  ..., -2.9531, -5.0156, -1.2188]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 09:59:41 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The state of being mad is madness
The state of being sad is sadness
The state of being attractive is attractiveness
The state of being obvious is obviousness
The state of being situated is situatedness
The state of being happy is happiness
The state of being random is randomness
The state of being distinct is
2024-07-30 09:59:41 root INFO     [order_1_approx] starting weight calculation for The state of being happy is happiness
The state of being situated is situatedness
The state of being distinct is distinctness
The state of being attractive is attractiveness
The state of being obvious is obviousness
The state of being random is randomness
The state of being mad is madness
The state of being sad is
2024-07-30 09:59:41 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 10:02:15 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0404, -0.1370,  0.0715,  ...,  0.1384, -0.5771,  0.2981],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.9922, -4.0312, -0.7578,  ..., -6.7422, -1.7910, -4.0508],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0226,  0.0144, -0.0088,  ..., -0.0130,  0.0059,  0.0020],
        [-0.0024,  0.0305,  0.0071,  ...,  0.0109,  0.0067, -0.0119],
        [ 0.0090, -0.0119,  0.0356,  ...,  0.0190, -0.0186, -0.0052],
        ...,
        [-0.0028,  0.0215, -0.0008,  ...,  0.0232, -0.0156,  0.0173],
        [ 0.0047,  0.0081, -0.0182,  ...,  0.0026,  0.0321, -0.0126],
        [-0.0078, -0.0126, -0.0095,  ..., -0.0167, -0.0155,  0.0301]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.1289, -4.1797, -0.7524,  ..., -6.9375, -1.7051, -4.1719]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 10:02:16 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The state of being happy is happiness
The state of being situated is situatedness
The state of being distinct is distinctness
The state of being attractive is attractiveness
The state of being obvious is obviousness
The state of being random is randomness
The state of being mad is madness
The state of being sad is
2024-07-30 10:02:16 root INFO     [order_1_approx] starting weight calculation for The state of being situated is situatedness
The state of being happy is happiness
The state of being mad is madness
The state of being obvious is obviousness
The state of being random is randomness
The state of being distinct is distinctness
The state of being sad is sadness
The state of being attractive is
2024-07-30 10:02:16 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 10:04:49 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1516, -0.1606, -0.0112,  ...,  0.3167, -0.0137,  0.0912],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.9727, -2.3125, -3.1641,  ..., -0.6787, -4.7812, -3.0078],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0362, -0.0126,  0.0100,  ...,  0.0103,  0.0029,  0.0102],
        [-0.0226,  0.0415, -0.0010,  ..., -0.0121,  0.0252, -0.0032],
        [ 0.0029, -0.0060,  0.0275,  ...,  0.0039, -0.0129, -0.0123],
        ...,
        [ 0.0073,  0.0171, -0.0062,  ..., -0.0070,  0.0123,  0.0021],
        [ 0.0061,  0.0085,  0.0180,  ...,  0.0013,  0.0145, -0.0129],
        [-0.0010,  0.0079,  0.0099,  ...,  0.0060, -0.0130,  0.0106]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.0293, -2.3008, -3.3984,  ..., -0.4097, -5.1133, -3.0430]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 10:04:50 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The state of being situated is situatedness
The state of being happy is happiness
The state of being mad is madness
The state of being obvious is obviousness
The state of being random is randomness
The state of being distinct is distinctness
The state of being sad is sadness
The state of being attractive is
2024-07-30 10:04:51 root INFO     [order_1_approx] starting weight calculation for The state of being sad is sadness
The state of being distinct is distinctness
The state of being situated is situatedness
The state of being random is randomness
The state of being attractive is attractiveness
The state of being happy is happiness
The state of being mad is madness
The state of being obvious is
2024-07-30 10:04:51 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 10:07:25 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1201,  0.1644, -0.1039,  ...,  0.0037, -0.6138,  0.1714],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.1729, -3.3535, -0.9580,  ..., -2.6426, -4.4922,  1.1406],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0320, -0.0050, -0.0016,  ...,  0.0327, -0.0082,  0.0179],
        [-0.0101,  0.0291,  0.0010,  ...,  0.0028,  0.0106, -0.0276],
        [ 0.0189,  0.0039,  0.0092,  ..., -0.0051, -0.0180,  0.0121],
        ...,
        [ 0.0085,  0.0291,  0.0279,  ...,  0.0071, -0.0100,  0.0137],
        [ 0.0088,  0.0024, -0.0052,  ..., -0.0211,  0.0155, -0.0506],
        [ 0.0216,  0.0103, -0.0043,  ..., -0.0100, -0.0146,  0.0194]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.0964, -3.5879, -1.2891,  ..., -2.6855, -4.6914,  1.0352]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 10:07:26 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The state of being sad is sadness
The state of being distinct is distinctness
The state of being situated is situatedness
The state of being random is randomness
The state of being attractive is attractiveness
The state of being happy is happiness
The state of being mad is madness
The state of being obvious is
2024-07-30 10:07:26 root INFO     [order_1_approx] starting weight calculation for The state of being attractive is attractiveness
The state of being distinct is distinctness
The state of being mad is madness
The state of being situated is situatedness
The state of being obvious is obviousness
The state of being random is randomness
The state of being sad is sadness
The state of being happy is
2024-07-30 10:07:26 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 10:10:00 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1047, -0.1766,  0.0165,  ..., -0.2961, -0.2373,  0.0098],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.3916, -0.1235,  0.3843,  ..., -0.8105, -3.6797, -2.4883],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0262, -0.0003,  0.0067,  ..., -0.0160,  0.0060,  0.0099],
        [-0.0147,  0.0238, -0.0052,  ...,  0.0172,  0.0162, -0.0163],
        [ 0.0035, -0.0036,  0.0059,  ...,  0.0234, -0.0271, -0.0115],
        ...,
        [ 0.0086,  0.0165,  0.0192,  ...,  0.0302,  0.0077, -0.0166],
        [-0.0004,  0.0193,  0.0119,  ...,  0.0040,  0.0172, -0.0311],
        [-0.0029, -0.0023, -0.0135,  ...,  0.0043, -0.0114,  0.0376]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.3359, -0.5747, -0.0354,  ..., -0.6636, -3.9316, -2.6914]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 10:10:01 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The state of being attractive is attractiveness
The state of being distinct is distinctness
The state of being mad is madness
The state of being situated is situatedness
The state of being obvious is obviousness
The state of being random is randomness
The state of being sad is sadness
The state of being happy is
2024-07-30 10:10:02 root INFO     [order_1_approx] starting weight calculation for The state of being random is randomness
The state of being obvious is obviousness
The state of being mad is madness
The state of being sad is sadness
The state of being attractive is attractiveness
The state of being distinct is distinctness
The state of being happy is happiness
The state of being situated is
2024-07-30 10:10:02 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 10:12:35 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1777,  0.0973, -0.3359,  ...,  0.1619, -0.6099,  0.0528],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.3867, -2.6289, -0.8911,  ..., -3.7578, -4.3398, -3.6406],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0431, -0.0018,  0.0054,  ..., -0.0136,  0.0019,  0.0130],
        [-0.0154,  0.0591, -0.0005,  ...,  0.0285,  0.0032,  0.0059],
        [ 0.0123,  0.0053,  0.0206,  ..., -0.0189, -0.0155, -0.0332],
        ...,
        [-0.0052,  0.0116,  0.0098,  ...,  0.0290, -0.0119,  0.0088],
        [-0.0172,  0.0071,  0.0113,  ..., -0.0058,  0.0473, -0.0304],
        [-0.0002,  0.0002,  0.0097,  ...,  0.0215, -0.0515,  0.0455]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.1250, -2.1328, -1.1738,  ..., -3.7207, -4.4570, -3.8672]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 10:12:36 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The state of being random is randomness
The state of being obvious is obviousness
The state of being mad is madness
The state of being sad is sadness
The state of being attractive is attractiveness
The state of being distinct is distinctness
The state of being happy is happiness
The state of being situated is
2024-07-30 10:12:36 root INFO     total operator prediction time: 1241.1556992530823 seconds
2024-07-30 10:12:36 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on re+verb_reg
2024-07-30 10:12:36 root INFO     building operator re+verb_reg
2024-07-30 10:12:36 root INFO     [order_1_approx] starting weight calculation for To connect again is to reconnect
To cognize again is to recognize
To create again is to recreate
To decorate again is to redecorate
To negotiate again is to renegotiate
To adjust again is to readjust
To invest again is to reinvest
To establish again is to
2024-07-30 10:12:36 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 10:15:10 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2079,  0.3406, -0.6401,  ..., -0.0576, -0.5269,  0.1985],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.8975, -4.6406,  0.7334,  ...,  1.4404, -5.2617, -3.1523],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0461, -0.0162,  0.0100,  ...,  0.0024, -0.0121,  0.0070],
        [-0.0118,  0.0313,  0.0106,  ...,  0.0082,  0.0037, -0.0004],
        [ 0.0145,  0.0186,  0.0237,  ..., -0.0028,  0.0068,  0.0053],
        ...,
        [ 0.0249, -0.0051, -0.0123,  ...,  0.0269, -0.0028, -0.0052],
        [-0.0135,  0.0197,  0.0065,  ...,  0.0114,  0.0322, -0.0062],
        [-0.0047,  0.0014,  0.0006,  ..., -0.0025, -0.0057,  0.0399]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.5195, -4.7578,  0.9004,  ...,  1.8691, -5.4531, -3.3848]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 10:15:11 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To connect again is to reconnect
To cognize again is to recognize
To create again is to recreate
To decorate again is to redecorate
To negotiate again is to renegotiate
To adjust again is to readjust
To invest again is to reinvest
To establish again is to
2024-07-30 10:15:12 root INFO     [order_1_approx] starting weight calculation for To adjust again is to readjust
To establish again is to reestablish
To negotiate again is to renegotiate
To decorate again is to redecorate
To connect again is to reconnect
To create again is to recreate
To invest again is to reinvest
To cognize again is to
2024-07-30 10:15:12 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 10:17:46 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0514,  0.3687, -0.5996,  ...,  0.0820,  0.0313,  0.2163],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.7764, -2.1504,  2.7969,  ...,  1.3770, -3.6367, -0.6211],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0679, -0.0219,  0.0224,  ...,  0.0164,  0.0060,  0.0044],
        [ 0.0175,  0.0386, -0.0004,  ...,  0.0141, -0.0051, -0.0091],
        [-0.0064, -0.0056,  0.0285,  ..., -0.0163, -0.0025,  0.0031],
        ...,
        [ 0.0482, -0.0172, -0.0160,  ...,  0.0538,  0.0081, -0.0008],
        [-0.0019,  0.0295, -0.0179,  ..., -0.0178,  0.0014, -0.0199],
        [-0.0005, -0.0057,  0.0040,  ..., -0.0063, -0.0166,  0.0326]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.6689, -2.0762,  2.6680,  ...,  1.9102, -3.8320, -0.8135]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 10:17:47 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To adjust again is to readjust
To establish again is to reestablish
To negotiate again is to renegotiate
To decorate again is to redecorate
To connect again is to reconnect
To create again is to recreate
To invest again is to reinvest
To cognize again is to
2024-07-30 10:17:47 root INFO     [order_1_approx] starting weight calculation for To negotiate again is to renegotiate
To cognize again is to recognize
To connect again is to reconnect
To establish again is to reestablish
To decorate again is to redecorate
To invest again is to reinvest
To adjust again is to readjust
To create again is to
2024-07-30 10:17:47 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 10:20:21 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0582,  0.1870, -0.2450,  ..., -0.0084, -0.1820, -0.0195],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-2.1074, -4.3672,  1.8477,  ...,  2.9805, -3.8516, -0.9995],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0372, -0.0271,  0.0196,  ...,  0.0083, -0.0027,  0.0192],
        [ 0.0074,  0.0344,  0.0053,  ...,  0.0158, -0.0010, -0.0207],
        [ 0.0058, -0.0053,  0.0146,  ..., -0.0050,  0.0127, -0.0058],
        ...,
        [ 0.0010,  0.0022,  0.0045,  ...,  0.0200,  0.0055, -0.0060],
        [-0.0141,  0.0308, -0.0065,  ...,  0.0008,  0.0249, -0.0114],
        [-0.0085, -0.0029,  0.0026,  ..., -0.0098, -0.0158,  0.0418]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.7871, -4.3984,  1.7363,  ...,  3.1309, -4.3633, -1.2744]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 10:20:23 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To negotiate again is to renegotiate
To cognize again is to recognize
To connect again is to reconnect
To establish again is to reestablish
To decorate again is to redecorate
To invest again is to reinvest
To adjust again is to readjust
To create again is to
2024-07-30 10:20:23 root INFO     [order_1_approx] starting weight calculation for To create again is to recreate
To adjust again is to readjust
To connect again is to reconnect
To decorate again is to redecorate
To establish again is to reestablish
To invest again is to reinvest
To cognize again is to recognize
To negotiate again is to
2024-07-30 10:20:23 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 10:22:57 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1515,  0.3950, -0.3354,  ..., -0.0378, -0.4910, -0.2214],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.1885, -3.1289,  3.2266,  ..., -0.8198, -5.1172, -3.1484],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0228, -0.0044,  0.0101,  ...,  0.0003, -0.0004,  0.0181],
        [-0.0086,  0.0205,  0.0022,  ...,  0.0148,  0.0083,  0.0055],
        [-0.0009,  0.0047,  0.0128,  ..., -0.0036, -0.0016,  0.0041],
        ...,
        [ 0.0026, -0.0039,  0.0025,  ...,  0.0258,  0.0056,  0.0051],
        [-0.0026,  0.0038, -0.0150,  ...,  0.0015, -0.0049, -0.0103],
        [ 0.0060, -0.0133, -0.0017,  ..., -0.0019, -0.0103,  0.0187]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.1731, -3.1191,  3.3203,  ..., -0.7617, -5.1172, -2.9082]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 10:22:58 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To create again is to recreate
To adjust again is to readjust
To connect again is to reconnect
To decorate again is to redecorate
To establish again is to reestablish
To invest again is to reinvest
To cognize again is to recognize
To negotiate again is to
2024-07-30 10:22:58 root INFO     [order_1_approx] starting weight calculation for To cognize again is to recognize
To establish again is to reestablish
To negotiate again is to renegotiate
To invest again is to reinvest
To create again is to recreate
To decorate again is to redecorate
To adjust again is to readjust
To connect again is to
2024-07-30 10:22:58 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 10:25:31 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1968,  0.0398, -0.4834,  ...,  0.3198, -0.3936,  0.1615],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-3.0918, -3.4844,  1.6074,  ...,  3.2930, -3.7305, -3.3047],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 4.5929e-02, -2.7802e-02,  1.5671e-02,  ...,  9.5978e-03,
         -6.8665e-03,  6.4240e-03],
        [ 1.0729e-05,  2.8687e-02,  2.2888e-02,  ...,  1.0361e-02,
         -1.8188e-02, -1.4229e-03],
        [ 7.4081e-03,  8.0109e-03,  3.8788e-02,  ..., -9.4452e-03,
         -1.9169e-04,  4.2076e-03],
        ...,
        [ 9.7885e-03,  6.7940e-03,  7.7248e-03,  ...,  2.8015e-02,
          4.3259e-03, -1.4133e-03],
        [-3.5801e-03,  7.4310e-03, -9.6054e-03,  ...,  3.6526e-03,
          1.3023e-02, -7.9041e-03],
        [-3.0899e-02, -6.0806e-03, -7.4339e-04,  ..., -1.7700e-03,
         -2.6138e-02,  3.5828e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-2.8496, -3.7734,  1.6035,  ...,  3.1836, -3.5742, -3.6133]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 10:25:31 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To cognize again is to recognize
To establish again is to reestablish
To negotiate again is to renegotiate
To invest again is to reinvest
To create again is to recreate
To decorate again is to redecorate
To adjust again is to readjust
To connect again is to
2024-07-30 10:25:32 root INFO     [order_1_approx] starting weight calculation for To create again is to recreate
To cognize again is to recognize
To decorate again is to redecorate
To establish again is to reestablish
To negotiate again is to renegotiate
To invest again is to reinvest
To connect again is to reconnect
To adjust again is to
2024-07-30 10:25:32 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 10:28:02 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1125,  0.3628, -0.8926,  ..., -0.0651, -0.1219,  0.1835],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.1466, -2.7129, -1.0869,  ...,  1.9395, -4.1875, -3.4492],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0607, -0.0008,  0.0134,  ..., -0.0145,  0.0061,  0.0189],
        [ 0.0073,  0.0406, -0.0090,  ...,  0.0184, -0.0066,  0.0120],
        [ 0.0056,  0.0092,  0.0210,  ...,  0.0053,  0.0305,  0.0237],
        ...,
        [ 0.0094, -0.0120, -0.0089,  ...,  0.0595,  0.0107, -0.0103],
        [-0.0060,  0.0133, -0.0281,  ..., -0.0183,  0.0357, -0.0149],
        [-0.0011,  0.0177, -0.0033,  ..., -0.0278, -0.0096,  0.0255]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.0881, -2.8145, -0.7222,  ...,  2.3008, -3.9922, -3.1133]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 10:28:04 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To create again is to recreate
To cognize again is to recognize
To decorate again is to redecorate
To establish again is to reestablish
To negotiate again is to renegotiate
To invest again is to reinvest
To connect again is to reconnect
To adjust again is to
2024-07-30 10:28:04 root INFO     [order_1_approx] starting weight calculation for To negotiate again is to renegotiate
To adjust again is to readjust
To create again is to recreate
To decorate again is to redecorate
To cognize again is to recognize
To establish again is to reestablish
To connect again is to reconnect
To invest again is to
2024-07-30 10:28:04 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 10:30:36 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0653,  0.2634, -0.5605,  ...,  0.1010,  0.0165, -0.1155],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.6157, -2.3105,  1.2041,  ...,  0.4158, -2.8867, -3.3398],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0288,  0.0042, -0.0065,  ..., -0.0054,  0.0042,  0.0114],
        [ 0.0091,  0.0065, -0.0012,  ...,  0.0151, -0.0067,  0.0060],
        [ 0.0161,  0.0153,  0.0236,  ..., -0.0101,  0.0068,  0.0008],
        ...,
        [ 0.0159,  0.0106,  0.0035,  ...,  0.0271,  0.0108, -0.0055],
        [-0.0128,  0.0149,  0.0082,  ..., -0.0094,  0.0025, -0.0012],
        [ 0.0072, -0.0037, -0.0145,  ..., -0.0061,  0.0032,  0.0238]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.8140, -2.2637,  1.1133,  ...,  0.4685, -3.2285, -3.3379]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 10:30:37 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To negotiate again is to renegotiate
To adjust again is to readjust
To create again is to recreate
To decorate again is to redecorate
To cognize again is to recognize
To establish again is to reestablish
To connect again is to reconnect
To invest again is to
2024-07-30 10:30:37 root INFO     [order_1_approx] starting weight calculation for To connect again is to reconnect
To adjust again is to readjust
To establish again is to reestablish
To negotiate again is to renegotiate
To invest again is to reinvest
To create again is to recreate
To cognize again is to recognize
To decorate again is to
2024-07-30 10:30:38 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 10:33:10 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0918, -0.1257, -0.3569,  ...,  0.1731, -0.3772,  0.1320],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.9043, -3.9668,  1.1455,  ...,  1.9365, -5.7500, -1.6084],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0375,  0.0017,  0.0059,  ..., -0.0083, -0.0074,  0.0114],
        [-0.0133,  0.0276,  0.0070,  ...,  0.0030, -0.0086, -0.0010],
        [ 0.0024, -0.0013,  0.0202,  ..., -0.0048, -0.0004,  0.0004],
        ...,
        [-0.0017, -0.0018,  0.0055,  ...,  0.0320, -0.0022, -0.0012],
        [ 0.0085,  0.0003, -0.0101,  ..., -0.0074,  0.0046,  0.0017],
        [-0.0010,  0.0062,  0.0056,  ..., -0.0060, -0.0155,  0.0188]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.8848, -3.7461,  1.0381,  ...,  2.0488, -5.7500, -1.4980]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 10:33:11 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To connect again is to reconnect
To adjust again is to readjust
To establish again is to reestablish
To negotiate again is to renegotiate
To invest again is to reinvest
To create again is to recreate
To cognize again is to recognize
To decorate again is to
2024-07-30 10:33:11 root INFO     total operator prediction time: 1234.8449068069458 seconds
2024-07-30 10:33:11 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on un+adj_reg
2024-07-30 10:33:11 root INFO     building operator un+adj_reg
2024-07-30 10:33:11 root INFO     [order_1_approx] starting weight calculation for The opposite of acceptable is unacceptable
The opposite of aware is unaware
The opposite of interrupted is uninterrupted
The opposite of pleasant is unpleasant
The opposite of restricted is unrestricted
The opposite of healthy is unhealthy
The opposite of reasonable is unreasonable
The opposite of employed is
2024-07-30 10:33:11 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 10:35:45 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3606, -0.0066, -0.3530,  ...,  0.0506, -0.4678,  0.0469],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.3193, -1.5859,  0.2612,  ..., -0.0278,  0.3643, -2.1406],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0505, -0.0256,  0.0019,  ...,  0.0282, -0.0258,  0.0098],
        [-0.0395,  0.0414,  0.0073,  ...,  0.0083,  0.0727, -0.0024],
        [ 0.0045,  0.0072,  0.0259,  ..., -0.0029,  0.0020, -0.0089],
        ...,
        [-0.0031,  0.0378,  0.0016,  ...,  0.0173, -0.0015, -0.0099],
        [-0.0041,  0.0105,  0.0077,  ...,  0.0063,  0.0663, -0.0108],
        [-0.0094, -0.0268,  0.0037,  ..., -0.0098,  0.0105,  0.0175]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.9907, -1.9980,  0.1392,  ...,  0.0363,  0.1338, -2.3066]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 10:35:47 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of acceptable is unacceptable
The opposite of aware is unaware
The opposite of interrupted is uninterrupted
The opposite of pleasant is unpleasant
The opposite of restricted is unrestricted
The opposite of healthy is unhealthy
The opposite of reasonable is unreasonable
The opposite of employed is
2024-07-30 10:35:47 root INFO     [order_1_approx] starting weight calculation for The opposite of reasonable is unreasonable
The opposite of interrupted is uninterrupted
The opposite of healthy is unhealthy
The opposite of acceptable is unacceptable
The opposite of employed is unemployed
The opposite of pleasant is unpleasant
The opposite of restricted is unrestricted
The opposite of aware is
2024-07-30 10:35:47 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 10:38:21 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2935,  0.3022, -0.4810,  ..., -0.2183, -0.0308,  0.4194],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.2969, -1.9590,  2.4629,  ..., -2.5703, -1.1621, -1.2451],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0345, -0.0068, -0.0051,  ...,  0.0029, -0.0157, -0.0094],
        [-0.0134,  0.0475, -0.0012,  ...,  0.0212,  0.0058, -0.0022],
        [-0.0285, -0.0082,  0.0506,  ...,  0.0158, -0.0303, -0.0013],
        ...,
        [ 0.0019,  0.0215, -0.0096,  ...,  0.0164,  0.0103, -0.0045],
        [-0.0145, -0.0043,  0.0127,  ...,  0.0231,  0.0405, -0.0202],
        [ 0.0100,  0.0195, -0.0247,  ...,  0.0184, -0.0014,  0.0248]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.4551, -1.9043,  2.0195,  ..., -2.2305, -1.3428, -1.1572]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 10:38:22 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of reasonable is unreasonable
The opposite of interrupted is uninterrupted
The opposite of healthy is unhealthy
The opposite of acceptable is unacceptable
The opposite of employed is unemployed
The opposite of pleasant is unpleasant
The opposite of restricted is unrestricted
The opposite of aware is
2024-07-30 10:38:23 root INFO     [order_1_approx] starting weight calculation for The opposite of employed is unemployed
The opposite of reasonable is unreasonable
The opposite of restricted is unrestricted
The opposite of healthy is unhealthy
The opposite of interrupted is uninterrupted
The opposite of aware is unaware
The opposite of pleasant is unpleasant
The opposite of acceptable is
2024-07-30 10:38:23 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 10:40:56 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0531,  0.4028, -0.1681,  ..., -0.0479, -0.4739,  0.2100],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.1504, -2.3086,  1.6973,  ..., -0.0654, -2.8887, -2.2617],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0306, -0.0233, -0.0095,  ...,  0.0245, -0.0092,  0.0158],
        [-0.0073,  0.0468, -0.0284,  ...,  0.0051,  0.0100, -0.0050],
        [-0.0036, -0.0065, -0.0019,  ...,  0.0127, -0.0293,  0.0041],
        ...,
        [-0.0005,  0.0530, -0.0016,  ...,  0.0393,  0.0344, -0.0313],
        [-0.0265, -0.0049,  0.0079,  ...,  0.0265,  0.0245, -0.0135],
        [-0.0013,  0.0086, -0.0125,  ...,  0.0042, -0.0159, -0.0015]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.9395, -2.6758,  1.0635,  ...,  0.3601, -2.4785, -2.0605]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 10:40:57 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of employed is unemployed
The opposite of reasonable is unreasonable
The opposite of restricted is unrestricted
The opposite of healthy is unhealthy
The opposite of interrupted is uninterrupted
The opposite of aware is unaware
The opposite of pleasant is unpleasant
The opposite of acceptable is
2024-07-30 10:40:58 root INFO     [order_1_approx] starting weight calculation for The opposite of reasonable is unreasonable
The opposite of acceptable is unacceptable
The opposite of aware is unaware
The opposite of employed is unemployed
The opposite of restricted is unrestricted
The opposite of pleasant is unpleasant
The opposite of healthy is unhealthy
The opposite of interrupted is
2024-07-30 10:40:58 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 10:43:31 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0906,  0.1787, -0.2213,  ..., -0.1851, -0.3459,  0.5161],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.8535,  0.2295,  0.2251,  ...,  0.1096, -2.4746, -1.2051],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0364,  0.0131, -0.0205,  ...,  0.0236, -0.0273,  0.0218],
        [ 0.0003,  0.0381,  0.0062,  ...,  0.0169,  0.0009, -0.0246],
        [ 0.0156, -0.0344,  0.0276,  ..., -0.0004, -0.0107,  0.0081],
        ...,
        [-0.0138,  0.0428,  0.0006,  ...,  0.0155,  0.0104, -0.0130],
        [-0.0131, -0.0056,  0.0034,  ...,  0.0166,  0.0339,  0.0099],
        [-0.0054,  0.0028,  0.0066,  ..., -0.0104,  0.0219,  0.0330]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.3047,  0.0232,  0.7080,  ...,  0.1234, -2.8281, -0.9380]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 10:43:33 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of reasonable is unreasonable
The opposite of acceptable is unacceptable
The opposite of aware is unaware
The opposite of employed is unemployed
The opposite of restricted is unrestricted
The opposite of pleasant is unpleasant
The opposite of healthy is unhealthy
The opposite of interrupted is
2024-07-30 10:43:33 root INFO     [order_1_approx] starting weight calculation for The opposite of interrupted is uninterrupted
The opposite of reasonable is unreasonable
The opposite of aware is unaware
The opposite of acceptable is unacceptable
The opposite of employed is unemployed
The opposite of restricted is unrestricted
The opposite of pleasant is unpleasant
The opposite of healthy is
2024-07-30 10:43:33 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 10:46:07 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1533, -0.2072, -0.0665,  ..., -0.2078,  0.0012,  0.1274],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.3164, -1.4902, -0.4839,  ..., -1.9717, -0.7676, -1.0752],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0436, -0.0246, -0.0051,  ...,  0.0067, -0.0385,  0.0220],
        [-0.0061,  0.0186,  0.0133,  ...,  0.0302,  0.0364, -0.0134],
        [ 0.0005, -0.0341,  0.0067,  ...,  0.0118, -0.0427,  0.0173],
        ...,
        [-0.0017,  0.0401,  0.0150,  ..., -0.0097,  0.0304, -0.0154],
        [-0.0089, -0.0184,  0.0212,  ..., -0.0093,  0.0057, -0.0291],
        [-0.0114,  0.0138,  0.0099,  ...,  0.0045,  0.0164, -0.0186]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.2617, -1.4727,  0.2935,  ..., -1.8066, -0.8037, -1.1719]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 10:46:09 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of interrupted is uninterrupted
The opposite of reasonable is unreasonable
The opposite of aware is unaware
The opposite of acceptable is unacceptable
The opposite of employed is unemployed
The opposite of restricted is unrestricted
The opposite of pleasant is unpleasant
The opposite of healthy is
2024-07-30 10:46:09 root INFO     [order_1_approx] starting weight calculation for The opposite of interrupted is uninterrupted
The opposite of healthy is unhealthy
The opposite of reasonable is unreasonable
The opposite of employed is unemployed
The opposite of pleasant is unpleasant
The opposite of aware is unaware
The opposite of acceptable is unacceptable
The opposite of restricted is
2024-07-30 10:46:09 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 10:48:43 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2362,  0.0834, -0.5596,  ..., -0.0757,  0.2522,  0.2854],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.0234,  0.1909,  1.9805,  ...,  0.6636, -1.6934, -1.5732],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0448, -0.0147, -0.0159,  ...,  0.0122,  0.0023,  0.0043],
        [-0.0284,  0.0300,  0.0199,  ..., -0.0109,  0.0177, -0.0119],
        [ 0.0012,  0.0081,  0.0055,  ..., -0.0020,  0.0031, -0.0122],
        ...,
        [ 0.0208,  0.0302,  0.0140,  ...,  0.0053,  0.0145, -0.0045],
        [-0.0064, -0.0176,  0.0039,  ...,  0.0152,  0.0163,  0.0079],
        [-0.0223,  0.0142, -0.0043,  ...,  0.0048,  0.0004,  0.0312]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.3828,  0.1727,  1.9668,  ...,  0.3623, -1.9316, -1.4629]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 10:48:44 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of interrupted is uninterrupted
The opposite of healthy is unhealthy
The opposite of reasonable is unreasonable
The opposite of employed is unemployed
The opposite of pleasant is unpleasant
The opposite of aware is unaware
The opposite of acceptable is unacceptable
The opposite of restricted is
2024-07-30 10:48:45 root INFO     [order_1_approx] starting weight calculation for The opposite of healthy is unhealthy
The opposite of reasonable is unreasonable
The opposite of employed is unemployed
The opposite of acceptable is unacceptable
The opposite of restricted is unrestricted
The opposite of interrupted is uninterrupted
The opposite of aware is unaware
The opposite of pleasant is
2024-07-30 10:48:45 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 10:51:18 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0394, -0.1498, -0.0907,  ..., -0.0348, -0.3137,  0.0876],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.5430, -0.2957, -3.2734,  ..., -0.0303, -2.4824, -0.6460],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0437, -0.0223,  0.0307,  ...,  0.0135, -0.0065,  0.0385],
        [-0.0209,  0.0460,  0.0125,  ...,  0.0105,  0.0279,  0.0210],
        [ 0.0016, -0.0014,  0.0226,  ...,  0.0317, -0.0025, -0.0110],
        ...,
        [ 0.0182, -0.0015, -0.0040,  ...,  0.0231,  0.0083, -0.0158],
        [-0.0034, -0.0135,  0.0181,  ..., -0.0029,  0.0186, -0.0204],
        [-0.0119,  0.0128, -0.0367,  ..., -0.0037, -0.0281, -0.0142]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.2090, -0.6094, -2.9199,  ...,  0.1443, -2.3477, -1.1035]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 10:51:20 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of healthy is unhealthy
The opposite of reasonable is unreasonable
The opposite of employed is unemployed
The opposite of acceptable is unacceptable
The opposite of restricted is unrestricted
The opposite of interrupted is uninterrupted
The opposite of aware is unaware
The opposite of pleasant is
2024-07-30 10:51:20 root INFO     [order_1_approx] starting weight calculation for The opposite of restricted is unrestricted
The opposite of interrupted is uninterrupted
The opposite of acceptable is unacceptable
The opposite of aware is unaware
The opposite of healthy is unhealthy
The opposite of pleasant is unpleasant
The opposite of employed is unemployed
The opposite of reasonable is
2024-07-30 10:51:20 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 10:53:54 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0608,  0.1448, -0.3311,  ..., -0.1659, -0.0536,  0.0991],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.2734, -1.4980, -0.3555,  ..., -1.5742, -3.4062, -4.4609],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 6.8298e-02, -1.8188e-02,  1.0460e-02,  ...,  2.7618e-03,
         -6.5002e-03,  1.6632e-02],
        [-4.4060e-03,  3.4119e-02, -1.9394e-02,  ...,  4.8256e-03,
          9.6512e-03,  1.1490e-02],
        [-1.8280e-02,  6.1455e-03,  4.2511e-02,  ...,  2.9510e-02,
         -3.9246e-02,  9.9182e-05],
        ...,
        [-2.6169e-03,  1.8097e-02,  8.4229e-03,  ...,  2.0386e-02,
          1.7838e-02,  1.9264e-04],
        [ 4.3030e-03,  3.4912e-02,  4.5074e-02,  ...,  1.0788e-02,
          2.4139e-02, -3.5858e-02],
        [ 6.3553e-03,  1.3065e-03, -1.0078e-02,  ..., -2.8725e-03,
         -1.4061e-02,  2.2263e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.9746, -1.5605, -0.0281,  ..., -1.1318, -3.3633, -4.4219]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 10:53:55 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of restricted is unrestricted
The opposite of interrupted is uninterrupted
The opposite of acceptable is unacceptable
The opposite of aware is unaware
The opposite of healthy is unhealthy
The opposite of pleasant is unpleasant
The opposite of employed is unemployed
The opposite of reasonable is
2024-07-30 10:53:55 root INFO     total operator prediction time: 1244.0581891536713 seconds
2024-07-30 10:53:55 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on verb+able_reg
2024-07-30 10:53:55 root INFO     building operator verb+able_reg
2024-07-30 10:53:56 root INFO     [order_1_approx] starting weight calculation for If you can accept something, that thing is acceptable
If you can learn something, that thing is learnable
If you can discover something, that thing is discoverable
If you can adapt something, that thing is adaptable
If you can maintain something, that thing is maintainable
If you can admire something, that thing is admirable
If you can execute something, that thing is executable
If you can download something, that thing is
2024-07-30 10:53:56 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 10:56:29 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1836,  0.0296, -0.1978,  ...,  0.2400, -0.2126, -0.1844],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.7148, -1.9258, -0.1958,  ..., -3.7930, -7.9453, -0.9160],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0134, -0.0168,  0.0220,  ...,  0.0071,  0.0267,  0.0171],
        [-0.0249,  0.0167,  0.0257,  ...,  0.0131, -0.0021,  0.0006],
        [ 0.0265, -0.0185,  0.0172,  ...,  0.0177, -0.0204, -0.0149],
        ...,
        [ 0.0273,  0.0236,  0.0248,  ...,  0.0475,  0.0233,  0.0091],
        [ 0.0070, -0.0377, -0.0114,  ..., -0.0049, -0.0061, -0.0121],
        [ 0.0153, -0.0013, -0.0077,  ..., -0.0116, -0.0218,  0.0188]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.9028, -2.0527, -0.1021,  ..., -3.5352, -7.0898, -1.2100]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 10:56:30 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you can accept something, that thing is acceptable
If you can learn something, that thing is learnable
If you can discover something, that thing is discoverable
If you can adapt something, that thing is adaptable
If you can maintain something, that thing is maintainable
If you can admire something, that thing is admirable
If you can execute something, that thing is executable
If you can download something, that thing is
2024-07-30 10:56:30 root INFO     [order_1_approx] starting weight calculation for If you can admire something, that thing is admirable
If you can adapt something, that thing is adaptable
If you can discover something, that thing is discoverable
If you can maintain something, that thing is maintainable
If you can download something, that thing is downloadable
If you can learn something, that thing is learnable
If you can execute something, that thing is executable
If you can accept something, that thing is
2024-07-30 10:56:30 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 10:59:03 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2322,  0.4683, -0.3149,  ...,  0.3552, -0.2603,  0.2012],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.6611,  1.0479, -3.2441,  ..., -2.4551, -9.2031, -0.1250],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0490, -0.0064,  0.0030,  ...,  0.0021, -0.0262, -0.0173],
        [-0.0077,  0.0458,  0.0040,  ...,  0.0070, -0.0252, -0.0233],
        [ 0.0187, -0.0113,  0.0148,  ..., -0.0192,  0.0227,  0.0105],
        ...,
        [ 0.0055,  0.0164,  0.0152,  ...,  0.0502,  0.0129, -0.0059],
        [ 0.0236,  0.0291, -0.0202,  ..., -0.0338,  0.0326,  0.0005],
        [-0.0103, -0.0020,  0.0046,  ..., -0.0153, -0.0145,  0.0130]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.7256,  1.0117, -2.8320,  ..., -2.3477, -9.0625, -0.3491]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 10:59:04 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you can admire something, that thing is admirable
If you can adapt something, that thing is adaptable
If you can discover something, that thing is discoverable
If you can maintain something, that thing is maintainable
If you can download something, that thing is downloadable
If you can learn something, that thing is learnable
If you can execute something, that thing is executable
If you can accept something, that thing is
2024-07-30 10:59:05 root INFO     [order_1_approx] starting weight calculation for If you can learn something, that thing is learnable
If you can maintain something, that thing is maintainable
If you can discover something, that thing is discoverable
If you can accept something, that thing is acceptable
If you can admire something, that thing is admirable
If you can download something, that thing is downloadable
If you can adapt something, that thing is adaptable
If you can execute something, that thing is
2024-07-30 10:59:05 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 11:01:38 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1450,  0.3086, -0.3015,  ...,  0.1364, -0.0230,  0.0404],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.3594, -1.0947,  1.2246,  ..., -2.2773, -8.2344, -4.5078],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0339, -0.0084, -0.0017,  ...,  0.0150,  0.0035,  0.0131],
        [-0.0138,  0.0579, -0.0088,  ...,  0.0005, -0.0076, -0.0183],
        [ 0.0163,  0.0038,  0.0242,  ..., -0.0086,  0.0111,  0.0057],
        ...,
        [ 0.0047,  0.0091, -0.0147,  ...,  0.0368,  0.0087, -0.0191],
        [ 0.0144, -0.0238, -0.0023,  ..., -0.0091,  0.0238, -0.0026],
        [ 0.0167, -0.0369,  0.0090,  ..., -0.0082, -0.0098,  0.0226]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.1758, -0.7471,  1.1396,  ..., -2.2031, -8.2500, -4.3438]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 11:01:39 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you can learn something, that thing is learnable
If you can maintain something, that thing is maintainable
If you can discover something, that thing is discoverable
If you can accept something, that thing is acceptable
If you can admire something, that thing is admirable
If you can download something, that thing is downloadable
If you can adapt something, that thing is adaptable
If you can execute something, that thing is
2024-07-30 11:01:40 root INFO     [order_1_approx] starting weight calculation for If you can download something, that thing is downloadable
If you can accept something, that thing is acceptable
If you can adapt something, that thing is adaptable
If you can maintain something, that thing is maintainable
If you can discover something, that thing is discoverable
If you can execute something, that thing is executable
If you can admire something, that thing is admirable
If you can learn something, that thing is
2024-07-30 11:01:40 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 11:04:13 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0147,  0.1906,  0.1965,  ..., -0.2185, -0.1851,  0.0271],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.9248, -1.0820,  1.1104,  ..., -0.8511, -8.9219, -4.4648],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0292, -0.0039, -0.0014,  ...,  0.0058,  0.0168,  0.0100],
        [-0.0079,  0.0338, -0.0068,  ...,  0.0086,  0.0074,  0.0011],
        [ 0.0081, -0.0151,  0.0323,  ...,  0.0048, -0.0100,  0.0029],
        ...,
        [ 0.0179,  0.0111,  0.0139,  ...,  0.0298,  0.0110, -0.0223],
        [ 0.0133,  0.0027, -0.0021,  ..., -0.0026,  0.0293, -0.0142],
        [-0.0121, -0.0065,  0.0030,  ...,  0.0040, -0.0078, -0.0087]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.1270, -0.8760,  1.0439,  ..., -1.1924, -8.7969, -4.4648]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 11:04:14 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you can download something, that thing is downloadable
If you can accept something, that thing is acceptable
If you can adapt something, that thing is adaptable
If you can maintain something, that thing is maintainable
If you can discover something, that thing is discoverable
If you can execute something, that thing is executable
If you can admire something, that thing is admirable
If you can learn something, that thing is
2024-07-30 11:04:14 root INFO     [order_1_approx] starting weight calculation for If you can admire something, that thing is admirable
If you can learn something, that thing is learnable
If you can download something, that thing is downloadable
If you can accept something, that thing is acceptable
If you can execute something, that thing is executable
If you can discover something, that thing is discoverable
If you can maintain something, that thing is maintainable
If you can adapt something, that thing is
2024-07-30 11:04:14 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 11:06:47 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1362,  0.6372, -0.3687,  ..., -0.2063,  0.0056,  0.6318],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.8164,  0.2046, -2.2715,  ..., -1.0527, -8.8828, -0.7773],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0180, -0.0025, -0.0161,  ...,  0.0155,  0.0203,  0.0053],
        [-0.0063,  0.0291,  0.0096,  ..., -0.0106, -0.0060, -0.0012],
        [-0.0071, -0.0105,  0.0267,  ...,  0.0171,  0.0067, -0.0182],
        ...,
        [ 0.0223,  0.0187,  0.0046,  ...,  0.0327,  0.0007,  0.0076],
        [ 0.0259,  0.0163,  0.0057,  ..., -0.0001,  0.0081, -0.0100],
        [-0.0063, -0.0212,  0.0034,  ..., -0.0042, -0.0261,  0.0118]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.5396,  0.1467, -2.3809,  ..., -1.4316, -8.7656, -0.6094]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 11:06:48 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you can admire something, that thing is admirable
If you can learn something, that thing is learnable
If you can download something, that thing is downloadable
If you can accept something, that thing is acceptable
If you can execute something, that thing is executable
If you can discover something, that thing is discoverable
If you can maintain something, that thing is maintainable
If you can adapt something, that thing is
2024-07-30 11:06:48 root INFO     [order_1_approx] starting weight calculation for If you can download something, that thing is downloadable
If you can discover something, that thing is discoverable
If you can accept something, that thing is acceptable
If you can learn something, that thing is learnable
If you can admire something, that thing is admirable
If you can execute something, that thing is executable
If you can adapt something, that thing is adaptable
If you can maintain something, that thing is
2024-07-30 11:06:49 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 11:09:22 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4575,  0.3462, -0.3093,  ...,  0.0685,  0.0188,  0.0065],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.8584, -0.0947, -3.2207,  ..., -5.2852, -6.4375, -1.0547],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0253, -0.0099, -0.0115,  ...,  0.0293,  0.0017, -0.0105],
        [-0.0091,  0.0384, -0.0013,  ..., -0.0152,  0.0307,  0.0053],
        [ 0.0060, -0.0113,  0.0175,  ..., -0.0025,  0.0134, -0.0009],
        ...,
        [ 0.0384,  0.0223,  0.0192,  ...,  0.0295,  0.0041,  0.0031],
        [ 0.0289,  0.0173, -0.0046,  ..., -0.0258,  0.0111, -0.0167],
        [-0.0108,  0.0026,  0.0155,  ..., -0.0102, -0.0077,  0.0027]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.8501, -0.3179, -3.2656,  ..., -5.6523, -6.4023, -0.8945]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 11:09:23 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you can download something, that thing is downloadable
If you can discover something, that thing is discoverable
If you can accept something, that thing is acceptable
If you can learn something, that thing is learnable
If you can admire something, that thing is admirable
If you can execute something, that thing is executable
If you can adapt something, that thing is adaptable
If you can maintain something, that thing is
2024-07-30 11:09:23 root INFO     [order_1_approx] starting weight calculation for If you can download something, that thing is downloadable
If you can admire something, that thing is admirable
If you can maintain something, that thing is maintainable
If you can learn something, that thing is learnable
If you can adapt something, that thing is adaptable
If you can execute something, that thing is executable
If you can accept something, that thing is acceptable
If you can discover something, that thing is
2024-07-30 11:09:23 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 11:11:57 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2216,  0.2275, -0.1874,  ..., -0.0084, -0.0892,  0.1182],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.2295, -1.8906,  0.7881,  ..., -1.9961, -7.3281,  1.5078],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 3.4180e-02, -6.1798e-03,  1.5511e-02,  ...,  1.5167e-02,
          1.5137e-02,  2.9892e-02],
        [-1.5381e-02,  4.3152e-02,  1.9424e-02,  ...,  8.3618e-03,
         -2.2278e-02, -9.4452e-03],
        [-1.5793e-03, -2.2339e-02,  4.0070e-02,  ...,  9.7733e-03,
         -1.2493e-03,  2.3460e-04],
        ...,
        [-8.1253e-04,  2.9327e-02,  9.6359e-03,  ...,  3.1616e-02,
          2.0561e-03,  9.3460e-05],
        [ 6.5384e-03,  4.2725e-03, -7.3738e-03,  ..., -1.1147e-02,
          3.4454e-02,  7.7057e-03],
        [ 7.3242e-04, -7.0953e-04,  1.3855e-02,  ..., -1.4687e-04,
         -3.0960e-02,  1.2711e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.0895, -2.1758,  0.7310,  ..., -2.0410, -7.3477,  1.5596]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 11:11:58 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you can download something, that thing is downloadable
If you can admire something, that thing is admirable
If you can maintain something, that thing is maintainable
If you can learn something, that thing is learnable
If you can adapt something, that thing is adaptable
If you can execute something, that thing is executable
If you can accept something, that thing is acceptable
If you can discover something, that thing is
2024-07-30 11:11:58 root INFO     [order_1_approx] starting weight calculation for If you can adapt something, that thing is adaptable
If you can maintain something, that thing is maintainable
If you can learn something, that thing is learnable
If you can download something, that thing is downloadable
If you can execute something, that thing is executable
If you can accept something, that thing is acceptable
If you can discover something, that thing is discoverable
If you can admire something, that thing is
2024-07-30 11:11:58 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 11:14:31 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1741,  0.4990,  0.0651,  ...,  0.2354, -0.0841,  0.4846],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.8945,  0.0312, -3.3926,  ..., -2.4844, -6.6758, -0.7197],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0201,  0.0029, -0.0035,  ...,  0.0144, -0.0035,  0.0104],
        [-0.0106,  0.0218,  0.0074,  ..., -0.0009,  0.0078, -0.0045],
        [ 0.0131, -0.0164,  0.0203,  ...,  0.0002,  0.0066,  0.0037],
        ...,
        [ 0.0064,  0.0157, -0.0050,  ...,  0.0042,  0.0134, -0.0025],
        [-0.0002,  0.0073,  0.0198,  ..., -0.0065,  0.0135,  0.0147],
        [-0.0082, -0.0005, -0.0068,  ..., -0.0056,  0.0057,  0.0015]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.6445,  0.1700, -3.5117,  ..., -2.2441, -6.7148, -0.6606]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 11:14:32 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you can adapt something, that thing is adaptable
If you can maintain something, that thing is maintainable
If you can learn something, that thing is learnable
If you can download something, that thing is downloadable
If you can execute something, that thing is executable
If you can accept something, that thing is acceptable
If you can discover something, that thing is discoverable
If you can admire something, that thing is
2024-07-30 11:14:32 root INFO     total operator prediction time: 1237.0813007354736 seconds
2024-07-30 11:14:32 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on verb+tion_irreg
2024-07-30 11:14:32 root INFO     building operator verb+tion_irreg
2024-07-30 11:14:32 root INFO     [order_1_approx] starting weight calculation for To admire results in admiration
To minimize results in minimization
To expire results in expiration
To customize results in customization
To accuse results in accusation
To compute results in computation
To observe results in observation
To globalize results in
2024-07-30 11:14:32 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 11:17:05 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.3206,  0.0732, -0.6064,  ..., -0.2378, -0.2510, -0.1208],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.0508, -2.8320,  1.2305,  ...,  1.0938, -3.1992, -2.2383],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0594,  0.0203,  0.0072,  ..., -0.0130, -0.0144,  0.0153],
        [-0.0146,  0.0254,  0.0069,  ...,  0.0313,  0.0054,  0.0107],
        [-0.0031,  0.0053,  0.0369,  ..., -0.0023,  0.0023,  0.0011],
        ...,
        [-0.0130, -0.0172, -0.0172,  ...,  0.0655,  0.0043,  0.0033],
        [ 0.0005,  0.0006,  0.0016,  ...,  0.0126,  0.0415,  0.0045],
        [-0.0112, -0.0266, -0.0011,  ...,  0.0276, -0.0188,  0.0486]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.2576, -2.5000,  1.1553,  ...,  1.5195, -3.1934, -2.1094]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 11:17:06 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To admire results in admiration
To minimize results in minimization
To expire results in expiration
To customize results in customization
To accuse results in accusation
To compute results in computation
To observe results in observation
To globalize results in
2024-07-30 11:17:07 root INFO     [order_1_approx] starting weight calculation for To expire results in expiration
To minimize results in minimization
To accuse results in accusation
To admire results in admiration
To compute results in computation
To globalize results in globalization
To customize results in customization
To observe results in
2024-07-30 11:17:07 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 11:19:39 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0392,  0.5566, -0.3945,  ..., -0.2380, -0.2661, -0.0406],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.2461, -4.2578,  2.1836,  ...,  1.0869, -1.7832, -0.9712],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0692,  0.0121, -0.0024,  ...,  0.0051,  0.0069,  0.0090],
        [-0.0166,  0.0565,  0.0096,  ...,  0.0254,  0.0011,  0.0105],
        [ 0.0034, -0.0116,  0.0536,  ...,  0.0155, -0.0136, -0.0052],
        ...,
        [-0.0046,  0.0093,  0.0039,  ...,  0.0626,  0.0002,  0.0024],
        [ 0.0081,  0.0165,  0.0136,  ...,  0.0147,  0.0541, -0.0084],
        [ 0.0039,  0.0026, -0.0146,  ...,  0.0298, -0.0171,  0.0449]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.1738, -4.3633,  1.5566,  ...,  0.8501, -2.4453, -0.8247]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 11:19:40 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To expire results in expiration
To minimize results in minimization
To accuse results in accusation
To admire results in admiration
To compute results in computation
To globalize results in globalization
To customize results in customization
To observe results in
2024-07-30 11:19:40 root INFO     [order_1_approx] starting weight calculation for To minimize results in minimization
To accuse results in accusation
To globalize results in globalization
To admire results in admiration
To observe results in observation
To compute results in computation
To customize results in customization
To expire results in
2024-07-30 11:19:41 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 11:22:13 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2378,  0.1580, -0.7852,  ..., -0.3774, -0.0023, -0.1090],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.1133, -3.7148,  0.7476,  ...,  0.3931, -2.8203, -1.9883],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0715,  0.0256, -0.0304,  ..., -0.0172, -0.0247,  0.0110],
        [-0.0065,  0.0168,  0.0019,  ...,  0.0443,  0.0203,  0.0100],
        [-0.0012,  0.0047,  0.0334,  ..., -0.0238, -0.0109, -0.0015],
        ...,
        [ 0.0275,  0.0352,  0.0079,  ...,  0.0820, -0.0199,  0.0058],
        [ 0.0075, -0.0058,  0.0213,  ...,  0.0326,  0.0505,  0.0054],
        [ 0.0027, -0.0210, -0.0154,  ...,  0.0304, -0.0250,  0.0840]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.0773, -3.2188,  0.4873,  ...,  0.6587, -3.2969, -1.4980]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 11:22:14 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To minimize results in minimization
To accuse results in accusation
To globalize results in globalization
To admire results in admiration
To observe results in observation
To compute results in computation
To customize results in customization
To expire results in
2024-07-30 11:22:14 root INFO     [order_1_approx] starting weight calculation for To minimize results in minimization
To globalize results in globalization
To expire results in expiration
To compute results in computation
To accuse results in accusation
To customize results in customization
To observe results in observation
To admire results in
2024-07-30 11:22:15 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 11:24:47 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1674,  0.5352, -0.0315,  ...,  0.1128, -0.1277,  0.5269],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.8828, -2.2109,  0.0337,  ...,  1.3896, -1.8047, -0.5977],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0279, -0.0023, -0.0191,  ..., -0.0040, -0.0029, -0.0025],
        [ 0.0059,  0.0193,  0.0034,  ..., -0.0044,  0.0023,  0.0266],
        [ 0.0038, -0.0192,  0.0275,  ...,  0.0060, -0.0058, -0.0033],
        ...,
        [ 0.0107,  0.0034, -0.0051,  ..., -0.0031,  0.0088, -0.0071],
        [-0.0039,  0.0012,  0.0056,  ...,  0.0204,  0.0198, -0.0034],
        [-0.0128, -0.0030, -0.0191,  ...,  0.0071, -0.0206,  0.0403]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.5898, -2.1777, -0.3027,  ...,  1.4727, -1.9551, -0.4937]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 11:24:48 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To minimize results in minimization
To globalize results in globalization
To expire results in expiration
To compute results in computation
To accuse results in accusation
To customize results in customization
To observe results in observation
To admire results in
2024-07-30 11:24:48 root INFO     [order_1_approx] starting weight calculation for To minimize results in minimization
To accuse results in accusation
To globalize results in globalization
To admire results in admiration
To observe results in observation
To expire results in expiration
To compute results in computation
To customize results in
2024-07-30 11:24:48 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 11:27:20 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2751, -0.1938, -0.6177,  ..., -0.1046, -0.2179,  0.0893],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.1084, -2.5859,  0.2920,  ...,  1.4316, -3.5859, -0.5361],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0415, -0.0064,  0.0103,  ..., -0.0012,  0.0038,  0.0288],
        [-0.0246,  0.0235, -0.0057,  ...,  0.0291,  0.0043,  0.0045],
        [-0.0088, -0.0071,  0.0229,  ..., -0.0019,  0.0104, -0.0005],
        ...,
        [-0.0082,  0.0069, -0.0091,  ...,  0.0527,  0.0032, -0.0049],
        [ 0.0009,  0.0153, -0.0086,  ...,  0.0101,  0.0409, -0.0186],
        [-0.0005, -0.0008, -0.0025,  ...,  0.0229, -0.0282,  0.0434]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.9863, -2.2520,  0.2808,  ...,  1.6191, -3.5195, -0.2258]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 11:27:21 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To minimize results in minimization
To accuse results in accusation
To globalize results in globalization
To admire results in admiration
To observe results in observation
To expire results in expiration
To compute results in computation
To customize results in
2024-07-30 11:27:22 root INFO     [order_1_approx] starting weight calculation for To accuse results in accusation
To customize results in customization
To expire results in expiration
To observe results in observation
To globalize results in globalization
To minimize results in minimization
To admire results in admiration
To compute results in
2024-07-30 11:27:22 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 11:29:54 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2026,  0.0107,  0.1506,  ..., -0.0500, -0.2421,  0.0549],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.2715, -2.0059,  0.9805,  ...,  1.0410, -1.6562, -0.7231],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 5.0720e-02,  1.3283e-02,  2.0905e-02,  ...,  2.7466e-03,
          9.1858e-03,  6.3095e-03],
        [ 1.4572e-03,  1.5488e-02, -2.1332e-02,  ...,  1.7273e-02,
          3.2444e-03,  1.0818e-02],
        [ 1.1932e-02,  9.9030e-03,  3.9032e-02,  ..., -1.1200e-02,
         -1.3153e-02, -1.3977e-02],
        ...,
        [-1.1169e-02, -1.0529e-02, -1.7624e-02,  ...,  3.9764e-02,
         -6.6528e-03, -1.0590e-02],
        [ 8.5831e-05,  3.2959e-02,  2.6886e-02,  ...,  1.4534e-02,
          3.1982e-02, -8.5144e-03],
        [-1.0826e-02, -1.0590e-02,  1.1398e-02,  ...,  3.0365e-02,
         -1.8127e-02,  4.5746e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.3154, -1.8975,  0.3960,  ...,  1.0117, -1.9961, -0.4487]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 11:29:55 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To accuse results in accusation
To customize results in customization
To expire results in expiration
To observe results in observation
To globalize results in globalization
To minimize results in minimization
To admire results in admiration
To compute results in
2024-07-30 11:29:55 root INFO     [order_1_approx] starting weight calculation for To customize results in customization
To globalize results in globalization
To expire results in expiration
To observe results in observation
To admire results in admiration
To compute results in computation
To accuse results in accusation
To minimize results in
2024-07-30 11:29:55 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 11:32:28 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0013, -0.3032, -0.5303,  ...,  0.0093,  0.0223, -0.2460],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.4883, -1.3340,  1.5068,  ..., -1.1084, -4.5820, -4.6875],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0360,  0.0119, -0.0173,  ..., -0.0116, -0.0053,  0.0061],
        [-0.0037,  0.0077, -0.0023,  ...,  0.0181, -0.0041,  0.0071],
        [ 0.0050,  0.0019,  0.0291,  ..., -0.0118, -0.0027,  0.0006],
        ...,
        [-0.0032, -0.0036, -0.0026,  ...,  0.0391, -0.0071,  0.0106],
        [-0.0084,  0.0023,  0.0012,  ...,  0.0144,  0.0346, -0.0033],
        [-0.0071, -0.0045,  0.0013,  ...,  0.0040, -0.0207,  0.0370]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.2092, -1.1992,  1.4941,  ..., -1.1504, -4.6445, -4.6016]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 11:32:29 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To customize results in customization
To globalize results in globalization
To expire results in expiration
To observe results in observation
To admire results in admiration
To compute results in computation
To accuse results in accusation
To minimize results in
2024-07-30 11:32:29 root INFO     [order_1_approx] starting weight calculation for To observe results in observation
To compute results in computation
To admire results in admiration
To globalize results in globalization
To minimize results in minimization
To expire results in expiration
To customize results in customization
To accuse results in
2024-07-30 11:32:29 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 11:35:01 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0496,  0.3865, -0.6035,  ...,  0.0693, -0.3047,  0.0921],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.8418, -4.3281,  1.5156,  ...,  4.5625, -0.8696, -0.1875],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0225,  0.0170,  0.0002,  ...,  0.0210, -0.0052, -0.0191],
        [ 0.0262,  0.0185, -0.0227,  ...,  0.0113, -0.0005,  0.0374],
        [-0.0130, -0.0154,  0.0461,  ...,  0.0023, -0.0020, -0.0172],
        ...,
        [ 0.0123,  0.0169, -0.0036,  ...,  0.0215, -0.0010,  0.0260],
        [-0.0222,  0.0047,  0.0007,  ...,  0.0125,  0.0234, -0.0070],
        [ 0.0257, -0.0183,  0.0076,  ...,  0.0073, -0.0247,  0.0759]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.1006e+00, -3.9668e+00,  1.2803e+00,  ...,  4.7891e+00,
         -1.1621e+00, -3.6621e-04]], device='cuda:1', dtype=torch.float16,
       grad_fn=<SubBackward0>) 

                    
2024-07-30 11:35:02 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To observe results in observation
To compute results in computation
To admire results in admiration
To globalize results in globalization
To minimize results in minimization
To expire results in expiration
To customize results in customization
To accuse results in
2024-07-30 11:35:02 root INFO     total operator prediction time: 1229.8918120861053 seconds
2024-07-30 11:35:02 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on adj+ly_reg
2024-07-30 11:35:02 root INFO     building operator adj+ly_reg
2024-07-30 11:35:02 root INFO     [order_1_approx] starting weight calculation for The adjective form of rare is rarely
The adjective form of regional is regionally
The adjective form of federal is federally
The adjective form of political is politically
The adjective form of famous is famously
The adjective form of physical is physically
The adjective form of mental is mentally
The adjective form of financial is
2024-07-30 11:35:02 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 11:37:37 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0149, -0.4519, -0.4065,  ..., -0.3027, -0.0388,  0.0488],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.6289, -1.3594,  2.4961,  ..., -2.3789, -1.0244, -0.6973],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 2.9099e-02, -1.0719e-02, -1.6495e-02,  ..., -8.9111e-03,
          2.9510e-02,  2.4750e-02],
        [-2.0447e-02,  6.7871e-02,  5.7487e-03,  ...,  5.8517e-03,
         -9.1124e-04, -1.9394e-02],
        [-7.3624e-04, -4.5929e-03,  5.3986e-02,  ..., -3.1071e-03,
          1.6647e-02, -9.6283e-03],
        ...,
        [ 7.0496e-03,  2.3224e-02, -1.4526e-02,  ...,  3.0334e-02,
          1.9409e-02,  4.0054e-05],
        [ 5.9814e-03,  9.8267e-03,  1.0475e-02,  ..., -2.3041e-03,
          3.5156e-02, -1.8951e-02],
        [ 1.6937e-02, -6.0806e-03,  8.1329e-03,  ...,  3.3951e-03,
          6.8054e-03,  1.7502e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.7456, -1.5654,  2.6641,  ..., -2.5215, -1.2988, -0.8716]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 11:37:38 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The adjective form of rare is rarely
The adjective form of regional is regionally
The adjective form of federal is federally
The adjective form of political is politically
The adjective form of famous is famously
The adjective form of physical is physically
The adjective form of mental is mentally
The adjective form of financial is
2024-07-30 11:37:38 root INFO     [order_1_approx] starting weight calculation for The adjective form of regional is regionally
The adjective form of rare is rarely
The adjective form of financial is financially
The adjective form of physical is physically
The adjective form of federal is federally
The adjective form of mental is mentally
The adjective form of political is politically
The adjective form of famous is
2024-07-30 11:37:38 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 11:40:12 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3032,  0.0969, -0.1824,  ..., -0.0559, -0.3772, -0.0301],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.8965, -2.5508,  2.9941,  ..., -0.9814, -3.1348, -2.6016],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0443, -0.0303, -0.0034,  ...,  0.0390,  0.0215,  0.0219],
        [-0.0084,  0.0542,  0.0137,  ..., -0.0059,  0.0304, -0.0147],
        [ 0.0055, -0.0405,  0.0539,  ...,  0.0243, -0.0177,  0.0120],
        ...,
        [ 0.0217,  0.0535,  0.0213,  ...,  0.0126, -0.0117,  0.0140],
        [ 0.0019,  0.0103, -0.0056,  ...,  0.0047,  0.0278,  0.0136],
        [-0.0177, -0.0233, -0.0113,  ...,  0.0171,  0.0068,  0.0209]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.0762, -3.2031,  3.5059,  ..., -1.6543, -3.3730, -2.6172]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 11:40:13 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The adjective form of regional is regionally
The adjective form of rare is rarely
The adjective form of financial is financially
The adjective form of physical is physically
The adjective form of federal is federally
The adjective form of mental is mentally
The adjective form of political is politically
The adjective form of famous is
2024-07-30 11:40:14 root INFO     [order_1_approx] starting weight calculation for The adjective form of regional is regionally
The adjective form of financial is financially
The adjective form of mental is mentally
The adjective form of political is politically
The adjective form of rare is rarely
The adjective form of famous is famously
The adjective form of federal is federally
The adjective form of physical is
2024-07-30 11:40:14 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 11:42:46 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0525, -0.2866, -0.1700,  ..., -0.1528, -0.2878,  0.1521],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.4014, -3.4531,  0.7578,  ..., -3.4297, -2.3496, -2.6738],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0321, -0.0484, -0.0052,  ...,  0.0154,  0.0118,  0.0388],
        [-0.0285,  0.1144, -0.0095,  ..., -0.0055,  0.0258, -0.0550],
        [ 0.0258, -0.0330,  0.0303,  ...,  0.0208, -0.0166,  0.0004],
        ...,
        [ 0.0218,  0.0442, -0.0620,  ...,  0.0255,  0.0036, -0.0244],
        [ 0.0304, -0.0234, -0.0324,  ..., -0.0049,  0.0175, -0.0088],
        [ 0.0176,  0.0153, -0.0243,  ..., -0.0266,  0.0101,  0.0117]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.7246, -3.1191,  0.8213,  ..., -3.0957, -2.1758, -3.0430]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 11:42:47 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The adjective form of regional is regionally
The adjective form of financial is financially
The adjective form of mental is mentally
The adjective form of political is politically
The adjective form of rare is rarely
The adjective form of famous is famously
The adjective form of federal is federally
The adjective form of physical is
2024-07-30 11:42:47 root INFO     [order_1_approx] starting weight calculation for The adjective form of famous is famously
The adjective form of physical is physically
The adjective form of financial is financially
The adjective form of federal is federally
The adjective form of political is politically
The adjective form of mental is mentally
The adjective form of rare is rarely
The adjective form of regional is
2024-07-30 11:42:47 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 11:45:21 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1803, -0.1592, -0.1552,  ..., -0.1245, -0.0618, -0.0517],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.8628, -2.6914,  1.6738,  ..., -4.3750, -1.4062, -3.1406],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0667, -0.0515, -0.0123,  ...,  0.0096,  0.0078,  0.0014],
        [ 0.0066,  0.0728,  0.0373,  ...,  0.0209,  0.0101, -0.0347],
        [ 0.0163, -0.0150,  0.0287,  ...,  0.0174, -0.0195,  0.0119],
        ...,
        [ 0.0189,  0.0288, -0.0215,  ...,  0.0325,  0.0119, -0.0028],
        [ 0.0093,  0.0060, -0.0065,  ...,  0.0062,  0.0196, -0.0134],
        [ 0.0076,  0.0088,  0.0022,  ..., -0.0078, -0.0078,  0.0219]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.1953, -2.8145,  2.0371,  ..., -3.6660, -1.4199, -3.4219]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 11:45:22 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The adjective form of famous is famously
The adjective form of physical is physically
The adjective form of financial is financially
The adjective form of federal is federally
The adjective form of political is politically
The adjective form of mental is mentally
The adjective form of rare is rarely
The adjective form of regional is
2024-07-30 11:45:23 root INFO     [order_1_approx] starting weight calculation for The adjective form of political is politically
The adjective form of famous is famously
The adjective form of rare is rarely
The adjective form of financial is financially
The adjective form of physical is physically
The adjective form of mental is mentally
The adjective form of regional is regionally
The adjective form of federal is
2024-07-30 11:45:23 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 11:47:56 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3154,  0.1383, -0.4170,  ..., -0.3967, -0.3735, -0.0622],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.3643, -1.9326,  4.0898,  ..., -1.2832, -0.5903, -0.7695],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 3.4302e-02, -3.8452e-02, -2.7313e-03,  ...,  1.4725e-02,
         -6.8970e-03, -2.6703e-05],
        [-4.4594e-03,  6.9763e-02,  4.9057e-03,  ...,  1.2527e-02,
          1.1734e-02, -3.0090e-02],
        [-3.6316e-03,  2.1057e-02,  2.5497e-02,  ..., -1.8539e-02,
         -4.2953e-03, -8.3771e-03],
        ...,
        [-9.2316e-03,  2.4063e-02, -1.3588e-02,  ...,  2.1805e-02,
          9.5978e-03, -2.0355e-02],
        [-9.9487e-03,  3.7155e-03, -1.4267e-02,  ..., -4.6005e-03,
          3.5934e-03, -3.2501e-02],
        [ 2.3239e-02,  1.3016e-02, -5.7068e-03,  ...,  2.3621e-02,
          1.5160e-02,  3.1464e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.2490, -2.2246,  3.8535,  ..., -1.2441, -0.9233, -0.9253]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 11:47:57 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The adjective form of political is politically
The adjective form of famous is famously
The adjective form of rare is rarely
The adjective form of financial is financially
The adjective form of physical is physically
The adjective form of mental is mentally
The adjective form of regional is regionally
The adjective form of federal is
2024-07-30 11:47:58 root INFO     [order_1_approx] starting weight calculation for The adjective form of federal is federally
The adjective form of physical is physically
The adjective form of regional is regionally
The adjective form of rare is rarely
The adjective form of financial is financially
The adjective form of mental is mentally
The adjective form of famous is famously
The adjective form of political is
2024-07-30 11:47:58 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 11:50:32 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1439,  0.1682, -0.1733,  ..., -0.2581, -0.4263,  0.0313],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 9.9609e-01, -3.2812e+00,  7.1631e-01,  ..., -2.7344e+00,
        -4.8828e-04,  3.9648e-01], device='cuda:1', dtype=torch.float16,
       grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0271, -0.0157, -0.0053,  ..., -0.0082,  0.0107,  0.0053],
        [-0.0022,  0.0565,  0.0206,  ...,  0.0074,  0.0019, -0.0151],
        [-0.0092, -0.0186,  0.0312,  ...,  0.0211, -0.0361,  0.0021],
        ...,
        [ 0.0162,  0.0304, -0.0089,  ...,  0.0414,  0.0127,  0.0036],
        [-0.0210,  0.0064, -0.0080,  ..., -0.0176,  0.0224, -0.0365],
        [ 0.0141,  0.0149, -0.0110,  ..., -0.0019,  0.0213,  0.0239]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.1436, -3.5488,  0.8423,  ..., -2.5020, -0.2405,  0.4788]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 11:50:33 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The adjective form of federal is federally
The adjective form of physical is physically
The adjective form of regional is regionally
The adjective form of rare is rarely
The adjective form of financial is financially
The adjective form of mental is mentally
The adjective form of famous is famously
The adjective form of political is
2024-07-30 11:50:33 root INFO     [order_1_approx] starting weight calculation for The adjective form of rare is rarely
The adjective form of regional is regionally
The adjective form of political is politically
The adjective form of financial is financially
The adjective form of federal is federally
The adjective form of famous is famously
The adjective form of physical is physically
The adjective form of mental is
2024-07-30 11:50:33 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 11:53:07 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1477, -0.2642,  0.2588,  ..., -0.4272, -0.3494,  0.0160],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.2109, -0.4326,  1.8213,  ..., -3.3066, -1.3857, -1.3682],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 3.7994e-02, -3.3627e-03, -2.3071e-02,  ...,  9.5673e-03,
          2.1683e-02,  1.1551e-02],
        [ 3.0136e-04,  7.9224e-02,  1.0986e-02,  ..., -8.9111e-03,
          1.0597e-02, -3.7140e-02],
        [-1.6510e-02,  4.7531e-03,  6.9153e-02,  ...,  3.2539e-03,
         -1.4725e-02,  5.5695e-04],
        ...,
        [ 3.3203e-02,  3.1830e-02,  6.7558e-03,  ...,  4.4952e-02,
         -6.6032e-03, -1.8341e-02],
        [ 1.0895e-02, -9.8190e-03, -6.5956e-03,  ...,  7.8506e-03,
          1.5915e-02, -2.3270e-03],
        [ 1.6617e-02,  2.5467e-02,  1.5686e-02,  ..., -4.4250e-04,
          1.8692e-04, -5.3406e-05]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.9668, -0.6646,  2.0977,  ..., -2.9707, -1.7461, -1.3184]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 11:53:09 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The adjective form of rare is rarely
The adjective form of regional is regionally
The adjective form of political is politically
The adjective form of financial is financially
The adjective form of federal is federally
The adjective form of famous is famously
The adjective form of physical is physically
The adjective form of mental is
2024-07-30 11:53:10 root INFO     [order_1_approx] starting weight calculation for The adjective form of financial is financially
The adjective form of famous is famously
The adjective form of federal is federally
The adjective form of physical is physically
The adjective form of political is politically
The adjective form of regional is regionally
The adjective form of mental is mentally
The adjective form of rare is
2024-07-30 11:53:10 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 11:55:44 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2366, -0.4160, -0.2327,  ..., -0.2190,  0.1750, -0.0169],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-2.1523, -4.2695, -0.0420,  ..., -4.5430, -3.7422, -4.5625],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0738, -0.0177, -0.0021,  ...,  0.0338, -0.0257,  0.0157],
        [ 0.0166,  0.0568,  0.0247,  ...,  0.0081, -0.0022, -0.0142],
        [ 0.0097, -0.0343,  0.0264,  ...,  0.0037,  0.0015,  0.0282],
        ...,
        [ 0.0284,  0.0612,  0.0185,  ...,  0.0193,  0.0072, -0.0344],
        [-0.0048,  0.0125,  0.0273,  ..., -0.0204,  0.0230, -0.0219],
        [ 0.0066,  0.0423, -0.0155,  ..., -0.0259, -0.0121,  0.0224]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.0176, -4.1836,  0.0831,  ..., -4.9414, -4.2891, -5.2539]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 11:55:45 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The adjective form of financial is financially
The adjective form of famous is famously
The adjective form of federal is federally
The adjective form of physical is physically
The adjective form of political is politically
The adjective form of regional is regionally
The adjective form of mental is mentally
The adjective form of rare is
2024-07-30 11:55:45 root INFO     total operator prediction time: 1243.2680089473724 seconds
2024-07-30 11:55:45 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on over+adj_reg
2024-07-30 11:55:45 root INFO     building operator over+adj_reg
2024-07-30 11:55:46 root INFO     [order_1_approx] starting weight calculation for If something is too qualified, it is overqualified
If something is too played, it is overplayed
If something is too saturated, it is oversaturated
If something is too confident, it is overconfident
If something is too sold, it is oversold
If something is too thrown, it is overthrown
If something is too cooked, it is overcooked
If something is too stated, it is
2024-07-30 11:55:46 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 11:58:19 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1017, -0.4658, -0.4529,  ..., -0.0811, -0.5796, -0.0254],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.2656, -2.4297,  1.3887,  ...,  0.5811, -2.4727, -1.4941],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0625, -0.0100, -0.0155,  ..., -0.0169,  0.0074,  0.0146],
        [-0.0242,  0.0877,  0.0039,  ..., -0.0149,  0.0233, -0.0122],
        [ 0.0065,  0.0079,  0.0421,  ...,  0.0213, -0.0164,  0.0055],
        ...,
        [ 0.0209,  0.0226,  0.0094,  ...,  0.0737,  0.0002,  0.0048],
        [-0.0004, -0.0254, -0.0058,  ...,  0.0126,  0.0121, -0.0220],
        [ 0.0127,  0.0281, -0.0067,  ..., -0.0095, -0.0155,  0.0498]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.2969, -2.6934,  2.1797,  ...,  0.4988, -2.1934, -1.5498]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 11:58:20 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is too qualified, it is overqualified
If something is too played, it is overplayed
If something is too saturated, it is oversaturated
If something is too confident, it is overconfident
If something is too sold, it is oversold
If something is too thrown, it is overthrown
If something is too cooked, it is overcooked
If something is too stated, it is
2024-07-30 11:58:20 root INFO     [order_1_approx] starting weight calculation for If something is too confident, it is overconfident
If something is too sold, it is oversold
If something is too thrown, it is overthrown
If something is too played, it is overplayed
If something is too cooked, it is overcooked
If something is too qualified, it is overqualified
If something is too stated, it is overstated
If something is too saturated, it is
2024-07-30 11:58:20 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 12:00:53 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0294, -0.1479, -0.3184,  ...,  0.3276, -0.4934, -0.3130],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.4141, -2.3535,  0.2378,  ..., -1.5068, -1.9570, -0.9238],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0611,  0.0027, -0.0048,  ..., -0.0184, -0.0179,  0.0116],
        [ 0.0060,  0.0609,  0.0230,  ..., -0.0062, -0.0123, -0.0120],
        [ 0.0066, -0.0044,  0.0204,  ..., -0.0084, -0.0035,  0.0143],
        ...,
        [ 0.0208, -0.0111, -0.0137,  ...,  0.0499, -0.0018,  0.0215],
        [-0.0106, -0.0034, -0.0128,  ..., -0.0001,  0.0466, -0.0334],
        [ 0.0129,  0.0196,  0.0082,  ...,  0.0097, -0.0110,  0.0618]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.6758, -2.2012,  0.3867,  ..., -1.7393, -2.0605, -1.1465]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 12:00:54 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is too confident, it is overconfident
If something is too sold, it is oversold
If something is too thrown, it is overthrown
If something is too played, it is overplayed
If something is too cooked, it is overcooked
If something is too qualified, it is overqualified
If something is too stated, it is overstated
If something is too saturated, it is
2024-07-30 12:00:54 root INFO     [order_1_approx] starting weight calculation for If something is too saturated, it is oversaturated
If something is too thrown, it is overthrown
If something is too sold, it is oversold
If something is too qualified, it is overqualified
If something is too played, it is overplayed
If something is too confident, it is overconfident
If something is too stated, it is overstated
If something is too cooked, it is
2024-07-30 12:00:54 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 12:03:27 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1814, -0.3682, -0.1870,  ..., -0.1178, -0.6626,  0.2754],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.5605, -2.6484,  0.9136,  ..., -1.3848, -2.3438,  0.0117],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0596,  0.0035,  0.0076,  ...,  0.0056, -0.0083,  0.0144],
        [ 0.0050,  0.0342,  0.0038,  ...,  0.0010,  0.0031, -0.0352],
        [ 0.0115, -0.0239,  0.0104,  ...,  0.0094, -0.0019,  0.0372],
        ...,
        [-0.0012, -0.0079,  0.0012,  ...,  0.0595,  0.0061,  0.0239],
        [ 0.0060,  0.0049, -0.0229,  ...,  0.0083,  0.0279, -0.0167],
        [-0.0125,  0.0110, -0.0040,  ...,  0.0090, -0.0182,  0.0508]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.6758, -2.5039,  0.7188,  ..., -1.2910, -2.3828,  0.0127]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 12:03:28 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is too saturated, it is oversaturated
If something is too thrown, it is overthrown
If something is too sold, it is oversold
If something is too qualified, it is overqualified
If something is too played, it is overplayed
If something is too confident, it is overconfident
If something is too stated, it is overstated
If something is too cooked, it is
2024-07-30 12:03:28 root INFO     [order_1_approx] starting weight calculation for If something is too confident, it is overconfident
If something is too thrown, it is overthrown
If something is too played, it is overplayed
If something is too stated, it is overstated
If something is too saturated, it is oversaturated
If something is too cooked, it is overcooked
If something is too qualified, it is overqualified
If something is too sold, it is
2024-07-30 12:03:28 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 12:06:00 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1146, -0.2063, -0.2136,  ..., -0.0028, -0.2371,  0.2156],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.4512, -3.0234,  0.4292,  ..., -1.1445, -3.2832, -0.8477],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0667, -0.0245, -0.0080,  ...,  0.0163,  0.0169,  0.0226],
        [ 0.0076,  0.0540, -0.0074,  ...,  0.0049, -0.0294, -0.0095],
        [ 0.0184, -0.0093,  0.0510,  ...,  0.0077,  0.0172,  0.0145],
        ...,
        [ 0.0061,  0.0018,  0.0094,  ...,  0.0377,  0.0065,  0.0256],
        [-0.0004,  0.0076,  0.0099,  ...,  0.0135,  0.0273,  0.0024],
        [ 0.0116,  0.0292, -0.0040,  ...,  0.0154, -0.0178,  0.0301]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.5830, -3.1621,  0.7324,  ..., -1.0039, -3.1191, -0.7261]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 12:06:01 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is too confident, it is overconfident
If something is too thrown, it is overthrown
If something is too played, it is overplayed
If something is too stated, it is overstated
If something is too saturated, it is oversaturated
If something is too cooked, it is overcooked
If something is too qualified, it is overqualified
If something is too sold, it is
2024-07-30 12:06:01 root INFO     [order_1_approx] starting weight calculation for If something is too stated, it is overstated
If something is too sold, it is oversold
If something is too thrown, it is overthrown
If something is too played, it is overplayed
If something is too cooked, it is overcooked
If something is too saturated, it is oversaturated
If something is too qualified, it is overqualified
If something is too confident, it is
2024-07-30 12:06:01 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 12:08:30 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0452,  0.1978, -0.3154,  ...,  0.6011, -0.3992, -0.0873],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.6445, -3.7148,  2.4766,  ...,  1.7832, -1.5469, -1.3926],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0559, -0.0002, -0.0063,  ...,  0.0040,  0.0054,  0.0083],
        [-0.0037,  0.0394,  0.0153,  ..., -0.0009, -0.0010,  0.0092],
        [ 0.0040,  0.0130,  0.0461,  ..., -0.0021,  0.0116,  0.0075],
        ...,
        [ 0.0078, -0.0012, -0.0077,  ...,  0.0445, -0.0011,  0.0056],
        [ 0.0115,  0.0075,  0.0386,  ..., -0.0084,  0.0452, -0.0241],
        [-0.0001, -0.0020,  0.0005,  ...,  0.0051, -0.0066,  0.0199]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.9434, -3.7305,  1.9023,  ...,  1.8428, -1.8584, -1.5322]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 12:08:31 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is too stated, it is overstated
If something is too sold, it is oversold
If something is too thrown, it is overthrown
If something is too played, it is overplayed
If something is too cooked, it is overcooked
If something is too saturated, it is oversaturated
If something is too qualified, it is overqualified
If something is too confident, it is
2024-07-30 12:08:31 root INFO     [order_1_approx] starting weight calculation for If something is too qualified, it is overqualified
If something is too saturated, it is oversaturated
If something is too stated, it is overstated
If something is too cooked, it is overcooked
If something is too played, it is overplayed
If something is too confident, it is overconfident
If something is too sold, it is oversold
If something is too thrown, it is
2024-07-30 12:08:31 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 12:11:03 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1151, -0.1445, -0.2329,  ..., -0.1151, -0.4497, -0.0543],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.8691, -3.6484,  1.1973,  ...,  0.9341, -1.9219, -2.1953],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0471,  0.0169,  0.0075,  ..., -0.0021,  0.0139,  0.0166],
        [-0.0296,  0.0590,  0.0080,  ..., -0.0030, -0.0140, -0.0088],
        [ 0.0290, -0.0076,  0.0171,  ...,  0.0181,  0.0024, -0.0001],
        ...,
        [ 0.0165, -0.0084, -0.0273,  ...,  0.0488, -0.0237,  0.0034],
        [ 0.0138, -0.0254, -0.0127,  ..., -0.0026,  0.0363, -0.0299],
        [-0.0149,  0.0084,  0.0050,  ..., -0.0036, -0.0030,  0.0367]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.5293, -3.4258,  1.0557,  ...,  1.1758, -2.1797, -2.2969]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 12:11:04 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is too qualified, it is overqualified
If something is too saturated, it is oversaturated
If something is too stated, it is overstated
If something is too cooked, it is overcooked
If something is too played, it is overplayed
If something is too confident, it is overconfident
If something is too sold, it is oversold
If something is too thrown, it is
2024-07-30 12:11:05 root INFO     [order_1_approx] starting weight calculation for If something is too played, it is overplayed
If something is too thrown, it is overthrown
If something is too confident, it is overconfident
If something is too sold, it is oversold
If something is too stated, it is overstated
If something is too cooked, it is overcooked
If something is too saturated, it is oversaturated
If something is too qualified, it is
2024-07-30 12:11:05 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 12:13:37 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0113, -0.2112, -0.2966,  ..., -0.2012, -0.0105,  0.0276],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.7847, -3.0000,  1.4414,  ...,  0.4502, -1.6133, -2.4531],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0710, -0.0129, -0.0045,  ..., -0.0161, -0.0011,  0.0188],
        [ 0.0014,  0.0503, -0.0023,  ..., -0.0002, -0.0035, -0.0108],
        [ 0.0117, -0.0077,  0.0303,  ..., -0.0084, -0.0004, -0.0118],
        ...,
        [ 0.0278,  0.0233, -0.0226,  ...,  0.0538,  0.0100,  0.0065],
        [-0.0010,  0.0035,  0.0090,  ...,  0.0273,  0.0233, -0.0209],
        [ 0.0056,  0.0031, -0.0002,  ...,  0.0099, -0.0317,  0.0242]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.1807, -3.4824,  1.5781,  ...,  0.5898, -1.7832, -2.2070]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 12:13:38 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is too played, it is overplayed
If something is too thrown, it is overthrown
If something is too confident, it is overconfident
If something is too sold, it is oversold
If something is too stated, it is overstated
If something is too cooked, it is overcooked
If something is too saturated, it is oversaturated
If something is too qualified, it is
2024-07-30 12:13:38 root INFO     [order_1_approx] starting weight calculation for If something is too thrown, it is overthrown
If something is too qualified, it is overqualified
If something is too cooked, it is overcooked
If something is too stated, it is overstated
If something is too sold, it is oversold
If something is too confident, it is overconfident
If something is too saturated, it is oversaturated
If something is too played, it is
2024-07-30 12:13:38 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 12:16:08 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0569, -0.3965, -0.4312,  ..., -0.2445, -0.6074,  0.1530],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.4023, -3.1562,  1.0156,  ..., -0.2717, -1.2217, -2.1836],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0781,  0.0047,  0.0199,  ...,  0.0034,  0.0216,  0.0355],
        [-0.0095,  0.0427, -0.0056,  ..., -0.0026, -0.0321,  0.0060],
        [ 0.0290, -0.0340,  0.0470,  ...,  0.0066, -0.0044,  0.0226],
        ...,
        [ 0.0213,  0.0181, -0.0107,  ...,  0.0489,  0.0008,  0.0137],
        [-0.0003,  0.0097, -0.0081,  ..., -0.0217,  0.0308, -0.0346],
        [ 0.0027,  0.0269, -0.0011,  ..., -0.0037, -0.0045,  0.0523]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.9434, -3.2734,  1.5752,  ..., -0.1836, -1.1523, -2.1387]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 12:16:09 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is too thrown, it is overthrown
If something is too qualified, it is overqualified
If something is too cooked, it is overcooked
If something is too stated, it is overstated
If something is too sold, it is oversold
If something is too confident, it is overconfident
If something is too saturated, it is oversaturated
If something is too played, it is
2024-07-30 12:16:09 root INFO     total operator prediction time: 1223.7577447891235 seconds
2024-07-30 12:16:09 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on verb+er_irreg
2024-07-30 12:16:09 root INFO     building operator verb+er_irreg
2024-07-30 12:16:09 root INFO     [order_1_approx] starting weight calculation for If you offend something, you are a offender
If you mourn something, you are a mourner
If you learn something, you are a learner
If you receive something, you are a receiver
If you intrude something, you are a intruder
If you bake something, you are a baker
If you follow something, you are a follower
If you borrow something, you are a
2024-07-30 12:16:09 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 12:18:42 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0319,  0.2812, -0.1213,  ..., -0.1823,  0.1638, -0.0105],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.5508, -2.1582, -0.7495,  ..., -1.7236, -1.3467, -3.7207],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0517,  0.0003, -0.0046,  ...,  0.0169,  0.0243,  0.0087],
        [-0.0130,  0.0381,  0.0130,  ...,  0.0281, -0.0207, -0.0089],
        [-0.0051, -0.0070,  0.0449,  ..., -0.0010,  0.0102,  0.0155],
        ...,
        [ 0.0258,  0.0011, -0.0049,  ...,  0.0463,  0.0118,  0.0163],
        [-0.0060,  0.0025,  0.0119,  ..., -0.0042,  0.0056,  0.0029],
        [-0.0131,  0.0126, -0.0013,  ..., -0.0243,  0.0052, -0.0043]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.1484, -2.2441, -0.8984,  ..., -1.6943, -1.1836, -4.6016]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 12:18:43 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you offend something, you are a offender
If you mourn something, you are a mourner
If you learn something, you are a learner
If you receive something, you are a receiver
If you intrude something, you are a intruder
If you bake something, you are a baker
If you follow something, you are a follower
If you borrow something, you are a
2024-07-30 12:18:43 root INFO     [order_1_approx] starting weight calculation for If you offend something, you are a offender
If you follow something, you are a follower
If you intrude something, you are a intruder
If you receive something, you are a receiver
If you bake something, you are a baker
If you borrow something, you are a borrower
If you learn something, you are a learner
If you mourn something, you are a
2024-07-30 12:18:43 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 12:21:16 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2119,  0.4277,  0.0060,  ..., -0.0192, -0.4788,  0.1990],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.7070, -2.8262, -0.3718,  ..., -1.7500, -1.9902,  0.2637],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0155, -0.0168,  0.0259,  ...,  0.0105,  0.0071, -0.0054],
        [-0.0162,  0.0226,  0.0208,  ...,  0.0009, -0.0069,  0.0174],
        [ 0.0039, -0.0098,  0.0535,  ..., -0.0077, -0.0040, -0.0167],
        ...,
        [ 0.0187,  0.0158,  0.0275,  ...,  0.0088, -0.0022,  0.0058],
        [-0.0025, -0.0076, -0.0067,  ..., -0.0006,  0.0130, -0.0238],
        [-0.0006,  0.0007, -0.0038,  ..., -0.0056, -0.0054,  0.0202]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.9629, -3.1426, -0.6084,  ..., -1.5771, -2.1250, -0.0186]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 12:21:17 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you offend something, you are a offender
If you follow something, you are a follower
If you intrude something, you are a intruder
If you receive something, you are a receiver
If you bake something, you are a baker
If you borrow something, you are a borrower
If you learn something, you are a learner
If you mourn something, you are a
2024-07-30 12:21:18 root INFO     [order_1_approx] starting weight calculation for If you mourn something, you are a mourner
If you follow something, you are a follower
If you bake something, you are a baker
If you offend something, you are a offender
If you learn something, you are a learner
If you intrude something, you are a intruder
If you borrow something, you are a borrower
If you receive something, you are a
2024-07-30 12:21:18 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 12:23:50 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0247,  0.3472, -0.2910,  ..., -0.3438,  0.0353,  0.0631],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.4697, -0.7197, -2.0527,  ..., -2.2520, -3.6641, -2.8398],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0381, -0.0121,  0.0257,  ...,  0.0208,  0.0157,  0.0165],
        [-0.0153,  0.0331,  0.0161,  ...,  0.0153, -0.0089, -0.0141],
        [ 0.0120,  0.0032,  0.0046,  ..., -0.0150,  0.0088, -0.0059],
        ...,
        [ 0.0284,  0.0012, -0.0094,  ...,  0.0347, -0.0140,  0.0137],
        [ 0.0115, -0.0003, -0.0014,  ..., -0.0205,  0.0177,  0.0012],
        [ 0.0027,  0.0073, -0.0062,  ..., -0.0049, -0.0043,  0.0088]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.0781, -0.7397, -1.9385,  ..., -1.8867, -3.6523, -3.1406]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 12:23:51 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you mourn something, you are a mourner
If you follow something, you are a follower
If you bake something, you are a baker
If you offend something, you are a offender
If you learn something, you are a learner
If you intrude something, you are a intruder
If you borrow something, you are a borrower
If you receive something, you are a
2024-07-30 12:23:51 root INFO     [order_1_approx] starting weight calculation for If you follow something, you are a follower
If you mourn something, you are a mourner
If you receive something, you are a receiver
If you borrow something, you are a borrower
If you learn something, you are a learner
If you offend something, you are a offender
If you bake something, you are a baker
If you intrude something, you are a
2024-07-30 12:23:51 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 12:26:24 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2917, -0.1154, -0.1370,  ...,  0.0300,  0.0814,  0.1974],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 6.2070, -1.9521, -0.7212,  ..., -0.9521, -5.0195, -1.0400],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 3.1982e-02, -6.9923e-03,  3.1052e-02,  ...,  1.6678e-02,
          2.1210e-03,  5.3978e-03],
        [-1.1040e-02,  4.7607e-02,  3.5126e-02,  ..., -9.9277e-04,
         -1.8883e-03,  1.3199e-02],
        [ 8.4400e-04, -6.9656e-03,  1.6953e-02,  ..., -8.1711e-03,
          9.7752e-05, -1.6235e-02],
        ...,
        [ 8.5297e-03,  3.3081e-02, -3.5896e-03,  ...,  4.5776e-02,
         -1.6499e-04, -2.5768e-03],
        [ 2.8763e-03,  2.4471e-03,  2.3636e-02,  ..., -1.4450e-02,
          3.1403e-02, -6.9094e-04],
        [ 1.0750e-02,  3.0117e-03,  6.6910e-03,  ..., -1.2302e-04,
         -1.9501e-02,  2.2598e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 6.0781, -1.9961, -0.6997,  ..., -0.7402, -5.0156, -1.1094]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 12:26:25 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you follow something, you are a follower
If you mourn something, you are a mourner
If you receive something, you are a receiver
If you borrow something, you are a borrower
If you learn something, you are a learner
If you offend something, you are a offender
If you bake something, you are a baker
If you intrude something, you are a
2024-07-30 12:26:25 root INFO     [order_1_approx] starting weight calculation for If you follow something, you are a follower
If you bake something, you are a baker
If you receive something, you are a receiver
If you learn something, you are a learner
If you borrow something, you are a borrower
If you mourn something, you are a mourner
If you intrude something, you are a intruder
If you offend something, you are a
2024-07-30 12:26:25 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 12:28:58 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0050,  0.5073, -0.4187,  ...,  0.3145, -0.3760,  0.1534],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.1016, -2.3965,  0.1731,  ..., -1.6270, -3.1641, -0.0508],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0438,  0.0014,  0.0206,  ...,  0.0137, -0.0035,  0.0146],
        [ 0.0199,  0.0398,  0.0156,  ..., -0.0019,  0.0087,  0.0027],
        [-0.0102, -0.0083,  0.0377,  ..., -0.0177,  0.0157,  0.0133],
        ...,
        [ 0.0071,  0.0121, -0.0087,  ...,  0.0326,  0.0156, -0.0006],
        [-0.0041,  0.0138,  0.0019,  ..., -0.0012,  0.0324,  0.0108],
        [-0.0053,  0.0024, -0.0088,  ...,  0.0008, -0.0094,  0.0200]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.2461, -2.6543,  0.1519,  ..., -1.2656, -2.9199,  0.2415]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 12:28:58 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you follow something, you are a follower
If you bake something, you are a baker
If you receive something, you are a receiver
If you learn something, you are a learner
If you borrow something, you are a borrower
If you mourn something, you are a mourner
If you intrude something, you are a intruder
If you offend something, you are a
2024-07-30 12:28:59 root INFO     [order_1_approx] starting weight calculation for If you offend something, you are a offender
If you receive something, you are a receiver
If you follow something, you are a follower
If you mourn something, you are a mourner
If you bake something, you are a baker
If you borrow something, you are a borrower
If you intrude something, you are a intruder
If you learn something, you are a
2024-07-30 12:28:59 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 12:31:31 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2896,  0.2173, -0.1514,  ..., -0.1355, -0.2959, -0.0322],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.0742, -2.4453,  1.4492,  ...,  1.1074, -4.4375, -6.4883],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0079, -0.0053,  0.0121,  ...,  0.0108,  0.0124,  0.0099],
        [-0.0068,  0.0338,  0.0067,  ...,  0.0040, -0.0102, -0.0012],
        [-0.0001,  0.0007,  0.0077,  ...,  0.0028, -0.0028,  0.0066],
        ...,
        [ 0.0172,  0.0157,  0.0123,  ...,  0.0058, -0.0061,  0.0012],
        [-0.0008,  0.0008, -0.0065,  ..., -0.0071,  0.0118, -0.0019],
        [-0.0032,  0.0044,  0.0130,  ...,  0.0015, -0.0112, -0.0047]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.0093, -2.4160,  1.2939,  ...,  1.1465, -4.4414, -6.4961]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 12:31:32 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you offend something, you are a offender
If you receive something, you are a receiver
If you follow something, you are a follower
If you mourn something, you are a mourner
If you bake something, you are a baker
If you borrow something, you are a borrower
If you intrude something, you are a intruder
If you learn something, you are a
2024-07-30 12:31:32 root INFO     [order_1_approx] starting weight calculation for If you mourn something, you are a mourner
If you follow something, you are a follower
If you learn something, you are a learner
If you borrow something, you are a borrower
If you offend something, you are a offender
If you intrude something, you are a intruder
If you receive something, you are a receiver
If you bake something, you are a
2024-07-30 12:31:32 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 12:34:05 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0146,  0.3293, -0.3950,  ..., -0.0707, -0.5762, -0.2361],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 5.0977, -1.6592, -0.3442,  ...,  0.6963, -4.6172, -2.5234],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0303, -0.0151,  0.0041,  ..., -0.0111,  0.0078,  0.0170],
        [ 0.0064,  0.0442,  0.0121,  ...,  0.0279,  0.0127,  0.0063],
        [ 0.0058, -0.0039,  0.0198,  ..., -0.0081,  0.0111,  0.0104],
        ...,
        [ 0.0064,  0.0233, -0.0090,  ...,  0.0432,  0.0114, -0.0029],
        [-0.0144,  0.0210, -0.0048,  ..., -0.0036,  0.0094, -0.0136],
        [ 0.0081,  0.0099, -0.0113,  ...,  0.0008, -0.0099,  0.0171]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 5.0312, -1.6641, -0.4365,  ...,  0.7861, -4.6680, -2.7422]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 12:34:06 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you mourn something, you are a mourner
If you follow something, you are a follower
If you learn something, you are a learner
If you borrow something, you are a borrower
If you offend something, you are a offender
If you intrude something, you are a intruder
If you receive something, you are a receiver
If you bake something, you are a
2024-07-30 12:34:06 root INFO     [order_1_approx] starting weight calculation for If you offend something, you are a offender
If you intrude something, you are a intruder
If you learn something, you are a learner
If you bake something, you are a baker
If you mourn something, you are a mourner
If you receive something, you are a receiver
If you borrow something, you are a borrower
If you follow something, you are a
2024-07-30 12:34:06 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 12:36:38 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1071,  0.1558, -0.2313,  ...,  0.1940,  0.0544,  0.1376],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.7422, -3.4551,  3.6797,  ..., -0.0645, -6.6680, -1.3379],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0414,  0.0030,  0.0066,  ...,  0.0229,  0.0014,  0.0089],
        [-0.0047,  0.0342,  0.0105,  ..., -0.0009,  0.0063, -0.0149],
        [-0.0015,  0.0016,  0.0315,  ...,  0.0012,  0.0025, -0.0136],
        ...,
        [ 0.0264,  0.0191, -0.0007,  ...,  0.0090, -0.0021,  0.0018],
        [ 0.0091, -0.0021, -0.0197,  ...,  0.0098,  0.0109, -0.0040],
        [-0.0100, -0.0121,  0.0188,  ..., -0.0059, -0.0034,  0.0082]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.8242, -3.9355,  3.5879,  ...,  0.0375, -6.4883, -1.4033]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 12:36:39 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you offend something, you are a offender
If you intrude something, you are a intruder
If you learn something, you are a learner
If you bake something, you are a baker
If you mourn something, you are a mourner
If you receive something, you are a receiver
If you borrow something, you are a borrower
If you follow something, you are a
2024-07-30 12:36:39 root INFO     total operator prediction time: 1230.0760197639465 seconds
2024-07-30 12:36:39 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on adj - superlative
2024-07-30 12:36:39 root INFO     building operator adj - superlative
2024-07-30 12:36:39 root INFO     [order_1_approx] starting weight calculation for If something is the most pure, it is purest
If something is the most lucky, it is luckiest
If something is the most angry, it is angriest
If something is the most huge, it is hugest
If something is the most hardy, it is hardiest
If something is the most cheap, it is cheapest
If something is the most strong, it is strongest
If something is the most nice, it is
2024-07-30 12:36:40 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 12:39:12 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0743,  0.0548, -0.1243,  ...,  0.1711, -0.2703, -0.0984],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.6758, -0.9951, -4.4492,  ...,  0.3232, -4.4219, -1.4785],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0086, -0.0344,  0.0190,  ..., -0.0177,  0.0150,  0.0232],
        [ 0.0083,  0.0392,  0.0039,  ...,  0.0019,  0.0072,  0.0045],
        [ 0.0043, -0.0235,  0.0270,  ...,  0.0036, -0.0365, -0.0153],
        ...,
        [ 0.0011,  0.0192,  0.0019,  ...,  0.0353,  0.0039, -0.0109],
        [ 0.0155, -0.0038,  0.0068,  ...,  0.0151,  0.0162, -0.0199],
        [ 0.0028, -0.0010,  0.0079,  ...,  0.0069, -0.0303,  0.0214]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.5347, -1.6221, -4.7109,  ...,  0.5229, -4.4531, -2.0703]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 12:39:13 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is the most pure, it is purest
If something is the most lucky, it is luckiest
If something is the most angry, it is angriest
If something is the most huge, it is hugest
If something is the most hardy, it is hardiest
If something is the most cheap, it is cheapest
If something is the most strong, it is strongest
If something is the most nice, it is
2024-07-30 12:39:14 root INFO     [order_1_approx] starting weight calculation for If something is the most hardy, it is hardiest
If something is the most cheap, it is cheapest
If something is the most huge, it is hugest
If something is the most pure, it is purest
If something is the most nice, it is nicest
If something is the most strong, it is strongest
If something is the most angry, it is angriest
If something is the most lucky, it is
2024-07-30 12:39:14 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 12:41:41 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1041,  0.2644, -0.1864,  ..., -0.0549, -0.2869, -0.2020],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.0781, -3.1816, -3.4805,  ..., -0.4980, -0.5703, -2.5723],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0177,  0.0017,  0.0065,  ...,  0.0106, -0.0083,  0.0047],
        [ 0.0019,  0.0212,  0.0096,  ...,  0.0020,  0.0032, -0.0015],
        [ 0.0109, -0.0046,  0.0141,  ...,  0.0029, -0.0158, -0.0033],
        ...,
        [ 0.0016,  0.0076,  0.0108,  ...,  0.0114,  0.0028,  0.0041],
        [-0.0040, -0.0038,  0.0100,  ..., -0.0021,  0.0036, -0.0141],
        [ 0.0027,  0.0035,  0.0067,  ..., -0.0032, -0.0063,  0.0068]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.3157, -3.1172, -3.4316,  ..., -0.5820, -0.8315, -2.6367]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 12:41:42 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is the most hardy, it is hardiest
If something is the most cheap, it is cheapest
If something is the most huge, it is hugest
If something is the most pure, it is purest
If something is the most nice, it is nicest
If something is the most strong, it is strongest
If something is the most angry, it is angriest
If something is the most lucky, it is
2024-07-30 12:41:42 root INFO     [order_1_approx] starting weight calculation for If something is the most cheap, it is cheapest
If something is the most nice, it is nicest
If something is the most strong, it is strongest
If something is the most huge, it is hugest
If something is the most angry, it is angriest
If something is the most hardy, it is hardiest
If something is the most lucky, it is luckiest
If something is the most pure, it is
2024-07-30 12:41:42 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 12:44:12 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1292,  0.0876,  0.0497,  ...,  0.0494, -0.0088, -0.0043],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.9668, -3.7852, -3.2656,  ..., -1.4834, -1.1035, -2.1660],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0229, -0.0150,  0.0167,  ..., -0.0002,  0.0208,  0.0048],
        [ 0.0035,  0.0257,  0.0211,  ..., -0.0178,  0.0025,  0.0042],
        [-0.0003,  0.0018,  0.0169,  ...,  0.0073, -0.0213,  0.0313],
        ...,
        [ 0.0029,  0.0141, -0.0020,  ...,  0.0147,  0.0125, -0.0103],
        [ 0.0157, -0.0007, -0.0100,  ...,  0.0087,  0.0056, -0.0241],
        [ 0.0078, -0.0092, -0.0025,  ...,  0.0060, -0.0021,  0.0114]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.3457, -3.6328, -3.1152,  ..., -1.3311, -1.2676, -2.2227]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 12:44:13 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is the most cheap, it is cheapest
If something is the most nice, it is nicest
If something is the most strong, it is strongest
If something is the most huge, it is hugest
If something is the most angry, it is angriest
If something is the most hardy, it is hardiest
If something is the most lucky, it is luckiest
If something is the most pure, it is
2024-07-30 12:44:13 root INFO     [order_1_approx] starting weight calculation for If something is the most huge, it is hugest
If something is the most nice, it is nicest
If something is the most angry, it is angriest
If something is the most pure, it is purest
If something is the most cheap, it is cheapest
If something is the most lucky, it is luckiest
If something is the most hardy, it is hardiest
If something is the most strong, it is
2024-07-30 12:44:13 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 12:46:46 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0137, -0.1311,  0.0995,  ...,  0.0427, -0.3376, -0.1827],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.4600, -7.4492, -3.0703,  ..., -0.3740, -1.1748, -2.3359],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0131, -0.0205,  0.0093,  ..., -0.0215,  0.0037,  0.0261],
        [-0.0158,  0.0049,  0.0280,  ..., -0.0071,  0.0052,  0.0047],
        [ 0.0036,  0.0075,  0.0041,  ...,  0.0059, -0.0217, -0.0018],
        ...,
        [-0.0034,  0.0312,  0.0012,  ...,  0.0145,  0.0002,  0.0081],
        [ 0.0075, -0.0084, -0.0100,  ..., -0.0156,  0.0129, -0.0319],
        [ 0.0054, -0.0158,  0.0178,  ...,  0.0037,  0.0080, -0.0172]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.2119, -7.2188, -3.0391,  ..., -0.7944, -1.6660, -2.1992]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 12:46:46 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is the most huge, it is hugest
If something is the most nice, it is nicest
If something is the most angry, it is angriest
If something is the most pure, it is purest
If something is the most cheap, it is cheapest
If something is the most lucky, it is luckiest
If something is the most hardy, it is hardiest
If something is the most strong, it is
2024-07-30 12:46:47 root INFO     [order_1_approx] starting weight calculation for If something is the most nice, it is nicest
If something is the most lucky, it is luckiest
If something is the most hardy, it is hardiest
If something is the most angry, it is angriest
If something is the most strong, it is strongest
If something is the most huge, it is hugest
If something is the most pure, it is purest
If something is the most cheap, it is
2024-07-30 12:46:47 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 12:49:13 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1292, -0.2220, -0.1057,  ...,  0.0313, -0.0585,  0.0366],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-2.6445, -0.2646, -2.2910,  ..., -2.3477, -1.5977, -2.1465],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0346, -0.0253,  0.0298,  ...,  0.0221,  0.0044,  0.0046],
        [-0.0040,  0.0121,  0.0304,  ..., -0.0105,  0.0027,  0.0174],
        [-0.0162,  0.0052,  0.0109,  ..., -0.0171, -0.0150,  0.0168],
        ...,
        [-0.0079,  0.0133,  0.0051,  ...,  0.0302,  0.0198,  0.0036],
        [ 0.0041, -0.0075, -0.0168,  ..., -0.0059,  0.0009, -0.0238],
        [ 0.0026, -0.0122, -0.0095,  ...,  0.0038, -0.0074,  0.0111]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-2.7012, -0.7856, -2.6211,  ..., -2.0742, -1.3877, -2.0508]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 12:49:13 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is the most nice, it is nicest
If something is the most lucky, it is luckiest
If something is the most hardy, it is hardiest
If something is the most angry, it is angriest
If something is the most strong, it is strongest
If something is the most huge, it is hugest
If something is the most pure, it is purest
If something is the most cheap, it is
2024-07-30 12:49:14 root INFO     [order_1_approx] starting weight calculation for If something is the most nice, it is nicest
If something is the most cheap, it is cheapest
If something is the most pure, it is purest
If something is the most huge, it is hugest
If something is the most angry, it is angriest
If something is the most strong, it is strongest
If something is the most lucky, it is luckiest
If something is the most hardy, it is
2024-07-30 12:49:14 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 12:51:46 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0016,  0.0210, -0.5059,  ..., -0.3179,  0.1132, -0.0585],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.2573, -7.2422, -1.4316,  ..., -2.2422, -3.0039, -2.3047],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0320, -0.0016,  0.0332,  ...,  0.0093, -0.0028, -0.0058],
        [ 0.0055,  0.0238, -0.0071,  ..., -0.0145,  0.0180, -0.0044],
        [ 0.0030, -0.0009,  0.0556,  ..., -0.0136, -0.0228, -0.0112],
        ...,
        [-0.0057,  0.0107,  0.0173,  ...,  0.0535,  0.0164,  0.0237],
        [ 0.0124, -0.0138, -0.0135,  ..., -0.0075,  0.0514, -0.0364],
        [-0.0039, -0.0161, -0.0086,  ..., -0.0140,  0.0174,  0.0383]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.0559, -7.2188, -1.5996,  ..., -1.7480, -2.8281, -2.0879]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 12:51:47 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is the most nice, it is nicest
If something is the most cheap, it is cheapest
If something is the most pure, it is purest
If something is the most huge, it is hugest
If something is the most angry, it is angriest
If something is the most strong, it is strongest
If something is the most lucky, it is luckiest
If something is the most hardy, it is
2024-07-30 12:51:48 root INFO     [order_1_approx] starting weight calculation for If something is the most pure, it is purest
If something is the most strong, it is strongest
If something is the most hardy, it is hardiest
If something is the most cheap, it is cheapest
If something is the most lucky, it is luckiest
If something is the most huge, it is hugest
If something is the most nice, it is nicest
If something is the most angry, it is
2024-07-30 12:51:48 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 12:54:19 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1031,  0.2891, -0.4839,  ..., -0.1046, -0.3105, -0.0396],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-2.1680, -7.1172, -2.9766,  ..., -2.7188, -2.5312, -1.3574],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 1.6815e-02, -1.4420e-02,  8.7662e-03,  ..., -9.4604e-04,
         -1.6571e-02,  6.8665e-03],
        [ 9.5062e-03,  1.3069e-02,  1.2802e-02,  ...,  5.0011e-03,
          4.1122e-03, -4.5090e-03],
        [-5.3749e-03, -1.1856e-02,  3.0640e-02,  ..., -1.8578e-03,
         -5.2643e-03,  8.3466e-03],
        ...,
        [ 7.1411e-03,  2.2980e-02,  1.0048e-02,  ...,  6.0997e-03,
          1.5297e-02,  1.4400e-04],
        [-1.3733e-04,  7.0534e-03,  1.3733e-03,  ..., -8.3923e-05,
          1.6800e-02, -2.7893e-02],
        [ 5.6801e-03,  7.5722e-03,  1.1795e-02,  ..., -6.9847e-03,
         -1.9501e-02,  9.1858e-03]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.3672, -6.6211, -3.4219,  ..., -2.1992, -2.8711, -1.6816]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 12:54:20 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is the most pure, it is purest
If something is the most strong, it is strongest
If something is the most hardy, it is hardiest
If something is the most cheap, it is cheapest
If something is the most lucky, it is luckiest
If something is the most huge, it is hugest
If something is the most nice, it is nicest
If something is the most angry, it is
2024-07-30 12:54:20 root INFO     [order_1_approx] starting weight calculation for If something is the most lucky, it is luckiest
If something is the most strong, it is strongest
If something is the most pure, it is purest
If something is the most cheap, it is cheapest
If something is the most nice, it is nicest
If something is the most hardy, it is hardiest
If something is the most angry, it is angriest
If something is the most huge, it is
2024-07-30 12:54:20 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 12:56:44 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0411, -0.0250,  0.0140,  ...,  0.1700, -0.0527, -0.3889],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.2910, -3.3496, -1.7041,  ..., -1.2637, -4.4219, -0.3311],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 1.5930e-02, -1.6388e-02, -1.3969e-02,  ..., -4.9591e-05,
          4.9515e-03,  1.1826e-03],
        [-2.4147e-03,  2.6001e-02,  3.6316e-02,  ..., -1.3046e-02,
         -1.6663e-02, -4.2152e-03],
        [-5.3825e-03, -6.1512e-04,  3.6102e-02,  ..., -8.6288e-03,
         -1.4809e-02,  3.0556e-03],
        ...,
        [-2.0218e-04,  3.5248e-02,  3.3417e-02,  ...,  4.0527e-02,
         -6.8741e-03,  1.6373e-02],
        [ 2.3407e-02,  1.1124e-02,  5.0354e-03,  ...,  2.5177e-02,
          3.8300e-02, -4.6921e-03],
        [ 1.1841e-02, -1.0414e-02,  7.0648e-03,  ...,  5.5046e-03,
         -5.5046e-03,  3.2463e-03]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.4077, -3.6973, -1.7510,  ..., -1.1699, -4.5977, -0.3984]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 12:56:45 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is the most lucky, it is luckiest
If something is the most strong, it is strongest
If something is the most pure, it is purest
If something is the most cheap, it is cheapest
If something is the most nice, it is nicest
If something is the most hardy, it is hardiest
If something is the most angry, it is angriest
If something is the most huge, it is
2024-07-30 12:56:45 root INFO     total operator prediction time: 1206.0621860027313 seconds
2024-07-30 12:56:45 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on verb_3pSg - Ved
2024-07-30 12:56:45 root INFO     building operator verb_3pSg - Ved
2024-07-30 12:56:46 root INFO     [order_1_approx] starting weight calculation for When he contains something, something has been contained
When he appoints something, something has been appointed
When he establishes something, something has been established
When he manages something, something has been managed
When he spends something, something has been spent
When he happens something, something has been happened
When he sends something, something has been sent
When he occurs something, something has been
2024-07-30 12:56:46 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 12:59:08 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.4639, -0.0155, -0.5449,  ..., -0.1346, -0.2316, -0.4248],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.2964,  1.0049,  2.1602,  ..., -0.6631, -0.1606,  0.5029],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0033, -0.0085,  0.0234,  ..., -0.0147,  0.0039,  0.0282],
        [ 0.0000,  0.0297,  0.0051,  ...,  0.0135, -0.0027, -0.0073],
        [ 0.0188, -0.0102, -0.0117,  ..., -0.0242, -0.0053, -0.0160],
        ...,
        [ 0.0120,  0.0118,  0.0245,  ...,  0.0174, -0.0071,  0.0195],
        [-0.0005, -0.0036, -0.0154,  ...,  0.0026,  0.0107,  0.0042],
        [ 0.0157,  0.0151,  0.0178,  ...,  0.0030, -0.0024,  0.0010]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.6934,  1.2451,  2.1738,  ..., -0.5571, -0.4341,  0.6187]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 12:59:09 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When he contains something, something has been contained
When he appoints something, something has been appointed
When he establishes something, something has been established
When he manages something, something has been managed
When he spends something, something has been spent
When he happens something, something has been happened
When he sends something, something has been sent
When he occurs something, something has been
2024-07-30 12:59:09 root INFO     [order_1_approx] starting weight calculation for When he appoints something, something has been appointed
When he happens something, something has been happened
When he establishes something, something has been established
When he sends something, something has been sent
When he manages something, something has been managed
When he contains something, something has been contained
When he occurs something, something has been occurred
When he spends something, something has been
2024-07-30 12:59:09 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 13:01:40 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.3135,  0.0623, -0.2976,  ...,  0.2773, -0.1356, -0.3162],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.7949, -1.0264, -0.8350,  ..., -0.9321, -1.6992, -1.3662],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0233, -0.0146,  0.0041,  ..., -0.0158,  0.0054,  0.0008],
        [-0.0208,  0.0366,  0.0018,  ..., -0.0006,  0.0094,  0.0076],
        [ 0.0087, -0.0173, -0.0143,  ..., -0.0163, -0.0024, -0.0109],
        ...,
        [ 0.0085,  0.0249,  0.0209,  ...,  0.0096, -0.0119,  0.0251],
        [-0.0048, -0.0132, -0.0206,  ...,  0.0098,  0.0229, -0.0219],
        [ 0.0034, -0.0036,  0.0189,  ...,  0.0084, -0.0161,  0.0035]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.0234, -1.1191, -0.6094,  ..., -0.8281, -1.2822, -1.7666]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 13:01:41 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When he appoints something, something has been appointed
When he happens something, something has been happened
When he establishes something, something has been established
When he sends something, something has been sent
When he manages something, something has been managed
When he contains something, something has been contained
When he occurs something, something has been occurred
When he spends something, something has been
2024-07-30 13:01:41 root INFO     [order_1_approx] starting weight calculation for When he spends something, something has been spent
When he establishes something, something has been established
When he sends something, something has been sent
When he occurs something, something has been occurred
When he appoints something, something has been appointed
When he manages something, something has been managed
When he happens something, something has been happened
When he contains something, something has been
2024-07-30 13:01:42 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 13:04:12 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1553, -0.2441, -0.5723,  ...,  0.3970,  0.0469, -0.3782],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.5010,  2.1992,  3.1406,  ..., -1.8789, -0.5586, -3.9102],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0316, -0.0087, -0.0047,  ...,  0.0015,  0.0042,  0.0376],
        [-0.0121,  0.0463,  0.0306,  ...,  0.0046, -0.0002,  0.0085],
        [ 0.0093,  0.0053,  0.0201,  ..., -0.0061, -0.0079, -0.0201],
        ...,
        [ 0.0089,  0.0018,  0.0097,  ...,  0.0218,  0.0106,  0.0165],
        [ 0.0196, -0.0106,  0.0053,  ...,  0.0026,  0.0077,  0.0024],
        [-0.0146, -0.0226,  0.0052,  ..., -0.0091, -0.0237, -0.0063]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.2285,  1.9111,  3.2285,  ..., -2.0098, -0.3086, -3.8711]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 13:04:13 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When he spends something, something has been spent
When he establishes something, something has been established
When he sends something, something has been sent
When he occurs something, something has been occurred
When he appoints something, something has been appointed
When he manages something, something has been managed
When he happens something, something has been happened
When he contains something, something has been
2024-07-30 13:04:13 root INFO     [order_1_approx] starting weight calculation for When he establishes something, something has been established
When he contains something, something has been contained
When he occurs something, something has been occurred
When he manages something, something has been managed
When he sends something, something has been sent
When he spends something, something has been spent
When he happens something, something has been happened
When he appoints something, something has been
2024-07-30 13:04:13 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 13:06:45 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1439,  0.2529, -0.1799,  ...,  0.2788, -0.0145, -0.3123],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.6172,  0.0330,  1.9336,  ...,  1.2764, -1.6709, -0.3945],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0175, -0.0145,  0.0051,  ..., -0.0120, -0.0029,  0.0116],
        [-0.0046,  0.0057,  0.0070,  ...,  0.0073,  0.0102, -0.0078],
        [ 0.0025, -0.0071, -0.0103,  ..., -0.0135, -0.0092, -0.0070],
        ...,
        [-0.0005,  0.0153, -0.0035,  ..., -0.0033, -0.0069,  0.0255],
        [ 0.0040, -0.0065, -0.0113,  ...,  0.0174,  0.0143, -0.0233],
        [-0.0008,  0.0104,  0.0125,  ...,  0.0096, -0.0075, -0.0061]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.6348, -0.1892,  2.2188,  ...,  1.3594, -1.5254, -0.5137]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 13:06:46 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When he establishes something, something has been established
When he contains something, something has been contained
When he occurs something, something has been occurred
When he manages something, something has been managed
When he sends something, something has been sent
When he spends something, something has been spent
When he happens something, something has been happened
When he appoints something, something has been
2024-07-30 13:06:46 root INFO     [order_1_approx] starting weight calculation for When he happens something, something has been happened
When he manages something, something has been managed
When he spends something, something has been spent
When he occurs something, something has been occurred
When he contains something, something has been contained
When he sends something, something has been sent
When he appoints something, something has been appointed
When he establishes something, something has been
2024-07-30 13:06:46 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 13:09:18 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2123,  0.2578, -0.4263,  ...,  0.2166, -0.1763,  0.1584],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.2520, -0.8037,  1.2598,  ...,  0.2305, -0.4609, -1.6562],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0023,  0.0030,  0.0040,  ...,  0.0092, -0.0081,  0.0070],
        [-0.0111,  0.0146,  0.0031,  ..., -0.0054,  0.0073, -0.0028],
        [ 0.0125, -0.0033, -0.0005,  ..., -0.0178,  0.0033,  0.0028],
        ...,
        [ 0.0088, -0.0029, -0.0017,  ..., -0.0036,  0.0041,  0.0123],
        [-0.0035,  0.0106, -0.0124,  ...,  0.0137,  0.0047, -0.0136],
        [-0.0021, -0.0041,  0.0188,  ...,  0.0095, -0.0138, -0.0117]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.3179, -0.5889,  1.4824,  ...,  0.5400, -0.5225, -1.9111]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 13:09:19 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When he happens something, something has been happened
When he manages something, something has been managed
When he spends something, something has been spent
When he occurs something, something has been occurred
When he contains something, something has been contained
When he sends something, something has been sent
When he appoints something, something has been appointed
When he establishes something, something has been
2024-07-30 13:09:19 root INFO     [order_1_approx] starting weight calculation for When he contains something, something has been contained
When he occurs something, something has been occurred
When he appoints something, something has been appointed
When he establishes something, something has been established
When he sends something, something has been sent
When he happens something, something has been happened
When he spends something, something has been spent
When he manages something, something has been
2024-07-30 13:09:19 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 13:11:51 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0325,  0.6123, -0.4473,  ...,  0.0613, -0.0723, -0.1440],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.4922, -0.7603,  2.6426,  ..., -0.4792, -0.7676, -2.9629],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0170, -0.0017, -0.0073,  ..., -0.0166,  0.0067,  0.0253],
        [-0.0035,  0.0235,  0.0260,  ...,  0.0203,  0.0130,  0.0104],
        [-0.0021, -0.0084,  0.0106,  ..., -0.0058, -0.0012, -0.0008],
        ...,
        [ 0.0124,  0.0123,  0.0106,  ...,  0.0152, -0.0020,  0.0070],
        [-0.0013, -0.0081, -0.0053,  ..., -0.0064,  0.0082, -0.0108],
        [ 0.0096, -0.0002,  0.0120,  ..., -0.0037, -0.0046, -0.0163]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.8223, -1.1182,  2.5586,  ..., -0.4998, -0.7725, -2.9824]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 13:11:52 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When he contains something, something has been contained
When he occurs something, something has been occurred
When he appoints something, something has been appointed
When he establishes something, something has been established
When he sends something, something has been sent
When he happens something, something has been happened
When he spends something, something has been spent
When he manages something, something has been
2024-07-30 13:11:52 root INFO     [order_1_approx] starting weight calculation for When he spends something, something has been spent
When he appoints something, something has been appointed
When he contains something, something has been contained
When he establishes something, something has been established
When he manages something, something has been managed
When he happens something, something has been happened
When he occurs something, something has been occurred
When he sends something, something has been
2024-07-30 13:11:52 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 13:14:24 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.3599,  0.2759, -0.0737,  ...,  0.2634,  0.1619, -0.3047],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.8203, -1.3662, -1.0908,  ..., -1.1953,  0.7114, -2.6992],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0415, -0.0039,  0.0201,  ..., -0.0144,  0.0092,  0.0021],
        [-0.0041,  0.0438,  0.0172,  ..., -0.0079,  0.0013, -0.0050],
        [ 0.0025, -0.0122,  0.0046,  ..., -0.0067, -0.0138, -0.0089],
        ...,
        [-0.0027,  0.0178,  0.0020,  ...,  0.0245, -0.0101,  0.0185],
        [-0.0097,  0.0050, -0.0192,  ...,  0.0069,  0.0226, -0.0149],
        [-0.0016, -0.0090,  0.0157,  ...,  0.0021, -0.0126, -0.0015]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.3086, -1.6465, -1.2090,  ..., -1.0781,  0.7642, -2.6680]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 13:14:25 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When he spends something, something has been spent
When he appoints something, something has been appointed
When he contains something, something has been contained
When he establishes something, something has been established
When he manages something, something has been managed
When he happens something, something has been happened
When he occurs something, something has been occurred
When he sends something, something has been
2024-07-30 13:14:25 root INFO     [order_1_approx] starting weight calculation for When he occurs something, something has been occurred
When he spends something, something has been spent
When he manages something, something has been managed
When he establishes something, something has been established
When he sends something, something has been sent
When he contains something, something has been contained
When he appoints something, something has been appointed
When he happens something, something has been
2024-07-30 13:14:25 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 13:16:56 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2059, -0.1582, -0.4443,  ..., -0.0642, -0.0288, -0.1265],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.8379,  0.9014,  2.1504,  ...,  0.2632, -3.2852,  0.6172],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0014, -0.0151, -0.0076,  ..., -0.0184,  0.0081,  0.0224],
        [-0.0256,  0.0211,  0.0103,  ...,  0.0057,  0.0108, -0.0030],
        [ 0.0250,  0.0068, -0.0042,  ..., -0.0236, -0.0141,  0.0179],
        ...,
        [ 0.0072,  0.0252, -0.0047,  ...,  0.0270,  0.0035,  0.0194],
        [-0.0124,  0.0039,  0.0076,  ...,  0.0033,  0.0119, -0.0042],
        [-0.0046,  0.0068,  0.0271,  ...,  0.0145,  0.0028, -0.0017]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.5586,  0.7637,  2.1934,  ...,  0.3132, -2.7383,  0.4568]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 13:16:58 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When he occurs something, something has been occurred
When he spends something, something has been spent
When he manages something, something has been managed
When he establishes something, something has been established
When he sends something, something has been sent
When he contains something, something has been contained
When he appoints something, something has been appointed
When he happens something, something has been
2024-07-30 13:16:58 root INFO     total operator prediction time: 1212.255921125412 seconds
2024-07-30 13:16:58 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on noun - plural_reg
2024-07-30 13:16:58 root INFO     building operator noun - plural_reg
2024-07-30 13:16:58 root INFO     [order_1_approx] starting weight calculation for The plural form of death is deaths
The plural form of population is populations
The plural form of idea is ideas
The plural form of road is roads
The plural form of river is rivers
The plural form of year is years
The plural form of department is departments
The plural form of album is
2024-07-30 13:16:58 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 13:19:30 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0422,  0.0693, -0.2496,  ..., -0.0432, -0.2272,  0.2522],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.0125, -3.5625,  1.5693,  ..., -0.0709, -0.9536, -0.7578],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0937,  0.0057, -0.0032,  ..., -0.0090,  0.0121,  0.0119],
        [-0.0075,  0.0726,  0.0135,  ...,  0.0264, -0.0113, -0.0094],
        [-0.0061, -0.0334,  0.0389,  ..., -0.0066, -0.0159, -0.0042],
        ...,
        [-0.0372,  0.0013, -0.0148,  ...,  0.0068, -0.0043,  0.0072],
        [-0.0296,  0.0101, -0.0018,  ...,  0.0155,  0.0395, -0.0108],
        [ 0.0031, -0.0003, -0.0053,  ..., -0.0315,  0.0096,  0.0339]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.0703, -3.6426,  1.8926,  ...,  0.0621, -1.2070, -0.5503]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 13:19:31 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of death is deaths
The plural form of population is populations
The plural form of idea is ideas
The plural form of road is roads
The plural form of river is rivers
The plural form of year is years
The plural form of department is departments
The plural form of album is
2024-07-30 13:19:31 root INFO     [order_1_approx] starting weight calculation for The plural form of road is roads
The plural form of idea is ideas
The plural form of department is departments
The plural form of population is populations
The plural form of death is deaths
The plural form of album is albums
The plural form of year is years
The plural form of river is
2024-07-30 13:19:31 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 13:22:06 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0926,  0.1748,  0.2034,  ..., -0.1667,  0.0249, -0.1254],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-3.1797, -6.2344,  2.2031,  ..., -2.0508,  1.6211, -2.0605],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0584, -0.0003,  0.0025,  ..., -0.0012, -0.0043, -0.0104],
        [-0.0024,  0.0392, -0.0161,  ..., -0.0085,  0.0042, -0.0200],
        [-0.0112,  0.0046,  0.0059,  ...,  0.0107, -0.0200,  0.0203],
        ...,
        [-0.0113,  0.0236, -0.0073,  ...,  0.0390, -0.0002, -0.0156],
        [ 0.0037,  0.0075,  0.0117,  ...,  0.0073,  0.0406, -0.0216],
        [ 0.0206, -0.0131, -0.0307,  ...,  0.0033, -0.0067,  0.0204]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-3.1777, -6.2148,  1.8467,  ..., -2.0566,  1.5557, -1.7090]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 13:22:07 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of road is roads
The plural form of idea is ideas
The plural form of department is departments
The plural form of population is populations
The plural form of death is deaths
The plural form of album is albums
The plural form of year is years
The plural form of river is
2024-07-30 13:22:07 root INFO     [order_1_approx] starting weight calculation for The plural form of population is populations
The plural form of river is rivers
The plural form of album is albums
The plural form of department is departments
The plural form of idea is ideas
The plural form of death is deaths
The plural form of road is roads
The plural form of year is
2024-07-30 13:22:07 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 13:24:42 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1029,  0.0479, -0.1550,  ..., -0.2832, -0.2084,  0.1963],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.2061, -4.7969,  1.9961,  ..., -1.8164, -0.4519, -4.3750],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0342,  0.0030, -0.0062,  ...,  0.0035, -0.0082, -0.0071],
        [-0.0114,  0.0382, -0.0038,  ...,  0.0150, -0.0067, -0.0304],
        [ 0.0020,  0.0208,  0.0394,  ...,  0.0018, -0.0179,  0.0349],
        ...,
        [ 0.0257,  0.0195, -0.0033,  ...,  0.0229, -0.0264,  0.0175],
        [-0.0266,  0.0325,  0.0246,  ...,  0.0258,  0.0254, -0.0189],
        [-0.0257, -0.0046, -0.0150,  ...,  0.0006, -0.0011,  0.0236]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.1523, -5.0703,  1.9336,  ..., -2.0215, -1.0957, -4.4609]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 13:24:43 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of population is populations
The plural form of river is rivers
The plural form of album is albums
The plural form of department is departments
The plural form of idea is ideas
The plural form of death is deaths
The plural form of road is roads
The plural form of year is
2024-07-30 13:24:43 root INFO     [order_1_approx] starting weight calculation for The plural form of death is deaths
The plural form of road is roads
The plural form of year is years
The plural form of album is albums
The plural form of idea is ideas
The plural form of population is populations
The plural form of river is rivers
The plural form of department is
2024-07-30 13:24:43 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 13:27:16 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1848,  0.1067, -0.1002,  ..., -0.1246,  0.0639,  0.0427],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.1738, -3.0234,  2.9629,  ..., -1.3594,  1.2686, -2.3281],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 5.6671e-02,  6.3057e-03, -1.2123e-02,  ..., -5.8594e-03,
         -1.1391e-02,  6.9160e-03],
        [ 1.8448e-02,  2.4567e-02,  6.7406e-03,  ...,  1.1642e-02,
         -1.4450e-02,  5.7220e-05],
        [-1.8936e-02,  1.9333e-02,  2.6718e-02,  ...,  1.2405e-02,
         -1.9440e-02,  7.4387e-03],
        ...,
        [-3.0334e-02,  2.1179e-02, -5.6610e-03,  ...,  2.1179e-02,
         -2.0599e-04, -1.1673e-02],
        [-3.1921e-02,  2.0187e-02, -2.9793e-03,  ...,  2.4841e-02,
          1.7944e-02,  5.6534e-03],
        [ 2.3010e-02, -2.7466e-02,  1.7014e-03,  ..., -9.1400e-03,
         -1.6357e-02,  2.2141e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.0430, -3.3574,  2.8496,  ..., -1.1533,  1.4512, -1.6533]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 13:27:17 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of death is deaths
The plural form of road is roads
The plural form of year is years
The plural form of album is albums
The plural form of idea is ideas
The plural form of population is populations
The plural form of river is rivers
The plural form of department is
2024-07-30 13:27:17 root INFO     [order_1_approx] starting weight calculation for The plural form of year is years
The plural form of album is albums
The plural form of department is departments
The plural form of death is deaths
The plural form of idea is ideas
The plural form of road is roads
The plural form of river is rivers
The plural form of population is
2024-07-30 13:27:18 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 13:29:52 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3584,  0.2717, -0.0229,  ..., -0.2822,  0.0811,  0.0933],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.4199, -3.6914,  1.5859,  ..., -1.5742, -2.9922, -2.0918],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0191,  0.0245, -0.0149,  ..., -0.0062,  0.0106,  0.0020],
        [ 0.0131,  0.0411,  0.0390,  ...,  0.0231, -0.0299,  0.0148],
        [ 0.0121,  0.0181,  0.0378,  ..., -0.0082, -0.0197,  0.0081],
        ...,
        [ 0.0110,  0.0049, -0.0033,  ...,  0.0414, -0.0095,  0.0259],
        [-0.0065, -0.0048, -0.0317,  ..., -0.0094,  0.0270, -0.0348],
        [-0.0096,  0.0182,  0.0172,  ...,  0.0202, -0.0275,  0.0461]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.4824, -4.1914,  1.1367,  ..., -1.6611, -2.9473, -2.1348]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 13:29:53 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of year is years
The plural form of album is albums
The plural form of department is departments
The plural form of death is deaths
The plural form of idea is ideas
The plural form of road is roads
The plural form of river is rivers
The plural form of population is
2024-07-30 13:29:53 root INFO     [order_1_approx] starting weight calculation for The plural form of population is populations
The plural form of album is albums
The plural form of department is departments
The plural form of year is years
The plural form of road is roads
The plural form of death is deaths
The plural form of river is rivers
The plural form of idea is
2024-07-30 13:29:53 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 13:32:25 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0502,  0.1313,  0.1895,  ..., -0.2253, -0.2017,  0.1954],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.5488, -2.7656,  2.4980,  ..., -0.6196, -1.1758, -2.1680],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 5.7953e-02, -2.9785e-02, -1.1044e-03,  ...,  2.3178e-02,
         -1.0643e-03,  1.9379e-02],
        [-9.8724e-03,  3.5095e-02,  1.4923e-02,  ...,  6.4850e-05,
         -1.7746e-02, -3.4561e-03],
        [-1.6953e-02, -2.3102e-02,  2.2369e-02,  ...,  5.3711e-03,
          2.0351e-03,  1.9012e-02],
        ...,
        [-7.2632e-03,  2.8412e-02, -3.3054e-03,  ...,  4.3411e-03,
          6.3210e-03, -2.4658e-02],
        [-1.8829e-02,  2.8442e-02,  2.5848e-02,  ..., -9.4376e-03,
          2.9572e-02, -1.6251e-02],
        [ 2.0401e-02, -8.5449e-03,  1.0719e-03,  ...,  1.0078e-02,
         -8.3694e-03,  3.1494e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.3320, -3.0723,  2.6836,  ..., -0.3887, -1.1318, -2.2793]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 13:32:26 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of population is populations
The plural form of album is albums
The plural form of department is departments
The plural form of year is years
The plural form of road is roads
The plural form of death is deaths
The plural form of river is rivers
The plural form of idea is
2024-07-30 13:32:26 root INFO     [order_1_approx] starting weight calculation for The plural form of idea is ideas
The plural form of population is populations
The plural form of death is deaths
The plural form of river is rivers
The plural form of department is departments
The plural form of year is years
The plural form of album is albums
The plural form of road is
2024-07-30 13:32:26 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 13:35:01 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0083, -0.0300,  0.2324,  ...,  0.0754,  0.1204, -0.0450],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.9458, -5.2852, -1.4043,  ...,  0.1279, -0.9902, -2.3066],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 6.8665e-02, -1.1726e-02, -6.4926e-03,  ...,  2.0752e-02,
         -2.2850e-03, -3.9368e-03],
        [-5.8594e-03,  3.7415e-02,  9.6130e-03,  ...,  6.6757e-05,
         -6.7425e-04, -2.7428e-03],
        [-1.3786e-02,  1.1902e-02,  3.6713e-02,  ...,  2.2526e-03,
         -5.3444e-03,  3.8788e-02],
        ...,
        [ 1.3039e-02,  5.0430e-03,  1.4091e-02,  ...,  1.9745e-02,
          9.0332e-03,  1.3100e-02],
        [-1.4122e-02,  3.6888e-03,  7.4196e-04,  ..., -9.9182e-05,
          3.9368e-02,  1.3332e-03],
        [-1.5488e-02, -1.9333e-02,  4.9820e-03,  ..., -5.3024e-03,
         -3.9062e-03,  1.5442e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.8486, -5.6250, -1.4844,  ...,  0.0447, -0.8740, -2.0391]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 13:35:02 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of idea is ideas
The plural form of population is populations
The plural form of death is deaths
The plural form of river is rivers
The plural form of department is departments
The plural form of year is years
The plural form of album is albums
The plural form of road is
2024-07-30 13:35:02 root INFO     [order_1_approx] starting weight calculation for The plural form of population is populations
The plural form of idea is ideas
The plural form of year is years
The plural form of road is roads
The plural form of river is rivers
The plural form of album is albums
The plural form of department is departments
The plural form of death is
2024-07-30 13:35:02 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 13:37:36 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0054, -0.1478,  0.0612,  ..., -0.3684, -0.1816,  0.3174],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.9248, -2.8711,  1.5605,  ..., -1.9971, -0.9253, -2.6055],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 6.0608e-02, -3.4668e-02,  1.8066e-02,  ...,  5.6549e-02,
          1.0681e-02,  3.9185e-02],
        [-1.1734e-02,  7.0374e-02,  9.1553e-05,  ...,  3.1128e-03,
         -2.2415e-02, -1.5099e-02],
        [-7.6523e-03,  1.3283e-02,  3.7476e-02,  ..., -2.4414e-03,
         -1.4687e-02,  2.2293e-02],
        ...,
        [ 2.0615e-02, -1.0727e-02, -7.6523e-03,  ...,  6.2714e-03,
         -1.7029e-02, -1.4709e-02],
        [-1.7090e-02,  4.5135e-02, -1.3351e-02,  ..., -2.6855e-02,
          4.5624e-02, -3.1677e-02],
        [ 2.1935e-03, -1.3611e-02, -5.8670e-03,  ...,  2.1362e-02,
         -9.9182e-03,  5.6519e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.5850, -3.1445,  1.2412,  ..., -1.8887, -1.2568, -2.6758]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 13:37:37 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of population is populations
The plural form of idea is ideas
The plural form of year is years
The plural form of road is roads
The plural form of river is rivers
The plural form of album is albums
The plural form of department is departments
The plural form of death is
2024-07-30 13:37:37 root INFO     total operator prediction time: 1239.0172452926636 seconds
2024-07-30 13:37:37 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on verb_Ving - 3pSg
2024-07-30 13:37:37 root INFO     building operator verb_Ving - 3pSg
2024-07-30 13:37:37 root INFO     [order_1_approx] starting weight calculation for When something is providing, it provides
When something is thanking, it thanks
When something is creating, it creates
When something is containing, it contains
When something is operating, it operates
When something is becoming, it becomes
When something is learning, it learns
When something is publishing, it
2024-07-30 13:37:37 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 13:40:11 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1918, -0.0895,  0.0742,  ...,  0.3579,  0.0317,  0.0557],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.2930, -4.3984, -0.6406,  ..., -1.8486, -5.9180,  0.0918],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 3.6072e-02, -9.1019e-03,  9.1171e-04,  ...,  1.7715e-02,
          4.9858e-03,  1.8723e-02],
        [-2.1515e-02,  2.2263e-02, -1.0696e-02,  ..., -3.1776e-03,
          1.0910e-02,  8.4686e-04],
        [ 2.2522e-02,  1.5259e-05,  4.2648e-03,  ..., -1.8692e-02,
         -3.5217e-02, -1.3138e-02],
        ...,
        [ 6.0158e-03,  5.9204e-03,  5.0468e-03,  ...,  2.8580e-02,
          1.2520e-02,  2.0966e-02],
        [ 5.5847e-03, -5.7144e-03, -2.5787e-02,  ...,  7.6752e-03,
         -4.3831e-03, -4.0100e-02],
        [ 1.5686e-02,  1.6388e-02,  3.3092e-03,  ..., -8.3694e-03,
         -2.5528e-02, -7.3318e-03]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.5352, -4.1289, -0.4668,  ..., -1.7510, -5.8320, -0.2668]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 13:40:12 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When something is providing, it provides
When something is thanking, it thanks
When something is creating, it creates
When something is containing, it contains
When something is operating, it operates
When something is becoming, it becomes
When something is learning, it learns
When something is publishing, it
2024-07-30 13:40:12 root INFO     [order_1_approx] starting weight calculation for When something is creating, it creates
When something is becoming, it becomes
When something is learning, it learns
When something is thanking, it thanks
When something is publishing, it publishes
When something is containing, it contains
When something is operating, it operates
When something is providing, it
2024-07-30 13:40:12 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 13:42:46 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1000,  0.0153, -0.2537,  ...,  0.1517, -0.2874, -0.2588],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.8438, -5.8984, -0.6426,  ..., -1.3320, -7.5859,  0.2891],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0503,  0.0029,  0.0170,  ...,  0.0131,  0.0038,  0.0586],
        [-0.0306,  0.0304, -0.0010,  ...,  0.0129, -0.0150,  0.0150],
        [-0.0022, -0.0039,  0.0266,  ..., -0.0191,  0.0081, -0.0155],
        ...,
        [ 0.0107,  0.0174,  0.0065,  ...,  0.0220, -0.0143,  0.0262],
        [ 0.0341, -0.0147, -0.0072,  ..., -0.0040,  0.0352, -0.0549],
        [-0.0042,  0.0019,  0.0094,  ..., -0.0048, -0.0150,  0.0291]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.4180, -5.5781, -0.2341,  ..., -1.3145, -6.7500, -0.0803]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 13:42:47 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When something is creating, it creates
When something is becoming, it becomes
When something is learning, it learns
When something is thanking, it thanks
When something is publishing, it publishes
When something is containing, it contains
When something is operating, it operates
When something is providing, it
2024-07-30 13:42:47 root INFO     [order_1_approx] starting weight calculation for When something is containing, it contains
When something is thanking, it thanks
When something is learning, it learns
When something is publishing, it publishes
When something is becoming, it becomes
When something is creating, it creates
When something is providing, it provides
When something is operating, it
2024-07-30 13:42:47 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 13:45:19 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0809,  0.2432, -0.3250,  ..., -0.0933, -0.2151, -0.3281],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.5859, -4.4336, -0.5566,  ..., -1.8770, -5.0547, -0.3057],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0191, -0.0055, -0.0055,  ...,  0.0042,  0.0055,  0.0307],
        [-0.0128,  0.0415, -0.0152,  ..., -0.0113,  0.0015,  0.0091],
        [-0.0016,  0.0160,  0.0329,  ..., -0.0019, -0.0136, -0.0006],
        ...,
        [ 0.0164,  0.0066, -0.0116,  ...,  0.0277, -0.0057,  0.0252],
        [ 0.0086, -0.0136, -0.0012,  ..., -0.0029,  0.0075, -0.0314],
        [ 0.0190, -0.0108,  0.0064,  ..., -0.0002, -0.0078,  0.0097]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.4727, -4.3398, -0.1738,  ..., -1.5996, -4.9844, -0.1576]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 13:45:20 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When something is containing, it contains
When something is thanking, it thanks
When something is learning, it learns
When something is publishing, it publishes
When something is becoming, it becomes
When something is creating, it creates
When something is providing, it provides
When something is operating, it
2024-07-30 13:45:20 root INFO     [order_1_approx] starting weight calculation for When something is publishing, it publishes
When something is learning, it learns
When something is creating, it creates
When something is thanking, it thanks
When something is operating, it operates
When something is containing, it contains
When something is providing, it provides
When something is becoming, it
2024-07-30 13:45:20 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 13:47:54 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0049,  0.2349,  0.0094,  ...,  0.1248, -0.1133,  0.0487],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.7500, -2.0234, -0.7188,  ...,  0.8286, -3.3359, -1.3887],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0122,  0.0226,  0.0274,  ...,  0.0262,  0.0078,  0.0332],
        [ 0.0025,  0.0331, -0.0145,  ...,  0.0198, -0.0209,  0.0113],
        [ 0.0141, -0.0249,  0.0326,  ..., -0.0062,  0.0113,  0.0071],
        ...,
        [ 0.0178,  0.0115, -0.0148,  ...,  0.0296, -0.0081,  0.0211],
        [ 0.0312,  0.0165, -0.0157,  ..., -0.0174,  0.0206, -0.0354],
        [-0.0118, -0.0020,  0.0096,  ...,  0.0005,  0.0034,  0.0158]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.3301, -2.0352, -0.6650,  ...,  0.8843, -3.6953, -1.3086]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 13:47:55 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When something is publishing, it publishes
When something is learning, it learns
When something is creating, it creates
When something is thanking, it thanks
When something is operating, it operates
When something is containing, it contains
When something is providing, it provides
When something is becoming, it
2024-07-30 13:47:56 root INFO     [order_1_approx] starting weight calculation for When something is publishing, it publishes
When something is learning, it learns
When something is containing, it contains
When something is thanking, it thanks
When something is becoming, it becomes
When something is providing, it provides
When something is operating, it operates
When something is creating, it
2024-07-30 13:47:56 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 13:50:29 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0744,  0.2269, -0.0969,  ...,  0.1414,  0.0265, -0.2222],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.3193, -2.9668,  0.5918,  ...,  0.1191, -5.9492,  0.8203],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0330,  0.0043,  0.0073,  ...,  0.0286, -0.0144,  0.0154],
        [-0.0126,  0.0369, -0.0052,  ...,  0.0018, -0.0193, -0.0212],
        [ 0.0141, -0.0180,  0.0161,  ...,  0.0164,  0.0155,  0.0037],
        ...,
        [ 0.0182,  0.0115, -0.0021,  ...,  0.0110, -0.0011,  0.0100],
        [ 0.0091,  0.0104, -0.0188,  ..., -0.0094,  0.0359, -0.0287],
        [-0.0141,  0.0163,  0.0064,  ..., -0.0125, -0.0081,  0.0144]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.3438, -2.7324,  0.6729,  ...,  0.4885, -6.2070,  0.7075]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 13:50:30 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When something is publishing, it publishes
When something is learning, it learns
When something is containing, it contains
When something is thanking, it thanks
When something is becoming, it becomes
When something is providing, it provides
When something is operating, it operates
When something is creating, it
2024-07-30 13:50:30 root INFO     [order_1_approx] starting weight calculation for When something is becoming, it becomes
When something is creating, it creates
When something is thanking, it thanks
When something is containing, it contains
When something is publishing, it publishes
When something is operating, it operates
When something is providing, it provides
When something is learning, it
2024-07-30 13:50:30 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 13:53:04 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.3325,  0.3652, -0.1238,  ..., -0.1384, -0.1615,  0.0283],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.9043, -2.6035, -0.0605,  ...,  0.9443, -5.6953, -3.5664],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0226, -0.0094,  0.0031,  ..., -0.0046,  0.0036,  0.0116],
        [ 0.0003,  0.0310, -0.0140,  ..., -0.0159, -0.0013,  0.0045],
        [-0.0030, -0.0109,  0.0408,  ..., -0.0020,  0.0232, -0.0077],
        ...,
        [ 0.0193,  0.0034,  0.0007,  ...,  0.0227,  0.0120,  0.0017],
        [ 0.0027,  0.0249, -0.0118,  ...,  0.0084,  0.0154, -0.0409],
        [ 0.0032, -0.0037,  0.0165,  ..., -0.0101, -0.0151, -0.0013]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.9971, -2.4043, -0.1399,  ...,  1.3525, -5.9492, -3.4922]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 13:53:06 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When something is becoming, it becomes
When something is creating, it creates
When something is thanking, it thanks
When something is containing, it contains
When something is publishing, it publishes
When something is operating, it operates
When something is providing, it provides
When something is learning, it
2024-07-30 13:53:06 root INFO     [order_1_approx] starting weight calculation for When something is publishing, it publishes
When something is thanking, it thanks
When something is creating, it creates
When something is operating, it operates
When something is providing, it provides
When something is becoming, it becomes
When something is learning, it learns
When something is containing, it
2024-07-30 13:53:06 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 13:55:40 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1482, -0.2754, -0.4624,  ...,  0.0923, -0.2117, -0.2888],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.8823, -2.1211,  0.6387,  ..., -2.2168, -4.7891, -1.7002],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0133, -0.0033, -0.0073,  ..., -0.0115, -0.0145,  0.0238],
        [-0.0045,  0.0633,  0.0116,  ..., -0.0182, -0.0035, -0.0023],
        [ 0.0112,  0.0123,  0.0285,  ..., -0.0247, -0.0045, -0.0085],
        ...,
        [-0.0144,  0.0009,  0.0208,  ...,  0.0168, -0.0098,  0.0264],
        [ 0.0340, -0.0103, -0.0269,  ..., -0.0040,  0.0167, -0.0262],
        [ 0.0151, -0.0079,  0.0180,  ..., -0.0299, -0.0262, -0.0082]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.8013, -2.4648,  0.6699,  ..., -1.8486, -3.8867, -2.0469]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 13:55:41 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When something is publishing, it publishes
When something is thanking, it thanks
When something is creating, it creates
When something is operating, it operates
When something is providing, it provides
When something is becoming, it becomes
When something is learning, it learns
When something is containing, it
2024-07-30 13:55:41 root INFO     [order_1_approx] starting weight calculation for When something is learning, it learns
When something is providing, it provides
When something is creating, it creates
When something is becoming, it becomes
When something is publishing, it publishes
When something is operating, it operates
When something is containing, it contains
When something is thanking, it
2024-07-30 13:55:41 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 13:58:15 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.4639,  0.1531, -0.2419,  ...,  0.2068, -0.1946, -0.0840],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.7588, -4.1484, -1.2852,  ..., -1.9316, -7.9531,  1.0332],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 1.3626e-02, -2.2335e-03,  1.7502e-02,  ..., -9.7580e-03,
         -1.0040e-02,  2.1095e-03],
        [-6.7978e-03,  2.3422e-02,  9.1095e-03,  ..., -1.6663e-02,
         -9.5825e-03,  2.9053e-02],
        [ 1.3306e-02, -8.7433e-03, -1.8997e-02,  ...,  9.4147e-03,
          4.2381e-03, -8.1100e-03],
        ...,
        [ 6.2637e-03,  1.4244e-02,  3.1605e-03,  ..., -4.0054e-05,
         -9.3689e-03,  2.6245e-02],
        [ 2.9480e-02, -5.8746e-04, -1.1383e-02,  ..., -1.2589e-03,
          4.2053e-02, -2.0905e-02],
        [-3.3020e-02,  4.6539e-04,  2.6215e-02,  ...,  1.1253e-02,
         -9.7961e-03,  8.1558e-03]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.5381, -3.8945, -1.0840,  ..., -1.8740, -7.8828,  0.6416]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 13:58:16 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When something is learning, it learns
When something is providing, it provides
When something is creating, it creates
When something is becoming, it becomes
When something is publishing, it publishes
When something is operating, it operates
When something is containing, it contains
When something is thanking, it
2024-07-30 13:58:16 root INFO     total operator prediction time: 1238.974530696869 seconds
2024-07-30 13:58:16 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on verb_inf - 3pSg
2024-07-30 13:58:16 root INFO     building operator verb_inf - 3pSg
2024-07-30 13:58:16 root INFO     [order_1_approx] starting weight calculation for I refer, he refers
I operate, he operates
I improve, he improves
I reduce, he reduces
I allow, he allows
I tell, he tells
I hear, he hears
I involve, he
2024-07-30 13:58:16 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 14:00:49 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1399,  0.3291, -0.3110,  ...,  0.1716, -0.5288, -0.0490],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.2520, -1.9756,  3.5215,  ...,  0.4688, -3.8770, -3.5586],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0362,  0.0105, -0.0034,  ...,  0.0242, -0.0059,  0.0155],
        [-0.0074,  0.0282, -0.0013,  ..., -0.0068,  0.0130, -0.0007],
        [-0.0086,  0.0089,  0.0257,  ..., -0.0106, -0.0060,  0.0111],
        ...,
        [ 0.0026,  0.0123, -0.0114,  ...,  0.0040,  0.0088, -0.0024],
        [-0.0190, -0.0128, -0.0054,  ..., -0.0099,  0.0156, -0.0192],
        [-0.0088,  0.0123, -0.0019,  ..., -0.0084, -0.0041, -0.0072]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.9873, -1.8447,  3.3145,  ...,  0.7754, -4.2383, -3.4844]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 14:00:50 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for I refer, he refers
I operate, he operates
I improve, he improves
I reduce, he reduces
I allow, he allows
I tell, he tells
I hear, he hears
I involve, he
2024-07-30 14:00:50 root INFO     [order_1_approx] starting weight calculation for I involve, he involves
I improve, he improves
I hear, he hears
I allow, he allows
I operate, he operates
I reduce, he reduces
I refer, he refers
I tell, he
2024-07-30 14:00:50 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 14:03:23 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0106, -0.0547, -0.2026,  ...,  0.1335, -0.0103, -0.0299],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([  2.4785,  -1.9785,   1.3320,  ...,   2.0039, -10.5234,  -1.4902],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0358,  0.0114, -0.0154,  ...,  0.0148,  0.0012,  0.0117],
        [-0.0126,  0.0228, -0.0051,  ..., -0.0105,  0.0120, -0.0136],
        [-0.0156, -0.0015,  0.0024,  ..., -0.0024, -0.0098, -0.0018],
        ...,
        [ 0.0020,  0.0050,  0.0044,  ...,  0.0006,  0.0128, -0.0032],
        [-0.0163, -0.0159,  0.0035,  ..., -0.0246,  0.0257,  0.0003],
        [ 0.0104,  0.0055, -0.0010,  ..., -0.0130,  0.0012,  0.0020]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[  2.2969,  -2.0117,   0.8286,  ...,   2.3516, -10.3672,  -1.5576]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 14:03:24 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for I involve, he involves
I improve, he improves
I hear, he hears
I allow, he allows
I operate, he operates
I reduce, he reduces
I refer, he refers
I tell, he
2024-07-30 14:03:25 root INFO     [order_1_approx] starting weight calculation for I operate, he operates
I tell, he tells
I involve, he involves
I hear, he hears
I reduce, he reduces
I allow, he allows
I refer, he refers
I improve, he
2024-07-30 14:03:25 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 14:05:59 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1213,  0.1808, -0.3320,  ..., -0.2739,  0.1064, -0.0530],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 6.3164, -3.7246, -1.7031,  ...,  1.1152, -7.3555,  0.6426],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0222,  0.0252, -0.0026,  ...,  0.0160,  0.0029,  0.0176],
        [ 0.0097,  0.0234,  0.0091,  ...,  0.0044,  0.0074,  0.0034],
        [ 0.0088,  0.0056,  0.0092,  ..., -0.0182,  0.0054, -0.0023],
        ...,
        [-0.0006,  0.0008, -0.0084,  ...,  0.0183, -0.0003, -0.0086],
        [-0.0037, -0.0114,  0.0045,  ...,  0.0071,  0.0033, -0.0166],
        [-0.0061, -0.0039, -0.0009,  ..., -0.0095, -0.0158,  0.0101]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 5.5781, -3.7129, -1.5576,  ...,  1.2119, -7.7539,  0.2688]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 14:05:59 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for I operate, he operates
I tell, he tells
I involve, he involves
I hear, he hears
I reduce, he reduces
I allow, he allows
I refer, he refers
I improve, he
2024-07-30 14:06:00 root INFO     [order_1_approx] starting weight calculation for I involve, he involves
I tell, he tells
I improve, he improves
I refer, he refers
I reduce, he reduces
I operate, he operates
I hear, he hears
I allow, he
2024-07-30 14:06:00 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 14:08:34 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1537,  0.2200, -0.2666,  ..., -0.3560, -0.3960, -0.1144],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.8594, -4.7383, -1.2148,  ..., -0.7793, -7.9102,  0.7109],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 6.3538e-02,  1.6830e-02,  1.8921e-03,  ..., -1.3275e-03,
         -2.7893e-02, -1.2970e-03],
        [-1.7838e-02,  1.5526e-02, -4.8332e-03,  ...,  4.6997e-03,
          1.7273e-02, -5.3139e-03],
        [-1.7807e-02,  1.3680e-02,  2.9404e-02,  ..., -3.1555e-02,
         -1.2077e-02, -8.7280e-03],
        ...,
        [-4.9629e-03, -6.1531e-03, -2.6474e-03,  ...,  2.1149e-02,
          2.7893e-02, -7.8201e-05],
        [-3.6499e-02,  2.8267e-03, -1.1383e-02,  ..., -2.2491e-02,
          3.0426e-02, -1.3840e-02],
        [-2.5902e-03,  2.3438e-02, -1.9550e-03,  ...,  4.4594e-03,
         -1.4030e-02,  8.5297e-03]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.9766, -4.7344, -1.1338,  ...,  0.1206, -8.2266,  0.3577]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 14:08:35 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for I involve, he involves
I tell, he tells
I improve, he improves
I refer, he refers
I reduce, he reduces
I operate, he operates
I hear, he hears
I allow, he
2024-07-30 14:08:35 root INFO     [order_1_approx] starting weight calculation for I tell, he tells
I reduce, he reduces
I refer, he refers
I involve, he involves
I operate, he operates
I improve, he improves
I allow, he allows
I hear, he
2024-07-30 14:08:35 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 14:11:07 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1442,  0.2004, -0.1377,  ...,  0.1506,  0.0703,  0.1185],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.5088, -3.8262, -2.1719,  ..., -2.8828, -8.5625, -3.4805],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0768, -0.0078, -0.0165,  ..., -0.0082, -0.0096,  0.0307],
        [-0.0217,  0.0540,  0.0007,  ...,  0.0204,  0.0168, -0.0497],
        [ 0.0082, -0.0198,  0.0232,  ..., -0.0261, -0.0013,  0.0044],
        ...,
        [ 0.0230, -0.0224, -0.0123,  ...,  0.0147,  0.0271, -0.0009],
        [-0.0096, -0.0096,  0.0016,  ..., -0.0140,  0.0401, -0.0231],
        [ 0.0282, -0.0304, -0.0049,  ..., -0.0374, -0.0064,  0.0039]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.8364, -3.8828, -2.1484,  ..., -2.2461, -8.5938, -2.9707]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 14:11:08 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for I tell, he tells
I reduce, he reduces
I refer, he refers
I involve, he involves
I operate, he operates
I improve, he improves
I allow, he allows
I hear, he
2024-07-30 14:11:08 root INFO     [order_1_approx] starting weight calculation for I hear, he hears
I involve, he involves
I operate, he operates
I tell, he tells
I refer, he refers
I improve, he improves
I allow, he allows
I reduce, he
2024-07-30 14:11:08 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 14:13:42 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1655,  0.1687, -0.4861,  ..., -0.3086,  0.1223, -0.1917],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.1641, -2.8535, -0.5605,  ..., -3.1602, -8.0469, -4.4062],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0378, -0.0015,  0.0031,  ...,  0.0170,  0.0023,  0.0184],
        [-0.0121,  0.0155, -0.0015,  ...,  0.0078,  0.0021, -0.0027],
        [ 0.0075,  0.0034,  0.0258,  ..., -0.0126,  0.0021, -0.0049],
        ...,
        [ 0.0038, -0.0218, -0.0148,  ...,  0.0177, -0.0098,  0.0114],
        [ 0.0174, -0.0014, -0.0114,  ..., -0.0152,  0.0169, -0.0379],
        [-0.0180, -0.0037,  0.0181,  ..., -0.0036, -0.0100,  0.0168]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.1011, -2.8379, -0.7148,  ..., -2.4258, -7.9375, -4.2695]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 14:13:43 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for I hear, he hears
I involve, he involves
I operate, he operates
I tell, he tells
I refer, he refers
I improve, he improves
I allow, he allows
I reduce, he
2024-07-30 14:13:43 root INFO     [order_1_approx] starting weight calculation for I allow, he allows
I improve, he improves
I hear, he hears
I reduce, he reduces
I refer, he refers
I involve, he involves
I tell, he tells
I operate, he
2024-07-30 14:13:43 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 14:16:17 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0119, -0.0651, -0.6558,  ..., -0.1543, -0.3574, -0.2183],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.7734, -4.3242,  0.2871,  ..., -1.2529, -5.4883, -0.1191],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0318, -0.0055,  0.0135,  ...,  0.0220, -0.0189,  0.0280],
        [-0.0053,  0.0245, -0.0012,  ...,  0.0021,  0.0310, -0.0132],
        [ 0.0145,  0.0204,  0.0278,  ..., -0.0324,  0.0071, -0.0199],
        ...,
        [ 0.0135, -0.0036, -0.0207,  ...,  0.0125,  0.0150,  0.0010],
        [ 0.0160, -0.0166, -0.0270,  ..., -0.0125,  0.0267, -0.0246],
        [ 0.0114, -0.0013, -0.0028,  ..., -0.0137, -0.0016,  0.0191]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.4258, -4.1016,  0.5908,  ..., -0.6538, -5.9062, -0.3250]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 14:16:18 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for I allow, he allows
I improve, he improves
I hear, he hears
I reduce, he reduces
I refer, he refers
I involve, he involves
I tell, he tells
I operate, he
2024-07-30 14:16:18 root INFO     [order_1_approx] starting weight calculation for I reduce, he reduces
I allow, he allows
I improve, he improves
I involve, he involves
I hear, he hears
I tell, he tells
I operate, he operates
I refer, he
2024-07-30 14:16:18 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 14:18:52 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.3406,  0.1373, -0.4539,  ...,  0.0005, -0.3296, -0.0050],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.6465, -4.7188,  0.1270,  ...,  1.4619, -7.6797, -1.7637],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0297, -0.0158,  0.0049,  ...,  0.0207,  0.0132,  0.0224],
        [-0.0186,  0.0352, -0.0130,  ..., -0.0217,  0.0154, -0.0009],
        [ 0.0067, -0.0009,  0.0087,  ..., -0.0306,  0.0063, -0.0122],
        ...,
        [ 0.0160,  0.0049, -0.0172,  ...,  0.0132,  0.0198,  0.0078],
        [ 0.0020,  0.0039,  0.0046,  ..., -0.0217, -0.0031, -0.0227],
        [ 0.0075,  0.0156,  0.0052,  ..., -0.0101, -0.0203,  0.0306]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.7812, -4.7070,  0.5059,  ...,  1.6973, -7.8398, -1.6934]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 14:18:53 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for I reduce, he reduces
I allow, he allows
I improve, he improves
I involve, he involves
I hear, he hears
I tell, he tells
I operate, he operates
I refer, he
2024-07-30 14:18:53 root INFO     total operator prediction time: 1237.3038079738617 seconds
2024-07-30 14:18:53 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on verb_inf - Ved
2024-07-30 14:18:53 root INFO     building operator verb_inf - Ved
2024-07-30 14:18:53 root INFO     [order_1_approx] starting weight calculation for If the present form is reduce, the past form is reduced
If the present form is relate, the past form is related
If the present form is publish, the past form is published
If the present form is marry, the past form is married
If the present form is lose, the past form is lost
If the present form is appear, the past form is appeared
If the present form is understand, the past form is understood
If the present form is tell, the past form is
2024-07-30 14:18:53 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 14:21:27 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0247,  0.0321,  0.1343,  ...,  0.2078, -0.3042,  0.2106],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.4512, -0.1057,  1.4512,  ...,  2.6973, -4.3789, -1.5195],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0407, -0.0105,  0.0019,  ...,  0.0008, -0.0014,  0.0295],
        [ 0.0077,  0.0547, -0.0077,  ..., -0.0020, -0.0071, -0.0034],
        [ 0.0084, -0.0281,  0.0171,  ..., -0.0135, -0.0208, -0.0117],
        ...,
        [ 0.0027,  0.0228, -0.0140,  ...,  0.0370,  0.0071, -0.0116],
        [-0.0128, -0.0109,  0.0130,  ..., -0.0080,  0.0313, -0.0023],
        [-0.0129,  0.0291,  0.0225,  ..., -0.0025, -0.0025,  0.0225]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.4121, -0.3611,  1.5557,  ...,  2.4941, -3.9961, -1.4531]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 14:21:27 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If the present form is reduce, the past form is reduced
If the present form is relate, the past form is related
If the present form is publish, the past form is published
If the present form is marry, the past form is married
If the present form is lose, the past form is lost
If the present form is appear, the past form is appeared
If the present form is understand, the past form is understood
If the present form is tell, the past form is
2024-07-30 14:21:28 root INFO     [order_1_approx] starting weight calculation for If the present form is understand, the past form is understood
If the present form is publish, the past form is published
If the present form is lose, the past form is lost
If the present form is tell, the past form is told
If the present form is relate, the past form is related
If the present form is appear, the past form is appeared
If the present form is reduce, the past form is reduced
If the present form is marry, the past form is
2024-07-30 14:21:28 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 14:24:01 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0381,  0.2627,  0.0190,  ..., -0.1675, -0.7100,  0.0947],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.7363, -2.0938,  1.8545,  ..., -1.2148, -2.0703, -0.9844],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0258, -0.0054,  0.0086,  ...,  0.0177, -0.0044, -0.0047],
        [-0.0309,  0.0460,  0.0213,  ...,  0.0127,  0.0020, -0.0110],
        [-0.0072,  0.0117,  0.0375,  ..., -0.0118, -0.0328,  0.0141],
        ...,
        [ 0.0041, -0.0139,  0.0164,  ...,  0.0366, -0.0041, -0.0137],
        [ 0.0146, -0.0111,  0.0044,  ..., -0.0011,  0.0049,  0.0122],
        [ 0.0054, -0.0004,  0.0145,  ..., -0.0111,  0.0024,  0.0266]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.4648, -2.1777,  1.7217,  ..., -0.7119, -1.6133, -1.0918]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 14:24:02 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If the present form is understand, the past form is understood
If the present form is publish, the past form is published
If the present form is lose, the past form is lost
If the present form is tell, the past form is told
If the present form is relate, the past form is related
If the present form is appear, the past form is appeared
If the present form is reduce, the past form is reduced
If the present form is marry, the past form is
2024-07-30 14:24:02 root INFO     [order_1_approx] starting weight calculation for If the present form is marry, the past form is married
If the present form is appear, the past form is appeared
If the present form is tell, the past form is told
If the present form is understand, the past form is understood
If the present form is publish, the past form is published
If the present form is lose, the past form is lost
If the present form is relate, the past form is related
If the present form is reduce, the past form is
2024-07-30 14:24:02 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 14:26:35 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0143,  0.1584, -0.3857,  ..., -0.2128,  0.0819,  0.1737],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.7471, -0.7031,  1.4043,  ..., -4.3516, -1.4121, -3.5254],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 5.6976e-02, -1.3969e-02,  7.8392e-04,  ...,  1.3374e-02,
          1.1726e-02, -6.3400e-03],
        [-2.3438e-02,  3.1647e-02,  3.2711e-03,  ..., -2.9926e-03,
         -1.0559e-02, -2.4750e-02],
        [ 2.8534e-02,  8.1253e-04,  2.9449e-03,  ..., -1.6968e-02,
         -1.9455e-02, -5.1689e-03],
        ...,
        [ 1.7975e-02, -5.9738e-03, -1.8677e-02,  ...,  2.9465e-02,
          4.9057e-03,  1.7365e-02],
        [ 1.2665e-02,  2.9068e-03,  9.1171e-03,  ..., -1.7128e-03,
          3.1982e-02,  6.2141e-03],
        [-1.6571e-02,  1.3000e-02,  1.8890e-02,  ..., -8.1635e-03,
          3.0518e-05,  2.9846e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.8770, -0.7847,  1.3711,  ..., -3.8164, -1.1465, -3.2324]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 14:26:36 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If the present form is marry, the past form is married
If the present form is appear, the past form is appeared
If the present form is tell, the past form is told
If the present form is understand, the past form is understood
If the present form is publish, the past form is published
If the present form is lose, the past form is lost
If the present form is relate, the past form is related
If the present form is reduce, the past form is
2024-07-30 14:26:36 root INFO     [order_1_approx] starting weight calculation for If the present form is lose, the past form is lost
If the present form is understand, the past form is understood
If the present form is publish, the past form is published
If the present form is marry, the past form is married
If the present form is reduce, the past form is reduced
If the present form is tell, the past form is told
If the present form is relate, the past form is related
If the present form is appear, the past form is
2024-07-30 14:26:37 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 14:29:10 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0245,  0.2957, -0.1987,  ..., -0.0500, -0.1904, -0.1814],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.0762,  0.9360,  0.3584,  ...,  1.3906, -3.2363,  0.9658],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0618, -0.0423,  0.0142,  ..., -0.0273, -0.0052,  0.0202],
        [-0.0320,  0.0726, -0.0102,  ...,  0.0437, -0.0217, -0.0260],
        [ 0.0110,  0.0200,  0.0495,  ..., -0.0009, -0.0020, -0.0146],
        ...,
        [-0.0036,  0.0066,  0.0025,  ...,  0.0282, -0.0067,  0.0149],
        [-0.0144,  0.0002,  0.0123,  ..., -0.0129,  0.0162, -0.0216],
        [-0.0249,  0.0084,  0.0030,  ...,  0.0068, -0.0166,  0.0298]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.0688,  0.3657,  0.0618,  ...,  1.5352, -2.8906,  0.7563]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 14:29:11 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If the present form is lose, the past form is lost
If the present form is understand, the past form is understood
If the present form is publish, the past form is published
If the present form is marry, the past form is married
If the present form is reduce, the past form is reduced
If the present form is tell, the past form is told
If the present form is relate, the past form is related
If the present form is appear, the past form is
2024-07-30 14:29:12 root INFO     [order_1_approx] starting weight calculation for If the present form is relate, the past form is related
If the present form is appear, the past form is appeared
If the present form is publish, the past form is published
If the present form is understand, the past form is understood
If the present form is reduce, the past form is reduced
If the present form is marry, the past form is married
If the present form is tell, the past form is told
If the present form is lose, the past form is
2024-07-30 14:29:12 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 14:31:45 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0519,  0.2037, -0.0216,  ..., -0.2162, -0.0624,  0.0350],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.0049, -1.6992, -0.2393,  ..., -0.4663, -0.5059, -1.2383],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0464, -0.0063,  0.0310,  ..., -0.0037,  0.0071,  0.0064],
        [-0.0094,  0.0637,  0.0178,  ...,  0.0056, -0.0036, -0.0130],
        [-0.0054, -0.0157,  0.0243,  ..., -0.0019, -0.0056,  0.0026],
        ...,
        [ 0.0067, -0.0032, -0.0154,  ...,  0.0347,  0.0223, -0.0025],
        [ 0.0017,  0.0128,  0.0182,  ..., -0.0131,  0.0245, -0.0063],
        [ 0.0091,  0.0302,  0.0157,  ..., -0.0111, -0.0032,  0.0104]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.0101, -1.7402, -0.0652,  ...,  0.1270, -0.4121, -1.1191]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 14:31:46 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If the present form is relate, the past form is related
If the present form is appear, the past form is appeared
If the present form is publish, the past form is published
If the present form is understand, the past form is understood
If the present form is reduce, the past form is reduced
If the present form is marry, the past form is married
If the present form is tell, the past form is told
If the present form is lose, the past form is
2024-07-30 14:31:46 root INFO     [order_1_approx] starting weight calculation for If the present form is lose, the past form is lost
If the present form is relate, the past form is related
If the present form is appear, the past form is appeared
If the present form is tell, the past form is told
If the present form is publish, the past form is published
If the present form is marry, the past form is married
If the present form is reduce, the past form is reduced
If the present form is understand, the past form is
2024-07-30 14:31:46 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 14:34:19 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1868,  0.1970,  0.0084,  ...,  0.1561, -0.3047,  0.0593],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.0859,  0.7217,  0.7783,  ..., -1.0469, -1.9775,  1.0371],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0350, -0.0147,  0.0011,  ...,  0.0080, -0.0028,  0.0295],
        [-0.0068,  0.0569,  0.0032,  ...,  0.0119, -0.0138,  0.0061],
        [-0.0035,  0.0148,  0.0046,  ..., -0.0012, -0.0163,  0.0016],
        ...,
        [ 0.0022,  0.0098, -0.0090,  ...,  0.0433,  0.0174, -0.0028],
        [ 0.0050, -0.0337,  0.0122,  ..., -0.0271,  0.0051, -0.0334],
        [-0.0028, -0.0115,  0.0092,  ...,  0.0052, -0.0066,  0.0115]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.5820,  0.4741,  0.6924,  ..., -1.1143, -1.4414,  0.9541]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 14:34:20 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If the present form is lose, the past form is lost
If the present form is relate, the past form is related
If the present form is appear, the past form is appeared
If the present form is tell, the past form is told
If the present form is publish, the past form is published
If the present form is marry, the past form is married
If the present form is reduce, the past form is reduced
If the present form is understand, the past form is
2024-07-30 14:34:20 root INFO     [order_1_approx] starting weight calculation for If the present form is understand, the past form is understood
If the present form is marry, the past form is married
If the present form is publish, the past form is published
If the present form is appear, the past form is appeared
If the present form is tell, the past form is told
If the present form is reduce, the past form is reduced
If the present form is lose, the past form is lost
If the present form is relate, the past form is
2024-07-30 14:34:20 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 14:36:53 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0701,  0.0321, -0.3169,  ..., -0.2495, -0.5801,  0.3899],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.2949,  0.2095,  2.0898,  ..., -0.3120, -1.8477, -1.0762],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 3.7079e-02, -3.7262e-02,  6.6681e-03,  ..., -2.4307e-02,
          2.6703e-05,  1.8787e-03],
        [-1.7029e-02,  9.0515e-02, -2.4490e-03,  ...,  7.2365e-03,
          5.6076e-04, -2.9678e-03],
        [ 2.2621e-03,  1.4603e-02,  4.6875e-02,  ...,  2.2717e-03,
         -1.7090e-02, -6.1684e-03],
        ...,
        [ 7.1526e-03,  4.2145e-02, -7.3624e-03,  ...,  4.9469e-02,
          1.5114e-02,  1.1772e-02],
        [ 1.7776e-03, -1.8845e-03, -6.1417e-03,  ...,  3.2654e-02,
          2.6825e-02, -2.9037e-02],
        [ 7.3624e-04, -3.3295e-02, -1.0849e-02,  ..., -1.0017e-02,
         -8.6823e-03,  2.6230e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.2041,  0.1837,  1.9316,  ..., -0.4700, -1.4062, -0.5249]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 14:36:54 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If the present form is understand, the past form is understood
If the present form is marry, the past form is married
If the present form is publish, the past form is published
If the present form is appear, the past form is appeared
If the present form is tell, the past form is told
If the present form is reduce, the past form is reduced
If the present form is lose, the past form is lost
If the present form is relate, the past form is
2024-07-30 14:36:55 root INFO     [order_1_approx] starting weight calculation for If the present form is relate, the past form is related
If the present form is tell, the past form is told
If the present form is understand, the past form is understood
If the present form is marry, the past form is married
If the present form is appear, the past form is appeared
If the present form is reduce, the past form is reduced
If the present form is lose, the past form is lost
If the present form is publish, the past form is
2024-07-30 14:36:55 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 14:39:28 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1917, -0.0357,  0.2788,  ...,  0.0005, -0.3230,  0.4180],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.0234, -1.9082,  0.2632,  ..., -2.1523, -1.5312,  1.7148],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0440, -0.0131,  0.0155,  ...,  0.0042,  0.0087,  0.0175],
        [-0.0225,  0.0504,  0.0108,  ...,  0.0045,  0.0116, -0.0112],
        [ 0.0453, -0.0125,  0.0235,  ..., -0.0148, -0.0299, -0.0004],
        ...,
        [ 0.0048,  0.0226, -0.0149,  ...,  0.0461,  0.0069,  0.0108],
        [ 0.0092, -0.0268, -0.0119,  ...,  0.0069,  0.0040, -0.0113],
        [ 0.0010,  0.0056,  0.0105,  ..., -0.0176, -0.0190,  0.0125]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.9678, -1.9199,  0.6577,  ..., -2.2578, -0.7866,  1.4893]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 14:39:29 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If the present form is relate, the past form is related
If the present form is tell, the past form is told
If the present form is understand, the past form is understood
If the present form is marry, the past form is married
If the present form is appear, the past form is appeared
If the present form is reduce, the past form is reduced
If the present form is lose, the past form is lost
If the present form is publish, the past form is
2024-07-30 14:39:29 root INFO     total operator prediction time: 1236.041758298874 seconds
2024-07-30 14:39:29 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on verb_Ving - Ved
2024-07-30 14:39:29 root INFO     building operator verb_Ving - Ved
2024-07-30 14:39:29 root INFO     [order_1_approx] starting weight calculation for After something is continuing, it has continued
After something is agreeing, it has agreed
After something is asking, it has asked
After something is providing, it has provided
After something is publishing, it has published
After something is suffering, it has suffered
After something is becoming, it has became
After something is replacing, it has
2024-07-30 14:39:29 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 14:42:04 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0740, -0.0234, -0.5298,  ...,  0.1501, -0.0225, -0.0237],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.2041, -2.5215, -0.0723,  ..., -1.1094, -1.0273, -0.9941],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0219,  0.0022,  0.0109,  ...,  0.0066,  0.0170,  0.0316],
        [-0.0299,  0.0388, -0.0019,  ...,  0.0255, -0.0111, -0.0170],
        [ 0.0099,  0.0019,  0.0260,  ...,  0.0021, -0.0172, -0.0097],
        ...,
        [-0.0132,  0.0297, -0.0128,  ...,  0.0215, -0.0054,  0.0366],
        [ 0.0250, -0.0081,  0.0024,  ..., -0.0069,  0.0063,  0.0038],
        [-0.0018, -0.0097,  0.0074,  ..., -0.0006, -0.0269,  0.0333]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.0371, -2.2441,  0.6514,  ..., -1.1230, -0.8813, -1.1465]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 14:42:05 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for After something is continuing, it has continued
After something is agreeing, it has agreed
After something is asking, it has asked
After something is providing, it has provided
After something is publishing, it has published
After something is suffering, it has suffered
After something is becoming, it has became
After something is replacing, it has
2024-07-30 14:42:05 root INFO     [order_1_approx] starting weight calculation for After something is suffering, it has suffered
After something is agreeing, it has agreed
After something is becoming, it has became
After something is replacing, it has replaced
After something is publishing, it has published
After something is asking, it has asked
After something is providing, it has provided
After something is continuing, it has
2024-07-30 14:42:05 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 14:44:40 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0524,  0.0222, -0.2352,  ..., -0.2388, -0.0583,  0.2639],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.5508, -3.0977,  2.2383,  ..., -1.1191,  0.6958, -1.6006],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 1.5656e-02,  1.1101e-02, -8.4460e-05,  ...,  9.6817e-03,
          1.4806e-04,  2.7466e-03],
        [-1.4175e-02,  2.3849e-02,  9.8267e-03,  ..., -4.2267e-03,
          9.0122e-04, -7.7858e-03],
        [ 6.3515e-04,  6.2752e-03,  1.9028e-02,  ..., -8.0261e-03,
         -1.3115e-02, -1.1414e-02],
        ...,
        [ 2.1667e-02,  2.6917e-02,  1.5457e-02,  ...,  2.5330e-02,
         -7.7515e-03,  5.8556e-03],
        [ 1.0941e-02,  1.9562e-02, -9.4757e-03,  ..., -7.0858e-04,
          6.7406e-03, -2.8820e-03],
        [-1.6479e-02,  1.5991e-02,  5.0697e-03,  ..., -1.0185e-02,
         -9.4910e-03,  1.2684e-03]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.5605, -2.8574,  2.0137,  ..., -0.8086,  0.3701, -1.8311]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 14:44:41 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for After something is suffering, it has suffered
After something is agreeing, it has agreed
After something is becoming, it has became
After something is replacing, it has replaced
After something is publishing, it has published
After something is asking, it has asked
After something is providing, it has provided
After something is continuing, it has
2024-07-30 14:44:42 root INFO     [order_1_approx] starting weight calculation for After something is continuing, it has continued
After something is asking, it has asked
After something is replacing, it has replaced
After something is suffering, it has suffered
After something is providing, it has provided
After something is agreeing, it has agreed
After something is publishing, it has published
After something is becoming, it has
2024-07-30 14:44:42 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 14:47:16 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0958,  0.2534,  0.0208,  ...,  0.0591, -0.0598, -0.0969],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.2402, -0.5132,  2.9512,  ..., -0.3401,  1.0527, -1.3945],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 2.7878e-02,  1.5244e-02,  8.7967e-03,  ...,  1.2001e-02,
          1.8951e-02,  3.2318e-02],
        [-1.4420e-02,  7.0374e-02,  8.9722e-03,  ...,  2.2751e-02,
         -2.9694e-02, -9.8114e-03],
        [ 2.9068e-03, -1.2634e-02,  4.0405e-02,  ...,  6.5880e-03,
         -3.3073e-03,  3.8452e-03],
        ...,
        [ 9.6512e-03,  2.7863e-02, -2.3453e-02,  ...,  2.4689e-02,
          4.7989e-03,  1.8417e-02],
        [ 1.5114e-02,  3.2158e-03, -5.9204e-03,  ..., -6.8130e-03,
          3.0045e-02, -7.7057e-03],
        [-9.8419e-03,  1.2161e-02,  1.9394e-02,  ..., -6.5613e-03,
          7.8917e-05,  2.3743e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.0742, -0.9038,  3.2461,  ..., -0.5498,  1.0176, -1.3691]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 14:47:17 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for After something is continuing, it has continued
After something is asking, it has asked
After something is replacing, it has replaced
After something is suffering, it has suffered
After something is providing, it has provided
After something is agreeing, it has agreed
After something is publishing, it has published
After something is becoming, it has
2024-07-30 14:47:17 root INFO     [order_1_approx] starting weight calculation for After something is suffering, it has suffered
After something is publishing, it has published
After something is agreeing, it has agreed
After something is asking, it has asked
After something is replacing, it has replaced
After something is becoming, it has became
After something is continuing, it has continued
After something is providing, it has
2024-07-30 14:47:17 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 14:49:51 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1471, -0.1617, -0.2251,  ...,  0.1321,  0.0563, -0.3770],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.6836, -5.6797,  1.0293,  ..., -1.6826, -3.0781, -0.5371],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 6.6956e-02, -1.6983e-02,  1.5099e-02,  ...,  1.4320e-02,
          5.5008e-03,  3.5431e-02],
        [-4.2572e-02,  2.3529e-02,  3.9825e-02,  ...,  1.7838e-02,
         -2.0996e-02, -5.8594e-03],
        [-3.3493e-03, -1.4198e-02,  2.0660e-02,  ...,  3.3455e-03,
         -1.1536e-02, -2.3994e-03],
        ...,
        [-1.5411e-03,  2.9633e-02,  3.0518e-05,  ...,  4.7302e-02,
          5.1918e-03,  1.6815e-02],
        [ 3.3264e-02, -9.9640e-03, -2.4231e-02,  ..., -5.6763e-03,
          3.5767e-02, -1.8936e-02],
        [-8.1863e-03,  9.9564e-03,  8.1329e-03,  ..., -1.4534e-02,
         -2.0920e-02,  4.7516e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.4746, -5.0898,  1.1748,  ..., -1.7227, -2.1680, -0.5659]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 14:49:52 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for After something is suffering, it has suffered
After something is publishing, it has published
After something is agreeing, it has agreed
After something is asking, it has asked
After something is replacing, it has replaced
After something is becoming, it has became
After something is continuing, it has continued
After something is providing, it has
2024-07-30 14:49:52 root INFO     [order_1_approx] starting weight calculation for After something is publishing, it has published
After something is providing, it has provided
After something is becoming, it has became
After something is agreeing, it has agreed
After something is asking, it has asked
After something is replacing, it has replaced
After something is continuing, it has continued
After something is suffering, it has
2024-07-30 14:49:52 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 14:52:27 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.3428,  0.2120,  0.0260,  ..., -0.2893, -0.1078, -0.0303],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 5.2031, -3.8125,  0.2886,  ..., -2.4883,  2.6719, -0.0059],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0395, -0.0274,  0.0328,  ..., -0.0173,  0.0313,  0.0285],
        [-0.0158,  0.0388,  0.0362,  ...,  0.0046,  0.0024, -0.0166],
        [-0.0151, -0.0156,  0.0153,  ..., -0.0069,  0.0173, -0.0192],
        ...,
        [ 0.0010,  0.0346,  0.0059,  ...,  0.0251,  0.0213, -0.0075],
        [ 0.0170,  0.0029, -0.0171,  ..., -0.0026,  0.0093, -0.0124],
        [-0.0018,  0.0107,  0.0320,  ..., -0.0096, -0.0202,  0.0132]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.8047, -3.6387,  0.2297,  ..., -2.2578,  2.8203,  0.2054]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 14:52:28 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for After something is publishing, it has published
After something is providing, it has provided
After something is becoming, it has became
After something is agreeing, it has agreed
After something is asking, it has asked
After something is replacing, it has replaced
After something is continuing, it has continued
After something is suffering, it has
2024-07-30 14:52:28 root INFO     [order_1_approx] starting weight calculation for After something is suffering, it has suffered
After something is replacing, it has replaced
After something is becoming, it has became
After something is agreeing, it has agreed
After something is providing, it has provided
After something is continuing, it has continued
After something is asking, it has asked
After something is publishing, it has
2024-07-30 14:52:28 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 14:55:02 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2310, -0.1639,  0.0298,  ...,  0.3027,  0.0428,  0.0332],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.8281, -3.2129,  0.4561,  ..., -2.4961, -1.7783,  0.3223],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0384, -0.0050,  0.0008,  ...,  0.0145, -0.0042,  0.0216],
        [-0.0307,  0.0324,  0.0065,  ...,  0.0083,  0.0052, -0.0052],
        [ 0.0213, -0.0092,  0.0227,  ...,  0.0004, -0.0257, -0.0051],
        ...,
        [ 0.0108,  0.0223,  0.0129,  ...,  0.0419,  0.0237,  0.0282],
        [ 0.0185, -0.0072, -0.0233,  ...,  0.0081, -0.0092, -0.0217],
        [-0.0049,  0.0163,  0.0189,  ..., -0.0179, -0.0132, -0.0109]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.9512, -3.1719,  0.6602,  ..., -2.2969, -1.4355,  0.0979]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 14:55:03 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for After something is suffering, it has suffered
After something is replacing, it has replaced
After something is becoming, it has became
After something is agreeing, it has agreed
After something is providing, it has provided
After something is continuing, it has continued
After something is asking, it has asked
After something is publishing, it has
2024-07-30 14:55:04 root INFO     [order_1_approx] starting weight calculation for After something is publishing, it has published
After something is providing, it has provided
After something is agreeing, it has agreed
After something is continuing, it has continued
After something is becoming, it has became
After something is replacing, it has replaced
After something is suffering, it has suffered
After something is asking, it has
2024-07-30 14:55:04 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 14:57:39 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0820,  0.0998, -0.1333,  ...,  0.2520, -0.0880, -0.6021],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.4219, -2.8984, -0.3511,  ...,  1.0088, -2.9434, -1.8438],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0255, -0.0199,  0.0169,  ...,  0.0128,  0.0028,  0.0060],
        [-0.0303,  0.0554,  0.0250,  ...,  0.0023, -0.0048,  0.0070],
        [-0.0122, -0.0276,  0.0226,  ..., -0.0186, -0.0134, -0.0197],
        ...,
        [-0.0117,  0.0544, -0.0170,  ...,  0.0105,  0.0062,  0.0097],
        [ 0.0314, -0.0327, -0.0038,  ..., -0.0240,  0.0084, -0.0154],
        [-0.0150,  0.0053,  0.0263,  ...,  0.0039, -0.0251, -0.0002]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.1211, -2.8027,  0.1777,  ...,  0.8506, -2.0605, -2.0078]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 14:57:40 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for After something is publishing, it has published
After something is providing, it has provided
After something is agreeing, it has agreed
After something is continuing, it has continued
After something is becoming, it has became
After something is replacing, it has replaced
After something is suffering, it has suffered
After something is asking, it has
2024-07-30 14:57:40 root INFO     [order_1_approx] starting weight calculation for After something is replacing, it has replaced
After something is providing, it has provided
After something is asking, it has asked
After something is continuing, it has continued
After something is becoming, it has became
After something is publishing, it has published
After something is suffering, it has suffered
After something is agreeing, it has
2024-07-30 14:57:40 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 15:00:14 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1139, -0.0743, -0.2275,  ...,  0.2773, -0.2306, -0.2302],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.2988, -3.5938,  1.1064,  ..., -0.3691, -1.3506, -1.2109],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0321, -0.0058,  0.0117,  ...,  0.0102, -0.0011,  0.0045],
        [-0.0115,  0.0277,  0.0045,  ...,  0.0143, -0.0060, -0.0043],
        [ 0.0087, -0.0012,  0.0098,  ...,  0.0065, -0.0117, -0.0058],
        ...,
        [ 0.0140,  0.0154,  0.0028,  ...,  0.0157,  0.0081,  0.0070],
        [ 0.0067, -0.0142, -0.0195,  ..., -0.0232, -0.0081, -0.0370],
        [-0.0151,  0.0128,  0.0285,  ..., -0.0007,  0.0059,  0.0178]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.4590, -3.7656,  1.4844,  ..., -0.4583, -0.9951, -1.3203]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 15:00:15 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for After something is replacing, it has replaced
After something is providing, it has provided
After something is asking, it has asked
After something is continuing, it has continued
After something is becoming, it has became
After something is publishing, it has published
After something is suffering, it has suffered
After something is agreeing, it has
2024-07-30 15:00:15 root INFO     total operator prediction time: 1246.1994223594666 seconds
2024-07-30 15:00:15 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on Ving - verb_inf
2024-07-30 15:00:15 root INFO     building operator Ving - verb_inf
2024-07-30 15:00:15 root INFO     [order_1_approx] starting weight calculation for continuing is the active form of continue
asking is the active form of ask
understanding is the active form of understand
maintaining is the active form of maintain
teaching is the active form of teach
establishing is the active form of establish
believing is the active form of believe
containing is the active form of
2024-07-30 15:00:15 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 15:02:50 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0270, -0.4829, -0.5645,  ..., -0.1521, -0.0264, -0.1366],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.2168, -2.3555,  1.9053,  ...,  0.4907, -0.7949, -1.8418],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0723, -0.0247,  0.0040,  ..., -0.0025, -0.0383,  0.0603],
        [-0.0035,  0.0823,  0.0174,  ...,  0.0011, -0.0179, -0.0270],
        [ 0.0247, -0.0083,  0.0559,  ..., -0.0126, -0.0069, -0.0164],
        ...,
        [ 0.0037,  0.0226, -0.0149,  ...,  0.0448,  0.0140, -0.0109],
        [-0.0004,  0.0094, -0.0318,  ..., -0.0140,  0.0606,  0.0201],
        [ 0.0014, -0.0064, -0.0329,  ..., -0.0293, -0.0137,  0.0500]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.0127, -2.6250,  2.0566,  ...,  0.6846, -0.1890, -1.9062]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 15:02:51 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for continuing is the active form of continue
asking is the active form of ask
understanding is the active form of understand
maintaining is the active form of maintain
teaching is the active form of teach
establishing is the active form of establish
believing is the active form of believe
containing is the active form of
2024-07-30 15:02:52 root INFO     [order_1_approx] starting weight calculation for containing is the active form of contain
establishing is the active form of establish
teaching is the active form of teach
maintaining is the active form of maintain
continuing is the active form of continue
believing is the active form of believe
asking is the active form of ask
understanding is the active form of
2024-07-30 15:02:52 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 15:05:26 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1671,  0.2295, -0.3542,  ...,  0.2610,  0.2644, -0.1257],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.7930, -1.8799,  0.4263,  ...,  0.1265, -1.4961, -0.7334],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0253, -0.0069, -0.0058,  ...,  0.0013, -0.0065,  0.0156],
        [ 0.0016,  0.0419, -0.0018,  ..., -0.0007, -0.0128,  0.0063],
        [ 0.0136, -0.0136,  0.0264,  ..., -0.0033, -0.0020,  0.0002],
        ...,
        [-0.0047,  0.0220, -0.0142,  ...,  0.0333,  0.0076, -0.0146],
        [ 0.0227, -0.0088,  0.0065,  ..., -0.0096,  0.0331, -0.0155],
        [ 0.0031,  0.0036, -0.0037,  ..., -0.0186, -0.0136,  0.0034]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.8672, -2.3477,  0.4988,  ..., -0.1843, -1.3037, -1.0850]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 15:05:32 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for containing is the active form of contain
establishing is the active form of establish
teaching is the active form of teach
maintaining is the active form of maintain
continuing is the active form of continue
believing is the active form of believe
asking is the active form of ask
understanding is the active form of
2024-07-30 15:05:32 root INFO     [order_1_approx] starting weight calculation for asking is the active form of ask
understanding is the active form of understand
establishing is the active form of establish
maintaining is the active form of maintain
continuing is the active form of continue
containing is the active form of contain
teaching is the active form of teach
believing is the active form of
2024-07-30 15:05:32 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 15:08:06 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2517,  0.0916, -0.1572,  ..., -0.1132, -0.2915,  0.2417],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.9707, -5.8750,  0.9688,  ...,  1.6387, -1.3828, -2.4570],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 2.1820e-02,  6.0959e-03,  4.3755e-03,  ...,  1.0880e-02,
         -8.6746e-03,  1.1353e-02],
        [-2.6665e-03,  2.4994e-02, -1.1139e-02,  ...,  7.7324e-03,
          4.1924e-03, -2.0180e-03],
        [ 1.0155e-02, -1.2245e-02,  3.3264e-02,  ...,  4.0364e-04,
         -1.6037e-02,  1.4618e-02],
        ...,
        [ 8.0261e-03,  1.2489e-02, -1.8060e-05,  ...,  1.8173e-02,
         -2.9716e-03, -1.1387e-03],
        [ 5.8365e-03,  4.5013e-04,  5.3329e-03,  ...,  1.4404e-02,
          1.5030e-02, -3.8643e-03],
        [ 8.8120e-03,  9.2392e-03, -8.5907e-03,  ..., -1.4595e-02,
         -9.3918e-03,  1.1238e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.9609, -5.9570,  0.9619,  ...,  1.6416, -1.0342, -2.7188]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 15:08:07 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for asking is the active form of ask
understanding is the active form of understand
establishing is the active form of establish
maintaining is the active form of maintain
continuing is the active form of continue
containing is the active form of contain
teaching is the active form of teach
believing is the active form of
2024-07-30 15:08:08 root INFO     [order_1_approx] starting weight calculation for understanding is the active form of understand
maintaining is the active form of maintain
believing is the active form of believe
establishing is the active form of establish
continuing is the active form of continue
containing is the active form of contain
asking is the active form of ask
teaching is the active form of
2024-07-30 15:08:08 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 15:10:42 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2435,  0.2458, -0.0780,  ..., -0.0809, -0.1204,  0.2329],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.6406, -3.5703,  2.2969,  ...,  3.5586, -2.2832, -4.4062],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0362,  0.0048,  0.0078,  ..., -0.0021,  0.0065,  0.0025],
        [ 0.0035,  0.0264, -0.0075,  ..., -0.0087, -0.0088, -0.0093],
        [ 0.0007, -0.0081,  0.0283,  ..., -0.0131,  0.0045, -0.0047],
        ...,
        [ 0.0002,  0.0113, -0.0047,  ...,  0.0153,  0.0031, -0.0108],
        [ 0.0076, -0.0236,  0.0137,  ...,  0.0119,  0.0166,  0.0031],
        [ 0.0026,  0.0009,  0.0004,  ..., -0.0080,  0.0042,  0.0243]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.4707, -3.6133,  2.3281,  ...,  3.4219, -1.8145, -4.2617]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 15:10:43 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for understanding is the active form of understand
maintaining is the active form of maintain
believing is the active form of believe
establishing is the active form of establish
continuing is the active form of continue
containing is the active form of contain
asking is the active form of ask
teaching is the active form of
2024-07-30 15:10:43 root INFO     [order_1_approx] starting weight calculation for continuing is the active form of continue
teaching is the active form of teach
believing is the active form of believe
containing is the active form of contain
understanding is the active form of understand
maintaining is the active form of maintain
establishing is the active form of establish
asking is the active form of
2024-07-30 15:10:43 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 15:13:18 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0689,  0.1070, -0.2830,  ..., -0.0251, -0.0273, -0.3120],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.2402, -4.5938, -0.8750,  ...,  2.8340, -1.2188, -1.5986],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 3.5980e-02, -1.7426e-02,  2.2564e-03,  ...,  1.8787e-03,
         -8.3160e-03,  1.0590e-02],
        [ 4.3983e-03,  4.3365e-02, -9.8724e-03,  ..., -6.3324e-03,
          8.4915e-03,  9.7275e-05],
        [ 7.9346e-03, -1.1772e-02,  2.1637e-02,  ...,  6.5756e-04,
          6.9313e-03, -6.4697e-03],
        ...,
        [ 1.2646e-03,  1.0643e-02, -5.3406e-03,  ...,  2.3270e-02,
          1.0185e-02, -1.0895e-02],
        [ 2.1515e-03, -3.5210e-03,  4.4708e-03,  ..., -3.6659e-03,
          2.1652e-02, -4.3869e-05],
        [-3.5515e-03,  1.2619e-02, -1.2329e-02,  ..., -6.5422e-03,
         -5.6190e-03,  3.0212e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.3325, -4.7773, -0.9634,  ...,  2.6211, -1.0391, -1.7490]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 15:13:19 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for continuing is the active form of continue
teaching is the active form of teach
believing is the active form of believe
containing is the active form of contain
understanding is the active form of understand
maintaining is the active form of maintain
establishing is the active form of establish
asking is the active form of
2024-07-30 15:13:19 root INFO     [order_1_approx] starting weight calculation for understanding is the active form of understand
believing is the active form of believe
teaching is the active form of teach
establishing is the active form of establish
asking is the active form of ask
containing is the active form of contain
maintaining is the active form of maintain
continuing is the active form of
2024-07-30 15:13:19 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 15:15:53 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1417, -0.0266, -0.4500,  ..., -0.3032, -0.1224,  0.1627],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.7617, -4.7773,  0.8203,  ...,  1.6611,  1.1943, -1.5430],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0286,  0.0026, -0.0053,  ...,  0.0013, -0.0060,  0.0202],
        [-0.0032,  0.0405, -0.0046,  ..., -0.0022,  0.0087, -0.0132],
        [ 0.0106, -0.0041,  0.0281,  ..., -0.0112, -0.0114,  0.0029],
        ...,
        [ 0.0138,  0.0235,  0.0102,  ...,  0.0175,  0.0014,  0.0080],
        [ 0.0055,  0.0037,  0.0037,  ...,  0.0024,  0.0256,  0.0030],
        [-0.0033,  0.0103, -0.0153,  ..., -0.0148, -0.0016,  0.0208]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.4478, -4.8672,  0.9287,  ...,  1.5361,  1.5254, -1.5596]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 15:15:54 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for understanding is the active form of understand
believing is the active form of believe
teaching is the active form of teach
establishing is the active form of establish
asking is the active form of ask
containing is the active form of contain
maintaining is the active form of maintain
continuing is the active form of
2024-07-30 15:15:54 root INFO     [order_1_approx] starting weight calculation for asking is the active form of ask
continuing is the active form of continue
maintaining is the active form of maintain
understanding is the active form of understand
teaching is the active form of teach
believing is the active form of believe
containing is the active form of contain
establishing is the active form of
2024-07-30 15:15:54 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 15:18:28 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0207, -0.0668, -0.2396,  ..., -0.3625, -0.2014,  0.0013],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.7861, -4.3750,  0.7559,  ...,  3.2598, -2.3008, -2.9102],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0180, -0.0044, -0.0073,  ...,  0.0144, -0.0058,  0.0068],
        [ 0.0053,  0.0329,  0.0065,  ..., -0.0045, -0.0002, -0.0042],
        [ 0.0124, -0.0150,  0.0082,  ..., -0.0002,  0.0001,  0.0031],
        ...,
        [ 0.0100,  0.0081,  0.0071,  ...,  0.0141,  0.0060,  0.0030],
        [-0.0054,  0.0065, -0.0084,  ...,  0.0131,  0.0254,  0.0110],
        [ 0.0001,  0.0198, -0.0032,  ..., -0.0181,  0.0005,  0.0092]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.8013, -4.3828,  0.8359,  ...,  3.0762, -2.2520, -3.0000]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 15:18:29 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for asking is the active form of ask
continuing is the active form of continue
maintaining is the active form of maintain
understanding is the active form of understand
teaching is the active form of teach
believing is the active form of believe
containing is the active form of contain
establishing is the active form of
2024-07-30 15:18:29 root INFO     [order_1_approx] starting weight calculation for continuing is the active form of continue
asking is the active form of ask
teaching is the active form of teach
understanding is the active form of understand
establishing is the active form of establish
believing is the active form of believe
containing is the active form of contain
maintaining is the active form of
2024-07-30 15:18:29 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 15:21:04 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3113, -0.0338, -0.3928,  ..., -0.1721, -0.1190,  0.0598],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.5742, -5.1328, -1.0488,  ...,  0.2959, -0.6182, -1.8750],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 4.9561e-02, -1.1940e-03, -7.9346e-04,  ...,  3.1471e-04,
         -9.7961e-03,  2.3117e-02],
        [ 1.2848e-02,  4.8859e-02,  3.8433e-03,  ..., -6.8283e-04,
          8.6288e-03, -3.2730e-03],
        [ 1.7822e-02, -2.1324e-03,  3.9917e-02,  ..., -9.2316e-03,
         -4.2820e-04, -7.6866e-03],
        ...,
        [ 1.1093e-02,  1.7151e-02,  4.9667e-03,  ...,  2.3483e-02,
         -3.8891e-03,  9.3079e-03],
        [ 6.6605e-03,  1.5221e-02, -1.0963e-02,  ..., -7.3700e-03,
          3.4576e-02,  1.1581e-02],
        [ 5.1498e-05,  1.6708e-02, -8.5907e-03,  ..., -1.6693e-02,
         -1.1086e-02,  3.1830e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.3955, -5.1016, -0.9585,  ...,  0.1921, -0.6816, -2.1191]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 15:21:05 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for continuing is the active form of continue
asking is the active form of ask
teaching is the active form of teach
understanding is the active form of understand
establishing is the active form of establish
believing is the active form of believe
containing is the active form of contain
maintaining is the active form of
2024-07-30 15:21:05 root INFO     total operator prediction time: 1250.03342628479 seconds
2024-07-30 15:21:05 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on noun - plural_irreg
2024-07-30 15:21:05 root INFO     building operator noun - plural_irreg
2024-07-30 15:21:06 root INFO     [order_1_approx] starting weight calculation for The plural form of analysis is analyses
The plural form of variety is varieties
The plural form of series is series
The plural form of life is lives
The plural form of industry is industries
The plural form of country is countries
The plural form of economy is economies
The plural form of formula is
2024-07-30 15:21:06 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 15:23:39 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3662, -0.1357, -0.0992,  ..., -0.1829, -0.2070,  0.2314],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.2593, -1.0625,  4.3125,  ..., -0.4668, -2.6719, -0.4727],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0848, -0.0180, -0.0076,  ..., -0.0174, -0.0277, -0.0025],
        [-0.0095,  0.0717,  0.0180,  ...,  0.0048, -0.0155,  0.0003],
        [-0.0348,  0.0130, -0.0027,  ...,  0.0205, -0.0003,  0.0130],
        ...,
        [-0.0065,  0.0247, -0.0050,  ...,  0.0269, -0.0052,  0.0076],
        [-0.0194,  0.0192, -0.0103,  ..., -0.0146,  0.0434, -0.0225],
        [ 0.0165,  0.0038,  0.0207,  ...,  0.0163, -0.0109,  0.0323]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.1790, -1.2021,  4.0977,  ..., -0.7817, -2.8125, -0.6074]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 15:23:41 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of analysis is analyses
The plural form of variety is varieties
The plural form of series is series
The plural form of life is lives
The plural form of industry is industries
The plural form of country is countries
The plural form of economy is economies
The plural form of formula is
2024-07-30 15:23:41 root INFO     [order_1_approx] starting weight calculation for The plural form of variety is varieties
The plural form of life is lives
The plural form of series is series
The plural form of formula is formulae
The plural form of country is countries
The plural form of analysis is analyses
The plural form of industry is industries
The plural form of economy is
2024-07-30 15:23:41 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 15:26:15 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2615,  0.2830, -0.2178,  ..., -0.4778,  0.0767,  0.0950],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.7148, -0.9590, -1.2168,  ..., -1.8965, -2.0195, -2.3984],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0279,  0.0096,  0.0210,  ...,  0.0063,  0.0127, -0.0023],
        [ 0.0103,  0.0627,  0.0073,  ...,  0.0210, -0.0194, -0.0177],
        [-0.0147, -0.0073,  0.0326,  ..., -0.0176,  0.0013,  0.0041],
        ...,
        [ 0.0128,  0.0092, -0.0057,  ...,  0.0065,  0.0040, -0.0015],
        [-0.0268,  0.0099, -0.0081,  ..., -0.0015,  0.0284, -0.0088],
        [ 0.0155, -0.0084, -0.0254,  ...,  0.0253, -0.0088,  0.0223]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.7607, -1.0137, -1.4180,  ..., -1.4238, -2.3711, -2.2305]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 15:26:20 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of variety is varieties
The plural form of life is lives
The plural form of series is series
The plural form of formula is formulae
The plural form of country is countries
The plural form of analysis is analyses
The plural form of industry is industries
The plural form of economy is
2024-07-30 15:26:20 root INFO     [order_1_approx] starting weight calculation for The plural form of formula is formulae
The plural form of economy is economies
The plural form of country is countries
The plural form of variety is varieties
The plural form of analysis is analyses
The plural form of life is lives
The plural form of industry is industries
The plural form of series is
2024-07-30 15:26:20 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 15:28:54 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1908, -0.0323, -0.3057,  ..., -0.0484, -0.2375,  0.3267],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.7515, -1.8604, -0.2241,  ..., -1.8496, -0.5879, -2.4082],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0718,  0.0023, -0.0154,  ...,  0.0136,  0.0036,  0.0069],
        [-0.0005,  0.0266, -0.0024,  ...,  0.0182, -0.0148, -0.0255],
        [-0.0116,  0.0113,  0.0467,  ...,  0.0078,  0.0037,  0.0287],
        ...,
        [ 0.0076,  0.0070,  0.0004,  ...,  0.0163, -0.0064,  0.0006],
        [-0.0103,  0.0237,  0.0039,  ...,  0.0041,  0.0218, -0.0022],
        [ 0.0258,  0.0060, -0.0127,  ...,  0.0105, -0.0088,  0.0578]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.8115, -2.1855,  0.2886,  ..., -1.7354, -1.1123, -2.6641]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 15:28:55 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of formula is formulae
The plural form of economy is economies
The plural form of country is countries
The plural form of variety is varieties
The plural form of analysis is analyses
The plural form of life is lives
The plural form of industry is industries
The plural form of series is
2024-07-30 15:28:55 root INFO     [order_1_approx] starting weight calculation for The plural form of economy is economies
The plural form of industry is industries
The plural form of series is series
The plural form of country is countries
The plural form of life is lives
The plural form of formula is formulae
The plural form of variety is varieties
The plural form of analysis is
2024-07-30 15:28:55 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 15:31:29 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1652,  0.2471, -0.1929,  ...,  0.0604, -0.1908,  0.2102],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.2070,  0.0605,  3.3672,  ..., -0.7935, -3.0820, -2.0137],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0671, -0.0037,  0.0057,  ...,  0.0137, -0.0157,  0.0208],
        [ 0.0031,  0.0811,  0.0030,  ...,  0.0334,  0.0099, -0.0100],
        [-0.0342, -0.0201,  0.0290,  ..., -0.0248, -0.0068, -0.0012],
        ...,
        [ 0.0118,  0.0168, -0.0094,  ...,  0.0334,  0.0193,  0.0207],
        [ 0.0054,  0.0220,  0.0040,  ..., -0.0312,  0.0296, -0.0251],
        [-0.0022,  0.0017,  0.0016,  ...,  0.0113, -0.0146,  0.0452]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.8652, -0.5420,  3.2227,  ..., -0.8652, -3.0176, -2.0117]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 15:31:33 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of economy is economies
The plural form of industry is industries
The plural form of series is series
The plural form of country is countries
The plural form of life is lives
The plural form of formula is formulae
The plural form of variety is varieties
The plural form of analysis is
2024-07-30 15:31:34 root INFO     [order_1_approx] starting weight calculation for The plural form of industry is industries
The plural form of series is series
The plural form of analysis is analyses
The plural form of country is countries
The plural form of economy is economies
The plural form of life is lives
The plural form of formula is formulae
The plural form of variety is
2024-07-30 15:31:34 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 15:34:08 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3447,  0.1006, -0.2399,  ...,  0.0034, -0.0653,  0.3682],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.5000, -2.5059,  0.9106,  ..., -2.1094, -3.7695, -2.2539],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0494, -0.0168,  0.0061,  ...,  0.0109,  0.0216,  0.0550],
        [-0.0045,  0.0437,  0.0221,  ...,  0.0178, -0.0353, -0.0207],
        [-0.0038, -0.0056,  0.0241,  ..., -0.0211, -0.0112,  0.0202],
        ...,
        [ 0.0122,  0.0110, -0.0226,  ...,  0.0494,  0.0051, -0.0061],
        [ 0.0198, -0.0118, -0.0119,  ..., -0.0070,  0.0340, -0.0048],
        [ 0.0093,  0.0197, -0.0006,  ...,  0.0171, -0.0180,  0.0477]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.5801, -2.2285,  0.7402,  ..., -1.7539, -3.7969, -1.9941]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 15:34:09 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of industry is industries
The plural form of series is series
The plural form of analysis is analyses
The plural form of country is countries
The plural form of economy is economies
The plural form of life is lives
The plural form of formula is formulae
The plural form of variety is
2024-07-30 15:34:10 root INFO     [order_1_approx] starting weight calculation for The plural form of formula is formulae
The plural form of series is series
The plural form of country is countries
The plural form of economy is economies
The plural form of variety is varieties
The plural form of analysis is analyses
The plural form of life is lives
The plural form of industry is
2024-07-30 15:34:11 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 15:36:45 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0817,  0.2396, -0.0332,  ..., -0.1415, -0.1582,  0.2104],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.1699, -3.1523,  0.5405,  ..., -0.5498, -1.4414, -1.6094],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0312,  0.0098, -0.0037,  ...,  0.0048,  0.0061,  0.0148],
        [ 0.0068,  0.0366,  0.0183,  ...,  0.0278, -0.0136, -0.0195],
        [ 0.0003,  0.0069,  0.0370,  ..., -0.0017,  0.0084,  0.0134],
        ...,
        [ 0.0064,  0.0189, -0.0097,  ...,  0.0178,  0.0006,  0.0016],
        [-0.0123,  0.0060, -0.0134,  ...,  0.0069,  0.0111, -0.0129],
        [ 0.0217,  0.0138,  0.0040,  ...,  0.0252, -0.0004,  0.0134]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.2012, -3.1504,  0.3213,  ..., -0.5239, -1.7539, -0.9800]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 15:36:46 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of formula is formulae
The plural form of series is series
The plural form of country is countries
The plural form of economy is economies
The plural form of variety is varieties
The plural form of analysis is analyses
The plural form of life is lives
The plural form of industry is
2024-07-30 15:36:46 root INFO     [order_1_approx] starting weight calculation for The plural form of series is series
The plural form of formula is formulae
The plural form of variety is varieties
The plural form of industry is industries
The plural form of economy is economies
The plural form of analysis is analyses
The plural form of life is lives
The plural form of country is
2024-07-30 15:36:46 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 15:39:20 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3323, -0.1241, -0.4458,  ..., -0.3193, -0.2150,  0.2607],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.7969, -5.0117,  1.1172,  ..., -0.9199,  1.3418, -2.5918],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0460, -0.0150,  0.0039,  ...,  0.0266,  0.0099,  0.0323],
        [-0.0134,  0.0438,  0.0221,  ...,  0.0010, -0.0071, -0.0126],
        [-0.0097,  0.0294,  0.0341,  ...,  0.0144, -0.0084,  0.0202],
        ...,
        [-0.0096,  0.0010, -0.0225,  ...,  0.0022, -0.0063,  0.0060],
        [-0.0251,  0.0358,  0.0109,  ..., -0.0206,  0.0427, -0.0451],
        [ 0.0125, -0.0040, -0.0278,  ...,  0.0236, -0.0182,  0.0297]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.1289, -5.0430,  0.9790,  ..., -0.5840,  0.6152, -1.8359]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 15:39:21 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of series is series
The plural form of formula is formulae
The plural form of variety is varieties
The plural form of industry is industries
The plural form of economy is economies
The plural form of analysis is analyses
The plural form of life is lives
The plural form of country is
2024-07-30 15:39:21 root INFO     [order_1_approx] starting weight calculation for The plural form of country is countries
The plural form of analysis is analyses
The plural form of series is series
The plural form of formula is formulae
The plural form of industry is industries
The plural form of economy is economies
The plural form of variety is varieties
The plural form of life is
2024-07-30 15:39:21 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 15:41:56 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3994,  0.1653, -0.1497,  ..., -0.2111, -0.3313,  0.2388],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.9502, -2.8867,  0.3845,  ..., -1.9160, -3.3848, -2.2344],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0361,  0.0192,  0.0195,  ...,  0.0076, -0.0031,  0.0022],
        [ 0.0075,  0.0647,  0.0152,  ...,  0.0312, -0.0279, -0.0246],
        [-0.0152, -0.0116,  0.0172,  ...,  0.0064, -0.0023,  0.0390],
        ...,
        [ 0.0116,  0.0117, -0.0383,  ...,  0.0146, -0.0104,  0.0232],
        [-0.0297, -0.0013, -0.0165,  ..., -0.0202, -0.0043, -0.0005],
        [-0.0123, -0.0089, -0.0220,  ...,  0.0110, -0.0230,  0.0346]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.5771, -3.3867,  0.4517,  ..., -1.4648, -3.3281, -1.8926]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 15:42:10 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of country is countries
The plural form of analysis is analyses
The plural form of series is series
The plural form of formula is formulae
The plural form of industry is industries
The plural form of economy is economies
The plural form of variety is varieties
The plural form of life is
2024-07-30 15:42:10 root INFO     total operator prediction time: 1265.0410284996033 seconds
2024-07-30 15:42:11 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on meronyms - member
2024-07-30 15:42:11 root INFO     building operator meronyms - member
2024-07-30 15:42:15 root INFO     [order_1_approx] starting weight calculation for A musician is a member of a orchestra
A county is a member of a state
A juror is a member of a jury
A cattle is a member of a herd
A lion is a member of a pride
A spouse is a member of a couple
A photo is a member of a album
A goose is a member of a
2024-07-30 15:42:15 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 15:44:49 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0912,  0.0642, -0.0948,  ..., -0.0061, -0.3052,  0.0343],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.3867, -2.7754,  2.8262,  ..., -0.3936, -4.9883,  2.3086],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0482,  0.0326, -0.0044,  ...,  0.0059, -0.0090,  0.0538],
        [-0.0049,  0.0410,  0.0409,  ..., -0.0021, -0.0206, -0.0187],
        [ 0.0157,  0.0011,  0.0490,  ...,  0.0161, -0.0023, -0.0251],
        ...,
        [ 0.0246,  0.0386,  0.0304,  ...,  0.0568,  0.0220, -0.0134],
        [ 0.0539,  0.0238,  0.0044,  ..., -0.0025,  0.0178,  0.0053],
        [-0.0014, -0.0021, -0.0082,  ..., -0.0262, -0.0206,  0.0448]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.1211, -2.6191,  2.4336,  ..., -0.6040, -5.4375,  2.5664]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 15:44:50 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A musician is a member of a orchestra
A county is a member of a state
A juror is a member of a jury
A cattle is a member of a herd
A lion is a member of a pride
A spouse is a member of a couple
A photo is a member of a album
A goose is a member of a
2024-07-30 15:44:50 root INFO     [order_1_approx] starting weight calculation for A cattle is a member of a herd
A musician is a member of a orchestra
A photo is a member of a album
A juror is a member of a jury
A goose is a member of a gaggle
A lion is a member of a pride
A county is a member of a state
A spouse is a member of a
2024-07-30 15:44:50 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 15:47:24 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.5796,  0.3584, -0.0784,  ...,  0.5630, -0.3811, -0.1901],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.1963, -2.7578,  2.7324,  ..., -2.0020, -0.8701,  2.2012],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0439, -0.0119,  0.0049,  ...,  0.0204, -0.0102, -0.0048],
        [-0.0042,  0.0356,  0.0089,  ...,  0.0110,  0.0162, -0.0114],
        [ 0.0172, -0.0007,  0.0285,  ...,  0.0142, -0.0101, -0.0055],
        ...,
        [ 0.0001,  0.0010,  0.0141,  ...,  0.0141,  0.0125, -0.0053],
        [ 0.0062,  0.0103, -0.0019,  ...,  0.0225,  0.0072, -0.0023],
        [-0.0022, -0.0074, -0.0170,  ..., -0.0199, -0.0135,  0.0528]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.4639, -2.5879,  2.5195,  ..., -2.1055, -1.1748,  2.2363]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 15:47:25 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A cattle is a member of a herd
A musician is a member of a orchestra
A photo is a member of a album
A juror is a member of a jury
A goose is a member of a gaggle
A lion is a member of a pride
A county is a member of a state
A spouse is a member of a
2024-07-30 15:47:25 root INFO     [order_1_approx] starting weight calculation for A photo is a member of a album
A county is a member of a state
A goose is a member of a gaggle
A juror is a member of a jury
A spouse is a member of a couple
A cattle is a member of a herd
A musician is a member of a orchestra
A lion is a member of a
2024-07-30 15:47:25 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 15:49:59 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1101,  0.1252, -0.0651,  ..., -0.1641, -0.2471,  0.0834],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 7.0977, -6.2031,  0.9419,  ..., -0.5723, -1.4668, -1.4902],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0281,  0.0028,  0.0111,  ..., -0.0095, -0.0050,  0.0224],
        [-0.0008,  0.0246,  0.0028,  ...,  0.0064, -0.0185,  0.0026],
        [ 0.0007, -0.0242,  0.0514,  ..., -0.0364,  0.0262, -0.0096],
        ...,
        [ 0.0113,  0.0006,  0.0100,  ...,  0.0649,  0.0071, -0.0284],
        [ 0.0382, -0.0007, -0.0198,  ...,  0.0031,  0.0258, -0.0380],
        [-0.0067, -0.0297, -0.0251,  ..., -0.0016, -0.0408,  0.0727]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 6.7266, -5.8789,  1.1816,  ..., -0.3794, -1.9639, -1.2432]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 15:50:00 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A photo is a member of a album
A county is a member of a state
A goose is a member of a gaggle
A juror is a member of a jury
A spouse is a member of a couple
A cattle is a member of a herd
A musician is a member of a orchestra
A lion is a member of a
2024-07-30 15:50:00 root INFO     [order_1_approx] starting weight calculation for A lion is a member of a pride
A county is a member of a state
A goose is a member of a gaggle
A musician is a member of a orchestra
A cattle is a member of a herd
A spouse is a member of a couple
A juror is a member of a jury
A photo is a member of a
2024-07-30 15:50:00 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 15:52:27 root INFO     loading model + tokenizer
2024-07-30 15:52:30 root INFO     model + tokenizer loaded
2024-07-30 15:52:30 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on verb+ment_irreg
2024-07-30 15:52:30 root INFO     building operator verb+ment_irreg
2024-07-30 15:52:31 root INFO     [order_1_approx] starting weight calculation for To establish results in a establishment
To encourage results in a encouragement
To commit results in a commitment
To infringe results in a infringement
To displace results in a displacement
To disappoint results in a disappointment
To enhance results in a enhancement
To develop results in a
2024-07-30 15:52:31 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-30 15:52:34 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.4812, -0.1564, -0.1869,  ...,  0.0070, -0.4026, -0.0210],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.9053, -1.3145,  3.6914,  ..., -3.8906,  0.9575, -0.5146],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0564,  0.0343,  0.0073,  ...,  0.0104, -0.0237, -0.0002],
        [ 0.0197,  0.0648,  0.0150,  ...,  0.0574, -0.0188, -0.0010],
        [-0.0140,  0.0314,  0.0316,  ...,  0.0122, -0.0064, -0.0068],
        ...,
        [ 0.0500, -0.0284, -0.0002,  ...,  0.0275, -0.0317, -0.0222],
        [-0.0045,  0.0726,  0.0014,  ..., -0.0003,  0.0549, -0.0146],
        [-0.0119, -0.0222,  0.0127,  ...,  0.0167, -0.0202,  0.0418]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.9395, -1.3330,  3.2051,  ..., -3.2500,  0.1294, -0.2695]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 15:52:36 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A lion is a member of a pride
A county is a member of a state
A goose is a member of a gaggle
A musician is a member of a orchestra
A cattle is a member of a herd
A spouse is a member of a couple
A juror is a member of a jury
A photo is a member of a
2024-07-30 15:52:36 root INFO     [order_1_approx] starting weight calculation for A cattle is a member of a herd
A photo is a member of a album
A musician is a member of a orchestra
A county is a member of a state
A spouse is a member of a couple
A goose is a member of a gaggle
A lion is a member of a pride
A juror is a member of a
2024-07-30 15:52:36 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 15:55:08 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1519,  0.3865, -0.1134,  ..., -0.1343, -0.3105, -0.0564],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.4395, -4.6758,  1.4805,  ...,  3.5312, -3.2891, -1.6973],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 4.4922e-02,  2.1545e-02,  3.8567e-03,  ...,  1.0933e-02,
         -1.0223e-03,  8.9951e-03],
        [-1.2604e-02,  2.7023e-02,  6.8054e-03,  ...,  1.7899e-02,
          2.4689e-02,  7.1430e-04],
        [-1.2604e-02, -1.5045e-02,  2.2781e-02,  ...,  1.2299e-02,
         -1.5282e-02,  2.2247e-02],
        ...,
        [ 6.8665e-05, -7.6904e-03, -6.8665e-04,  ...,  5.1880e-02,
         -1.0345e-02,  1.5839e-02],
        [ 2.3422e-02,  1.1429e-02,  1.4893e-02,  ..., -1.8875e-02,
          2.0523e-02,  6.8130e-03],
        [ 7.7209e-03, -7.5455e-03, -1.1902e-03,  ...,  1.4725e-02,
         -3.9276e-02,  3.4363e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.9355, -4.1758,  1.5898,  ...,  3.2383, -3.5820, -1.5762]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 15:55:09 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To establish results in a establishment
To encourage results in a encouragement
To commit results in a commitment
To infringe results in a infringement
To displace results in a displacement
To disappoint results in a disappointment
To enhance results in a enhancement
To develop results in a
2024-07-30 15:55:09 root INFO     [order_1_approx] starting weight calculation for To encourage results in a encouragement
To displace results in a displacement
To establish results in a establishment
To enhance results in a enhancement
To infringe results in a infringement
To develop results in a development
To commit results in a commitment
To disappoint results in a
2024-07-30 15:55:09 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-30 15:55:09 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1471, -0.0015, -0.1545,  ...,  0.1909, -0.2408, -0.1289],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.4531, -4.3945,  3.9727,  ..., -3.2949, -0.9014, -2.5742],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 3.6407e-02,  5.6839e-04,  1.8372e-02,  ...,  3.1891e-02,
         -2.1458e-03,  1.4816e-02],
        [ 1.2650e-02,  1.0902e-02,  2.0737e-02,  ...,  7.9575e-03,
         -7.8812e-03, -1.5289e-02],
        [-4.6082e-03,  5.3368e-03,  1.0674e-02,  ..., -6.4850e-05,
          1.1292e-02,  6.3133e-03],
        ...,
        [ 1.4977e-02,  6.2294e-03,  2.6321e-04,  ...,  2.2827e-02,
         -3.3703e-03, -8.9569e-03],
        [ 1.9646e-03,  3.4294e-03, -2.3132e-02,  ...,  4.1389e-03,
          1.8631e-02,  1.4954e-02],
        [ 7.8049e-03, -2.0370e-02,  5.7640e-03,  ...,  1.5091e-02,
         -5.8136e-03,  3.5522e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.9434, -3.9102,  3.7051,  ..., -2.9414, -1.0010, -2.4062]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 15:55:10 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A cattle is a member of a herd
A photo is a member of a album
A musician is a member of a orchestra
A county is a member of a state
A spouse is a member of a couple
A goose is a member of a gaggle
A lion is a member of a pride
A juror is a member of a
2024-07-30 15:55:11 root INFO     [order_1_approx] starting weight calculation for A lion is a member of a pride
A juror is a member of a jury
A goose is a member of a gaggle
A county is a member of a state
A photo is a member of a album
A cattle is a member of a herd
A spouse is a member of a couple
A musician is a member of a
2024-07-30 15:55:11 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 15:57:43 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0635,  0.2437,  0.0963,  ..., -0.0692, -0.3167, -0.0762],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.2949, -6.7578,  3.4238,  ..., -2.8359, -1.4912, -3.8516],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0428,  0.0090,  0.0195,  ...,  0.0322,  0.0012, -0.0024],
        [-0.0128,  0.0247, -0.0010,  ..., -0.0059,  0.0103, -0.0207],
        [ 0.0180,  0.0051,  0.0327,  ...,  0.0064,  0.0073, -0.0084],
        ...,
        [ 0.0123,  0.0212,  0.0032,  ...,  0.0253,  0.0001, -0.0089],
        [ 0.0142,  0.0055,  0.0007,  ...,  0.0004,  0.0233,  0.0123],
        [ 0.0170, -0.0264, -0.0261,  ..., -0.0141,  0.0054,  0.0259]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.3184, -6.6211,  3.4668,  ..., -2.4355, -1.9463, -3.2695]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 15:57:44 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A lion is a member of a pride
A juror is a member of a jury
A goose is a member of a gaggle
A county is a member of a state
A photo is a member of a album
A cattle is a member of a herd
A spouse is a member of a couple
A musician is a member of a
2024-07-30 15:57:45 root INFO     [order_1_approx] starting weight calculation for A lion is a member of a pride
A spouse is a member of a couple
A juror is a member of a jury
A musician is a member of a orchestra
A cattle is a member of a herd
A goose is a member of a gaggle
A photo is a member of a album
A county is a member of a
2024-07-30 15:57:45 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 15:57:49 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0854,  0.6304, -0.5034,  ..., -0.0591, -0.4065, -0.1476],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.9766, -3.7930,  0.9453,  ...,  0.9570,  2.2285, -1.4902],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0190, -0.0016, -0.0046,  ...,  0.0108, -0.0199,  0.0300],
        [-0.0119,  0.0351,  0.0081,  ...,  0.0409,  0.0186, -0.0010],
        [ 0.0182, -0.0546, -0.0157,  ..., -0.0042, -0.0058,  0.0036],
        ...,
        [ 0.0127,  0.0203,  0.0146,  ...,  0.0211, -0.0181,  0.0267],
        [ 0.0175, -0.0016,  0.0159,  ...,  0.0141, -0.0020, -0.0331],
        [ 0.0050,  0.0163,  0.0119,  ..., -0.0036, -0.0515,  0.0028]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.0664, -3.6465,  0.9312,  ...,  0.8960,  2.1348, -1.6475]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 15:57:50 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To encourage results in a encouragement
To displace results in a displacement
To establish results in a establishment
To enhance results in a enhancement
To infringe results in a infringement
To develop results in a development
To commit results in a commitment
To disappoint results in a
2024-07-30 15:57:50 root INFO     [order_1_approx] starting weight calculation for To establish results in a establishment
To enhance results in a enhancement
To displace results in a displacement
To disappoint results in a disappointment
To commit results in a commitment
To develop results in a development
To encourage results in a encouragement
To infringe results in a
2024-07-30 15:57:50 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-30 16:00:17 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0087, -0.0019, -0.4072,  ..., -0.1533, -0.0766,  0.0889],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.1445, -5.9141,  4.0625,  ..., -6.0664,  3.7754, -4.3281],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0278, -0.0100,  0.0015,  ...,  0.0188, -0.0104,  0.0190],
        [-0.0053,  0.0112, -0.0207,  ...,  0.0069, -0.0244,  0.0087],
        [ 0.0170,  0.0300,  0.0524,  ..., -0.0264, -0.0063, -0.0191],
        ...,
        [ 0.0003, -0.0062, -0.0418,  ...,  0.0360,  0.0082,  0.0009],
        [ 0.0070,  0.0230,  0.0007,  ..., -0.0165,  0.0420, -0.0091],
        [-0.0185, -0.0411, -0.0428,  ...,  0.0246, -0.0229,  0.0625]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.1426, -4.7539,  3.6875,  ..., -5.4805,  3.3555, -3.7363]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 16:00:18 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A lion is a member of a pride
A spouse is a member of a couple
A juror is a member of a jury
A musician is a member of a orchestra
A cattle is a member of a herd
A goose is a member of a gaggle
A photo is a member of a album
A county is a member of a
2024-07-30 16:00:19 root INFO     [order_1_approx] starting weight calculation for A photo is a member of a album
A musician is a member of a orchestra
A spouse is a member of a couple
A county is a member of a state
A juror is a member of a jury
A lion is a member of a pride
A goose is a member of a gaggle
A cattle is a member of a
2024-07-30 16:00:19 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 16:00:25 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0157,  0.2393, -0.5425,  ...,  0.1676, -0.2966, -0.1467],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.5156, -4.1367,  1.4336,  ...,  0.7173, -2.1328, -0.7588],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0442,  0.0004,  0.0131,  ..., -0.0232, -0.0016,  0.0252],
        [-0.0454,  0.0406,  0.0093,  ...,  0.0131,  0.0305,  0.0070],
        [-0.0073, -0.0123,  0.0193,  ..., -0.0073,  0.0121, -0.0306],
        ...,
        [ 0.0101,  0.0190, -0.0033,  ...,  0.0665, -0.0045,  0.0244],
        [ 0.0071, -0.0122,  0.0043,  ...,  0.0050,  0.0525, -0.0165],
        [ 0.0303,  0.0100,  0.0073,  ...,  0.0016, -0.0451,  0.0164]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.0703, -3.1758,  1.6934,  ...,  1.0039, -2.2305, -0.6660]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 16:00:26 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To establish results in a establishment
To enhance results in a enhancement
To displace results in a displacement
To disappoint results in a disappointment
To commit results in a commitment
To develop results in a development
To encourage results in a encouragement
To infringe results in a
2024-07-30 16:00:26 root INFO     [order_1_approx] starting weight calculation for To encourage results in a encouragement
To disappoint results in a disappointment
To commit results in a commitment
To enhance results in a enhancement
To infringe results in a infringement
To displace results in a displacement
To develop results in a development
To establish results in a
2024-07-30 16:00:26 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-30 16:02:52 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0881,  0.1194, -0.2257,  ..., -0.2286, -0.1996,  0.1494],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.8555, -3.2344,  1.8311,  ..., -3.9570,  1.0312, -2.8711],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 6.1707e-02,  3.9520e-02,  1.3268e-02,  ...,  3.2745e-02,
         -1.8692e-02,  1.3008e-02],
        [-1.5335e-03,  5.2795e-02,  1.3336e-02,  ...,  3.6377e-02,
         -1.5175e-02,  3.7727e-03],
        [ 2.2659e-03, -4.5288e-02,  2.5360e-02,  ..., -4.8340e-02,
         -4.9591e-05, -1.6556e-02],
        ...,
        [-4.7073e-03, -2.9297e-02, -1.1375e-02,  ...,  4.3915e-02,
          2.4017e-02,  2.6741e-03],
        [ 3.1586e-03,  4.7180e-02,  6.3629e-03,  ...,  1.3954e-02,
          6.0852e-02, -3.2654e-02],
        [-2.6031e-02, -3.5156e-02, -3.8971e-02,  ..., -2.2736e-02,
         -1.4091e-02,  8.3496e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.6836, -3.6445,  2.0527,  ..., -3.2461,  0.3467, -2.5742]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 16:02:52 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A photo is a member of a album
A musician is a member of a orchestra
A spouse is a member of a couple
A county is a member of a state
A juror is a member of a jury
A lion is a member of a pride
A goose is a member of a gaggle
A cattle is a member of a
2024-07-30 16:02:52 root INFO     total operator prediction time: 1241.68701171875 seconds
2024-07-30 16:02:52 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on antonyms - binary
2024-07-30 16:02:52 root INFO     building operator antonyms - binary
2024-07-30 16:02:53 root INFO     [order_1_approx] starting weight calculation for The opposite of dive is emerge
The opposite of anterior is posterior
The opposite of below is above
The opposite of forward is backward
The opposite of previously is subsequently
The opposite of forget is remember
The opposite of front is back
The opposite of internal is
2024-07-30 16:02:53 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 16:03:03 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0386,  0.4473, -0.3281,  ...,  0.0397, -0.3398, -0.0479],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.5576, -3.4395, -0.9990,  ...,  2.0527, -1.8105,  0.2344],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0088, -0.0054,  0.0141,  ...,  0.0079, -0.0187,  0.0355],
        [-0.0154,  0.0502, -0.0023,  ...,  0.0084,  0.0098, -0.0144],
        [ 0.0278, -0.0107, -0.0012,  ..., -0.0131,  0.0174, -0.0027],
        ...,
        [ 0.0228, -0.0019, -0.0165,  ...,  0.0074,  0.0050,  0.0252],
        [-0.0031,  0.0284, -0.0309,  ...,  0.0254,  0.0076, -0.0181],
        [ 0.0149, -0.0058, -0.0194,  ...,  0.0255, -0.0283, -0.0031]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.3984, -3.4023, -0.8779,  ...,  2.2246, -1.9951, -0.1311]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 16:03:04 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To encourage results in a encouragement
To disappoint results in a disappointment
To commit results in a commitment
To enhance results in a enhancement
To infringe results in a infringement
To displace results in a displacement
To develop results in a development
To establish results in a
2024-07-30 16:03:04 root INFO     [order_1_approx] starting weight calculation for To commit results in a commitment
To develop results in a development
To encourage results in a encouragement
To enhance results in a enhancement
To infringe results in a infringement
To disappoint results in a disappointment
To establish results in a establishment
To displace results in a
2024-07-30 16:03:05 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-30 16:05:24 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0465, -0.3667, -0.0349,  ..., -0.2529, -0.0183,  0.3823],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.0898,  0.1199,  1.6953,  ..., -2.4766, -0.3745, -5.7422],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0277, -0.0506, -0.0003,  ...,  0.0196, -0.0360,  0.0102],
        [-0.0168,  0.0157,  0.0099,  ...,  0.0141,  0.0118, -0.0150],
        [-0.0173, -0.0229,  0.0047,  ...,  0.0056, -0.0280,  0.0139],
        ...,
        [ 0.0490,  0.0478,  0.0107,  ...,  0.0079,  0.0544, -0.0215],
        [ 0.0105,  0.0072, -0.0301,  ...,  0.0275,  0.0106, -0.0197],
        [-0.0079,  0.0019,  0.0073,  ...,  0.0116, -0.0011,  0.0679]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.4053,  0.2029,  1.3633,  ..., -2.9551, -0.2812, -5.4961]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 16:05:25 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of dive is emerge
The opposite of anterior is posterior
The opposite of below is above
The opposite of forward is backward
The opposite of previously is subsequently
The opposite of forget is remember
The opposite of front is back
The opposite of internal is
2024-07-30 16:05:25 root INFO     [order_1_approx] starting weight calculation for The opposite of front is back
The opposite of forward is backward
The opposite of dive is emerge
The opposite of below is above
The opposite of forget is remember
The opposite of previously is subsequently
The opposite of internal is external
The opposite of anterior is
2024-07-30 16:05:25 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 16:05:44 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0063,  0.3625, -0.3567,  ...,  0.1043, -0.1912,  0.0207],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.0664, -2.7285, -0.2305,  ...,  1.6885, -0.9316, -1.0996],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0515,  0.0195,  0.0080,  ...,  0.0182, -0.0003,  0.0345],
        [-0.0366,  0.0221, -0.0062,  ...,  0.0291, -0.0205,  0.0019],
        [ 0.0180,  0.0111,  0.0083,  ..., -0.0333,  0.0032, -0.0219],
        ...,
        [ 0.0295,  0.0416,  0.0084,  ...,  0.0433, -0.0296,  0.0217],
        [ 0.0615,  0.0536, -0.0039,  ..., -0.0091,  0.0360,  0.0012],
        [ 0.0468,  0.0450,  0.0296,  ...,  0.0023, -0.0219,  0.0750]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.6953, -2.3867, -0.2386,  ...,  0.9312, -0.9321, -1.7715]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 16:05:45 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To commit results in a commitment
To develop results in a development
To encourage results in a encouragement
To enhance results in a enhancement
To infringe results in a infringement
To disappoint results in a disappointment
To establish results in a establishment
To displace results in a
2024-07-30 16:05:45 root INFO     [order_1_approx] starting weight calculation for To enhance results in a enhancement
To disappoint results in a disappointment
To infringe results in a infringement
To establish results in a establishment
To displace results in a displacement
To develop results in a development
To encourage results in a encouragement
To commit results in a
2024-07-30 16:05:45 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-30 16:07:54 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0228,  0.2170, -0.3032,  ..., -0.4417, -0.3394,  0.2211],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.5684, -2.4707,  2.8887,  ..., -3.3867, -3.2129, -4.3477],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0129, -0.0250, -0.0107,  ...,  0.0365, -0.0212, -0.0095],
        [ 0.0258,  0.0160, -0.0275,  ...,  0.0426,  0.0041, -0.0345],
        [-0.0075, -0.0050,  0.0078,  ..., -0.0159, -0.0309, -0.0113],
        ...,
        [ 0.0154,  0.0318,  0.0101,  ..., -0.0059,  0.0365, -0.0122],
        [-0.0041, -0.0138,  0.0043,  ...,  0.0312,  0.0218, -0.0120],
        [-0.0134, -0.0102, -0.0508,  ..., -0.0028,  0.0056,  0.0336]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.6772, -2.1641,  2.8848,  ..., -2.9844, -2.9805, -3.8008]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 16:07:55 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of front is back
The opposite of forward is backward
The opposite of dive is emerge
The opposite of below is above
The opposite of forget is remember
The opposite of previously is subsequently
The opposite of internal is external
The opposite of anterior is
2024-07-30 16:07:56 root INFO     [order_1_approx] starting weight calculation for The opposite of internal is external
The opposite of forward is backward
The opposite of dive is emerge
The opposite of anterior is posterior
The opposite of previously is subsequently
The opposite of front is back
The opposite of below is above
The opposite of forget is
2024-07-30 16:07:56 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 16:08:25 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0848,  0.5225, -0.3269,  ...,  0.1923, -0.3994, -0.2063],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.8184, -4.0625, -0.6172,  ..., -0.3430, -0.1410, -0.4639],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 2.8091e-02,  3.9825e-02, -1.2512e-02,  ...,  5.4550e-03,
         -4.2114e-03, -4.2801e-03],
        [-4.4365e-03,  4.5959e-02,  2.4765e-02,  ...,  5.8624e-02,
          2.6428e-02, -7.7820e-03],
        [ 6.9847e-03, -2.8839e-02,  2.9469e-03,  ..., -8.3847e-03,
         -2.4155e-02,  3.1204e-03],
        ...,
        [ 9.6893e-03,  2.5589e-02,  1.8982e-02,  ...,  3.5492e-02,
          1.4450e-02,  1.0475e-02],
        [ 2.2263e-02, -6.3477e-03,  1.7147e-03,  ..., -2.3209e-02,
         -7.6294e-06, -2.9572e-02],
        [ 3.0563e-02, -1.6617e-02,  3.1616e-02,  ..., -1.4526e-02,
         -3.2898e-02,  2.0691e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.7773, -4.1797, -0.6035,  ..., -0.4441, -0.0331, -0.5059]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 16:08:45 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To enhance results in a enhancement
To disappoint results in a disappointment
To infringe results in a infringement
To establish results in a establishment
To displace results in a displacement
To develop results in a development
To encourage results in a encouragement
To commit results in a
2024-07-30 16:08:45 root INFO     [order_1_approx] starting weight calculation for To commit results in a commitment
To displace results in a displacement
To encourage results in a encouragement
To develop results in a development
To infringe results in a infringement
To establish results in a establishment
To disappoint results in a disappointment
To enhance results in a
2024-07-30 16:08:45 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-30 16:10:26 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2886,  0.1714,  0.0218,  ..., -0.1287, -0.0554,  0.3420],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.1562, -3.6309, -1.3018,  ..., -1.1035, -5.2891, -2.1484],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0362, -0.0315, -0.0099,  ...,  0.0299, -0.0303, -0.0055],
        [-0.0156,  0.0091, -0.0327,  ...,  0.0560, -0.0329,  0.0154],
        [-0.0294, -0.0182,  0.0188,  ..., -0.0119, -0.0301, -0.0135],
        ...,
        [ 0.0022, -0.0047, -0.0061,  ...,  0.0621,  0.0090, -0.0013],
        [-0.0095,  0.0172,  0.0320,  ...,  0.0097,  0.0361, -0.0172],
        [ 0.0128, -0.0054, -0.0295,  ...,  0.0442,  0.0006,  0.0209]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.1023, -3.9883, -2.0117,  ..., -0.6406, -5.4141, -2.6172]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 16:10:27 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of internal is external
The opposite of forward is backward
The opposite of dive is emerge
The opposite of anterior is posterior
The opposite of previously is subsequently
The opposite of front is back
The opposite of below is above
The opposite of forget is
2024-07-30 16:10:27 root INFO     [order_1_approx] starting weight calculation for The opposite of internal is external
The opposite of forget is remember
The opposite of previously is subsequently
The opposite of dive is emerge
The opposite of anterior is posterior
The opposite of below is above
The opposite of front is back
The opposite of forward is
2024-07-30 16:10:27 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 16:11:25 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0797,  0.2238, -0.0529,  ...,  0.0805, -0.1785, -0.0407],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.6904, -0.3701, -0.4663,  ...,  3.2871, -5.4102, -2.7773],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0275, -0.0057,  0.0077,  ..., -0.0074, -0.0148,  0.0192],
        [-0.0152,  0.0409, -0.0186,  ...,  0.0112,  0.0018,  0.0083],
        [-0.0055, -0.0152,  0.0307,  ...,  0.0101,  0.0034,  0.0070],
        ...,
        [ 0.0123, -0.0094, -0.0331,  ...,  0.0431,  0.0014,  0.0079],
        [ 0.0291,  0.0047,  0.0209,  ..., -0.0165,  0.0600, -0.0051],
        [-0.0003, -0.0065, -0.0085,  ...,  0.0254, -0.0244,  0.0319]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.7549, -0.4653, -0.1843,  ...,  3.1191, -5.6484, -2.8223]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 16:11:26 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To commit results in a commitment
To displace results in a displacement
To encourage results in a encouragement
To develop results in a development
To infringe results in a infringement
To establish results in a establishment
To disappoint results in a disappointment
To enhance results in a
2024-07-30 16:11:26 root INFO     [order_1_approx] starting weight calculation for To infringe results in a infringement
To commit results in a commitment
To develop results in a development
To disappoint results in a disappointment
To enhance results in a enhancement
To establish results in a establishment
To displace results in a displacement
To encourage results in a
2024-07-30 16:11:26 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-30 16:13:00 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1792,  0.2310, -0.3489,  ..., -0.2346,  0.1541,  0.2546],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.6777, -2.4199, -0.0582,  ..., -1.4375, -2.4336, -1.7754],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0559, -0.0312, -0.0114,  ...,  0.0338, -0.0226,  0.0307],
        [ 0.0069,  0.0554,  0.0141,  ...,  0.0037,  0.0056,  0.0060],
        [-0.0106, -0.0372,  0.0185,  ...,  0.0299, -0.0251, -0.0222],
        ...,
        [ 0.0013,  0.0396, -0.0163,  ...,  0.0449,  0.0426, -0.0034],
        [ 0.0041,  0.0094, -0.0025,  ...,  0.0153,  0.0718, -0.0011],
        [ 0.0050, -0.0162,  0.0030,  ...,  0.0019,  0.0161,  0.0190]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.1895, -2.5762,  0.2568,  ..., -1.2490, -2.5137, -2.0879]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 16:13:01 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of internal is external
The opposite of forget is remember
The opposite of previously is subsequently
The opposite of dive is emerge
The opposite of anterior is posterior
The opposite of below is above
The opposite of front is back
The opposite of forward is
2024-07-30 16:13:01 root INFO     [order_1_approx] starting weight calculation for The opposite of forget is remember
The opposite of anterior is posterior
The opposite of forward is backward
The opposite of dive is emerge
The opposite of below is above
The opposite of internal is external
The opposite of previously is subsequently
The opposite of front is
2024-07-30 16:13:01 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 16:14:06 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0314,  0.5957, -0.4587,  ..., -0.0042, -0.2595, -0.0330],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.4951, -2.2617, -0.8770,  ...,  4.1680, -0.3926, -1.4785],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0254,  0.0295,  0.0176,  ..., -0.0038,  0.0171,  0.0354],
        [-0.0240,  0.0075, -0.0166,  ...,  0.0277,  0.0105,  0.0013],
        [ 0.0158, -0.0115, -0.0119,  ..., -0.0106,  0.0014,  0.0106],
        ...,
        [ 0.0073, -0.0040, -0.0090,  ...,  0.0259,  0.0010,  0.0136],
        [ 0.0452,  0.0328,  0.0042,  ..., -0.0248,  0.0105,  0.0031],
        [ 0.0413, -0.0032, -0.0135,  ...,  0.0469, -0.0358,  0.0316]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.7178, -2.5312, -0.6875,  ...,  3.8125, -0.6011, -1.5010]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 16:14:07 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To infringe results in a infringement
To commit results in a commitment
To develop results in a development
To disappoint results in a disappointment
To enhance results in a enhancement
To establish results in a establishment
To displace results in a displacement
To encourage results in a
2024-07-30 16:14:07 root INFO     total operator prediction time: 1296.6868226528168 seconds
2024-07-30 16:14:07 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on noun+less_reg
2024-07-30 16:14:07 root INFO     building operator noun+less_reg
2024-07-30 16:14:08 root INFO     [order_1_approx] starting weight calculation for Something without leg is legless
Something without breath is breathless
Something without penny is penniless
Something without collar is collarless
Something without thought is thoughtless
Something without friction is frictionless
Something without friend is friendless
Something without heart is
2024-07-30 16:14:08 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-30 16:15:33 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1562,  0.0749, -0.1489,  ..., -0.2554,  0.0063,  0.2256],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.5352, -2.9824,  1.0273,  ..., -1.0596, -1.1406, -1.5957],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 2.3193e-02, -5.1392e-02,  8.3923e-05,  ...,  2.7832e-02,
         -3.8391e-02, -1.6464e-02],
        [ 2.3804e-03,  5.6244e-02,  1.3840e-02,  ...,  2.0370e-02,
          8.8501e-03, -1.8723e-02],
        [-8.2169e-03, -2.7100e-02,  2.3460e-03,  ..., -5.3215e-03,
         -3.6285e-02, -7.4043e-03],
        ...,
        [ 1.4458e-02,  1.5038e-02, -1.2794e-02,  ...,  3.8635e-02,
          3.9764e-02,  2.4506e-02],
        [ 9.7656e-03,  1.5594e-02,  1.7990e-02,  ...,  1.1032e-02,
          5.0415e-02,  1.5762e-02],
        [-5.4817e-03,  2.3994e-03, -1.2169e-02,  ...,  4.7798e-03,
          1.1795e-02,  3.7506e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.2046, -2.7168,  1.0918,  ..., -1.0498, -1.3428, -1.3486]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 16:15:34 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of forget is remember
The opposite of anterior is posterior
The opposite of forward is backward
The opposite of dive is emerge
The opposite of below is above
The opposite of internal is external
The opposite of previously is subsequently
The opposite of front is
2024-07-30 16:15:34 root INFO     [order_1_approx] starting weight calculation for The opposite of previously is subsequently
The opposite of internal is external
The opposite of forget is remember
The opposite of front is back
The opposite of anterior is posterior
The opposite of forward is backward
The opposite of below is above
The opposite of dive is
2024-07-30 16:15:35 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 16:16:47 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0598, -0.3782, -0.0187,  ..., -0.1340, -0.0115,  0.1183],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.9321, -4.2422, -1.1699,  ..., -3.2539, -1.5645, -1.8252],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0361, -0.0049,  0.0339,  ...,  0.0006, -0.0379,  0.0159],
        [ 0.0255,  0.0438, -0.0043,  ..., -0.0048, -0.0175,  0.0054],
        [-0.0182, -0.0318,  0.0289,  ..., -0.0096, -0.0155, -0.0105],
        ...,
        [ 0.0118,  0.0221, -0.0016,  ...,  0.0219, -0.0071,  0.0119],
        [-0.0042,  0.0181, -0.0325,  ..., -0.0004,  0.0252, -0.0180],
        [ 0.0126, -0.0032,  0.0014,  ...,  0.0122,  0.0017,  0.0062]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.5264, -4.5781, -1.8252,  ..., -3.3516, -1.4971, -1.7695]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 16:16:49 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Something without leg is legless
Something without breath is breathless
Something without penny is penniless
Something without collar is collarless
Something without thought is thoughtless
Something without friction is frictionless
Something without friend is friendless
Something without heart is
2024-07-30 16:16:49 root INFO     [order_1_approx] starting weight calculation for Something without heart is heartless
Something without friction is frictionless
Something without thought is thoughtless
Something without breath is breathless
Something without collar is collarless
Something without leg is legless
Something without friend is friendless
Something without penny is
2024-07-30 16:16:49 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-30 16:18:07 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1995,  0.2529,  0.0522,  ..., -0.1548, -0.2019,  0.2805],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.8496, -0.7148, -0.1914,  ...,  2.3730, -2.7129,  2.4629],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0751, -0.0247, -0.0133,  ...,  0.0220,  0.0125,  0.0215],
        [ 0.0135,  0.0382, -0.0298,  ...,  0.0325, -0.0046,  0.0246],
        [ 0.0211,  0.0086, -0.0157,  ..., -0.0203,  0.0133, -0.0466],
        ...,
        [-0.0032,  0.0388,  0.0196,  ...,  0.0151,  0.0144, -0.0209],
        [-0.0101, -0.0060,  0.0302,  ...,  0.0025,  0.0282,  0.0084],
        [ 0.0028,  0.0060,  0.0015,  ..., -0.0146,  0.0269,  0.0141]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.3555, -0.9292, -0.1725,  ...,  2.1250, -3.1191,  1.7715]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 16:18:08 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of previously is subsequently
The opposite of internal is external
The opposite of forget is remember
The opposite of front is back
The opposite of anterior is posterior
The opposite of forward is backward
The opposite of below is above
The opposite of dive is
2024-07-30 16:18:09 root INFO     [order_1_approx] starting weight calculation for The opposite of internal is external
The opposite of front is back
The opposite of dive is emerge
The opposite of forward is backward
The opposite of previously is subsequently
The opposite of forget is remember
The opposite of anterior is posterior
The opposite of below is
2024-07-30 16:18:09 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 16:19:28 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1029, -0.3352, -0.2284,  ..., -0.1367, -0.0826, -0.0592],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.0269, -3.2891, -0.2837,  ..., -4.9844, -4.6602, -1.1572],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0505, -0.0098,  0.0192,  ..., -0.0380, -0.0109, -0.0028],
        [ 0.0097,  0.0204,  0.0211,  ...,  0.0257, -0.0122, -0.0067],
        [ 0.0091, -0.0195,  0.0323,  ..., -0.0083, -0.0072,  0.0149],
        ...,
        [ 0.0081,  0.0096, -0.0083,  ...,  0.0151, -0.0015,  0.0117],
        [-0.0071,  0.0226,  0.0178,  ...,  0.0202,  0.0277, -0.0202],
        [-0.0025, -0.0075, -0.0023,  ...,  0.0069,  0.0004,  0.0224]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.2173, -3.8242, -0.4370,  ..., -5.1641, -4.1445, -1.1816]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 16:19:29 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Something without heart is heartless
Something without friction is frictionless
Something without thought is thoughtless
Something without breath is breathless
Something without collar is collarless
Something without leg is legless
Something without friend is friendless
Something without penny is
2024-07-30 16:19:30 root INFO     [order_1_approx] starting weight calculation for Something without leg is legless
Something without friend is friendless
Something without thought is thoughtless
Something without friction is frictionless
Something without penny is penniless
Something without breath is breathless
Something without heart is heartless
Something without collar is
2024-07-30 16:19:30 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-30 16:20:41 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2651, -0.2676, -0.0691,  ..., -0.0529, -0.2766,  0.1610],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.8047, -2.0820,  1.3672,  ..., -0.6758,  2.3105, -1.2412],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0322, -0.0142, -0.0057,  ...,  0.0110, -0.0150,  0.0145],
        [ 0.0196,  0.0504,  0.0259,  ..., -0.0113,  0.0050, -0.0135],
        [-0.0138, -0.0154, -0.0131,  ...,  0.0058, -0.0322,  0.0132],
        ...,
        [ 0.0271,  0.0096,  0.0132,  ...,  0.0148,  0.0149, -0.0146],
        [ 0.0127, -0.0052,  0.0149,  ..., -0.0045,  0.0090,  0.0141],
        [ 0.0006, -0.0009,  0.0368,  ...,  0.0021,  0.0080,  0.0273]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.7998, -2.2324,  1.7744,  ..., -0.5708,  2.1113, -1.7402]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 16:20:42 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of internal is external
The opposite of front is back
The opposite of dive is emerge
The opposite of forward is backward
The opposite of previously is subsequently
The opposite of forget is remember
The opposite of anterior is posterior
The opposite of below is
2024-07-30 16:20:42 root INFO     [order_1_approx] starting weight calculation for The opposite of dive is emerge
The opposite of anterior is posterior
The opposite of front is back
The opposite of forget is remember
The opposite of below is above
The opposite of forward is backward
The opposite of internal is external
The opposite of previously is
2024-07-30 16:20:42 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 16:22:09 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2842, -0.2844,  0.1935,  ..., -0.0939, -0.2612, -0.1422],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.5088, -3.1152,  0.0322,  ..., -1.2500,  1.2246,  0.7168],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 5.2063e-02,  9.7156e-05, -1.6651e-03,  ...,  2.9945e-03,
          6.3210e-03, -5.1804e-03],
        [ 6.0539e-03,  5.4138e-02, -2.1957e-02,  ...,  2.8534e-03,
          2.4841e-02,  1.0941e-02],
        [ 1.1971e-02, -1.2482e-02,  2.7710e-02,  ..., -1.1780e-02,
         -1.8326e-02, -1.7365e-02],
        ...,
        [ 3.0151e-02,  2.4994e-02, -5.7411e-03,  ...,  7.8354e-03,
         -1.0300e-03, -5.8136e-03],
        [-1.4359e-02,  1.5511e-02, -2.6291e-02,  ..., -8.3008e-03,
          2.3819e-02, -1.3809e-02],
        [ 1.3016e-02, -1.6632e-03, -5.7259e-03,  ..., -4.3488e-03,
         -8.2245e-03,  3.0853e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.3787, -3.0703, -0.0435,  ..., -1.3086,  0.9175,  0.7109]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 16:22:10 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Something without leg is legless
Something without friend is friendless
Something without thought is thoughtless
Something without friction is frictionless
Something without penny is penniless
Something without breath is breathless
Something without heart is heartless
Something without collar is
2024-07-30 16:22:10 root INFO     [order_1_approx] starting weight calculation for Something without collar is collarless
Something without leg is legless
Something without friction is frictionless
Something without heart is heartless
Something without friend is friendless
Something without thought is thoughtless
Something without penny is penniless
Something without breath is
2024-07-30 16:22:10 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-30 16:23:14 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1074, -0.0636, -0.1598,  ..., -0.3555, -0.3850,  0.2471],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.3926, -2.7461, -0.4221,  ..., -1.4121, -1.8887, -4.8008],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 3.6652e-02, -3.1799e-02, -1.3191e-02,  ...,  4.2572e-02,
         -9.5520e-03,  1.6495e-02],
        [-4.6143e-02,  4.2816e-02, -2.5970e-02,  ...,  6.6711e-02,
         -8.2016e-05,  1.1749e-02],
        [ 6.1302e-03,  1.4664e-02,  2.9572e-02,  ...,  3.0632e-03,
          8.4229e-03, -2.0798e-02],
        ...,
        [-2.6581e-02, -4.2558e-05, -2.7023e-02,  ...,  2.4261e-02,
          1.6006e-02, -1.1391e-02],
        [ 2.5909e-02,  3.3226e-03,  4.4373e-02,  ...,  1.6876e-02,
          5.6396e-02, -3.0899e-04],
        [-3.3234e-02,  2.7191e-02, -3.1158e-02,  ...,  2.4796e-03,
         -1.8936e-02,  1.7853e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.3223, -2.2656, -0.2571,  ..., -1.1309, -1.8535, -4.9219]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 16:23:15 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of dive is emerge
The opposite of anterior is posterior
The opposite of front is back
The opposite of forget is remember
The opposite of below is above
The opposite of forward is backward
The opposite of internal is external
The opposite of previously is
2024-07-30 16:23:15 root INFO     total operator prediction time: 1222.4507479667664 seconds
2024-07-30 16:23:15 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on hyponyms - misc
2024-07-30 16:23:15 root INFO     building operator hyponyms - misc
2024-07-30 16:23:15 root INFO     [order_1_approx] starting weight calculation for A more specific term for a flask is thermos
A more specific term for a computer is laptop
A more specific term for a oven is broiler
A more specific term for a backpack is daypack
A more specific term for a shoes is sneakers
A more specific term for a mixer is blender
A more specific term for a guitar is ukulele
A more specific term for a container is
2024-07-30 16:23:15 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 16:24:50 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1959, -0.2993, -0.2227,  ..., -0.3074, -0.1106,  0.1946],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.5586, -4.5977,  0.5405,  ..., -2.6836, -1.7891, -1.4268],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0250, -0.0294,  0.0013,  ..., -0.0058,  0.0035,  0.0394],
        [ 0.0185,  0.0508,  0.0131,  ...,  0.0094, -0.0283,  0.0082],
        [-0.0103, -0.0344,  0.0409,  ..., -0.0163, -0.0154, -0.0070],
        ...,
        [ 0.0068, -0.0014,  0.0030,  ..., -0.0062, -0.0132,  0.0011],
        [ 0.0117,  0.0053,  0.0040,  ..., -0.0172,  0.0235, -0.0280],
        [-0.0050, -0.0121, -0.0002,  ...,  0.0030, -0.0214,  0.0028]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.5293, -4.5742,  0.0852,  ..., -2.7871, -2.0352, -1.7266]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 16:24:51 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Something without collar is collarless
Something without leg is legless
Something without friction is frictionless
Something without heart is heartless
Something without friend is friendless
Something without thought is thoughtless
Something without penny is penniless
Something without breath is
2024-07-30 16:24:51 root INFO     [order_1_approx] starting weight calculation for Something without penny is penniless
Something without friction is frictionless
Something without breath is breathless
Something without collar is collarless
Something without heart is heartless
Something without friend is friendless
Something without leg is legless
Something without thought is
2024-07-30 16:24:51 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-30 16:25:47 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.3894, -0.2937, -0.1250,  ...,  0.1819, -0.2856, -0.1508],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.3828, -4.7656, -1.1699,  ..., -0.3096,  0.8096, -0.5752],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 4.2877e-02,  1.2978e-02,  1.5869e-02,  ...,  1.1887e-02,
         -1.0500e-03,  2.8137e-02],
        [-1.6575e-03,  1.5327e-02,  1.1581e-02,  ..., -2.1393e-02,
         -3.0914e-02,  1.3168e-02],
        [-2.3132e-02, -1.2054e-02,  5.3741e-02,  ...,  2.2221e-03,
         -1.1795e-02, -8.3923e-05],
        ...,
        [ 3.6072e-02,  2.1973e-03, -4.7379e-03,  ...,  3.5065e-02,
         -7.6065e-03, -5.6496e-03],
        [-9.8114e-03,  1.5152e-02, -7.0190e-04,  ...,  5.1300e-02,
          3.4882e-02,  1.4343e-03],
        [ 2.6642e-02,  4.3564e-03,  6.7902e-04,  ...,  7.8888e-03,
         -1.8051e-02,  4.2267e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.6875, -4.4766, -0.7935,  ..., -0.1763,  0.4565, -0.6411]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 16:25:48 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more specific term for a flask is thermos
A more specific term for a computer is laptop
A more specific term for a oven is broiler
A more specific term for a backpack is daypack
A more specific term for a shoes is sneakers
A more specific term for a mixer is blender
A more specific term for a guitar is ukulele
A more specific term for a container is
2024-07-30 16:25:48 root INFO     [order_1_approx] starting weight calculation for A more specific term for a oven is broiler
A more specific term for a mixer is blender
A more specific term for a container is bag
A more specific term for a shoes is sneakers
A more specific term for a flask is thermos
A more specific term for a guitar is ukulele
A more specific term for a backpack is daypack
A more specific term for a computer is
2024-07-30 16:25:48 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 16:27:30 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2839, -0.1321,  0.2174,  ..., -0.0479,  0.0187,  0.2908],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.9570, -2.2031,  2.1934,  ..., -2.6895, -2.8086, -0.5186],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 2.8259e-02,  2.0508e-02, -1.4515e-03,  ...,  5.4092e-03,
         -3.8361e-02,  1.0864e-02],
        [ 1.7151e-02,  3.4973e-02,  4.9686e-04,  ..., -1.7471e-03,
          3.3722e-03,  9.6130e-03],
        [-6.2637e-03, -3.1738e-02,  4.6539e-02,  ...,  3.2463e-03,
         -1.7456e-02, -5.9662e-03],
        ...,
        [ 1.6144e-02,  2.0332e-03,  3.0518e-05,  ...,  1.5366e-02,
          1.3680e-02, -7.6294e-06],
        [-1.0689e-02, -3.4599e-03, -8.1024e-03,  ..., -1.2627e-02,
          2.0660e-02, -7.2937e-03],
        [ 2.1877e-03, -1.2459e-02,  6.0730e-03,  ...,  1.3885e-02,
          9.9716e-03,  5.3406e-05]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.5938, -2.7578,  1.6855,  ..., -2.4629, -2.6230, -0.5298]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 16:27:31 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Something without penny is penniless
Something without friction is frictionless
Something without breath is breathless
Something without collar is collarless
Something without heart is heartless
Something without friend is friendless
Something without leg is legless
Something without thought is
2024-07-30 16:27:31 root INFO     [order_1_approx] starting weight calculation for Something without heart is heartless
Something without thought is thoughtless
Something without friend is friendless
Something without breath is breathless
Something without penny is penniless
Something without collar is collarless
Something without leg is legless
Something without friction is
2024-07-30 16:27:31 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-30 16:28:20 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0061, -0.2297,  0.0743,  ...,  0.0010, -0.3774, -0.1831],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.5894, -4.4453, -0.1497,  ..., -1.8105, -0.7241, -1.6699],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0238, -0.0075, -0.0146,  ..., -0.0006,  0.0193,  0.0362],
        [ 0.0140,  0.0344,  0.0166,  ..., -0.0022, -0.0178, -0.0196],
        [-0.0132,  0.0040,  0.0519,  ...,  0.0083,  0.0042,  0.0136],
        ...,
        [ 0.0057,  0.0276, -0.0037,  ...,  0.0227,  0.0219,  0.0151],
        [ 0.0091, -0.0003,  0.0049,  ...,  0.0101,  0.0272, -0.0177],
        [ 0.0031,  0.0294, -0.0036,  ..., -0.0101, -0.0143,  0.0592]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.3127, -4.3633,  0.1663,  ..., -1.5947, -0.8896, -1.5850]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 16:28:21 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more specific term for a oven is broiler
A more specific term for a mixer is blender
A more specific term for a container is bag
A more specific term for a shoes is sneakers
A more specific term for a flask is thermos
A more specific term for a guitar is ukulele
A more specific term for a backpack is daypack
A more specific term for a computer is
2024-07-30 16:28:21 root INFO     [order_1_approx] starting weight calculation for A more specific term for a shoes is sneakers
A more specific term for a mixer is blender
A more specific term for a computer is laptop
A more specific term for a backpack is daypack
A more specific term for a flask is thermos
A more specific term for a guitar is ukulele
A more specific term for a container is bag
A more specific term for a oven is
2024-07-30 16:28:21 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 16:30:10 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0898, -0.3010, -0.3940,  ...,  0.0795,  0.2046,  0.2286],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.5449, -1.3164,  2.0684,  ..., -1.7188, -2.5508, -0.3281],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 3.6469e-02,  1.9897e-02,  5.0592e-04,  ..., -1.3336e-02,
          1.0635e-02,  4.1924e-03],
        [ 4.5013e-03,  3.9734e-02,  1.1482e-02,  ..., -8.6441e-03,
         -4.7684e-05,  1.0567e-02],
        [ 7.4348e-03,  6.0425e-03,  4.7638e-02,  ..., -1.1765e-02,
         -7.6828e-03, -1.5808e-02],
        ...,
        [ 3.0899e-02,  1.5259e-02,  9.5901e-03,  ...,  8.3801e-02,
          2.1057e-02,  9.9182e-03],
        [ 1.3084e-03,  1.5572e-02, -5.2147e-03,  ..., -1.4008e-02,
          3.8788e-02, -1.1230e-02],
        [ 1.5144e-02, -2.9221e-03, -9.7275e-04,  ...,  3.0243e-02,
          1.7700e-02,  2.0950e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.1738, -1.3750,  1.9756,  ..., -1.3301, -2.1055, -0.5195]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 16:30:11 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Something without heart is heartless
Something without thought is thoughtless
Something without friend is friendless
Something without breath is breathless
Something without penny is penniless
Something without collar is collarless
Something without leg is legless
Something without friction is
2024-07-30 16:30:11 root INFO     [order_1_approx] starting weight calculation for Something without heart is heartless
Something without breath is breathless
Something without thought is thoughtless
Something without friend is friendless
Something without collar is collarless
Something without friction is frictionless
Something without penny is penniless
Something without leg is
2024-07-30 16:30:11 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-30 16:30:54 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0392, -0.1086, -0.0956,  ..., -0.1276, -0.3662, -0.0378],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.6836, -3.8848,  3.4512,  ..., -3.3633, -2.0938,  1.6777],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0232, -0.0008, -0.0044,  ...,  0.0179, -0.0069,  0.0251],
        [ 0.0079,  0.0469, -0.0008,  ..., -0.0017,  0.0185, -0.0048],
        [-0.0576,  0.0108,  0.0425,  ...,  0.0143,  0.0175, -0.0005],
        ...,
        [-0.0075,  0.0007, -0.0087,  ...,  0.0291,  0.0036, -0.0083],
        [-0.0054, -0.0134,  0.0087,  ...,  0.0037,  0.0668, -0.0328],
        [-0.0093, -0.0026, -0.0029,  ..., -0.0168, -0.0041,  0.0228]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.3789, -4.0703,  3.2051,  ..., -2.9199, -1.2812,  1.8438]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 16:30:55 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more specific term for a shoes is sneakers
A more specific term for a mixer is blender
A more specific term for a computer is laptop
A more specific term for a backpack is daypack
A more specific term for a flask is thermos
A more specific term for a guitar is ukulele
A more specific term for a container is bag
A more specific term for a oven is
2024-07-30 16:30:55 root INFO     [order_1_approx] starting weight calculation for A more specific term for a backpack is daypack
A more specific term for a guitar is ukulele
A more specific term for a flask is thermos
A more specific term for a shoes is sneakers
A more specific term for a oven is broiler
A more specific term for a computer is laptop
A more specific term for a container is bag
A more specific term for a mixer is
2024-07-30 16:30:56 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 16:32:45 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4424, -0.1096,  0.0328,  ..., -0.0691, -0.0433, -0.2776],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.1853, -4.4062,  0.1152,  ..., -1.9375, -0.8311, -1.8770],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0574, -0.0243, -0.0014,  ..., -0.0056, -0.0295,  0.0558],
        [ 0.0019,  0.0164, -0.0042,  ...,  0.0054, -0.0360,  0.0111],
        [ 0.0059, -0.0104,  0.0201,  ..., -0.0174, -0.0122,  0.0084],
        ...,
        [ 0.0319,  0.0060,  0.0085,  ...,  0.0362,  0.0302,  0.0047],
        [-0.0240,  0.0256, -0.0188,  ...,  0.0097,  0.0545, -0.0352],
        [ 0.0075,  0.0154,  0.0222,  ...,  0.0116,  0.0024,  0.0040]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.0833, -4.3906, -0.1090,  ..., -2.3926, -0.8569, -2.1250]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 16:32:48 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Something without heart is heartless
Something without breath is breathless
Something without thought is thoughtless
Something without friend is friendless
Something without collar is collarless
Something without friction is frictionless
Something without penny is penniless
Something without leg is
2024-07-30 16:32:48 root INFO     [order_1_approx] starting weight calculation for Something without heart is heartless
Something without leg is legless
Something without penny is penniless
Something without collar is collarless
Something without friction is frictionless
Something without breath is breathless
Something without thought is thoughtless
Something without friend is
2024-07-30 16:32:49 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-30 16:33:28 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1317,  0.0240, -0.0929,  ...,  0.4390, -0.3486, -0.2272],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.1221, -4.8828, -1.9053,  ...,  0.5747, -1.3086, -0.5752],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0487,  0.0017, -0.0013,  ...,  0.0087, -0.0031, -0.0054],
        [ 0.0311,  0.0468,  0.0084,  ..., -0.0085,  0.0047,  0.0088],
        [-0.0129, -0.0207,  0.0606,  ..., -0.0244,  0.0093,  0.0399],
        ...,
        [ 0.0328,  0.0231, -0.0170,  ...,  0.0630, -0.0304, -0.0239],
        [-0.0586, -0.0037, -0.0271,  ...,  0.0253,  0.0821, -0.0207],
        [ 0.0235,  0.0247,  0.0135,  ..., -0.0313, -0.0278,  0.0424]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.2236, -4.9844, -2.1328,  ...,  0.5903, -0.9971, -0.8027]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 16:33:31 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more specific term for a backpack is daypack
A more specific term for a guitar is ukulele
A more specific term for a flask is thermos
A more specific term for a shoes is sneakers
A more specific term for a oven is broiler
A more specific term for a computer is laptop
A more specific term for a container is bag
A more specific term for a mixer is
2024-07-30 16:33:32 root INFO     [order_1_approx] starting weight calculation for A more specific term for a oven is broiler
A more specific term for a computer is laptop
A more specific term for a shoes is sneakers
A more specific term for a mixer is blender
A more specific term for a flask is thermos
A more specific term for a guitar is ukulele
A more specific term for a container is bag
A more specific term for a backpack is
2024-07-30 16:33:32 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 16:35:28 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2725, -0.4951, -0.1254,  ..., -0.1759,  0.0432, -0.3843],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.0674, -1.8174,  1.5742,  ..., -1.1387, -3.0000,  0.5713],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0312, -0.0095,  0.0004,  ..., -0.0055, -0.0395,  0.0182],
        [-0.0014, -0.0005,  0.0034,  ...,  0.0038, -0.0053, -0.0087],
        [ 0.0113, -0.0138,  0.0158,  ...,  0.0033, -0.0207, -0.0045],
        ...,
        [-0.0005,  0.0093, -0.0054,  ...,  0.0087,  0.0147, -0.0056],
        [-0.0110,  0.0142, -0.0038,  ...,  0.0015,  0.0211,  0.0007],
        [ 0.0097,  0.0030, -0.0085,  ..., -0.0044, -0.0019,  0.0067]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.6396, -2.0566,  1.5527,  ..., -1.3047, -3.1660,  0.1968]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 16:35:29 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Something without heart is heartless
Something without leg is legless
Something without penny is penniless
Something without collar is collarless
Something without friction is frictionless
Something without breath is breathless
Something without thought is thoughtless
Something without friend is
2024-07-30 16:35:29 root INFO     total operator prediction time: 1281.4127371311188 seconds
2024-07-30 16:35:29 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on adj+ness_reg
2024-07-30 16:35:29 root INFO     building operator adj+ness_reg
2024-07-30 16:35:29 root INFO     [order_1_approx] starting weight calculation for The state of being devoted is devotedness
The state of being creative is creativeness
The state of being strange is strangeness
The state of being dangerous is dangerousness
The state of being happy is happiness
The state of being hot is hotness
The state of being pure is pureness
The state of being effective is
2024-07-30 16:35:29 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-30 16:36:04 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1416,  0.3049,  0.2068,  ..., -0.1466, -0.6787, -0.2001],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.9062, -4.7773, -1.1562,  ..., -0.0547,  2.7656, -0.2324],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0567,  0.0022,  0.0031,  ...,  0.0170, -0.0116,  0.0205],
        [ 0.0046,  0.0504, -0.0165,  ..., -0.0090,  0.0070, -0.0196],
        [-0.0168, -0.0001,  0.0415,  ...,  0.0093, -0.0093,  0.0080],
        ...,
        [ 0.0169,  0.0128, -0.0230,  ...,  0.0229, -0.0157, -0.0256],
        [-0.0074,  0.0276,  0.0024,  ...,  0.0121,  0.0271, -0.0102],
        [ 0.0061,  0.0017,  0.0019,  ..., -0.0153, -0.0148,  0.0423]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.0117, -4.8633, -1.0000,  ...,  0.3918,  3.1953, -0.5557]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 16:36:07 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more specific term for a oven is broiler
A more specific term for a computer is laptop
A more specific term for a shoes is sneakers
A more specific term for a mixer is blender
A more specific term for a flask is thermos
A more specific term for a guitar is ukulele
A more specific term for a container is bag
A more specific term for a backpack is
2024-07-30 16:36:09 root INFO     [order_1_approx] starting weight calculation for A more specific term for a container is bag
A more specific term for a guitar is ukulele
A more specific term for a shoes is sneakers
A more specific term for a backpack is daypack
A more specific term for a mixer is blender
A more specific term for a computer is laptop
A more specific term for a oven is broiler
A more specific term for a flask is
2024-07-30 16:36:09 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 16:38:07 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0521,  0.0791,  0.1549,  ..., -0.0316, -0.3909, -0.3457],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.6123, -2.7930, -1.0859,  ..., -0.7642, -3.6562, -5.4609],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0107,  0.0023, -0.0102,  ..., -0.0109,  0.0130, -0.0008],
        [-0.0263,  0.0400,  0.0128,  ...,  0.0096,  0.0122, -0.0132],
        [ 0.0286, -0.0101,  0.0146,  ..., -0.0089, -0.0188,  0.0013],
        ...,
        [ 0.0384,  0.0133,  0.0002,  ...,  0.0277, -0.0026,  0.0179],
        [ 0.0152,  0.0217,  0.0057,  ..., -0.0070,  0.0106, -0.0246],
        [ 0.0245, -0.0271, -0.0208,  ...,  0.0068, -0.0030,  0.0091]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.9751, -2.0000, -1.3311,  ..., -0.2778, -4.6719, -5.3203]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 16:38:09 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The state of being devoted is devotedness
The state of being creative is creativeness
The state of being strange is strangeness
The state of being dangerous is dangerousness
The state of being happy is happiness
The state of being hot is hotness
The state of being pure is pureness
The state of being effective is
2024-07-30 16:38:09 root INFO     [order_1_approx] starting weight calculation for The state of being dangerous is dangerousness
The state of being effective is effectiveness
The state of being devoted is devotedness
The state of being pure is pureness
The state of being happy is happiness
The state of being strange is strangeness
The state of being hot is hotness
The state of being creative is
2024-07-30 16:38:09 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-30 16:38:41 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1787, -0.3796, -0.4097,  ..., -0.0749,  0.2014,  0.1918],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.0273, -3.1445,  0.2812,  ..., -0.5293,  2.4355, -1.5557],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.1176, -0.0105,  0.0057,  ...,  0.0127, -0.0040, -0.0136],
        [ 0.0220,  0.0857, -0.0073,  ..., -0.0528, -0.0018, -0.0101],
        [ 0.0059,  0.0070,  0.1061,  ...,  0.0205,  0.0016,  0.0412],
        ...,
        [ 0.0316,  0.0146, -0.0087,  ...,  0.0557, -0.0248, -0.0009],
        [-0.0704,  0.0007, -0.0543,  ..., -0.0270,  0.0687, -0.0749],
        [ 0.0216,  0.0279, -0.0365,  ..., -0.0063, -0.0098,  0.0736]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.4688, -2.8984,  0.0397,  ..., -0.4644,  2.6953, -1.5479]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 16:38:42 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more specific term for a container is bag
A more specific term for a guitar is ukulele
A more specific term for a shoes is sneakers
A more specific term for a backpack is daypack
A more specific term for a mixer is blender
A more specific term for a computer is laptop
A more specific term for a oven is broiler
A more specific term for a flask is
2024-07-30 16:38:42 root INFO     [order_1_approx] starting weight calculation for A more specific term for a mixer is blender
A more specific term for a backpack is daypack
A more specific term for a shoes is sneakers
A more specific term for a oven is broiler
A more specific term for a computer is laptop
A more specific term for a flask is thermos
A more specific term for a container is bag
A more specific term for a guitar is
2024-07-30 16:38:42 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 16:40:47 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0005,  0.2444,  0.1061,  ..., -0.0111, -0.1991, -0.0386],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.7236, -4.1562,  1.3965,  ...,  0.8447, -0.9512, -0.1680],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 4.9530e-02, -6.9237e-03,  1.0689e-02,  ...,  1.1215e-02,
         -4.6654e-03,  1.3657e-02],
        [ 4.3945e-03,  7.5722e-03,  1.8265e-02,  ...,  1.3016e-02,
          1.3367e-02,  3.2749e-03],
        [-4.5395e-03, -1.9745e-02,  3.4973e-02,  ...,  1.1665e-02,
         -1.7090e-02, -1.7731e-02],
        ...,
        [ 3.4332e-05,  7.1983e-03, -6.9199e-03,  ...,  2.3010e-02,
         -5.2490e-03, -1.0201e-02],
        [-5.2643e-04,  1.8845e-02, -6.4697e-03,  ..., -7.5073e-03,
          5.6610e-03, -2.1240e-02],
        [ 1.4603e-02, -1.4618e-02, -1.5198e-02,  ...,  1.7044e-02,
         -2.1179e-02,  3.7231e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.7974, -4.2188,  1.3408,  ...,  1.1270, -1.1924, -0.0518]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 16:40:49 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The state of being dangerous is dangerousness
The state of being effective is effectiveness
The state of being devoted is devotedness
The state of being pure is pureness
The state of being happy is happiness
The state of being strange is strangeness
The state of being hot is hotness
The state of being creative is
2024-07-30 16:40:50 root INFO     [order_1_approx] starting weight calculation for The state of being creative is creativeness
The state of being hot is hotness
The state of being effective is effectiveness
The state of being devoted is devotedness
The state of being pure is pureness
The state of being happy is happiness
The state of being dangerous is dangerousness
The state of being strange is
2024-07-30 16:40:50 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-30 16:41:12 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1675,  0.4404,  0.0626,  ..., -0.0348, -0.2954,  0.0600],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.4502, -6.2656, -1.0625,  ..., -1.0771,  0.8599, -4.3125],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0232, -0.0044,  0.0144,  ...,  0.0125,  0.0278,  0.0229],
        [-0.0233,  0.0475, -0.0055,  ...,  0.0227, -0.0056, -0.0195],
        [ 0.0202,  0.0181,  0.0615,  ..., -0.0016, -0.0150,  0.0122],
        ...,
        [ 0.0052,  0.0052,  0.0093,  ...,  0.0542,  0.0155,  0.0048],
        [-0.0027, -0.0070,  0.0373,  ...,  0.0234,  0.0472, -0.0154],
        [ 0.0108,  0.0004, -0.0044,  ..., -0.0206, -0.0168,  0.0236]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.6904, -6.0156, -1.0791,  ..., -0.8765,  0.8628, -4.1523]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 16:41:13 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more specific term for a mixer is blender
A more specific term for a backpack is daypack
A more specific term for a shoes is sneakers
A more specific term for a oven is broiler
A more specific term for a computer is laptop
A more specific term for a flask is thermos
A more specific term for a container is bag
A more specific term for a guitar is
2024-07-30 16:41:13 root INFO     [order_1_approx] starting weight calculation for A more specific term for a backpack is daypack
A more specific term for a container is bag
A more specific term for a computer is laptop
A more specific term for a flask is thermos
A more specific term for a mixer is blender
A more specific term for a oven is broiler
A more specific term for a guitar is ukulele
A more specific term for a shoes is
2024-07-30 16:41:13 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 16:43:28 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0927, -0.0356,  0.0454,  ...,  0.0315, -0.1011,  0.0439],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.7803, -3.2461, -2.3359,  ..., -2.3848, -4.4922, -2.5742],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0211,  0.0051, -0.0363,  ..., -0.0135, -0.0239,  0.0023],
        [-0.0097,  0.0210,  0.0070,  ...,  0.0085,  0.0023, -0.0021],
        [ 0.0182, -0.0206,  0.0186,  ...,  0.0082, -0.0013, -0.0013],
        ...,
        [-0.0083,  0.0107,  0.0121,  ...,  0.0277,  0.0067, -0.0031],
        [ 0.0023,  0.0107,  0.0185,  ...,  0.0099,  0.0100, -0.0251],
        [ 0.0138,  0.0086, -0.0004,  ...,  0.0203, -0.0194,  0.0139]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.6367, -3.2344, -2.3164,  ..., -2.3594, -4.7031, -2.6855]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 16:43:31 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The state of being creative is creativeness
The state of being hot is hotness
The state of being effective is effectiveness
The state of being devoted is devotedness
The state of being pure is pureness
The state of being happy is happiness
The state of being dangerous is dangerousness
The state of being strange is
2024-07-30 16:43:31 root INFO     [order_1_approx] starting weight calculation for The state of being effective is effectiveness
The state of being strange is strangeness
The state of being hot is hotness
The state of being dangerous is dangerousness
The state of being devoted is devotedness
The state of being happy is happiness
The state of being creative is creativeness
The state of being pure is
2024-07-30 16:43:31 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-30 16:43:46 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0905, -0.1232, -0.0063,  ...,  0.4399, -0.2505, -0.2864],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 5.8789, -6.7344, -0.4795,  ..., -0.1118,  1.4395,  0.9946],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0115, -0.0172, -0.0028,  ...,  0.0025, -0.0034,  0.0020],
        [-0.0024,  0.0271, -0.0006,  ...,  0.0129, -0.0081, -0.0214],
        [ 0.0170, -0.0036,  0.0573,  ...,  0.0003, -0.0416,  0.0100],
        ...,
        [ 0.0083,  0.0068, -0.0035,  ...,  0.0201,  0.0126, -0.0046],
        [-0.0108,  0.0060, -0.0058,  ...,  0.0137,  0.0043,  0.0094],
        [ 0.0040, -0.0003,  0.0073,  ..., -0.0208,  0.0167,  0.0309]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 5.6250, -6.5195, -0.6904,  ..., -0.0298,  1.4590,  0.8154]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 16:43:47 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more specific term for a backpack is daypack
A more specific term for a container is bag
A more specific term for a computer is laptop
A more specific term for a flask is thermos
A more specific term for a mixer is blender
A more specific term for a oven is broiler
A more specific term for a guitar is ukulele
A more specific term for a shoes is
2024-07-30 16:43:47 root INFO     total operator prediction time: 1231.9940888881683 seconds
2024-07-30 16:43:47 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on hypernyms - animals
2024-07-30 16:43:47 root INFO     building operator hypernyms - animals
2024-07-30 16:43:47 root INFO     [order_1_approx] starting weight calculation for The goose falls into the category of fowl
The leopard falls into the category of feline
The squirrel falls into the category of rodent
The tyrannosaurus falls into the category of dinosaur
The fox falls into the category of canine
The velociraptor falls into the category of dinosaur
The falcon falls into the category of raptor
The cobra falls into the category of
2024-07-30 16:43:47 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 16:46:09 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0019, -0.1619,  0.3193,  ...,  0.0100, -0.1909,  0.0982],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.0293, -2.0195, -2.1758,  ..., -3.0059, -4.0586, -3.5547],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0518,  0.0088, -0.0002,  ..., -0.0231, -0.0139, -0.0078],
        [ 0.0013,  0.0199,  0.0297,  ...,  0.0121,  0.0112,  0.0029],
        [ 0.0090, -0.0209,  0.0330,  ...,  0.0212, -0.0086, -0.0022],
        ...,
        [ 0.0081,  0.0031,  0.0137,  ..., -0.0020,  0.0052,  0.0082],
        [ 0.0248, -0.0053, -0.0210,  ...,  0.0039,  0.0094, -0.0104],
        [ 0.0030,  0.0036, -0.0055,  ...,  0.0324,  0.0082,  0.0319]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.8145, -2.0547, -2.6113,  ..., -2.6621, -4.2461, -3.3711]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 16:46:10 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The state of being effective is effectiveness
The state of being strange is strangeness
The state of being hot is hotness
The state of being dangerous is dangerousness
The state of being devoted is devotedness
The state of being happy is happiness
The state of being creative is creativeness
The state of being pure is
2024-07-30 16:46:10 root INFO     [order_1_approx] starting weight calculation for The state of being creative is creativeness
The state of being dangerous is dangerousness
The state of being pure is pureness
The state of being effective is effectiveness
The state of being devoted is devotedness
The state of being strange is strangeness
The state of being happy is happiness
The state of being hot is
2024-07-30 16:46:10 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-30 16:46:18 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1086,  0.0790, -0.3284,  ...,  0.2800, -0.2261,  0.2058],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.6406, -4.2852,  1.8926,  ..., -2.0312, -3.9082,  0.2124],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0497, -0.0005,  0.0025,  ..., -0.0094,  0.0034,  0.0041],
        [-0.0078,  0.0529, -0.0047,  ...,  0.0023,  0.0088, -0.0096],
        [ 0.0104,  0.0124,  0.0548,  ..., -0.0310, -0.0216, -0.0089],
        ...,
        [ 0.0044,  0.0109,  0.0007,  ...,  0.0551,  0.0154,  0.0066],
        [-0.0281,  0.0309,  0.0035,  ...,  0.0179,  0.0308,  0.0032],
        [-0.0082, -0.0152,  0.0037,  ..., -0.0268,  0.0113,  0.0145]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.8936, -4.7461,  1.2422,  ..., -1.7529, -4.8984,  1.0293]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 16:46:20 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The goose falls into the category of fowl
The leopard falls into the category of feline
The squirrel falls into the category of rodent
The tyrannosaurus falls into the category of dinosaur
The fox falls into the category of canine
The velociraptor falls into the category of dinosaur
The falcon falls into the category of raptor
The cobra falls into the category of
2024-07-30 16:46:20 root INFO     [order_1_approx] starting weight calculation for The falcon falls into the category of raptor
The tyrannosaurus falls into the category of dinosaur
The squirrel falls into the category of rodent
The cobra falls into the category of snake
The goose falls into the category of fowl
The leopard falls into the category of feline
The velociraptor falls into the category of dinosaur
The fox falls into the category of
2024-07-30 16:46:20 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 16:48:45 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2334, -0.1833,  0.1593,  ...,  0.0242, -0.1149, -0.0450],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.6250, -2.9277,  0.0166,  ..., -4.5312, -5.6641, -0.6162],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0449, -0.0463, -0.0108,  ..., -0.0350, -0.0285,  0.0411],
        [-0.0042, -0.0021,  0.0126,  ..., -0.0262, -0.0057,  0.0149],
        [-0.0064, -0.0064,  0.0250,  ...,  0.0026,  0.0050,  0.0080],
        ...,
        [-0.0004, -0.0202,  0.0119,  ..., -0.0073,  0.0036, -0.0154],
        [ 0.0168,  0.0224, -0.0139,  ...,  0.0056,  0.0420, -0.0344],
        [-0.0064, -0.0477, -0.0098,  ..., -0.0208,  0.0053,  0.0503]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.6831, -2.7402, -0.3889,  ..., -4.5039, -5.7578, -0.5889]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 16:48:46 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The state of being creative is creativeness
The state of being dangerous is dangerousness
The state of being pure is pureness
The state of being effective is effectiveness
The state of being devoted is devotedness
The state of being strange is strangeness
The state of being happy is happiness
The state of being hot is
2024-07-30 16:48:47 root INFO     [order_1_approx] starting weight calculation for The state of being effective is effectiveness
The state of being hot is hotness
The state of being devoted is devotedness
The state of being creative is creativeness
The state of being pure is pureness
The state of being strange is strangeness
The state of being dangerous is dangerousness
The state of being happy is
2024-07-30 16:48:47 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-30 16:48:50 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0387,  0.1812, -0.0207,  ...,  0.1242, -0.0870, -0.0099],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.6533, -5.3359,  1.9951,  ..., -3.1875, -5.5156,  1.8438],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0331,  0.0058,  0.0007,  ...,  0.0164, -0.0153, -0.0109],
        [ 0.0189,  0.0311,  0.0131,  ...,  0.0056, -0.0079, -0.0194],
        [ 0.0075,  0.0280,  0.0531,  ..., -0.0529,  0.0034, -0.0195],
        ...,
        [ 0.0125,  0.0090, -0.0022,  ..., -0.0012,  0.0198,  0.0034],
        [-0.0016, -0.0053, -0.0119,  ...,  0.0118,  0.0485,  0.0092],
        [ 0.0124, -0.0086,  0.0023,  ...,  0.0094, -0.0069,  0.0188]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.8472, -5.5703,  1.3320,  ..., -3.1484, -5.6445,  2.0273]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 16:48:51 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The falcon falls into the category of raptor
The tyrannosaurus falls into the category of dinosaur
The squirrel falls into the category of rodent
The cobra falls into the category of snake
The goose falls into the category of fowl
The leopard falls into the category of feline
The velociraptor falls into the category of dinosaur
The fox falls into the category of
2024-07-30 16:48:51 root INFO     [order_1_approx] starting weight calculation for The tyrannosaurus falls into the category of dinosaur
The squirrel falls into the category of rodent
The velociraptor falls into the category of dinosaur
The leopard falls into the category of feline
The fox falls into the category of canine
The cobra falls into the category of snake
The goose falls into the category of fowl
The falcon falls into the category of
2024-07-30 16:48:51 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 16:51:21 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0755,  0.1355, -0.2864,  ...,  0.3206, -0.0849,  0.1532],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.6758, -3.1602,  2.3555,  ..., -1.0781, -5.7969,  1.9893],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0498, -0.0079, -0.0075,  ...,  0.0043,  0.0002,  0.0083],
        [ 0.0354,  0.0381,  0.0039,  ...,  0.0084,  0.0033,  0.0059],
        [-0.0005, -0.0060,  0.0378,  ..., -0.0045, -0.0042, -0.0156],
        ...,
        [ 0.0273, -0.0030,  0.0019,  ...,  0.0402, -0.0155,  0.0093],
        [-0.0007,  0.0047,  0.0124,  ...,  0.0149,  0.0466,  0.0083],
        [-0.0108, -0.0198,  0.0055,  ..., -0.0075, -0.0093,  0.0253]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.6445, -3.3418,  1.7930,  ..., -0.9443, -6.5078,  2.7070]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 16:51:22 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1187, -0.1014, -0.0486,  ..., -0.2676, -0.1567, -0.0007],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.5967, -0.5439,  1.2383,  ..., -1.7725, -5.1953, -2.3066],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0351,  0.0199, -0.0072,  ..., -0.0244,  0.0014,  0.0093],
        [-0.0097,  0.0163,  0.0136,  ...,  0.0083,  0.0105,  0.0072],
        [-0.0059, -0.0223,  0.0135,  ..., -0.0037, -0.0307, -0.0195],
        ...,
        [ 0.0150, -0.0047,  0.0014,  ...,  0.0278, -0.0264, -0.0199],
        [-0.0033, -0.0176,  0.0089,  ..., -0.0058,  0.0260, -0.0292],
        [ 0.0091, -0.0108, -0.0197,  ...,  0.0054, -0.0231,  0.0459]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.2500, -0.8428,  1.4102,  ..., -1.5391, -5.0703, -2.6055]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 16:51:25 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The tyrannosaurus falls into the category of dinosaur
The squirrel falls into the category of rodent
The velociraptor falls into the category of dinosaur
The leopard falls into the category of feline
The fox falls into the category of canine
The cobra falls into the category of snake
The goose falls into the category of fowl
The falcon falls into the category of
2024-07-30 16:51:28 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The state of being effective is effectiveness
The state of being hot is hotness
The state of being devoted is devotedness
The state of being creative is creativeness
The state of being pure is pureness
The state of being strange is strangeness
The state of being dangerous is dangerousness
The state of being happy is
2024-07-30 16:51:28 root INFO     [order_1_approx] starting weight calculation for The tyrannosaurus falls into the category of dinosaur
The squirrel falls into the category of rodent
The goose falls into the category of fowl
The velociraptor falls into the category of dinosaur
The fox falls into the category of canine
The cobra falls into the category of snake
The falcon falls into the category of raptor
The leopard falls into the category of
2024-07-30 16:51:28 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 16:51:30 root INFO     [order_1_approx] starting weight calculation for The state of being strange is strangeness
The state of being pure is pureness
The state of being devoted is devotedness
The state of being hot is hotness
The state of being creative is creativeness
The state of being effective is effectiveness
The state of being happy is happiness
The state of being dangerous is
2024-07-30 16:51:30 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-30 16:53:56 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1714, -0.0854, -0.2542,  ...,  0.3357, -0.2192, -0.0737],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.0317, -6.2500, -1.2344,  ..., -4.3359, -6.9648, -0.3203],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0246, -0.0038, -0.0060,  ..., -0.0004, -0.0107,  0.0035],
        [ 0.0183,  0.0123,  0.0033,  ..., -0.0096,  0.0075,  0.0072],
        [-0.0040, -0.0006,  0.0321,  ..., -0.0108, -0.0039, -0.0029],
        ...,
        [-0.0018,  0.0099,  0.0044,  ...,  0.0141,  0.0068,  0.0147],
        [-0.0062, -0.0147, -0.0040,  ...,  0.0052,  0.0187,  0.0044],
        [-0.0117, -0.0043, -0.0053,  ..., -0.0112, -0.0011,  0.0159]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.0920, -6.1055, -1.1719,  ..., -4.2773, -6.9102, -0.2419]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 16:53:57 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The tyrannosaurus falls into the category of dinosaur
The squirrel falls into the category of rodent
The goose falls into the category of fowl
The velociraptor falls into the category of dinosaur
The fox falls into the category of canine
The cobra falls into the category of snake
The falcon falls into the category of raptor
The leopard falls into the category of
2024-07-30 16:53:57 root INFO     [order_1_approx] starting weight calculation for The falcon falls into the category of raptor
The cobra falls into the category of snake
The fox falls into the category of canine
The squirrel falls into the category of rodent
The leopard falls into the category of feline
The velociraptor falls into the category of dinosaur
The goose falls into the category of fowl
The tyrannosaurus falls into the category of
2024-07-30 16:53:57 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 16:54:08 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0271,  0.4666, -0.0457,  ...,  0.2397, -0.1855, -0.2024],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.6475, -4.4023, -1.1543,  ..., -3.4297, -2.7793, -1.6309],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0247, -0.0104, -0.0039,  ...,  0.0055, -0.0302, -0.0004],
        [-0.0249, -0.0020,  0.0279,  ...,  0.0086,  0.0270,  0.0093],
        [ 0.0007, -0.0164,  0.0163,  ..., -0.0172,  0.0015, -0.0060],
        ...,
        [ 0.0145,  0.0196,  0.0147,  ...,  0.0234,  0.0088, -0.0035],
        [ 0.0103,  0.0014,  0.0020,  ...,  0.0144,  0.0297, -0.0055],
        [ 0.0022, -0.0143,  0.0017,  ...,  0.0154, -0.0038,  0.0104]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.8032, -3.9551, -1.1504,  ..., -3.6309, -2.7383, -1.9062]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 16:54:09 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The state of being strange is strangeness
The state of being pure is pureness
The state of being devoted is devotedness
The state of being hot is hotness
The state of being creative is creativeness
The state of being effective is effectiveness
The state of being happy is happiness
The state of being dangerous is
2024-07-30 16:54:09 root INFO     [order_1_approx] starting weight calculation for The state of being effective is effectiveness
The state of being creative is creativeness
The state of being pure is pureness
The state of being dangerous is dangerousness
The state of being strange is strangeness
The state of being hot is hotness
The state of being happy is happiness
The state of being devoted is
2024-07-30 16:54:09 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-30 16:56:25 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1168, -0.1980, -0.6611,  ..., -0.0997, -0.5576, -0.0458],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.8125, -3.9492,  1.6250,  ..., -2.5859, -6.3594, -1.3379],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0334, -0.0109, -0.0064,  ..., -0.0064,  0.0034,  0.0115],
        [ 0.0045,  0.0229, -0.0141,  ..., -0.0054, -0.0002, -0.0055],
        [ 0.0058,  0.0075,  0.0279,  ..., -0.0185, -0.0245, -0.0053],
        ...,
        [ 0.0082, -0.0085,  0.0158,  ...,  0.0497, -0.0013, -0.0035],
        [-0.0009,  0.0046, -0.0091,  ...,  0.0052,  0.0227, -0.0032],
        [-0.0030, -0.0277,  0.0076,  ...,  0.0128,  0.0047,  0.0300]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.5371, -3.9199,  1.7451,  ..., -2.3789, -6.7695, -1.2559]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 16:56:27 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The falcon falls into the category of raptor
The cobra falls into the category of snake
The fox falls into the category of canine
The squirrel falls into the category of rodent
The leopard falls into the category of feline
The velociraptor falls into the category of dinosaur
The goose falls into the category of fowl
The tyrannosaurus falls into the category of
2024-07-30 16:56:28 root INFO     [order_1_approx] starting weight calculation for The falcon falls into the category of raptor
The tyrannosaurus falls into the category of dinosaur
The velociraptor falls into the category of dinosaur
The leopard falls into the category of feline
The fox falls into the category of canine
The squirrel falls into the category of rodent
The cobra falls into the category of snake
The goose falls into the category of
2024-07-30 16:56:28 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 16:56:48 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0703,  0.1970, -0.0897,  ...,  0.2627, -0.7163,  0.1893],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.5117, -4.9531, -1.3359,  ..., -2.5059, -3.6094, -2.9121],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0363,  0.0146, -0.0220,  ...,  0.0144,  0.0072, -0.0255],
        [-0.0082,  0.0427, -0.0144,  ...,  0.0112,  0.0235,  0.0248],
        [ 0.0151, -0.0296,  0.0225,  ..., -0.0083, -0.0260, -0.0019],
        ...,
        [ 0.0339,  0.0053,  0.0305,  ...,  0.0217,  0.0072,  0.0212],
        [ 0.0391, -0.0259, -0.0080,  ..., -0.0106,  0.0061, -0.0338],
        [ 0.0292,  0.0043, -0.0107,  ...,  0.0094, -0.0108,  0.0463]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.2188, -3.9766, -1.7832,  ..., -2.4434, -4.2539, -2.6465]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 16:56:49 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The state of being effective is effectiveness
The state of being creative is creativeness
The state of being pure is pureness
The state of being dangerous is dangerousness
The state of being strange is strangeness
The state of being hot is hotness
The state of being happy is happiness
The state of being devoted is
2024-07-30 16:56:49 root INFO     total operator prediction time: 1280.1260256767273 seconds
2024-07-30 16:56:49 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on re+verb_reg
2024-07-30 16:56:49 root INFO     building operator re+verb_reg
2024-07-30 16:56:49 root INFO     [order_1_approx] starting weight calculation for To distribute again is to redistribute
To calculate again is to recalculate
To submit again is to resubmit
To locate again is to relocate
To cognize again is to recognize
To assess again is to reassess
To establish again is to reestablish
To generate again is to
2024-07-30 16:56:49 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-30 16:58:58 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1372, -0.2166, -0.2097,  ...,  0.4082, -0.4246,  0.1166],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.8887, -3.2656,  4.2031,  ..., -2.0527, -8.7969,  1.7520],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0493, -0.0090, -0.0359,  ..., -0.0028, -0.0102, -0.0077],
        [ 0.0253,  0.0315,  0.0072,  ...,  0.0287,  0.0013, -0.0231],
        [-0.0117,  0.0103,  0.0492,  ..., -0.0092, -0.0152, -0.0057],
        ...,
        [ 0.0201, -0.0059,  0.0212,  ...,  0.0280,  0.0136, -0.0063],
        [ 0.0065,  0.0088, -0.0041,  ...,  0.0160,  0.0516,  0.0115],
        [ 0.0031, -0.0296, -0.0084,  ..., -0.0217,  0.0042,  0.0408]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.3320, -3.1367,  3.7539,  ..., -2.0137, -9.0078,  2.2031]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 16:59:01 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The falcon falls into the category of raptor
The tyrannosaurus falls into the category of dinosaur
The velociraptor falls into the category of dinosaur
The leopard falls into the category of feline
The fox falls into the category of canine
The squirrel falls into the category of rodent
The cobra falls into the category of snake
The goose falls into the category of
2024-07-30 16:59:01 root INFO     [order_1_approx] starting weight calculation for The fox falls into the category of canine
The cobra falls into the category of snake
The tyrannosaurus falls into the category of dinosaur
The goose falls into the category of fowl
The falcon falls into the category of raptor
The leopard falls into the category of feline
The squirrel falls into the category of rodent
The velociraptor falls into the category of
2024-07-30 16:59:02 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 16:59:26 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0948,  0.1812, -0.0505,  ...,  0.2449, -0.0180, -0.1006],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.2439, -1.7412,  1.0156,  ...,  2.4062, -4.3672, -3.7969],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0336, -0.0100,  0.0413,  ...,  0.0306,  0.0077,  0.0175],
        [ 0.0131,  0.0320, -0.0130,  ...,  0.0019,  0.0065,  0.0066],
        [-0.0031, -0.0126,  0.0235,  ..., -0.0009, -0.0003, -0.0201],
        ...,
        [ 0.0074, -0.0057,  0.0081,  ...,  0.0349, -0.0060,  0.0122],
        [ 0.0027,  0.0202, -0.0221,  ..., -0.0162, -0.0020, -0.0145],
        [-0.0252, -0.0159, -0.0005,  ..., -0.0121, -0.0126,  0.0305]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.1152, -1.7119,  1.4443,  ...,  2.4023, -4.9102, -3.9062]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 16:59:36 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To distribute again is to redistribute
To calculate again is to recalculate
To submit again is to resubmit
To locate again is to relocate
To cognize again is to recognize
To assess again is to reassess
To establish again is to reestablish
To generate again is to
2024-07-30 16:59:36 root INFO     [order_1_approx] starting weight calculation for To establish again is to reestablish
To cognize again is to recognize
To assess again is to reassess
To calculate again is to recalculate
To distribute again is to redistribute
To locate again is to relocate
To generate again is to regenerate
To submit again is to
2024-07-30 16:59:36 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-30 17:01:33 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0461, -0.4075, -0.5210,  ..., -0.0555, -0.6309, -0.0717],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.3320, -5.8828,  2.6523,  ..., -1.2109, -7.8906,  0.9248],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 2.7069e-02,  2.6655e-04, -2.9926e-03,  ...,  6.4812e-03,
         -6.6986e-03,  2.9602e-03],
        [ 6.6643e-03,  2.0584e-02,  4.3144e-03,  ..., -5.3406e-04,
         -1.4267e-03, -7.5302e-03],
        [ 1.5884e-02,  4.0817e-03,  1.0559e-02,  ..., -8.8043e-03,
         -1.4145e-02,  2.1038e-03],
        ...,
        [ 7.6141e-03, -1.5907e-03,  5.8060e-03,  ...,  2.1057e-02,
          7.0534e-03,  1.2245e-02],
        [-1.1589e-02, -1.6403e-03, -9.6321e-05,  ...,  3.6697e-03,
          1.7242e-02,  6.2866e-03],
        [ 2.0428e-03, -1.5900e-02,  7.3853e-03,  ...,  1.1703e-02,
          3.9024e-03,  2.9572e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.2002, -5.6172,  2.6641,  ..., -1.0410, -8.0703,  1.2178]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 17:01:35 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The fox falls into the category of canine
The cobra falls into the category of snake
The tyrannosaurus falls into the category of dinosaur
The goose falls into the category of fowl
The falcon falls into the category of raptor
The leopard falls into the category of feline
The squirrel falls into the category of rodent
The velociraptor falls into the category of
2024-07-30 17:01:35 root INFO     [order_1_approx] starting weight calculation for The falcon falls into the category of raptor
The leopard falls into the category of feline
The tyrannosaurus falls into the category of dinosaur
The fox falls into the category of canine
The velociraptor falls into the category of dinosaur
The cobra falls into the category of snake
The goose falls into the category of fowl
The squirrel falls into the category of
2024-07-30 17:01:35 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 17:02:18 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1825,  0.0426, -0.1665,  ...,  0.0136, -0.4209,  0.2874],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.9629, -2.8711,  0.4058,  ...,  0.5176, -4.3398, -3.5898],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0486,  0.0103, -0.0040,  ..., -0.0147, -0.0168,  0.0137],
        [-0.0059,  0.0013,  0.0250,  ...,  0.0245,  0.0166, -0.0029],
        [-0.0179,  0.0158,  0.0172,  ..., -0.0002,  0.0210,  0.0057],
        ...,
        [ 0.0054, -0.0204,  0.0259,  ...,  0.0623,  0.0210,  0.0147],
        [-0.0050,  0.0117,  0.0010,  ..., -0.0303,  0.0152, -0.0178],
        [-0.0203, -0.0432, -0.0029,  ...,  0.0214, -0.0305,  0.0336]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.6387, -2.2441,  0.5654,  ...,  0.9131, -4.6602, -3.5117]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 17:02:18 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To establish again is to reestablish
To cognize again is to recognize
To assess again is to reassess
To calculate again is to recalculate
To distribute again is to redistribute
To locate again is to relocate
To generate again is to regenerate
To submit again is to
2024-07-30 17:02:19 root INFO     [order_1_approx] starting weight calculation for To submit again is to resubmit
To generate again is to regenerate
To locate again is to relocate
To calculate again is to recalculate
To distribute again is to redistribute
To establish again is to reestablish
To cognize again is to recognize
To assess again is to
2024-07-30 17:02:19 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-30 17:04:01 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0471, -0.4043, -0.4370,  ...,  0.0980, -0.3711,  0.1146],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.5459, -4.0977,  2.0000,  ..., -3.6211, -5.8008, -0.8096],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0236,  0.0047, -0.0007,  ...,  0.0004, -0.0131, -0.0006],
        [ 0.0145,  0.0020,  0.0153,  ..., -0.0036,  0.0117, -0.0074],
        [-0.0106,  0.0164,  0.0285,  ..., -0.0224,  0.0038, -0.0070],
        ...,
        [-0.0070,  0.0130, -0.0004,  ...,  0.0073,  0.0028, -0.0062],
        [ 0.0047,  0.0021, -0.0132,  ...,  0.0001,  0.0262,  0.0032],
        [-0.0164, -0.0228,  0.0029,  ..., -0.0146, -0.0027,  0.0095]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.2617, -3.9668,  1.6816,  ..., -3.5117, -5.8281, -0.4380]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 17:04:04 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The falcon falls into the category of raptor
The leopard falls into the category of feline
The tyrannosaurus falls into the category of dinosaur
The fox falls into the category of canine
The velociraptor falls into the category of dinosaur
The cobra falls into the category of snake
The goose falls into the category of fowl
The squirrel falls into the category of
2024-07-30 17:04:04 root INFO     total operator prediction time: 1216.6581528186798 seconds
2024-07-30 17:04:04 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on synonyms - intensity
2024-07-30 17:04:04 root INFO     building operator synonyms - intensity
2024-07-30 17:04:04 root INFO     [order_1_approx] starting weight calculation for A more intense word for sniffles is pneumonia
A more intense word for happy is ecstatic
A more intense word for guilty is remorseful
A more intense word for jog is run
A more intense word for pain is torment
A more intense word for hungry is starving
A more intense word for tired is exhausted
A more intense word for warm is
2024-07-30 17:04:04 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 17:04:56 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0014,  0.1847, -0.1176,  ...,  0.2063, -0.2220, -0.2454],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.0332, -2.3516,  0.7490,  ..., -0.0635, -5.1953, -4.6289],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 4.3976e-02, -7.1869e-03,  2.5528e-02,  ...,  2.6474e-03,
         -4.3411e-03,  1.5991e-02],
        [ 4.0512e-03,  8.4915e-03, -1.5091e-02,  ...,  1.1261e-02,
          4.9057e-03,  1.6022e-02],
        [-2.4124e-02,  6.0539e-03,  2.3468e-02,  ...,  5.4855e-03,
          2.7878e-02,  2.8496e-03],
        ...,
        [ 1.6235e-02,  4.2648e-03,  1.1215e-02,  ...,  4.6570e-02,
          6.6757e-05, -2.7588e-02],
        [-2.6611e-02, -8.7204e-03, -4.4098e-03,  ...,  7.7209e-03,
          1.8509e-02, -8.8654e-03],
        [ 1.0750e-02, -2.8706e-03,  1.6785e-03,  ...,  5.8517e-03,
         -1.5747e-02,  1.1635e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.0674, -1.9795,  1.0430,  ..., -0.2595, -5.2266, -4.3867]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 17:04:57 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To submit again is to resubmit
To generate again is to regenerate
To locate again is to relocate
To calculate again is to recalculate
To distribute again is to redistribute
To establish again is to reestablish
To cognize again is to recognize
To assess again is to
2024-07-30 17:04:57 root INFO     [order_1_approx] starting weight calculation for To distribute again is to redistribute
To submit again is to resubmit
To locate again is to relocate
To assess again is to reassess
To generate again is to regenerate
To cognize again is to recognize
To establish again is to reestablish
To calculate again is to
2024-07-30 17:04:57 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-30 17:06:36 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3391, -0.2930,  0.0212,  ..., -0.1646, -0.3328,  0.3049],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.9653, -2.7520, -1.8613,  ..., -2.0859, -6.9492,  1.5547],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 2.2751e-02, -6.3324e-04, -8.2626e-03,  ..., -1.2695e-02,
         -8.8654e-03,  8.7585e-03],
        [-8.8425e-03,  4.8035e-02,  2.3407e-02,  ...,  2.4445e-02,
         -1.2833e-02,  1.5366e-02],
        [-2.7344e-02, -3.0029e-02,  3.0945e-02,  ...,  2.1912e-02,
         -2.1225e-02, -1.9932e-03],
        ...,
        [ 3.3379e-05,  2.3376e-02,  1.2123e-02,  ...,  3.0975e-02,
         -9.0485e-03,  5.2109e-03],
        [ 3.7415e-02, -2.2522e-02,  9.7504e-03,  ...,  1.9669e-02,
          3.2043e-02, -1.3733e-02],
        [-3.1677e-02, -2.3392e-02, -3.1311e-02,  ...,  1.1063e-04,
          1.7838e-02,  9.5367e-03]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.3613, -2.7578, -1.8447,  ..., -2.1406, -6.5312,  1.4600]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 17:06:37 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more intense word for sniffles is pneumonia
A more intense word for happy is ecstatic
A more intense word for guilty is remorseful
A more intense word for jog is run
A more intense word for pain is torment
A more intense word for hungry is starving
A more intense word for tired is exhausted
A more intense word for warm is
2024-07-30 17:06:37 root INFO     [order_1_approx] starting weight calculation for A more intense word for warm is hot
A more intense word for jog is run
A more intense word for tired is exhausted
A more intense word for hungry is starving
A more intense word for pain is torment
A more intense word for guilty is remorseful
A more intense word for happy is ecstatic
A more intense word for sniffles is
2024-07-30 17:06:37 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 17:07:37 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0864,  0.1638,  0.0883,  ..., -0.0858, -0.3604, -0.0879],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-2.3203, -0.2952,  3.0234,  ...,  0.8799, -2.6016, -1.8789],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 5.3436e-02, -4.0436e-02,  2.0996e-02,  ...,  1.5144e-02,
         -6.7139e-04,  1.1047e-02],
        [-2.4700e-03,  9.6664e-03, -2.3727e-02,  ...,  1.7258e-02,
          1.6922e-02, -4.5700e-03],
        [-2.0599e-02,  3.1799e-02,  2.9968e-02,  ...,  4.3869e-03,
         -5.9891e-03, -3.2837e-02],
        ...,
        [ 2.4765e-02,  1.3130e-02,  1.7990e-02,  ...,  2.4506e-02,
         -1.1734e-02, -7.1108e-05],
        [ 3.9043e-03,  1.8433e-02, -2.3407e-02,  ...,  1.2161e-02,
         -1.4587e-02, -2.2263e-02],
        [-3.6545e-03,  1.6998e-02, -6.9122e-03,  ..., -8.8882e-04,
         -2.4902e-02, -2.7122e-03]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-2.0723, -0.2886,  2.9727,  ...,  1.0195, -2.4395, -1.7422]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 17:07:39 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To distribute again is to redistribute
To submit again is to resubmit
To locate again is to relocate
To assess again is to reassess
To generate again is to regenerate
To cognize again is to recognize
To establish again is to reestablish
To calculate again is to
2024-07-30 17:07:39 root INFO     [order_1_approx] starting weight calculation for To assess again is to reassess
To submit again is to resubmit
To calculate again is to recalculate
To generate again is to regenerate
To establish again is to reestablish
To cognize again is to recognize
To distribute again is to redistribute
To locate again is to
2024-07-30 17:07:39 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-30 17:09:08 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0842, -0.4563, -0.4526,  ...,  0.1995, -0.6567,  0.2023],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.8105, -1.2686,  2.7109,  ..., -0.8901,  1.0059,  3.2051],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0281, -0.0016,  0.0173,  ...,  0.0051,  0.0113,  0.0471],
        [-0.0212,  0.0434,  0.0053,  ..., -0.0149,  0.0113, -0.0349],
        [-0.0107, -0.0079,  0.0656,  ...,  0.0419, -0.0346, -0.0071],
        ...,
        [ 0.0363, -0.0027,  0.0175,  ...,  0.0389, -0.0066, -0.0063],
        [ 0.0064, -0.0133,  0.0017,  ...,  0.0137,  0.0092, -0.0122],
        [-0.0192,  0.0150, -0.0032,  ...,  0.0127,  0.0192,  0.0143]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.6523, -0.5483,  2.9902,  ..., -0.6772,  1.4004,  2.6797]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 17:09:08 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more intense word for warm is hot
A more intense word for jog is run
A more intense word for tired is exhausted
A more intense word for hungry is starving
A more intense word for pain is torment
A more intense word for guilty is remorseful
A more intense word for happy is ecstatic
A more intense word for sniffles is
2024-07-30 17:09:09 root INFO     [order_1_approx] starting weight calculation for A more intense word for tired is exhausted
A more intense word for warm is hot
A more intense word for pain is torment
A more intense word for jog is run
A more intense word for hungry is starving
A more intense word for happy is ecstatic
A more intense word for sniffles is pneumonia
A more intense word for guilty is
2024-07-30 17:09:09 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 17:10:17 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0361,  0.3799, -0.4697,  ...,  0.0220, -0.1636, -0.1359],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-2.2305, -3.7891,  0.8125,  ...,  0.3643, -5.7617, -4.0742],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0454, -0.0437,  0.0044,  ...,  0.0225,  0.0218,  0.0135],
        [ 0.0110,  0.0358,  0.0098,  ...,  0.0056, -0.0031,  0.0142],
        [-0.0041,  0.0416,  0.0230,  ..., -0.0137,  0.0144, -0.0191],
        ...,
        [ 0.0121,  0.0150,  0.0001,  ...,  0.0335,  0.0033,  0.0029],
        [ 0.0206,  0.0109, -0.0178,  ..., -0.0004,  0.0130,  0.0098],
        [-0.0054,  0.0033, -0.0279,  ...,  0.0013, -0.0192,  0.0219]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-2.0195, -4.0312,  0.9160,  ...,  0.0527, -5.5469, -4.0312]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 17:10:18 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To assess again is to reassess
To submit again is to resubmit
To calculate again is to recalculate
To generate again is to regenerate
To establish again is to reestablish
To cognize again is to recognize
To distribute again is to redistribute
To locate again is to
2024-07-30 17:10:18 root INFO     [order_1_approx] starting weight calculation for To calculate again is to recalculate
To assess again is to reassess
To establish again is to reestablish
To submit again is to resubmit
To cognize again is to recognize
To generate again is to regenerate
To locate again is to relocate
To distribute again is to
2024-07-30 17:10:18 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-30 17:11:37 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1560, -0.1887, -0.3066,  ...,  0.1127, -0.0870,  0.4829],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.4238, -3.0977,  1.7803,  ..., -1.9092, -2.1777,  0.5786],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0567,  0.0102,  0.0238,  ..., -0.0045, -0.0074,  0.0349],
        [-0.0247,  0.0292,  0.0059,  ..., -0.0305, -0.0116, -0.0310],
        [-0.0035, -0.0127,  0.0602,  ...,  0.0238, -0.0005,  0.0206],
        ...,
        [-0.0239,  0.0072, -0.0101,  ...,  0.0435,  0.0024, -0.0359],
        [-0.0070, -0.0093,  0.0178,  ...,  0.0084,  0.0321, -0.0146],
        [-0.0106,  0.0044, -0.0071,  ...,  0.0020, -0.0127,  0.0207]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.2500, -2.8223,  1.9102,  ..., -1.9180, -2.0078,  0.1235]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 17:11:39 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more intense word for tired is exhausted
A more intense word for warm is hot
A more intense word for pain is torment
A more intense word for jog is run
A more intense word for hungry is starving
A more intense word for happy is ecstatic
A more intense word for sniffles is pneumonia
A more intense word for guilty is
2024-07-30 17:11:39 root INFO     [order_1_approx] starting weight calculation for A more intense word for hungry is starving
A more intense word for guilty is remorseful
A more intense word for tired is exhausted
A more intense word for jog is run
A more intense word for sniffles is pneumonia
A more intense word for pain is torment
A more intense word for warm is hot
A more intense word for happy is
2024-07-30 17:11:39 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 17:12:57 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1931,  0.4333, -0.0603,  ...,  0.2214, -0.1814,  0.1061],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.0356, -3.3086,  0.9531,  ...,  0.2402, -4.9648, -3.7500],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0330, -0.0239,  0.0155,  ...,  0.0048, -0.0107,  0.0278],
        [-0.0077,  0.0298,  0.0046,  ...,  0.0080,  0.0053,  0.0037],
        [ 0.0138,  0.0157,  0.0213,  ..., -0.0222,  0.0113,  0.0056],
        ...,
        [ 0.0236,  0.0118,  0.0067,  ...,  0.0444, -0.0136,  0.0017],
        [ 0.0146, -0.0022, -0.0079,  ..., -0.0187,  0.0363, -0.0166],
        [ 0.0004, -0.0104,  0.0038,  ...,  0.0028, -0.0378,  0.0553]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.1985, -3.5859,  1.3301,  ...,  0.3206, -4.8750, -3.5117]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 17:12:58 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To calculate again is to recalculate
To assess again is to reassess
To establish again is to reestablish
To submit again is to resubmit
To cognize again is to recognize
To generate again is to regenerate
To locate again is to relocate
To distribute again is to
2024-07-30 17:12:58 root INFO     [order_1_approx] starting weight calculation for To generate again is to regenerate
To distribute again is to redistribute
To cognize again is to recognize
To locate again is to relocate
To submit again is to resubmit
To assess again is to reassess
To calculate again is to recalculate
To establish again is to
2024-07-30 17:12:58 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-30 17:14:07 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1406, -0.0227,  0.1215,  ..., -0.0866, -0.4004,  0.2015],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.1172, -1.2227,  4.1484,  ...,  1.9268, -6.3633,  0.0664],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0585,  0.0138,  0.0293,  ..., -0.0258,  0.0091,  0.0296],
        [ 0.0122,  0.0187,  0.0128,  ..., -0.0087,  0.0040,  0.0015],
        [-0.0055,  0.0022,  0.0303,  ...,  0.0236, -0.0308, -0.0160],
        ...,
        [-0.0110,  0.0048, -0.0131,  ...,  0.0316, -0.0096, -0.0164],
        [ 0.0021, -0.0151, -0.0071,  ...,  0.0268,  0.0065, -0.0134],
        [-0.0176, -0.0114, -0.0148,  ...,  0.0007,  0.0001,  0.0242]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.9258, -1.3662,  3.7188,  ...,  2.0234, -6.3086, -0.0978]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 17:14:08 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more intense word for hungry is starving
A more intense word for guilty is remorseful
A more intense word for tired is exhausted
A more intense word for jog is run
A more intense word for sniffles is pneumonia
A more intense word for pain is torment
A more intense word for warm is hot
A more intense word for happy is
2024-07-30 17:14:08 root INFO     [order_1_approx] starting weight calculation for A more intense word for warm is hot
A more intense word for tired is exhausted
A more intense word for happy is ecstatic
A more intense word for sniffles is pneumonia
A more intense word for hungry is starving
A more intense word for guilty is remorseful
A more intense word for pain is torment
A more intense word for jog is
2024-07-30 17:14:08 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 17:15:38 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1400,  0.1575, -0.4106,  ...,  0.1241, -0.4099,  0.1934],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.0391, -4.0391,  1.2383,  ...,  1.4297, -4.3516, -3.1992],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0497, -0.0240,  0.0111,  ...,  0.0088, -0.0218,  0.0004],
        [-0.0046,  0.0279,  0.0015,  ...,  0.0039, -0.0051, -0.0069],
        [ 0.0039,  0.0272,  0.0158,  ..., -0.0006,  0.0209,  0.0074],
        ...,
        [ 0.0240,  0.0038, -0.0118,  ...,  0.0271,  0.0052, -0.0152],
        [ 0.0006,  0.0071, -0.0094,  ..., -0.0009,  0.0278,  0.0030],
        [-0.0084, -0.0078,  0.0020,  ...,  0.0059, -0.0075,  0.0299]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.8555, -4.0273,  1.5596,  ...,  1.2295, -4.5859, -3.5000]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 17:15:39 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To generate again is to regenerate
To distribute again is to redistribute
To cognize again is to recognize
To locate again is to relocate
To submit again is to resubmit
To assess again is to reassess
To calculate again is to recalculate
To establish again is to
2024-07-30 17:15:39 root INFO     [order_1_approx] starting weight calculation for To calculate again is to recalculate
To generate again is to regenerate
To establish again is to reestablish
To submit again is to resubmit
To distribute again is to redistribute
To locate again is to relocate
To assess again is to reassess
To cognize again is to
2024-07-30 17:15:39 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-30 17:16:40 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1521, -0.0923,  0.0568,  ..., -0.1815, -0.6162, -0.0046],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.2305, -6.3672,  2.5430,  ...,  3.5371, -4.4688, -1.0547],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 5.1605e-02, -1.3283e-02, -2.6703e-05,  ...,  2.2125e-04,
          2.4963e-02,  3.6041e-02],
        [-2.7313e-02,  4.0192e-02,  2.6077e-02,  ...,  2.4429e-02,
          6.6872e-03, -4.7028e-02],
        [-1.8372e-02, -2.8858e-03,  3.6987e-02,  ...,  1.7578e-02,
         -1.1391e-02,  7.8201e-05],
        ...,
        [ 3.0411e-02, -1.3290e-02,  2.5055e-02,  ...,  4.3243e-02,
         -2.1515e-02, -2.2873e-02],
        [-5.9967e-03, -2.1545e-02, -9.8896e-04,  ..., -1.4526e-02,
          1.2924e-02, -1.1627e-02],
        [-2.8183e-02, -8.6670e-03, -1.4133e-03,  ..., -4.1229e-02,
          8.2245e-03,  4.3823e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.7031, -7.1758,  3.0664,  ...,  3.2949, -4.2617, -1.4277]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 17:16:41 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more intense word for warm is hot
A more intense word for tired is exhausted
A more intense word for happy is ecstatic
A more intense word for sniffles is pneumonia
A more intense word for hungry is starving
A more intense word for guilty is remorseful
A more intense word for pain is torment
A more intense word for jog is
2024-07-30 17:16:41 root INFO     [order_1_approx] starting weight calculation for A more intense word for guilty is remorseful
A more intense word for sniffles is pneumonia
A more intense word for warm is hot
A more intense word for happy is ecstatic
A more intense word for pain is torment
A more intense word for hungry is starving
A more intense word for jog is run
A more intense word for tired is
2024-07-30 17:16:41 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 17:18:18 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1444,  0.4910, -0.5010,  ...,  0.0330, -0.0342,  0.0578],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-2.1230, -2.2500,  3.1367,  ...,  1.0176, -3.7617, -1.1553],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0594,  0.0014,  0.0273,  ...,  0.0160,  0.0043, -0.0013],
        [ 0.0170,  0.0167, -0.0017,  ...,  0.0058,  0.0041,  0.0087],
        [-0.0074, -0.0086,  0.0192,  ..., -0.0064, -0.0079, -0.0016],
        ...,
        [ 0.0310, -0.0009, -0.0226,  ...,  0.0384, -0.0011, -0.0109],
        [ 0.0231,  0.0189, -0.0237,  ..., -0.0121,  0.0129, -0.0041],
        [ 0.0043, -0.0047, -0.0052,  ..., -0.0055, -0.0206,  0.0129]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-2.0840, -2.3848,  3.1074,  ...,  1.0908, -3.9160, -1.4580]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 17:18:19 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To calculate again is to recalculate
To generate again is to regenerate
To establish again is to reestablish
To submit again is to resubmit
To distribute again is to redistribute
To locate again is to relocate
To assess again is to reassess
To cognize again is to
2024-07-30 17:18:19 root INFO     total operator prediction time: 1289.8864104747772 seconds
2024-07-30 17:18:19 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on un+adj_reg
2024-07-30 17:18:19 root INFO     building operator un+adj_reg
2024-07-30 17:18:19 root INFO     [order_1_approx] starting weight calculation for The opposite of intended is unintended
The opposite of satisfactory is unsatisfactory
The opposite of usual is unusual
The opposite of conscious is unconscious
The opposite of lucky is unlucky
The opposite of happy is unhappy
The opposite of employed is unemployed
The opposite of restricted is
2024-07-30 17:18:19 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-30 17:19:13 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1262, -0.3022, -0.1136,  ..., -0.0593, -0.3350,  0.5396],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.3945, -7.5312,  4.3516,  ..., -2.3047, -0.5664, -0.1094],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0433, -0.0011,  0.0166,  ..., -0.0030,  0.0243,  0.0017],
        [ 0.0080,  0.0396,  0.0004,  ..., -0.0021,  0.0027, -0.0181],
        [-0.0080,  0.0059,  0.0511,  ...,  0.0123, -0.0242,  0.0010],
        ...,
        [ 0.0208,  0.0064,  0.0076,  ...,  0.0166, -0.0028, -0.0110],
        [-0.0205,  0.0043,  0.0076,  ...,  0.0299,  0.0271, -0.0044],
        [-0.0054, -0.0040,  0.0080,  ..., -0.0129,  0.0043,  0.0170]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.7441, -7.0664,  4.4023,  ..., -2.2422, -0.6865, -0.7129]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 17:19:13 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more intense word for guilty is remorseful
A more intense word for sniffles is pneumonia
A more intense word for warm is hot
A more intense word for happy is ecstatic
A more intense word for pain is torment
A more intense word for hungry is starving
A more intense word for jog is run
A more intense word for tired is
2024-07-30 17:19:14 root INFO     [order_1_approx] starting weight calculation for A more intense word for guilty is remorseful
A more intense word for warm is hot
A more intense word for jog is run
A more intense word for hungry is starving
A more intense word for tired is exhausted
A more intense word for sniffles is pneumonia
A more intense word for happy is ecstatic
A more intense word for pain is
2024-07-30 17:19:14 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 17:20:58 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0642, -0.0964, -0.5039,  ..., -0.0528, -0.0201,  0.1483],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.0879,  0.5859,  2.3984,  ...,  0.5967, -1.7520, -1.9180],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 3.2715e-02, -4.3221e-03, -4.2145e-02,  ...,  3.9253e-03,
         -7.7248e-03,  8.5297e-03],
        [-3.9825e-02,  1.5823e-02,  2.5604e-02,  ..., -1.5541e-02,
          3.6392e-03, -1.9287e-02],
        [-3.7346e-03,  2.7962e-03,  5.2071e-03,  ..., -1.2695e-02,
          5.8556e-03, -1.0147e-02],
        ...,
        [ 1.5717e-02,  3.9459e-02,  1.7593e-02,  ..., -5.9662e-03,
         -9.7656e-04, -1.9867e-02],
        [ 2.8458e-03, -1.9577e-02,  2.1935e-05,  ...,  8.4305e-03,
          6.7234e-04,  1.4801e-02],
        [-6.9160e-03,  1.3153e-02, -5.4588e-03,  ...,  1.8570e-02,
          1.3809e-02,  1.8677e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.2930,  0.5483,  2.7461,  ...,  0.3000, -1.6670, -1.7119]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 17:20:59 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of intended is unintended
The opposite of satisfactory is unsatisfactory
The opposite of usual is unusual
The opposite of conscious is unconscious
The opposite of lucky is unlucky
The opposite of happy is unhappy
The opposite of employed is unemployed
The opposite of restricted is
2024-07-30 17:20:59 root INFO     [order_1_approx] starting weight calculation for The opposite of intended is unintended
The opposite of lucky is unlucky
The opposite of restricted is unrestricted
The opposite of happy is unhappy
The opposite of conscious is unconscious
The opposite of employed is unemployed
The opposite of usual is unusual
The opposite of satisfactory is
2024-07-30 17:20:59 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-30 17:21:45 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0360, -0.3062, -0.0973,  ..., -0.1947, -0.2607,  0.4663],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 5.9570, -5.7031,  0.5786,  ..., -1.2773, -1.3350, -2.5273],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0481, -0.0025, -0.0032,  ..., -0.0045, -0.0137,  0.0061],
        [ 0.0030,  0.0202, -0.0029,  ..., -0.0014, -0.0025, -0.0039],
        [ 0.0111, -0.0238,  0.0439,  ...,  0.0114, -0.0132,  0.0033],
        ...,
        [-0.0011, -0.0084, -0.0217,  ...,  0.0222, -0.0112, -0.0174],
        [ 0.0005,  0.0152, -0.0020,  ...,  0.0050,  0.0222, -0.0095],
        [ 0.0141, -0.0005, -0.0250,  ...,  0.0073, -0.0193,  0.0203]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 5.9102, -5.6406,  0.6548,  ..., -1.3115, -1.4277, -2.4336]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 17:21:46 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more intense word for guilty is remorseful
A more intense word for warm is hot
A more intense word for jog is run
A more intense word for hungry is starving
A more intense word for tired is exhausted
A more intense word for sniffles is pneumonia
A more intense word for happy is ecstatic
A more intense word for pain is
2024-07-30 17:21:46 root INFO     [order_1_approx] starting weight calculation for A more intense word for pain is torment
A more intense word for guilty is remorseful
A more intense word for jog is run
A more intense word for warm is hot
A more intense word for happy is ecstatic
A more intense word for tired is exhausted
A more intense word for sniffles is pneumonia
A more intense word for hungry is
2024-07-30 17:21:47 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 17:23:32 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0167,  0.1379, -0.3188,  ..., -0.0605, -0.2688, -0.0254],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.5957, -2.5840,  2.7656,  ..., -2.0957, -1.8984, -1.3672],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0475, -0.0067, -0.0062,  ...,  0.0100, -0.0017, -0.0022],
        [-0.0142,  0.0242, -0.0091,  ...,  0.0135,  0.0122, -0.0166],
        [ 0.0056, -0.0045,  0.0017,  ..., -0.0074,  0.0049,  0.0086],
        ...,
        [ 0.0084,  0.0317, -0.0079,  ...,  0.0120, -0.0015, -0.0198],
        [-0.0396,  0.0206,  0.0260,  ...,  0.0105,  0.0343,  0.0113],
        [-0.0427,  0.0196, -0.0122,  ...,  0.0050, -0.0390,  0.0075]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.2969, -3.0000,  3.1875,  ..., -2.0957, -1.9102, -1.1025]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 17:23:33 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of intended is unintended
The opposite of lucky is unlucky
The opposite of restricted is unrestricted
The opposite of happy is unhappy
The opposite of conscious is unconscious
The opposite of employed is unemployed
The opposite of usual is unusual
The opposite of satisfactory is
2024-07-30 17:23:33 root INFO     [order_1_approx] starting weight calculation for The opposite of employed is unemployed
The opposite of lucky is unlucky
The opposite of usual is unusual
The opposite of satisfactory is unsatisfactory
The opposite of happy is unhappy
The opposite of restricted is unrestricted
The opposite of intended is unintended
The opposite of conscious is
2024-07-30 17:23:33 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-30 17:24:19 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1038, -0.4180, -0.0399,  ..., -0.1738, -0.3708,  0.6021],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 5.3906, -4.6289,  2.6641,  ...,  0.0615, -2.7969, -0.3047],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0351,  0.0061,  0.0091,  ..., -0.0003,  0.0074,  0.0101],
        [ 0.0065,  0.0427, -0.0102,  ...,  0.0004,  0.0033, -0.0039],
        [ 0.0152, -0.0013,  0.0391,  ...,  0.0250, -0.0016, -0.0094],
        ...,
        [ 0.0023,  0.0034,  0.0073,  ...,  0.0487, -0.0094, -0.0307],
        [ 0.0074,  0.0019, -0.0009,  ..., -0.0016,  0.0359, -0.0048],
        [ 0.0067, -0.0122, -0.0042,  ...,  0.0028, -0.0051,  0.0191]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 5.2617, -4.3594,  2.5469,  ..., -0.1671, -2.7656, -0.3274]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 17:24:19 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more intense word for pain is torment
A more intense word for guilty is remorseful
A more intense word for jog is run
A more intense word for warm is hot
A more intense word for happy is ecstatic
A more intense word for tired is exhausted
A more intense word for sniffles is pneumonia
A more intense word for hungry is
2024-07-30 17:24:19 root INFO     total operator prediction time: 1215.864547252655 seconds
2024-07-30 17:24:19 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on meronyms - substance
2024-07-30 17:24:19 root INFO     building operator meronyms - substance
2024-07-30 17:24:20 root INFO     [order_1_approx] starting weight calculation for A jeans is made up of fabric
A doorknob is made up of metal
A beach is made up of sand
A boots is made up of leather
A table is made up of wood
A candy is made up of sugar
A yogurt is made up of milk
A steel is made up of
2024-07-30 17:24:20 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 17:26:11 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2106,  0.1007, -0.1757,  ..., -0.2065, -0.4546,  0.1926],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.0586, -0.6245,  4.5000,  ..., -2.1523,  2.0137, -1.5742],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0430, -0.0008, -0.0075,  ...,  0.0320, -0.0395, -0.0232],
        [-0.0204,  0.0209, -0.0085,  ..., -0.0161,  0.0217, -0.0054],
        [-0.0278, -0.0648,  0.0739,  ...,  0.0056, -0.0366, -0.0256],
        ...,
        [ 0.0246,  0.0377,  0.0233,  ...,  0.0037, -0.0026, -0.0117],
        [-0.0044, -0.0120, -0.0038,  ..., -0.0433,  0.0367, -0.0247],
        [ 0.0265, -0.0045, -0.0343,  ...,  0.0224, -0.0166,  0.0235]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.9531, -0.3892,  4.2188,  ..., -1.8789,  1.3350, -1.6455]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 17:26:12 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of employed is unemployed
The opposite of lucky is unlucky
The opposite of usual is unusual
The opposite of satisfactory is unsatisfactory
The opposite of happy is unhappy
The opposite of restricted is unrestricted
The opposite of intended is unintended
The opposite of conscious is
2024-07-30 17:26:12 root INFO     [order_1_approx] starting weight calculation for The opposite of intended is unintended
The opposite of satisfactory is unsatisfactory
The opposite of employed is unemployed
The opposite of restricted is unrestricted
The opposite of usual is unusual
The opposite of conscious is unconscious
The opposite of lucky is unlucky
The opposite of happy is
2024-07-30 17:26:12 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-30 17:26:53 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2671, -0.1196, -0.4243,  ..., -0.0841, -0.0421,  0.1562],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.5625, -6.0469, -0.2300,  ..., -3.4492, -1.0879, -1.1914],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 1.8738e-02, -2.7863e-02, -5.4626e-03,  ..., -1.8417e-02,
         -6.9237e-03, -2.8198e-02],
        [-2.1927e-02,  4.3121e-02,  1.4572e-02,  ..., -2.6703e-04,
          1.4572e-02, -7.3204e-03],
        [ 2.2400e-02,  2.5543e-02,  3.2715e-02,  ...,  2.1057e-02,
          7.5912e-03, -8.5297e-03],
        ...,
        [ 4.1656e-03, -4.2175e-02,  1.9440e-02,  ...,  8.0566e-03,
         -7.0572e-05, -1.5839e-02],
        [-1.5419e-02,  1.7044e-02, -1.2863e-02,  ...,  1.8219e-02,
          1.4305e-02,  1.0399e-02],
        [ 2.1667e-03, -1.8814e-02, -3.4027e-02,  ..., -4.6783e-02,
          3.8300e-03,  3.2837e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.5000, -6.0664, -0.5210,  ..., -2.6855, -1.3311, -1.3066]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 17:26:54 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A jeans is made up of fabric
A doorknob is made up of metal
A beach is made up of sand
A boots is made up of leather
A table is made up of wood
A candy is made up of sugar
A yogurt is made up of milk
A steel is made up of
2024-07-30 17:26:54 root INFO     [order_1_approx] starting weight calculation for A doorknob is made up of metal
A steel is made up of iron
A table is made up of wood
A boots is made up of leather
A yogurt is made up of milk
A beach is made up of sand
A jeans is made up of fabric
A candy is made up of
2024-07-30 17:26:54 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 17:28:52 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0739,  0.1137,  0.0348,  ..., -0.2202, -0.2720,  0.2087],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.1348, -1.4609,  1.1768,  ..., -2.9453, -1.7676, -1.8076],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0519,  0.0106,  0.0167,  ..., -0.0074, -0.0348,  0.0079],
        [-0.0141,  0.0482,  0.0079,  ...,  0.0088,  0.0127, -0.0057],
        [ 0.0018, -0.0197,  0.0388,  ...,  0.0216, -0.0294, -0.0044],
        ...,
        [ 0.0020, -0.0047,  0.0080,  ...,  0.0391, -0.0086, -0.0062],
        [-0.0085,  0.0027, -0.0164,  ...,  0.0134,  0.0469, -0.0021],
        [ 0.0022, -0.0284, -0.0171,  ...,  0.0251,  0.0069,  0.0403]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.9512, -1.8223,  0.8354,  ..., -2.7812, -1.6934, -2.0977]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 17:28:53 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of intended is unintended
The opposite of satisfactory is unsatisfactory
The opposite of employed is unemployed
The opposite of restricted is unrestricted
The opposite of usual is unusual
The opposite of conscious is unconscious
The opposite of lucky is unlucky
The opposite of happy is
2024-07-30 17:28:53 root INFO     [order_1_approx] starting weight calculation for The opposite of employed is unemployed
The opposite of restricted is unrestricted
The opposite of usual is unusual
The opposite of happy is unhappy
The opposite of conscious is unconscious
The opposite of lucky is unlucky
The opposite of satisfactory is unsatisfactory
The opposite of intended is
2024-07-30 17:28:53 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-30 17:29:24 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.3152,  0.2144, -0.3464,  ..., -0.1558, -0.2769, -0.1533],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.4971, -6.2031, -0.8535,  ..., -2.6582, -1.6250,  4.9805],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0314, -0.0053,  0.0118,  ...,  0.0071, -0.0320,  0.0046],
        [-0.0160,  0.0454,  0.0095,  ..., -0.0086,  0.0368, -0.0194],
        [-0.0034,  0.0176,  0.0299,  ...,  0.0034, -0.0149, -0.0065],
        ...,
        [-0.0016, -0.0148,  0.0180,  ...,  0.0339, -0.0013,  0.0053],
        [-0.0146,  0.0230,  0.0040,  ...,  0.0224,  0.0230, -0.0176],
        [ 0.0081,  0.0011, -0.0020,  ..., -0.0092,  0.0209,  0.0410]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.3086, -6.2656, -1.0479,  ..., -2.7305, -2.7656,  5.5820]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 17:29:25 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A doorknob is made up of metal
A steel is made up of iron
A table is made up of wood
A boots is made up of leather
A yogurt is made up of milk
A beach is made up of sand
A jeans is made up of fabric
A candy is made up of
2024-07-30 17:29:25 root INFO     [order_1_approx] starting weight calculation for A steel is made up of iron
A beach is made up of sand
A table is made up of wood
A boots is made up of leather
A candy is made up of sugar
A jeans is made up of fabric
A doorknob is made up of metal
A yogurt is made up of
2024-07-30 17:29:25 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 17:31:31 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1707,  0.3589, -0.2700,  ..., -0.1868,  0.0131,  0.0601],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.5410, -0.8213,  0.1719,  ...,  0.8696, -0.3828, -4.6250],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0300,  0.0123, -0.0037,  ...,  0.0153, -0.0238, -0.0023],
        [-0.0300,  0.0458,  0.0025,  ...,  0.0101,  0.0326, -0.0137],
        [-0.0116, -0.0013,  0.0416,  ...,  0.0016,  0.0076, -0.0099],
        ...,
        [-0.0215,  0.0171,  0.0230,  ...,  0.0198, -0.0010, -0.0065],
        [-0.0134,  0.0105,  0.0084,  ...,  0.0048,  0.0593, -0.0265],
        [ 0.0001,  0.0216,  0.0090,  ...,  0.0111,  0.0083,  0.0205]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.8535, -0.7148,  0.3003,  ...,  0.3752,  0.1743, -5.0195]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 17:31:32 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of employed is unemployed
The opposite of restricted is unrestricted
The opposite of usual is unusual
The opposite of happy is unhappy
The opposite of conscious is unconscious
The opposite of lucky is unlucky
The opposite of satisfactory is unsatisfactory
The opposite of intended is
2024-07-30 17:31:32 root INFO     [order_1_approx] starting weight calculation for The opposite of usual is unusual
The opposite of happy is unhappy
The opposite of restricted is unrestricted
The opposite of employed is unemployed
The opposite of satisfactory is unsatisfactory
The opposite of conscious is unconscious
The opposite of intended is unintended
The opposite of lucky is
2024-07-30 17:31:32 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-30 17:31:56 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.4648, -0.2310, -0.1178,  ...,  0.0832, -0.3674, -0.1306],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.0469, -4.6719,  1.5215,  ..., -4.2070, -1.5635,  0.0986],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0118, -0.0044, -0.0187,  ...,  0.0045, -0.0104,  0.0151],
        [-0.0045,  0.0421,  0.0023,  ...,  0.0060,  0.0232, -0.0072],
        [-0.0110,  0.0169, -0.0050,  ...,  0.0069, -0.0126,  0.0347],
        ...,
        [ 0.0084,  0.0044,  0.0140,  ...,  0.0390,  0.0064, -0.0199],
        [-0.0415,  0.0144, -0.0096,  ...,  0.0228,  0.0116,  0.0338],
        [ 0.0175, -0.0045,  0.0110,  ..., -0.0135,  0.0139,  0.0254]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.7793, -5.3984,  1.4541,  ..., -4.0664, -1.7881,  0.3452]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 17:31:57 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A steel is made up of iron
A beach is made up of sand
A table is made up of wood
A boots is made up of leather
A candy is made up of sugar
A jeans is made up of fabric
A doorknob is made up of metal
A yogurt is made up of
2024-07-30 17:31:57 root INFO     [order_1_approx] starting weight calculation for A doorknob is made up of metal
A candy is made up of sugar
A boots is made up of leather
A steel is made up of iron
A beach is made up of sand
A jeans is made up of fabric
A yogurt is made up of milk
A table is made up of
2024-07-30 17:31:57 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 17:34:09 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0651,  0.2073,  0.1672,  ..., -0.2462, -0.1859, -0.0072],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.5928, -0.4668, -1.2197,  ..., -2.3535,  0.5029, -2.1387],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0567, -0.0532, -0.0198,  ...,  0.0155, -0.0515,  0.0241],
        [-0.0116,  0.0125,  0.0039,  ...,  0.0157,  0.0019,  0.0228],
        [ 0.0081, -0.0409,  0.0233,  ...,  0.0487, -0.0222, -0.0047],
        ...,
        [ 0.0136,  0.0268,  0.0195,  ...,  0.0092,  0.0093, -0.0247],
        [ 0.0091,  0.0489,  0.0180,  ...,  0.0077,  0.0302, -0.0237],
        [ 0.0104,  0.0133, -0.0233,  ...,  0.0313,  0.0469,  0.0055]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.2266, -0.5659, -0.6035,  ..., -2.7266, -0.1069, -2.3281]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 17:34:10 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of usual is unusual
The opposite of happy is unhappy
The opposite of restricted is unrestricted
The opposite of employed is unemployed
The opposite of satisfactory is unsatisfactory
The opposite of conscious is unconscious
The opposite of intended is unintended
The opposite of lucky is
2024-07-30 17:34:10 root INFO     [order_1_approx] starting weight calculation for The opposite of conscious is unconscious
The opposite of lucky is unlucky
The opposite of employed is unemployed
The opposite of satisfactory is unsatisfactory
The opposite of restricted is unrestricted
The opposite of happy is unhappy
The opposite of intended is unintended
The opposite of usual is
2024-07-30 17:34:10 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-30 17:34:29 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0175, -0.1788, -0.4397,  ..., -0.0085, -0.3079, -0.1935],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.3828, -6.1328,  2.4414,  ..., -5.5938,  1.0723, -1.6973],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0398, -0.0133,  0.0019,  ..., -0.0041, -0.0037, -0.0247],
        [-0.0290,  0.0439,  0.0112,  ..., -0.0033, -0.0121,  0.0117],
        [ 0.0083,  0.0214,  0.0240,  ..., -0.0035, -0.0132,  0.0002],
        ...,
        [-0.0202, -0.0163,  0.0383,  ...,  0.0352, -0.0168,  0.0205],
        [ 0.0009,  0.0152, -0.0147,  ...,  0.0014,  0.0379, -0.0083],
        [-0.0204, -0.0067, -0.0017,  ..., -0.0004,  0.0137,  0.0217]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.4414, -6.4336,  1.9121,  ..., -5.7617,  0.7842, -1.5781]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 17:34:40 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A doorknob is made up of metal
A candy is made up of sugar
A boots is made up of leather
A steel is made up of iron
A beach is made up of sand
A jeans is made up of fabric
A yogurt is made up of milk
A table is made up of
2024-07-30 17:34:40 root INFO     [order_1_approx] starting weight calculation for A yogurt is made up of milk
A beach is made up of sand
A table is made up of wood
A jeans is made up of fabric
A boots is made up of leather
A candy is made up of sugar
A steel is made up of iron
A doorknob is made up of
2024-07-30 17:34:40 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 17:36:47 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0649, -0.0296,  0.1932,  ..., -0.2952, -0.4089, -0.1036],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.3174, -1.3330,  1.7598,  ..., -1.9209, -1.4727, -2.1758],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0572, -0.0017, -0.0233,  ...,  0.0244, -0.0148,  0.0362],
        [-0.0345,  0.0723, -0.0031,  ...,  0.0016,  0.0019, -0.0100],
        [-0.0087, -0.0096,  0.0507,  ...,  0.0076, -0.0067, -0.0090],
        ...,
        [ 0.0254,  0.0129,  0.0152,  ...,  0.0506,  0.0162, -0.0047],
        [ 0.0205,  0.0213, -0.0088,  ...,  0.0155,  0.0246,  0.0014],
        [ 0.0046,  0.0017, -0.0240,  ...,  0.0208, -0.0042,  0.0244]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.4766, -1.1992,  1.7070,  ..., -1.3945, -1.5840, -1.9932]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 17:36:48 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of conscious is unconscious
The opposite of lucky is unlucky
The opposite of employed is unemployed
The opposite of satisfactory is unsatisfactory
The opposite of restricted is unrestricted
The opposite of happy is unhappy
The opposite of intended is unintended
The opposite of usual is
2024-07-30 17:36:48 root INFO     [order_1_approx] starting weight calculation for The opposite of restricted is unrestricted
The opposite of usual is unusual
The opposite of lucky is unlucky
The opposite of conscious is unconscious
The opposite of happy is unhappy
The opposite of satisfactory is unsatisfactory
The opposite of intended is unintended
The opposite of employed is
2024-07-30 17:36:48 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-30 17:37:14 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0206, -0.1525, -0.1901,  ...,  0.4075, -0.3091, -0.1116],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.7305, -4.2031, -2.2422,  ..., -2.3652,  0.4607, -1.3320],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 3.5645e-02, -2.0309e-02, -5.9013e-03,  ...,  1.2886e-02,
         -3.2921e-03, -2.4796e-03],
        [-1.9150e-02,  2.9907e-02,  1.2199e-02,  ..., -3.3455e-03,
         -3.9520e-03,  1.2341e-03],
        [ 9.0332e-03, -3.3722e-03,  4.5074e-02,  ..., -2.1629e-03,
          1.1120e-03, -5.5170e-04],
        ...,
        [ 2.7725e-02, -6.3896e-05,  7.8201e-03,  ...,  4.9713e-02,
         -1.2741e-02, -6.7425e-04],
        [ 5.9891e-04,  2.0645e-02, -2.1286e-02,  ...,  1.0834e-02,
          2.1194e-02, -9.6207e-03],
        [-2.4376e-03, -2.8229e-04,  2.2476e-02,  ...,  6.1111e-03,
         -1.8959e-03,  2.0126e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.3750, -3.8516, -2.1953,  ..., -2.5742,  0.1665, -0.9814]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 17:37:15 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A yogurt is made up of milk
A beach is made up of sand
A table is made up of wood
A jeans is made up of fabric
A boots is made up of leather
A candy is made up of sugar
A steel is made up of iron
A doorknob is made up of
2024-07-30 17:37:15 root INFO     [order_1_approx] starting weight calculation for A candy is made up of sugar
A doorknob is made up of metal
A boots is made up of leather
A table is made up of wood
A yogurt is made up of milk
A beach is made up of sand
A steel is made up of iron
A jeans is made up of
2024-07-30 17:37:15 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 17:39:27 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1926,  0.0911, -0.1130,  ...,  0.0215, -0.4102, -0.0421],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.3418, -1.0049, -0.1172,  ..., -0.5259,  1.0254, -2.3418],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0620, -0.0169,  0.0318,  ...,  0.0229, -0.0366,  0.0021],
        [-0.0432,  0.0336,  0.0106,  ..., -0.0004,  0.0572,  0.0115],
        [ 0.0190,  0.0034,  0.0464,  ..., -0.0174,  0.0039,  0.0122],
        ...,
        [ 0.0229,  0.0241, -0.0008,  ...,  0.0159, -0.0003, -0.0074],
        [-0.0184,  0.0143,  0.0071,  ...,  0.0060,  0.0459, -0.0023],
        [-0.0011,  0.0051,  0.0002,  ...,  0.0079,  0.0033,  0.0100]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.0957, -1.2354, -0.1090,  ..., -0.1443,  1.0693, -2.3965]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 17:39:28 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of restricted is unrestricted
The opposite of usual is unusual
The opposite of lucky is unlucky
The opposite of conscious is unconscious
The opposite of happy is unhappy
The opposite of satisfactory is unsatisfactory
The opposite of intended is unintended
The opposite of employed is
2024-07-30 17:39:28 root INFO     total operator prediction time: 1269.7116980552673 seconds
2024-07-30 17:39:28 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on verb+able_reg
2024-07-30 17:39:28 root INFO     building operator verb+able_reg
2024-07-30 17:39:29 root INFO     [order_1_approx] starting weight calculation for If you can deliver something, that thing is deliverable
If you can predict something, that thing is predictable
If you can sustain something, that thing is sustainable
If you can define something, that thing is definable
If you can foresee something, that thing is foreseeable
If you can achieve something, that thing is achieveable
If you can advise something, that thing is advisable
If you can renew something, that thing is
2024-07-30 17:39:29 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-30 17:39:47 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2532,  0.0129, -0.2474,  ...,  0.3967, -0.6763, -0.0569],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 5.1328, -8.0781,  0.1736,  ..., -0.5635, -2.4219,  1.5400],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0229, -0.0025, -0.0009,  ..., -0.0108,  0.0013, -0.0079],
        [ 0.0115,  0.0308, -0.0061,  ...,  0.0078,  0.0176, -0.0264],
        [ 0.0002,  0.0003,  0.0444,  ...,  0.0096, -0.0066, -0.0102],
        ...,
        [ 0.0182,  0.0015,  0.0222,  ...,  0.0190,  0.0030, -0.0184],
        [-0.0049,  0.0053, -0.0041,  ...,  0.0077,  0.0121,  0.0010],
        [ 0.0140, -0.0173, -0.0083,  ..., -0.0201,  0.0243,  0.0255]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.8047, -8.3750, -0.1592,  ..., -0.4773, -2.5840,  1.7021]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 17:39:48 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A candy is made up of sugar
A doorknob is made up of metal
A boots is made up of leather
A table is made up of wood
A yogurt is made up of milk
A beach is made up of sand
A steel is made up of iron
A jeans is made up of
2024-07-30 17:39:49 root INFO     [order_1_approx] starting weight calculation for A beach is made up of sand
A table is made up of wood
A doorknob is made up of metal
A steel is made up of iron
A jeans is made up of fabric
A candy is made up of sugar
A yogurt is made up of milk
A boots is made up of
2024-07-30 17:39:49 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 17:42:12 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2189,  0.2925, -0.0674,  ..., -0.1603, -0.1222,  0.0936],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-3.1094, -1.7539, -0.3484,  ..., -3.6758, -6.0625, -3.0566],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 2.6855e-02, -1.1253e-02,  3.3142e-02,  ...,  1.6037e-02,
          3.0319e-02, -2.9469e-03],
        [-4.0436e-04,  3.5461e-02, -1.0490e-02,  ...,  1.6403e-02,
         -2.2850e-03,  1.1452e-02],
        [ 2.4246e-02, -1.1078e-02,  3.3875e-02,  ..., -1.1765e-02,
         -1.0262e-02, -2.4292e-02],
        ...,
        [ 2.0111e-02, -1.7532e-02,  1.8021e-02,  ...,  3.6316e-02,
         -3.4668e-02, -6.8188e-05],
        [-1.7118e-03,  5.8594e-03,  2.3758e-02,  ...,  2.3708e-03,
          8.2169e-03,  4.3678e-03],
        [ 4.4365e-03,  3.1952e-02,  3.0640e-02,  ..., -1.6846e-02,
         -5.1025e-02, -9.8419e-04]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-2.6191, -2.2168, -0.3193,  ..., -3.6758, -6.3203, -3.6016]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 17:42:13 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you can deliver something, that thing is deliverable
If you can predict something, that thing is predictable
If you can sustain something, that thing is sustainable
If you can define something, that thing is definable
If you can foresee something, that thing is foreseeable
If you can achieve something, that thing is achieveable
If you can advise something, that thing is advisable
If you can renew something, that thing is
2024-07-30 17:42:13 root INFO     [order_1_approx] starting weight calculation for If you can predict something, that thing is predictable
If you can sustain something, that thing is sustainable
If you can renew something, that thing is renewable
If you can achieve something, that thing is achieveable
If you can define something, that thing is definable
If you can advise something, that thing is advisable
If you can foresee something, that thing is foreseeable
If you can deliver something, that thing is
2024-07-30 17:42:13 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-30 17:42:21 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1120, -0.2294,  0.1995,  ...,  0.2424, -0.3193, -0.2032],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.3047, -6.9062,  2.0078,  ...,  0.9111, -1.2012,  2.9258],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0386, -0.0028,  0.0146,  ..., -0.0013, -0.0191, -0.0019],
        [-0.0145,  0.0462, -0.0008,  ...,  0.0207, -0.0199, -0.0255],
        [-0.0046,  0.0155,  0.0263,  ...,  0.0068, -0.0194, -0.0137],
        ...,
        [-0.0044,  0.0029,  0.0067,  ...,  0.0387, -0.0027,  0.0016],
        [-0.0231, -0.0009, -0.0264,  ...,  0.0088,  0.0364, -0.0174],
        [-0.0068, -0.0268,  0.0271,  ...,  0.0005, -0.0086,  0.0515]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.3164, -7.0625,  1.4375,  ...,  0.4885, -1.6787,  3.4766]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 17:42:22 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A beach is made up of sand
A table is made up of wood
A doorknob is made up of metal
A steel is made up of iron
A jeans is made up of fabric
A candy is made up of sugar
A yogurt is made up of milk
A boots is made up of
2024-07-30 17:42:22 root INFO     [order_1_approx] starting weight calculation for A yogurt is made up of milk
A steel is made up of iron
A doorknob is made up of metal
A jeans is made up of fabric
A table is made up of wood
A boots is made up of leather
A candy is made up of sugar
A beach is made up of
2024-07-30 17:42:23 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 17:44:46 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0218,  0.4829,  0.1256,  ...,  0.2386, -0.1578, -0.0614],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.2422, -1.2061, -0.8545,  ..., -3.3203, -8.1172, -3.1016],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0331, -0.0029,  0.0229,  ...,  0.0117, -0.0066,  0.0101],
        [-0.0100,  0.0356, -0.0149,  ...,  0.0124, -0.0079, -0.0038],
        [ 0.0042, -0.0076,  0.0380,  ..., -0.0214,  0.0018, -0.0305],
        ...,
        [ 0.0201,  0.0090, -0.0065,  ...,  0.0305,  0.0028, -0.0027],
        [ 0.0058, -0.0079, -0.0138,  ..., -0.0413,  0.0034, -0.0280],
        [ 0.0227, -0.0028, -0.0080,  ..., -0.0013, -0.0009,  0.0211]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.2598, -1.0293, -0.8330,  ..., -3.2031, -8.2344, -2.8164]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 17:44:47 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you can predict something, that thing is predictable
If you can sustain something, that thing is sustainable
If you can renew something, that thing is renewable
If you can achieve something, that thing is achieveable
If you can define something, that thing is definable
If you can advise something, that thing is advisable
If you can foresee something, that thing is foreseeable
If you can deliver something, that thing is
2024-07-30 17:44:47 root INFO     [order_1_approx] starting weight calculation for If you can advise something, that thing is advisable
If you can sustain something, that thing is sustainable
If you can predict something, that thing is predictable
If you can foresee something, that thing is foreseeable
If you can achieve something, that thing is achieveable
If you can renew something, that thing is renewable
If you can deliver something, that thing is deliverable
If you can define something, that thing is
2024-07-30 17:44:47 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-30 17:44:51 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1159,  0.2192, -0.1996,  ..., -0.1965, -0.5298,  0.1215],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.6797, -2.8887, -0.9219,  ..., -2.2461,  3.0078, -1.8564],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 3.1235e-02,  4.0283e-03, -1.6060e-03,  ...,  1.4664e-02,
          1.0193e-02, -1.5884e-02],
        [-1.4565e-02,  3.4027e-02, -1.1139e-02,  ..., -4.6005e-03,
          5.6992e-03, -2.0065e-02],
        [-8.6670e-03,  1.1749e-02,  2.1530e-02,  ...,  7.4768e-03,
         -3.0518e-05,  8.5602e-03],
        ...,
        [ 4.4479e-03,  2.0218e-04,  1.5839e-02,  ...,  2.6581e-02,
          3.4294e-03, -1.7118e-03],
        [-3.1372e-02,  2.4628e-02, -8.0872e-04,  ...,  6.2180e-03,
          1.4931e-02,  1.0208e-02],
        [ 3.9253e-03, -1.3260e-02, -4.3945e-03,  ..., -1.3031e-02,
         -1.0445e-02,  4.5593e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.5449, -2.8574, -1.1914,  ..., -2.2930,  2.0234, -1.2207]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 17:44:52 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A yogurt is made up of milk
A steel is made up of iron
A doorknob is made up of metal
A jeans is made up of fabric
A table is made up of wood
A boots is made up of leather
A candy is made up of sugar
A beach is made up of
2024-07-30 17:44:52 root INFO     total operator prediction time: 1232.82417345047 seconds
2024-07-30 17:44:52 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on hypernyms - misc
2024-07-30 17:44:52 root INFO     building operator hypernyms - misc
2024-07-30 17:44:53 root INFO     [order_1_approx] starting weight calculation for The vase falls into the category of jar
The skirt falls into the category of clothes
The notebook falls into the category of book
The toaster falls into the category of appliance
The hairpin falls into the category of pin
The lemon falls into the category of citrus
The grapefruit falls into the category of citrus
The shelf falls into the category of
2024-07-30 17:44:53 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 17:47:24 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0571,  0.0776,  0.2341,  ...,  0.2297, -0.1074, -0.1689],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.0332, -1.3135,  3.1621,  ..., -2.3672, -7.1094, -2.5801],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0284, -0.0006,  0.0166,  ...,  0.0166, -0.0249,  0.0143],
        [-0.0227,  0.0373,  0.0336,  ..., -0.0191,  0.0059, -0.0198],
        [-0.0092, -0.0050,  0.0282,  ...,  0.0003,  0.0332,  0.0059],
        ...,
        [ 0.0073,  0.0342,  0.0148,  ...,  0.0419,  0.0092, -0.0083],
        [ 0.0211,  0.0076,  0.0063,  ..., -0.0076,  0.0136,  0.0159],
        [-0.0085,  0.0118,  0.0223,  ..., -0.0169, -0.0035, -0.0016]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.6089, -1.3965,  3.4102,  ..., -2.5801, -7.0508, -2.1211]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 17:47:25 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0057, -0.0798, -0.4385,  ...,  0.1324, -0.3855,  0.1066],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.0117, -3.0020,  3.8652,  ..., -0.5537, -4.7578,  1.0010],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0746, -0.0023, -0.0022,  ..., -0.0093, -0.0093, -0.0112],
        [-0.0015,  0.0401,  0.0110,  ...,  0.0310,  0.0004,  0.0140],
        [-0.0145,  0.0215,  0.0512,  ..., -0.0061, -0.0242,  0.0099],
        ...,
        [-0.0097,  0.0333,  0.0340,  ...,  0.0397, -0.0008, -0.0099],
        [ 0.0161, -0.0032, -0.0089,  ...,  0.0085,  0.0507,  0.0027],
        [-0.0020,  0.0084,  0.0176,  ...,  0.0012, -0.0080,  0.0297]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.8115, -3.0879,  3.6973,  ..., -0.8120, -4.4453,  0.9307]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 17:47:25 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you can advise something, that thing is advisable
If you can sustain something, that thing is sustainable
If you can predict something, that thing is predictable
If you can foresee something, that thing is foreseeable
If you can achieve something, that thing is achieveable
If you can renew something, that thing is renewable
If you can deliver something, that thing is deliverable
If you can define something, that thing is
2024-07-30 17:47:25 root INFO     [order_1_approx] starting weight calculation for If you can advise something, that thing is advisable
If you can renew something, that thing is renewable
If you can define something, that thing is definable
If you can deliver something, that thing is deliverable
If you can sustain something, that thing is sustainable
If you can foresee something, that thing is foreseeable
If you can predict something, that thing is predictable
If you can achieve something, that thing is
2024-07-30 17:47:25 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-30 17:47:26 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The vase falls into the category of jar
The skirt falls into the category of clothes
The notebook falls into the category of book
The toaster falls into the category of appliance
The hairpin falls into the category of pin
The lemon falls into the category of citrus
The grapefruit falls into the category of citrus
The shelf falls into the category of
2024-07-30 17:47:26 root INFO     [order_1_approx] starting weight calculation for The grapefruit falls into the category of citrus
The notebook falls into the category of book
The hairpin falls into the category of pin
The skirt falls into the category of clothes
The toaster falls into the category of appliance
The shelf falls into the category of furniture
The lemon falls into the category of citrus
The vase falls into the category of
2024-07-30 17:47:26 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 17:49:55 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0006, -0.2129, -0.0868,  ...,  0.2029, -0.1450, -0.2966],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.5586, -2.6465,  0.2476,  ..., -3.8086, -3.6680,  1.0527],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0677,  0.0132, -0.0117,  ..., -0.0069, -0.0145,  0.0094],
        [-0.0084,  0.0609,  0.0196,  ...,  0.0263, -0.0309,  0.0070],
        [ 0.0042, -0.0033,  0.0349,  ..., -0.0304, -0.0150,  0.0007],
        ...,
        [-0.0168, -0.0028,  0.0023,  ...,  0.0384,  0.0103, -0.0166],
        [ 0.0005,  0.0094, -0.0088,  ..., -0.0167,  0.0456, -0.0064],
        [-0.0181,  0.0048,  0.0152,  ..., -0.0200, -0.0035,  0.0414]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.4551, -2.6133, -0.0552,  ..., -3.7129, -3.2539,  0.5762]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 17:49:57 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The grapefruit falls into the category of citrus
The notebook falls into the category of book
The hairpin falls into the category of pin
The skirt falls into the category of clothes
The toaster falls into the category of appliance
The shelf falls into the category of furniture
The lemon falls into the category of citrus
The vase falls into the category of
2024-07-30 17:49:57 root INFO     [order_1_approx] starting weight calculation for The grapefruit falls into the category of citrus
The lemon falls into the category of citrus
The vase falls into the category of jar
The shelf falls into the category of furniture
The notebook falls into the category of book
The hairpin falls into the category of pin
The toaster falls into the category of appliance
The skirt falls into the category of
2024-07-30 17:49:57 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 17:49:58 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0750,  0.4861,  0.1975,  ..., -0.0522, -0.3274,  0.0834],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.3203, -0.5874, -1.7568,  ..., -4.7930, -8.3594, -3.4883],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0184,  0.0022,  0.0195,  ...,  0.0236,  0.0140,  0.0157],
        [-0.0151,  0.0156,  0.0053,  ...,  0.0002, -0.0130, -0.0204],
        [ 0.0166, -0.0192,  0.0224,  ..., -0.0140, -0.0067,  0.0017],
        ...,
        [ 0.0081,  0.0245, -0.0011,  ...,  0.0177,  0.0223, -0.0178],
        [ 0.0187,  0.0311,  0.0095,  ..., -0.0264,  0.0100,  0.0140],
        [ 0.0158,  0.0093, -0.0059,  ..., -0.0055, -0.0091, -0.0021]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.2219, -0.6675, -2.0605,  ..., -4.4375, -8.4844, -3.3125]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 17:49:59 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you can advise something, that thing is advisable
If you can renew something, that thing is renewable
If you can define something, that thing is definable
If you can deliver something, that thing is deliverable
If you can sustain something, that thing is sustainable
If you can foresee something, that thing is foreseeable
If you can predict something, that thing is predictable
If you can achieve something, that thing is
2024-07-30 17:49:59 root INFO     [order_1_approx] starting weight calculation for If you can deliver something, that thing is deliverable
If you can advise something, that thing is advisable
If you can achieve something, that thing is achieveable
If you can define something, that thing is definable
If you can predict something, that thing is predictable
If you can sustain something, that thing is sustainable
If you can renew something, that thing is renewable
If you can foresee something, that thing is
2024-07-30 17:49:59 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-30 17:52:28 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0151, -0.4045, -0.3301,  ...,  0.4089, -0.3135,  0.2090],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.7227, -6.6406, -0.8154,  ...,  0.5483, -3.0977,  0.3564],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 4.5349e-02, -8.7585e-03, -3.0708e-03,  ...,  4.7264e-03,
          1.2054e-02,  6.7291e-03],
        [ 2.0542e-03,  1.0483e-02,  3.6125e-03,  ..., -9.1553e-05,
         -3.1891e-03,  5.6114e-03],
        [ 7.2327e-03,  1.2527e-02,  1.6708e-02,  ...,  2.9945e-03,
         -7.7438e-03, -1.0559e-02],
        ...,
        [ 1.0872e-03,  1.9121e-04,  1.7120e-02,  ...,  3.6926e-02,
          8.8654e-03, -1.4687e-02],
        [ 2.4109e-03, -3.2711e-03, -6.4240e-03,  ...,  2.5360e-02,
          3.3783e-02, -1.0605e-02],
        [-5.0011e-03, -1.8005e-02,  1.8448e-02,  ..., -4.6234e-03,
         -1.3626e-02,  3.5065e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.2490, -5.9766, -1.3652,  ...,  0.4370, -3.2441,  0.5195]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 17:52:29 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The grapefruit falls into the category of citrus
The lemon falls into the category of citrus
The vase falls into the category of jar
The shelf falls into the category of furniture
The notebook falls into the category of book
The hairpin falls into the category of pin
The toaster falls into the category of appliance
The skirt falls into the category of
2024-07-30 17:52:29 root INFO     [order_1_approx] starting weight calculation for The hairpin falls into the category of pin
The grapefruit falls into the category of citrus
The toaster falls into the category of appliance
The shelf falls into the category of furniture
The skirt falls into the category of clothes
The vase falls into the category of jar
The notebook falls into the category of book
The lemon falls into the category of
2024-07-30 17:52:30 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 17:52:33 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0562,  0.2690,  0.0809,  ..., -0.2607, -0.0416, -0.2593],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.0664,  0.9497, -0.9141,  ..., -3.5430, -7.1016, -2.1133],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 1.5884e-02,  1.7883e-02,  1.0712e-02,  ..., -1.9287e-02,
          1.8967e-02,  9.6664e-03],
        [-2.9602e-02,  2.5269e-02,  4.5090e-03,  ...,  6.6490e-03,
         -7.3433e-03, -1.3550e-02],
        [ 5.1498e-05, -1.0666e-02,  2.1027e-02,  ...,  1.1475e-02,
         -1.2875e-03, -3.4103e-03],
        ...,
        [ 1.6232e-03,  4.5395e-03, -9.7275e-03,  ...,  2.7283e-02,
         -6.0196e-03,  8.5907e-03],
        [ 1.6251e-02, -2.8000e-03, -7.7438e-04,  ..., -2.3251e-03,
          4.8141e-03, -9.4604e-03],
        [-3.6087e-03, -6.8588e-03, -9.4528e-03,  ...,  8.7433e-03,
         -1.1299e-02,  1.4442e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.0059,  0.9644, -0.9121,  ..., -3.5176, -7.1797, -1.9814]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 17:52:34 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you can deliver something, that thing is deliverable
If you can advise something, that thing is advisable
If you can achieve something, that thing is achieveable
If you can define something, that thing is definable
If you can predict something, that thing is predictable
If you can sustain something, that thing is sustainable
If you can renew something, that thing is renewable
If you can foresee something, that thing is
2024-07-30 17:52:35 root INFO     [order_1_approx] starting weight calculation for If you can deliver something, that thing is deliverable
If you can achieve something, that thing is achieveable
If you can renew something, that thing is renewable
If you can foresee something, that thing is foreseeable
If you can advise something, that thing is advisable
If you can define something, that thing is definable
If you can predict something, that thing is predictable
If you can sustain something, that thing is
2024-07-30 17:52:35 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-30 17:54:58 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.3418, -0.6543, -0.5952,  ..., -0.1638, -0.0500, -0.2993],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.3848, -5.1602, -1.3896,  ..., -5.5195, -2.2871, -2.5332],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0514,  0.0248, -0.0063,  ...,  0.0069,  0.0082,  0.0073],
        [ 0.0258,  0.0283,  0.0117,  ...,  0.0073, -0.0045,  0.0140],
        [-0.0164, -0.0032,  0.0450,  ...,  0.0070, -0.0177, -0.0069],
        ...,
        [-0.0007,  0.0013,  0.0007,  ...,  0.0710, -0.0049, -0.0143],
        [ 0.0096, -0.0086,  0.0143,  ...,  0.0082,  0.0373,  0.0048],
        [-0.0228, -0.0200,  0.0135,  ..., -0.0010, -0.0060,  0.0519]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.1367, -5.0508, -1.4775,  ..., -5.4414, -2.3887, -2.0039]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 17:54:59 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The hairpin falls into the category of pin
The grapefruit falls into the category of citrus
The toaster falls into the category of appliance
The shelf falls into the category of furniture
The skirt falls into the category of clothes
The vase falls into the category of jar
The notebook falls into the category of book
The lemon falls into the category of
2024-07-30 17:54:59 root INFO     [order_1_approx] starting weight calculation for The notebook falls into the category of book
The lemon falls into the category of citrus
The skirt falls into the category of clothes
The toaster falls into the category of appliance
The shelf falls into the category of furniture
The vase falls into the category of jar
The grapefruit falls into the category of citrus
The hairpin falls into the category of
2024-07-30 17:54:59 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 17:55:15 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0386,  0.3491,  0.1714,  ...,  0.0657, -0.0799, -0.0146],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.7139, -2.2891, -1.5713,  ..., -4.1367, -5.4805, -2.1133],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0194, -0.0004, -0.0048,  ..., -0.0009,  0.0218,  0.0124],
        [-0.0101,  0.0208,  0.0018,  ...,  0.0009,  0.0016, -0.0035],
        [ 0.0040, -0.0092,  0.0256,  ..., -0.0166, -0.0051, -0.0064],
        ...,
        [ 0.0173,  0.0135,  0.0022,  ...,  0.0104, -0.0143, -0.0073],
        [ 0.0051,  0.0067,  0.0070,  ..., -0.0139, -0.0064, -0.0156],
        [-0.0019,  0.0043,  0.0102,  ..., -0.0064, -0.0288, -0.0080]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.7012, -2.5254, -1.5547,  ..., -4.2461, -5.5156, -2.2461]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 17:55:16 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you can deliver something, that thing is deliverable
If you can achieve something, that thing is achieveable
If you can renew something, that thing is renewable
If you can foresee something, that thing is foreseeable
If you can advise something, that thing is advisable
If you can define something, that thing is definable
If you can predict something, that thing is predictable
If you can sustain something, that thing is
2024-07-30 17:55:16 root INFO     [order_1_approx] starting weight calculation for If you can foresee something, that thing is foreseeable
If you can predict something, that thing is predictable
If you can deliver something, that thing is deliverable
If you can sustain something, that thing is sustainable
If you can achieve something, that thing is achieveable
If you can define something, that thing is definable
If you can renew something, that thing is renewable
If you can advise something, that thing is
2024-07-30 17:55:16 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-30 17:57:30 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1068, -0.3835, -0.1104,  ...,  0.2321,  0.0974, -0.2832],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.9180, -4.1562, -1.7773,  ..., -1.5850, -5.2422,  2.4219],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0908, -0.0111, -0.0031,  ..., -0.0102, -0.0063,  0.0136],
        [ 0.0076,  0.0361, -0.0224,  ..., -0.0017, -0.0213,  0.0050],
        [-0.0108,  0.0142,  0.0474,  ..., -0.0014, -0.0002, -0.0074],
        ...,
        [-0.0201, -0.0027,  0.0139,  ...,  0.0425,  0.0152, -0.0166],
        [-0.0074,  0.0009,  0.0037,  ...,  0.0111,  0.0343,  0.0145],
        [-0.0138, -0.0080, -0.0025,  ..., -0.0133,  0.0075,  0.0390]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.1523, -4.7773, -2.2637,  ..., -1.6260, -5.0977,  2.1016]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 17:57:31 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The notebook falls into the category of book
The lemon falls into the category of citrus
The skirt falls into the category of clothes
The toaster falls into the category of appliance
The shelf falls into the category of furniture
The vase falls into the category of jar
The grapefruit falls into the category of citrus
The hairpin falls into the category of
2024-07-30 17:57:31 root INFO     [order_1_approx] starting weight calculation for The skirt falls into the category of clothes
The grapefruit falls into the category of citrus
The lemon falls into the category of citrus
The vase falls into the category of jar
The notebook falls into the category of book
The shelf falls into the category of furniture
The hairpin falls into the category of pin
The toaster falls into the category of
2024-07-30 17:57:31 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 17:57:58 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0535,  0.6470,  0.0099,  ...,  0.0846, -0.1924,  0.0547],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.6562, -0.8843, -2.0625,  ..., -0.5552, -8.4688, -1.2051],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0275, -0.0127, -0.0094,  ...,  0.0107, -0.0173,  0.0188],
        [-0.0001,  0.0474, -0.0019,  ...,  0.0107,  0.0062, -0.0245],
        [-0.0149,  0.0050,  0.0389,  ...,  0.0004,  0.0081,  0.0025],
        ...,
        [ 0.0267,  0.0217, -0.0023,  ...,  0.0431, -0.0160, -0.0060],
        [ 0.0237,  0.0151,  0.0086,  ..., -0.0130,  0.0182,  0.0189],
        [ 0.0039, -0.0017,  0.0195,  ...,  0.0140, -0.0171,  0.0084]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.5342, -0.5879, -2.0996,  ..., -0.4712, -8.2891, -1.1562]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 17:57:59 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you can foresee something, that thing is foreseeable
If you can predict something, that thing is predictable
If you can deliver something, that thing is deliverable
If you can sustain something, that thing is sustainable
If you can achieve something, that thing is achieveable
If you can define something, that thing is definable
If you can renew something, that thing is renewable
If you can advise something, that thing is
2024-07-30 17:57:59 root INFO     [order_1_approx] starting weight calculation for If you can advise something, that thing is advisable
If you can renew something, that thing is renewable
If you can sustain something, that thing is sustainable
If you can deliver something, that thing is deliverable
If you can define something, that thing is definable
If you can foresee something, that thing is foreseeable
If you can achieve something, that thing is achieveable
If you can predict something, that thing is
2024-07-30 17:57:59 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-30 17:59:59 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.5771, -0.1150, -0.1823,  ...,  0.1230, -0.2896,  0.0413],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.5566, -2.8281, -0.4595,  ..., -0.7627, -3.0039,  3.0234],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0900,  0.0046, -0.0169,  ...,  0.0031, -0.0279,  0.0008],
        [ 0.0399,  0.0660,  0.0186,  ...,  0.0090, -0.0135, -0.0016],
        [ 0.0016,  0.0053,  0.0257,  ..., -0.0311, -0.0383,  0.0168],
        ...,
        [-0.0121,  0.0111,  0.0053,  ...,  0.0623,  0.0001,  0.0009],
        [-0.0276, -0.0138,  0.0205,  ...,  0.0156,  0.0646, -0.0180],
        [ 0.0217, -0.0077, -0.0064,  ..., -0.0159, -0.0053,  0.0527]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.5078, -2.8301, -0.8877,  ..., -1.2695, -2.4453,  3.2324]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 18:00:06 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The skirt falls into the category of clothes
The grapefruit falls into the category of citrus
The lemon falls into the category of citrus
The vase falls into the category of jar
The notebook falls into the category of book
The shelf falls into the category of furniture
The hairpin falls into the category of pin
The toaster falls into the category of
2024-07-30 18:00:06 root INFO     [order_1_approx] starting weight calculation for The shelf falls into the category of furniture
The skirt falls into the category of clothes
The lemon falls into the category of citrus
The vase falls into the category of jar
The toaster falls into the category of appliance
The grapefruit falls into the category of citrus
The hairpin falls into the category of pin
The notebook falls into the category of
2024-07-30 18:00:06 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 18:00:43 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0956,  0.4629,  0.2119,  ..., -0.1816,  0.0249, -0.2551],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.5029, -0.8271, -2.2402,  ..., -2.3594, -5.7109, -2.0234],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0292, -0.0013, -0.0027,  ...,  0.0060, -0.0109,  0.0148],
        [-0.0287,  0.0288,  0.0077,  ...,  0.0094, -0.0072,  0.0103],
        [-0.0051, -0.0029,  0.0199,  ...,  0.0052,  0.0025, -0.0039],
        ...,
        [ 0.0075,  0.0108, -0.0015,  ...,  0.0404, -0.0159, -0.0075],
        [ 0.0300,  0.0155, -0.0087,  ..., -0.0183, -0.0024, -0.0042],
        [-0.0110,  0.0144, -0.0071,  ...,  0.0014, -0.0077,  0.0104]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.3301, -0.8262, -2.5273,  ..., -2.3691, -5.7070, -2.1504]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 18:00:44 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you can advise something, that thing is advisable
If you can renew something, that thing is renewable
If you can sustain something, that thing is sustainable
If you can deliver something, that thing is deliverable
If you can define something, that thing is definable
If you can foresee something, that thing is foreseeable
If you can achieve something, that thing is achieveable
If you can predict something, that thing is
2024-07-30 18:00:44 root INFO     total operator prediction time: 1275.4310863018036 seconds
2024-07-30 18:00:44 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on verb+tion_irreg
2024-07-30 18:00:44 root INFO     building operator verb+tion_irreg
2024-07-30 18:00:44 root INFO     [order_1_approx] starting weight calculation for To civilize results in civilization
To authorize results in authorization
To accuse results in accusation
To specialize results in specialization
To determine results in determination
To modernize results in modernization
To perspire results in perspiration
To minimize results in
2024-07-30 18:00:44 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-30 18:02:37 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.5195,  0.0721, -0.2832,  ...,  0.3223, -0.3853, -0.0175],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.8818, -3.9941,  1.0889,  ..., -2.0781, -2.9219, -1.0732],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0429, -0.0054, -0.0023,  ..., -0.0066,  0.0061,  0.0100],
        [ 0.0081,  0.0353, -0.0050,  ...,  0.0069, -0.0173, -0.0110],
        [-0.0051, -0.0060,  0.0421,  ..., -0.0068, -0.0235,  0.0273],
        ...,
        [ 0.0155,  0.0140, -0.0009,  ...,  0.0495, -0.0205, -0.0053],
        [-0.0092, -0.0019,  0.0266,  ...,  0.0145,  0.0355, -0.0069],
        [-0.0007, -0.0002,  0.0267,  ..., -0.0181, -0.0103,  0.0347]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.6260, -4.2266,  0.8018,  ..., -2.4258, -2.9648, -0.9429]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 18:02:38 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The shelf falls into the category of furniture
The skirt falls into the category of clothes
The lemon falls into the category of citrus
The vase falls into the category of jar
The toaster falls into the category of appliance
The grapefruit falls into the category of citrus
The hairpin falls into the category of pin
The notebook falls into the category of
2024-07-30 18:02:38 root INFO     [order_1_approx] starting weight calculation for The shelf falls into the category of furniture
The vase falls into the category of jar
The notebook falls into the category of book
The toaster falls into the category of appliance
The hairpin falls into the category of pin
The lemon falls into the category of citrus
The skirt falls into the category of clothes
The grapefruit falls into the category of
2024-07-30 18:02:38 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 18:03:23 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0913, -0.1726, -0.3926,  ..., -0.1366, -0.1083, -0.3081],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.6719, -1.0674,  2.2812,  ..., -0.9688, -2.4141, -2.6504],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0346, -0.0079, -0.0348,  ..., -0.0217, -0.0544,  0.0109],
        [-0.0167,  0.0299,  0.0435,  ...,  0.0245,  0.0144,  0.0046],
        [-0.0096, -0.0080, -0.0015,  ..., -0.0048, -0.0201, -0.0067],
        ...,
        [ 0.0064, -0.0007,  0.0025,  ...,  0.0434,  0.0027,  0.0174],
        [ 0.0007, -0.0057,  0.0016,  ...,  0.0141,  0.0358, -0.0059],
        [-0.0120, -0.0030,  0.0394,  ...,  0.0020, -0.0055,  0.0164]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.0537, -0.0420,  2.2402,  ..., -0.8901, -2.3594, -2.1914]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 18:03:24 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To civilize results in civilization
To authorize results in authorization
To accuse results in accusation
To specialize results in specialization
To determine results in determination
To modernize results in modernization
To perspire results in perspiration
To minimize results in
2024-07-30 18:03:24 root INFO     [order_1_approx] starting weight calculation for To minimize results in minimization
To authorize results in authorization
To accuse results in accusation
To specialize results in specialization
To modernize results in modernization
To perspire results in perspiration
To civilize results in civilization
To determine results in
2024-07-30 18:03:24 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-30 18:05:09 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.3838, -0.7197, -0.2622,  ..., -0.1824, -0.4985,  0.0137],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.2109, -4.8555,  1.1836,  ..., -5.8164, -3.0352, -2.1992],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0354,  0.0224, -0.0094,  ..., -0.0027, -0.0053,  0.0130],
        [ 0.0111,  0.0288,  0.0146,  ...,  0.0226, -0.0034,  0.0127],
        [-0.0054,  0.0050,  0.0248,  ...,  0.0105, -0.0142,  0.0106],
        ...,
        [ 0.0090,  0.0007, -0.0074,  ...,  0.0666, -0.0067,  0.0006],
        [ 0.0040, -0.0023,  0.0092,  ...,  0.0143,  0.0216, -0.0045],
        [-0.0051, -0.0114,  0.0212,  ..., -0.0125, -0.0119,  0.0385]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.3398, -5.1953,  0.8115,  ..., -5.6445, -2.8184, -2.0273]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 18:05:10 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The shelf falls into the category of furniture
The vase falls into the category of jar
The notebook falls into the category of book
The toaster falls into the category of appliance
The hairpin falls into the category of pin
The lemon falls into the category of citrus
The skirt falls into the category of clothes
The grapefruit falls into the category of
2024-07-30 18:05:10 root INFO     total operator prediction time: 1217.858276605606 seconds
2024-07-30 18:05:10 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on synonyms - exact
2024-07-30 18:05:10 root INFO     building operator synonyms - exact
2024-07-30 18:05:10 root INFO     [order_1_approx] starting weight calculation for Another word for sweets is confectionery
Another word for murder is slaying
Another word for package is parcel
Another word for style is manner
Another word for father is dad
Another word for child is kid
Another word for shore is coast
Another word for sofa is
2024-07-30 18:05:10 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 18:06:03 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0491,  0.1890, -0.3018,  ...,  0.1181, -0.4187, -0.2495],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.4883, -5.0352,  1.4766,  ..., -0.4971, -4.8438, -2.0586],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-2.8229e-03,  6.1707e-02, -3.8727e-02,  ..., -4.3335e-02,
         -8.2520e-02, -3.8605e-03],
        [ 4.9286e-02, -4.5547e-03,  1.3107e-02,  ...,  5.4901e-02,
          3.4851e-02,  2.9755e-02],
        [-1.3031e-02,  1.6800e-02,  4.2534e-04,  ..., -1.9058e-02,
         -3.0731e-02, -2.1286e-02],
        ...,
        [ 2.0157e-02,  6.1150e-03,  2.5726e-02,  ...,  7.6294e-02,
          1.1536e-02,  6.9656e-03],
        [ 1.1234e-03, -2.9564e-05, -1.0895e-02,  ...,  2.9785e-02,
          2.8778e-02, -2.4368e-02],
        [ 3.1204e-03, -5.0507e-03,  1.7288e-02,  ...,  2.1729e-02,
         -1.7563e-02,  1.0544e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.4619, -3.9297,  1.2871,  ...,  0.0347, -4.9102, -1.9414]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 18:06:04 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To minimize results in minimization
To authorize results in authorization
To accuse results in accusation
To specialize results in specialization
To modernize results in modernization
To perspire results in perspiration
To civilize results in civilization
To determine results in
2024-07-30 18:06:04 root INFO     [order_1_approx] starting weight calculation for To civilize results in civilization
To perspire results in perspiration
To modernize results in modernization
To minimize results in minimization
To accuse results in accusation
To determine results in determination
To specialize results in specialization
To authorize results in
2024-07-30 18:06:04 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-30 18:07:44 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3018,  0.0475,  0.3599,  ...,  0.1105, -0.1008,  0.1033],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.8525, -3.3926,  4.3633,  ..., -0.8838, -2.8164, -2.0801],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 7.1594e-02,  2.8305e-03, -3.2730e-03,  ...,  3.0655e-02,
         -2.4231e-02, -9.1629e-03],
        [-3.8414e-03,  8.6060e-02,  1.8883e-03,  ...,  1.8967e-02,
          1.4038e-02, -2.5436e-02],
        [-3.5980e-02, -2.8973e-03,  7.8369e-02,  ..., -9.4604e-03,
         -2.4109e-02, -2.3987e-02],
        ...,
        [ 3.5858e-02,  1.3000e-02, -2.5055e-02,  ...,  9.2407e-02,
          5.0278e-03, -2.7969e-02],
        [ 2.0340e-02,  9.3460e-03, -3.3325e-02,  ...,  1.2276e-02,
          5.8868e-02,  6.9923e-03],
        [-3.0518e-05,  1.9073e-04, -2.2568e-02,  ..., -2.1484e-02,
         -2.0552e-04,  2.4750e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.4277, -2.6777,  3.4668,  ..., -0.5820, -2.4961, -1.5596]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 18:07:45 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Another word for sweets is confectionery
Another word for murder is slaying
Another word for package is parcel
Another word for style is manner
Another word for father is dad
Another word for child is kid
Another word for shore is coast
Another word for sofa is
2024-07-30 18:07:45 root INFO     [order_1_approx] starting weight calculation for Another word for father is dad
Another word for child is kid
Another word for sofa is couch
Another word for shore is coast
Another word for package is parcel
Another word for murder is slaying
Another word for sweets is confectionery
Another word for style is
2024-07-30 18:07:45 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 18:08:42 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0481,  0.5542, -0.4434,  ..., -0.1494, -0.2651, -0.0307],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.4893, -4.1758,  1.7676,  ...,  1.3203, -2.7578, -2.2070],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0458, -0.0185,  0.0155,  ...,  0.0086, -0.0161, -0.0034],
        [-0.0097,  0.0301, -0.0161,  ...,  0.0156,  0.0209,  0.0025],
        [-0.0037, -0.0081, -0.0165,  ...,  0.0047, -0.0093,  0.0058],
        ...,
        [ 0.0138,  0.0287, -0.0127,  ...,  0.0081, -0.0054,  0.0035],
        [ 0.0109,  0.0021,  0.0081,  ...,  0.0081,  0.0100, -0.0124],
        [-0.0017, -0.0012, -0.0025,  ...,  0.0155, -0.0269,  0.0124]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.3936, -4.0273,  1.7285,  ...,  1.3320, -2.8184, -2.4355]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 18:08:43 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To civilize results in civilization
To perspire results in perspiration
To modernize results in modernization
To minimize results in minimization
To accuse results in accusation
To determine results in determination
To specialize results in specialization
To authorize results in
2024-07-30 18:08:43 root INFO     [order_1_approx] starting weight calculation for To authorize results in authorization
To determine results in determination
To specialize results in specialization
To modernize results in modernization
To civilize results in civilization
To minimize results in minimization
To accuse results in accusation
To perspire results in
2024-07-30 18:08:44 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-30 18:10:20 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2615, -0.1384,  0.0908,  ..., -0.2247,  0.2720,  0.3760],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.7397, -2.1504,  0.3398,  ...,  2.4961, -5.2812, -1.4062],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0939, -0.0114, -0.0088,  ...,  0.0329,  0.0069, -0.0322],
        [-0.0135,  0.0666,  0.0230,  ..., -0.0181,  0.0006,  0.0135],
        [-0.0335,  0.0045,  0.0818,  ..., -0.0279,  0.0075, -0.0032],
        ...,
        [-0.0002, -0.0148,  0.0260,  ...,  0.0584, -0.0009,  0.0003],
        [ 0.0327, -0.0129, -0.0184,  ...,  0.0123,  0.0578,  0.0164],
        [-0.0024,  0.0505,  0.0034,  ..., -0.0489,  0.0113,  0.0243]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.5776, -1.6230,  0.5884,  ...,  2.5664, -5.1797, -1.7529]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 18:10:21 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Another word for father is dad
Another word for child is kid
Another word for sofa is couch
Another word for shore is coast
Another word for package is parcel
Another word for murder is slaying
Another word for sweets is confectionery
Another word for style is
2024-07-30 18:10:21 root INFO     [order_1_approx] starting weight calculation for Another word for child is kid
Another word for package is parcel
Another word for sofa is couch
Another word for murder is slaying
Another word for shore is coast
Another word for father is dad
Another word for style is manner
Another word for sweets is
2024-07-30 18:10:21 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 18:11:23 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1543, -0.2141, -0.6929,  ..., -0.1566, -0.1891, -0.0465],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.0352, -4.5938,  1.1846,  ..., -1.8340, -1.1787, -0.4238],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0347,  0.0238, -0.0003,  ..., -0.0179,  0.0148,  0.0015],
        [-0.0289,  0.0514,  0.0052,  ...,  0.0569, -0.0452,  0.0501],
        [-0.0158,  0.0145,  0.0163,  ...,  0.0080, -0.0195,  0.0038],
        ...,
        [ 0.0105, -0.0163, -0.0021,  ...,  0.0459, -0.0171,  0.0171],
        [-0.0148,  0.0068, -0.0016,  ...,  0.0010,  0.0303, -0.0201],
        [-0.0043, -0.0519, -0.0095,  ...,  0.0553, -0.0323,  0.0938]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.9453, -4.0156,  1.3477,  ..., -1.6758, -1.3662,  0.3916]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 18:11:23 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To authorize results in authorization
To determine results in determination
To specialize results in specialization
To modernize results in modernization
To civilize results in civilization
To minimize results in minimization
To accuse results in accusation
To perspire results in
2024-07-30 18:11:24 root INFO     [order_1_approx] starting weight calculation for To civilize results in civilization
To determine results in determination
To perspire results in perspiration
To specialize results in specialization
To authorize results in authorization
To accuse results in accusation
To minimize results in minimization
To modernize results in
2024-07-30 18:11:24 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-30 18:12:56 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1484, -0.0207,  0.5264,  ..., -0.0544,  0.0179, -0.0421],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.3926, -6.8789,  0.9443,  ..., -2.0898, -1.3477,  2.9531],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0665, -0.0121,  0.0091,  ..., -0.0134, -0.0163,  0.0181],
        [-0.0098,  0.0698,  0.0183,  ...,  0.0110, -0.0138, -0.0094],
        [-0.0008, -0.0273,  0.0487,  ...,  0.0161,  0.0038,  0.0136],
        ...,
        [ 0.0045,  0.0188, -0.0066,  ...,  0.0534,  0.0208, -0.0025],
        [-0.0073,  0.0180, -0.0323,  ...,  0.0427,  0.0488, -0.0170],
        [-0.0254, -0.0162, -0.0082,  ..., -0.0291,  0.0410,  0.0617]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.2363, -6.8398,  0.5654,  ..., -1.9092, -1.2559,  2.5195]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 18:12:56 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Another word for child is kid
Another word for package is parcel
Another word for sofa is couch
Another word for murder is slaying
Another word for shore is coast
Another word for father is dad
Another word for style is manner
Another word for sweets is
2024-07-30 18:12:57 root INFO     [order_1_approx] starting weight calculation for Another word for sweets is confectionery
Another word for murder is slaying
Another word for style is manner
Another word for sofa is couch
Another word for shore is coast
Another word for father is dad
Another word for package is parcel
Another word for child is
2024-07-30 18:12:57 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 18:14:02 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0034,  0.3118, -0.4663,  ..., -0.4175, -0.2397, -0.2150],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.5498, -4.3672,  0.0723,  ...,  0.1196, -2.5820, -0.9805],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0222, -0.0175,  0.0144,  ...,  0.0117, -0.0123,  0.0075],
        [-0.0255,  0.0198,  0.0096,  ...,  0.0289, -0.0084,  0.0141],
        [-0.0052, -0.0048,  0.0120,  ..., -0.0011,  0.0002,  0.0100],
        ...,
        [ 0.0182, -0.0016,  0.0103,  ...,  0.0233, -0.0296, -0.0035],
        [-0.0010,  0.0182,  0.0023,  ...,  0.0023,  0.0458, -0.0186],
        [-0.0060, -0.0212, -0.0078,  ...,  0.0122, -0.0155,  0.0283]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.4412, -3.8086,  0.0625,  ..., -0.1244, -2.9141, -0.6689]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 18:14:03 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To civilize results in civilization
To determine results in determination
To perspire results in perspiration
To specialize results in specialization
To authorize results in authorization
To accuse results in accusation
To minimize results in minimization
To modernize results in
2024-07-30 18:14:03 root INFO     [order_1_approx] starting weight calculation for To minimize results in minimization
To determine results in determination
To perspire results in perspiration
To civilize results in civilization
To authorize results in authorization
To accuse results in accusation
To modernize results in modernization
To specialize results in
2024-07-30 18:14:04 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-30 18:15:31 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2756, -0.0508,  0.0760,  ..., -0.1779, -0.5801,  0.2588],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.2617, -3.7227, -3.3906,  ...,  0.7969, -0.6890, -0.5815],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0583, -0.0112,  0.0150,  ...,  0.0330, -0.0008,  0.0032],
        [-0.0154,  0.0343,  0.0040,  ..., -0.0087,  0.0117, -0.0128],
        [-0.0222,  0.0033,  0.0555,  ...,  0.0048,  0.0039, -0.0039],
        ...,
        [-0.0342, -0.0069, -0.0132,  ..., -0.0186, -0.0028,  0.0145],
        [-0.0008,  0.0101, -0.0088,  ...,  0.0283,  0.0138, -0.0169],
        [ 0.0008, -0.0273,  0.0030,  ..., -0.0383,  0.0006,  0.0525]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.9082, -2.8906, -3.4023,  ...,  0.9229, -0.7227, -0.4014]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 18:15:32 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Another word for sweets is confectionery
Another word for murder is slaying
Another word for style is manner
Another word for sofa is couch
Another word for shore is coast
Another word for father is dad
Another word for package is parcel
Another word for child is
2024-07-30 18:15:32 root INFO     [order_1_approx] starting weight calculation for Another word for style is manner
Another word for sweets is confectionery
Another word for shore is coast
Another word for father is dad
Another word for child is kid
Another word for package is parcel
Another word for sofa is couch
Another word for murder is
2024-07-30 18:15:32 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 18:16:43 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0222,  0.0856, -0.2883,  ..., -0.2109, -0.3137, -0.2474],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.6523, -2.1211,  1.2012,  ...,  1.2422, -2.4453, -3.4023],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0522, -0.0115,  0.0163,  ...,  0.0130, -0.0143,  0.0066],
        [-0.0116,  0.0450,  0.0209,  ...,  0.0056,  0.0185, -0.0050],
        [-0.0147,  0.0085,  0.0244,  ...,  0.0034, -0.0031, -0.0147],
        ...,
        [ 0.0062,  0.0138,  0.0083,  ...,  0.0328, -0.0117, -0.0033],
        [ 0.0154, -0.0035,  0.0087,  ...,  0.0336,  0.0256, -0.0089],
        [-0.0137, -0.0083,  0.0045,  ..., -0.0114, -0.0022,  0.0229]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.6328, -1.6836,  1.3516,  ...,  1.5283, -2.5781, -3.5449]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 18:17:04 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To minimize results in minimization
To determine results in determination
To perspire results in perspiration
To civilize results in civilization
To authorize results in authorization
To accuse results in accusation
To modernize results in modernization
To specialize results in
2024-07-30 18:17:04 root INFO     [order_1_approx] starting weight calculation for To minimize results in minimization
To specialize results in specialization
To determine results in determination
To perspire results in perspiration
To civilize results in civilization
To modernize results in modernization
To authorize results in authorization
To accuse results in
2024-07-30 18:17:04 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-30 18:18:06 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0214,  0.3394,  0.2900,  ..., -0.2493, -0.0359,  0.1000],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.5703, -6.0977, -1.8789,  ...,  0.6924, -1.3320, -4.1055],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0616, -0.0040,  0.0110,  ...,  0.0056,  0.0095,  0.0208],
        [-0.0197,  0.0343,  0.0310,  ..., -0.0249,  0.0110, -0.0218],
        [-0.0263,  0.0062,  0.0530,  ..., -0.0064,  0.0065,  0.0262],
        ...,
        [ 0.0044, -0.0053,  0.0070,  ...,  0.0202, -0.0196,  0.0090],
        [-0.0004,  0.0189,  0.0076,  ..., -0.0061,  0.0394, -0.0087],
        [ 0.0077, -0.0019, -0.0030,  ..., -0.0142,  0.0034,  0.0300]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.3782, -5.8945, -1.7529,  ...,  0.8647, -1.4893, -3.8867]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 18:18:07 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Another word for style is manner
Another word for sweets is confectionery
Another word for shore is coast
Another word for father is dad
Another word for child is kid
Another word for package is parcel
Another word for sofa is couch
Another word for murder is
2024-07-30 18:18:08 root INFO     [order_1_approx] starting weight calculation for Another word for package is parcel
Another word for sofa is couch
Another word for murder is slaying
Another word for sweets is confectionery
Another word for shore is coast
Another word for child is kid
Another word for style is manner
Another word for father is
2024-07-30 18:18:08 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 18:19:43 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1133,  0.4436, -0.5171,  ...,  0.1660, -0.4417, -0.0640],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.0723, -3.8945, -0.0977,  ...,  4.1641, -0.4038, -0.7451],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0440,  0.0009,  0.0156,  ...,  0.0173, -0.0359, -0.0081],
        [-0.0123,  0.0297, -0.0240,  ...,  0.0193, -0.0051,  0.0080],
        [-0.0130, -0.0220,  0.0254,  ..., -0.0080,  0.0090, -0.0155],
        ...,
        [ 0.0163,  0.0257, -0.0137,  ...,  0.0278, -0.0088, -0.0029],
        [ 0.0058,  0.0279, -0.0392,  ...,  0.0155, -0.0031,  0.0067],
        [ 0.0228,  0.0152,  0.0283,  ...,  0.0167, -0.0369,  0.0675]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.2949, -3.6641, -0.1941,  ...,  3.8828, -1.5273, -0.4089]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 18:19:44 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To minimize results in minimization
To specialize results in specialization
To determine results in determination
To perspire results in perspiration
To civilize results in civilization
To modernize results in modernization
To authorize results in authorization
To accuse results in
2024-07-30 18:19:44 root INFO     [order_1_approx] starting weight calculation for To authorize results in authorization
To modernize results in modernization
To minimize results in minimization
To specialize results in specialization
To accuse results in accusation
To determine results in determination
To perspire results in perspiration
To civilize results in
2024-07-30 18:19:44 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-30 18:20:42 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2241,  0.1544, -0.0697,  ..., -0.2311,  0.0065,  0.1753],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.2617, -1.9688, -0.5669,  ...,  0.4683, -2.3105, -2.2168],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0567, -0.0139,  0.0380,  ...,  0.0118,  0.0005,  0.0359],
        [ 0.0090,  0.0342, -0.0033,  ...,  0.0151,  0.0299, -0.0165],
        [ 0.0012,  0.0016,  0.0775,  ...,  0.0108, -0.0125, -0.0038],
        ...,
        [-0.0168,  0.0159, -0.0002,  ...,  0.0181,  0.0043, -0.0056],
        [-0.0231, -0.0022, -0.0040,  ...,  0.0467,  0.0258, -0.0122],
        [-0.0042, -0.0203, -0.0061,  ..., -0.0014,  0.0133,  0.0361]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.1846, -1.4629, -0.0239,  ...,  0.4062, -2.2754, -2.5195]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 18:20:42 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Another word for package is parcel
Another word for sofa is couch
Another word for murder is slaying
Another word for sweets is confectionery
Another word for shore is coast
Another word for child is kid
Another word for style is manner
Another word for father is
2024-07-30 18:20:43 root INFO     [order_1_approx] starting weight calculation for Another word for child is kid
Another word for murder is slaying
Another word for sofa is couch
Another word for father is dad
Another word for sweets is confectionery
Another word for style is manner
Another word for shore is coast
Another word for package is
2024-07-30 18:20:43 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 18:22:23 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0766,  0.5117, -0.6855,  ..., -0.3613, -0.3555, -0.0286],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.3994, -2.4531,  2.4785,  ..., -0.0447, -0.6792, -1.6426],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 3.6621e-02, -2.7847e-02,  2.7206e-02,  ...,  3.6926e-03,
         -2.1759e-02,  2.6947e-02],
        [-7.2021e-03,  3.8300e-02, -5.8708e-03,  ...,  3.1433e-02,
          1.3399e-03,  4.3793e-03],
        [-1.0078e-02, -1.0330e-02,  3.1036e-02,  ...,  1.9970e-03,
         -1.5541e-02,  1.1673e-02],
        ...,
        [ 1.9272e-02,  1.1780e-02, -2.0050e-02,  ...,  2.8030e-02,
          7.6218e-03,  7.3791e-05],
        [ 2.0569e-02,  8.0109e-04, -1.7929e-04,  ...,  1.9028e-02,
          3.6072e-02, -1.7929e-02],
        [ 4.2458e-03, -1.2024e-02,  9.4757e-03,  ...,  3.8147e-05,
         -2.2491e-02,  3.0838e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.0996, -2.3594,  2.5527,  ..., -0.3147, -0.7002, -1.3516]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 18:22:24 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To authorize results in authorization
To modernize results in modernization
To minimize results in minimization
To specialize results in specialization
To accuse results in accusation
To determine results in determination
To perspire results in perspiration
To civilize results in
2024-07-30 18:22:24 root INFO     total operator prediction time: 1299.9087171554565 seconds
2024-07-30 18:22:24 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on adj+ly_reg
2024-07-30 18:22:24 root INFO     building operator adj+ly_reg
2024-07-30 18:22:24 root INFO     [order_1_approx] starting weight calculation for The adjective form of financial is financially
The adjective form of actual is actually
The adjective form of virtual is virtually
The adjective form of famous is famously
The adjective form of subsequent is subsequently
The adjective form of practical is practically
The adjective form of federal is federally
The adjective form of increasing is
2024-07-30 18:22:24 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-30 18:23:17 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2231,  0.0615,  0.1033,  ..., -0.0307, -0.0701,  0.0895],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.3516, -2.5039, -1.4473,  ..., -1.5420, -0.6216, -0.6030],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0985,  0.0123, -0.0012,  ...,  0.0244, -0.0601,  0.0257],
        [ 0.0037,  0.0760,  0.0234,  ..., -0.0145, -0.0023, -0.0176],
        [-0.0372, -0.0299,  0.0793,  ...,  0.0025,  0.0050, -0.0234],
        ...,
        [ 0.0187,  0.0125,  0.0404,  ...,  0.0445, -0.0242,  0.0058],
        [ 0.0007,  0.0158, -0.0338,  ...,  0.0047,  0.0698, -0.0177],
        [-0.0186, -0.0177, -0.0070,  ..., -0.0303, -0.0098,  0.0662]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 5.1055, -2.8867, -1.1982,  ..., -1.9453, -0.5161, -0.4609]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 18:23:18 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Another word for child is kid
Another word for murder is slaying
Another word for sofa is couch
Another word for father is dad
Another word for sweets is confectionery
Another word for style is manner
Another word for shore is coast
Another word for package is
2024-07-30 18:23:18 root INFO     [order_1_approx] starting weight calculation for Another word for sofa is couch
Another word for child is kid
Another word for style is manner
Another word for father is dad
Another word for sweets is confectionery
Another word for package is parcel
Another word for murder is slaying
Another word for shore is
2024-07-30 18:23:18 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 18:25:03 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0756,  0.0257, -0.2217,  ...,  0.0471, -0.2476, -0.0500],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.2637, -2.5000,  0.3213,  ..., -0.8291, -2.3613, -1.2275],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0275, -0.0176, -0.0148,  ...,  0.0113,  0.0240,  0.0205],
        [ 0.0325,  0.0216, -0.0141,  ..., -0.0006, -0.0044, -0.0149],
        [ 0.0428, -0.0304,  0.0195,  ..., -0.0122,  0.0141,  0.0296],
        ...,
        [ 0.0085,  0.0048, -0.0155,  ...,  0.0475, -0.0094, -0.0068],
        [-0.0125,  0.0320,  0.0148,  ...,  0.0190,  0.0179,  0.0109],
        [-0.0111, -0.0072,  0.0064,  ..., -0.0044, -0.0212,  0.0083]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.1533, -2.8398,  0.3040,  ..., -0.8213, -1.8828, -1.4395]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 18:25:05 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The adjective form of financial is financially
The adjective form of actual is actually
The adjective form of virtual is virtually
The adjective form of famous is famously
The adjective form of subsequent is subsequently
The adjective form of practical is practically
The adjective form of federal is federally
The adjective form of increasing is
2024-07-30 18:25:05 root INFO     [order_1_approx] starting weight calculation for The adjective form of increasing is increasingly
The adjective form of practical is practically
The adjective form of financial is financially
The adjective form of subsequent is subsequently
The adjective form of virtual is virtually
The adjective form of federal is federally
The adjective form of actual is actually
The adjective form of famous is
2024-07-30 18:25:05 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-30 18:25:51 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2008,  0.2976,  0.1682,  ..., -0.1830,  0.0856,  0.3223],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.4688, -3.4648,  0.4380,  ...,  4.1992, -0.4426, -1.8252],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0886, -0.0167,  0.0007,  ...,  0.0554, -0.0332,  0.0114],
        [-0.0027,  0.0718, -0.0066,  ..., -0.0001, -0.0027,  0.0050],
        [-0.0432, -0.0072,  0.0975,  ..., -0.0197, -0.0216, -0.0204],
        ...,
        [ 0.0097,  0.0046,  0.0220,  ...,  0.0540,  0.0104, -0.0147],
        [-0.0168,  0.0080,  0.0392,  ...,  0.0220,  0.0911, -0.0419],
        [-0.0191,  0.0061, -0.0218,  ..., -0.0254,  0.0019,  0.0764]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.9824, -3.1797,  0.3291,  ...,  4.0859,  0.0168, -1.5869]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 18:25:52 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Another word for sofa is couch
Another word for child is kid
Another word for style is manner
Another word for father is dad
Another word for sweets is confectionery
Another word for package is parcel
Another word for murder is slaying
Another word for shore is
2024-07-30 18:25:52 root INFO     total operator prediction time: 1242.0823521614075 seconds
2024-07-30 18:25:52 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on animal - youth
2024-07-30 18:25:52 root INFO     building operator animal - youth
2024-07-30 18:25:52 root INFO     [order_1_approx] starting weight calculation for The offspring of a cockroach is referred to as a nymph
The offspring of a gorilla is referred to as a infant
The offspring of a horse is referred to as a foal
The offspring of a duck is referred to as a duckling
The offspring of a raccoon is referred to as a kit
The offspring of a seal is referred to as a pup
The offspring of a tiger is referred to as a cub
The offspring of a weasel is referred to as a
2024-07-30 18:25:53 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 18:27:44 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2505,  0.1550, -0.2126,  ...,  0.0135, -0.3596, -0.1942],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.1230, -1.6572,  2.5781,  ..., -1.1963, -2.7578, -2.0938],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0348, -0.0248,  0.0017,  ...,  0.0438, -0.0054,  0.0196],
        [-0.0097,  0.0166,  0.0183,  ..., -0.0176,  0.0167, -0.0150],
        [ 0.0004,  0.0018,  0.0671,  ..., -0.0373, -0.0105,  0.0071],
        ...,
        [ 0.0356,  0.0069,  0.0131,  ...,  0.0570, -0.0033,  0.0060],
        [ 0.0337,  0.0336, -0.0079,  ...,  0.0100,  0.0347,  0.0337],
        [ 0.0166, -0.0079,  0.0185,  ..., -0.0074, -0.0092, -0.0029]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.8213, -1.5469,  2.5723,  ..., -0.9121, -3.3086, -2.2793]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 18:27:45 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The adjective form of increasing is increasingly
The adjective form of practical is practically
The adjective form of financial is financially
The adjective form of subsequent is subsequently
The adjective form of virtual is virtually
The adjective form of federal is federally
The adjective form of actual is actually
The adjective form of famous is
2024-07-30 18:27:45 root INFO     [order_1_approx] starting weight calculation for The adjective form of increasing is increasingly
The adjective form of financial is financially
The adjective form of famous is famously
The adjective form of actual is actually
The adjective form of federal is federally
The adjective form of practical is practically
The adjective form of subsequent is subsequently
The adjective form of virtual is
2024-07-30 18:27:45 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-30 18:28:24 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2238,  0.1873,  0.1295,  ..., -0.2061, -0.4224, -0.1727],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.4688, -2.3516, -0.1826,  ...,  1.6602, -0.6729,  1.7686],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 2.5650e-02,  4.0054e-03, -1.2581e-02,  ..., -7.6485e-03,
          1.0551e-02,  2.0638e-03],
        [ 8.3084e-03,  1.3672e-02,  4.1885e-03,  ...,  2.1324e-03,
          4.7646e-03, -3.1319e-03],
        [ 1.0429e-02, -4.2610e-03,  1.4900e-02,  ...,  6.7520e-03,
         -8.7128e-03, -1.4313e-02],
        ...,
        [ 5.9776e-03,  7.4291e-04,  8.9569e-03,  ...,  4.3335e-03,
          1.8005e-02, -6.1874e-03],
        [ 1.3672e-02,  1.9855e-03,  6.4430e-03,  ...,  2.0386e-02,
         -5.2834e-04,  1.9026e-03],
        [-3.7651e-03, -9.4070e-03,  2.0981e-03,  ..., -3.7909e-05,
         -7.8430e-03,  8.3389e-03]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.4355, -2.3828, -0.0304,  ...,  1.7617, -0.5898,  1.7246]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 18:28:25 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The offspring of a cockroach is referred to as a nymph
The offspring of a gorilla is referred to as a infant
The offspring of a horse is referred to as a foal
The offspring of a duck is referred to as a duckling
The offspring of a raccoon is referred to as a kit
The offspring of a seal is referred to as a pup
The offspring of a tiger is referred to as a cub
The offspring of a weasel is referred to as a
2024-07-30 18:28:25 root INFO     [order_1_approx] starting weight calculation for The offspring of a weasel is referred to as a kit
The offspring of a gorilla is referred to as a infant
The offspring of a tiger is referred to as a cub
The offspring of a horse is referred to as a foal
The offspring of a cockroach is referred to as a nymph
The offspring of a raccoon is referred to as a kit
The offspring of a duck is referred to as a duckling
The offspring of a seal is referred to as a
2024-07-30 18:28:25 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 18:30:22 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1709, -0.1290,  0.1718,  ..., -0.0935, -0.0543,  0.2183],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.2773, -3.2402,  0.1978,  ..., -3.3438, -0.3682,  0.1572],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0526, -0.0510,  0.0308,  ...,  0.0272,  0.0082,  0.0088],
        [ 0.0009,  0.0170, -0.0153,  ..., -0.0485, -0.0041, -0.0310],
        [-0.0114, -0.0288,  0.0286,  ...,  0.0010, -0.0263, -0.0209],
        ...,
        [ 0.0140,  0.0095, -0.0177,  ...,  0.0416, -0.0042, -0.0188],
        [ 0.0506,  0.0238, -0.0211,  ...,  0.0144,  0.0450,  0.0007],
        [-0.0216,  0.0319, -0.0054,  ..., -0.0356, -0.0248,  0.0273]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.6084, -3.1152, -0.0378,  ..., -3.1934, -0.7471, -0.1697]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 18:30:23 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The adjective form of increasing is increasingly
The adjective form of financial is financially
The adjective form of famous is famously
The adjective form of actual is actually
The adjective form of federal is federally
The adjective form of practical is practically
The adjective form of subsequent is subsequently
The adjective form of virtual is
2024-07-30 18:30:23 root INFO     [order_1_approx] starting weight calculation for The adjective form of virtual is virtually
The adjective form of financial is financially
The adjective form of actual is actually
The adjective form of increasing is increasingly
The adjective form of subsequent is subsequently
The adjective form of famous is famously
The adjective form of practical is practically
The adjective form of federal is
2024-07-30 18:30:23 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-30 18:30:53 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3926, -0.2008, -0.2155,  ..., -0.1802, -0.4910,  0.3369],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.2695, -3.7578, -2.7402,  ..., -0.5493, -3.1602,  2.7070],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0429, -0.0349, -0.0185,  ...,  0.0219, -0.0210,  0.0021],
        [ 0.0035,  0.0460,  0.0038,  ..., -0.0012, -0.0081, -0.0155],
        [ 0.0042, -0.0197,  0.0419,  ...,  0.0262, -0.0069, -0.0395],
        ...,
        [ 0.0141, -0.0142,  0.0137,  ...,  0.0392,  0.0338, -0.0176],
        [-0.0068, -0.0132,  0.0166,  ...,  0.0450,  0.0298, -0.0084],
        [-0.0232, -0.0034,  0.0056,  ..., -0.0119, -0.0115,  0.0200]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.3662, -3.4375, -2.4941,  ..., -0.0591, -3.0840,  2.4082]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 18:30:54 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The offspring of a weasel is referred to as a kit
The offspring of a gorilla is referred to as a infant
The offspring of a tiger is referred to as a cub
The offspring of a horse is referred to as a foal
The offspring of a cockroach is referred to as a nymph
The offspring of a raccoon is referred to as a kit
The offspring of a duck is referred to as a duckling
The offspring of a seal is referred to as a
2024-07-30 18:30:54 root INFO     [order_1_approx] starting weight calculation for The offspring of a cockroach is referred to as a nymph
The offspring of a weasel is referred to as a kit
The offspring of a horse is referred to as a foal
The offspring of a raccoon is referred to as a kit
The offspring of a tiger is referred to as a cub
The offspring of a duck is referred to as a duckling
The offspring of a seal is referred to as a pup
The offspring of a gorilla is referred to as a
2024-07-30 18:30:55 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 18:33:02 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1152,  0.0181, -0.2661,  ..., -0.2460, -0.3613, -0.0929],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.6445, -0.9976,  3.9297,  ..., -2.3750, -0.8843, -0.3818],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0581, -0.0463, -0.0315,  ...,  0.0291, -0.0112, -0.0022],
        [-0.0023,  0.0256, -0.0065,  ..., -0.0056, -0.0058, -0.0051],
        [ 0.0021,  0.0079,  0.0368,  ..., -0.0324, -0.0041, -0.0112],
        ...,
        [-0.0047,  0.0025, -0.0329,  ...,  0.0471,  0.0256, -0.0181],
        [ 0.0003,  0.0084, -0.0266,  ...,  0.0010,  0.0213, -0.0352],
        [ 0.0130, -0.0015,  0.0196,  ..., -0.0084, -0.0194,  0.0328]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.3730, -0.8862,  3.7852,  ..., -2.5312, -1.5391, -0.1949]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 18:33:03 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The adjective form of virtual is virtually
The adjective form of financial is financially
The adjective form of actual is actually
The adjective form of increasing is increasingly
The adjective form of subsequent is subsequently
The adjective form of famous is famously
The adjective form of practical is practically
The adjective form of federal is
2024-07-30 18:33:03 root INFO     [order_1_approx] starting weight calculation for The adjective form of famous is famously
The adjective form of practical is practically
The adjective form of subsequent is subsequently
The adjective form of financial is financially
The adjective form of increasing is increasingly
The adjective form of federal is federally
The adjective form of virtual is virtually
The adjective form of actual is
2024-07-30 18:33:03 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-30 18:33:24 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2583, -0.0979, -0.2642,  ..., -0.1523, -0.7241,  0.2344],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.7666, -3.0273, -0.5918,  ...,  0.7295, -2.0938,  1.8047],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 2.3834e-02, -1.1429e-02, -4.1656e-03,  ...,  1.1044e-03,
         -4.9858e-03, -2.5902e-03],
        [ 5.6381e-03,  1.4992e-02,  7.2021e-03,  ...,  3.3913e-03,
          6.7062e-03, -2.2945e-03],
        [ 1.0216e-02,  1.0033e-02,  2.5604e-02,  ...,  6.8626e-03,
          6.0959e-03, -1.7517e-02],
        ...,
        [-5.2223e-03,  1.1963e-02, -4.9324e-03,  ...,  2.4857e-02,
          5.5237e-03, -8.2550e-03],
        [ 1.4145e-02, -1.8967e-02,  2.1118e-02,  ...,  8.8730e-03,
          1.7014e-02,  1.5121e-02],
        [-1.6403e-02, -8.7261e-05, -1.0414e-02,  ..., -2.3819e-02,
         -2.1545e-02,  2.4170e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.6440, -2.9219, -0.3652,  ...,  1.0381, -2.1055,  1.4102]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 18:33:25 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The offspring of a cockroach is referred to as a nymph
The offspring of a weasel is referred to as a kit
The offspring of a horse is referred to as a foal
The offspring of a raccoon is referred to as a kit
The offspring of a tiger is referred to as a cub
The offspring of a duck is referred to as a duckling
The offspring of a seal is referred to as a pup
The offspring of a gorilla is referred to as a
2024-07-30 18:33:25 root INFO     [order_1_approx] starting weight calculation for The offspring of a seal is referred to as a pup
The offspring of a tiger is referred to as a cub
The offspring of a weasel is referred to as a kit
The offspring of a gorilla is referred to as a infant
The offspring of a duck is referred to as a duckling
The offspring of a cockroach is referred to as a nymph
The offspring of a horse is referred to as a foal
The offspring of a raccoon is referred to as a
2024-07-30 18:33:26 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 18:35:43 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1497,  0.1803, -0.2457,  ..., -0.3135, -0.2671, -0.0230],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.1504, -2.3809,  1.8125,  ..., -0.7578, -1.8047, -1.2285],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0392, -0.0521,  0.0023,  ...,  0.0347,  0.0045,  0.0350],
        [ 0.0036,  0.0112, -0.0093,  ..., -0.0574,  0.0082, -0.0558],
        [ 0.0289, -0.0095,  0.0289,  ...,  0.0014, -0.0200, -0.0133],
        ...,
        [ 0.0438,  0.0426, -0.0091,  ...,  0.0325, -0.0182, -0.0331],
        [ 0.0388,  0.0119, -0.0051,  ..., -0.0127,  0.0224, -0.0247],
        [ 0.0632,  0.0102,  0.0014,  ..., -0.0388, -0.0055, -0.0174]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.3730, -2.0312,  2.1582,  ..., -0.3074, -2.1445, -1.2529]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 18:35:44 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The adjective form of famous is famously
The adjective form of practical is practically
The adjective form of subsequent is subsequently
The adjective form of financial is financially
The adjective form of increasing is increasingly
The adjective form of federal is federally
The adjective form of virtual is virtually
The adjective form of actual is
2024-07-30 18:35:44 root INFO     [order_1_approx] starting weight calculation for The adjective form of federal is federally
The adjective form of subsequent is subsequently
The adjective form of actual is actually
The adjective form of famous is famously
The adjective form of practical is practically
The adjective form of virtual is virtually
The adjective form of increasing is increasingly
The adjective form of financial is
2024-07-30 18:35:44 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-30 18:35:56 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0835,  0.1235, -0.2267,  ..., -0.0837, -0.6235, -0.0692],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.4785, -2.6113,  0.7437,  ..., -0.3838, -1.4902,  1.5312],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 3.2562e-02, -1.1009e-02,  8.4305e-04,  ...,  7.6294e-05,
         -3.6030e-03,  3.7594e-03],
        [-1.2636e-03,  1.2299e-02,  4.1723e-04,  ..., -7.3433e-04,
          1.0635e-02, -1.3481e-02],
        [ 8.2855e-03,  5.7907e-03,  9.8724e-03,  ...,  6.8016e-03,
         -6.8703e-03, -9.9182e-03],
        ...,
        [ 4.4518e-03,  3.0251e-03, -6.6719e-03,  ...,  1.2520e-02,
          5.5542e-03, -1.1986e-02],
        [ 7.1049e-04, -3.5534e-03, -3.4103e-03,  ...,  2.8324e-03,
          1.2718e-02,  1.7080e-03],
        [-2.7733e-03,  3.1796e-03, -4.3221e-03,  ..., -8.7814e-03,
          2.7275e-04,  7.2403e-03]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.2363, -2.4922,  0.6919,  ..., -0.3271, -1.3545,  1.5957]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 18:35:57 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The offspring of a seal is referred to as a pup
The offspring of a tiger is referred to as a cub
The offspring of a weasel is referred to as a kit
The offspring of a gorilla is referred to as a infant
The offspring of a duck is referred to as a duckling
The offspring of a cockroach is referred to as a nymph
The offspring of a horse is referred to as a foal
The offspring of a raccoon is referred to as a
2024-07-30 18:35:57 root INFO     [order_1_approx] starting weight calculation for The offspring of a gorilla is referred to as a infant
The offspring of a seal is referred to as a pup
The offspring of a weasel is referred to as a kit
The offspring of a raccoon is referred to as a kit
The offspring of a tiger is referred to as a cub
The offspring of a horse is referred to as a foal
The offspring of a duck is referred to as a duckling
The offspring of a cockroach is referred to as a
2024-07-30 18:35:57 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 18:38:14 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0681, -0.1613, -0.2908,  ..., -0.0831, -0.1106,  0.0394],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.1699, -0.8623,  2.1973,  ..., -2.3203, -1.9619, -0.3848],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0594, -0.0344, -0.0035,  ...,  0.0228, -0.0011,  0.0155],
        [-0.0316,  0.0547,  0.0035,  ..., -0.0589, -0.0277, -0.0262],
        [ 0.0142,  0.0074,  0.0602,  ..., -0.0150,  0.0169,  0.0028],
        ...,
        [ 0.0052, -0.0014, -0.0215,  ...,  0.0564,  0.0254, -0.0114],
        [ 0.0193,  0.0227, -0.0024,  ..., -0.0273,  0.0551, -0.0165],
        [ 0.0124, -0.0149, -0.0026,  ..., -0.0080, -0.0206,  0.0213]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.3096, -0.5547,  2.4355,  ..., -2.1094, -2.1855, -0.3723]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 18:38:15 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The adjective form of federal is federally
The adjective form of subsequent is subsequently
The adjective form of actual is actually
The adjective form of famous is famously
The adjective form of practical is practically
The adjective form of virtual is virtually
The adjective form of increasing is increasingly
The adjective form of financial is
2024-07-30 18:38:15 root INFO     [order_1_approx] starting weight calculation for The adjective form of famous is famously
The adjective form of financial is financially
The adjective form of federal is federally
The adjective form of actual is actually
The adjective form of virtual is virtually
The adjective form of subsequent is subsequently
The adjective form of increasing is increasingly
The adjective form of practical is
2024-07-30 18:38:15 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-30 18:38:24 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1660,  0.0607, -0.5957,  ..., -0.0253, -0.2896, -0.0306],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.3391, -4.2891, -0.8408,  ..., -0.7793, -3.4395, -0.3896],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0355, -0.0013,  0.0092,  ..., -0.0062, -0.0103, -0.0079],
        [ 0.0132,  0.0146,  0.0092,  ..., -0.0032, -0.0116, -0.0060],
        [ 0.0036,  0.0109,  0.0259,  ...,  0.0079,  0.0089, -0.0143],
        ...,
        [ 0.0007, -0.0165, -0.0116,  ...,  0.0240,  0.0017, -0.0097],
        [ 0.0069, -0.0032,  0.0105,  ...,  0.0274, -0.0182,  0.0060],
        [-0.0170,  0.0055,  0.0058,  ..., -0.0278,  0.0086,  0.0154]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.3074, -4.0234, -0.9727,  ..., -0.3662, -3.1074, -0.6035]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 18:38:25 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The offspring of a gorilla is referred to as a infant
The offspring of a seal is referred to as a pup
The offspring of a weasel is referred to as a kit
The offspring of a raccoon is referred to as a kit
The offspring of a tiger is referred to as a cub
The offspring of a horse is referred to as a foal
The offspring of a duck is referred to as a duckling
The offspring of a cockroach is referred to as a
2024-07-30 18:38:25 root INFO     [order_1_approx] starting weight calculation for The offspring of a tiger is referred to as a cub
The offspring of a seal is referred to as a pup
The offspring of a raccoon is referred to as a kit
The offspring of a horse is referred to as a foal
The offspring of a weasel is referred to as a kit
The offspring of a gorilla is referred to as a infant
The offspring of a cockroach is referred to as a nymph
The offspring of a duck is referred to as a
2024-07-30 18:38:25 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 18:40:52 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1075,  0.0331, -0.1783,  ..., -0.2253, -0.2610,  0.2350],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.0117, -3.0840, -0.7725,  ..., -2.1309, -1.8115,  0.2461],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0113, -0.0311,  0.0149,  ...,  0.0051, -0.0133,  0.0183],
        [-0.0158,  0.0434,  0.0147,  ..., -0.0399,  0.0056, -0.0156],
        [ 0.0131, -0.0054,  0.0326,  ..., -0.0171, -0.0150, -0.0038],
        ...,
        [ 0.0419,  0.0184,  0.0041,  ...,  0.0782, -0.0091,  0.0179],
        [ 0.0746,  0.0052,  0.0025,  ..., -0.0226,  0.0248, -0.0527],
        [ 0.0345, -0.0084,  0.0116,  ..., -0.0257, -0.0136,  0.0307]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.3516, -2.2695, -0.5801,  ..., -1.4766, -2.1953,  0.3235]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 18:40:53 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The adjective form of famous is famously
The adjective form of financial is financially
The adjective form of federal is federally
The adjective form of actual is actually
The adjective form of virtual is virtually
The adjective form of subsequent is subsequently
The adjective form of increasing is increasingly
The adjective form of practical is
2024-07-30 18:40:53 root INFO     [order_1_approx] starting weight calculation for The adjective form of practical is practically
The adjective form of famous is famously
The adjective form of actual is actually
The adjective form of increasing is increasingly
The adjective form of federal is federally
The adjective form of financial is financially
The adjective form of virtual is virtually
The adjective form of subsequent is
2024-07-30 18:40:53 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-30 18:40:55 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2047, -0.0900,  0.1532,  ...,  0.0062, -0.4666,  0.2671],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.1689, -1.0820, -2.3496,  ...,  0.0391, -5.5820,  2.6094],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0398, -0.0111,  0.0044,  ..., -0.0040, -0.0113,  0.0160],
        [ 0.0187,  0.0395,  0.0192,  ...,  0.0121, -0.0005, -0.0105],
        [ 0.0008,  0.0008,  0.0335,  ..., -0.0028, -0.0186, -0.0168],
        ...,
        [-0.0196, -0.0068, -0.0057,  ...,  0.0215,  0.0265, -0.0106],
        [-0.0017, -0.0018,  0.0079,  ...,  0.0143,  0.0138, -0.0005],
        [-0.0004,  0.0033,  0.0069,  ..., -0.0055, -0.0136,  0.0138]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.7300, -1.2607, -2.3730,  ...,  0.5317, -5.7109,  2.7578]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 18:40:55 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The offspring of a tiger is referred to as a cub
The offspring of a seal is referred to as a pup
The offspring of a raccoon is referred to as a kit
The offspring of a horse is referred to as a foal
The offspring of a weasel is referred to as a kit
The offspring of a gorilla is referred to as a infant
The offspring of a cockroach is referred to as a nymph
The offspring of a duck is referred to as a
2024-07-30 18:40:56 root INFO     [order_1_approx] starting weight calculation for The offspring of a gorilla is referred to as a infant
The offspring of a cockroach is referred to as a nymph
The offspring of a seal is referred to as a pup
The offspring of a duck is referred to as a duckling
The offspring of a tiger is referred to as a cub
The offspring of a raccoon is referred to as a kit
The offspring of a weasel is referred to as a kit
The offspring of a horse is referred to as a
2024-07-30 18:40:56 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 18:43:28 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1849,  0.1182, -0.1508,  ..., -0.3198, -0.4448,  0.3838],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.2217,  0.1484,  1.8018,  ..., -0.8145,  1.6680, -2.7207],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0230, -0.0359, -0.0112,  ...,  0.0015,  0.0161,  0.0179],
        [-0.0364,  0.0008,  0.0112,  ..., -0.0048,  0.0112, -0.0194],
        [ 0.0377, -0.0191,  0.0384,  ..., -0.0180, -0.0144,  0.0166],
        ...,
        [ 0.0009,  0.0289,  0.0112,  ...,  0.0587,  0.0117,  0.0091],
        [ 0.0045,  0.0298,  0.0466,  ...,  0.0164,  0.0402, -0.0349],
        [ 0.0109, -0.0064, -0.0127,  ..., -0.0248, -0.0207,  0.0320]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.9009,  0.5679,  2.3105,  ..., -0.4727,  1.3242, -2.8262]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 18:43:28 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1183, -0.0062, -0.0931,  ...,  0.0663, -0.1454,  0.3225],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.6221, -4.8516, -2.5488,  ...,  2.6504, -1.6328,  2.4258],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0159, -0.0238, -0.0057,  ..., -0.0085, -0.0224,  0.0085],
        [ 0.0103,  0.0261,  0.0024,  ...,  0.0179,  0.0014, -0.0158],
        [-0.0014, -0.0002,  0.0254,  ..., -0.0016, -0.0130, -0.0108],
        ...,
        [ 0.0130, -0.0066, -0.0041,  ...,  0.0320, -0.0019, -0.0106],
        [ 0.0032,  0.0247,  0.0174,  ...,  0.0221,  0.0270, -0.0088],
        [ 0.0060, -0.0148,  0.0070,  ..., -0.0222,  0.0033,  0.0199]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.5557, -4.5977, -2.5488,  ...,  3.0723, -2.1484,  2.7012]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 18:43:30 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The adjective form of practical is practically
The adjective form of famous is famously
The adjective form of actual is actually
The adjective form of increasing is increasingly
The adjective form of federal is federally
The adjective form of financial is financially
The adjective form of virtual is virtually
The adjective form of subsequent is
2024-07-30 18:43:30 root INFO     total operator prediction time: 1266.5090084075928 seconds
2024-07-30 18:43:30 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on over+adj_reg
2024-07-30 18:43:30 root INFO     building operator over+adj_reg
2024-07-30 18:43:30 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The offspring of a gorilla is referred to as a infant
The offspring of a cockroach is referred to as a nymph
The offspring of a seal is referred to as a pup
The offspring of a duck is referred to as a duckling
The offspring of a tiger is referred to as a cub
The offspring of a raccoon is referred to as a kit
The offspring of a weasel is referred to as a kit
The offspring of a horse is referred to as a
2024-07-30 18:43:31 root INFO     [order_1_approx] starting weight calculation for The offspring of a horse is referred to as a foal
The offspring of a cockroach is referred to as a nymph
The offspring of a seal is referred to as a pup
The offspring of a weasel is referred to as a kit
The offspring of a raccoon is referred to as a kit
The offspring of a gorilla is referred to as a infant
The offspring of a duck is referred to as a duckling
The offspring of a tiger is referred to as a
2024-07-30 18:43:31 root INFO     [order_1_approx] starting weight calculation for If something is too turned, it is overturned
If something is too simplified, it is oversimplified
If something is too arching, it is overarching
If something is too saturated, it is oversaturated
If something is too written, it is overwritten
If something is too booked, it is overbooked
If something is too developed, it is overdeveloped
If something is too ambitious, it is
2024-07-30 18:43:31 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 18:43:31 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-30 18:46:01 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0518,  0.2566, -0.2399,  ...,  0.1504, -0.1809,  0.0038],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.0566e+00, -5.1719e+00, -1.9883e+00,  ...,  9.7656e-04,
        -2.0293e+00,  8.5449e-01], device='cuda:1', dtype=torch.float16,
       grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0320, -0.0303, -0.0137,  ...,  0.0056, -0.0026, -0.0077],
        [ 0.0012,  0.0465,  0.0097,  ..., -0.0034, -0.0043, -0.0281],
        [ 0.0063, -0.0011,  0.0457,  ...,  0.0070,  0.0175, -0.0056],
        ...,
        [ 0.0063, -0.0016,  0.0176,  ...,  0.0420,  0.0080, -0.0156],
        [ 0.0039, -0.0140,  0.0164,  ...,  0.0196, -0.0007,  0.0065],
        [-0.0101, -0.0016, -0.0159,  ..., -0.0297, -0.0148,  0.0229]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.0469, -4.7227, -1.7334,  ...,  0.3354, -1.9443,  0.6782]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 18:46:02 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The offspring of a horse is referred to as a foal
The offspring of a cockroach is referred to as a nymph
The offspring of a seal is referred to as a pup
The offspring of a weasel is referred to as a kit
The offspring of a raccoon is referred to as a kit
The offspring of a gorilla is referred to as a infant
The offspring of a duck is referred to as a duckling
The offspring of a tiger is referred to as a
2024-07-30 18:46:02 root INFO     total operator prediction time: 1209.4347279071808 seconds
2024-07-30 18:46:02 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on animal - sound
2024-07-30 18:46:02 root INFO     building operator animal - sound
2024-07-30 18:46:02 root INFO     [order_1_approx] starting weight calculation for The sound that a deer makes is called a bellow
The sound that a wasp makes is called a buzz
The sound that a mallard makes is called a quack
The sound that a fly makes is called a buzz
The sound that a songbird makes is called a chirrup
The sound that a pig makes is called a oink
The sound that a lion makes is called a roar
The sound that a cicada makes is called a
2024-07-30 18:46:02 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 18:46:09 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1783,  0.1840, -0.2466,  ...,  0.0615, -0.2925, -0.1394],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.6055, -3.5781,  0.5908,  ...,  0.6572, -1.8613, -2.0586],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0160,  0.0089,  0.0033,  ...,  0.0003,  0.0019,  0.0070],
        [-0.0033,  0.0168,  0.0035,  ..., -0.0073, -0.0038,  0.0081],
        [ 0.0181,  0.0104,  0.0257,  ..., -0.0101,  0.0249, -0.0137],
        ...,
        [ 0.0129,  0.0191,  0.0028,  ...,  0.0061, -0.0017, -0.0094],
        [ 0.0210,  0.0110,  0.0114,  ...,  0.0002,  0.0119, -0.0177],
        [-0.0046, -0.0138, -0.0092,  ..., -0.0019, -0.0012,  0.0062]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.8359, -3.3262,  0.5435,  ...,  0.5513, -2.0703, -1.8809]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 18:46:10 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is too turned, it is overturned
If something is too simplified, it is oversimplified
If something is too arching, it is overarching
If something is too saturated, it is oversaturated
If something is too written, it is overwritten
If something is too booked, it is overbooked
If something is too developed, it is overdeveloped
If something is too ambitious, it is
2024-07-30 18:46:10 root INFO     [order_1_approx] starting weight calculation for If something is too arching, it is overarching
If something is too developed, it is overdeveloped
If something is too simplified, it is oversimplified
If something is too saturated, it is oversaturated
If something is too ambitious, it is overambitious
If something is too turned, it is overturned
If something is too written, it is overwritten
If something is too booked, it is
2024-07-30 18:46:11 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-30 18:48:28 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1616,  0.2705, -0.2639,  ..., -0.0872, -0.0309,  0.3474],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.5400, -2.9980,  3.8496,  ..., -0.9453, -1.7422,  1.3691],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0476, -0.0219,  0.0079,  ..., -0.0271, -0.0095,  0.0282],
        [-0.0058,  0.0399,  0.0065,  ...,  0.0203,  0.0214, -0.0321],
        [ 0.0138,  0.0260,  0.0393,  ...,  0.0116, -0.0355,  0.0127],
        ...,
        [-0.0002, -0.0046,  0.0214,  ...,  0.0455,  0.0041, -0.0199],
        [ 0.0034, -0.0009, -0.0040,  ..., -0.0071,  0.0205, -0.0163],
        [-0.0097, -0.0059, -0.0378,  ...,  0.0008,  0.0086,  0.0316]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.8818, -3.0840,  3.1426,  ..., -0.7725, -1.7158,  1.2266]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 18:48:29 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The sound that a deer makes is called a bellow
The sound that a wasp makes is called a buzz
The sound that a mallard makes is called a quack
The sound that a fly makes is called a buzz
The sound that a songbird makes is called a chirrup
The sound that a pig makes is called a oink
The sound that a lion makes is called a roar
The sound that a cicada makes is called a
2024-07-30 18:48:29 root INFO     [order_1_approx] starting weight calculation for The sound that a wasp makes is called a buzz
The sound that a cicada makes is called a buzz
The sound that a pig makes is called a oink
The sound that a lion makes is called a roar
The sound that a songbird makes is called a chirrup
The sound that a fly makes is called a buzz
The sound that a deer makes is called a bellow
The sound that a mallard makes is called a
2024-07-30 18:48:29 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 18:48:54 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0213, -0.1926, -0.1611,  ...,  0.0611, -0.0781,  0.2462],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.6885, -2.7383,  1.5127,  ...,  1.7715, -0.6523, -3.0801],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0201, -0.0154, -0.0139,  ..., -0.0029,  0.0023,  0.0083],
        [-0.0157,  0.0083,  0.0090,  ...,  0.0074,  0.0006, -0.0047],
        [ 0.0059,  0.0163,  0.0166,  ..., -0.0098,  0.0133, -0.0031],
        ...,
        [ 0.0057,  0.0083, -0.0031,  ...,  0.0339,  0.0159, -0.0043],
        [ 0.0055,  0.0171, -0.0158,  ..., -0.0009,  0.0172,  0.0023],
        [ 0.0005, -0.0023, -0.0011,  ...,  0.0040,  0.0058,  0.0202]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.1758, -2.4316,  1.1504,  ...,  1.8955, -0.6680, -3.2344]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 18:48:55 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is too arching, it is overarching
If something is too developed, it is overdeveloped
If something is too simplified, it is oversimplified
If something is too saturated, it is oversaturated
If something is too ambitious, it is overambitious
If something is too turned, it is overturned
If something is too written, it is overwritten
If something is too booked, it is
2024-07-30 18:48:55 root INFO     [order_1_approx] starting weight calculation for If something is too saturated, it is oversaturated
If something is too arching, it is overarching
If something is too booked, it is overbooked
If something is too ambitious, it is overambitious
If something is too simplified, it is oversimplified
If something is too developed, it is overdeveloped
If something is too turned, it is overturned
If something is too written, it is
2024-07-30 18:48:55 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-30 18:51:00 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2214,  0.0898, -0.3477,  ...,  0.3223, -0.4058,  0.0714],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.4673, -6.7305,  1.7197,  ...,  0.1113, -4.3594,  1.1309],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0265, -0.0379, -0.0008,  ..., -0.0044, -0.0170,  0.0004],
        [ 0.0023,  0.0399,  0.0078,  ...,  0.0320, -0.0013, -0.0202],
        [-0.0004,  0.0206,  0.0209,  ..., -0.0193, -0.0267, -0.0011],
        ...,
        [-0.0074,  0.0087, -0.0131,  ...,  0.0697,  0.0118, -0.0018],
        [ 0.0231,  0.0169, -0.0076,  ...,  0.0083,  0.0244,  0.0019],
        [ 0.0006,  0.0015, -0.0119,  ..., -0.0186, -0.0145,  0.0147]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.3589, -6.4453,  1.4951,  ..., -0.2183, -4.4609,  0.8154]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 18:51:01 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The sound that a wasp makes is called a buzz
The sound that a cicada makes is called a buzz
The sound that a pig makes is called a oink
The sound that a lion makes is called a roar
The sound that a songbird makes is called a chirrup
The sound that a fly makes is called a buzz
The sound that a deer makes is called a bellow
The sound that a mallard makes is called a
2024-07-30 18:51:01 root INFO     [order_1_approx] starting weight calculation for The sound that a deer makes is called a bellow
The sound that a pig makes is called a oink
The sound that a wasp makes is called a buzz
The sound that a lion makes is called a roar
The sound that a cicada makes is called a buzz
The sound that a mallard makes is called a quack
The sound that a songbird makes is called a chirrup
The sound that a fly makes is called a
2024-07-30 18:51:01 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 18:51:32 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0920, -0.1185, -0.1227,  ..., -0.2930, -0.3220, -0.0402],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.8047, -3.3008,  2.6113,  ..., -0.4146, -1.9395, -1.8926],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0255,  0.0182, -0.0104,  ...,  0.0045,  0.0172,  0.0127],
        [-0.0028,  0.0350,  0.0149,  ...,  0.0074, -0.0184,  0.0081],
        [ 0.0309,  0.0298,  0.0282,  ...,  0.0199,  0.0092, -0.0020],
        ...,
        [ 0.0131,  0.0201, -0.0030,  ...,  0.0444,  0.0013, -0.0099],
        [-0.0051,  0.0095,  0.0132,  ...,  0.0028,  0.0221,  0.0008],
        [ 0.0240,  0.0079,  0.0132,  ...,  0.0103, -0.0323,  0.0145]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.1797, -3.1504,  3.1777,  ..., -0.2534, -1.8184, -1.5801]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 18:51:33 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is too saturated, it is oversaturated
If something is too arching, it is overarching
If something is too booked, it is overbooked
If something is too ambitious, it is overambitious
If something is too simplified, it is oversimplified
If something is too developed, it is overdeveloped
If something is too turned, it is overturned
If something is too written, it is
2024-07-30 18:51:33 root INFO     [order_1_approx] starting weight calculation for If something is too simplified, it is oversimplified
If something is too booked, it is overbooked
If something is too arching, it is overarching
If something is too saturated, it is oversaturated
If something is too developed, it is overdeveloped
If something is too written, it is overwritten
If something is too ambitious, it is overambitious
If something is too turned, it is
2024-07-30 18:51:33 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-30 18:53:34 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0920, -0.1677, -0.4590,  ...,  0.2278,  0.1423,  0.4197],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.8906, -1.8350,  1.8242,  ..., -1.5078, -1.3525,  1.5381],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0433, -0.0137, -0.0283,  ..., -0.0004, -0.0248,  0.0019],
        [ 0.0039,  0.0526, -0.0085,  ...,  0.0125,  0.0123, -0.0242],
        [ 0.0029,  0.0200,  0.0440,  ..., -0.0275,  0.0029, -0.0037],
        ...,
        [ 0.0331, -0.0032,  0.0215,  ...,  0.0627,  0.0002, -0.0025],
        [ 0.0085,  0.0239,  0.0251,  ...,  0.0126,  0.0045,  0.0119],
        [ 0.0083,  0.0034, -0.0192,  ..., -0.0219, -0.0205,  0.0428]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.9150, -2.0312,  1.5967,  ..., -1.2998, -2.2109,  1.5283]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 18:53:35 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The sound that a deer makes is called a bellow
The sound that a pig makes is called a oink
The sound that a wasp makes is called a buzz
The sound that a lion makes is called a roar
The sound that a cicada makes is called a buzz
The sound that a mallard makes is called a quack
The sound that a songbird makes is called a chirrup
The sound that a fly makes is called a
2024-07-30 18:53:35 root INFO     [order_1_approx] starting weight calculation for The sound that a deer makes is called a bellow
The sound that a pig makes is called a oink
The sound that a songbird makes is called a chirrup
The sound that a lion makes is called a roar
The sound that a cicada makes is called a buzz
The sound that a mallard makes is called a quack
The sound that a fly makes is called a buzz
The sound that a wasp makes is called a
2024-07-30 18:53:36 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 18:54:17 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1666, -0.2142, -0.0538,  ...,  0.0972, -0.2021, -0.1160],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.4121, -3.7305,  2.2930,  ...,  0.6143, -1.3369, -1.3359],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0410,  0.0157,  0.0033,  ...,  0.0002,  0.0009,  0.0109],
        [-0.0132,  0.0255, -0.0100,  ...,  0.0021, -0.0171, -0.0067],
        [ 0.0027,  0.0057,  0.0340,  ...,  0.0222,  0.0025, -0.0100],
        ...,
        [ 0.0037,  0.0120,  0.0094,  ...,  0.0501,  0.0048,  0.0015],
        [ 0.0259, -0.0073,  0.0117,  ...,  0.0038,  0.0185, -0.0204],
        [-0.0098, -0.0023,  0.0086,  ..., -0.0096, -0.0233,  0.0294]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.8516, -3.4863,  1.9746,  ...,  0.3506, -1.9180, -1.2051]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 18:54:18 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is too simplified, it is oversimplified
If something is too booked, it is overbooked
If something is too arching, it is overarching
If something is too saturated, it is oversaturated
If something is too developed, it is overdeveloped
If something is too written, it is overwritten
If something is too ambitious, it is overambitious
If something is too turned, it is
2024-07-30 18:54:18 root INFO     [order_1_approx] starting weight calculation for If something is too simplified, it is oversimplified
If something is too saturated, it is oversaturated
If something is too written, it is overwritten
If something is too turned, it is overturned
If something is too arching, it is overarching
If something is too ambitious, it is overambitious
If something is too booked, it is overbooked
If something is too developed, it is
2024-07-30 18:54:18 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-30 18:56:09 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0775, -0.0042,  0.1282,  ...,  0.2573, -0.0791,  0.1450],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.2246, -2.4727,  1.9727,  ..., -1.2002,  0.0752,  2.2246],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0288, -0.0305, -0.0209,  ...,  0.0167, -0.0362, -0.0048],
        [-0.0171,  0.0655,  0.0056,  ...,  0.0021, -0.0077, -0.0007],
        [-0.0025,  0.0202,  0.0269,  ..., -0.0017, -0.0077, -0.0098],
        ...,
        [-0.0022, -0.0017,  0.0240,  ...,  0.0356, -0.0090, -0.0036],
        [-0.0216, -0.0077, -0.0008,  ...,  0.0163, -0.0067, -0.0015],
        [-0.0096,  0.0018, -0.0146,  ..., -0.0108, -0.0168,  0.0309]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.1934, -2.5664,  1.8740,  ..., -1.5674, -0.3940,  2.2676]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 18:56:10 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The sound that a deer makes is called a bellow
The sound that a pig makes is called a oink
The sound that a songbird makes is called a chirrup
The sound that a lion makes is called a roar
The sound that a cicada makes is called a buzz
The sound that a mallard makes is called a quack
The sound that a fly makes is called a buzz
The sound that a wasp makes is called a
2024-07-30 18:56:10 root INFO     [order_1_approx] starting weight calculation for The sound that a fly makes is called a buzz
The sound that a deer makes is called a bellow
The sound that a lion makes is called a roar
The sound that a mallard makes is called a quack
The sound that a songbird makes is called a chirrup
The sound that a wasp makes is called a buzz
The sound that a cicada makes is called a buzz
The sound that a pig makes is called a
2024-07-30 18:56:10 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 18:56:56 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2542, -0.1638, -0.2239,  ..., -0.0959, -0.2930,  0.0636],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.2266, -3.0059,  1.1953,  ...,  0.9570, -4.4141, -1.4824],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0225, -0.0013,  0.0054,  ..., -0.0012, -0.0115,  0.0148],
        [ 0.0016,  0.0463,  0.0041,  ..., -0.0057, -0.0005,  0.0114],
        [ 0.0013,  0.0067,  0.0138,  ..., -0.0317,  0.0105,  0.0153],
        ...,
        [ 0.0196,  0.0121, -0.0244,  ...,  0.0418, -0.0139, -0.0072],
        [ 0.0025, -0.0203,  0.0295,  ..., -0.0269,  0.0166,  0.0094],
        [-0.0077, -0.0057, -0.0031,  ...,  0.0310, -0.0124,  0.0175]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.2422, -2.7832,  1.0801,  ...,  0.9185, -4.2969, -1.3066]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 18:56:57 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is too simplified, it is oversimplified
If something is too saturated, it is oversaturated
If something is too written, it is overwritten
If something is too turned, it is overturned
If something is too arching, it is overarching
If something is too ambitious, it is overambitious
If something is too booked, it is overbooked
If something is too developed, it is
2024-07-30 18:56:57 root INFO     [order_1_approx] starting weight calculation for If something is too ambitious, it is overambitious
If something is too developed, it is overdeveloped
If something is too saturated, it is oversaturated
If something is too written, it is overwritten
If something is too turned, it is overturned
If something is too booked, it is overbooked
If something is too simplified, it is oversimplified
If something is too arching, it is
2024-07-30 18:56:57 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-30 18:58:43 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1376, -0.0155, -0.2751,  ...,  0.0380, -0.0828,  0.1980],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.4316, -1.9756,  2.9570,  ..., -2.2520,  0.6265,  1.9277],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0413, -0.0030, -0.0064,  ..., -0.0219, -0.0130, -0.0275],
        [ 0.0008,  0.0408,  0.0098,  ..., -0.0078, -0.0166, -0.0282],
        [ 0.0009, -0.0024,  0.0317,  ..., -0.0246, -0.0173,  0.0036],
        ...,
        [ 0.0301, -0.0014,  0.0073,  ...,  0.0287, -0.0176,  0.0079],
        [ 0.0129,  0.0180,  0.0045,  ...,  0.0366,  0.0271,  0.0048],
        [ 0.0100, -0.0186,  0.0053,  ..., -0.0270,  0.0039,  0.0174]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.5020, -2.1152,  2.6992,  ..., -2.2520,  0.4297,  1.6846]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 18:58:45 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The sound that a fly makes is called a buzz
The sound that a deer makes is called a bellow
The sound that a lion makes is called a roar
The sound that a mallard makes is called a quack
The sound that a songbird makes is called a chirrup
The sound that a wasp makes is called a buzz
The sound that a cicada makes is called a buzz
The sound that a pig makes is called a
2024-07-30 18:58:45 root INFO     [order_1_approx] starting weight calculation for The sound that a wasp makes is called a buzz
The sound that a mallard makes is called a quack
The sound that a pig makes is called a oink
The sound that a deer makes is called a bellow
The sound that a songbird makes is called a chirrup
The sound that a fly makes is called a buzz
The sound that a cicada makes is called a buzz
The sound that a lion makes is called a
2024-07-30 18:58:45 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 18:59:32 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0433, -0.4766,  0.0792,  ...,  0.0086, -0.4871, -0.5391],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.5469, -3.2051,  2.3301,  ...,  0.5977, -1.1123, -2.7773],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0485,  0.0010, -0.0105,  ...,  0.0040,  0.0057,  0.0077],
        [ 0.0012,  0.0370,  0.0014,  ...,  0.0156, -0.0015,  0.0044],
        [-0.0190,  0.0004,  0.0381,  ...,  0.0073,  0.0084, -0.0164],
        ...,
        [ 0.0142,  0.0237,  0.0036,  ...,  0.0516,  0.0007,  0.0056],
        [ 0.0280, -0.0236,  0.0278,  ..., -0.0141,  0.0530,  0.0022],
        [-0.0411,  0.0035, -0.0098,  ..., -0.0013, -0.0251,  0.0214]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.8164, -3.0820,  2.0078,  ...,  0.7720, -1.2451, -2.7441]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 18:59:32 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is too ambitious, it is overambitious
If something is too developed, it is overdeveloped
If something is too saturated, it is oversaturated
If something is too written, it is overwritten
If something is too turned, it is overturned
If something is too booked, it is overbooked
If something is too simplified, it is oversimplified
If something is too arching, it is
2024-07-30 18:59:33 root INFO     [order_1_approx] starting weight calculation for If something is too booked, it is overbooked
If something is too turned, it is overturned
If something is too written, it is overwritten
If something is too developed, it is overdeveloped
If something is too simplified, it is oversimplified
If something is too arching, it is overarching
If something is too ambitious, it is overambitious
If something is too saturated, it is
2024-07-30 18:59:33 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-30 19:01:15 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0451,  0.1071, -0.2478,  ...,  0.0586, -0.1180,  0.0809],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.7402, -8.4062, -0.6455,  ..., -2.4219,  1.6523,  0.8828],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0287, -0.0217,  0.0129,  ..., -0.0229,  0.0057,  0.0024],
        [-0.0072,  0.0419, -0.0065,  ...,  0.0099, -0.0004, -0.0171],
        [-0.0176,  0.0067,  0.0307,  ..., -0.0424,  0.0139,  0.0133],
        ...,
        [-0.0053,  0.0147,  0.0176,  ...,  0.0545,  0.0154, -0.0140],
        [ 0.0197, -0.0121, -0.0209,  ...,  0.0136,  0.0151, -0.0046],
        [-0.0080, -0.0103, -0.0248,  ..., -0.0283, -0.0220,  0.0071]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.8477, -8.4609, -0.3274,  ..., -2.3262,  1.2998,  0.7041]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 19:01:16 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The sound that a wasp makes is called a buzz
The sound that a mallard makes is called a quack
The sound that a pig makes is called a oink
The sound that a deer makes is called a bellow
The sound that a songbird makes is called a chirrup
The sound that a fly makes is called a buzz
The sound that a cicada makes is called a buzz
The sound that a lion makes is called a
2024-07-30 19:01:16 root INFO     [order_1_approx] starting weight calculation for The sound that a wasp makes is called a buzz
The sound that a mallard makes is called a quack
The sound that a lion makes is called a roar
The sound that a fly makes is called a buzz
The sound that a pig makes is called a oink
The sound that a deer makes is called a bellow
The sound that a cicada makes is called a buzz
The sound that a songbird makes is called a
2024-07-30 19:01:16 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 19:02:11 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1604, -0.2749,  0.0065,  ...,  0.4160, -0.4006, -0.2881],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.2930, -2.9688,  0.0039,  ..., -1.9043, -2.4570, -0.5977],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 2.8885e-02,  2.2644e-02, -2.7657e-03,  ..., -2.1774e-02,
         -1.6907e-02,  2.0416e-02],
        [ 8.3237e-03,  2.8107e-02,  1.3229e-02,  ..., -5.9319e-03,
         -1.6998e-02, -8.5907e-03],
        [ 1.2222e-02,  1.2299e-02,  1.0704e-02,  ..., -9.5673e-03,
          6.1035e-05,  1.3023e-02],
        ...,
        [ 1.0620e-02,  2.4490e-03,  1.8631e-02,  ...,  4.7211e-02,
         -6.0272e-03,  1.1299e-02],
        [-1.1299e-02, -1.0178e-02,  1.9653e-02,  ..., -8.9111e-03,
          2.4292e-02, -1.3809e-02],
        [-2.6970e-03,  2.3270e-03,  1.0742e-02,  ..., -3.9673e-03,
         -9.3536e-03,  3.3020e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.7500, -2.9590,  0.3435,  ..., -1.9902, -2.8008, -0.9355]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 19:02:14 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is too booked, it is overbooked
If something is too turned, it is overturned
If something is too written, it is overwritten
If something is too developed, it is overdeveloped
If something is too simplified, it is oversimplified
If something is too arching, it is overarching
If something is too ambitious, it is overambitious
If something is too saturated, it is
2024-07-30 19:02:14 root INFO     [order_1_approx] starting weight calculation for If something is too written, it is overwritten
If something is too ambitious, it is overambitious
If something is too developed, it is overdeveloped
If something is too arching, it is overarching
If something is too turned, it is overturned
If something is too saturated, it is oversaturated
If something is too booked, it is overbooked
If something is too simplified, it is
2024-07-30 19:02:14 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-30 19:03:44 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0774,  0.2961,  0.0317,  ...,  0.1813, -0.2140, -0.2314],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.2979, -5.1797,  2.6836,  ...,  0.1572, -0.6680, -0.9033],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0321,  0.0055, -0.0108,  ...,  0.0006, -0.0172,  0.0106],
        [-0.0086,  0.0316,  0.0224,  ...,  0.0262,  0.0187, -0.0262],
        [ 0.0011,  0.0079,  0.0279,  ..., -0.0054, -0.0082,  0.0203],
        ...,
        [-0.0182, -0.0034,  0.0058,  ...,  0.0378,  0.0051, -0.0123],
        [ 0.0072,  0.0124,  0.0061,  ...,  0.0179,  0.0062,  0.0028],
        [-0.0264, -0.0046, -0.0121,  ..., -0.0299,  0.0099,  0.0395]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.3057, -5.5234,  3.0234,  ...,  0.0771, -1.1133, -0.7632]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 19:03:45 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The sound that a wasp makes is called a buzz
The sound that a mallard makes is called a quack
The sound that a lion makes is called a roar
The sound that a fly makes is called a buzz
The sound that a pig makes is called a oink
The sound that a deer makes is called a bellow
The sound that a cicada makes is called a buzz
The sound that a songbird makes is called a
2024-07-30 19:03:45 root INFO     [order_1_approx] starting weight calculation for The sound that a songbird makes is called a chirrup
The sound that a wasp makes is called a buzz
The sound that a cicada makes is called a buzz
The sound that a lion makes is called a roar
The sound that a mallard makes is called a quack
The sound that a fly makes is called a buzz
The sound that a pig makes is called a oink
The sound that a deer makes is called a
2024-07-30 19:03:45 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 19:04:52 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0624,  0.2810, -0.2507,  ..., -0.1024, -0.0894, -0.0502],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.2988, -2.0234,  1.2842,  ..., -1.5654, -3.5312, -0.2793],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0300,  0.0229,  0.0299,  ..., -0.0019, -0.0111,  0.0290],
        [ 0.0207,  0.0343,  0.0079,  ..., -0.0040, -0.0236, -0.0024],
        [-0.0075, -0.0012,  0.0075,  ...,  0.0182, -0.0215, -0.0098],
        ...,
        [ 0.0343,  0.0129,  0.0051,  ...,  0.0466, -0.0043,  0.0010],
        [ 0.0231, -0.0284,  0.0181,  ..., -0.0054, -0.0157, -0.0177],
        [ 0.0110,  0.0224,  0.0049,  ..., -0.0184, -0.0243,  0.0123]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.3711, -2.2363,  1.1729,  ..., -1.1357, -3.3574, -0.4712]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 19:04:53 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is too written, it is overwritten
If something is too ambitious, it is overambitious
If something is too developed, it is overdeveloped
If something is too arching, it is overarching
If something is too turned, it is overturned
If something is too saturated, it is oversaturated
If something is too booked, it is overbooked
If something is too simplified, it is
2024-07-30 19:04:53 root INFO     total operator prediction time: 1282.3354096412659 seconds
2024-07-30 19:04:53 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on verb+er_irreg
2024-07-30 19:04:53 root INFO     building operator verb+er_irreg
2024-07-30 19:04:53 root INFO     [order_1_approx] starting weight calculation for If you teach something, you are a teacher
If you compose something, you are a composer
If you intrude something, you are a intruder
If you discover something, you are a discoverer
If you contend something, you are a contender
If you publish something, you are a publisher
If you bake something, you are a baker
If you examine something, you are a
2024-07-30 19:04:53 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-30 19:06:17 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0439,  0.1761, -0.2534,  ...,  0.1396, -0.4688,  0.2983],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.6021, -2.0449, -0.8965,  ..., -0.3472, -1.8027, -0.6328],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0371, -0.0128, -0.0082,  ..., -0.0113, -0.0188,  0.0010],
        [ 0.0082,  0.0423,  0.0027,  ...,  0.0243, -0.0086, -0.0281],
        [-0.0283,  0.0142,  0.0308,  ..., -0.0287, -0.0092,  0.0058],
        ...,
        [ 0.0037,  0.0350,  0.0121,  ...,  0.0683, -0.0076, -0.0116],
        [ 0.0106,  0.0187, -0.0001,  ..., -0.0173,  0.0377, -0.0059],
        [-0.0005, -0.0091, -0.0033,  ..., -0.0206, -0.0217,  0.0206]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.6411, -2.2500, -0.7383,  ..., -0.5898, -1.7188, -1.1172]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 19:06:18 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The sound that a songbird makes is called a chirrup
The sound that a wasp makes is called a buzz
The sound that a cicada makes is called a buzz
The sound that a lion makes is called a roar
The sound that a mallard makes is called a quack
The sound that a fly makes is called a buzz
The sound that a pig makes is called a oink
The sound that a deer makes is called a
2024-07-30 19:06:18 root INFO     total operator prediction time: 1215.9790716171265 seconds
2024-07-30 19:06:18 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on things - color
2024-07-30 19:06:18 root INFO     building operator things - color
2024-07-30 19:06:18 root INFO     [order_1_approx] starting weight calculation for The toothpaste is colored white
The cranberry is colored red
The spinach is colored green
The blood is colored red
The milk is colored white
The pepper is colored black
The peony is colored red
The raven is colored
2024-07-30 19:06:18 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 19:07:32 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1338, -0.0232, -0.1846,  ..., -0.1165,  0.2317, -0.3213],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.0000, -2.7988,  3.3633,  ..., -1.8271, -3.9961, -5.7656],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0279, -0.0082,  0.0402,  ...,  0.0087, -0.0155, -0.0050],
        [-0.0334,  0.0424,  0.0103,  ...,  0.0173,  0.0087,  0.0019],
        [ 0.0194, -0.0305, -0.0081,  ..., -0.0083, -0.0080,  0.0503],
        ...,
        [ 0.0156,  0.0213,  0.0021,  ...,  0.0296, -0.0042, -0.0284],
        [-0.0165, -0.0118, -0.0119,  ..., -0.0026, -0.0016,  0.0140],
        [ 0.0283,  0.0077, -0.0005,  ...,  0.0062, -0.0423, -0.0016]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.8516, -2.8906,  2.8691,  ..., -1.9492, -4.1250, -5.5469]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 19:07:55 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you teach something, you are a teacher
If you compose something, you are a composer
If you intrude something, you are a intruder
If you discover something, you are a discoverer
If you contend something, you are a contender
If you publish something, you are a publisher
If you bake something, you are a baker
If you examine something, you are a
2024-07-30 19:07:55 root INFO     [order_1_approx] starting weight calculation for If you contend something, you are a contender
If you compose something, you are a composer
If you discover something, you are a discoverer
If you examine something, you are a examiner
If you intrude something, you are a intruder
If you publish something, you are a publisher
If you teach something, you are a teacher
If you bake something, you are a
2024-07-30 19:07:55 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-30 19:08:49 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2021,  0.1311, -0.2300,  ...,  0.1846, -0.0605,  0.1901],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.0977, -3.2188,  2.2227,  ...,  0.3535,  2.3730, -1.6719],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0575,  0.0140, -0.0016,  ...,  0.0100,  0.0099, -0.0072],
        [-0.0109,  0.0247,  0.0421,  ...,  0.0352, -0.0266, -0.0216],
        [-0.0013, -0.0192,  0.0623,  ...,  0.0091, -0.0085, -0.0007],
        ...,
        [ 0.0100,  0.0152,  0.0222,  ...,  0.0918, -0.0152, -0.0022],
        [ 0.0098,  0.0222,  0.0163,  ...,  0.0490,  0.0306, -0.0185],
        [-0.0114, -0.0121, -0.0255,  ..., -0.0096, -0.0355,  0.0461]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.7070, -3.6133,  1.8975,  ..., -0.0264,  1.5654, -1.4473]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 19:08:50 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The toothpaste is colored white
The cranberry is colored red
The spinach is colored green
The blood is colored red
The milk is colored white
The pepper is colored black
The peony is colored red
The raven is colored
2024-07-30 19:08:50 root INFO     [order_1_approx] starting weight calculation for The toothpaste is colored white
The spinach is colored green
The pepper is colored black
The cranberry is colored red
The raven is colored black
The blood is colored red
The peony is colored red
The milk is colored
2024-07-30 19:08:50 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 19:10:31 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0727,  0.2439, -0.0669,  ..., -0.1351, -0.4395, -0.2891],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.8008, -3.5000,  0.4185,  ...,  0.8096, -3.5137, -2.9668],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0165, -0.0141,  0.0012,  ..., -0.0148,  0.0007,  0.0084],
        [-0.0061,  0.0362,  0.0090,  ...,  0.0135, -0.0026,  0.0060],
        [-0.0022, -0.0050,  0.0188,  ..., -0.0066,  0.0237,  0.0139],
        ...,
        [ 0.0029,  0.0202,  0.0061,  ...,  0.0381,  0.0117, -0.0003],
        [-0.0044,  0.0183, -0.0118,  ...,  0.0025,  0.0087, -0.0277],
        [ 0.0018,  0.0033, -0.0155,  ..., -0.0186, -0.0013,  0.0042]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.9180, -3.3613,  0.4883,  ...,  0.8525, -3.3730, -3.0117]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 19:10:32 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you contend something, you are a contender
If you compose something, you are a composer
If you discover something, you are a discoverer
If you examine something, you are a examiner
If you intrude something, you are a intruder
If you publish something, you are a publisher
If you teach something, you are a teacher
If you bake something, you are a
2024-07-30 19:10:32 root INFO     [order_1_approx] starting weight calculation for If you compose something, you are a composer
If you publish something, you are a publisher
If you examine something, you are a examiner
If you discover something, you are a discoverer
If you intrude something, you are a intruder
If you bake something, you are a baker
If you contend something, you are a contender
If you teach something, you are a
2024-07-30 19:10:32 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-30 19:11:24 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1458, -0.4458, -0.2944,  ...,  0.0803, -0.2986,  0.1737],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.7188, -3.1172,  0.5762,  ..., -1.5664, -1.6172, -0.8848],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0543,  0.0276,  0.0111,  ..., -0.0064,  0.0132,  0.0199],
        [-0.0134,  0.0500,  0.0107,  ..., -0.0086, -0.0046, -0.0070],
        [-0.0078,  0.0018,  0.0363,  ...,  0.0209,  0.0004,  0.0142],
        ...,
        [-0.0030,  0.0078,  0.0024,  ...,  0.0455, -0.0064,  0.0029],
        [-0.0153,  0.0117,  0.0033,  ...,  0.0183,  0.0381,  0.0067],
        [-0.0076, -0.0139,  0.0013,  ..., -0.0051, -0.0120,  0.0211]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.5703, -3.1211,  0.6060,  ..., -1.6113, -1.7148, -0.4563]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 19:11:25 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The toothpaste is colored white
The spinach is colored green
The pepper is colored black
The cranberry is colored red
The raven is colored black
The blood is colored red
The peony is colored red
The milk is colored
2024-07-30 19:11:25 root INFO     [order_1_approx] starting weight calculation for The spinach is colored green
The raven is colored black
The pepper is colored black
The milk is colored white
The cranberry is colored red
The toothpaste is colored white
The peony is colored red
The blood is colored
2024-07-30 19:11:25 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 19:13:03 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1417,  0.3240, -0.1337,  ...,  0.0546, -0.2014, -0.2427],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.5000, -3.8906,  5.1680,  ...,  2.2852, -2.8438, -6.0898],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0153,  0.0054,  0.0126,  ..., -0.0051,  0.0130,  0.0112],
        [-0.0042,  0.0181, -0.0065,  ..., -0.0091,  0.0100, -0.0008],
        [-0.0138,  0.0011,  0.0105,  ...,  0.0031,  0.0015, -0.0005],
        ...,
        [ 0.0104,  0.0180,  0.0069,  ...,  0.0022, -0.0030, -0.0016],
        [ 0.0082,  0.0097, -0.0094,  ..., -0.0010,  0.0025, -0.0023],
        [ 0.0184, -0.0092,  0.0072,  ...,  0.0124, -0.0133,  0.0005]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.3770, -3.9902,  5.1328,  ...,  2.1523, -2.8633, -6.0898]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 19:13:04 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you compose something, you are a composer
If you publish something, you are a publisher
If you examine something, you are a examiner
If you discover something, you are a discoverer
If you intrude something, you are a intruder
If you bake something, you are a baker
If you contend something, you are a contender
If you teach something, you are a
2024-07-30 19:13:04 root INFO     [order_1_approx] starting weight calculation for If you examine something, you are a examiner
If you teach something, you are a teacher
If you publish something, you are a publisher
If you bake something, you are a baker
If you contend something, you are a contender
If you discover something, you are a discoverer
If you compose something, you are a composer
If you intrude something, you are a
2024-07-30 19:13:04 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-30 19:13:50 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0132, -0.3320, -0.6216,  ..., -0.1578, -0.3538,  0.0981],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.5283, -8.8281, -2.0234,  ..., -1.5527,  0.4902, -1.6982],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 5.2094e-02,  8.2703e-03,  2.1988e-02,  ..., -4.4250e-03,
          1.5259e-02, -2.4700e-03],
        [ 2.7180e-03,  9.7885e-03, -4.1809e-03,  ..., -7.0724e-03,
          1.3000e-02, -1.2108e-02],
        [ 4.5166e-03, -2.9736e-03,  3.0640e-02,  ..., -3.1109e-03,
         -1.8616e-02,  2.4246e-02],
        ...,
        [-9.3536e-03,  1.2951e-03,  4.1962e-05,  ...,  3.7109e-02,
         -1.8524e-02, -2.9964e-03],
        [-2.1225e-02,  4.4098e-02,  1.1017e-02,  ...,  2.2491e-02,
          3.3539e-02, -5.4054e-03],
        [ 1.3447e-03, -2.3163e-02, -4.8904e-03,  ..., -1.1345e-02,
         -3.1097e-02,  3.0518e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.2959, -8.7812, -1.5488,  ..., -1.5479,  0.3523, -1.4863]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 19:13:51 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The spinach is colored green
The raven is colored black
The pepper is colored black
The milk is colored white
The cranberry is colored red
The toothpaste is colored white
The peony is colored red
The blood is colored
2024-07-30 19:13:51 root INFO     [order_1_approx] starting weight calculation for The spinach is colored green
The milk is colored white
The peony is colored red
The blood is colored red
The toothpaste is colored white
The raven is colored black
The cranberry is colored red
The pepper is colored
2024-07-30 19:13:52 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 19:15:43 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0257,  0.0594, -0.3291,  ...,  0.2566, -0.0025,  0.2502],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 5.7383, -3.3320, -0.0557,  ..., -1.1484, -4.1758, -2.4395],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0351,  0.0198,  0.0311,  ..., -0.0042,  0.0172, -0.0016],
        [-0.0051,  0.0472,  0.0353,  ..., -0.0070, -0.0046,  0.0206],
        [-0.0134, -0.0085,  0.0151,  ..., -0.0003,  0.0364, -0.0057],
        ...,
        [-0.0065,  0.0225,  0.0122,  ...,  0.0322, -0.0208,  0.0155],
        [ 0.0016,  0.0071,  0.0494,  ...,  0.0023,  0.0232, -0.0113],
        [ 0.0266, -0.0016, -0.0042,  ..., -0.0097, -0.0068,  0.0167]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 5.8398, -3.7832,  0.6147,  ..., -0.5156, -3.9863, -1.9199]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 19:15:44 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you examine something, you are a examiner
If you teach something, you are a teacher
If you publish something, you are a publisher
If you bake something, you are a baker
If you contend something, you are a contender
If you discover something, you are a discoverer
If you compose something, you are a composer
If you intrude something, you are a
2024-07-30 19:15:44 root INFO     [order_1_approx] starting weight calculation for If you discover something, you are a discoverer
If you bake something, you are a baker
If you examine something, you are a examiner
If you compose something, you are a composer
If you teach something, you are a teacher
If you publish something, you are a publisher
If you intrude something, you are a intruder
If you contend something, you are a
2024-07-30 19:15:44 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-30 19:16:23 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.6108, -0.1838, -0.5527,  ..., -0.0829, -0.5312,  0.1526],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-2.6406, -7.2578, -1.3652,  ..., -1.8623, -1.4912, -2.5078],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 7.0496e-02,  1.6418e-02,  1.4282e-02,  ..., -2.8412e-02,
          4.0710e-02,  2.1545e-02],
        [ 4.7226e-03,  5.3253e-02,  2.5772e-02,  ..., -8.4877e-05,
          1.9974e-02,  6.3992e-04],
        [-1.0025e-02, -1.1925e-02,  3.3539e-02,  ...,  3.8208e-02,
         -2.6657e-02,  1.5106e-02],
        ...,
        [ 5.9929e-03, -3.0670e-03,  1.3535e-02,  ...,  8.8379e-02,
         -1.6830e-02, -7.1793e-03],
        [ 2.9114e-02, -1.1688e-02, -4.0863e-02,  ...,  2.8687e-02,
          3.9581e-02, -2.5879e-02],
        [-2.7283e-02, -5.0964e-03, -1.2894e-02,  ..., -1.7609e-02,
         -3.7918e-03,  3.2654e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-2.5723, -6.9805, -1.4170,  ..., -2.1875, -1.5967, -1.9346]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 19:16:24 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The spinach is colored green
The milk is colored white
The peony is colored red
The blood is colored red
The toothpaste is colored white
The raven is colored black
The cranberry is colored red
The pepper is colored
2024-07-30 19:16:24 root INFO     [order_1_approx] starting weight calculation for The pepper is colored black
The blood is colored red
The toothpaste is colored white
The cranberry is colored red
The spinach is colored green
The raven is colored black
The milk is colored white
The peony is colored
2024-07-30 19:16:24 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 19:18:23 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2847,  0.3652, -0.1918,  ..., -0.0634, -0.1178,  0.0095],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.6514, -5.9766,  1.7969,  ..., -2.0059, -0.9292, -2.3750],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0034,  0.0058,  0.0283,  ...,  0.0020,  0.0124,  0.0001],
        [-0.0134,  0.0234,  0.0005,  ..., -0.0035,  0.0277,  0.0013],
        [ 0.0115,  0.0165,  0.0210,  ..., -0.0115,  0.0022,  0.0015],
        ...,
        [-0.0050,  0.0377,  0.0114,  ...,  0.0096,  0.0336, -0.0023],
        [-0.0073,  0.0188,  0.0167,  ...,  0.0021,  0.0294, -0.0333],
        [ 0.0348, -0.0161, -0.0066,  ..., -0.0030, -0.0387,  0.0191]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.9561, -6.1250,  2.0000,  ..., -1.8193, -1.0215, -2.3594]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 19:18:23 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you discover something, you are a discoverer
If you bake something, you are a baker
If you examine something, you are a examiner
If you compose something, you are a composer
If you teach something, you are a teacher
If you publish something, you are a publisher
If you intrude something, you are a intruder
If you contend something, you are a
2024-07-30 19:18:24 root INFO     [order_1_approx] starting weight calculation for If you bake something, you are a baker
If you intrude something, you are a intruder
If you teach something, you are a teacher
If you contend something, you are a contender
If you publish something, you are a publisher
If you compose something, you are a composer
If you examine something, you are a examiner
If you discover something, you are a
2024-07-30 19:18:24 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-30 19:18:57 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0933,  0.0191, -0.8735,  ..., -0.1917, -0.1714, -0.0305],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.2744, -3.5938,  1.9795,  ...,  0.1450, -2.6934,  1.3682],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0711, -0.0063,  0.0123,  ...,  0.0027,  0.0123,  0.0069],
        [-0.0196,  0.0307,  0.0400,  ..., -0.0061,  0.0024, -0.0091],
        [-0.0067,  0.0249,  0.0573,  ...,  0.0221, -0.0128,  0.0191],
        ...,
        [ 0.0110, -0.0154, -0.0042,  ...,  0.0637, -0.0232, -0.0007],
        [-0.0002,  0.0124, -0.0009,  ...,  0.0155,  0.0564, -0.0235],
        [-0.0338,  0.0035, -0.0020,  ..., -0.0050, -0.0003,  0.0369]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.1182, -3.3027,  1.8096,  ...,  0.5361, -2.9043,  1.4053]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 19:18:58 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The pepper is colored black
The blood is colored red
The toothpaste is colored white
The cranberry is colored red
The spinach is colored green
The raven is colored black
The milk is colored white
The peony is colored
2024-07-30 19:18:58 root INFO     [order_1_approx] starting weight calculation for The toothpaste is colored white
The pepper is colored black
The blood is colored red
The milk is colored white
The spinach is colored green
The peony is colored red
The raven is colored black
The cranberry is colored
2024-07-30 19:18:58 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 19:21:01 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0088,  0.1687,  0.0591,  ..., -0.0533, -0.1456, -0.1984],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.6328, -4.2344,  1.6016,  ..., -0.0879, -5.5781, -0.8955],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0006, -0.0014,  0.0128,  ...,  0.0259,  0.0340,  0.0142],
        [-0.0063,  0.0216, -0.0021,  ..., -0.0035, -0.0092, -0.0116],
        [ 0.0095, -0.0137,  0.0109,  ...,  0.0083, -0.0307,  0.0017],
        ...,
        [ 0.0203,  0.0114,  0.0178,  ...,  0.0295, -0.0067, -0.0015],
        [ 0.0070, -0.0222, -0.0035,  ..., -0.0161, -0.0089,  0.0068],
        [ 0.0205,  0.0096, -0.0011,  ...,  0.0076, -0.0420, -0.0042]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.8223, -4.2617,  0.9258,  ..., -0.1472, -5.6680, -1.2666]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 19:21:02 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you bake something, you are a baker
If you intrude something, you are a intruder
If you teach something, you are a teacher
If you contend something, you are a contender
If you publish something, you are a publisher
If you compose something, you are a composer
If you examine something, you are a examiner
If you discover something, you are a
2024-07-30 19:21:02 root INFO     [order_1_approx] starting weight calculation for If you intrude something, you are a intruder
If you discover something, you are a discoverer
If you contend something, you are a contender
If you bake something, you are a baker
If you examine something, you are a examiner
If you teach something, you are a teacher
If you publish something, you are a publisher
If you compose something, you are a
2024-07-30 19:21:02 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-30 19:21:31 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2642, -0.5708, -0.8613,  ...,  0.0532, -0.4666, -0.1484],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-3.9375, -6.1172, -1.5430,  ..., -0.8540,  0.3784, -0.2764],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0490, -0.0235, -0.0089,  ..., -0.0188,  0.0200, -0.0002],
        [-0.0120,  0.0328,  0.0271,  ...,  0.0161,  0.0151, -0.0140],
        [ 0.0062, -0.0054,  0.0335,  ...,  0.0204, -0.0171,  0.0082],
        ...,
        [ 0.0013,  0.0024,  0.0027,  ...,  0.0817, -0.0144,  0.0052],
        [-0.0098,  0.0003,  0.0030,  ...,  0.0269,  0.0208,  0.0172],
        [-0.0194,  0.0056,  0.0019,  ..., -0.0163, -0.0026,  0.0404]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-3.6504, -5.9883, -1.4082,  ..., -0.8984, -0.0496, -0.3677]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 19:21:31 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The toothpaste is colored white
The pepper is colored black
The blood is colored red
The milk is colored white
The spinach is colored green
The peony is colored red
The raven is colored black
The cranberry is colored
2024-07-30 19:21:32 root INFO     [order_1_approx] starting weight calculation for The peony is colored red
The cranberry is colored red
The milk is colored white
The spinach is colored green
The blood is colored red
The pepper is colored black
The raven is colored black
The toothpaste is colored
2024-07-30 19:21:32 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 19:23:33 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1818, -0.0948, -0.2419,  ..., -0.2798,  0.0329, -0.1841],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.1406, -2.5566,  0.9990,  ...,  0.1328, -3.1992,  0.4492],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0124, -0.0036,  0.0223,  ...,  0.0381, -0.0155, -0.0047],
        [-0.0115,  0.0210, -0.0276,  ...,  0.0333,  0.0064, -0.0171],
        [ 0.0205,  0.0029, -0.0034,  ..., -0.0167, -0.0016, -0.0059],
        ...,
        [ 0.0006,  0.0469,  0.0160,  ...,  0.0242,  0.0140, -0.0293],
        [ 0.0178,  0.0023, -0.0136,  ..., -0.0100,  0.0224,  0.0067],
        [ 0.0303, -0.0034,  0.0164,  ...,  0.0009, -0.0304,  0.0023]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.1113, -2.6602,  0.7388,  ...,  0.1995, -3.3438,  0.1558]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 19:23:34 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you intrude something, you are a intruder
If you discover something, you are a discoverer
If you contend something, you are a contender
If you bake something, you are a baker
If you examine something, you are a examiner
If you teach something, you are a teacher
If you publish something, you are a publisher
If you compose something, you are a
2024-07-30 19:23:34 root INFO     [order_1_approx] starting weight calculation for If you bake something, you are a baker
If you discover something, you are a discoverer
If you compose something, you are a composer
If you intrude something, you are a intruder
If you teach something, you are a teacher
If you contend something, you are a contender
If you examine something, you are a examiner
If you publish something, you are a
2024-07-30 19:23:34 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-30 19:24:03 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0506, -0.4214, -0.4233,  ..., -0.0598, -0.4011, -0.2433],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.8281, -1.9219,  0.1992,  ...,  1.0264, -3.6953, -0.0195],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0497,  0.0180,  0.0099,  ..., -0.0005, -0.0249,  0.0095],
        [ 0.0042,  0.0534, -0.0081,  ...,  0.0055, -0.0134, -0.0140],
        [-0.0066, -0.0125,  0.0199,  ...,  0.0078, -0.0080, -0.0135],
        ...,
        [-0.0031,  0.0329,  0.0077,  ...,  0.0269, -0.0135,  0.0070],
        [-0.0091,  0.0277, -0.0092,  ...,  0.0225,  0.0240, -0.0118],
        [ 0.0209, -0.0298,  0.0023,  ...,  0.0047,  0.0001,  0.0282]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.8125, -2.5547,  0.2471,  ...,  1.1924, -3.8008,  0.1808]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 19:24:04 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The peony is colored red
The cranberry is colored red
The milk is colored white
The spinach is colored green
The blood is colored red
The pepper is colored black
The raven is colored black
The toothpaste is colored
2024-07-30 19:24:04 root INFO     [order_1_approx] starting weight calculation for The cranberry is colored red
The milk is colored white
The pepper is colored black
The blood is colored red
The toothpaste is colored white
The peony is colored red
The raven is colored black
The spinach is colored
2024-07-30 19:24:04 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 19:26:10 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2478,  0.1438, -0.2413,  ...,  0.2678,  0.2401,  0.0024],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.2930, -3.1758,  0.3057,  ...,  2.2500, -4.3438, -1.9834],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0287, -0.0168,  0.0090,  ...,  0.0165,  0.0014,  0.0078],
        [-0.0050,  0.0208,  0.0058,  ..., -0.0113,  0.0049, -0.0058],
        [ 0.0053, -0.0021,  0.0217,  ..., -0.0034,  0.0053,  0.0165],
        ...,
        [ 0.0056,  0.0286, -0.0041,  ...,  0.0381,  0.0113, -0.0154],
        [ 0.0008,  0.0039, -0.0146,  ..., -0.0081,  0.0165,  0.0037],
        [ 0.0235,  0.0210,  0.0229,  ..., -0.0078, -0.0211,  0.0137]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.5781, -3.3047,  0.2607,  ...,  2.1719, -4.5391, -2.2246]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 19:26:11 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you bake something, you are a baker
If you discover something, you are a discoverer
If you compose something, you are a composer
If you intrude something, you are a intruder
If you teach something, you are a teacher
If you contend something, you are a contender
If you examine something, you are a examiner
If you publish something, you are a
2024-07-30 19:26:11 root INFO     total operator prediction time: 1278.8008193969727 seconds
2024-07-30 19:26:11 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on adj - superlative
2024-07-30 19:26:11 root INFO     building operator adj - superlative
2024-07-30 19:26:12 root INFO     [order_1_approx] starting weight calculation for If something is the most lazy, it is laziest
If something is the most vague, it is vaguest
If something is the most sad, it is saddest
If something is the most able, it is ablest
If something is the most tricky, it is trickiest
If something is the most subtle, it is subtlest
If something is the most wealthy, it is wealthiest
If something is the most polite, it is
2024-07-30 19:26:12 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-30 19:26:38 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2852, -0.1040, -0.3999,  ..., -0.2048, -0.6357,  0.1125],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.0156, -4.1250, -1.4893,  ..., -1.0508, -1.1191, -2.3066],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 6.3110e-02,  5.4260e-02, -1.2878e-02,  ..., -2.0889e-02,
          2.2827e-02,  1.8112e-02],
        [ 2.4033e-04,  2.0187e-02,  2.6047e-02,  ..., -9.3031e-04,
          2.0477e-02,  8.4305e-04],
        [-2.1225e-02, -5.0659e-02,  3.2379e-02,  ...,  1.5701e-02,
         -2.2797e-02,  2.3060e-03],
        ...,
        [ 1.1124e-02, -3.2288e-02, -3.1204e-03,  ...,  5.4596e-02,
         -4.8065e-04,  2.5101e-03],
        [-5.4245e-03,  8.2779e-03, -2.1629e-03,  ...,  5.9662e-03,
          2.1667e-02,  3.6373e-03],
        [ 9.6130e-03, -1.9928e-02, -7.9155e-05,  ...,  4.4212e-03,
         -1.9913e-02,  2.5177e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.3223, -4.1875, -1.6475,  ..., -0.6250, -1.5801, -2.1230]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 19:26:39 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The cranberry is colored red
The milk is colored white
The pepper is colored black
The blood is colored red
The toothpaste is colored white
The peony is colored red
The raven is colored black
The spinach is colored
2024-07-30 19:26:39 root INFO     total operator prediction time: 1221.2443721294403 seconds
2024-07-30 19:26:39 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on country - capital
2024-07-30 19:26:39 root INFO     building operator country - capital
2024-07-30 19:26:39 root INFO     [order_1_approx] starting weight calculation for The country with bern as its capital is known as switzerland
The country with cairo as its capital is known as egypt
The country with athens as its capital is known as greece
The country with helsinki as its capital is known as finland
The country with kiev as its capital is known as ukraine
The country with ottawa as its capital is known as canada
The country with berlin as its capital is known as germany
The country with santiago as its capital is known as
2024-07-30 19:26:39 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 19:28:53 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1194,  0.1697,  0.0211,  ...,  0.0887, -0.0854, -0.1438],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.4353,  0.2007, -2.4531,  ...,  0.2585, -1.2334, -0.8193],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0149, -0.0222,  0.0259,  ..., -0.0116,  0.0096, -0.0008],
        [-0.0044,  0.0572, -0.0023,  ..., -0.0004,  0.0154,  0.0118],
        [ 0.0019, -0.0262,  0.0321,  ..., -0.0099, -0.0025, -0.0131],
        ...,
        [-0.0026,  0.0075, -0.0154,  ...,  0.0527, -0.0121,  0.0032],
        [ 0.0021, -0.0041,  0.0115,  ..., -0.0054,  0.0258, -0.0142],
        [ 0.0243, -0.0045,  0.0106,  ...,  0.0178, -0.0073, -0.0001]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.3167,  0.2290, -2.4844,  ...,  0.3054, -1.5469, -0.4897]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 19:28:54 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is the most lazy, it is laziest
If something is the most vague, it is vaguest
If something is the most sad, it is saddest
If something is the most able, it is ablest
If something is the most tricky, it is trickiest
If something is the most subtle, it is subtlest
If something is the most wealthy, it is wealthiest
If something is the most polite, it is
2024-07-30 19:28:54 root INFO     [order_1_approx] starting weight calculation for If something is the most subtle, it is subtlest
If something is the most polite, it is politest
If something is the most vague, it is vaguest
If something is the most lazy, it is laziest
If something is the most wealthy, it is wealthiest
If something is the most able, it is ablest
If something is the most tricky, it is trickiest
If something is the most sad, it is
2024-07-30 19:28:54 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-30 19:29:11 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1893, -0.0814, -0.7188,  ...,  0.1211,  0.0350,  0.2148],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.9648, -1.1719, -0.0217,  ...,  0.6396, -0.5527, -3.3945],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 3.0930e-02, -2.4128e-04, -1.4999e-02,  ...,  1.7105e-02,
         -4.4312e-02,  3.6831e-03],
        [ 2.2888e-04,  1.5087e-03,  7.6790e-03,  ..., -3.0167e-02,
         -5.0812e-03, -7.7591e-03],
        [-3.5973e-03,  3.2532e-02,  3.4271e-02,  ..., -2.9648e-02,
          3.6926e-03, -2.1713e-02],
        ...,
        [ 9.5444e-03,  6.1150e-03, -1.3824e-02,  ...,  1.9730e-02,
         -3.5400e-03, -2.0676e-02],
        [ 3.5004e-02, -4.5509e-03, -1.3535e-02,  ...,  2.0279e-02,
          1.0376e-02, -1.5961e-02],
        [-3.5801e-03, -2.6226e-05,  6.5155e-03,  ..., -1.6312e-02,
          2.2526e-03, -6.7520e-03]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.8203, -0.7817, -0.3691,  ...,  0.9404, -0.7334, -3.3359]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 19:29:13 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country with bern as its capital is known as switzerland
The country with cairo as its capital is known as egypt
The country with athens as its capital is known as greece
The country with helsinki as its capital is known as finland
The country with kiev as its capital is known as ukraine
The country with ottawa as its capital is known as canada
The country with berlin as its capital is known as germany
The country with santiago as its capital is known as
2024-07-30 19:29:13 root INFO     [order_1_approx] starting weight calculation for The country with helsinki as its capital is known as finland
The country with kiev as its capital is known as ukraine
The country with santiago as its capital is known as chile
The country with cairo as its capital is known as egypt
The country with athens as its capital is known as greece
The country with bern as its capital is known as switzerland
The country with ottawa as its capital is known as canada
The country with berlin as its capital is known as
2024-07-30 19:29:13 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 19:31:32 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0217,  0.0858, -0.1677,  ..., -0.1272, -0.4595, -0.0021],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.1201, -5.5234, -2.9766,  ..., -4.1172, -0.3809, -2.7363],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-1.5015e-02, -1.6479e-02,  1.6678e-02,  ..., -2.9221e-02,
          1.3268e-02,  1.7105e-02],
        [ 2.5131e-02,  3.1300e-03,  9.6359e-03,  ...,  8.9874e-03,
          1.4305e-03,  2.4548e-03],
        [-1.8158e-03,  2.4033e-04,  1.0414e-02,  ...,  1.3542e-03,
         -9.5367e-03, -8.1062e-05],
        ...,
        [ 2.4433e-03,  9.6130e-04,  1.7487e-02,  ...,  1.2184e-02,
         -1.0094e-02,  1.1360e-02],
        [ 7.5073e-03, -9.9792e-03,  1.3710e-02,  ...,  2.2217e-02,
          2.2552e-02, -2.5055e-02],
        [ 1.9043e-02, -6.0959e-03,  1.8444e-03,  ..., -9.0637e-03,
         -1.0323e-02,  1.8051e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.2095, -6.0430, -3.0605,  ..., -3.5684, -0.4819, -2.4258]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 19:31:33 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is the most subtle, it is subtlest
If something is the most polite, it is politest
If something is the most vague, it is vaguest
If something is the most lazy, it is laziest
If something is the most wealthy, it is wealthiest
If something is the most able, it is ablest
If something is the most tricky, it is trickiest
If something is the most sad, it is
2024-07-30 19:31:33 root INFO     [order_1_approx] starting weight calculation for If something is the most wealthy, it is wealthiest
If something is the most sad, it is saddest
If something is the most lazy, it is laziest
If something is the most subtle, it is subtlest
If something is the most able, it is ablest
If something is the most polite, it is politest
If something is the most vague, it is vaguest
If something is the most tricky, it is
2024-07-30 19:31:33 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-30 19:31:46 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1591, -0.0303, -0.2976,  ...,  0.4919,  0.0083,  0.2134],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.3696, -5.3047, -1.3848,  ...,  0.2356,  0.8130, -4.6680],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0153, -0.0045, -0.0158,  ...,  0.0170, -0.0003,  0.0110],
        [-0.0055,  0.0164,  0.0183,  ..., -0.0151, -0.0082, -0.0325],
        [-0.0032,  0.0141,  0.0481,  ...,  0.0051,  0.0026, -0.0122],
        ...,
        [-0.0027, -0.0064,  0.0024,  ...,  0.0500,  0.0035, -0.0106],
        [ 0.0062,  0.0062, -0.0032,  ...,  0.0140, -0.0028, -0.0153],
        [-0.0152, -0.0151,  0.0028,  ...,  0.0090, -0.0055,  0.0267]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.4524, -5.1367, -1.3721,  ...,  0.6484,  0.6123, -4.2891]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 19:31:47 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country with helsinki as its capital is known as finland
The country with kiev as its capital is known as ukraine
The country with santiago as its capital is known as chile
The country with cairo as its capital is known as egypt
The country with athens as its capital is known as greece
The country with bern as its capital is known as switzerland
The country with ottawa as its capital is known as canada
The country with berlin as its capital is known as
2024-07-30 19:31:48 root INFO     [order_1_approx] starting weight calculation for The country with santiago as its capital is known as chile
The country with helsinki as its capital is known as finland
The country with cairo as its capital is known as egypt
The country with ottawa as its capital is known as canada
The country with bern as its capital is known as switzerland
The country with kiev as its capital is known as ukraine
The country with berlin as its capital is known as germany
The country with athens as its capital is known as
2024-07-30 19:31:48 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 19:34:16 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0620, -0.0117,  0.0559,  ...,  0.1014, -0.4043,  0.0189],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.0559, -4.1562, -3.4375,  ...,  0.4614, -2.6211,  0.4131],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0248, -0.0085,  0.0008,  ...,  0.0161, -0.0118,  0.0326],
        [ 0.0040,  0.0068,  0.0378,  ..., -0.0080, -0.0283,  0.0101],
        [ 0.0084, -0.0148,  0.0325,  ...,  0.0096, -0.0196,  0.0071],
        ...,
        [-0.0139,  0.0033, -0.0048,  ...,  0.0354, -0.0108, -0.0136],
        [ 0.0115, -0.0061,  0.0267,  ..., -0.0077,  0.0309, -0.0019],
        [ 0.0083, -0.0098,  0.0002,  ..., -0.0119, -0.0180,  0.0153]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.1575, -4.3750, -3.3184,  ...,  0.9580, -2.1797,  0.2500]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 19:34:17 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is the most wealthy, it is wealthiest
If something is the most sad, it is saddest
If something is the most lazy, it is laziest
If something is the most subtle, it is subtlest
If something is the most able, it is ablest
If something is the most polite, it is politest
If something is the most vague, it is vaguest
If something is the most tricky, it is
2024-07-30 19:34:17 root INFO     [order_1_approx] starting weight calculation for If something is the most tricky, it is trickiest
If something is the most able, it is ablest
If something is the most subtle, it is subtlest
If something is the most sad, it is saddest
If something is the most vague, it is vaguest
If something is the most lazy, it is laziest
If something is the most polite, it is politest
If something is the most wealthy, it is
2024-07-30 19:34:18 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-30 19:34:21 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2168, -0.0546, -0.6909,  ...,  0.0419, -0.1123, -0.1797],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.8594, -5.4375, -3.3125,  ...,  0.0088,  1.3184, -3.0312],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0296, -0.0017, -0.0123,  ...,  0.0036, -0.0133, -0.0039],
        [ 0.0055,  0.0178,  0.0018,  ...,  0.0122, -0.0045, -0.0134],
        [-0.0157,  0.0190,  0.0531,  ...,  0.0041,  0.0035, -0.0158],
        ...,
        [-0.0087,  0.0054, -0.0077,  ...,  0.0301,  0.0206, -0.0122],
        [ 0.0018, -0.0050, -0.0002,  ..., -0.0048,  0.0182,  0.0002],
        [-0.0085, -0.0137, -0.0029,  ..., -0.0005, -0.0093,  0.0120]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.9121, -5.3789, -3.3770,  ...,  0.2053,  1.1172, -2.6797]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 19:34:22 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country with santiago as its capital is known as chile
The country with helsinki as its capital is known as finland
The country with cairo as its capital is known as egypt
The country with ottawa as its capital is known as canada
The country with bern as its capital is known as switzerland
The country with kiev as its capital is known as ukraine
The country with berlin as its capital is known as germany
The country with athens as its capital is known as
2024-07-30 19:34:22 root INFO     [order_1_approx] starting weight calculation for The country with santiago as its capital is known as chile
The country with ottawa as its capital is known as canada
The country with athens as its capital is known as greece
The country with cairo as its capital is known as egypt
The country with berlin as its capital is known as germany
The country with bern as its capital is known as switzerland
The country with helsinki as its capital is known as finland
The country with kiev as its capital is known as
2024-07-30 19:34:22 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 19:36:54 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2546, -0.2808, -0.3203,  ...,  0.0739, -0.4836, -0.0195],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.8242, -4.0703, -1.4023,  ...,  0.5938, -0.3916, -3.6641],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0293,  0.0036, -0.0193,  ...,  0.0285, -0.0126, -0.0047],
        [-0.0116,  0.0295,  0.0153,  ...,  0.0074,  0.0062, -0.0085],
        [-0.0039,  0.0408,  0.0292,  ..., -0.0072, -0.0046, -0.0237],
        ...,
        [-0.0165,  0.0177,  0.0062,  ...,  0.0385,  0.0048, -0.0196],
        [ 0.0161, -0.0138,  0.0044,  ...,  0.0022,  0.0187,  0.0040],
        [-0.0062, -0.0037,  0.0069,  ...,  0.0075,  0.0048,  0.0099]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.8262, -3.9199, -1.6133,  ...,  0.7622, -0.6943, -3.0703]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 19:36:55 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country with santiago as its capital is known as chile
The country with ottawa as its capital is known as canada
The country with athens as its capital is known as greece
The country with cairo as its capital is known as egypt
The country with berlin as its capital is known as germany
The country with bern as its capital is known as switzerland
The country with helsinki as its capital is known as finland
The country with kiev as its capital is known as
2024-07-30 19:36:55 root INFO     [order_1_approx] starting weight calculation for The country with helsinki as its capital is known as finland
The country with santiago as its capital is known as chile
The country with athens as its capital is known as greece
The country with berlin as its capital is known as germany
The country with cairo as its capital is known as egypt
The country with ottawa as its capital is known as canada
The country with kiev as its capital is known as ukraine
The country with bern as its capital is known as
2024-07-30 19:36:55 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 19:37:02 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3157,  0.1859, -0.3547,  ...,  0.0618, -0.2120, -0.0359],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.4194, -4.2695, -2.4883,  ..., -1.5557, -2.7227,  0.2021],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0012, -0.0168, -0.0015,  ..., -0.0063, -0.0104,  0.0173],
        [-0.0069,  0.0056,  0.0071,  ..., -0.0006,  0.0037,  0.0029],
        [-0.0039, -0.0098,  0.0197,  ...,  0.0059, -0.0024,  0.0020],
        ...,
        [-0.0073, -0.0045,  0.0077,  ...,  0.0205, -0.0093,  0.0096],
        [ 0.0053, -0.0042,  0.0042,  ...,  0.0066,  0.0143, -0.0055],
        [-0.0057, -0.0069,  0.0058,  ...,  0.0139,  0.0010,  0.0013]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.3623, -3.9355, -2.5762,  ..., -1.2236, -2.9180,  0.5400]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 19:37:02 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is the most tricky, it is trickiest
If something is the most able, it is ablest
If something is the most subtle, it is subtlest
If something is the most sad, it is saddest
If something is the most vague, it is vaguest
If something is the most lazy, it is laziest
If something is the most polite, it is politest
If something is the most wealthy, it is
2024-07-30 19:37:03 root INFO     [order_1_approx] starting weight calculation for If something is the most sad, it is saddest
If something is the most wealthy, it is wealthiest
If something is the most lazy, it is laziest
If something is the most polite, it is politest
If something is the most able, it is ablest
If something is the most vague, it is vaguest
If something is the most tricky, it is trickiest
If something is the most subtle, it is
2024-07-30 19:37:03 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-30 19:39:24 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3835,  0.4258, -0.1918,  ...,  0.1470,  0.0731,  0.0478],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.9404, -6.1094, -2.0977,  ...,  0.3018, -1.7637, -1.6621],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0280, -0.0358, -0.0193,  ...,  0.0336, -0.0146, -0.0093],
        [ 0.0206,  0.0098,  0.0255,  ..., -0.0332,  0.0109, -0.0384],
        [ 0.0171,  0.0175,  0.0523,  ...,  0.0028,  0.0184,  0.0103],
        ...,
        [ 0.0102, -0.0062, -0.0083,  ...,  0.0383,  0.0133, -0.0295],
        [ 0.0245,  0.0162,  0.0116,  ...,  0.0352,  0.0270,  0.0067],
        [-0.0137, -0.0056, -0.0073,  ..., -0.0277,  0.0167,  0.0124]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.6094, -6.1875, -2.1270,  ...,  0.6538, -2.0176, -1.9199]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 19:39:25 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country with helsinki as its capital is known as finland
The country with santiago as its capital is known as chile
The country with athens as its capital is known as greece
The country with berlin as its capital is known as germany
The country with cairo as its capital is known as egypt
The country with ottawa as its capital is known as canada
The country with kiev as its capital is known as ukraine
The country with bern as its capital is known as
2024-07-30 19:39:25 root INFO     [order_1_approx] starting weight calculation for The country with kiev as its capital is known as ukraine
The country with bern as its capital is known as switzerland
The country with berlin as its capital is known as germany
The country with ottawa as its capital is known as canada
The country with santiago as its capital is known as chile
The country with helsinki as its capital is known as finland
The country with athens as its capital is known as greece
The country with cairo as its capital is known as
2024-07-30 19:39:25 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 19:39:44 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0127, -0.2184,  0.0210,  ..., -0.2133, -0.3877, -0.1578],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.0195, -0.7417, -0.8091,  ..., -0.8862, -1.5195, -0.8867],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0134,  0.0078, -0.0012,  ..., -0.0274,  0.0211,  0.0251],
        [ 0.0086,  0.0241,  0.0094,  ..., -0.0061,  0.0073,  0.0166],
        [ 0.0144, -0.0055,  0.0338,  ...,  0.0115,  0.0050,  0.0003],
        ...,
        [ 0.0055,  0.0360,  0.0013,  ...,  0.0430,  0.0106, -0.0058],
        [ 0.0109,  0.0005,  0.0020,  ...,  0.0178,  0.0087, -0.0254],
        [ 0.0211, -0.0075,  0.0155,  ..., -0.0175, -0.0304, -0.0058]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.3340, -0.8975, -0.5771,  ..., -0.5752, -1.8027, -0.9150]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 19:39:45 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is the most sad, it is saddest
If something is the most wealthy, it is wealthiest
If something is the most lazy, it is laziest
If something is the most polite, it is politest
If something is the most able, it is ablest
If something is the most vague, it is vaguest
If something is the most tricky, it is trickiest
If something is the most subtle, it is
2024-07-30 19:39:46 root INFO     [order_1_approx] starting weight calculation for If something is the most sad, it is saddest
If something is the most vague, it is vaguest
If something is the most able, it is ablest
If something is the most tricky, it is trickiest
If something is the most subtle, it is subtlest
If something is the most wealthy, it is wealthiest
If something is the most polite, it is politest
If something is the most lazy, it is
2024-07-30 19:39:46 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-30 19:41:54 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0424, -0.1254, -0.6978,  ...,  0.4937, -0.4678,  0.1824],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.5312, -3.0391,  1.5303,  ..., -0.6025,  0.6890, -1.7764],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0225, -0.0061, -0.0081,  ...,  0.0255, -0.0265,  0.0005],
        [ 0.0119,  0.0235,  0.0256,  ..., -0.0013,  0.0015, -0.0070],
        [-0.0013,  0.0427,  0.0368,  ..., -0.0018, -0.0250, -0.0236],
        ...,
        [ 0.0064,  0.0219,  0.0180,  ...,  0.0211, -0.0051, -0.0206],
        [ 0.0050, -0.0161, -0.0052,  ..., -0.0089,  0.0155,  0.0025],
        [-0.0082, -0.0071, -0.0092,  ...,  0.0168, -0.0109,  0.0054]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.8887, -2.8984,  1.4189,  ..., -0.3508,  0.6914, -1.7207]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 19:41:55 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country with kiev as its capital is known as ukraine
The country with bern as its capital is known as switzerland
The country with berlin as its capital is known as germany
The country with ottawa as its capital is known as canada
The country with santiago as its capital is known as chile
The country with helsinki as its capital is known as finland
The country with athens as its capital is known as greece
The country with cairo as its capital is known as
2024-07-30 19:41:56 root INFO     [order_1_approx] starting weight calculation for The country with helsinki as its capital is known as finland
The country with kiev as its capital is known as ukraine
The country with santiago as its capital is known as chile
The country with athens as its capital is known as greece
The country with bern as its capital is known as switzerland
The country with berlin as its capital is known as germany
The country with cairo as its capital is known as egypt
The country with ottawa as its capital is known as
2024-07-30 19:41:56 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 19:42:25 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1543,  0.1071, -0.1642,  ..., -0.1835, -0.1982,  0.1648],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-2.5293, -4.7617, -1.9053,  ..., -1.5205, -1.1426, -2.2695],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0285, -0.0114,  0.0005,  ...,  0.0005,  0.0144,  0.0109],
        [ 0.0006,  0.0008,  0.0213,  ..., -0.0186, -0.0041,  0.0044],
        [ 0.0077, -0.0018,  0.0239,  ..., -0.0075, -0.0103, -0.0056],
        ...,
        [-0.0067,  0.0189,  0.0160,  ...,  0.0309, -0.0015, -0.0047],
        [ 0.0151, -0.0141,  0.0040,  ...,  0.0101,  0.0365, -0.0267],
        [ 0.0291, -0.0086,  0.0068,  ..., -0.0278, -0.0061, -0.0031]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-2.1172, -4.5195, -2.2930,  ..., -1.2783, -1.1377, -2.5137]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 19:42:27 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is the most sad, it is saddest
If something is the most vague, it is vaguest
If something is the most able, it is ablest
If something is the most tricky, it is trickiest
If something is the most subtle, it is subtlest
If something is the most wealthy, it is wealthiest
If something is the most polite, it is politest
If something is the most lazy, it is
2024-07-30 19:42:27 root INFO     [order_1_approx] starting weight calculation for If something is the most tricky, it is trickiest
If something is the most wealthy, it is wealthiest
If something is the most lazy, it is laziest
If something is the most subtle, it is subtlest
If something is the most sad, it is saddest
If something is the most polite, it is politest
If something is the most able, it is ablest
If something is the most vague, it is
2024-07-30 19:42:27 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-30 19:44:20 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2144, -0.1469, -0.5039,  ..., -0.0917, -0.1864,  0.1072],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.3521, -6.5078,  1.0615,  ..., -0.6514,  1.6025, -1.1758],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0152,  0.0014, -0.0050,  ...,  0.0309, -0.0082,  0.0151],
        [-0.0046,  0.0330,  0.0296,  ..., -0.0273, -0.0002, -0.0104],
        [ 0.0098,  0.0284,  0.0509,  ..., -0.0023,  0.0154, -0.0193],
        ...,
        [ 0.0057,  0.0081, -0.0070,  ...,  0.0254,  0.0021, -0.0110],
        [ 0.0046,  0.0029,  0.0015,  ..., -0.0018,  0.0166,  0.0016],
        [ 0.0020,  0.0106,  0.0101,  ...,  0.0067, -0.0113,  0.0179]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.4187, -6.6055,  0.3999,  ..., -0.8818,  1.2480, -0.8979]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 19:44:21 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country with helsinki as its capital is known as finland
The country with kiev as its capital is known as ukraine
The country with santiago as its capital is known as chile
The country with athens as its capital is known as greece
The country with bern as its capital is known as switzerland
The country with berlin as its capital is known as germany
The country with cairo as its capital is known as egypt
The country with ottawa as its capital is known as
2024-07-30 19:44:22 root INFO     [order_1_approx] starting weight calculation for The country with ottawa as its capital is known as canada
The country with berlin as its capital is known as germany
The country with cairo as its capital is known as egypt
The country with kiev as its capital is known as ukraine
The country with santiago as its capital is known as chile
The country with bern as its capital is known as switzerland
The country with athens as its capital is known as greece
The country with helsinki as its capital is known as
2024-07-30 19:44:22 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 19:45:04 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0615,  0.1812, -0.0780,  ..., -0.0405, -0.0583, -0.2734],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-2.4941, -3.3965, -0.5083,  ...,  0.3818, -4.1172, -0.0967],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0363, -0.0181,  0.0041,  ..., -0.0248,  0.0211,  0.0091],
        [-0.0148,  0.0168,  0.0037,  ..., -0.0039,  0.0210,  0.0271],
        [-0.0127,  0.0227,  0.0633,  ...,  0.0026, -0.0208,  0.0214],
        ...,
        [ 0.0275,  0.0497,  0.0243,  ...,  0.0564, -0.0485, -0.0092],
        [ 0.0153, -0.0189,  0.0238,  ...,  0.0020,  0.0271, -0.0172],
        [ 0.0134,  0.0273,  0.0179,  ..., -0.0085, -0.0236,  0.0279]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-2.3340, -3.4141, -0.3538,  ...,  0.4915, -3.9180, -0.2642]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 19:45:05 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is the most tricky, it is trickiest
If something is the most wealthy, it is wealthiest
If something is the most lazy, it is laziest
If something is the most subtle, it is subtlest
If something is the most sad, it is saddest
If something is the most polite, it is politest
If something is the most able, it is ablest
If something is the most vague, it is
2024-07-30 19:45:06 root INFO     [order_1_approx] starting weight calculation for If something is the most tricky, it is trickiest
If something is the most sad, it is saddest
If something is the most wealthy, it is wealthiest
If something is the most vague, it is vaguest
If something is the most subtle, it is subtlest
If something is the most lazy, it is laziest
If something is the most polite, it is politest
If something is the most able, it is
2024-07-30 19:45:06 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-30 19:46:52 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0751, -0.5864, -0.5063,  ..., -0.1023,  0.0161,  0.0268],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.1797, -5.5625, -1.6875,  ..., -0.0349, -2.7617, -3.8633],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 1.3550e-02,  6.7177e-03, -2.2240e-03,  ...,  1.3863e-02,
         -5.0468e-03,  2.9922e-04],
        [ 3.0899e-03,  6.2714e-03,  4.6692e-03,  ..., -1.6052e-02,
          3.7670e-03, -3.1700e-03],
        [ 3.2043e-03,  7.9880e-03,  8.2779e-03,  ...,  3.5324e-03,
         -4.3678e-04, -5.0430e-03],
        ...,
        [-1.6346e-03,  1.5926e-04,  8.4877e-05,  ...,  1.5419e-02,
          7.2975e-03, -3.0003e-03],
        [ 5.6343e-03, -2.3376e-02, -4.3488e-03,  ..., -4.5738e-03,
          2.0493e-02,  3.2730e-03],
        [-5.6076e-03, -1.6449e-02, -1.3184e-02,  ...,  3.6240e-03,
         -3.2616e-04,  8.4991e-03]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.2266, -5.5820, -1.6094,  ...,  0.0799, -2.8750, -3.7227]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 19:46:53 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country with ottawa as its capital is known as canada
The country with berlin as its capital is known as germany
The country with cairo as its capital is known as egypt
The country with kiev as its capital is known as ukraine
The country with santiago as its capital is known as chile
The country with bern as its capital is known as switzerland
The country with athens as its capital is known as greece
The country with helsinki as its capital is known as
2024-07-30 19:46:53 root INFO     total operator prediction time: 1214.2236413955688 seconds
2024-07-30 19:46:53 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on name - occupation
2024-07-30 19:46:53 root INFO     building operator name - occupation
2024-07-30 19:46:53 root INFO     [order_1_approx] starting weight calculation for hitler was known for their work as a  dictator
pascal was known for their work as a  mathematician
wagner was known for their work as a  composer
kant was known for their work as a  philosopher
marx was known for their work as a  philosopher
hegel was known for their work as a  philosopher
locke was known for their work as a  philosopher
wittgenstein was known for their work as a 
2024-07-30 19:46:53 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 19:47:49 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3809,  0.1486, -0.0900,  ..., -0.0372, -0.1757, -0.2686],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.7339, -5.1836, -1.6924,  ...,  1.2061, -3.9141, -0.8525],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0015, -0.0341,  0.0104,  ...,  0.0011, -0.0071,  0.0100],
        [-0.0055,  0.0107,  0.0067,  ..., -0.0014, -0.0081, -0.0108],
        [ 0.0042, -0.0207,  0.0343,  ..., -0.0064, -0.0200, -0.0009],
        ...,
        [-0.0203,  0.0148,  0.0115,  ...,  0.0234, -0.0089,  0.0138],
        [ 0.0246,  0.0268,  0.0053,  ..., -0.0225,  0.0388, -0.0300],
        [ 0.0157,  0.0076,  0.0081,  ...,  0.0035,  0.0233, -0.0181]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.8740, -4.7266, -1.5449,  ...,  1.4600, -3.8613, -0.8760]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 19:47:50 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is the most tricky, it is trickiest
If something is the most sad, it is saddest
If something is the most wealthy, it is wealthiest
If something is the most vague, it is vaguest
If something is the most subtle, it is subtlest
If something is the most lazy, it is laziest
If something is the most polite, it is politest
If something is the most able, it is
2024-07-30 19:47:50 root INFO     total operator prediction time: 1298.266241312027 seconds
2024-07-30 19:47:50 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on verb_3pSg - Ved
2024-07-30 19:47:50 root INFO     building operator verb_3pSg - Ved
2024-07-30 19:47:50 root INFO     [order_1_approx] starting weight calculation for When he performs something, something has been performed
When he suggests something, something has been suggested
When he manages something, something has been managed
When he tells something, something has been told
When he asks something, something has been asked
When he provides something, something has been provided
When he contains something, something has been contained
When he creates something, something has been
2024-07-30 19:47:50 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-30 19:49:24 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0308, -0.5557, -0.4592,  ...,  0.3589,  0.1015,  0.1616],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.1855, -4.6406,  1.9609,  ..., -6.1641, -0.1960, -1.1025],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0082, -0.0224,  0.0022,  ...,  0.0007,  0.0055,  0.0054],
        [ 0.0016,  0.0190,  0.0009,  ...,  0.0030, -0.0029, -0.0113],
        [-0.0025, -0.0077,  0.0212,  ..., -0.0082,  0.0057,  0.0143],
        ...,
        [ 0.0008, -0.0061,  0.0045,  ...,  0.0303,  0.0073,  0.0102],
        [-0.0010,  0.0059,  0.0068,  ...,  0.0071,  0.0068, -0.0034],
        [ 0.0039, -0.0087,  0.0053,  ..., -0.0002,  0.0074,  0.0067]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.3809, -4.4844,  1.9893,  ..., -6.0000, -0.3040, -0.9868]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 19:49:26 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for hitler was known for their work as a  dictator
pascal was known for their work as a  mathematician
wagner was known for their work as a  composer
kant was known for their work as a  philosopher
marx was known for their work as a  philosopher
hegel was known for their work as a  philosopher
locke was known for their work as a  philosopher
wittgenstein was known for their work as a 
2024-07-30 19:49:26 root INFO     [order_1_approx] starting weight calculation for locke was known for their work as a  philosopher
hegel was known for their work as a  philosopher
hitler was known for their work as a  dictator
kant was known for their work as a  philosopher
pascal was known for their work as a  mathematician
wagner was known for their work as a  composer
wittgenstein was known for their work as a  philosopher
marx was known for their work as a 
2024-07-30 19:49:26 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 19:50:30 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1768,  0.3210, -0.0675,  ...,  0.0671,  0.0709, -0.0887],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.1367,  0.6885,  2.7305,  ...,  0.0898, -1.9551,  0.1016],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0333, -0.0213,  0.0079,  ...,  0.0020, -0.0061,  0.0198],
        [-0.0094,  0.0308,  0.0053,  ...,  0.0077, -0.0093, -0.0193],
        [ 0.0046,  0.0011, -0.0047,  ..., -0.0065,  0.0076,  0.0010],
        ...,
        [ 0.0079,  0.0054, -0.0024,  ...,  0.0079,  0.0106,  0.0101],
        [ 0.0132,  0.0172,  0.0079,  ...,  0.0081,  0.0132,  0.0028],
        [ 0.0035, -0.0035, -0.0029,  ...,  0.0127, -0.0043, -0.0047]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.9062,  0.5620,  2.6074,  ...,  0.1449, -1.8828,  0.1501]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 19:50:31 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When he performs something, something has been performed
When he suggests something, something has been suggested
When he manages something, something has been managed
When he tells something, something has been told
When he asks something, something has been asked
When he provides something, something has been provided
When he contains something, something has been contained
When he creates something, something has been
2024-07-30 19:50:31 root INFO     [order_1_approx] starting weight calculation for When he performs something, something has been performed
When he asks something, something has been asked
When he suggests something, something has been suggested
When he creates something, something has been created
When he provides something, something has been provided
When he contains something, something has been contained
When he tells something, something has been told
When he manages something, something has been
2024-07-30 19:50:31 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-30 19:51:56 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3169,  0.1349,  0.2615,  ..., -0.0398,  0.0974,  0.1438],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.3633, -8.4531,  3.6875,  ..., -5.6836,  1.2568, -2.8672],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0148, -0.0034, -0.0148,  ..., -0.0379, -0.0127,  0.0091],
        [ 0.0017,  0.0016,  0.0181,  ...,  0.0076,  0.0084,  0.0019],
        [ 0.0094,  0.0124,  0.0211,  ..., -0.0141, -0.0140, -0.0022],
        ...,
        [ 0.0194, -0.0012,  0.0264,  ...,  0.0583,  0.0183,  0.0015],
        [ 0.0026,  0.0266,  0.0044,  ...,  0.0094,  0.0022, -0.0028],
        [ 0.0049, -0.0038,  0.0174,  ...,  0.0262,  0.0192,  0.0220]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.7607, -7.9453,  3.5117,  ..., -5.9141,  1.1201, -2.8574]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 19:51:57 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for locke was known for their work as a  philosopher
hegel was known for their work as a  philosopher
hitler was known for their work as a  dictator
kant was known for their work as a  philosopher
pascal was known for their work as a  mathematician
wagner was known for their work as a  composer
wittgenstein was known for their work as a  philosopher
marx was known for their work as a 
2024-07-30 19:51:57 root INFO     [order_1_approx] starting weight calculation for pascal was known for their work as a  mathematician
hitler was known for their work as a  dictator
marx was known for their work as a  philosopher
hegel was known for their work as a  philosopher
wagner was known for their work as a  composer
wittgenstein was known for their work as a  philosopher
kant was known for their work as a  philosopher
locke was known for their work as a 
2024-07-30 19:51:57 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 19:53:13 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0966,  0.7080, -0.1533,  ...,  0.1067, -0.1041, -0.1925],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.7842,  1.1699,  2.9512,  ..., -0.9302, -1.0752, -2.2402],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 1.8814e-02, -7.5378e-03,  5.0449e-04,  ..., -4.3869e-04,
          1.5747e-02,  2.1408e-02],
        [-5.9509e-03,  2.0752e-02,  1.3817e-02,  ...,  1.1810e-02,
          9.4070e-03,  1.2489e-02],
        [-2.2644e-02, -9.3384e-03,  1.4267e-02,  ..., -5.8823e-03,
          1.4832e-02,  2.5349e-03],
        ...,
        [ 1.2749e-02,  7.9575e-03,  2.2995e-02,  ...,  9.1324e-03,
          1.2650e-02,  8.2703e-03],
        [ 1.1284e-02, -1.3809e-02,  1.4946e-02,  ...,  5.3406e-05,
          1.0880e-02, -9.1019e-03],
        [ 2.2995e-02,  1.6052e-02, -2.5654e-03,  ...,  3.4752e-03,
         -1.1070e-02, -1.3252e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.9590,  0.8730,  3.1172,  ..., -0.8174, -0.8418, -2.4883]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 19:53:14 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When he performs something, something has been performed
When he asks something, something has been asked
When he suggests something, something has been suggested
When he creates something, something has been created
When he provides something, something has been provided
When he contains something, something has been contained
When he tells something, something has been told
When he manages something, something has been
2024-07-30 19:53:14 root INFO     [order_1_approx] starting weight calculation for When he creates something, something has been created
When he asks something, something has been asked
When he suggests something, something has been suggested
When he contains something, something has been contained
When he tells something, something has been told
When he performs something, something has been performed
When he manages something, something has been managed
When he provides something, something has been
2024-07-30 19:53:15 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-30 19:54:24 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0073, -0.1143, -0.5601,  ..., -0.1688, -0.0027,  0.0429],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.8140, -3.7461,  2.4102,  ..., -6.1562,  1.5420, -3.0371],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0370, -0.0113,  0.0086,  ...,  0.0121,  0.0015,  0.0121],
        [ 0.0166,  0.0253,  0.0108,  ...,  0.0090, -0.0083, -0.0065],
        [ 0.0059,  0.0168,  0.0352,  ..., -0.0114,  0.0119,  0.0075],
        ...,
        [ 0.0094,  0.0067,  0.0071,  ...,  0.0504,  0.0056,  0.0058],
        [-0.0073,  0.0195,  0.0083,  ...,  0.0278,  0.0233, -0.0157],
        [ 0.0118, -0.0135,  0.0047,  ..., -0.0179,  0.0002,  0.0303]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.4248, -3.6836,  2.0938,  ..., -5.7422,  1.6426, -2.8359]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 19:54:25 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for pascal was known for their work as a  mathematician
hitler was known for their work as a  dictator
marx was known for their work as a  philosopher
hegel was known for their work as a  philosopher
wagner was known for their work as a  composer
wittgenstein was known for their work as a  philosopher
kant was known for their work as a  philosopher
locke was known for their work as a 
2024-07-30 19:54:25 root INFO     [order_1_approx] starting weight calculation for wittgenstein was known for their work as a  philosopher
locke was known for their work as a  philosopher
kant was known for their work as a  philosopher
wagner was known for their work as a  composer
hitler was known for their work as a  dictator
hegel was known for their work as a  philosopher
marx was known for their work as a  philosopher
pascal was known for their work as a 
2024-07-30 19:54:25 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 19:55:53 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0194,  0.1667, -0.2266,  ...,  0.2661, -0.0154, -0.2510],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.3379, -1.7412,  1.2109,  ..., -1.9355, -3.3223, -0.1484],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0318, -0.0102, -0.0027,  ..., -0.0010,  0.0021,  0.0291],
        [-0.0181,  0.0085,  0.0157,  ...,  0.0063, -0.0083,  0.0137],
        [-0.0130, -0.0144, -0.0047,  ..., -0.0089, -0.0110, -0.0056],
        ...,
        [ 0.0107,  0.0194, -0.0091,  ...,  0.0026, -0.0007,  0.0102],
        [ 0.0367, -0.0017,  0.0058,  ...,  0.0039,  0.0080, -0.0199],
        [ 0.0154,  0.0252, -0.0095,  ...,  0.0037, -0.0190, -0.0126]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.4648, -1.7754,  0.9634,  ..., -1.8369, -2.9336, -0.3037]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 19:55:54 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When he creates something, something has been created
When he asks something, something has been asked
When he suggests something, something has been suggested
When he contains something, something has been contained
When he tells something, something has been told
When he performs something, something has been performed
When he manages something, something has been managed
When he provides something, something has been
2024-07-30 19:55:54 root INFO     [order_1_approx] starting weight calculation for When he suggests something, something has been suggested
When he performs something, something has been performed
When he tells something, something has been told
When he manages something, something has been managed
When he provides something, something has been provided
When he creates something, something has been created
When he contains something, something has been contained
When he asks something, something has been
2024-07-30 19:55:54 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-30 19:56:51 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1262, -0.0839, -0.2378,  ..., -0.2478,  0.0168,  0.4951],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.8691, -2.4688,  3.0312,  ..., -6.2891,  0.1699,  1.2852],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0532, -0.0222, -0.0074,  ...,  0.0057, -0.0115, -0.0228],
        [ 0.0340,  0.0654,  0.0038,  ...,  0.0068, -0.0052,  0.0152],
        [-0.0033,  0.0090,  0.0742,  ...,  0.0030,  0.0259,  0.0141],
        ...,
        [ 0.0156,  0.0034,  0.0187,  ...,  0.0444,  0.0242, -0.0069],
        [-0.0160,  0.0043,  0.0055,  ...,  0.0665,  0.0307,  0.0208],
        [-0.0003,  0.0187,  0.0106,  ..., -0.0307,  0.0057,  0.0537]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.5654, -2.6660,  2.9668,  ..., -6.0586,  0.2727,  1.2559]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 19:56:52 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for wittgenstein was known for their work as a  philosopher
locke was known for their work as a  philosopher
kant was known for their work as a  philosopher
wagner was known for their work as a  composer
hitler was known for their work as a  dictator
hegel was known for their work as a  philosopher
marx was known for their work as a  philosopher
pascal was known for their work as a 
2024-07-30 19:56:52 root INFO     [order_1_approx] starting weight calculation for locke was known for their work as a  philosopher
wittgenstein was known for their work as a  philosopher
wagner was known for their work as a  composer
marx was known for their work as a  philosopher
kant was known for their work as a  philosopher
pascal was known for their work as a  mathematician
hitler was known for their work as a  dictator
hegel was known for their work as a 
2024-07-30 19:56:52 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 19:58:30 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1322,  0.2180, -0.0924,  ...,  0.2625, -0.1284, -0.4497],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.1123,  0.6885,  0.2878,  ...,  0.1624, -2.6758,  1.4609],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0434,  0.0032,  0.0336,  ..., -0.0168, -0.0092, -0.0059],
        [-0.0142,  0.0219,  0.0108,  ...,  0.0258, -0.0009, -0.0007],
        [-0.0055, -0.0082,  0.0328,  ..., -0.0080,  0.0044, -0.0072],
        ...,
        [-0.0099,  0.0387, -0.0024,  ...,  0.0190,  0.0095,  0.0038],
        [ 0.0142, -0.0111, -0.0127,  ...,  0.0153,  0.0164,  0.0010],
        [-0.0100,  0.0003,  0.0197,  ...,  0.0155, -0.0166, -0.0019]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.5078,  0.6621,  0.4980,  ...,  0.0126, -2.7754,  1.2070]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 19:58:47 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When he suggests something, something has been suggested
When he performs something, something has been performed
When he tells something, something has been told
When he manages something, something has been managed
When he provides something, something has been provided
When he creates something, something has been created
When he contains something, something has been contained
When he asks something, something has been
2024-07-30 19:58:47 root INFO     [order_1_approx] starting weight calculation for When he asks something, something has been asked
When he performs something, something has been performed
When he contains something, something has been contained
When he manages something, something has been managed
When he creates something, something has been created
When he provides something, something has been provided
When he tells something, something has been told
When he suggests something, something has been
2024-07-30 19:58:47 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-30 19:59:18 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3486,  0.4668, -0.0267,  ...,  0.2158,  0.3499,  0.2070],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.8276, -6.8086,  3.8281,  ..., -5.4141,  0.0303, -1.4180],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0312,  0.0429, -0.0093,  ..., -0.0457, -0.0176, -0.0104],
        [-0.0017, -0.0232,  0.0314,  ...,  0.0365, -0.0087,  0.0098],
        [ 0.0081,  0.0214,  0.0347,  ..., -0.0251,  0.0035, -0.0057],
        ...,
        [ 0.0154, -0.0234,  0.0094,  ...,  0.0885,  0.0334,  0.0320],
        [ 0.0008,  0.0331, -0.0131,  ...,  0.0013,  0.0102, -0.0147],
        [-0.0028, -0.0361,  0.0063,  ...,  0.0334,  0.0107,  0.0449]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.8169, -5.9844,  3.3906,  ..., -5.7383,  0.2352, -1.1533]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 19:59:19 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for locke was known for their work as a  philosopher
wittgenstein was known for their work as a  philosopher
wagner was known for their work as a  composer
marx was known for their work as a  philosopher
kant was known for their work as a  philosopher
pascal was known for their work as a  mathematician
hitler was known for their work as a  dictator
hegel was known for their work as a 
2024-07-30 19:59:19 root INFO     [order_1_approx] starting weight calculation for marx was known for their work as a  philosopher
hegel was known for their work as a  philosopher
pascal was known for their work as a  mathematician
kant was known for their work as a  philosopher
locke was known for their work as a  philosopher
wagner was known for their work as a  composer
wittgenstein was known for their work as a  philosopher
hitler was known for their work as a 
2024-07-30 19:59:20 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 20:01:26 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1174,  0.2690,  0.1538,  ...,  0.4185, -0.3154, -0.2947],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.9609,  0.8198, -0.8086,  ...,  1.0234,  0.0083,  1.5703],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0309, -0.0213,  0.0182,  ..., -0.0076, -0.0057,  0.0072],
        [-0.0027,  0.0071, -0.0183,  ..., -0.0018, -0.0032, -0.0059],
        [-0.0151, -0.0122,  0.0230,  ..., -0.0090,  0.0119, -0.0013],
        ...,
        [-0.0166,  0.0028,  0.0187,  ...,  0.0099,  0.0197,  0.0243],
        [ 0.0210,  0.0261, -0.0051,  ..., -0.0155,  0.0082, -0.0287],
        [ 0.0208,  0.0190,  0.0210,  ...,  0.0126, -0.0219, -0.0179]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.1094,  1.1787, -0.4380,  ...,  1.1562, -0.2886,  1.0479]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 20:01:26 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When he asks something, something has been asked
When he performs something, something has been performed
When he contains something, something has been contained
When he manages something, something has been managed
When he creates something, something has been created
When he provides something, something has been provided
When he tells something, something has been told
When he suggests something, something has been
2024-07-30 20:01:27 root INFO     [order_1_approx] starting weight calculation for When he asks something, something has been asked
When he creates something, something has been created
When he provides something, something has been provided
When he performs something, something has been performed
When he manages something, something has been managed
When he contains something, something has been contained
When he suggests something, something has been suggested
When he tells something, something has been
2024-07-30 20:01:27 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-30 20:01:49 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3232,  0.0089, -0.2837,  ...,  0.2446,  0.1284,  0.1554],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.3740, -7.6953,  3.5156,  ..., -3.8418, -0.1533, -2.1973],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0484, -0.0227,  0.0045,  ...,  0.0122, -0.0082,  0.0278],
        [ 0.0047,  0.0300, -0.0018,  ..., -0.0012,  0.0022, -0.0201],
        [ 0.0035,  0.0121,  0.0766,  ...,  0.0010, -0.0094, -0.0065],
        ...,
        [ 0.0024,  0.0221,  0.0052,  ...,  0.0688,  0.0033, -0.0140],
        [-0.0043,  0.0133,  0.0119,  ..., -0.0051,  0.0089, -0.0030],
        [-0.0026, -0.0112, -0.0023,  ...,  0.0113, -0.0068,  0.0498]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.8828e-04, -7.1445e+00,  2.9395e+00,  ..., -3.9062e+00,
         -5.8167e-02, -1.6279e+00]], device='cuda:1', dtype=torch.float16,
       grad_fn=<SubBackward0>) 

                    
2024-07-30 20:01:50 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for marx was known for their work as a  philosopher
hegel was known for their work as a  philosopher
pascal was known for their work as a  mathematician
kant was known for their work as a  philosopher
locke was known for their work as a  philosopher
wagner was known for their work as a  composer
wittgenstein was known for their work as a  philosopher
hitler was known for their work as a 
2024-07-30 20:01:50 root INFO     [order_1_approx] starting weight calculation for kant was known for their work as a  philosopher
pascal was known for their work as a  mathematician
marx was known for their work as a  philosopher
wittgenstein was known for their work as a  philosopher
locke was known for their work as a  philosopher
hitler was known for their work as a  dictator
hegel was known for their work as a  philosopher
wagner was known for their work as a 
2024-07-30 20:01:50 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 20:04:01 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1329,  0.1750,  0.1073,  ...,  0.1926, -0.0529, -0.2561],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.5254,  1.5156,  4.8320,  ...,  1.2861, -4.7500, -0.7227],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0003, -0.0044, -0.0128,  ...,  0.0023,  0.0048,  0.0189],
        [-0.0108,  0.0099,  0.0042,  ..., -0.0015, -0.0114, -0.0074],
        [ 0.0052, -0.0262,  0.0053,  ...,  0.0017,  0.0027, -0.0045],
        ...,
        [ 0.0132,  0.0039, -0.0095,  ...,  0.0145, -0.0094,  0.0056],
        [ 0.0028, -0.0146, -0.0039,  ..., -0.0074,  0.0236, -0.0007],
        [ 0.0057,  0.0101, -0.0055,  ...,  0.0137,  0.0011,  0.0036]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.6582,  1.4258,  4.4414,  ...,  1.3408, -4.7891, -1.1758]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 20:04:02 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When he asks something, something has been asked
When he creates something, something has been created
When he provides something, something has been provided
When he performs something, something has been performed
When he manages something, something has been managed
When he contains something, something has been contained
When he suggests something, something has been suggested
When he tells something, something has been
2024-07-30 20:04:03 root INFO     [order_1_approx] starting weight calculation for When he manages something, something has been managed
When he creates something, something has been created
When he performs something, something has been performed
When he asks something, something has been asked
When he provides something, something has been provided
When he suggests something, something has been suggested
When he tells something, something has been told
When he contains something, something has been
2024-07-30 20:04:03 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-30 20:04:20 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4619,  0.5352,  0.1056,  ...,  0.2532, -0.0045, -0.0468],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.6602, -7.8828,  3.4141,  ..., -3.9062, -0.5288, -2.2246],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0563,  0.0033,  0.0167,  ..., -0.0223, -0.0226, -0.0044],
        [ 0.0081,  0.0279,  0.0074,  ...,  0.0007,  0.0034, -0.0134],
        [ 0.0261,  0.0341,  0.0556,  ..., -0.0139, -0.0074, -0.0041],
        ...,
        [-0.0154,  0.0234,  0.0184,  ...,  0.0866, -0.0039, -0.0024],
        [ 0.0028, -0.0116, -0.0004,  ...,  0.0110,  0.0276,  0.0061],
        [-0.0091,  0.0011,  0.0073,  ..., -0.0168,  0.0018,  0.0406]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.3750, -7.0117,  2.9941,  ..., -4.2148, -0.0977, -2.1172]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 20:04:21 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for kant was known for their work as a  philosopher
pascal was known for their work as a  mathematician
marx was known for their work as a  philosopher
wittgenstein was known for their work as a  philosopher
locke was known for their work as a  philosopher
hitler was known for their work as a  dictator
hegel was known for their work as a  philosopher
wagner was known for their work as a 
2024-07-30 20:04:21 root INFO     [order_1_approx] starting weight calculation for pascal was known for their work as a  mathematician
locke was known for their work as a  philosopher
hitler was known for their work as a  dictator
hegel was known for their work as a  philosopher
wagner was known for their work as a  composer
wittgenstein was known for their work as a  philosopher
marx was known for their work as a  philosopher
kant was known for their work as a 
2024-07-30 20:04:21 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 20:06:41 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0088, -0.0453, -0.1044,  ...,  0.1846, -0.3545, -0.4170],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.5889,  2.9648,  2.3145,  ..., -2.0820, -0.3486, -2.9492],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 2.6535e-02, -1.6876e-02,  6.3324e-03,  ...,  3.0365e-03,
          9.4528e-03,  2.5024e-02],
        [-3.0785e-03,  4.1077e-02,  7.3700e-03,  ...,  1.3687e-02,
         -2.8534e-03,  7.1259e-03],
        [-1.1536e-02, -7.0333e-05,  2.3239e-02,  ..., -2.0798e-02,
          3.2597e-03, -1.6754e-02],
        ...,
        [ 9.3746e-04,  1.5175e-02,  1.5762e-02,  ...,  2.6184e-02,
          1.2901e-02, -9.2926e-03],
        [ 3.3844e-02, -3.0273e-02, -1.4153e-02,  ..., -3.8986e-03,
          2.8992e-02,  5.6915e-03],
        [ 1.1543e-02, -9.6436e-03, -8.8959e-03,  ..., -4.3678e-03,
         -3.1235e-02, -2.3773e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.2971,  2.6621,  2.1738,  ..., -2.2539, -0.5547, -2.9199]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 20:06:43 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When he manages something, something has been managed
When he creates something, something has been created
When he performs something, something has been performed
When he asks something, something has been asked
When he provides something, something has been provided
When he suggests something, something has been suggested
When he tells something, something has been told
When he contains something, something has been
2024-07-30 20:06:43 root INFO     [order_1_approx] starting weight calculation for When he tells something, something has been told
When he manages something, something has been managed
When he contains something, something has been contained
When he provides something, something has been provided
When he asks something, something has been asked
When he creates something, something has been created
When he suggests something, something has been suggested
When he performs something, something has been
2024-07-30 20:06:43 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-30 20:06:53 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3274, -0.1927, -0.2424,  ...,  0.0782,  0.1216,  0.2399],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.2168, -6.3438,  2.9141,  ..., -5.9414, -0.9502, -3.0820],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 2.8519e-02, -1.1139e-02,  8.5526e-03,  ..., -1.4496e-04,
         -1.8692e-04,  1.4847e-02],
        [-8.0490e-04,  1.9745e-02,  1.0025e-02,  ...,  1.2894e-02,
         -1.2581e-02,  1.5154e-03],
        [ 1.3405e-02,  2.1744e-02,  3.0548e-02,  ..., -2.1194e-02,
          2.9373e-03,  1.1917e-02],
        ...,
        [ 5.6992e-03,  9.4147e-03,  1.3695e-02,  ...,  4.7974e-02,
          1.8600e-02,  7.0572e-05],
        [ 1.5259e-04,  1.1101e-02,  1.1930e-03,  ...,  1.7365e-02,
          1.3428e-02,  3.6278e-03],
        [-9.4910e-03, -1.4938e-02,  1.7471e-03,  ...,  1.9989e-03,
         -4.9896e-03,  4.1656e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.6807, -6.0469,  2.6953,  ..., -5.7188, -0.7710, -3.0840]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 20:07:13 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for pascal was known for their work as a  mathematician
locke was known for their work as a  philosopher
hitler was known for their work as a  dictator
hegel was known for their work as a  philosopher
wagner was known for their work as a  composer
wittgenstein was known for their work as a  philosopher
marx was known for their work as a  philosopher
kant was known for their work as a 
2024-07-30 20:07:13 root INFO     total operator prediction time: 1219.7905905246735 seconds
2024-07-30 20:07:13 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on male - female
2024-07-30 20:07:13 root INFO     building operator male - female
2024-07-30 20:07:14 root INFO     [order_1_approx] starting weight calculation for A female buck is known as a doe
A female poet is known as a poetess
A female grandfather is known as a grandmother
A female superman is known as a superwoman
A female actor is known as a actress
A female webmaster is known as a webmistress
A female father is known as a mother
A female batman is known as a
2024-07-30 20:07:14 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 20:09:20 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1101,  0.4114, -0.0976,  ..., -0.0919, -0.1011, -0.1881],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.7236,  0.8833,  4.5078,  ..., -1.3438, -2.9961, -0.8359],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0130,  0.0112,  0.0034,  ..., -0.0143,  0.0147,  0.0317],
        [-0.0294,  0.0336,  0.0059,  ..., -0.0006,  0.0202,  0.0057],
        [-0.0079,  0.0041, -0.0095,  ..., -0.0075,  0.0173,  0.0204],
        ...,
        [ 0.0071,  0.0141, -0.0026,  ..., -0.0042,  0.0216, -0.0014],
        [ 0.0282,  0.0032,  0.0016,  ...,  0.0050,  0.0225, -0.0086],
        [ 0.0310,  0.0110, -0.0023,  ...,  0.0093, -0.0103, -0.0044]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.1543,  0.6016,  4.5781,  ..., -0.9419, -2.3828, -0.9912]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 20:09:21 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When he tells something, something has been told
When he manages something, something has been managed
When he contains something, something has been contained
When he provides something, something has been provided
When he asks something, something has been asked
When he creates something, something has been created
When he suggests something, something has been suggested
When he performs something, something has been
2024-07-30 20:09:21 root INFO     total operator prediction time: 1291.2376072406769 seconds
2024-07-30 20:09:21 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on noun - plural_reg
2024-07-30 20:09:21 root INFO     building operator noun - plural_reg
2024-07-30 20:09:21 root INFO     [order_1_approx] starting weight calculation for The plural form of solution is solutions
The plural form of science is sciences
The plural form of period is periods
The plural form of director is directors
The plural form of car is cars
The plural form of version is versions
The plural form of day is days
The plural form of example is
2024-07-30 20:09:21 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-30 20:09:45 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0815,  0.2568, -0.1646,  ..., -0.0106, -0.2769, -0.0522],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 5.4961, -4.8945,  1.5020,  ..., -1.1465, -2.6973,  0.2583],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0027, -0.0248, -0.0100,  ...,  0.0044,  0.0090,  0.0005],
        [ 0.0161,  0.0372,  0.0009,  ...,  0.0147,  0.0213, -0.0041],
        [ 0.0071,  0.0263,  0.0387,  ..., -0.0122, -0.0140, -0.0200],
        ...,
        [ 0.0036,  0.0103, -0.0367,  ...,  0.0404,  0.0098,  0.0105],
        [-0.0010, -0.0287,  0.0052,  ...,  0.0300,  0.0024,  0.0095],
        [ 0.0036, -0.0123, -0.0208,  ..., -0.0119,  0.0109,  0.0182]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 5.4883, -4.9492,  1.4531,  ..., -1.0859, -2.7441,  0.1136]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 20:09:46 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A female buck is known as a doe
A female poet is known as a poetess
A female grandfather is known as a grandmother
A female superman is known as a superwoman
A female actor is known as a actress
A female webmaster is known as a webmistress
A female father is known as a mother
A female batman is known as a
2024-07-30 20:09:47 root INFO     [order_1_approx] starting weight calculation for A female father is known as a mother
A female poet is known as a poetess
A female superman is known as a superwoman
A female actor is known as a actress
A female webmaster is known as a webmistress
A female buck is known as a doe
A female batman is known as a batwoman
A female grandfather is known as a
2024-07-30 20:09:47 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 20:12:01 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0347, -0.3354, -0.0842,  ...,  0.2062, -0.1411, -0.0903],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.7095, -1.6240, -0.0811,  ..., -0.5410, -1.3896, -2.4668],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0333, -0.0273,  0.0358,  ..., -0.0134,  0.0125,  0.0107],
        [-0.0202,  0.0557,  0.0376,  ...,  0.0023, -0.0107, -0.0115],
        [-0.0465, -0.0182,  0.0478,  ..., -0.0098,  0.0095, -0.0007],
        ...,
        [ 0.0005,  0.0083, -0.0020,  ...,  0.0310, -0.0103, -0.0079],
        [ 0.0283,  0.0094, -0.0231,  ...,  0.0147,  0.0064, -0.0318],
        [-0.0216,  0.0117,  0.0187,  ...,  0.0068, -0.0128,  0.0272]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.0288, -1.7617,  0.0900,  ..., -0.4858, -1.6914, -1.8018]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 20:12:02 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of solution is solutions
The plural form of science is sciences
The plural form of period is periods
The plural form of director is directors
The plural form of car is cars
The plural form of version is versions
The plural form of day is days
The plural form of example is
2024-07-30 20:12:02 root INFO     [order_1_approx] starting weight calculation for The plural form of period is periods
The plural form of solution is solutions
The plural form of director is directors
The plural form of car is cars
The plural form of example is examples
The plural form of day is days
The plural form of science is sciences
The plural form of version is
2024-07-30 20:12:02 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-30 20:12:17 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4963,  0.1031, -0.1362,  ..., -0.2230, -0.0553, -0.0017],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.5156, -1.7891, -1.3359,  ...,  0.7456, -4.7422, -2.1953],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0068, -0.0175,  0.0195,  ...,  0.0558, -0.0258,  0.0230],
        [ 0.0130,  0.0439, -0.0015,  ...,  0.0072, -0.0030, -0.0018],
        [-0.0162, -0.0078,  0.0459,  ...,  0.0167, -0.0085,  0.0035],
        ...,
        [ 0.0195,  0.0301, -0.0187,  ...,  0.0159,  0.0089, -0.0157],
        [-0.0078,  0.0059,  0.0247,  ...,  0.0069, -0.0055,  0.0234],
        [-0.0132,  0.0030, -0.0053,  ...,  0.0222,  0.0433,  0.0322]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.5547, -1.6953, -1.4180,  ...,  0.6724, -4.7539, -2.4277]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 20:12:18 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A female father is known as a mother
A female poet is known as a poetess
A female superman is known as a superwoman
A female actor is known as a actress
A female webmaster is known as a webmistress
A female buck is known as a doe
A female batman is known as a batwoman
A female grandfather is known as a
2024-07-30 20:12:19 root INFO     [order_1_approx] starting weight calculation for A female batman is known as a batwoman
A female webmaster is known as a webmistress
A female poet is known as a poetess
A female actor is known as a actress
A female grandfather is known as a grandmother
A female father is known as a mother
A female superman is known as a superwoman
A female buck is known as a
2024-07-30 20:12:19 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 20:14:40 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1189, -0.3906, -0.2207,  ...,  0.1195, -0.0488,  0.1285],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.9551, -3.8984, -0.5073,  ..., -1.4414, -1.9961, -1.4004],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0684,  0.0031,  0.0281,  ...,  0.0088,  0.0149,  0.0275],
        [ 0.0210,  0.0482,  0.0106,  ..., -0.0067,  0.0032, -0.0078],
        [ 0.0209, -0.0370,  0.0335,  ..., -0.0279,  0.0128,  0.0103],
        ...,
        [ 0.0051,  0.0194,  0.0092,  ...,  0.0345, -0.0072, -0.0147],
        [-0.0264,  0.0209, -0.0015,  ..., -0.0194,  0.0112, -0.0258],
        [ 0.0465,  0.0055, -0.0049,  ...,  0.0214, -0.0163,  0.0486]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.2979, -3.8711,  0.0054,  ..., -1.5586, -2.2578, -1.1738]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 20:14:41 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of period is periods
The plural form of solution is solutions
The plural form of director is directors
The plural form of car is cars
The plural form of example is examples
The plural form of day is days
The plural form of science is sciences
The plural form of version is
2024-07-30 20:14:41 root INFO     [order_1_approx] starting weight calculation for The plural form of solution is solutions
The plural form of director is directors
The plural form of science is sciences
The plural form of period is periods
The plural form of example is examples
The plural form of version is versions
The plural form of day is days
The plural form of car is
2024-07-30 20:14:41 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-30 20:14:46 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2505,  0.2913, -0.0211,  ..., -0.0846, -0.3142,  0.5908],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.3281, -2.6855, -0.8320,  ...,  2.3672, -5.6875,  0.9985],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0216,  0.0218,  0.0017,  ...,  0.0199,  0.0154, -0.0168],
        [-0.0024,  0.0561,  0.0131,  ...,  0.0297,  0.0407,  0.0116],
        [-0.0107, -0.0069,  0.0344,  ..., -0.0099, -0.0173, -0.0111],
        ...,
        [-0.0163, -0.0401, -0.0082,  ...,  0.0432,  0.0074, -0.0186],
        [ 0.0104,  0.0192,  0.0188,  ..., -0.0200,  0.0017, -0.0165],
        [-0.0086, -0.0141, -0.0129,  ..., -0.0392, -0.0074,  0.0130]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.4648, -3.0137, -0.6934,  ...,  2.7363, -5.7891,  1.4102]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 20:14:47 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A female batman is known as a batwoman
A female webmaster is known as a webmistress
A female poet is known as a poetess
A female actor is known as a actress
A female grandfather is known as a grandmother
A female father is known as a mother
A female superman is known as a superwoman
A female buck is known as a
2024-07-30 20:14:48 root INFO     [order_1_approx] starting weight calculation for A female webmaster is known as a webmistress
A female grandfather is known as a grandmother
A female batman is known as a batwoman
A female actor is known as a actress
A female buck is known as a doe
A female poet is known as a poetess
A female superman is known as a superwoman
A female father is known as a
2024-07-30 20:14:48 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 20:17:19 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0071, -0.0214, -0.0244,  ...,  0.0273, -0.1428,  0.0832],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.8828, -4.4375,  1.4785,  ..., -2.4844,  1.4463, -0.4824],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0389,  0.0151, -0.0011,  ..., -0.0233,  0.0076,  0.0080],
        [ 0.0166,  0.0139,  0.0216,  ...,  0.0177,  0.0055, -0.0234],
        [ 0.0042, -0.0123,  0.0283,  ...,  0.0028, -0.0182,  0.0555],
        ...,
        [ 0.0078,  0.0202, -0.0047,  ...,  0.0035, -0.0101,  0.0101],
        [-0.0153,  0.0537, -0.0095,  ...,  0.0100,  0.0233, -0.0607],
        [ 0.0005, -0.0076, -0.0304,  ...,  0.0035, -0.0206,  0.0250]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.9580, -4.4688,  1.7871,  ..., -2.1289,  0.7153,  0.1680]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 20:17:20 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of solution is solutions
The plural form of director is directors
The plural form of science is sciences
The plural form of period is periods
The plural form of example is examples
The plural form of version is versions
The plural form of day is days
The plural form of car is
2024-07-30 20:17:20 root INFO     [order_1_approx] starting weight calculation for The plural form of period is periods
The plural form of example is examples
The plural form of science is sciences
The plural form of director is directors
The plural form of solution is solutions
The plural form of car is cars
The plural form of version is versions
The plural form of day is
2024-07-30 20:17:20 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-30 20:17:20 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2881,  0.2400, -0.3169,  ..., -0.3667, -0.2920,  0.0879],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 5.7812, -2.5098, -0.9580,  ...,  1.1602, -4.3672, -0.7798],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0048,  0.0051,  0.0185,  ...,  0.0192,  0.0111,  0.0197],
        [-0.0007,  0.0630,  0.0226,  ...,  0.0301,  0.0149, -0.0163],
        [-0.0177, -0.0104,  0.0512,  ..., -0.0148, -0.0163, -0.0003],
        ...,
        [ 0.0140, -0.0119, -0.0022,  ...,  0.0341,  0.0172, -0.0195],
        [ 0.0332, -0.0102,  0.0309,  ..., -0.0127, -0.0193,  0.0023],
        [ 0.0165, -0.0389, -0.0128,  ..., -0.0308,  0.0168,  0.0205]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 5.3594, -2.7246, -1.0684,  ...,  1.6289, -4.0430, -0.2666]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 20:17:21 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A female webmaster is known as a webmistress
A female grandfather is known as a grandmother
A female batman is known as a batwoman
A female actor is known as a actress
A female buck is known as a doe
A female poet is known as a poetess
A female superman is known as a superwoman
A female father is known as a
2024-07-30 20:17:21 root INFO     [order_1_approx] starting weight calculation for A female buck is known as a doe
A female grandfather is known as a grandmother
A female superman is known as a superwoman
A female father is known as a mother
A female actor is known as a actress
A female batman is known as a batwoman
A female webmaster is known as a webmistress
A female poet is known as a
2024-07-30 20:17:21 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 20:19:54 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0447,  0.1345, -0.0802,  ..., -0.1199, -0.2301,  0.2810],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.2871, -6.5430,  0.6982,  ..., -0.8359, -4.8438, -0.3828],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0445, -0.0119,  0.0069,  ...,  0.0010,  0.0059,  0.0138],
        [ 0.0282,  0.0193, -0.0007,  ...,  0.0090,  0.0088, -0.0213],
        [ 0.0152,  0.0092,  0.0534,  ...,  0.0088, -0.0374,  0.0059],
        ...,
        [ 0.0024,  0.0053,  0.0104,  ...,  0.0536,  0.0058, -0.0203],
        [-0.0027, -0.0026,  0.0038,  ...,  0.0154,  0.0031, -0.0003],
        [ 0.0184, -0.0047, -0.0105,  ..., -0.0117,  0.0031,  0.0233]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.7744, -6.1055,  0.5918,  ..., -0.4756, -4.8008, -0.0649]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 20:19:55 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A female buck is known as a doe
A female grandfather is known as a grandmother
A female superman is known as a superwoman
A female father is known as a mother
A female actor is known as a actress
A female batman is known as a batwoman
A female webmaster is known as a webmistress
A female poet is known as a
2024-07-30 20:19:55 root INFO     [order_1_approx] starting weight calculation for A female grandfather is known as a grandmother
A female webmaster is known as a webmistress
A female batman is known as a batwoman
A female poet is known as a poetess
A female actor is known as a actress
A female father is known as a mother
A female buck is known as a doe
A female superman is known as a
2024-07-30 20:19:55 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 20:19:59 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0259, -0.0515, -0.0863,  ..., -0.1704, -0.3259,  0.0604],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.1099, -4.3477,  2.2188,  ..., -1.1084, -0.3047, -3.3672],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0416, -0.0262, -0.0100,  ...,  0.0121,  0.0044, -0.0079],
        [ 0.0325,  0.0148,  0.0193,  ..., -0.0085, -0.0239, -0.0088],
        [-0.0107, -0.0628,  0.0198,  ...,  0.0147, -0.0316,  0.0291],
        ...,
        [ 0.0064, -0.0200,  0.0018,  ...,  0.0155, -0.0288, -0.0028],
        [-0.0238,  0.0518, -0.0167,  ...,  0.0025,  0.0596, -0.0244],
        [-0.0152, -0.0546, -0.0215,  ...,  0.0121, -0.0223,  0.0311]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.3184, -4.4844,  2.1113,  ..., -0.5962, -0.8608, -2.3828]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 20:20:00 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of period is periods
The plural form of example is examples
The plural form of science is sciences
The plural form of director is directors
The plural form of solution is solutions
The plural form of car is cars
The plural form of version is versions
The plural form of day is
2024-07-30 20:20:00 root INFO     [order_1_approx] starting weight calculation for The plural form of day is days
The plural form of director is directors
The plural form of science is sciences
The plural form of car is cars
The plural form of solution is solutions
The plural form of example is examples
The plural form of version is versions
The plural form of period is
2024-07-30 20:20:00 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-30 20:22:27 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3838,  0.0695,  0.0718,  ...,  0.2014, -0.2878,  0.2079],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 6.8984, -4.6914,  0.3972,  ...,  0.9375, -2.9688,  1.8594],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0022, -0.0191,  0.0086,  ...,  0.0121, -0.0009,  0.0010],
        [ 0.0208,  0.0483,  0.0014,  ...,  0.0267,  0.0105, -0.0037],
        [ 0.0189,  0.0360,  0.0378,  ..., -0.0136, -0.0049, -0.0276],
        ...,
        [ 0.0145, -0.0045, -0.0319,  ...,  0.0414, -0.0044,  0.0171],
        [-0.0133, -0.0144, -0.0035,  ...,  0.0143,  0.0139, -0.0023],
        [ 0.0063, -0.0205, -0.0047,  ..., -0.0135,  0.0033,  0.0150]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 6.7812, -4.6055,  0.1182,  ...,  1.2480, -3.0703,  2.0332]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 20:22:28 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A female grandfather is known as a grandmother
A female webmaster is known as a webmistress
A female batman is known as a batwoman
A female poet is known as a poetess
A female actor is known as a actress
A female father is known as a mother
A female buck is known as a doe
A female superman is known as a
2024-07-30 20:22:28 root INFO     [order_1_approx] starting weight calculation for A female superman is known as a superwoman
A female actor is known as a actress
A female buck is known as a doe
A female grandfather is known as a grandmother
A female poet is known as a poetess
A female father is known as a mother
A female batman is known as a batwoman
A female webmaster is known as a
2024-07-30 20:22:28 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 20:22:42 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1572,  0.0298, -0.0361,  ..., -0.0166, -0.2426,  0.0680],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.0202, -2.8242,  2.0605,  ..., -0.4629, -0.2642, -0.8223],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0472,  0.0019,  0.0154,  ..., -0.0162, -0.0133, -0.0037],
        [ 0.0368,  0.0521,  0.0136,  ...,  0.0014, -0.0225,  0.0055],
        [-0.0332, -0.0136,  0.0559,  ..., -0.0030, -0.0093, -0.0157],
        ...,
        [ 0.0088,  0.0386,  0.0182,  ...,  0.0681,  0.0045,  0.0222],
        [-0.0055, -0.0039, -0.0192,  ...,  0.0436,  0.0349, -0.0105],
        [ 0.0257, -0.0086, -0.0213,  ...,  0.0159, -0.0088,  0.0354]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.3889, -2.3984,  1.8027,  ..., -0.3157, -0.4268, -0.6631]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 20:22:43 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of day is days
The plural form of director is directors
The plural form of science is sciences
The plural form of car is cars
The plural form of solution is solutions
The plural form of example is examples
The plural form of version is versions
The plural form of period is
2024-07-30 20:22:43 root INFO     [order_1_approx] starting weight calculation for The plural form of period is periods
The plural form of version is versions
The plural form of science is sciences
The plural form of solution is solutions
The plural form of day is days
The plural form of car is cars
The plural form of example is examples
The plural form of director is
2024-07-30 20:22:43 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-30 20:25:00 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4033,  0.1978, -0.1395,  ...,  0.2661, -0.5386,  0.1921],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.3984, -5.4219, -0.1082,  ...,  0.5317, -2.0684,  1.1670],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0540, -0.0097, -0.0219,  ...,  0.0066, -0.0064,  0.0149],
        [-0.0094,  0.0428, -0.0122,  ...,  0.0047,  0.0085,  0.0047],
        [-0.0103,  0.0079,  0.0487,  ..., -0.0241, -0.0098,  0.0051],
        ...,
        [ 0.0062,  0.0171,  0.0003,  ...,  0.0525,  0.0033, -0.0141],
        [-0.0126,  0.0147, -0.0076,  ...,  0.0032,  0.0185, -0.0307],
        [-0.0014, -0.0201, -0.0117,  ..., -0.0075,  0.0022,  0.0334]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.4922, -5.7812, -0.3010,  ...,  0.8208, -2.1172,  1.1592]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 20:25:01 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A female superman is known as a superwoman
A female actor is known as a actress
A female buck is known as a doe
A female grandfather is known as a grandmother
A female poet is known as a poetess
A female father is known as a mother
A female batman is known as a batwoman
A female webmaster is known as a
2024-07-30 20:25:01 root INFO     [order_1_approx] starting weight calculation for A female buck is known as a doe
A female poet is known as a poetess
A female grandfather is known as a grandmother
A female father is known as a mother
A female superman is known as a superwoman
A female batman is known as a batwoman
A female webmaster is known as a webmistress
A female actor is known as a
2024-07-30 20:25:01 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 20:25:21 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0262,  0.1864, -0.2163,  ..., -0.0012, -0.1953,  0.0543],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.4355, -3.0352,  3.5254,  ..., -1.3223, -0.3030, -3.3438],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0587,  0.0098, -0.0043,  ...,  0.0052, -0.0288, -0.0254],
        [ 0.0327,  0.0162,  0.0101,  ..., -0.0275, -0.0070, -0.0198],
        [ 0.0048, -0.0120,  0.0373,  ...,  0.0209, -0.0474,  0.0075],
        ...,
        [-0.0103, -0.0108, -0.0004,  ...,  0.0341,  0.0036, -0.0094],
        [-0.0197, -0.0087, -0.0169,  ...,  0.0380,  0.0263, -0.0286],
        [ 0.0376, -0.0170,  0.0018,  ...,  0.0061,  0.0003,  0.0328]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.4824, -2.8496,  3.2715,  ..., -1.5244,  0.0784, -3.2812]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 20:25:22 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of period is periods
The plural form of version is versions
The plural form of science is sciences
The plural form of solution is solutions
The plural form of day is days
The plural form of car is cars
The plural form of example is examples
The plural form of director is
2024-07-30 20:25:22 root INFO     [order_1_approx] starting weight calculation for The plural form of example is examples
The plural form of version is versions
The plural form of science is sciences
The plural form of car is cars
The plural form of day is days
The plural form of period is periods
The plural form of director is directors
The plural form of solution is
2024-07-30 20:25:22 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-30 20:27:33 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2529,  0.6963, -0.1494,  ..., -0.0878, -0.4321, -0.0859],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.8672, -4.2539,  1.4072,  ..., -0.6562, -4.5781, -0.3330],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0299, -0.0184,  0.0041,  ...,  0.0137,  0.0226,  0.0087],
        [ 0.0233,  0.0427,  0.0040,  ...,  0.0085,  0.0251, -0.0062],
        [ 0.0015,  0.0117,  0.0533,  ..., -0.0292, -0.0257, -0.0099],
        ...,
        [-0.0036,  0.0125, -0.0087,  ...,  0.0322,  0.0104, -0.0184],
        [-0.0206, -0.0038,  0.0096,  ..., -0.0227,  0.0067, -0.0053],
        [ 0.0206,  0.0028, -0.0374,  ..., -0.0002,  0.0165,  0.0335]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.4336, -4.2148,  1.3994,  ..., -0.2864, -4.9648, -0.1995]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 20:27:34 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A female buck is known as a doe
A female poet is known as a poetess
A female grandfather is known as a grandmother
A female father is known as a mother
A female superman is known as a superwoman
A female batman is known as a batwoman
A female webmaster is known as a webmistress
A female actor is known as a
2024-07-30 20:27:34 root INFO     total operator prediction time: 1221.156025648117 seconds
2024-07-30 20:27:34 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on animal - shelter
2024-07-30 20:27:34 root INFO     building operator animal - shelter
2024-07-30 20:27:34 root INFO     [order_1_approx] starting weight calculation for The place tiger lives in is called den
The place hedgehog lives in is called nest
The place fox lives in is called den
The place wasp lives in is called nest
The place scorpion lives in is called nest
The place spider lives in is called web
The place locust lives in is called nest
The place crocodile lives in is called
2024-07-30 20:27:34 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 20:28:02 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1343, -0.1356, -0.2314,  ..., -0.1353, -0.3313,  0.1169],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.0859, -1.8662,  1.0146,  ..., -0.9199, -2.8164, -1.2969],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0849,  0.0259,  0.0154,  ..., -0.0220,  0.0238, -0.0274],
        [-0.0011,  0.0315,  0.0033,  ...,  0.0179, -0.0106,  0.0276],
        [-0.0068, -0.0023,  0.0151,  ..., -0.0009, -0.0315, -0.0216],
        ...,
        [-0.0038,  0.0014,  0.0048,  ...,  0.0630, -0.0180,  0.0205],
        [ 0.0168,  0.0073, -0.0354,  ...,  0.0018,  0.0453, -0.0314],
        [ 0.0308,  0.0088, -0.0024,  ...,  0.0374,  0.0078,  0.0630]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.7480, -2.2891,  1.4463,  ..., -0.2822, -2.9902, -1.2490]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 20:28:03 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of example is examples
The plural form of version is versions
The plural form of science is sciences
The plural form of car is cars
The plural form of day is days
The plural form of period is periods
The plural form of director is directors
The plural form of solution is
2024-07-30 20:28:03 root INFO     [order_1_approx] starting weight calculation for The plural form of solution is solutions
The plural form of example is examples
The plural form of day is days
The plural form of period is periods
The plural form of car is cars
The plural form of director is directors
The plural form of version is versions
The plural form of science is
2024-07-30 20:28:03 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-30 20:30:05 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.5020, -0.3027, -0.2556,  ...,  0.0391, -0.4028,  0.1715],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.2344, -6.6797, -0.0605,  ..., -2.3945, -0.2715,  0.6523],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0117,  0.0001,  0.0046,  ...,  0.0033, -0.0027, -0.0075],
        [-0.0049,  0.0148, -0.0012,  ...,  0.0038, -0.0091,  0.0031],
        [-0.0064,  0.0072,  0.0194,  ..., -0.0028,  0.0047, -0.0044],
        ...,
        [-0.0055,  0.0019,  0.0019,  ...,  0.0102,  0.0091,  0.0058],
        [ 0.0042,  0.0042,  0.0078,  ...,  0.0050,  0.0096,  0.0019],
        [-0.0086,  0.0027, -0.0018,  ..., -0.0033, -0.0049,  0.0174]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.3242, -6.6289, -0.2910,  ..., -2.3164, -0.4517,  0.5996]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 20:30:06 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The place tiger lives in is called den
The place hedgehog lives in is called nest
The place fox lives in is called den
The place wasp lives in is called nest
The place scorpion lives in is called nest
The place spider lives in is called web
The place locust lives in is called nest
The place crocodile lives in is called
2024-07-30 20:30:06 root INFO     [order_1_approx] starting weight calculation for The place hedgehog lives in is called nest
The place wasp lives in is called nest
The place fox lives in is called den
The place scorpion lives in is called nest
The place tiger lives in is called den
The place spider lives in is called web
The place crocodile lives in is called river
The place locust lives in is called
2024-07-30 20:30:06 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 20:30:43 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1754, -0.0620, -0.0585,  ..., -0.0856, -0.1748, -0.0697],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.4238, -1.9199,  2.6465,  ..., -0.0176, -1.6387, -1.8965],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0740, -0.0220,  0.0425,  ..., -0.0095, -0.0247, -0.0324],
        [ 0.0046,  0.0413,  0.0551,  ...,  0.0080, -0.0224, -0.0206],
        [-0.0257, -0.0121,  0.0309,  ..., -0.0081, -0.0116,  0.0132],
        ...,
        [ 0.0440,  0.0318, -0.0077,  ...,  0.0367, -0.0013,  0.0274],
        [ 0.0031,  0.0281, -0.0255,  ..., -0.0076,  0.0381,  0.0086],
        [ 0.0125, -0.0169, -0.0105,  ...,  0.0275, -0.0016, -0.0245]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.7354, -2.6133,  1.9482,  ...,  0.1719, -1.8340, -1.3828]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 20:30:44 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of solution is solutions
The plural form of example is examples
The plural form of day is days
The plural form of period is periods
The plural form of car is cars
The plural form of director is directors
The plural form of version is versions
The plural form of science is
2024-07-30 20:30:44 root INFO     total operator prediction time: 1283.029676437378 seconds
2024-07-30 20:30:44 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on verb_Ving - 3pSg
2024-07-30 20:30:44 root INFO     building operator verb_Ving - 3pSg
2024-07-30 20:30:44 root INFO     [order_1_approx] starting weight calculation for When something is creating, it creates
When something is adding, it adds
When something is providing, it provides
When something is asking, it asks
When something is improving, it improves
When something is hearing, it hears
When something is receiving, it receives
When something is understanding, it
2024-07-30 20:30:44 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-30 20:32:36 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0169, -0.2603,  0.0120,  ...,  0.2479, -0.2303,  0.0117],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.3789, -5.2031,  3.0742,  ..., -0.0387,  1.1963, -3.4375],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 3.7048e-02, -2.8458e-02,  1.7715e-02,  ...,  1.9653e-02,
         -3.7689e-03,  4.7531e-03],
        [ 3.9429e-02,  2.6398e-02,  1.1414e-02,  ...,  3.1769e-02,
         -2.2675e-02,  8.9645e-05],
        [-1.2646e-03,  2.1881e-02,  6.8970e-02,  ...,  2.4445e-02,
         -2.9999e-02,  5.0011e-03],
        ...,
        [-7.7972e-03,  1.1795e-02,  2.8519e-02,  ...,  7.0618e-02,
          1.3779e-02,  5.3444e-03],
        [-7.1106e-03,  1.1803e-02,  1.6235e-02,  ...,  3.1738e-02,
          1.6312e-02,  1.0994e-02],
        [-4.7951e-03,  4.7836e-03, -5.5199e-03,  ..., -3.0918e-03,
         -1.3908e-02,  5.6458e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.2500, -5.7852,  2.6230,  ..., -0.4775,  0.4609, -2.9707]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 20:32:37 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The place hedgehog lives in is called nest
The place wasp lives in is called nest
The place fox lives in is called den
The place scorpion lives in is called nest
The place tiger lives in is called den
The place spider lives in is called web
The place crocodile lives in is called river
The place locust lives in is called
2024-07-30 20:32:38 root INFO     [order_1_approx] starting weight calculation for The place tiger lives in is called den
The place wasp lives in is called nest
The place locust lives in is called nest
The place spider lives in is called web
The place fox lives in is called den
The place scorpion lives in is called nest
The place crocodile lives in is called river
The place hedgehog lives in is called
2024-07-30 20:32:38 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 20:33:23 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0146,  0.5811, -0.0516,  ...,  0.2603, -0.2839, -0.2443],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.8281, -1.8652, -0.8281,  ..., -1.3203, -6.4766,  1.9648],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0135, -0.0028,  0.0051,  ..., -0.0066, -0.0218,  0.0053],
        [-0.0106,  0.0104,  0.0004,  ..., -0.0024, -0.0009,  0.0149],
        [ 0.0085, -0.0106,  0.0177,  ..., -0.0234, -0.0224, -0.0068],
        ...,
        [ 0.0207,  0.0023,  0.0108,  ...,  0.0099, -0.0069, -0.0067],
        [ 0.0149, -0.0055,  0.0010,  ..., -0.0120, -0.0099, -0.0405],
        [-0.0083, -0.0162,  0.0107,  ...,  0.0150, -0.0420, -0.0155]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.7383, -1.8164, -0.9004,  ..., -1.1875, -6.6367,  1.2207]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 20:33:24 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When something is creating, it creates
When something is adding, it adds
When something is providing, it provides
When something is asking, it asks
When something is improving, it improves
When something is hearing, it hears
When something is receiving, it receives
When something is understanding, it
2024-07-30 20:33:24 root INFO     [order_1_approx] starting weight calculation for When something is providing, it provides
When something is understanding, it understands
When something is creating, it creates
When something is improving, it improves
When something is adding, it adds
When something is hearing, it hears
When something is asking, it asks
When something is receiving, it
2024-07-30 20:33:24 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-30 20:35:07 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2445, -0.2310,  0.0646,  ...,  0.0410, -0.4290, -0.0508],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.2070, -5.1328,  0.8125,  ..., -1.7471,  1.5967,  0.6445],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 1.2054e-02, -1.4511e-02, -6.9351e-03,  ..., -7.7171e-03,
         -6.9351e-03, -5.5351e-03],
        [ 2.1420e-03,  3.1708e-02,  5.9891e-03,  ...,  1.4511e-02,
          2.0218e-03, -1.0376e-02],
        [ 2.5101e-03,  1.4915e-02,  1.1986e-02,  ..., -1.2985e-02,
         -5.1346e-03,  8.9836e-04],
        ...,
        [ 5.5847e-03,  1.1955e-02,  1.0010e-02,  ...,  1.5961e-02,
          4.7035e-03,  6.0577e-03],
        [-8.6784e-05,  2.2461e-02, -4.2343e-04,  ...,  1.4595e-02,
          1.7670e-02, -7.4654e-03],
        [ 2.1942e-02, -7.0343e-03, -9.7466e-04,  ...,  7.6752e-03,
         -2.4597e-02,  6.7062e-03]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.0781, -5.0742,  0.6006,  ..., -1.8184,  1.5684,  0.1780]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 20:35:07 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The place tiger lives in is called den
The place wasp lives in is called nest
The place locust lives in is called nest
The place spider lives in is called web
The place fox lives in is called den
The place scorpion lives in is called nest
The place crocodile lives in is called river
The place hedgehog lives in is called
2024-07-30 20:35:08 root INFO     [order_1_approx] starting weight calculation for The place crocodile lives in is called river
The place fox lives in is called den
The place locust lives in is called nest
The place scorpion lives in is called nest
The place tiger lives in is called den
The place spider lives in is called web
The place hedgehog lives in is called nest
The place wasp lives in is called
2024-07-30 20:35:08 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 20:36:02 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1790,  0.1027, -0.0344,  ..., -0.2468,  0.0621, -0.2378],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.0615, -2.7578, -3.3770,  ..., -2.4512, -6.6914, -2.4180],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0174,  0.0016, -0.0021,  ...,  0.0057, -0.0100,  0.0091],
        [-0.0155,  0.0080,  0.0086,  ..., -0.0063, -0.0117, -0.0043],
        [ 0.0052, -0.0033,  0.0193,  ..., -0.0167, -0.0026, -0.0120],
        ...,
        [ 0.0305,  0.0128,  0.0192,  ...,  0.0141, -0.0131,  0.0082],
        [ 0.0380, -0.0132, -0.0124,  ..., -0.0305,  0.0201, -0.0465],
        [ 0.0128,  0.0007, -0.0150,  ...,  0.0126, -0.0003, -0.0084]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.4282, -3.0957, -3.1387,  ..., -2.5410, -7.1016, -2.8672]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 20:36:03 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When something is providing, it provides
When something is understanding, it understands
When something is creating, it creates
When something is improving, it improves
When something is adding, it adds
When something is hearing, it hears
When something is asking, it asks
When something is receiving, it
2024-07-30 20:36:03 root INFO     [order_1_approx] starting weight calculation for When something is understanding, it understands
When something is asking, it asks
When something is providing, it provides
When something is creating, it creates
When something is hearing, it hears
When something is improving, it improves
When something is receiving, it receives
When something is adding, it
2024-07-30 20:36:03 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-30 20:37:39 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1327, -0.3965,  0.0602,  ...,  0.5312,  0.0995, -0.0386],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.5273, -5.7383,  3.2148,  ..., -1.9971, -0.1987,  0.6240],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 5.6305e-02,  2.8801e-03,  2.0065e-03,  ...,  1.8768e-02,
         -7.9193e-03, -6.9618e-03],
        [-1.4328e-02,  6.1646e-02,  1.8585e-02,  ...,  2.6459e-02,
          2.5864e-03, -9.6664e-03],
        [-7.1287e-04,  4.4250e-02,  4.9469e-02,  ...,  1.4252e-02,
         -3.2410e-02,  6.1493e-03],
        ...,
        [-1.3977e-02, -1.1475e-02,  2.0020e-02,  ...,  3.6072e-02,
          2.3941e-02, -2.4796e-05],
        [ 8.1863e-03, -2.4948e-03, -5.4054e-03,  ...,  3.4302e-02,
         -8.8806e-03,  3.7060e-03],
        [-1.2512e-02, -1.7410e-02, -1.8524e-02,  ...,  1.3489e-02,
         -4.0253e-02,  3.5370e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.7461, -5.8789,  2.7148,  ..., -1.8779, -0.1989,  0.9048]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 20:37:40 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The place crocodile lives in is called river
The place fox lives in is called den
The place locust lives in is called nest
The place scorpion lives in is called nest
The place tiger lives in is called den
The place spider lives in is called web
The place hedgehog lives in is called nest
The place wasp lives in is called
2024-07-30 20:37:40 root INFO     [order_1_approx] starting weight calculation for The place tiger lives in is called den
The place wasp lives in is called nest
The place crocodile lives in is called river
The place spider lives in is called web
The place fox lives in is called den
The place hedgehog lives in is called nest
The place locust lives in is called nest
The place scorpion lives in is called
2024-07-30 20:37:40 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 20:38:43 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0345,  0.0656,  0.1799,  ...,  0.1543, -0.3826,  0.0155],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.6240, -1.4971, -2.4648,  ...,  0.4460, -9.7109,  0.1016],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0414, -0.0257,  0.0086,  ...,  0.0050, -0.0243, -0.0066],
        [-0.0230,  0.0483,  0.0194,  ..., -0.0027, -0.0219, -0.0047],
        [-0.0269,  0.0153,  0.0356,  ...,  0.0137,  0.0075,  0.0057],
        ...,
        [ 0.0060,  0.0069,  0.0200,  ...,  0.0175, -0.0164,  0.0118],
        [ 0.0465, -0.0118, -0.0145,  ..., -0.0357,  0.0300, -0.0154],
        [ 0.0028, -0.0092,  0.0095,  ..., -0.0060, -0.0335,  0.0116]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.2773, -2.1816, -1.8955,  ...,  0.4866, -9.8906, -0.1743]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 20:38:44 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When something is understanding, it understands
When something is asking, it asks
When something is providing, it provides
When something is creating, it creates
When something is hearing, it hears
When something is improving, it improves
When something is receiving, it receives
When something is adding, it
2024-07-30 20:38:44 root INFO     [order_1_approx] starting weight calculation for When something is creating, it creates
When something is understanding, it understands
When something is adding, it adds
When something is asking, it asks
When something is receiving, it receives
When something is hearing, it hears
When something is improving, it improves
When something is providing, it
2024-07-30 20:38:44 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-30 20:40:12 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1289, -0.1758, -0.2439,  ..., -0.1251,  0.0401,  0.0928],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.9609, -5.3711,  1.5967,  ..., -1.8770,  0.8696, -0.4004],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 1.9852e-02,  1.5850e-03,  7.1526e-03,  ...,  1.2245e-02,
         -7.3586e-03, -5.0430e-03],
        [-6.5765e-03,  9.8038e-03, -4.1885e-03,  ...,  5.1651e-03,
         -4.3869e-03,  3.9101e-05],
        [ 1.1307e-02,  1.6785e-02,  1.5511e-02,  ...,  8.8501e-04,
          7.9632e-05, -1.8845e-03],
        ...,
        [-2.8744e-03,  5.4550e-03,  4.2953e-03,  ...,  8.1406e-03,
          6.8817e-03, -1.6174e-03],
        [ 1.6251e-03,  4.5891e-03, -1.2608e-03,  ...,  3.2787e-03,
          1.2657e-02, -6.0959e-03],
        [-9.1476e-03, -3.3684e-03, -5.2299e-03,  ..., -4.8561e-03,
         -2.3823e-03,  1.7761e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.9785, -5.4922,  1.4131,  ..., -1.8984,  0.8613, -0.3042]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 20:40:13 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The place tiger lives in is called den
The place wasp lives in is called nest
The place crocodile lives in is called river
The place spider lives in is called web
The place fox lives in is called den
The place hedgehog lives in is called nest
The place locust lives in is called nest
The place scorpion lives in is called
2024-07-30 20:40:14 root INFO     [order_1_approx] starting weight calculation for The place crocodile lives in is called river
The place scorpion lives in is called nest
The place fox lives in is called den
The place hedgehog lives in is called nest
The place wasp lives in is called nest
The place locust lives in is called nest
The place spider lives in is called web
The place tiger lives in is called
2024-07-30 20:40:14 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 20:41:23 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3228,  0.0486, -0.1350,  ...,  0.0909, -0.1677, -0.2179],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.9453, -6.1406, -1.5000,  ..., -2.0156, -8.5312,  1.4180],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0261, -0.0050, -0.0211,  ...,  0.0124, -0.0265,  0.0163],
        [-0.0001,  0.0303, -0.0010,  ..., -0.0039,  0.0119,  0.0216],
        [-0.0014, -0.0041,  0.0269,  ..., -0.0091, -0.0270, -0.0328],
        ...,
        [ 0.0223,  0.0235,  0.0086,  ...,  0.0117, -0.0148, -0.0026],
        [ 0.0254, -0.0082, -0.0041,  ..., -0.0150, -0.0115, -0.0579],
        [ 0.0044,  0.0033, -0.0122,  ...,  0.0008, -0.0475,  0.0018]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.8281, -6.0508, -1.3154,  ..., -2.0527, -8.7812,  0.6304]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 20:41:24 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When something is creating, it creates
When something is understanding, it understands
When something is adding, it adds
When something is asking, it asks
When something is receiving, it receives
When something is hearing, it hears
When something is improving, it improves
When something is providing, it
2024-07-30 20:41:24 root INFO     [order_1_approx] starting weight calculation for When something is receiving, it receives
When something is understanding, it understands
When something is improving, it improves
When something is asking, it asks
When something is creating, it creates
When something is adding, it adds
When something is providing, it provides
When something is hearing, it
2024-07-30 20:41:24 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-30 20:42:46 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0720,  0.2156, -0.2991,  ...,  0.3843, -0.1560, -0.0145],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([  4.2891, -10.2188,   0.9863,  ...,  -2.0254,  -0.6182,  -1.6436],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0199, -0.0152, -0.0007,  ...,  0.0026, -0.0059, -0.0131],
        [ 0.0104,  0.0137,  0.0095,  ...,  0.0134, -0.0011,  0.0048],
        [-0.0260,  0.0213,  0.0593,  ...,  0.0065,  0.0007, -0.0302],
        ...,
        [-0.0065,  0.0003,  0.0203,  ...,  0.0387,  0.0162, -0.0159],
        [ 0.0219, -0.0019, -0.0034,  ...,  0.0287,  0.0124, -0.0269],
        [-0.0146, -0.0315, -0.0226,  ..., -0.0337, -0.0316,  0.0486]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.3398, -9.4688,  0.5127,  ..., -1.7930, -0.7915, -0.8892]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 20:42:47 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The place crocodile lives in is called river
The place scorpion lives in is called nest
The place fox lives in is called den
The place hedgehog lives in is called nest
The place wasp lives in is called nest
The place locust lives in is called nest
The place spider lives in is called web
The place tiger lives in is called
2024-07-30 20:42:47 root INFO     [order_1_approx] starting weight calculation for The place fox lives in is called den
The place wasp lives in is called nest
The place scorpion lives in is called nest
The place locust lives in is called nest
The place hedgehog lives in is called nest
The place crocodile lives in is called river
The place tiger lives in is called den
The place spider lives in is called
2024-07-30 20:42:47 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 20:44:01 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0323, -0.0205,  0.0653,  ...,  0.2830,  0.0322, -0.0029],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.5664, -3.1367, -1.3730,  ..., -3.0977, -7.4375, -2.7500],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0352,  0.0097,  0.0347,  ..., -0.0107,  0.0038, -0.0271],
        [-0.0161,  0.0285,  0.0002,  ..., -0.0112, -0.0128,  0.0167],
        [ 0.0062, -0.0087,  0.0290,  ..., -0.0161, -0.0044, -0.0005],
        ...,
        [ 0.0392, -0.0092,  0.0144,  ...,  0.0350, -0.0114,  0.0105],
        [ 0.0136,  0.0065, -0.0210,  ..., -0.0184,  0.0440, -0.0270],
        [ 0.0168,  0.0075,  0.0059,  ...,  0.0135,  0.0076,  0.0182]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.5674, -3.3789, -1.2695,  ..., -2.7793, -7.0391, -3.2832]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 20:44:02 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When something is receiving, it receives
When something is understanding, it understands
When something is improving, it improves
When something is asking, it asks
When something is creating, it creates
When something is adding, it adds
When something is providing, it provides
When something is hearing, it
2024-07-30 20:44:03 root INFO     [order_1_approx] starting weight calculation for When something is receiving, it receives
When something is adding, it adds
When something is providing, it provides
When something is creating, it creates
When something is hearing, it hears
When something is improving, it improves
When something is understanding, it understands
When something is asking, it
2024-07-30 20:44:03 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-30 20:45:18 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0450, -0.0593, -0.0240,  ...,  0.3625,  0.0998,  0.3096],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.8018, -5.1992,  3.0000,  ...,  0.0884, -0.2756, -1.8633],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0241, -0.0161, -0.0024,  ..., -0.0040, -0.0026, -0.0155],
        [-0.0173,  0.0323,  0.0038,  ...,  0.0197, -0.0056, -0.0106],
        [ 0.0047,  0.0491,  0.0439,  ...,  0.0055, -0.0117, -0.0133],
        ...,
        [-0.0089, -0.0037,  0.0040,  ...,  0.0306,  0.0249,  0.0037],
        [ 0.0043,  0.0033, -0.0070,  ...,  0.0134,  0.0207,  0.0015],
        [-0.0137, -0.0013, -0.0074,  ...,  0.0017, -0.0001,  0.0442]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.4062, -5.3125,  2.4688,  ...,  0.0781, -0.2202, -1.5352]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 20:45:19 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The place fox lives in is called den
The place wasp lives in is called nest
The place scorpion lives in is called nest
The place locust lives in is called nest
The place hedgehog lives in is called nest
The place crocodile lives in is called river
The place tiger lives in is called den
The place spider lives in is called
2024-07-30 20:45:19 root INFO     [order_1_approx] starting weight calculation for The place wasp lives in is called nest
The place spider lives in is called web
The place hedgehog lives in is called nest
The place locust lives in is called nest
The place scorpion lives in is called nest
The place tiger lives in is called den
The place crocodile lives in is called river
The place fox lives in is called
2024-07-30 20:45:19 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 20:46:41 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0149,  0.2598, -0.0938,  ...,  0.2817, -0.1333, -0.4038],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.4141, -3.6348, -1.9512,  ..., -0.9590, -7.4570,  0.3535],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0231, -0.0012,  0.0131,  ...,  0.0147, -0.0101, -0.0082],
        [-0.0160,  0.0251, -0.0060,  ...,  0.0159, -0.0104,  0.0107],
        [-0.0042, -0.0023,  0.0386,  ..., -0.0086, -0.0051,  0.0181],
        ...,
        [ 0.0012,  0.0075,  0.0130,  ...,  0.0098, -0.0075, -0.0015],
        [ 0.0107,  0.0265, -0.0361,  ..., -0.0244,  0.0043, -0.0215],
        [-0.0257, -0.0131, -0.0020,  ...,  0.0161, -0.0241, -0.0102]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.2402, -3.6172, -1.4082,  ..., -0.7529, -7.5000,  0.1772]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 20:46:41 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When something is receiving, it receives
When something is adding, it adds
When something is providing, it provides
When something is creating, it creates
When something is hearing, it hears
When something is improving, it improves
When something is understanding, it understands
When something is asking, it
2024-07-30 20:46:42 root INFO     [order_1_approx] starting weight calculation for When something is understanding, it understands
When something is hearing, it hears
When something is asking, it asks
When something is improving, it improves
When something is adding, it adds
When something is providing, it provides
When something is receiving, it receives
When something is creating, it
2024-07-30 20:46:42 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-30 20:47:50 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1389,  0.2769, -0.1589,  ...,  0.0845, -0.1781, -0.0594],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.7109, -9.0625,  1.5605,  ..., -1.6904, -0.0615,  2.4023],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 2.2110e-02, -8.7738e-05, -3.4447e-03,  ...,  3.5400e-02,
         -3.1548e-03, -7.5188e-03],
        [-6.3324e-03,  4.6570e-02, -1.5198e-02,  ...,  2.4368e-02,
         -2.5970e-02, -2.1362e-02],
        [-1.0544e-02,  1.4725e-02,  5.7831e-02,  ..., -3.0548e-02,
          1.0910e-02, -5.6458e-03],
        ...,
        [-1.6342e-02, -1.1196e-03,  1.0162e-02,  ...,  3.7109e-02,
          1.2901e-02, -1.4809e-02],
        [ 2.5604e-02,  5.1765e-03, -3.0518e-03,  ...,  3.0937e-03,
          2.9572e-02, -1.5091e-02],
        [-2.2316e-03, -1.0277e-02, -2.0981e-02,  ...,  1.0986e-02,
         -1.6602e-02,  4.0222e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.6602, -8.7344,  1.1826,  ..., -1.2676, -0.4666,  2.5391]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 20:47:51 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The place wasp lives in is called nest
The place spider lives in is called web
The place hedgehog lives in is called nest
The place locust lives in is called nest
The place scorpion lives in is called nest
The place tiger lives in is called den
The place crocodile lives in is called river
The place fox lives in is called
2024-07-30 20:47:51 root INFO     total operator prediction time: 1216.7465751171112 seconds
2024-07-30 20:47:51 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on country - language
2024-07-30 20:47:51 root INFO     building operator country - language
2024-07-30 20:47:51 root INFO     [order_1_approx] starting weight calculation for The country of kazakhstan primarily speaks the language of kazak
The country of jordan primarily speaks the language of arabic
The country of denmark primarily speaks the language of danish
The country of haiti primarily speaks the language of creole
The country of ireland primarily speaks the language of english
The country of canada primarily speaks the language of english
The country of ecuador primarily speaks the language of spanish
The country of iraq primarily speaks the language of
2024-07-30 20:47:51 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 20:49:20 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0353,  0.2932, -0.1263,  ..., -0.0150, -0.0957, -0.1221],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.8496, -3.3906,  0.7012,  ..., -0.0391, -6.1016,  1.1328],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0399,  0.0017,  0.0121,  ...,  0.0178, -0.0174,  0.0032],
        [ 0.0084,  0.0461,  0.0141,  ..., -0.0028, -0.0255, -0.0259],
        [-0.0095, -0.0138,  0.0064,  ...,  0.0017, -0.0090, -0.0011],
        ...,
        [ 0.0204,  0.0078,  0.0130,  ...,  0.0251, -0.0085, -0.0008],
        [ 0.0201,  0.0017, -0.0206,  ..., -0.0216,  0.0107, -0.0239],
        [ 0.0074,  0.0095,  0.0070,  ..., -0.0065, -0.0227,  0.0157]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.8066, -3.4336,  0.7407,  ...,  0.1934, -6.2617,  0.4990]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 20:49:29 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When something is understanding, it understands
When something is hearing, it hears
When something is asking, it asks
When something is improving, it improves
When something is adding, it adds
When something is providing, it provides
When something is receiving, it receives
When something is creating, it
2024-07-30 20:49:30 root INFO     [order_1_approx] starting weight calculation for When something is adding, it adds
When something is receiving, it receives
When something is creating, it creates
When something is providing, it provides
When something is hearing, it hears
When something is understanding, it understands
When something is asking, it asks
When something is improving, it
2024-07-30 20:49:30 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-30 20:50:19 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1002, -0.2729, -0.1289,  ...,  0.3000, -0.4717,  0.4194],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.0605, -3.3281,  1.3594,  ..., -2.0547,  0.5264, -2.3477],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0115, -0.0093, -0.0014,  ...,  0.0037,  0.0054,  0.0045],
        [ 0.0075,  0.0167,  0.0040,  ..., -0.0032,  0.0121, -0.0023],
        [-0.0094,  0.0074,  0.0524,  ...,  0.0041, -0.0005, -0.0259],
        ...,
        [ 0.0016, -0.0038, -0.0024,  ...,  0.0287,  0.0052, -0.0059],
        [-0.0095, -0.0012,  0.0051,  ..., -0.0076,  0.0380,  0.0096],
        [-0.0084, -0.0109, -0.0047,  ...,  0.0111, -0.0086,  0.0154]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.6162, -2.9082,  1.4717,  ..., -1.7939,  0.7319, -2.4062]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 20:50:20 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country of kazakhstan primarily speaks the language of kazak
The country of jordan primarily speaks the language of arabic
The country of denmark primarily speaks the language of danish
The country of haiti primarily speaks the language of creole
The country of ireland primarily speaks the language of english
The country of canada primarily speaks the language of english
The country of ecuador primarily speaks the language of spanish
The country of iraq primarily speaks the language of
2024-07-30 20:50:20 root INFO     [order_1_approx] starting weight calculation for The country of haiti primarily speaks the language of creole
The country of kazakhstan primarily speaks the language of kazak
The country of jordan primarily speaks the language of arabic
The country of ireland primarily speaks the language of english
The country of canada primarily speaks the language of english
The country of ecuador primarily speaks the language of spanish
The country of iraq primarily speaks the language of arabic
The country of denmark primarily speaks the language of
2024-07-30 20:50:21 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 20:52:07 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0357,  0.0489, -0.0291,  ...,  0.0679, -0.0594,  0.2827],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 5.9727, -3.9727, -2.5957,  ..., -0.2300, -7.2734, -0.0664],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0240,  0.0254, -0.0082,  ...,  0.0169, -0.0010,  0.0046],
        [-0.0039,  0.0174, -0.0208,  ...,  0.0120, -0.0085,  0.0177],
        [ 0.0105,  0.0035,  0.0119,  ...,  0.0086,  0.0105, -0.0255],
        ...,
        [ 0.0045, -0.0008,  0.0107,  ...,  0.0125,  0.0012,  0.0153],
        [-0.0063, -0.0191,  0.0038,  ...,  0.0014, -0.0181, -0.0385],
        [-0.0033, -0.0056,  0.0118,  ..., -0.0060, -0.0267,  0.0198]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 6.1172, -4.1367, -2.4434,  ..., -0.0249, -7.8828, -0.3677]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 20:52:08 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When something is adding, it adds
When something is receiving, it receives
When something is creating, it creates
When something is providing, it provides
When something is hearing, it hears
When something is understanding, it understands
When something is asking, it asks
When something is improving, it
2024-07-30 20:52:08 root INFO     total operator prediction time: 1284.2864513397217 seconds
2024-07-30 20:52:08 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on verb_inf - 3pSg
2024-07-30 20:52:08 root INFO     building operator verb_inf - 3pSg
2024-07-30 20:52:08 root INFO     [order_1_approx] starting weight calculation for I seem, he seems
I send, he sends
I maintain, he maintains
I enjoy, he enjoys
I reduce, he reduces
I occur, he occurs
I promote, he promotes
I accept, he
2024-07-30 20:52:08 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-30 20:52:52 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2954, -0.3640, -0.4077,  ...,  0.1311,  0.1414,  0.3984],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.8931, -3.6797,  2.0293,  ..., -2.7910, -1.2305, -1.3945],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0435, -0.0203, -0.0285,  ...,  0.0076,  0.0083,  0.0027],
        [-0.0048,  0.0233, -0.0012,  ..., -0.0008,  0.0032, -0.0020],
        [-0.0212, -0.0004,  0.0668,  ..., -0.0092, -0.0099,  0.0026],
        ...,
        [-0.0162,  0.0098,  0.0131,  ...,  0.0193,  0.0059,  0.0036],
        [ 0.0141,  0.0170, -0.0065,  ...,  0.0255,  0.0311,  0.0098],
        [ 0.0010, -0.0404, -0.0290,  ...,  0.0067, -0.0128,  0.0200]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.6880, -3.4336,  1.9678,  ..., -2.6836, -1.2441, -1.2061]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 20:52:53 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country of haiti primarily speaks the language of creole
The country of kazakhstan primarily speaks the language of kazak
The country of jordan primarily speaks the language of arabic
The country of ireland primarily speaks the language of english
The country of canada primarily speaks the language of english
The country of ecuador primarily speaks the language of spanish
The country of iraq primarily speaks the language of arabic
The country of denmark primarily speaks the language of
2024-07-30 20:52:53 root INFO     [order_1_approx] starting weight calculation for The country of canada primarily speaks the language of english
The country of ecuador primarily speaks the language of spanish
The country of denmark primarily speaks the language of danish
The country of kazakhstan primarily speaks the language of kazak
The country of iraq primarily speaks the language of arabic
The country of jordan primarily speaks the language of arabic
The country of haiti primarily speaks the language of creole
The country of ireland primarily speaks the language of
2024-07-30 20:52:53 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 20:54:45 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1382,  0.5791, -0.1246,  ...,  0.1082, -0.2666, -0.1631],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.6289, -2.6406, -2.3809,  ...,  0.5889, -7.5195,  0.4043],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0277, -0.0030,  0.0373,  ...,  0.0093, -0.0033,  0.0097],
        [-0.0101,  0.0190, -0.0210,  ...,  0.0225,  0.0088, -0.0022],
        [-0.0052,  0.0017, -0.0055,  ..., -0.0232,  0.0044, -0.0181],
        ...,
        [ 0.0197,  0.0085,  0.0022,  ...,  0.0308,  0.0026, -0.0156],
        [-0.0150,  0.0129, -0.0140,  ..., -0.0025,  0.0263,  0.0004],
        [ 0.0013, -0.0033,  0.0161,  ..., -0.0029, -0.0135,  0.0103]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.3125, -2.4492, -2.4121,  ...,  0.7354, -7.5352,  0.3867]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 20:54:46 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for I seem, he seems
I send, he sends
I maintain, he maintains
I enjoy, he enjoys
I reduce, he reduces
I occur, he occurs
I promote, he promotes
I accept, he
2024-07-30 20:54:46 root INFO     [order_1_approx] starting weight calculation for I send, he sends
I enjoy, he enjoys
I reduce, he reduces
I maintain, he maintains
I seem, he seems
I promote, he promotes
I accept, he accepts
I occur, he
2024-07-30 20:54:46 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-30 20:55:26 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1265, -0.0460, -0.2610,  ...,  0.1405,  0.0679,  0.3308],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.0427, -3.0742,  0.3210,  ...,  0.8501, -0.1494, -3.3574],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0352, -0.0226, -0.0006,  ...,  0.0130, -0.0058, -0.0123],
        [ 0.0060,  0.0361, -0.0006,  ..., -0.0051, -0.0020, -0.0182],
        [-0.0102,  0.0204,  0.0406,  ..., -0.0030,  0.0101, -0.0087],
        ...,
        [-0.0268,  0.0296,  0.0052,  ...,  0.0220, -0.0127,  0.0061],
        [-0.0013,  0.0012,  0.0013,  ...,  0.0114,  0.0318,  0.0041],
        [ 0.0266, -0.0298,  0.0034,  ...,  0.0173, -0.0112,  0.0233]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.2957, -3.0449,  0.0447,  ...,  0.7637, -0.2202, -3.0586]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 20:55:27 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country of canada primarily speaks the language of english
The country of ecuador primarily speaks the language of spanish
The country of denmark primarily speaks the language of danish
The country of kazakhstan primarily speaks the language of kazak
The country of iraq primarily speaks the language of arabic
The country of jordan primarily speaks the language of arabic
The country of haiti primarily speaks the language of creole
The country of ireland primarily speaks the language of
2024-07-30 20:55:27 root INFO     [order_1_approx] starting weight calculation for The country of canada primarily speaks the language of english
The country of haiti primarily speaks the language of creole
The country of iraq primarily speaks the language of arabic
The country of kazakhstan primarily speaks the language of kazak
The country of denmark primarily speaks the language of danish
The country of ireland primarily speaks the language of english
The country of jordan primarily speaks the language of arabic
The country of ecuador primarily speaks the language of
2024-07-30 20:55:27 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 20:57:26 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1971,  0.3167, -0.1769,  ..., -0.2217, -0.2053, -0.4907],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.8711, -3.0508, -1.8223,  ..., -0.7720, -4.5391,  1.5918],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0041, -0.0286,  0.0258,  ..., -0.0172,  0.0217,  0.0407],
        [-0.0191,  0.0345,  0.0056,  ...,  0.0039,  0.0211, -0.0078],
        [ 0.0178, -0.0010, -0.0041,  ..., -0.0156, -0.0302, -0.0271],
        ...,
        [-0.0026, -0.0128, -0.0003,  ..., -0.0002, -0.0132, -0.0042],
        [ 0.0046, -0.0056, -0.0059,  ...,  0.0018, -0.0055, -0.0163],
        [ 0.0219,  0.0035, -0.0164,  ...,  0.0023, -0.0181,  0.0002]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.5151, -3.1582, -2.1367,  ..., -0.4053, -4.8711,  1.2793]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 20:57:27 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for I send, he sends
I enjoy, he enjoys
I reduce, he reduces
I maintain, he maintains
I seem, he seems
I promote, he promotes
I accept, he accepts
I occur, he
2024-07-30 20:57:27 root INFO     [order_1_approx] starting weight calculation for I occur, he occurs
I seem, he seems
I accept, he accepts
I promote, he promotes
I enjoy, he enjoys
I maintain, he maintains
I reduce, he reduces
I send, he
2024-07-30 20:57:27 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-30 20:57:55 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0461, -0.3423, -0.1567,  ...,  0.2959, -0.1204,  0.2056],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.5405, -1.0010,  1.9834,  ..., -0.1941, -1.0293, -2.0859],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0179, -0.0046, -0.0030,  ..., -0.0190,  0.0127, -0.0096],
        [ 0.0097,  0.0142,  0.0054,  ...,  0.0143, -0.0098, -0.0216],
        [-0.0095,  0.0162,  0.0483,  ...,  0.0014, -0.0076, -0.0212],
        ...,
        [-0.0069,  0.0249,  0.0231,  ...,  0.0230, -0.0069, -0.0115],
        [ 0.0202,  0.0068, -0.0142,  ...,  0.0006,  0.0305,  0.0071],
        [ 0.0067, -0.0341, -0.0022,  ...,  0.0235, -0.0045,  0.0278]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.5825, -1.1992,  1.7461,  ..., -0.2664, -1.2197, -1.7578]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 20:57:58 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country of canada primarily speaks the language of english
The country of haiti primarily speaks the language of creole
The country of iraq primarily speaks the language of arabic
The country of kazakhstan primarily speaks the language of kazak
The country of denmark primarily speaks the language of danish
The country of ireland primarily speaks the language of english
The country of jordan primarily speaks the language of arabic
The country of ecuador primarily speaks the language of
2024-07-30 20:57:58 root INFO     [order_1_approx] starting weight calculation for The country of jordan primarily speaks the language of arabic
The country of iraq primarily speaks the language of arabic
The country of ireland primarily speaks the language of english
The country of denmark primarily speaks the language of danish
The country of kazakhstan primarily speaks the language of kazak
The country of ecuador primarily speaks the language of spanish
The country of haiti primarily speaks the language of creole
The country of canada primarily speaks the language of
2024-07-30 20:57:58 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 21:00:06 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0485,  0.0858,  0.0921,  ...,  0.0979, -0.1040, -0.1294],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.3516, -3.3086, -4.9297,  ..., -1.4883, -6.6211, -3.0898],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0370,  0.0104, -0.0014,  ..., -0.0096, -0.0071,  0.0010],
        [-0.0122,  0.0152,  0.0127,  ..., -0.0057,  0.0127, -0.0089],
        [ 0.0220,  0.0042,  0.0013,  ...,  0.0011,  0.0016,  0.0034],
        ...,
        [ 0.0264, -0.0042,  0.0270,  ...,  0.0076,  0.0137,  0.0145],
        [-0.0004, -0.0154, -0.0076,  ...,  0.0040,  0.0139,  0.0088],
        [ 0.0299, -0.0114,  0.0007,  ...,  0.0302, -0.0232,  0.0070]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.3516, -3.3906, -4.7148,  ..., -1.4014, -6.7930, -3.4180]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 21:00:08 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for I occur, he occurs
I seem, he seems
I accept, he accepts
I promote, he promotes
I enjoy, he enjoys
I maintain, he maintains
I reduce, he reduces
I send, he
2024-07-30 21:00:08 root INFO     [order_1_approx] starting weight calculation for I send, he sends
I accept, he accepts
I maintain, he maintains
I reduce, he reduces
I enjoy, he enjoys
I occur, he occurs
I promote, he promotes
I seem, he
2024-07-30 21:00:08 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-30 21:00:29 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0176, -0.1594, -0.0846,  ..., -0.0684,  0.0610,  0.2271],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.9419, -4.7031,  2.2266,  ..., -0.4219,  1.4922, -1.6367],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 2.4124e-02, -1.9867e-02, -6.7902e-03,  ...,  2.7695e-03,
          7.6065e-03, -9.7198e-03],
        [ 1.4488e-02,  1.4465e-02, -6.9580e-03,  ..., -1.0941e-02,
          3.8147e-05, -1.1200e-02],
        [-2.1301e-02,  2.4658e-02,  3.1219e-02,  ...,  3.4790e-03,
          4.6463e-03, -4.0131e-03],
        ...,
        [-1.6388e-02,  2.6245e-02,  5.8670e-03,  ...,  2.1851e-02,
          1.2489e-02,  1.1070e-02],
        [-1.1330e-02,  1.9538e-04, -2.8610e-04,  ...,  1.4999e-02,
          1.0246e-02,  6.5918e-03],
        [ 2.9327e-02, -2.3712e-02, -1.7517e-02,  ..., -5.8212e-03,
         -7.3280e-03,  1.5099e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.3125, -3.9219,  1.7764,  ..., -0.7139,  1.4658, -1.3652]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 21:00:30 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country of jordan primarily speaks the language of arabic
The country of iraq primarily speaks the language of arabic
The country of ireland primarily speaks the language of english
The country of denmark primarily speaks the language of danish
The country of kazakhstan primarily speaks the language of kazak
The country of ecuador primarily speaks the language of spanish
The country of haiti primarily speaks the language of creole
The country of canada primarily speaks the language of
2024-07-30 21:00:30 root INFO     [order_1_approx] starting weight calculation for The country of jordan primarily speaks the language of arabic
The country of ireland primarily speaks the language of english
The country of haiti primarily speaks the language of creole
The country of ecuador primarily speaks the language of spanish
The country of denmark primarily speaks the language of danish
The country of canada primarily speaks the language of english
The country of iraq primarily speaks the language of arabic
The country of kazakhstan primarily speaks the language of
2024-07-30 21:00:31 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 21:02:46 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.3159,  0.4136, -0.1404,  ...,  0.2554, -0.4492, -0.1382],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.5059, -1.7324, -3.0273,  ...,  1.4365, -5.6523, -0.6426],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0294,  0.0215,  0.0128,  ...,  0.0025, -0.0060,  0.0076],
        [-0.0227,  0.0197, -0.0055,  ..., -0.0174,  0.0215, -0.0062],
        [-0.0014, -0.0078,  0.0048,  ..., -0.0257, -0.0035, -0.0055],
        ...,
        [ 0.0068,  0.0137, -0.0031,  ...,  0.0313, -0.0042,  0.0098],
        [-0.0030, -0.0034, -0.0232,  ...,  0.0033,  0.0052, -0.0263],
        [ 0.0049, -0.0004, -0.0188,  ...,  0.0270, -0.0133, -0.0208]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.4004, -1.9014, -2.8477,  ...,  1.5635, -6.1719, -1.1211]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 21:02:47 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for I send, he sends
I accept, he accepts
I maintain, he maintains
I reduce, he reduces
I enjoy, he enjoys
I occur, he occurs
I promote, he promotes
I seem, he
2024-07-30 21:02:47 root INFO     [order_1_approx] starting weight calculation for I seem, he seems
I occur, he occurs
I promote, he promotes
I send, he sends
I accept, he accepts
I maintain, he maintains
I enjoy, he enjoys
I reduce, he
2024-07-30 21:02:47 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-30 21:03:03 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1677, -0.5327, -0.3357,  ...,  0.0060, -0.2820,  0.2178],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.1543, -3.9863, -1.1016,  ..., -3.1133, -2.3984, -1.5947],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 3.4943e-03,  2.4796e-04, -8.9798e-03,  ...,  1.2112e-04,
          3.1300e-03,  2.9087e-03],
        [ 3.4637e-03,  1.3596e-02,  2.3689e-03,  ..., -9.2566e-05,
         -1.7910e-03, -5.4398e-03],
        [ 8.0299e-04,  1.2085e-02,  1.5778e-02,  ..., -6.6681e-03,
         -5.2376e-03, -5.1003e-03],
        ...,
        [-3.6907e-04, -3.7689e-03, -3.2578e-03,  ...,  3.9215e-03,
          3.7155e-03,  6.9466e-03],
        [-2.8572e-03,  4.1771e-03,  8.0109e-03,  ...,  1.2999e-03,
          2.2812e-02, -1.8692e-04],
        [-8.2169e-03, -7.9803e-03, -6.2408e-03,  ...,  2.2087e-03,
         -1.2115e-02,  9.1019e-03]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.1055, -3.8809, -1.0752,  ..., -2.9766, -2.3359, -1.6006]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 21:03:04 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country of jordan primarily speaks the language of arabic
The country of ireland primarily speaks the language of english
The country of haiti primarily speaks the language of creole
The country of ecuador primarily speaks the language of spanish
The country of denmark primarily speaks the language of danish
The country of canada primarily speaks the language of english
The country of iraq primarily speaks the language of arabic
The country of kazakhstan primarily speaks the language of
2024-07-30 21:03:04 root INFO     [order_1_approx] starting weight calculation for The country of denmark primarily speaks the language of danish
The country of ecuador primarily speaks the language of spanish
The country of iraq primarily speaks the language of arabic
The country of canada primarily speaks the language of english
The country of jordan primarily speaks the language of arabic
The country of ireland primarily speaks the language of english
The country of kazakhstan primarily speaks the language of kazak
The country of haiti primarily speaks the language of
2024-07-30 21:03:05 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 21:05:27 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2803,  0.0968, -0.1327,  ..., -0.2703,  0.0552, -0.1002],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.3877, -2.6406, -0.3848,  ..., -2.4766, -6.4609, -4.1289],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0464,  0.0255,  0.0085,  ...,  0.0140,  0.0016,  0.0152],
        [-0.0194,  0.0161, -0.0170,  ..., -0.0036,  0.0065, -0.0043],
        [-0.0016,  0.0538,  0.0310,  ..., -0.0283, -0.0208, -0.0088],
        ...,
        [ 0.0351, -0.0524, -0.0387,  ...,  0.0299,  0.0006,  0.0055],
        [ 0.0242, -0.0327, -0.0157,  ...,  0.0180,  0.0143, -0.0065],
        [-0.0205, -0.0123,  0.0199,  ..., -0.0154, -0.0025,  0.0091]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.1575, -2.5137, -0.6855,  ..., -1.7773, -6.5391, -4.3164]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 21:05:29 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for I seem, he seems
I occur, he occurs
I promote, he promotes
I send, he sends
I accept, he accepts
I maintain, he maintains
I enjoy, he enjoys
I reduce, he
2024-07-30 21:05:29 root INFO     [order_1_approx] starting weight calculation for I occur, he occurs
I reduce, he reduces
I accept, he accepts
I maintain, he maintains
I enjoy, he enjoys
I seem, he seems
I send, he sends
I promote, he
2024-07-30 21:05:29 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-30 21:05:36 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1102,  0.2612, -0.3335,  ...,  0.0247, -0.0553,  0.3889],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.2266, -2.1797,  1.8438,  ..., -1.4844,  0.7539, -0.6406],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0194, -0.0077,  0.0048,  ...,  0.0149, -0.0039, -0.0148],
        [ 0.0196,  0.0385, -0.0021,  ..., -0.0020, -0.0012, -0.0275],
        [-0.0121,  0.0063,  0.0502,  ..., -0.0261,  0.0300, -0.0249],
        ...,
        [-0.0352,  0.0148,  0.0248,  ...,  0.0269,  0.0008, -0.0024],
        [ 0.0020,  0.0148,  0.0043,  ...,  0.0022,  0.0449,  0.0034],
        [ 0.0076, -0.0099,  0.0063,  ..., -0.0087,  0.0122,  0.0290]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.7607, -1.9297,  1.1504,  ..., -1.8945,  0.8276, -0.8467]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 21:05:37 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country of denmark primarily speaks the language of danish
The country of ecuador primarily speaks the language of spanish
The country of iraq primarily speaks the language of arabic
The country of canada primarily speaks the language of english
The country of jordan primarily speaks the language of arabic
The country of ireland primarily speaks the language of english
The country of kazakhstan primarily speaks the language of kazak
The country of haiti primarily speaks the language of
2024-07-30 21:05:38 root INFO     [order_1_approx] starting weight calculation for The country of ecuador primarily speaks the language of spanish
The country of ireland primarily speaks the language of english
The country of haiti primarily speaks the language of creole
The country of kazakhstan primarily speaks the language of kazak
The country of iraq primarily speaks the language of arabic
The country of denmark primarily speaks the language of danish
The country of canada primarily speaks the language of english
The country of jordan primarily speaks the language of
2024-07-30 21:05:38 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 21:08:07 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0351,  0.3323, -0.1443,  ..., -0.1072, -0.0828,  0.0304],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.0781, -4.3594, -0.4453,  ...,  0.1123, -8.8359,  0.3789],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0489, -0.0080,  0.0138,  ..., -0.0047, -0.0040,  0.0187],
        [-0.0248,  0.0267, -0.0202,  ...,  0.0031,  0.0239, -0.0021],
        [ 0.0049,  0.0224,  0.0133,  ..., -0.0147, -0.0303,  0.0093],
        ...,
        [ 0.0129, -0.0126, -0.0217,  ...,  0.0214,  0.0066, -0.0124],
        [ 0.0184, -0.0054, -0.0227,  ..., -0.0042, -0.0098, -0.0069],
        [ 0.0363,  0.0025, -0.0125,  ..., -0.0146, -0.0330,  0.0099]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.0977, -4.3359, -0.7324,  ...,  0.2935, -8.8516,  0.2347]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 21:08:08 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for I occur, he occurs
I reduce, he reduces
I accept, he accepts
I maintain, he maintains
I enjoy, he enjoys
I seem, he seems
I send, he sends
I promote, he
2024-07-30 21:08:08 root INFO     [order_1_approx] starting weight calculation for I occur, he occurs
I send, he sends
I reduce, he reduces
I accept, he accepts
I enjoy, he enjoys
I seem, he seems
I promote, he promotes
I maintain, he
2024-07-30 21:08:08 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-30 21:08:10 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0422, -0.0939, -0.3530,  ...,  0.2742, -0.5020, -0.1128],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-2.0176, -3.0391,  0.6924,  ..., -2.1660,  0.7324, -1.9531],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 2.0844e-02,  4.3488e-04, -1.1681e-02,  ..., -3.4256e-03,
         -6.0806e-03,  2.9030e-03],
        [ 1.4610e-02,  3.7140e-02,  4.3716e-03,  ..., -9.4833e-03,
          8.7357e-03, -1.0071e-02],
        [-5.7640e-03,  4.9057e-03,  2.9434e-02,  ..., -1.6510e-02,
          1.2032e-02, -1.3138e-02],
        ...,
        [-8.1253e-04,  1.3519e-02,  5.6534e-03,  ...,  2.4521e-02,
          7.6904e-03, -1.6281e-02],
        [-6.1951e-03, -4.5776e-04, -5.2719e-03,  ..., -5.1384e-03,
          2.6245e-02, -9.4757e-03],
        [ 2.8763e-03, -1.1391e-02,  3.0518e-05,  ...,  1.1879e-02,
         -1.3245e-02,  5.8861e-03]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-2.1914, -2.8008,  0.8462,  ..., -1.8574,  0.5615, -2.0195]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 21:08:11 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country of ecuador primarily speaks the language of spanish
The country of ireland primarily speaks the language of english
The country of haiti primarily speaks the language of creole
The country of kazakhstan primarily speaks the language of kazak
The country of iraq primarily speaks the language of arabic
The country of denmark primarily speaks the language of danish
The country of canada primarily speaks the language of english
The country of jordan primarily speaks the language of
2024-07-30 21:08:11 root INFO     total operator prediction time: 1220.341420173645 seconds
2024-07-30 21:08:11 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on name - nationality
2024-07-30 21:08:11 root INFO     building operator name - nationality
2024-07-30 21:08:12 root INFO     [order_1_approx] starting weight calculation for michelangelo was italian
kant was german
einstein was jewish
confucius was chinese
spinoza was dutch
locke was english
dickens was english
lavoisier was
2024-07-30 21:08:12 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 21:10:46 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3560,  0.1416, -0.3972,  ..., -0.0360,  0.1671,  0.1890],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.6836, -2.5938,  1.2266,  ..., -3.3848, -0.1270,  1.2754],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0713, -0.0230, -0.0477,  ..., -0.0162, -0.0011, -0.0157],
        [ 0.0302,  0.0964,  0.0341,  ...,  0.0246, -0.0062,  0.0040],
        [ 0.0234,  0.0015,  0.0681,  ..., -0.0039,  0.0157, -0.0138],
        ...,
        [ 0.0245, -0.0143,  0.0002,  ...,  0.0717, -0.0068, -0.0048],
        [ 0.0158, -0.0028,  0.0078,  ...,  0.0034,  0.0669, -0.0239],
        [-0.0211,  0.0114, -0.0030,  ..., -0.0024, -0.0055,  0.0938]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.6641, -3.0762,  0.0449,  ..., -3.3926, -0.4399,  1.2246]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 21:10:47 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for michelangelo was italian
kant was german
einstein was jewish
confucius was chinese
spinoza was dutch
locke was english
dickens was english
lavoisier was
2024-07-30 21:10:47 root INFO     [order_1_approx] starting weight calculation for locke was english
dickens was english
michelangelo was italian
einstein was jewish
spinoza was dutch
lavoisier was french
confucius was chinese
kant was
2024-07-30 21:10:47 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 21:10:47 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3735,  0.3308, -0.1669,  ..., -0.1787, -0.4419,  0.0154],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.4395, -4.3125, -1.9082,  ..., -0.5527, -5.0039, -0.4102],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0242, -0.0080,  0.0084,  ..., -0.0091,  0.0006,  0.0214],
        [-0.0152,  0.0291,  0.0024,  ..., -0.0096,  0.0304,  0.0043],
        [ 0.0094, -0.0090,  0.0251,  ..., -0.0195, -0.0221, -0.0076],
        ...,
        [ 0.0199,  0.0013,  0.0052,  ...,  0.0132,  0.0014,  0.0083],
        [-0.0034, -0.0007, -0.0203,  ..., -0.0124,  0.0052, -0.0166],
        [ 0.0107,  0.0099, -0.0186,  ...,  0.0099, -0.0101, -0.0106]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.3281, -4.3906, -2.2734,  ..., -0.6411, -4.9375, -0.7080]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 21:10:48 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for I occur, he occurs
I send, he sends
I reduce, he reduces
I accept, he accepts
I enjoy, he enjoys
I seem, he seems
I promote, he promotes
I maintain, he
2024-07-30 21:10:48 root INFO     [order_1_approx] starting weight calculation for I seem, he seems
I occur, he occurs
I accept, he accepts
I promote, he promotes
I send, he sends
I maintain, he maintains
I reduce, he reduces
I enjoy, he
2024-07-30 21:10:48 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-30 21:13:20 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0483, -0.3040, -0.4338,  ...,  0.0459,  0.0149,  0.1633],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.9658, -3.9707,  1.4512,  ..., -3.0449, -1.1377, -2.1621],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0484, -0.0076,  0.0002,  ..., -0.0200,  0.0106, -0.0184],
        [ 0.0084,  0.0345,  0.0220,  ...,  0.0348, -0.0108, -0.0095],
        [ 0.0141,  0.0118,  0.0644,  ..., -0.0018,  0.0157,  0.0202],
        ...,
        [ 0.0033, -0.0011,  0.0169,  ...,  0.0641, -0.0063,  0.0190],
        [ 0.0091, -0.0066, -0.0122,  ..., -0.0099,  0.0460,  0.0217],
        [ 0.0015,  0.0132,  0.0024,  ...,  0.0205, -0.0160,  0.0921]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.0146, -3.2734,  1.1396,  ..., -2.4883, -0.7344, -1.4502]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 21:13:21 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for locke was english
dickens was english
michelangelo was italian
einstein was jewish
spinoza was dutch
lavoisier was french
confucius was chinese
kant was
2024-07-30 21:13:21 root INFO     [order_1_approx] starting weight calculation for spinoza was dutch
locke was english
confucius was chinese
lavoisier was french
einstein was jewish
kant was german
michelangelo was italian
dickens was
2024-07-30 21:13:21 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 21:13:28 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0493,  0.2891,  0.0495,  ..., -0.0865, -0.3298, -0.2076],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.5186, -3.0312, -0.4629,  ..., -0.5117, -5.7344, -0.5518],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0387,  0.0271,  0.0087,  ...,  0.0024,  0.0084,  0.0236],
        [ 0.0035,  0.0164, -0.0020,  ..., -0.0135,  0.0101, -0.0095],
        [-0.0004,  0.0029,  0.0068,  ...,  0.0046, -0.0387,  0.0004],
        ...,
        [ 0.0307, -0.0036,  0.0048,  ...,  0.0175, -0.0093, -0.0225],
        [-0.0089,  0.0030,  0.0130,  ..., -0.0046, -0.0091, -0.0140],
        [ 0.0079, -0.0231,  0.0094,  ...,  0.0011, -0.0207, -0.0180]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.6338, -3.1270, -0.4280,  ..., -0.3335, -5.6797, -1.1582]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 21:13:29 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for I seem, he seems
I occur, he occurs
I accept, he accepts
I promote, he promotes
I send, he sends
I maintain, he maintains
I reduce, he reduces
I enjoy, he
2024-07-30 21:13:29 root INFO     total operator prediction time: 1280.4495108127594 seconds
2024-07-30 21:13:29 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on verb_inf - Ved
2024-07-30 21:13:29 root INFO     building operator verb_inf - Ved
2024-07-30 21:13:29 root INFO     [order_1_approx] starting weight calculation for If the present form is include, the past form is included
If the present form is reduce, the past form is reduced
If the present form is develop, the past form is developed
If the present form is hear, the past form is heard
If the present form is create, the past form is created
If the present form is ask, the past form is asked
If the present form is require, the past form is required
If the present form is receive, the past form is
2024-07-30 21:13:29 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-30 21:15:55 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0796,  0.4062, -0.4487,  ...,  0.3105, -0.4446, -0.2732],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.2734, -1.9854,  2.0176,  ..., -3.9316,  0.8350, -2.9141],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0673, -0.0085, -0.0141,  ..., -0.0115, -0.0225, -0.0396],
        [ 0.0116,  0.0160,  0.0251,  ...,  0.0237,  0.0342,  0.0064],
        [-0.0132,  0.0004,  0.0737,  ...,  0.0218,  0.0260,  0.0308],
        ...,
        [ 0.0565, -0.0245, -0.0118,  ...,  0.0590,  0.0054,  0.0011],
        [ 0.0091,  0.0006,  0.0051,  ..., -0.0006,  0.0304,  0.0137],
        [ 0.0006, -0.0002, -0.0130,  ...,  0.0248,  0.0068,  0.0960]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.0117, -1.7920,  1.2246,  ..., -3.5430,  0.5210, -2.4434]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 21:15:56 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for spinoza was dutch
locke was english
confucius was chinese
lavoisier was french
einstein was jewish
kant was german
michelangelo was italian
dickens was
2024-07-30 21:15:56 root INFO     [order_1_approx] starting weight calculation for spinoza was dutch
dickens was english
locke was english
michelangelo was italian
kant was german
lavoisier was french
confucius was chinese
einstein was
2024-07-30 21:15:56 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 21:16:07 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0614, -0.0184,  0.0243,  ..., -0.2686, -0.2020, -0.0235],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.9893,  0.5225, -0.6978,  ..., -3.4141, -1.4902, -1.1055],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0358, -0.0108,  0.0100,  ..., -0.0116,  0.0110,  0.0200],
        [-0.0557,  0.0500,  0.0453,  ..., -0.0023, -0.0279, -0.0175],
        [ 0.0079, -0.0050, -0.0002,  ..., -0.0130, -0.0288, -0.0097],
        ...,
        [ 0.0257, -0.0116, -0.0096,  ...,  0.0222, -0.0019, -0.0241],
        [ 0.0274, -0.0255, -0.0148,  ..., -0.0319,  0.0398, -0.0186],
        [ 0.0032,  0.0136,  0.0124,  ..., -0.0027, -0.0242,  0.0011]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.8496,  0.3201, -0.6299,  ..., -3.2207, -1.3340, -0.8613]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 21:16:08 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If the present form is include, the past form is included
If the present form is reduce, the past form is reduced
If the present form is develop, the past form is developed
If the present form is hear, the past form is heard
If the present form is create, the past form is created
If the present form is ask, the past form is asked
If the present form is require, the past form is required
If the present form is receive, the past form is
2024-07-30 21:16:08 root INFO     [order_1_approx] starting weight calculation for If the present form is create, the past form is created
If the present form is require, the past form is required
If the present form is receive, the past form is received
If the present form is reduce, the past form is reduced
If the present form is develop, the past form is developed
If the present form is ask, the past form is asked
If the present form is include, the past form is included
If the present form is hear, the past form is
2024-07-30 21:16:09 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-30 21:18:31 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1761, -0.5332, -0.5684,  ..., -0.0890, -0.2993,  0.5166],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.7222, -4.6641,  0.4590,  ..., -3.3008, -2.6953, -0.3616],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0443, -0.0137, -0.0058,  ..., -0.0236, -0.0061, -0.0375],
        [-0.0029,  0.0143,  0.0045,  ...,  0.0121, -0.0057, -0.0150],
        [ 0.0111,  0.0208,  0.0367,  ...,  0.0141,  0.0134,  0.0395],
        ...,
        [ 0.0208, -0.0026, -0.0111,  ...,  0.0467,  0.0036,  0.0236],
        [ 0.0023,  0.0016,  0.0048,  ...,  0.0092,  0.0090, -0.0081],
        [-0.0122,  0.0119,  0.0009,  ...,  0.0147, -0.0048,  0.0491]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.1113, -3.8906,  0.5986,  ..., -2.6035, -2.3711, -0.1398]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 21:18:32 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for spinoza was dutch
dickens was english
locke was english
michelangelo was italian
kant was german
lavoisier was french
confucius was chinese
einstein was
2024-07-30 21:18:32 root INFO     [order_1_approx] starting weight calculation for kant was german
confucius was chinese
dickens was english
michelangelo was italian
spinoza was dutch
lavoisier was french
einstein was jewish
locke was
2024-07-30 21:18:32 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 21:18:47 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1055,  0.0427,  0.2634,  ...,  0.1978, -0.1030,  0.0447],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.2715, -0.5112,  1.0264,  ..., -0.1948, -3.0703, -2.8711],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0639, -0.0071, -0.0023,  ...,  0.0093,  0.0233,  0.0145],
        [-0.0131,  0.0657,  0.0299,  ...,  0.0028, -0.0174, -0.0217],
        [-0.0041,  0.0024,  0.0223,  ...,  0.0023, -0.0166,  0.0068],
        ...,
        [ 0.0186,  0.0029, -0.0031,  ...,  0.0168,  0.0154, -0.0092],
        [ 0.0177, -0.0065, -0.0132,  ..., -0.0095,  0.0223,  0.0009],
        [-0.0033,  0.0248,  0.0077,  ...,  0.0145,  0.0224,  0.0321]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.2314, -0.4624,  0.8262,  ...,  0.2627, -2.2227, -2.9551]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 21:18:48 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If the present form is create, the past form is created
If the present form is require, the past form is required
If the present form is receive, the past form is received
If the present form is reduce, the past form is reduced
If the present form is develop, the past form is developed
If the present form is ask, the past form is asked
If the present form is include, the past form is included
If the present form is hear, the past form is
2024-07-30 21:18:48 root INFO     [order_1_approx] starting weight calculation for If the present form is include, the past form is included
If the present form is receive, the past form is received
If the present form is hear, the past form is heard
If the present form is create, the past form is created
If the present form is develop, the past form is developed
If the present form is ask, the past form is asked
If the present form is reduce, the past form is reduced
If the present form is require, the past form is
2024-07-30 21:18:49 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-30 21:21:05 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1145,  0.0581, -0.7007,  ..., -0.1479, -0.0328,  0.1061],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.2852, -2.1992,  1.5176,  ..., -5.0977,  0.2490, -3.1855],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0389,  0.0051, -0.0070,  ...,  0.0051,  0.0055, -0.0213],
        [ 0.0044,  0.0433,  0.0330,  ...,  0.0162,  0.0093, -0.0165],
        [-0.0035, -0.0145,  0.0289,  ..., -0.0175,  0.0009,  0.0005],
        ...,
        [ 0.0272,  0.0140,  0.0109,  ...,  0.0487,  0.0055,  0.0126],
        [-0.0072, -0.0063,  0.0084,  ..., -0.0037,  0.0217, -0.0026],
        [ 0.0112,  0.0039, -0.0154,  ...,  0.0029,  0.0032,  0.0555]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.0508, -2.4277,  1.4307,  ..., -4.6523,  0.4717, -3.5059]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 21:21:06 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for kant was german
confucius was chinese
dickens was english
michelangelo was italian
spinoza was dutch
lavoisier was french
einstein was jewish
locke was
2024-07-30 21:21:06 root INFO     [order_1_approx] starting weight calculation for michelangelo was italian
dickens was english
lavoisier was french
einstein was jewish
locke was english
spinoza was dutch
kant was german
confucius was
2024-07-30 21:21:06 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 21:21:30 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2031, -0.2352, -0.1241,  ..., -0.0522, -0.3450,  0.1378],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.7422,  0.5293,  0.9917,  ..., -2.0664, -2.7168, -1.5615],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 1.8265e-02, -1.2016e-03,  3.4119e-02,  ..., -1.3290e-02,
          1.0284e-02,  1.3321e-02],
        [-2.2690e-02,  3.7140e-02,  5.6534e-03,  ..., -4.5319e-03,
         -2.5940e-02,  6.9046e-04],
        [ 2.9869e-03,  1.2093e-02, -2.3632e-03,  ..., -1.4908e-02,
         -2.4368e-02, -1.1795e-02],
        ...,
        [-8.5831e-05,  1.7212e-02,  6.6223e-03,  ...,  3.9246e-02,
          2.1393e-02,  1.4858e-03],
        [ 2.8320e-02, -3.2776e-02, -2.8801e-03,  ...,  5.4626e-03,
         -1.6357e-02, -1.2268e-02],
        [ 4.8027e-03,  8.9874e-03, -1.6212e-04,  ...,  8.7585e-03,
         -4.8187e-02,  3.9368e-03]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-2.1094,  0.2729,  1.2559,  ..., -1.7188, -2.8047, -1.5088]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 21:21:32 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If the present form is include, the past form is included
If the present form is receive, the past form is received
If the present form is hear, the past form is heard
If the present form is create, the past form is created
If the present form is develop, the past form is developed
If the present form is ask, the past form is asked
If the present form is reduce, the past form is reduced
If the present form is require, the past form is
2024-07-30 21:21:32 root INFO     [order_1_approx] starting weight calculation for If the present form is receive, the past form is received
If the present form is hear, the past form is heard
If the present form is require, the past form is required
If the present form is ask, the past form is asked
If the present form is develop, the past form is developed
If the present form is include, the past form is included
If the present form is create, the past form is created
If the present form is reduce, the past form is
2024-07-30 21:21:32 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-30 21:23:40 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0826, -0.2413, -0.8022,  ...,  0.2627, -0.3157,  0.0313],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.3672, -0.4092,  2.1016,  ..., -4.6172, -0.3340,  1.2930],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0626,  0.0197, -0.0007,  ..., -0.0074,  0.0160, -0.0507],
        [-0.0274,  0.0036,  0.0034,  ...,  0.0020, -0.0263,  0.0300],
        [-0.0033, -0.0007,  0.0342,  ...,  0.0138,  0.0150,  0.0011],
        ...,
        [ 0.0175, -0.0045, -0.0198,  ..., -0.0012, -0.0123,  0.0133],
        [ 0.0044, -0.0002,  0.0038,  ...,  0.0083,  0.0124,  0.0115],
        [-0.0487, -0.0043, -0.0106,  ...,  0.0204, -0.0321,  0.0554]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.7285,  0.8877,  1.3281,  ..., -3.4180, -0.0935,  1.6768]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 21:23:41 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for michelangelo was italian
dickens was english
lavoisier was french
einstein was jewish
locke was english
spinoza was dutch
kant was german
confucius was
2024-07-30 21:23:41 root INFO     [order_1_approx] starting weight calculation for confucius was chinese
locke was english
dickens was english
lavoisier was french
einstein was jewish
kant was german
michelangelo was italian
spinoza was
2024-07-30 21:23:42 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 21:24:11 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0888, -0.0242, -0.1039,  ..., -0.0357,  0.0340, -0.0251],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-2.5645, -0.5371,  1.0029,  ..., -3.9023, -1.3438, -4.3359],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0577, -0.0189, -0.0171,  ...,  0.0044,  0.0422,  0.0047],
        [-0.0210,  0.0342,  0.0043,  ...,  0.0143, -0.0123, -0.0250],
        [ 0.0258,  0.0049, -0.0136,  ..., -0.0125,  0.0067,  0.0113],
        ...,
        [ 0.0302, -0.0032, -0.0197,  ...,  0.0174, -0.0059,  0.0162],
        [ 0.0036,  0.0067,  0.0130,  ...,  0.0016,  0.0090, -0.0032],
        [-0.0200,  0.0075,  0.0192,  ..., -0.0047, -0.0225,  0.0244]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-2.6406, -0.7256,  0.6108,  ..., -3.3496, -1.3691, -3.9551]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 21:24:12 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If the present form is receive, the past form is received
If the present form is hear, the past form is heard
If the present form is require, the past form is required
If the present form is ask, the past form is asked
If the present form is develop, the past form is developed
If the present form is include, the past form is included
If the present form is create, the past form is created
If the present form is reduce, the past form is
2024-07-30 21:24:13 root INFO     [order_1_approx] starting weight calculation for If the present form is reduce, the past form is reduced
If the present form is ask, the past form is asked
If the present form is receive, the past form is received
If the present form is require, the past form is required
If the present form is hear, the past form is heard
If the present form is develop, the past form is developed
If the present form is include, the past form is included
If the present form is create, the past form is
2024-07-30 21:24:13 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-30 21:26:16 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1157, -0.2040, -0.1836,  ..., -0.0083, -0.0760, -0.0300],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.2637, -0.6455,  2.4004,  ..., -6.1719, -0.3633, -2.7695],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0783,  0.0347, -0.0006,  ...,  0.0167, -0.0095, -0.0005],
        [ 0.0052,  0.0412,  0.0196,  ...,  0.0234, -0.0215, -0.0388],
        [ 0.0087,  0.0148,  0.0615,  ...,  0.0155, -0.0004,  0.0060],
        ...,
        [ 0.0052, -0.0197, -0.0045,  ...,  0.0405, -0.0124, -0.0284],
        [ 0.0121, -0.0039,  0.0065,  ...,  0.0230,  0.0354,  0.0077],
        [-0.0280, -0.0259, -0.0130,  ..., -0.0016, -0.0170,  0.0346]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.8164, -0.9561,  1.2930,  ..., -4.9688, -0.5469, -1.9258]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 21:26:17 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for confucius was chinese
locke was english
dickens was english
lavoisier was french
einstein was jewish
kant was german
michelangelo was italian
spinoza was
2024-07-30 21:26:17 root INFO     [order_1_approx] starting weight calculation for lavoisier was french
einstein was jewish
confucius was chinese
kant was german
locke was english
spinoza was dutch
dickens was english
michelangelo was
2024-07-30 21:26:17 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 21:26:53 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0534,  0.1123,  0.0801,  ..., -0.0302, -0.2964,  0.0907],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.2520, -1.5332,  1.4834,  ..., -1.0732, -1.7441,  0.1426],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0310, -0.0194,  0.0036,  ..., -0.0155,  0.0053,  0.0101],
        [ 0.0085,  0.0617,  0.0159,  ...,  0.0114, -0.0130, -0.0146],
        [ 0.0031,  0.0168,  0.0212,  ...,  0.0101, -0.0120, -0.0189],
        ...,
        [ 0.0129,  0.0106, -0.0004,  ...,  0.0208,  0.0126, -0.0128],
        [ 0.0162,  0.0024, -0.0081,  ...,  0.0008,  0.0045, -0.0069],
        [-0.0118,  0.0045,  0.0020,  ..., -0.0058, -0.0501,  0.0170]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.1855, -1.5664,  0.8252,  ..., -0.7354, -2.1992,  0.2236]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 21:26:54 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If the present form is reduce, the past form is reduced
If the present form is ask, the past form is asked
If the present form is receive, the past form is received
If the present form is require, the past form is required
If the present form is hear, the past form is heard
If the present form is develop, the past form is developed
If the present form is include, the past form is included
If the present form is create, the past form is
2024-07-30 21:26:54 root INFO     [order_1_approx] starting weight calculation for If the present form is require, the past form is required
If the present form is develop, the past form is developed
If the present form is hear, the past form is heard
If the present form is ask, the past form is asked
If the present form is create, the past form is created
If the present form is receive, the past form is received
If the present form is reduce, the past form is reduced
If the present form is include, the past form is
2024-07-30 21:26:54 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-30 21:28:51 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2749, -0.0006, -0.4551,  ...,  0.1377, -0.0052,  0.5283],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.1328, -5.9102,  1.3926,  ..., -3.3008, -1.7129, -0.0693],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0540,  0.0180, -0.0074,  ...,  0.0114, -0.0212, -0.0410],
        [ 0.0186,  0.0618,  0.0312,  ..., -0.0104, -0.0106, -0.0241],
        [-0.0051,  0.0369,  0.0571,  ...,  0.0027,  0.0042, -0.0168],
        ...,
        [ 0.0295,  0.0068,  0.0054,  ...,  0.0299, -0.0144, -0.0089],
        [-0.0023, -0.0143, -0.0093,  ..., -0.0242,  0.0583,  0.0052],
        [-0.0274,  0.0011,  0.0185,  ..., -0.0046, -0.0340,  0.0643]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.9883, -6.3047,  0.4648,  ..., -2.6641, -0.9951, -0.7549]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 21:28:52 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for lavoisier was french
einstein was jewish
confucius was chinese
kant was german
locke was english
spinoza was dutch
dickens was english
michelangelo was
2024-07-30 21:28:52 root INFO     total operator prediction time: 1240.2675459384918 seconds
2024-07-30 21:28:52 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on UK_city - county
2024-07-30 21:28:52 root INFO     building operator UK_city - county
2024-07-30 21:28:52 root INFO     [order_1_approx] starting weight calculation for In the United Kingdom, the city of cambridge is in the county of cambridgeshire
In the United Kingdom, the city of belfast is in the county of antrim
In the United Kingdom, the city of stirling is in the county of stirlingshire
In the United Kingdom, the city of preston is in the county of lancashire
In the United Kingdom, the city of inverness is in the county of highlands
In the United Kingdom, the city of plymouth is in the county of devon
In the United Kingdom, the city of lancaster is in the county of lancashire
In the United Kingdom, the city of brighton is in the county of
2024-07-30 21:28:52 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 21:29:30 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0077, -0.0649,  0.2542,  ...,  0.2686, -0.0302,  0.1245],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.8633,  0.8579,  0.2339,  ..., -1.3594, -0.7744, -2.2012],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0512,  0.0084,  0.0127,  ..., -0.0092,  0.0181,  0.0081],
        [-0.0004,  0.0423,  0.0333,  ...,  0.0179, -0.0252, -0.0354],
        [-0.0033,  0.0150,  0.0099,  ..., -0.0016, -0.0234, -0.0076],
        ...,
        [-0.0246,  0.0045,  0.0070,  ...,  0.0347,  0.0314,  0.0054],
        [ 0.0092,  0.0060,  0.0149,  ..., -0.0235, -0.0024,  0.0121],
        [ 0.0173,  0.0094,  0.0154,  ..., -0.0254, -0.0372,  0.0200]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.1934,  0.9155,  0.7021,  ..., -1.6953, -0.2383, -1.9570]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 21:29:31 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If the present form is require, the past form is required
If the present form is develop, the past form is developed
If the present form is hear, the past form is heard
If the present form is ask, the past form is asked
If the present form is create, the past form is created
If the present form is receive, the past form is received
If the present form is reduce, the past form is reduced
If the present form is include, the past form is
2024-07-30 21:29:31 root INFO     [order_1_approx] starting weight calculation for If the present form is require, the past form is required
If the present form is reduce, the past form is reduced
If the present form is receive, the past form is received
If the present form is include, the past form is included
If the present form is develop, the past form is developed
If the present form is create, the past form is created
If the present form is hear, the past form is heard
If the present form is ask, the past form is
2024-07-30 21:29:31 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-30 21:31:31 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4954, -0.0349,  0.0436,  ...,  0.7598, -0.0295, -0.0995],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.4502, -3.2266, -0.5503,  ..., -2.9004,  1.9219, -0.3538],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0157,  0.0071,  0.0168,  ..., -0.0079, -0.0077, -0.0286],
        [-0.0095,  0.0446,  0.0252,  ...,  0.0268, -0.0089, -0.0103],
        [-0.0215, -0.0077,  0.0107,  ...,  0.0142,  0.0062,  0.0121],
        ...,
        [ 0.0031, -0.0138, -0.0129,  ...,  0.0102,  0.0136,  0.0028],
        [ 0.0021, -0.0063, -0.0072,  ...,  0.0214,  0.0031,  0.0096],
        [-0.0017,  0.0186, -0.0013,  ..., -0.0040, -0.0015, -0.0020]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.3506, -3.3359, -0.7007,  ..., -2.4980,  1.9248, -0.2988]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 21:31:48 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for In the United Kingdom, the city of cambridge is in the county of cambridgeshire
In the United Kingdom, the city of belfast is in the county of antrim
In the United Kingdom, the city of stirling is in the county of stirlingshire
In the United Kingdom, the city of preston is in the county of lancashire
In the United Kingdom, the city of inverness is in the county of highlands
In the United Kingdom, the city of plymouth is in the county of devon
In the United Kingdom, the city of lancaster is in the county of lancashire
In the United Kingdom, the city of brighton is in the county of
2024-07-30 21:32:00 root INFO     [order_1_approx] starting weight calculation for In the United Kingdom, the city of belfast is in the county of antrim
In the United Kingdom, the city of stirling is in the county of stirlingshire
In the United Kingdom, the city of lancaster is in the county of lancashire
In the United Kingdom, the city of brighton is in the county of sussex
In the United Kingdom, the city of inverness is in the county of highlands
In the United Kingdom, the city of cambridge is in the county of cambridgeshire
In the United Kingdom, the city of preston is in the county of lancashire
In the United Kingdom, the city of plymouth is in the county of
2024-07-30 21:32:01 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 21:32:10 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1229,  0.2625, -0.1230,  ...,  0.2299, -0.3865, -0.1666],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.7471, -2.5625, -0.6895,  ...,  1.2930, -2.6465, -1.2188],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0140, -0.0110,  0.0010,  ..., -0.0067,  0.0092, -0.0083],
        [ 0.0005,  0.0236,  0.0223,  ...,  0.0031, -0.0276, -0.0132],
        [-0.0229, -0.0121, -0.0046,  ..., -0.0122, -0.0092,  0.0078],
        ...,
        [-0.0153,  0.0080,  0.0032,  ...,  0.0107,  0.0242,  0.0002],
        [ 0.0068, -0.0096, -0.0150,  ..., -0.0302,  0.0092,  0.0122],
        [-0.0007,  0.0162,  0.0143,  ..., -0.0106, -0.0288,  0.0008]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.6704, -2.5410, -0.5161,  ...,  1.6055, -2.4102, -1.1221]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 21:32:11 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If the present form is require, the past form is required
If the present form is reduce, the past form is reduced
If the present form is receive, the past form is received
If the present form is include, the past form is included
If the present form is develop, the past form is developed
If the present form is create, the past form is created
If the present form is hear, the past form is heard
If the present form is ask, the past form is
2024-07-30 21:32:11 root INFO     [order_1_approx] starting weight calculation for If the present form is hear, the past form is heard
If the present form is reduce, the past form is reduced
If the present form is include, the past form is included
If the present form is receive, the past form is received
If the present form is require, the past form is required
If the present form is ask, the past form is asked
If the present form is create, the past form is created
If the present form is develop, the past form is
2024-07-30 21:32:11 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-30 21:34:39 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3252, -0.0090, -0.1688,  ...,  0.5000, -0.2871,  0.0499],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.3516, -4.9414,  1.8223,  ..., -4.6250,  0.3623, -1.2607],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0018, -0.0047, -0.0067,  ..., -0.0002,  0.0008, -0.0002],
        [-0.0045,  0.0175,  0.0075,  ...,  0.0063,  0.0044,  0.0025],
        [-0.0118,  0.0088,  0.0176,  ...,  0.0298,  0.0069, -0.0113],
        ...,
        [ 0.0005,  0.0007, -0.0052,  ...,  0.0205,  0.0060, -0.0120],
        [-0.0121, -0.0097, -0.0108,  ...,  0.0099, -0.0050,  0.0100],
        [-0.0055,  0.0076,  0.0094,  ..., -0.0004, -0.0083, -0.0136]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.1328, -5.0039,  1.6680,  ..., -4.3398,  0.3901, -1.2266]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 21:34:40 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for In the United Kingdom, the city of belfast is in the county of antrim
In the United Kingdom, the city of stirling is in the county of stirlingshire
In the United Kingdom, the city of lancaster is in the county of lancashire
In the United Kingdom, the city of brighton is in the county of sussex
In the United Kingdom, the city of inverness is in the county of highlands
In the United Kingdom, the city of cambridge is in the county of cambridgeshire
In the United Kingdom, the city of preston is in the county of lancashire
In the United Kingdom, the city of plymouth is in the county of
2024-07-30 21:34:41 root INFO     [order_1_approx] starting weight calculation for In the United Kingdom, the city of lancaster is in the county of lancashire
In the United Kingdom, the city of brighton is in the county of sussex
In the United Kingdom, the city of preston is in the county of lancashire
In the United Kingdom, the city of stirling is in the county of stirlingshire
In the United Kingdom, the city of inverness is in the county of highlands
In the United Kingdom, the city of cambridge is in the county of cambridgeshire
In the United Kingdom, the city of plymouth is in the county of devon
In the United Kingdom, the city of belfast is in the county of
2024-07-30 21:34:41 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 21:34:45 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1301,  0.0092,  0.3020,  ..., -0.2070, -0.4644,  0.0434],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.2393, -1.0898,  3.6992,  ..., -1.8867, -0.8213, -2.4004],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0158, -0.0011, -0.0069,  ...,  0.0058,  0.0002,  0.0211],
        [-0.0142,  0.0590,  0.0069,  ...,  0.0193, -0.0273, -0.0187],
        [-0.0096, -0.0129,  0.0016,  ...,  0.0251, -0.0457,  0.0130],
        ...,
        [ 0.0184,  0.0161, -0.0059,  ...,  0.0386,  0.0236,  0.0214],
        [ 0.0290, -0.0133, -0.0145,  ..., -0.0073,  0.0148, -0.0297],
        [ 0.0273, -0.0123, -0.0027,  ..., -0.0102, -0.0348, -0.0070]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.2354, -1.6543,  3.6172,  ..., -1.4180, -1.4160, -3.2656]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 21:34:46 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If the present form is hear, the past form is heard
If the present form is reduce, the past form is reduced
If the present form is include, the past form is included
If the present form is receive, the past form is received
If the present form is require, the past form is required
If the present form is ask, the past form is asked
If the present form is create, the past form is created
If the present form is develop, the past form is
2024-07-30 21:34:46 root INFO     total operator prediction time: 1277.344788312912 seconds
2024-07-30 21:34:46 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on verb_Ving - Ved
2024-07-30 21:34:46 root INFO     building operator verb_Ving - Ved
2024-07-30 21:34:46 root INFO     [order_1_approx] starting weight calculation for After something is losing, it has lost
After something is suffering, it has suffered
After something is locating, it has located
After something is including, it has included
After something is announcing, it has announced
After something is operating, it has operated
After something is teaching, it has taught
After something is failing, it has
2024-07-30 21:34:46 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-30 21:37:20 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4919,  0.0492, -0.5859,  ...,  0.3855, -0.1705,  0.3489],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 5.6406, -4.6250,  1.6533,  ..., -2.3926, -0.1436, -0.9663],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0017,  0.0038, -0.0034,  ...,  0.0172, -0.0117, -0.0034],
        [ 0.0109,  0.0184,  0.0069,  ...,  0.0005, -0.0139, -0.0083],
        [-0.0034,  0.0208,  0.0146,  ...,  0.0163,  0.0107, -0.0254],
        ...,
        [-0.0135, -0.0007, -0.0020,  ...,  0.0262, -0.0030, -0.0074],
        [ 0.0181, -0.0137,  0.0122,  ...,  0.0097, -0.0136, -0.0003],
        [-0.0054, -0.0039,  0.0037,  ..., -0.0033,  0.0065,  0.0151]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 5.9141, -4.6055,  1.4092,  ..., -2.1250, -0.0187, -0.7500]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 21:37:21 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for In the United Kingdom, the city of lancaster is in the county of lancashire
In the United Kingdom, the city of brighton is in the county of sussex
In the United Kingdom, the city of preston is in the county of lancashire
In the United Kingdom, the city of stirling is in the county of stirlingshire
In the United Kingdom, the city of inverness is in the county of highlands
In the United Kingdom, the city of cambridge is in the county of cambridgeshire
In the United Kingdom, the city of plymouth is in the county of devon
In the United Kingdom, the city of belfast is in the county of
2024-07-30 21:37:21 root INFO     [order_1_approx] starting weight calculation for In the United Kingdom, the city of brighton is in the county of sussex
In the United Kingdom, the city of plymouth is in the county of devon
In the United Kingdom, the city of stirling is in the county of stirlingshire
In the United Kingdom, the city of preston is in the county of lancashire
In the United Kingdom, the city of belfast is in the county of antrim
In the United Kingdom, the city of inverness is in the county of highlands
In the United Kingdom, the city of cambridge is in the county of cambridgeshire
In the United Kingdom, the city of lancaster is in the county of
2024-07-30 21:37:21 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 21:37:25 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0070,  0.0631, -0.3162,  ..., -0.1510,  0.2500, -0.3018],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.4219, -0.0244,  3.3867,  ..., -3.1250, -0.7783, -1.3691],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0230, -0.0132,  0.0222,  ..., -0.0227, -0.0061,  0.0484],
        [-0.0389,  0.0395, -0.0011,  ...,  0.0242,  0.0188, -0.0376],
        [ 0.0021, -0.0289,  0.0126,  ..., -0.0130,  0.0373, -0.0067],
        ...,
        [ 0.0068,  0.0168, -0.0237,  ...,  0.0167, -0.0101, -0.0053],
        [ 0.0154, -0.0260,  0.0192,  ...,  0.0251,  0.0463,  0.0039],
        [-0.0088,  0.0432, -0.0067,  ...,  0.0028, -0.0091, -0.0168]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.5269, -0.1277,  3.0000,  ..., -2.7480, -0.8247, -1.4307]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 21:37:26 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for After something is losing, it has lost
After something is suffering, it has suffered
After something is locating, it has located
After something is including, it has included
After something is announcing, it has announced
After something is operating, it has operated
After something is teaching, it has taught
After something is failing, it has
2024-07-30 21:37:27 root INFO     [order_1_approx] starting weight calculation for After something is losing, it has lost
After something is locating, it has located
After something is announcing, it has announced
After something is suffering, it has suffered
After something is teaching, it has taught
After something is operating, it has operated
After something is failing, it has failed
After something is including, it has
2024-07-30 21:37:27 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-30 21:40:00 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2227, -0.0470, -0.5327,  ...,  0.2896, -0.6367, -0.0625],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.0801, -2.9961,  2.7617,  ..., -4.3477,  2.0898,  1.0996],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0201, -0.0007,  0.0125,  ..., -0.0059,  0.0089, -0.0202],
        [ 0.0283,  0.0303,  0.0163,  ...,  0.0042, -0.0044,  0.0014],
        [-0.0319,  0.0397,  0.0226,  ...,  0.0180,  0.0096, -0.0339],
        ...,
        [ 0.0023,  0.0061,  0.0005,  ...,  0.0150,  0.0179,  0.0054],
        [ 0.0154, -0.0037, -0.0010,  ...,  0.0164, -0.0073, -0.0058],
        [-0.0080, -0.0065, -0.0010,  ..., -0.0131, -0.0134,  0.0088]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.0098, -3.1426,  2.9043,  ..., -3.8711,  2.1445,  1.1953]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 21:40:01 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for In the United Kingdom, the city of brighton is in the county of sussex
In the United Kingdom, the city of plymouth is in the county of devon
In the United Kingdom, the city of stirling is in the county of stirlingshire
In the United Kingdom, the city of preston is in the county of lancashire
In the United Kingdom, the city of belfast is in the county of antrim
In the United Kingdom, the city of inverness is in the county of highlands
In the United Kingdom, the city of cambridge is in the county of cambridgeshire
In the United Kingdom, the city of lancaster is in the county of
2024-07-30 21:40:01 root INFO     [order_1_approx] starting weight calculation for In the United Kingdom, the city of lancaster is in the county of lancashire
In the United Kingdom, the city of belfast is in the county of antrim
In the United Kingdom, the city of cambridge is in the county of cambridgeshire
In the United Kingdom, the city of preston is in the county of lancashire
In the United Kingdom, the city of plymouth is in the county of devon
In the United Kingdom, the city of stirling is in the county of stirlingshire
In the United Kingdom, the city of brighton is in the county of sussex
In the United Kingdom, the city of inverness is in the county of
2024-07-30 21:40:01 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 21:40:05 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0385,  0.0223,  0.0378,  ...,  0.2102, -0.1149, -0.1270],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.1484,  1.7910,  0.8584,  ..., -2.1133, -0.4873, -2.4219],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0774, -0.0160,  0.0056,  ...,  0.0086,  0.0277, -0.0151],
        [-0.0396,  0.0266,  0.0055,  ...,  0.0281, -0.0356, -0.0346],
        [ 0.0106, -0.0211, -0.0118,  ..., -0.0075, -0.0098, -0.0010],
        ...,
        [ 0.0252,  0.0259, -0.0191,  ...,  0.0193,  0.0305,  0.0182],
        [ 0.0396, -0.0226, -0.0083,  ..., -0.0152, -0.0167,  0.0233],
        [-0.0413,  0.0498,  0.0295,  ...,  0.0196, -0.0640,  0.0189]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.4365,  1.8936,  1.4492,  ..., -2.1621,  0.0027, -2.6602]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 21:40:09 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for After something is losing, it has lost
After something is locating, it has located
After something is announcing, it has announced
After something is suffering, it has suffered
After something is teaching, it has taught
After something is operating, it has operated
After something is failing, it has failed
After something is including, it has
2024-07-30 21:40:31 root INFO     [order_1_approx] starting weight calculation for After something is losing, it has lost
After something is locating, it has located
After something is failing, it has failed
After something is announcing, it has announced
After something is teaching, it has taught
After something is operating, it has operated
After something is including, it has included
After something is suffering, it has
2024-07-30 21:40:31 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-30 21:42:41 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2273,  0.0287, -0.1069,  ...,  0.0264, -0.1506,  0.1411],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.9375, -2.1074,  0.6245,  ..., -4.3633, -1.1709, -2.3125],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0061, -0.0157, -0.0024,  ...,  0.0023, -0.0116,  0.0085],
        [ 0.0106,  0.0333,  0.0157,  ...,  0.0076, -0.0040, -0.0219],
        [-0.0153,  0.0112,  0.0275,  ...,  0.0229, -0.0037,  0.0068],
        ...,
        [ 0.0077,  0.0173,  0.0053,  ...,  0.0204,  0.0201,  0.0068],
        [ 0.0022, -0.0074, -0.0125,  ...,  0.0068, -0.0009,  0.0132],
        [-0.0172,  0.0054, -0.0148,  ...,  0.0025,  0.0039,  0.0250]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.9590, -1.8799,  0.6714,  ..., -3.3164, -1.4297, -2.4336]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 21:42:42 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for In the United Kingdom, the city of lancaster is in the county of lancashire
In the United Kingdom, the city of belfast is in the county of antrim
In the United Kingdom, the city of cambridge is in the county of cambridgeshire
In the United Kingdom, the city of preston is in the county of lancashire
In the United Kingdom, the city of plymouth is in the county of devon
In the United Kingdom, the city of stirling is in the county of stirlingshire
In the United Kingdom, the city of brighton is in the county of sussex
In the United Kingdom, the city of inverness is in the county of
2024-07-30 21:42:42 root INFO     [order_1_approx] starting weight calculation for In the United Kingdom, the city of lancaster is in the county of lancashire
In the United Kingdom, the city of preston is in the county of lancashire
In the United Kingdom, the city of brighton is in the county of sussex
In the United Kingdom, the city of plymouth is in the county of devon
In the United Kingdom, the city of cambridge is in the county of cambridgeshire
In the United Kingdom, the city of belfast is in the county of antrim
In the United Kingdom, the city of inverness is in the county of highlands
In the United Kingdom, the city of stirling is in the county of
2024-07-30 21:42:42 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 21:43:08 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0413,  0.3306,  0.0249,  ..., -0.3865, -0.1887, -0.0364],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.3008, -1.8867,  0.9702,  ..., -3.8008,  2.7969,  0.8848],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0373, -0.0092,  0.0130,  ..., -0.0243,  0.0217,  0.0363],
        [-0.0322,  0.0273,  0.0206,  ...,  0.0085,  0.0017, -0.0044],
        [-0.0140, -0.0011,  0.0101,  ..., -0.0072,  0.0368, -0.0145],
        ...,
        [ 0.0102,  0.0133, -0.0138,  ...,  0.0090,  0.0071, -0.0089],
        [ 0.0001, -0.0022,  0.0064,  ..., -0.0088,  0.0289, -0.0226],
        [ 0.0016,  0.0261,  0.0137,  ...,  0.0108, -0.0209, -0.0022]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.0312, -1.8125,  1.0479,  ..., -3.5293,  2.8945,  0.4768]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 21:43:09 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for After something is losing, it has lost
After something is locating, it has located
After something is failing, it has failed
After something is announcing, it has announced
After something is teaching, it has taught
After something is operating, it has operated
After something is including, it has included
After something is suffering, it has
2024-07-30 21:43:09 root INFO     [order_1_approx] starting weight calculation for After something is failing, it has failed
After something is locating, it has located
After something is announcing, it has announced
After something is operating, it has operated
After something is suffering, it has suffered
After something is losing, it has lost
After something is including, it has included
After something is teaching, it has
2024-07-30 21:43:10 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-30 21:45:28 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2842,  0.3557, -0.2294,  ...,  0.2241, -0.2111,  0.1882],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.7148, -4.1523,  0.1621,  ..., -3.6074, -2.3203, -1.6973],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0011, -0.0044,  0.0200,  ...,  0.0201, -0.0094, -0.0324],
        [ 0.0149,  0.0182,  0.0261,  ...,  0.0068,  0.0070,  0.0051],
        [ 0.0075,  0.0089,  0.0316,  ...,  0.0159,  0.0059, -0.0140],
        ...,
        [ 0.0344, -0.0117, -0.0152,  ...,  0.0359,  0.0158,  0.0072],
        [-0.0075, -0.0254, -0.0279,  ...,  0.0203, -0.0050,  0.0195],
        [-0.0022, -0.0102, -0.0244,  ..., -0.0048, -0.0133,  0.0358]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.4531, -3.7734,  0.2625,  ..., -3.0117, -1.9258, -1.6787]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 21:45:28 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for In the United Kingdom, the city of lancaster is in the county of lancashire
In the United Kingdom, the city of preston is in the county of lancashire
In the United Kingdom, the city of brighton is in the county of sussex
In the United Kingdom, the city of plymouth is in the county of devon
In the United Kingdom, the city of cambridge is in the county of cambridgeshire
In the United Kingdom, the city of belfast is in the county of antrim
In the United Kingdom, the city of inverness is in the county of highlands
In the United Kingdom, the city of stirling is in the county of
2024-07-30 21:45:29 root INFO     [order_1_approx] starting weight calculation for In the United Kingdom, the city of belfast is in the county of antrim
In the United Kingdom, the city of brighton is in the county of sussex
In the United Kingdom, the city of preston is in the county of lancashire
In the United Kingdom, the city of plymouth is in the county of devon
In the United Kingdom, the city of lancaster is in the county of lancashire
In the United Kingdom, the city of stirling is in the county of stirlingshire
In the United Kingdom, the city of inverness is in the county of highlands
In the United Kingdom, the city of cambridge is in the county of
2024-07-30 21:45:29 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 21:45:49 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2437,  0.3701,  0.1223,  ..., -0.0800, -0.1858, -0.0453],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.1406,  1.0391,  3.5312,  ..., -1.1025, -2.6406, -4.4102],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 1.9150e-02, -4.2229e-03,  1.1911e-03,  ...,  8.3237e-03,
         -7.5455e-03,  9.6893e-03],
        [-3.5767e-02,  4.2358e-02, -2.2415e-02,  ...,  1.2009e-02,
         -9.8267e-03, -1.5274e-02],
        [-1.6006e-02, -3.6621e-04, -7.0534e-03,  ...,  2.0035e-02,
          1.9928e-02, -2.3613e-03],
        ...,
        [ 2.5528e-02,  2.2354e-02, -2.0065e-02,  ..., -5.2681e-03,
          1.9180e-02,  1.5411e-02],
        [ 1.4107e-02,  2.8030e-02,  1.2329e-02,  ...,  1.5976e-02,
          2.5055e-02, -2.8896e-03],
        [-1.9073e-05,  2.2430e-02,  1.6052e-02,  ...,  2.7237e-02,
          2.1515e-03, -7.9956e-03]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.1094,  0.9072,  3.7051,  ..., -0.9800, -2.6504, -4.7383]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 21:45:50 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for After something is failing, it has failed
After something is locating, it has located
After something is announcing, it has announced
After something is operating, it has operated
After something is suffering, it has suffered
After something is losing, it has lost
After something is including, it has included
After something is teaching, it has
2024-07-30 21:45:50 root INFO     [order_1_approx] starting weight calculation for After something is teaching, it has taught
After something is operating, it has operated
After something is announcing, it has announced
After something is including, it has included
After something is suffering, it has suffered
After something is losing, it has lost
After something is failing, it has failed
After something is locating, it has
2024-07-30 21:45:50 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-30 21:48:08 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4636, -0.0782, -0.1567,  ...,  0.1553, -0.3396,  0.2122],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.2148, -3.8438, -0.3789,  ..., -5.2422, -2.5938,  1.5664],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0048, -0.0085,  0.0022,  ..., -0.0020, -0.0383,  0.0038],
        [-0.0008,  0.0243,  0.0174,  ...,  0.0140, -0.0155, -0.0182],
        [-0.0061,  0.0254,  0.0170,  ...,  0.0349,  0.0138,  0.0093],
        ...,
        [ 0.0019, -0.0071, -0.0117,  ...,  0.0249,  0.0221,  0.0050],
        [-0.0002, -0.0142, -0.0182,  ...,  0.0118,  0.0087,  0.0208],
        [ 0.0051,  0.0088,  0.0195,  ...,  0.0036, -0.0394,  0.0009]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.3613, -4.1055, -1.0996,  ..., -4.8633, -2.7012,  1.5938]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 21:48:09 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for In the United Kingdom, the city of belfast is in the county of antrim
In the United Kingdom, the city of brighton is in the county of sussex
In the United Kingdom, the city of preston is in the county of lancashire
In the United Kingdom, the city of plymouth is in the county of devon
In the United Kingdom, the city of lancaster is in the county of lancashire
In the United Kingdom, the city of stirling is in the county of stirlingshire
In the United Kingdom, the city of inverness is in the county of highlands
In the United Kingdom, the city of cambridge is in the county of
2024-07-30 21:48:09 root INFO     [order_1_approx] starting weight calculation for In the United Kingdom, the city of cambridge is in the county of cambridgeshire
In the United Kingdom, the city of brighton is in the county of sussex
In the United Kingdom, the city of plymouth is in the county of devon
In the United Kingdom, the city of inverness is in the county of highlands
In the United Kingdom, the city of lancaster is in the county of lancashire
In the United Kingdom, the city of belfast is in the county of antrim
In the United Kingdom, the city of stirling is in the county of stirlingshire
In the United Kingdom, the city of preston is in the county of
2024-07-30 21:48:09 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 21:48:31 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0646,  0.2739, -0.2128,  ...,  0.1135, -0.0883, -0.2172],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.7539, -1.2793, -1.5439,  ..., -2.2305, -2.9551, -2.7832],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0465, -0.0289, -0.0081,  ...,  0.0139, -0.0041,  0.0241],
        [-0.0246,  0.0531,  0.0067,  ...,  0.0186,  0.0110, -0.0204],
        [ 0.0151, -0.0065,  0.0179,  ..., -0.0132, -0.0005, -0.0060],
        ...,
        [ 0.0112,  0.0338, -0.0029,  ...,  0.0090, -0.0056,  0.0167],
        [ 0.0208, -0.0214,  0.0048,  ..., -0.0200, -0.0097,  0.0011],
        [-0.0014,  0.0501,  0.0153,  ...,  0.0292, -0.0572,  0.0134]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.8457, -1.1729, -1.2080,  ..., -2.0742, -2.9746, -2.6660]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 21:48:54 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for After something is teaching, it has taught
After something is operating, it has operated
After something is announcing, it has announced
After something is including, it has included
After something is suffering, it has suffered
After something is losing, it has lost
After something is failing, it has failed
After something is locating, it has
2024-07-30 21:48:54 root INFO     [order_1_approx] starting weight calculation for After something is including, it has included
After something is locating, it has located
After something is suffering, it has suffered
After something is teaching, it has taught
After something is losing, it has lost
After something is announcing, it has announced
After something is failing, it has failed
After something is operating, it has
2024-07-30 21:48:54 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-30 21:50:49 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1287,  0.2030, -0.3835,  ...,  0.5361, -0.2062, -0.0120],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.3086, -4.1328,  1.2422,  ..., -2.0488,  0.4775, -1.4990],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0040,  0.0102, -0.0126,  ..., -0.0003, -0.0135, -0.0033],
        [ 0.0147,  0.0313,  0.0162,  ...,  0.0143, -0.0097,  0.0236],
        [ 0.0036,  0.0176,  0.0470,  ...,  0.0249,  0.0054, -0.0558],
        ...,
        [ 0.0198, -0.0052,  0.0011,  ...,  0.0443,  0.0080, -0.0311],
        [ 0.0237, -0.0171, -0.0047,  ...,  0.0142, -0.0102, -0.0119],
        [ 0.0273, -0.0220, -0.0002,  ..., -0.0174, -0.0174,  0.0012]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.0371, -4.1484,  1.0469,  ..., -1.8604,  0.9009, -1.1660]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 21:50:50 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for In the United Kingdom, the city of cambridge is in the county of cambridgeshire
In the United Kingdom, the city of brighton is in the county of sussex
In the United Kingdom, the city of plymouth is in the county of devon
In the United Kingdom, the city of inverness is in the county of highlands
In the United Kingdom, the city of lancaster is in the county of lancashire
In the United Kingdom, the city of belfast is in the county of antrim
In the United Kingdom, the city of stirling is in the county of stirlingshire
In the United Kingdom, the city of preston is in the county of
2024-07-30 21:50:50 root INFO     total operator prediction time: 1318.0692129135132 seconds
2024-07-30 21:50:50 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on verb+ment_irreg
2024-07-30 21:50:50 root INFO     building operator verb+ment_irreg
2024-07-30 21:50:50 root INFO     [order_1_approx] starting weight calculation for To appoint results in a appointment
To assess results in a assessment
To detach results in a detachment
To entitle results in a entitlement
To embarrass results in a embarrassment
To reinforce results in a reinforcement
To equip results in a equipment
To encourage results in a
2024-07-30 21:50:50 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 21:51:29 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1976,  0.0618, -0.3296,  ..., -0.1036, -0.1329, -0.2981],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.8838, -0.2700,  0.7861,  ..., -3.7266, -1.3740, -0.3398],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0312, -0.0164,  0.0149,  ..., -0.0116, -0.0007,  0.0063],
        [-0.0282,  0.0575, -0.0160,  ...,  0.0145,  0.0013, -0.0207],
        [-0.0280,  0.0208,  0.0159,  ..., -0.0129,  0.0327,  0.0019],
        ...,
        [ 0.0224,  0.0248, -0.0285,  ...,  0.0197,  0.0257, -0.0034],
        [ 0.0173, -0.0236,  0.0040,  ..., -0.0013,  0.0160, -0.0048],
        [ 0.0048,  0.0161,  0.0015,  ...,  0.0090, -0.0266,  0.0055]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.1328, -0.0930,  1.1807,  ..., -3.2227, -1.7617, -0.6250]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 21:51:31 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for After something is including, it has included
After something is locating, it has located
After something is suffering, it has suffered
After something is teaching, it has taught
After something is losing, it has lost
After something is announcing, it has announced
After something is failing, it has failed
After something is operating, it has
2024-07-30 21:51:31 root INFO     [order_1_approx] starting weight calculation for After something is failing, it has failed
After something is teaching, it has taught
After something is suffering, it has suffered
After something is operating, it has operated
After something is including, it has included
After something is locating, it has located
After something is announcing, it has announced
After something is losing, it has
2024-07-30 21:51:31 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-30 21:53:22 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0706,  0.8496, -0.6226,  ..., -0.0364, -0.1255,  0.2119],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.1943, -1.8496, -0.2147,  ...,  4.3828, -0.8486, -1.8076],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0068,  0.0249,  0.0096,  ...,  0.0131, -0.0005,  0.0101],
        [-0.0137,  0.0355, -0.0164,  ...,  0.0215,  0.0218,  0.0033],
        [ 0.0098, -0.0041, -0.0151,  ..., -0.0125,  0.0167, -0.0079],
        ...,
        [-0.0053, -0.0040,  0.0250,  ...,  0.0136, -0.0061,  0.0119],
        [ 0.0094,  0.0008,  0.0004,  ..., -0.0085,  0.0111, -0.0056],
        [ 0.0110,  0.0054, -0.0089,  ...,  0.0369, -0.0330,  0.0319]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.4199, -1.7480, -0.0576,  ...,  4.1445, -1.1973, -1.6113]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 21:53:23 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To appoint results in a appointment
To assess results in a assessment
To detach results in a detachment
To entitle results in a entitlement
To embarrass results in a embarrassment
To reinforce results in a reinforcement
To equip results in a equipment
To encourage results in a
2024-07-30 21:53:23 root INFO     [order_1_approx] starting weight calculation for To entitle results in a entitlement
To embarrass results in a embarrassment
To detach results in a detachment
To encourage results in a encouragement
To appoint results in a appointment
To assess results in a assessment
To reinforce results in a reinforcement
To equip results in a
2024-07-30 21:53:23 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 21:54:06 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0919,  0.1283,  0.0828,  ..., -0.2148,  0.0867, -0.1132],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.5854, -0.4160,  0.0762,  ..., -1.9980, -0.6211, -0.6953],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0360,  0.0057,  0.0240,  ..., -0.0136, -0.0040,  0.0026],
        [-0.0286,  0.0797,  0.0152,  ...,  0.0168, -0.0053, -0.0374],
        [-0.0041, -0.0058,  0.0331,  ..., -0.0021, -0.0035, -0.0036],
        ...,
        [-0.0026,  0.0210, -0.0481,  ...,  0.0028, -0.0046,  0.0065],
        [ 0.0418, -0.0261,  0.0050,  ..., -0.0071,  0.0415,  0.0031],
        [-0.0024,  0.0303,  0.0368,  ..., -0.0069,  0.0006, -0.0046]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.0449, -0.6865,  0.4248,  ..., -1.3076, -0.4414, -0.9507]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 21:54:07 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for After something is failing, it has failed
After something is teaching, it has taught
After something is suffering, it has suffered
After something is operating, it has operated
After something is including, it has included
After something is locating, it has located
After something is announcing, it has announced
After something is losing, it has
2024-07-30 21:54:07 root INFO     [order_1_approx] starting weight calculation for After something is losing, it has lost
After something is operating, it has operated
After something is including, it has included
After something is failing, it has failed
After something is suffering, it has suffered
After something is locating, it has located
After something is teaching, it has taught
After something is announcing, it has
2024-07-30 21:54:07 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-30 21:55:57 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0379,  0.6626, -0.4214,  ..., -0.0067, -0.0421,  0.2097],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.1641, -1.9316, -0.6885,  ...,  4.0820, -2.8809, -2.5176],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0336, -0.0140,  0.0102,  ...,  0.0155,  0.0077,  0.0130],
        [-0.0240,  0.0481,  0.0009,  ...,  0.0116,  0.0061, -0.0189],
        [ 0.0118, -0.0137,  0.0164,  ..., -0.0110,  0.0043, -0.0027],
        ...,
        [ 0.0073,  0.0187,  0.0149,  ...,  0.0189,  0.0052, -0.0060],
        [-0.0112,  0.0111,  0.0095,  ...,  0.0014,  0.0376, -0.0082],
        [-0.0126, -0.0182,  0.0017,  ...,  0.0269, -0.0270,  0.0343]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.1201, -1.8398, -0.7085,  ...,  4.6406, -2.9199, -2.4961]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 21:55:58 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To entitle results in a entitlement
To embarrass results in a embarrassment
To detach results in a detachment
To encourage results in a encouragement
To appoint results in a appointment
To assess results in a assessment
To reinforce results in a reinforcement
To equip results in a
2024-07-30 21:55:58 root INFO     [order_1_approx] starting weight calculation for To encourage results in a encouragement
To reinforce results in a reinforcement
To assess results in a assessment
To detach results in a detachment
To embarrass results in a embarrassment
To equip results in a equipment
To appoint results in a appointment
To entitle results in a
2024-07-30 21:55:58 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 21:56:45 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0276,  0.4094, -0.0430,  ...,  0.0693, -0.2307, -0.3022],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.1680, -1.4980,  2.3301,  ...,  0.8999, -2.5039,  1.2344],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0175, -0.0004,  0.0032,  ...,  0.0213, -0.0063,  0.0226],
        [-0.0144,  0.0144,  0.0028,  ..., -0.0035,  0.0110, -0.0138],
        [ 0.0047, -0.0205, -0.0022,  ..., -0.0127,  0.0091,  0.0097],
        ...,
        [ 0.0080,  0.0170, -0.0081,  ..., -0.0074,  0.0202,  0.0334],
        [ 0.0033,  0.0021, -0.0025,  ..., -0.0165, -0.0061, -0.0108],
        [ 0.0081,  0.0209,  0.0128,  ..., -0.0003, -0.0222, -0.0085]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.6445, -1.5068,  2.6328,  ...,  1.2930, -2.7148,  0.7461]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 21:56:46 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for After something is losing, it has lost
After something is operating, it has operated
After something is including, it has included
After something is failing, it has failed
After something is suffering, it has suffered
After something is locating, it has located
After something is teaching, it has taught
After something is announcing, it has
2024-07-30 21:56:46 root INFO     total operator prediction time: 1319.9563941955566 seconds
2024-07-30 21:56:46 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on Ving - verb_inf
2024-07-30 21:56:46 root INFO     building operator Ving - verb_inf
2024-07-30 21:56:46 root INFO     [order_1_approx] starting weight calculation for including is the active form of include
telling is the active form of tell
happening is the active form of happen
maintaining is the active form of maintain
identifying is the active form of identify
ensuring is the active form of ensure
avoiding is the active form of avoid
continuing is the active form of
2024-07-30 21:56:46 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-30 21:58:31 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1582,  0.1849, -0.4175,  ...,  0.2803, -0.4917,  0.3057],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.2007, -3.9883,  0.5117,  ...,  1.9707, -2.4570, -2.6797],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0339,  0.0025,  0.0032,  ...,  0.0287, -0.0041,  0.0047],
        [-0.0278,  0.0354, -0.0039,  ...,  0.0274,  0.0258, -0.0078],
        [ 0.0070, -0.0354, -0.0028,  ..., -0.0057, -0.0149,  0.0043],
        ...,
        [ 0.0005,  0.0141,  0.0037,  ...,  0.0079,  0.0275,  0.0123],
        [ 0.0021, -0.0079,  0.0081,  ...,  0.0129,  0.0238, -0.0100],
        [-0.0020, -0.0107,  0.0124,  ...,  0.0048, -0.0112,  0.0529]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.3867, -3.3320,  0.5205,  ...,  2.3047, -2.5176, -2.4805]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 21:58:32 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To encourage results in a encouragement
To reinforce results in a reinforcement
To assess results in a assessment
To detach results in a detachment
To embarrass results in a embarrassment
To equip results in a equipment
To appoint results in a appointment
To entitle results in a
2024-07-30 21:58:32 root INFO     [order_1_approx] starting weight calculation for To reinforce results in a reinforcement
To detach results in a detachment
To equip results in a equipment
To entitle results in a entitlement
To embarrass results in a embarrassment
To appoint results in a appointment
To encourage results in a encouragement
To assess results in a
2024-07-30 21:58:32 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 21:59:26 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1589,  0.0594, -0.2942,  ..., -0.1781, -0.2717,  0.0869],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.3818, -4.0430,  0.8901,  ...,  1.4941,  1.0410, -1.6895],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0191, -0.0090, -0.0153,  ...,  0.0008, -0.0081,  0.0066],
        [-0.0224,  0.0377, -0.0060,  ...,  0.0012,  0.0157,  0.0099],
        [ 0.0061,  0.0037,  0.0222,  ..., -0.0103, -0.0076, -0.0052],
        ...,
        [ 0.0103,  0.0198,  0.0090,  ...,  0.0288, -0.0067,  0.0214],
        [ 0.0101, -0.0018, -0.0026,  ...,  0.0053,  0.0292,  0.0222],
        [ 0.0056,  0.0190, -0.0091,  ..., -0.0138, -0.0054,  0.0163]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.1459, -4.0625,  0.6992,  ...,  1.4961,  1.3223, -1.8945]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 21:59:27 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for including is the active form of include
telling is the active form of tell
happening is the active form of happen
maintaining is the active form of maintain
identifying is the active form of identify
ensuring is the active form of ensure
avoiding is the active form of avoid
continuing is the active form of
2024-07-30 21:59:27 root INFO     [order_1_approx] starting weight calculation for continuing is the active form of continue
identifying is the active form of identify
ensuring is the active form of ensure
avoiding is the active form of avoid
including is the active form of include
happening is the active form of happen
telling is the active form of tell
maintaining is the active form of
2024-07-30 21:59:27 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-30 22:01:05 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1234,  0.2788, -0.3438,  ...,  0.0907, -0.0428, -0.1051],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.7109, -2.6387, -0.4321,  ...,  2.5684, -2.7227, -2.1738],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0305, -0.0229,  0.0028,  ..., -0.0082,  0.0133,  0.0170],
        [-0.0049,  0.0303,  0.0241,  ...,  0.0249,  0.0219, -0.0008],
        [ 0.0224, -0.0010,  0.0193,  ..., -0.0241, -0.0035, -0.0294],
        ...,
        [ 0.0001,  0.0160,  0.0009,  ...,  0.0298,  0.0120, -0.0045],
        [-0.0176,  0.0019,  0.0072,  ...,  0.0096,  0.0234,  0.0117],
        [ 0.0160,  0.0009, -0.0038,  ...,  0.0229, -0.0160,  0.0224]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.5859, -2.4824, -0.3125,  ...,  2.8164, -2.7637, -2.0020]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 22:01:06 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To reinforce results in a reinforcement
To detach results in a detachment
To equip results in a equipment
To entitle results in a entitlement
To embarrass results in a embarrassment
To appoint results in a appointment
To encourage results in a encouragement
To assess results in a
2024-07-30 22:01:06 root INFO     [order_1_approx] starting weight calculation for To entitle results in a entitlement
To appoint results in a appointment
To equip results in a equipment
To embarrass results in a embarrassment
To assess results in a assessment
To encourage results in a encouragement
To detach results in a detachment
To reinforce results in a
2024-07-30 22:01:06 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 22:02:06 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4316,  0.0342, -0.1409,  ..., -0.1665, -0.2986,  0.0419],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.9043, -4.4688, -0.4204,  ...,  0.3423, -0.6621, -1.7480],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0543, -0.0003, -0.0019,  ..., -0.0135, -0.0233,  0.0158],
        [-0.0055,  0.0554, -0.0043,  ...,  0.0168,  0.0131, -0.0028],
        [ 0.0105,  0.0053,  0.0237,  ..., -0.0121, -0.0029, -0.0085],
        ...,
        [ 0.0100,  0.0074, -0.0075,  ...,  0.0357, -0.0017,  0.0085],
        [ 0.0052,  0.0021, -0.0006,  ..., -0.0095,  0.0384,  0.0086],
        [-0.0006,  0.0094, -0.0116,  ..., -0.0109, -0.0073,  0.0318]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.7822, -4.7031, -0.4524,  ...,  0.2300, -0.6313, -1.9785]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 22:02:07 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for continuing is the active form of continue
identifying is the active form of identify
ensuring is the active form of ensure
avoiding is the active form of avoid
including is the active form of include
happening is the active form of happen
telling is the active form of tell
maintaining is the active form of
2024-07-30 22:02:07 root INFO     [order_1_approx] starting weight calculation for identifying is the active form of identify
telling is the active form of tell
maintaining is the active form of maintain
including is the active form of include
happening is the active form of happen
avoiding is the active form of avoid
continuing is the active form of continue
ensuring is the active form of
2024-07-30 22:02:07 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-30 22:03:39 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0140,  0.0057, -0.3818,  ...,  0.3650, -0.3296, -0.0042],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.3848, -2.8691,  2.2754,  ...,  4.3203, -2.7031, -5.0469],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0488, -0.0098,  0.0039,  ...,  0.0184, -0.0082,  0.0274],
        [-0.0281,  0.0634, -0.0008,  ...,  0.0045,  0.0368, -0.0102],
        [ 0.0112, -0.0217,  0.0172,  ..., -0.0046, -0.0052,  0.0108],
        ...,
        [ 0.0193,  0.0028,  0.0020,  ...,  0.0320,  0.0032,  0.0140],
        [-0.0023,  0.0176, -0.0001,  ..., -0.0021,  0.0249, -0.0121],
        [-0.0207, -0.0166,  0.0105,  ...,  0.0097, -0.0163,  0.0142]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.5420, -2.7363,  2.7305,  ...,  4.2031, -2.9980, -5.0078]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 22:03:40 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To entitle results in a entitlement
To appoint results in a appointment
To equip results in a equipment
To embarrass results in a embarrassment
To assess results in a assessment
To encourage results in a encouragement
To detach results in a detachment
To reinforce results in a
2024-07-30 22:03:41 root INFO     [order_1_approx] starting weight calculation for To reinforce results in a reinforcement
To detach results in a detachment
To equip results in a equipment
To assess results in a assessment
To embarrass results in a embarrassment
To encourage results in a encouragement
To entitle results in a entitlement
To appoint results in a
2024-07-30 22:03:41 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 22:04:47 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0253,  0.3481, -0.2346,  ..., -0.0176,  0.0558, -0.2465],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.7695, -3.6992, -0.1660,  ...,  1.4902, -1.9854, -2.9297],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 1.7059e-02, -4.9973e-03, -5.1270e-03,  ...,  1.3245e-02,
         -7.2136e-03, -5.6000e-03],
        [-7.1182e-03,  2.1851e-02,  4.3068e-03,  ...,  7.2861e-03,
         -6.2256e-03,  1.6031e-03],
        [-5.5618e-03,  8.6975e-03,  2.0504e-03,  ..., -3.9825e-03,
          5.5885e-03, -5.6610e-03],
        ...,
        [ 3.9482e-03,  4.6539e-04,  9.2010e-03,  ...,  1.2344e-02,
         -1.2848e-02,  2.5921e-03],
        [ 1.2650e-02,  4.3640e-03, -3.4332e-05,  ...,  4.8943e-03,
          1.6296e-02,  1.9394e-02],
        [ 1.0414e-02,  1.7059e-02,  1.9398e-03,  ...,  4.0054e-05,
         -3.2654e-03,  2.3743e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.7075, -3.6992, -0.2147,  ...,  1.5596, -1.9756, -3.0605]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 22:04:50 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for identifying is the active form of identify
telling is the active form of tell
maintaining is the active form of maintain
including is the active form of include
happening is the active form of happen
avoiding is the active form of avoid
continuing is the active form of continue
ensuring is the active form of
2024-07-30 22:04:52 root INFO     [order_1_approx] starting weight calculation for telling is the active form of tell
identifying is the active form of identify
including is the active form of include
continuing is the active form of continue
ensuring is the active form of ensure
avoiding is the active form of avoid
maintaining is the active form of maintain
happening is the active form of
2024-07-30 22:04:52 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-30 22:06:14 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.5200,  0.4907, -0.3184,  ...,  0.1038, -0.3093, -0.0347],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.6221, -4.5742,  1.4414,  ...,  3.6758, -2.6953, -2.9414],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0449,  0.0140, -0.0083,  ...,  0.0059, -0.0064,  0.0010],
        [-0.0010,  0.0326,  0.0420,  ...,  0.0316,  0.0270, -0.0075],
        [ 0.0054, -0.0044, -0.0024,  ..., -0.0231, -0.0221, -0.0029],
        ...,
        [-0.0060,  0.0331, -0.0181,  ...,  0.0225,  0.0186,  0.0173],
        [-0.0024, -0.0034, -0.0027,  ..., -0.0023,  0.0150, -0.0186],
        [ 0.0164, -0.0116, -0.0034,  ...,  0.0135,  0.0073,  0.0419]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.6484, -3.8242,  1.1699,  ...,  3.5762, -3.0879, -2.8301]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 22:06:14 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To reinforce results in a reinforcement
To detach results in a detachment
To equip results in a equipment
To assess results in a assessment
To embarrass results in a embarrassment
To encourage results in a encouragement
To entitle results in a entitlement
To appoint results in a
2024-07-30 22:06:15 root INFO     [order_1_approx] starting weight calculation for To entitle results in a entitlement
To reinforce results in a reinforcement
To assess results in a assessment
To embarrass results in a embarrassment
To encourage results in a encouragement
To equip results in a equipment
To appoint results in a appointment
To detach results in a
2024-07-30 22:06:15 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 22:07:33 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1117,  0.3049,  0.0323,  ..., -0.2942, -0.1777, -0.4600],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.1250, -3.5488,  1.5469,  ...,  2.0273, -3.0078, -0.6475],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0249, -0.0009,  0.0034,  ...,  0.0012, -0.0033,  0.0107],
        [-0.0020,  0.0185, -0.0136,  ..., -0.0062,  0.0058, -0.0094],
        [ 0.0100, -0.0044,  0.0216,  ...,  0.0027, -0.0116, -0.0203],
        ...,
        [ 0.0021,  0.0126, -0.0095,  ...,  0.0090, -0.0064,  0.0007],
        [ 0.0149, -0.0177, -0.0117,  ...,  0.0135,  0.0327,  0.0238],
        [ 0.0070,  0.0159,  0.0051,  ...,  0.0026, -0.0001,  0.0219]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.0000, -3.5508,  1.4072,  ...,  1.9434, -2.7109, -0.7495]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 22:07:34 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for telling is the active form of tell
identifying is the active form of identify
including is the active form of include
continuing is the active form of continue
ensuring is the active form of ensure
avoiding is the active form of avoid
maintaining is the active form of maintain
happening is the active form of
2024-07-30 22:07:34 root INFO     [order_1_approx] starting weight calculation for continuing is the active form of continue
including is the active form of include
telling is the active form of tell
maintaining is the active form of maintain
happening is the active form of happen
ensuring is the active form of ensure
identifying is the active form of identify
avoiding is the active form of
2024-07-30 22:07:34 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-30 22:08:48 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1151,  0.0342, -0.5737,  ..., -0.0073, -0.1636,  0.2070],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.8906, -2.7344, -0.5903,  ...,  2.2949, -1.4678, -2.7812],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0461,  0.0099, -0.0083,  ..., -0.0042,  0.0004, -0.0020],
        [-0.0114,  0.0186,  0.0312,  ...,  0.0128,  0.0248, -0.0008],
        [ 0.0060, -0.0139,  0.0075,  ..., -0.0172, -0.0003, -0.0045],
        ...,
        [ 0.0147,  0.0244,  0.0138,  ...,  0.0429,  0.0032,  0.0178],
        [ 0.0064, -0.0074, -0.0201,  ...,  0.0130,  0.0119, -0.0042],
        [-0.0068,  0.0106,  0.0178,  ..., -0.0012, -0.0313,  0.0498]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.8047, -2.1328, -0.4482,  ...,  2.3574, -1.7832, -2.4922]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 22:08:49 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To entitle results in a entitlement
To reinforce results in a reinforcement
To assess results in a assessment
To embarrass results in a embarrassment
To encourage results in a encouragement
To equip results in a equipment
To appoint results in a appointment
To detach results in a
2024-07-30 22:08:49 root INFO     [order_1_approx] starting weight calculation for To entitle results in a entitlement
To appoint results in a appointment
To detach results in a detachment
To assess results in a assessment
To encourage results in a encouragement
To reinforce results in a reinforcement
To equip results in a equipment
To embarrass results in a
2024-07-30 22:08:49 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 22:10:11 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1597,  0.0209, -0.2388,  ..., -0.1523,  0.0312,  0.0745],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.3730, -3.1328, -2.3809,  ...,  2.9609, -0.7905, -1.7852],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 7.4387e-03, -4.9362e-03,  8.2626e-03,  ..., -2.0313e-03,
         -7.8888e-03,  1.1383e-02],
        [-1.2070e-02,  2.9556e-02,  1.9073e-06,  ..., -1.4496e-04,
          1.3824e-02, -1.0635e-02],
        [ 1.2749e-02,  3.0117e-03,  8.8120e-03,  ..., -4.1008e-03,
         -6.0577e-03,  3.8795e-03],
        ...,
        [ 8.3313e-03,  7.1678e-03, -1.6296e-02,  ...,  3.5877e-03,
         -1.4008e-02,  3.0060e-03],
        [ 8.9035e-03,  6.5327e-04,  1.1909e-02,  ...,  5.2452e-04,
          2.3315e-02,  8.1940e-03],
        [ 1.1314e-02,  1.4931e-02, -5.1041e-03,  ..., -5.6839e-03,
         -4.8828e-03,  1.0201e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.6377, -3.3008, -2.2461,  ...,  2.7578, -0.9141, -1.8262]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 22:10:12 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for continuing is the active form of continue
including is the active form of include
telling is the active form of tell
maintaining is the active form of maintain
happening is the active form of happen
ensuring is the active form of ensure
identifying is the active form of identify
avoiding is the active form of
2024-07-30 22:10:13 root INFO     [order_1_approx] starting weight calculation for including is the active form of include
happening is the active form of happen
avoiding is the active form of avoid
maintaining is the active form of maintain
telling is the active form of tell
ensuring is the active form of ensure
continuing is the active form of continue
identifying is the active form of
2024-07-30 22:10:13 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-30 22:11:22 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.3164,  0.4097, -0.6479,  ...,  0.0679, -0.3174,  0.4836],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.2773, -0.4150,  0.9331,  ...,  2.0215,  1.9873, -1.9219],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0614,  0.0141, -0.0017,  ...,  0.0101, -0.0044, -0.0044],
        [ 0.0128,  0.0575,  0.0106,  ...,  0.0113,  0.0287,  0.0053],
        [ 0.0071,  0.0026,  0.0113,  ..., -0.0056, -0.0061, -0.0087],
        ...,
        [ 0.0234,  0.0224, -0.0058,  ...,  0.0056,  0.0032, -0.0086],
        [ 0.0163,  0.0020, -0.0169,  ..., -0.0072,  0.0039, -0.0118],
        [ 0.0046,  0.0079,  0.0129,  ...,  0.0193, -0.0233,  0.0384]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.0410, -0.1184,  0.8589,  ...,  2.0742,  1.2637, -1.6201]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 22:11:23 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To entitle results in a entitlement
To appoint results in a appointment
To detach results in a detachment
To assess results in a assessment
To encourage results in a encouragement
To reinforce results in a reinforcement
To equip results in a equipment
To embarrass results in a
2024-07-30 22:11:23 root INFO     total operator prediction time: 1233.3518614768982 seconds
2024-07-30 22:11:23 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on noun+less_reg
2024-07-30 22:11:23 root INFO     building operator noun+less_reg
2024-07-30 22:11:23 root INFO     [order_1_approx] starting weight calculation for Something without mirth is mirthless
Something without arm is armless
Something without heir is heirless
Something without defence is defenceless
Something without speech is speechless
Something without sensor is sensorless
Something without leg is legless
Something without remorse is
2024-07-30 22:11:23 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 22:12:50 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2004,  0.0393, -0.1613,  ...,  0.2249, -0.0584, -0.1987],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.5605, -2.9727,  1.2754,  ...,  1.1855, -2.2480, -2.7734],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0584,  0.0092, -0.0031,  ...,  0.0013, -0.0032, -0.0096],
        [-0.0114,  0.0302, -0.0002,  ...,  0.0040,  0.0002,  0.0009],
        [ 0.0143, -0.0110,  0.0024,  ..., -0.0131, -0.0160, -0.0121],
        ...,
        [ 0.0196, -0.0076, -0.0104,  ...,  0.0028, -0.0122,  0.0091],
        [-0.0012,  0.0174, -0.0123,  ...,  0.0082,  0.0223,  0.0241],
        [-0.0027,  0.0313, -0.0084,  ..., -0.0044, -0.0048,  0.0096]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.4561, -3.0273,  1.2080,  ...,  1.3740, -2.4902, -2.9121]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 22:12:51 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for including is the active form of include
happening is the active form of happen
avoiding is the active form of avoid
maintaining is the active form of maintain
telling is the active form of tell
ensuring is the active form of ensure
continuing is the active form of continue
identifying is the active form of
2024-07-30 22:12:51 root INFO     [order_1_approx] starting weight calculation for identifying is the active form of identify
including is the active form of include
happening is the active form of happen
maintaining is the active form of maintain
continuing is the active form of continue
ensuring is the active form of ensure
avoiding is the active form of avoid
telling is the active form of
2024-07-30 22:12:51 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-30 22:13:55 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1450,  0.0116, -0.1093,  ...,  0.2908, -0.1920,  0.2783],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.3750, -3.5430,  0.1370,  ..., -3.2988, -2.2656, -2.9922],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 3.8452e-02,  5.7983e-03,  2.0618e-03,  ..., -1.6388e-02,
         -7.8888e-03,  1.3107e-02],
        [ 1.0262e-02,  1.4687e-02, -4.1428e-03,  ...,  1.6113e-02,
         -5.5847e-03, -3.7193e-03],
        [ 4.0054e-05,  1.1406e-03,  4.5898e-02,  ...,  2.1973e-03,
         -3.2387e-03, -4.8035e-02],
        ...,
        [ 2.4719e-02,  4.6570e-02, -2.9907e-03,  ...,  6.6910e-03,
         -4.8409e-03,  1.1795e-02],
        [-8.1062e-04,  3.0731e-02,  2.3224e-02,  ..., -2.2354e-02,
          3.0838e-02,  1.4183e-02],
        [ 2.0386e-02,  1.5045e-02,  4.4174e-03,  ..., -1.4313e-02,
         -4.4189e-02,  3.8055e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.2578, -3.5176, -0.1243,  ..., -3.4707, -2.1543, -3.5332]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 22:13:56 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Something without mirth is mirthless
Something without arm is armless
Something without heir is heirless
Something without defence is defenceless
Something without speech is speechless
Something without sensor is sensorless
Something without leg is legless
Something without remorse is
2024-07-30 22:13:56 root INFO     [order_1_approx] starting weight calculation for Something without remorse is remorseless
Something without speech is speechless
Something without heir is heirless
Something without sensor is sensorless
Something without defence is defenceless
Something without mirth is mirthless
Something without leg is legless
Something without arm is
2024-07-30 22:13:56 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 22:15:28 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0139, -0.0648,  0.0430,  ...,  0.1084, -0.0005, -0.1285],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.3105, -2.1270,  1.0820,  ...,  3.5508, -4.3047, -2.1758],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0436, -0.0121, -0.0008,  ...,  0.0031, -0.0104,  0.0103],
        [ 0.0052,  0.0232, -0.0132,  ...,  0.0038, -0.0055,  0.0084],
        [-0.0055, -0.0144,  0.0154,  ...,  0.0080,  0.0061, -0.0008],
        ...,
        [ 0.0023,  0.0219, -0.0228,  ...,  0.0082, -0.0085,  0.0027],
        [-0.0186, -0.0016,  0.0112,  ...,  0.0156,  0.0220,  0.0129],
        [ 0.0092,  0.0081, -0.0017,  ...,  0.0078,  0.0020,  0.0283]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.3047, -2.2129,  0.7739,  ...,  3.5098, -3.7246, -2.4746]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 22:15:29 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for identifying is the active form of identify
including is the active form of include
happening is the active form of happen
maintaining is the active form of maintain
continuing is the active form of continue
ensuring is the active form of ensure
avoiding is the active form of avoid
telling is the active form of
2024-07-30 22:15:29 root INFO     [order_1_approx] starting weight calculation for maintaining is the active form of maintain
continuing is the active form of continue
telling is the active form of tell
happening is the active form of happen
identifying is the active form of identify
ensuring is the active form of ensure
avoiding is the active form of avoid
including is the active form of
2024-07-30 22:15:29 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-30 22:16:28 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0817, -0.0957,  0.3127,  ..., -0.2903, -0.1583,  0.0481],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.2305, -4.2578, -1.8203,  ..., -0.6416, -1.3955, -2.3203],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0276,  0.0063,  0.0150,  ...,  0.0040, -0.0043,  0.0025],
        [ 0.0107,  0.0177,  0.0021,  ..., -0.0093,  0.0159, -0.0117],
        [-0.0218, -0.0198,  0.0215,  ..., -0.0286, -0.0101, -0.0249],
        ...,
        [-0.0177,  0.0067,  0.0128,  ...,  0.0364,  0.0088, -0.0089],
        [ 0.0087,  0.0202, -0.0094,  ..., -0.0070,  0.0446, -0.0175],
        [ 0.0070, -0.0057,  0.0135,  ...,  0.0079, -0.0052,  0.0053]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.3813, -4.3359, -1.8018,  ..., -0.6978, -1.2344, -2.4863]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 22:16:29 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Something without remorse is remorseless
Something without speech is speechless
Something without heir is heirless
Something without sensor is sensorless
Something without defence is defenceless
Something without mirth is mirthless
Something without leg is legless
Something without arm is
2024-07-30 22:16:29 root INFO     [order_1_approx] starting weight calculation for Something without heir is heirless
Something without sensor is sensorless
Something without mirth is mirthless
Something without defence is defenceless
Something without leg is legless
Something without arm is armless
Something without remorse is remorseless
Something without speech is
2024-07-30 22:16:29 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 22:18:08 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1131, -0.0393,  0.0494,  ...,  0.0215,  0.1750, -0.1974],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.1211, -1.4287,  0.7178,  ...,  0.5693, -1.6191, -3.2539],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0550, -0.0049, -0.0160,  ..., -0.0148, -0.0041, -0.0155],
        [ 0.0031,  0.0416,  0.0044,  ...,  0.0082, -0.0122,  0.0023],
        [-0.0085,  0.0048,  0.0260,  ...,  0.0034, -0.0123, -0.0062],
        ...,
        [-0.0019,  0.0132, -0.0162,  ...,  0.0599, -0.0133,  0.0076],
        [-0.0134,  0.0132, -0.0130,  ..., -0.0020,  0.0527, -0.0010],
        [ 0.0064,  0.0058, -0.0187,  ..., -0.0061,  0.0169,  0.0346]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.1636, -1.4531,  0.7803,  ...,  0.5688, -1.3379, -3.1543]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 22:18:09 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for maintaining is the active form of maintain
continuing is the active form of continue
telling is the active form of tell
happening is the active form of happen
identifying is the active form of identify
ensuring is the active form of ensure
avoiding is the active form of avoid
including is the active form of
2024-07-30 22:18:09 root INFO     total operator prediction time: 1282.6966230869293 seconds
2024-07-30 22:18:09 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on noun - plural_irreg
2024-07-30 22:18:09 root INFO     building operator noun - plural_irreg
2024-07-30 22:18:09 root INFO     [order_1_approx] starting weight calculation for The plural form of security is securities
The plural form of child is children
The plural form of family is families
The plural form of memory is memories
The plural form of century is centuries
The plural form of facility is facilities
The plural form of basis is bases
The plural form of opportunity is
2024-07-30 22:18:09 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-30 22:18:59 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0298, -0.2408,  0.0881,  ...,  0.0750,  0.2218,  0.2703],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.3457, -3.3477,  0.5298,  ...,  0.5000, -0.8770, -0.4004],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0468, -0.0112,  0.0002,  ..., -0.0013,  0.0075,  0.0075],
        [ 0.0229,  0.0310,  0.0219,  ..., -0.0017, -0.0186, -0.0055],
        [ 0.0041, -0.0333,  0.0318,  ...,  0.0005, -0.0109, -0.0110],
        ...,
        [-0.0119,  0.0292,  0.0061,  ...,  0.0154,  0.0002, -0.0040],
        [-0.0120,  0.0162, -0.0005,  ..., -0.0149,  0.0193, -0.0214],
        [-0.0131,  0.0154,  0.0079,  ..., -0.0114, -0.0011,  0.0048]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.5981, -3.7324,  0.4243,  ..., -0.0576, -1.0293, -1.0098]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 22:19:00 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Something without heir is heirless
Something without sensor is sensorless
Something without mirth is mirthless
Something without defence is defenceless
Something without leg is legless
Something without arm is armless
Something without remorse is remorseless
Something without speech is
2024-07-30 22:19:00 root INFO     [order_1_approx] starting weight calculation for Something without remorse is remorseless
Something without arm is armless
Something without leg is legless
Something without sensor is sensorless
Something without mirth is mirthless
Something without speech is speechless
Something without defence is defenceless
Something without heir is
2024-07-30 22:19:00 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 22:20:47 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0165,  0.1494, -0.0432,  ...,  0.2275, -0.1836,  0.0026],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.2822, -0.1558, -0.5635,  ..., -0.0625, -1.4307, -0.3301],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0323, -0.0198,  0.0165,  ..., -0.0094,  0.0202,  0.0131],
        [ 0.0017,  0.0292,  0.0064,  ..., -0.0081, -0.0257,  0.0090],
        [ 0.0056,  0.0125,  0.0125,  ...,  0.0163,  0.0006,  0.0378],
        ...,
        [-0.0097,  0.0346, -0.0088,  ...,  0.0452,  0.0040, -0.0029],
        [-0.0101, -0.0120,  0.0226,  ..., -0.0099,  0.0193, -0.0414],
        [-0.0107, -0.0163, -0.0031,  ...,  0.0179, -0.0027,  0.0217]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.4932, -0.1793, -0.5796,  ..., -0.6279, -2.3984, -0.4297]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 22:20:48 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of security is securities
The plural form of child is children
The plural form of family is families
The plural form of memory is memories
The plural form of century is centuries
The plural form of facility is facilities
The plural form of basis is bases
The plural form of opportunity is
2024-07-30 22:20:48 root INFO     [order_1_approx] starting weight calculation for The plural form of security is securities
The plural form of child is children
The plural form of basis is bases
The plural form of opportunity is opportunities
The plural form of memory is memories
The plural form of century is centuries
The plural form of facility is facilities
The plural form of family is
2024-07-30 22:20:48 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-30 22:21:32 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0602, -0.0215, -0.2197,  ..., -0.2627, -0.2101, -0.1650],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.8394, -2.0742,  0.1858,  ..., -3.1875, -4.7461, -3.3203],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0402, -0.0006,  0.0018,  ...,  0.0074, -0.0131,  0.0046],
        [-0.0105,  0.0146, -0.0105,  ..., -0.0190,  0.0029, -0.0127],
        [-0.0109, -0.0011,  0.0232,  ...,  0.0128, -0.0157, -0.0020],
        ...,
        [ 0.0264,  0.0192, -0.0016,  ..., -0.0356,  0.0030, -0.0013],
        [-0.0420, -0.0090,  0.0036,  ..., -0.0019,  0.0283, -0.0205],
        [ 0.0069, -0.0031,  0.0040,  ..., -0.0117, -0.0147,  0.0051]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.2998, -2.5352,  0.2698,  ..., -3.2305, -4.9922, -3.4551]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 22:21:33 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Something without remorse is remorseless
Something without arm is armless
Something without leg is legless
Something without sensor is sensorless
Something without mirth is mirthless
Something without speech is speechless
Something without defence is defenceless
Something without heir is
2024-07-30 22:21:33 root INFO     [order_1_approx] starting weight calculation for Something without speech is speechless
Something without heir is heirless
Something without remorse is remorseless
Something without arm is armless
Something without mirth is mirthless
Something without sensor is sensorless
Something without defence is defenceless
Something without leg is
2024-07-30 22:21:33 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 22:23:28 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0255, -0.1185, -0.0739,  ..., -0.1293, -0.1886,  0.0155],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.5547, -1.1738,  3.0996,  ..., -1.2842, -1.9795, -3.8359],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0537,  0.0112, -0.0204,  ..., -0.0233, -0.0096, -0.0046],
        [ 0.0016,  0.0454,  0.0296,  ..., -0.0178, -0.0284, -0.0206],
        [-0.0223, -0.0018,  0.0312,  ...,  0.0067,  0.0065,  0.0089],
        ...,
        [ 0.0052,  0.0388, -0.0046,  ...,  0.0005, -0.0021, -0.0125],
        [ 0.0049,  0.0050, -0.0345,  ...,  0.0499,  0.0371,  0.0002],
        [ 0.0401,  0.0139,  0.0171,  ..., -0.0401, -0.0395,  0.0111]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.9736, -1.2188,  2.6914,  ..., -1.0479, -1.5889, -4.1641]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 22:23:28 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of security is securities
The plural form of child is children
The plural form of basis is bases
The plural form of opportunity is opportunities
The plural form of memory is memories
The plural form of century is centuries
The plural form of facility is facilities
The plural form of family is
2024-07-30 22:23:29 root INFO     [order_1_approx] starting weight calculation for The plural form of memory is memories
The plural form of family is families
The plural form of security is securities
The plural form of basis is bases
The plural form of century is centuries
The plural form of opportunity is opportunities
The plural form of child is children
The plural form of facility is
2024-07-30 22:23:29 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-30 22:24:02 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2922, -0.0714, -0.1733,  ...,  0.0213, -0.1628, -0.2355],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.0586, -5.9531,  0.1357,  ..., -0.3652, -0.9980, -2.4277],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0501,  0.0065,  0.0149,  ..., -0.0015, -0.0324,  0.0384],
        [-0.0005,  0.0019, -0.0096,  ...,  0.0035, -0.0083, -0.0118],
        [-0.0060,  0.0123,  0.0180,  ..., -0.0068, -0.0363, -0.0026],
        ...,
        [ 0.0197,  0.0169,  0.0123,  ...,  0.0185,  0.0337,  0.0033],
        [ 0.0021,  0.0239, -0.0252,  ..., -0.0081,  0.0131, -0.0389],
        [ 0.0022,  0.0104,  0.0087,  ..., -0.0255, -0.0004, -0.0139]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.1937, -5.8789, -0.1484,  ..., -0.5039, -1.3408, -2.5117]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 22:24:03 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Something without speech is speechless
Something without heir is heirless
Something without remorse is remorseless
Something without arm is armless
Something without mirth is mirthless
Something without sensor is sensorless
Something without defence is defenceless
Something without leg is
2024-07-30 22:24:03 root INFO     [order_1_approx] starting weight calculation for Something without sensor is sensorless
Something without leg is legless
Something without mirth is mirthless
Something without remorse is remorseless
Something without speech is speechless
Something without heir is heirless
Something without arm is armless
Something without defence is
2024-07-30 22:24:03 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 22:26:07 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0693,  0.0505, -0.2332,  ..., -0.2410, -0.2047,  0.1476],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.8535, -2.7305,  3.9004,  ..., -0.0699, -1.1758, -2.1973],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0564, -0.0272, -0.0070,  ..., -0.0088,  0.0150,  0.0160],
        [-0.0078,  0.0374,  0.0034,  ...,  0.0383, -0.0130, -0.0102],
        [-0.0214, -0.0014,  0.0453,  ..., -0.0137, -0.0144, -0.0017],
        ...,
        [-0.0350,  0.0091, -0.0348,  ...,  0.0624,  0.0112, -0.0148],
        [-0.0188,  0.0049, -0.0089,  ...,  0.0333,  0.0513, -0.0394],
        [ 0.0087, -0.0087, -0.0005,  ...,  0.0212,  0.0247,  0.0481]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.6914, -3.0762,  3.9043,  ..., -0.4829, -1.2861, -1.8623]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 22:26:08 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of memory is memories
The plural form of family is families
The plural form of security is securities
The plural form of basis is bases
The plural form of century is centuries
The plural form of opportunity is opportunities
The plural form of child is children
The plural form of facility is
2024-07-30 22:26:08 root INFO     [order_1_approx] starting weight calculation for The plural form of security is securities
The plural form of opportunity is opportunities
The plural form of family is families
The plural form of facility is facilities
The plural form of basis is bases
The plural form of century is centuries
The plural form of memory is memories
The plural form of child is
2024-07-30 22:26:08 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-30 22:26:32 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0027,  0.0329, -0.1101,  ..., -0.1096, -0.1265, -0.1399],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.9238, -5.1953,  0.8179,  ..., -2.3789, -2.3652, -2.1914],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0324,  0.0136, -0.0009,  ...,  0.0326, -0.0151,  0.0174],
        [-0.0136,  0.0033,  0.0128,  ..., -0.0199, -0.0063,  0.0089],
        [ 0.0097, -0.0290,  0.0463,  ...,  0.0233, -0.0360, -0.0333],
        ...,
        [ 0.0056,  0.0437, -0.0274,  ..., -0.0109,  0.0412, -0.0053],
        [-0.0199, -0.0057, -0.0138,  ..., -0.0055,  0.0121, -0.0319],
        [ 0.0193, -0.0060, -0.0008,  ..., -0.0186,  0.0028,  0.0093]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.7979, -4.9492,  1.0205,  ..., -2.2598, -2.3633, -2.4609]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 22:26:32 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Something without sensor is sensorless
Something without leg is legless
Something without mirth is mirthless
Something without remorse is remorseless
Something without speech is speechless
Something without heir is heirless
Something without arm is armless
Something without defence is
2024-07-30 22:26:33 root INFO     [order_1_approx] starting weight calculation for Something without defence is defenceless
Something without sensor is sensorless
Something without heir is heirless
Something without leg is legless
Something without speech is speechless
Something without remorse is remorseless
Something without arm is armless
Something without mirth is
2024-07-30 22:26:33 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 22:28:47 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0414, -0.1105, -0.0405,  ..., -0.1028, -0.6294,  0.1272],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.8281, -2.4980,  1.5703,  ..., -1.5117, -0.7012, -2.2871],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0152,  0.0212,  0.0047,  ..., -0.0041,  0.0064, -0.0077],
        [-0.0080,  0.0244,  0.0213,  ..., -0.0185, -0.0309, -0.0035],
        [ 0.0013, -0.0209,  0.0352,  ...,  0.0013, -0.0337,  0.0235],
        ...,
        [-0.0273,  0.0175, -0.0099,  ...,  0.0184, -0.0125,  0.0016],
        [-0.0310,  0.0178, -0.0413,  ...,  0.0415,  0.0378, -0.0155],
        [ 0.0084, -0.0274,  0.0130,  ..., -0.0006, -0.0499,  0.0354]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.1191, -2.2969,  1.7305,  ..., -1.5244, -0.9102, -2.2559]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 22:28:48 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of security is securities
The plural form of opportunity is opportunities
The plural form of family is families
The plural form of facility is facilities
The plural form of basis is bases
The plural form of century is centuries
The plural form of memory is memories
The plural form of child is
2024-07-30 22:28:49 root INFO     [order_1_approx] starting weight calculation for The plural form of security is securities
The plural form of basis is bases
The plural form of facility is facilities
The plural form of child is children
The plural form of century is centuries
The plural form of opportunity is opportunities
The plural form of family is families
The plural form of memory is
2024-07-30 22:28:49 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-30 22:29:03 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2212,  0.1139,  0.2817,  ...,  0.1755, -0.3574,  0.2325],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.5986, -2.0977, -0.1851,  ..., -1.3477, -3.9492, -2.5254],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0424,  0.0298, -0.0020,  ...,  0.0076,  0.0325,  0.0251],
        [ 0.0056, -0.0124, -0.0068,  ..., -0.0195, -0.0255,  0.0124],
        [ 0.0103, -0.0423,  0.0603,  ...,  0.0117, -0.0189, -0.0074],
        ...,
        [ 0.0128,  0.0338,  0.0092,  ..., -0.0049,  0.0036,  0.0068],
        [ 0.0206, -0.0185, -0.0092,  ..., -0.0280,  0.0140, -0.0208],
        [ 0.0015, -0.0066, -0.0176,  ...,  0.0154, -0.0164,  0.0174]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.5381, -2.3848, -0.2939,  ..., -1.1338, -3.4863, -2.7891]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 22:29:05 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Something without defence is defenceless
Something without sensor is sensorless
Something without heir is heirless
Something without leg is legless
Something without speech is speechless
Something without remorse is remorseless
Something without arm is armless
Something without mirth is
2024-07-30 22:29:05 root INFO     [order_1_approx] starting weight calculation for Something without arm is armless
Something without leg is legless
Something without heir is heirless
Something without remorse is remorseless
Something without speech is speechless
Something without defence is defenceless
Something without mirth is mirthless
Something without sensor is
2024-07-30 22:29:05 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 22:31:30 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2671, -0.1233,  0.0419,  ..., -0.1239,  0.0091,  0.1047],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.6411, -0.7676,  0.2559,  ..., -1.3711, -4.7969, -4.2383],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0529, -0.0008, -0.0167,  ...,  0.0013,  0.0049,  0.0218],
        [ 0.0341,  0.0504, -0.0065,  ..., -0.0002, -0.0270, -0.0333],
        [-0.0270, -0.0408,  0.0504,  ..., -0.0172, -0.0112,  0.0201],
        ...,
        [-0.0060,  0.0107, -0.0178,  ...,  0.0599,  0.0042, -0.0028],
        [-0.0024, -0.0065, -0.0259,  ..., -0.0068,  0.0308,  0.0239],
        [ 0.0159, -0.0173,  0.0076,  ...,  0.0029, -0.0025,  0.0180]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.0303, -0.9028,  0.2876,  ..., -1.1982, -4.9492, -3.7617]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 22:31:31 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of security is securities
The plural form of basis is bases
The plural form of facility is facilities
The plural form of child is children
The plural form of century is centuries
The plural form of opportunity is opportunities
The plural form of family is families
The plural form of memory is
2024-07-30 22:31:31 root INFO     [order_1_approx] starting weight calculation for The plural form of memory is memories
The plural form of child is children
The plural form of basis is bases
The plural form of century is centuries
The plural form of family is families
The plural form of facility is facilities
The plural form of opportunity is opportunities
The plural form of security is
2024-07-30 22:31:31 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-30 22:31:37 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1149, -0.2656, -0.4951,  ..., -0.1643, -0.1486, -0.2910],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.1055, -2.7891, -0.0391,  ..., -4.5078, -4.1875, -1.9307],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0912,  0.0126,  0.0117,  ..., -0.0009, -0.0082,  0.0173],
        [ 0.0098,  0.0366,  0.0159,  ..., -0.0106, -0.0155, -0.0109],
        [ 0.0060, -0.0179,  0.0320,  ..., -0.0096, -0.0368,  0.0082],
        ...,
        [ 0.0484,  0.0145,  0.0098,  ...,  0.0624, -0.0068,  0.0066],
        [ 0.0167, -0.0102, -0.0225,  ...,  0.0022,  0.0090, -0.0150],
        [ 0.0102,  0.0170, -0.0061,  ...,  0.0247, -0.0230, -0.0128]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.3965, -2.9141, -0.2240,  ..., -3.9922, -4.0703, -2.2656]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 22:31:38 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Something without arm is armless
Something without leg is legless
Something without heir is heirless
Something without remorse is remorseless
Something without speech is speechless
Something without defence is defenceless
Something without mirth is mirthless
Something without sensor is
2024-07-30 22:31:38 root INFO     total operator prediction time: 1214.6128261089325 seconds
2024-07-30 22:31:38 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on adj+ness_reg
2024-07-30 22:31:38 root INFO     building operator adj+ness_reg
2024-07-30 22:31:38 root INFO     [order_1_approx] starting weight calculation for The state of being sacred is sacredness
The state of being mad is madness
The state of being same is sameness
The state of being related is relatedness
The state of being righteous is righteousness
The state of being helpful is helpfulness
The state of being reasonable is reasonableness
The state of being fixed is
2024-07-30 22:31:38 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 22:34:07 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0730, -0.0251, -0.2783,  ...,  0.0433, -0.1067, -0.0202],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.2666, -1.5713,  1.4727,  ...,  0.0369, -2.4883, -5.2656],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0564, -0.0204,  0.0063,  ..., -0.0016,  0.0070,  0.0016],
        [-0.0333,  0.0251,  0.0260,  ..., -0.0055,  0.0035,  0.0148],
        [ 0.0112,  0.0446,  0.0352,  ...,  0.0089, -0.0062,  0.0000],
        ...,
        [ 0.0067,  0.0234, -0.0116,  ...,  0.0134,  0.0046, -0.0035],
        [-0.0051,  0.0088, -0.0154,  ...,  0.0040,  0.0275,  0.0057],
        [ 0.0189, -0.0145,  0.0112,  ...,  0.0199,  0.0036,  0.0260]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.4399, -2.4629,  1.8896,  ...,  0.2888, -2.9688, -4.6914]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 22:34:08 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of memory is memories
The plural form of child is children
The plural form of basis is bases
The plural form of century is centuries
The plural form of family is families
The plural form of facility is facilities
The plural form of opportunity is opportunities
The plural form of security is
2024-07-30 22:34:09 root INFO     [order_1_approx] starting weight calculation for The plural form of child is children
The plural form of opportunity is opportunities
The plural form of memory is memories
The plural form of facility is facilities
The plural form of security is securities
The plural form of century is centuries
The plural form of family is families
The plural form of basis is
2024-07-30 22:34:09 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-30 22:34:09 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1871, -0.3047, -0.4048,  ...,  0.0737, -0.1012,  0.3716],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.3086, -4.4805,  0.5913,  ..., -0.1714, -4.8516, -2.7012],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 3.0655e-02, -2.3689e-03, -1.4214e-02,  ...,  8.9493e-03,
         -7.1487e-03,  2.9190e-02],
        [ 2.9449e-03,  3.9307e-02, -5.2948e-03,  ...,  1.7197e-02,
          5.2605e-03,  3.8776e-03],
        [-3.0487e-02,  3.8147e-05,  3.0289e-02,  ...,  5.0068e-04,
         -8.6594e-03,  3.3234e-02],
        ...,
        [ 1.5579e-02,  6.9313e-03,  2.0962e-03,  ...,  8.3618e-03,
          3.6812e-03, -2.3468e-02],
        [-2.2568e-02,  1.4946e-02,  1.4801e-03,  ..., -3.0060e-02,
          4.5288e-02, -2.9327e-02],
        [ 9.4604e-03,  1.6113e-02,  3.5877e-03,  ...,  1.8250e-02,
         -2.4063e-02,  5.4626e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.2891, -4.1211,  0.5601,  ...,  0.3242, -4.9648, -2.5566]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 22:34:10 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The state of being sacred is sacredness
The state of being mad is madness
The state of being same is sameness
The state of being related is relatedness
The state of being righteous is righteousness
The state of being helpful is helpfulness
The state of being reasonable is reasonableness
The state of being fixed is
2024-07-30 22:34:10 root INFO     [order_1_approx] starting weight calculation for The state of being righteous is righteousness
The state of being sacred is sacredness
The state of being helpful is helpfulness
The state of being mad is madness
The state of being reasonable is reasonableness
The state of being related is relatedness
The state of being fixed is fixedness
The state of being same is
2024-07-30 22:34:10 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 22:36:42 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0447, -0.1193, -0.4089,  ...,  0.2607, -0.2825,  0.2815],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.0898, -2.6836, -2.2969,  ..., -3.3281, -5.6094, -0.5430],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0255,  0.0229,  0.0003,  ...,  0.0191,  0.0234,  0.0106],
        [-0.0073,  0.0345,  0.0036,  ...,  0.0068, -0.0005, -0.0061],
        [ 0.0040, -0.0033,  0.0020,  ..., -0.0092, -0.0081,  0.0155],
        ...,
        [ 0.0099,  0.0071,  0.0127,  ..., -0.0007, -0.0133,  0.0104],
        [-0.0162,  0.0026, -0.0075,  ..., -0.0306,  0.0140,  0.0040],
        [-0.0008,  0.0191, -0.0011,  ...,  0.0022, -0.0119,  0.0400]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.9316, -2.6309, -2.2051,  ..., -3.1797, -5.8633, -0.8535]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 22:36:43 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The state of being righteous is righteousness
The state of being sacred is sacredness
The state of being helpful is helpfulness
The state of being mad is madness
The state of being reasonable is reasonableness
The state of being related is relatedness
The state of being fixed is fixedness
The state of being same is
2024-07-30 22:36:43 root INFO     [order_1_approx] starting weight calculation for The state of being helpful is helpfulness
The state of being righteous is righteousness
The state of being fixed is fixedness
The state of being same is sameness
The state of being sacred is sacredness
The state of being related is relatedness
The state of being mad is madness
The state of being reasonable is
2024-07-30 22:36:43 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 22:36:49 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2157, -0.3828, -0.4285,  ...,  0.1147, -0.5513,  0.1106],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.6680, -1.8643,  1.6719,  ..., -2.1348, -2.3438, -2.1621],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0536, -0.0095,  0.0110,  ...,  0.0039, -0.0049, -0.0188],
        [ 0.0267,  0.0602,  0.0118,  ...,  0.0521, -0.0152, -0.0022],
        [ 0.0114, -0.0081,  0.0432,  ...,  0.0076,  0.0112,  0.0264],
        ...,
        [ 0.0060,  0.0058, -0.0083,  ...,  0.0158,  0.0034,  0.0334],
        [-0.0314,  0.0359, -0.0179,  ..., -0.0548,  0.0522, -0.0191],
        [ 0.0176, -0.0213, -0.0273,  ...,  0.0278, -0.0323,  0.0458]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.3203, -1.6621,  1.8320,  ..., -2.0059, -2.4355, -1.3926]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 22:36:50 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of child is children
The plural form of opportunity is opportunities
The plural form of memory is memories
The plural form of facility is facilities
The plural form of security is securities
The plural form of century is centuries
The plural form of family is families
The plural form of basis is
2024-07-30 22:36:50 root INFO     [order_1_approx] starting weight calculation for The plural form of memory is memories
The plural form of family is families
The plural form of facility is facilities
The plural form of child is children
The plural form of security is securities
The plural form of opportunity is opportunities
The plural form of basis is bases
The plural form of century is
2024-07-30 22:36:50 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-30 22:39:17 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0467,  0.0615, -0.1486,  ..., -0.3501, -0.2314, -0.1151],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.9902, -1.5840, -1.3555,  ..., -2.9102, -5.3281, -2.8242],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 3.3447e-02, -9.9487e-03, -6.5117e-03,  ...,  7.3624e-03,
         -1.2802e-02,  1.6525e-02],
        [-1.4526e-02,  4.5258e-02,  1.8631e-02,  ...,  1.2749e-02,
          8.8654e-03, -1.1082e-03],
        [ 1.3130e-02, -2.9083e-02,  3.8361e-02,  ...,  1.3084e-03,
         -1.6571e-02,  9.1553e-05],
        ...,
        [ 2.2568e-02,  9.1400e-03,  1.0658e-02,  ...,  3.3051e-02,
          3.6430e-03,  9.1324e-03],
        [ 1.6113e-02, -3.2711e-03,  2.2949e-02,  ...,  6.8207e-03,
          1.1688e-02, -1.7075e-02],
        [-2.3232e-03,  1.4282e-02,  2.0828e-03,  ...,  9.9487e-03,
         -2.7115e-02,  2.8381e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.7490, -1.2988, -1.2100,  ..., -2.4004, -5.6250, -2.3281]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 22:39:19 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The state of being helpful is helpfulness
The state of being righteous is righteousness
The state of being fixed is fixedness
The state of being same is sameness
The state of being sacred is sacredness
The state of being related is relatedness
The state of being mad is madness
The state of being reasonable is
2024-07-30 22:39:19 root INFO     [order_1_approx] starting weight calculation for The state of being reasonable is reasonableness
The state of being same is sameness
The state of being sacred is sacredness
The state of being related is relatedness
The state of being helpful is helpfulness
The state of being mad is madness
The state of being fixed is fixedness
The state of being righteous is
2024-07-30 22:39:19 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 22:39:29 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0004, -0.0981,  0.0068,  ..., -0.1753, -0.3630,  0.3157],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.4468, -1.8633,  2.2520,  ..., -3.7617, -0.8931, -1.2832],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0163, -0.0364, -0.0013,  ...,  0.0261, -0.0043, -0.0074],
        [ 0.0107,  0.0362,  0.0150,  ...,  0.0044,  0.0014, -0.0381],
        [-0.0166, -0.0127,  0.0439,  ...,  0.0200, -0.0374,  0.0534],
        ...,
        [ 0.0011,  0.0454, -0.0061,  ...,  0.0047,  0.0134, -0.0062],
        [ 0.0012,  0.0441, -0.0084,  ..., -0.0003,  0.0231, -0.0117],
        [-0.0096, -0.0151, -0.0105,  ...,  0.0083, -0.0090,  0.0346]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.5732, -1.7822,  2.1211,  ..., -3.9219, -0.9014, -1.0166]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 22:39:30 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of memory is memories
The plural form of family is families
The plural form of facility is facilities
The plural form of child is children
The plural form of security is securities
The plural form of opportunity is opportunities
The plural form of basis is bases
The plural form of century is
2024-07-30 22:39:30 root INFO     total operator prediction time: 1281.5653731822968 seconds
2024-07-30 22:39:30 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on meronyms - member
2024-07-30 22:39:30 root INFO     building operator meronyms - member
2024-07-30 22:39:30 root INFO     [order_1_approx] starting weight calculation for A acrobat is a member of a troupe
A singer is a member of a choir
A cow is a member of a herd
A nomad is a member of a horde
A secretary is a member of a staff
A book is a member of a library
A calf is a member of a cattle
A spouse is a member of a
2024-07-30 22:39:31 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-30 22:41:50 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2852, -0.1165, -0.2217,  ..., -0.0290, -0.4172,  0.0359],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.2080, -2.3750,  0.2891,  ..., -4.4375, -3.4766, -1.0312],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0455, -0.0103,  0.0071,  ...,  0.0027,  0.0008,  0.0126],
        [ 0.0050,  0.0267,  0.0142,  ...,  0.0193,  0.0121, -0.0090],
        [-0.0021,  0.0022,  0.0388,  ..., -0.0090, -0.0200,  0.0019],
        ...,
        [ 0.0271,  0.0056,  0.0091,  ...,  0.0301, -0.0016, -0.0006],
        [ 0.0092,  0.0232,  0.0116,  ..., -0.0158,  0.0242, -0.0112],
        [-0.0046,  0.0119,  0.0017,  ..., -0.0040, -0.0207,  0.0277]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.1086, -2.1055, -0.0093,  ..., -4.3125, -3.7773, -1.1270]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 22:41:50 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The state of being reasonable is reasonableness
The state of being same is sameness
The state of being sacred is sacredness
The state of being related is relatedness
The state of being helpful is helpfulness
The state of being mad is madness
The state of being fixed is fixedness
The state of being righteous is
2024-07-30 22:41:51 root INFO     [order_1_approx] starting weight calculation for The state of being mad is madness
The state of being same is sameness
The state of being sacred is sacredness
The state of being reasonable is reasonableness
The state of being righteous is righteousness
The state of being fixed is fixedness
The state of being related is relatedness
The state of being helpful is
2024-07-30 22:41:51 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 22:42:09 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.4348,  0.3096, -0.0477,  ...,  0.4221, -0.2284, -0.1748],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.6621, -3.6699,  2.7227,  ..., -1.9336, -1.8105,  1.8867],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0521, -0.0439,  0.0258,  ...,  0.0138, -0.0024,  0.0134],
        [ 0.0007,  0.0025,  0.0016,  ...,  0.0104, -0.0073,  0.0135],
        [-0.0015,  0.0189,  0.0308,  ...,  0.0157,  0.0037, -0.0305],
        ...,
        [ 0.0154, -0.0237,  0.0172,  ...,  0.0303,  0.0176, -0.0116],
        [ 0.0066,  0.0266, -0.0210,  ...,  0.0124, -0.0019, -0.0227],
        [ 0.0204, -0.0022, -0.0145,  ..., -0.0224,  0.0042,  0.0438]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.0234, -3.4043,  2.5723,  ..., -1.8047, -1.8184,  2.0957]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 22:42:10 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A acrobat is a member of a troupe
A singer is a member of a choir
A cow is a member of a herd
A nomad is a member of a horde
A secretary is a member of a staff
A book is a member of a library
A calf is a member of a cattle
A spouse is a member of a
2024-07-30 22:42:11 root INFO     [order_1_approx] starting weight calculation for A nomad is a member of a horde
A cow is a member of a herd
A singer is a member of a choir
A calf is a member of a cattle
A book is a member of a library
A secretary is a member of a staff
A spouse is a member of a couple
A acrobat is a member of a
2024-07-30 22:42:11 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-30 22:44:21 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0303, -0.1649,  0.0846,  ...,  0.4126, -0.3821,  0.2632],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.7129, -1.7441, -1.7354,  ...,  1.3457, -5.3359, -2.6484],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 2.0416e-02,  1.8555e-02, -5.0507e-03,  ...,  2.5269e-02,
         -4.5776e-05,  1.0429e-02],
        [-4.3411e-03,  1.7376e-03,  1.6785e-03,  ...,  1.7944e-02,
         -2.2507e-04,  2.1935e-03],
        [-1.2245e-02, -3.1616e-02,  1.9974e-02,  ..., -8.6517e-03,
         -1.7410e-02, -1.6891e-02],
        ...,
        [ 3.0937e-03,  3.6755e-03,  3.8757e-03,  ..., -5.1727e-03,
          6.7444e-03,  2.8076e-03],
        [-1.0590e-02,  1.6422e-03,  1.6830e-02,  ..., -7.4654e-03,
          9.2850e-03, -2.2385e-02],
        [ 1.2970e-03, -3.7785e-03, -8.0719e-03,  ..., -4.6158e-03,
         -1.4900e-02,  1.7517e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.9043, -1.3770, -1.7598,  ...,  1.5957, -5.4180, -2.5059]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 22:44:22 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The state of being mad is madness
The state of being same is sameness
The state of being sacred is sacredness
The state of being reasonable is reasonableness
The state of being righteous is righteousness
The state of being fixed is fixedness
The state of being related is relatedness
The state of being helpful is
2024-07-30 22:44:22 root INFO     [order_1_approx] starting weight calculation for The state of being same is sameness
The state of being sacred is sacredness
The state of being related is relatedness
The state of being fixed is fixedness
The state of being righteous is righteousness
The state of being reasonable is reasonableness
The state of being helpful is helpfulness
The state of being mad is
2024-07-30 22:44:22 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 22:44:47 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1219, -0.1985,  0.0437,  ...,  0.0745, -0.3569,  0.1105],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.9062, -5.9180,  4.3047,  ...,  0.9292, -0.6523, -0.9316],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0167, -0.0143,  0.0265,  ..., -0.0008, -0.0107,  0.0165],
        [-0.0137,  0.0084, -0.0130,  ..., -0.0050, -0.0199,  0.0115],
        [-0.0182,  0.0101,  0.0331,  ..., -0.0079,  0.0099, -0.0071],
        ...,
        [ 0.0174,  0.0233, -0.0069,  ...,  0.0650, -0.0199, -0.0076],
        [ 0.0093,  0.0341, -0.0170,  ...,  0.0035,  0.0508, -0.0031],
        [ 0.0121, -0.0352,  0.0096,  ...,  0.0020, -0.0243,  0.0426]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.8965, -5.7188,  3.6348,  ...,  0.7676, -0.9551, -0.5605]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 22:44:48 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A nomad is a member of a horde
A cow is a member of a herd
A singer is a member of a choir
A calf is a member of a cattle
A book is a member of a library
A secretary is a member of a staff
A spouse is a member of a couple
A acrobat is a member of a
2024-07-30 22:44:48 root INFO     [order_1_approx] starting weight calculation for A singer is a member of a choir
A spouse is a member of a couple
A acrobat is a member of a troupe
A secretary is a member of a staff
A cow is a member of a herd
A book is a member of a library
A nomad is a member of a horde
A calf is a member of a
2024-07-30 22:44:48 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-30 22:46:55 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0276,  0.0258, -0.2678,  ...,  0.2291, -0.2269,  0.3545],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.0625, -3.0098,  0.2144,  ..., -3.5996, -0.2408, -0.8213],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0384,  0.0071,  0.0087,  ..., -0.0110, -0.0010, -0.0010],
        [ 0.0092,  0.0260, -0.0042,  ...,  0.0009, -0.0064, -0.0117],
        [ 0.0050, -0.0143,  0.0340,  ...,  0.0044, -0.0020,  0.0106],
        ...,
        [ 0.0352,  0.0041,  0.0036,  ...,  0.0307,  0.0005,  0.0006],
        [-0.0159,  0.0120, -0.0082,  ...,  0.0021,  0.0173, -0.0217],
        [ 0.0074,  0.0046,  0.0047,  ..., -0.0017, -0.0188,  0.0419]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.0859, -3.1855,  0.1208,  ..., -3.5664, -1.0771, -0.7168]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 22:46:56 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The state of being same is sameness
The state of being sacred is sacredness
The state of being related is relatedness
The state of being fixed is fixedness
The state of being righteous is righteousness
The state of being reasonable is reasonableness
The state of being helpful is helpfulness
The state of being mad is
2024-07-30 22:46:56 root INFO     [order_1_approx] starting weight calculation for The state of being related is relatedness
The state of being helpful is helpfulness
The state of being same is sameness
The state of being mad is madness
The state of being fixed is fixedness
The state of being reasonable is reasonableness
The state of being righteous is righteousness
The state of being sacred is
2024-07-30 22:46:56 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 22:47:26 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0553, -0.2393,  0.0548,  ..., -0.2007, -0.2849,  0.0234],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 5.1992, -1.1660,  1.2344,  ..., -1.7402, -0.7300, -1.0674],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0368,  0.0112,  0.0204,  ...,  0.0022, -0.0320, -0.0229],
        [ 0.0242,  0.0422, -0.0158,  ...,  0.0055, -0.0134,  0.0005],
        [ 0.0043, -0.0212,  0.0347,  ...,  0.0127, -0.0168, -0.0167],
        ...,
        [ 0.0269,  0.0013,  0.0042,  ...,  0.0370,  0.0171, -0.0238],
        [ 0.0167,  0.0345,  0.0061,  ...,  0.0087,  0.0271, -0.0159],
        [-0.0059, -0.0013, -0.0046,  ..., -0.0047,  0.0329,  0.0453]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.9727, -1.4785,  1.5029,  ..., -1.8008, -0.9282, -1.0586]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 22:47:29 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A singer is a member of a choir
A spouse is a member of a couple
A acrobat is a member of a troupe
A secretary is a member of a staff
A cow is a member of a herd
A book is a member of a library
A nomad is a member of a horde
A calf is a member of a
2024-07-30 22:47:29 root INFO     [order_1_approx] starting weight calculation for A spouse is a member of a couple
A acrobat is a member of a troupe
A book is a member of a library
A nomad is a member of a horde
A secretary is a member of a staff
A calf is a member of a cattle
A singer is a member of a choir
A cow is a member of a
2024-07-30 22:47:29 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-30 22:49:28 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0964,  0.1138, -0.2971,  ...,  0.0809, -0.7168,  0.3713],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.7070, -3.5625, -0.1670,  ..., -5.1094, -2.1953, -1.4844],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0427,  0.0037,  0.0143,  ...,  0.0233, -0.0052,  0.0086],
        [-0.0010,  0.0439,  0.0094,  ...,  0.0140, -0.0201,  0.0012],
        [-0.0080, -0.0148,  0.0266,  ..., -0.0122, -0.0030, -0.0052],
        ...,
        [ 0.0185, -0.0187,  0.0011,  ...,  0.0041, -0.0246,  0.0127],
        [ 0.0084,  0.0259,  0.0302,  ..., -0.0406,  0.0575, -0.0211],
        [-0.0042,  0.0029, -0.0311,  ...,  0.0161, -0.0187,  0.0245]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.7236, -3.4121, -0.2478,  ..., -5.1641, -2.8867, -1.6035]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 22:49:29 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The state of being related is relatedness
The state of being helpful is helpfulness
The state of being same is sameness
The state of being mad is madness
The state of being fixed is fixedness
The state of being reasonable is reasonableness
The state of being righteous is righteousness
The state of being sacred is
2024-07-30 22:49:30 root INFO     [order_1_approx] starting weight calculation for The state of being same is sameness
The state of being mad is madness
The state of being helpful is helpfulness
The state of being fixed is fixedness
The state of being sacred is sacredness
The state of being righteous is righteousness
The state of being reasonable is reasonableness
The state of being related is
2024-07-30 22:49:30 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 22:50:10 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0079, -0.1048, -0.0247,  ..., -0.0355, -0.0660, -0.1475],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 5.9062, -2.3242,  2.9434,  ..., -4.0781, -1.5801, -1.6973],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0369, -0.0138, -0.0164,  ..., -0.0204, -0.0291,  0.0034],
        [ 0.0176,  0.0261,  0.0177,  ...,  0.0221, -0.0473, -0.0206],
        [ 0.0051, -0.0085,  0.0415,  ...,  0.0048,  0.0100, -0.0192],
        ...,
        [ 0.0252, -0.0116,  0.0088,  ...,  0.0584,  0.0552,  0.0121],
        [ 0.0117,  0.0384,  0.0128,  ...,  0.0059,  0.0483, -0.0269],
        [-0.0149, -0.0221, -0.0183,  ..., -0.0180, -0.0246,  0.0388]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 5.8750, -2.4336,  3.2363,  ..., -3.6328, -2.1836, -1.3037]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 22:50:11 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A spouse is a member of a couple
A acrobat is a member of a troupe
A book is a member of a library
A nomad is a member of a horde
A secretary is a member of a staff
A calf is a member of a cattle
A singer is a member of a choir
A cow is a member of a
2024-07-30 22:50:11 root INFO     [order_1_approx] starting weight calculation for A book is a member of a library
A secretary is a member of a staff
A calf is a member of a cattle
A nomad is a member of a horde
A acrobat is a member of a troupe
A spouse is a member of a couple
A cow is a member of a herd
A singer is a member of a
2024-07-30 22:50:11 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-30 22:52:02 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0319, -0.1003, -0.4675,  ...,  0.0573, -0.4570,  0.1497],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.6895, -2.3594, -1.8574,  ...,  1.3643, -3.5938, -2.0352],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 4.0710e-02, -5.2528e-03, -9.0561e-03,  ...,  9.0561e-03,
         -5.6992e-03,  1.4938e-02],
        [-1.0597e-02,  4.0070e-02,  2.4506e-02,  ...,  5.6396e-02,
         -1.1101e-02,  1.8204e-02],
        [-1.2875e-05, -1.3519e-02,  3.1799e-02,  ...,  1.1246e-02,
         -2.6588e-03,  5.1460e-03],
        ...,
        [ 1.4984e-02,  1.4297e-02,  8.2626e-03,  ...,  1.7654e-02,
          1.0185e-02,  7.7858e-03],
        [ 1.4969e-02,  2.2705e-02,  1.4313e-02,  ..., -3.6377e-02,
          1.6800e-02, -1.4755e-02],
        [-1.5137e-02,  8.2550e-03,  4.0131e-03,  ...,  1.9562e-02,
         -2.2644e-02,  4.6906e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.5020, -2.0996, -1.8711,  ...,  0.8784, -3.5098, -2.3223]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 22:52:02 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The state of being same is sameness
The state of being mad is madness
The state of being helpful is helpfulness
The state of being fixed is fixedness
The state of being sacred is sacredness
The state of being righteous is righteousness
The state of being reasonable is reasonableness
The state of being related is
2024-07-30 22:52:02 root INFO     total operator prediction time: 1224.8420696258545 seconds
2024-07-30 22:52:02 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on re+verb_reg
2024-07-30 22:52:02 root INFO     building operator re+verb_reg
2024-07-30 22:52:03 root INFO     [order_1_approx] starting weight calculation for To marry again is to remarry
To upload again is to reupload
To publish again is to republish
To investigate again is to reinvestigate
To consider again is to reconsider
To unite again is to reunite
To send again is to resend
To locate again is to
2024-07-30 22:52:03 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 22:52:49 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0686,  0.0014, -0.2496,  ...,  0.0723, -0.0773,  0.0834],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.9951, -4.6562,  4.8555,  ...,  0.1514, -0.6318, -2.2812],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0699, -0.0327,  0.0268,  ..., -0.0013,  0.0203, -0.0126],
        [ 0.0115,  0.0278, -0.0020,  ...,  0.0099, -0.0181, -0.0230],
        [-0.0137,  0.0073,  0.0499,  ..., -0.0066, -0.0031, -0.0003],
        ...,
        [ 0.0241,  0.0156,  0.0242,  ...,  0.0811,  0.0022, -0.0144],
        [-0.0092,  0.0071, -0.0206,  ...,  0.0153,  0.0262,  0.0065],
        [ 0.0278, -0.0177, -0.0108,  ..., -0.0252, -0.0172,  0.0491]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.5078, -4.7422,  5.0586,  ...,  0.0870, -0.7300, -2.0020]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 22:52:50 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A book is a member of a library
A secretary is a member of a staff
A calf is a member of a cattle
A nomad is a member of a horde
A acrobat is a member of a troupe
A spouse is a member of a couple
A cow is a member of a herd
A singer is a member of a
2024-07-30 22:52:50 root INFO     [order_1_approx] starting weight calculation for A singer is a member of a choir
A secretary is a member of a staff
A spouse is a member of a couple
A acrobat is a member of a troupe
A book is a member of a library
A cow is a member of a herd
A calf is a member of a cattle
A nomad is a member of a
2024-07-30 22:52:51 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-30 22:54:36 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1649,  0.3433, -0.9429,  ...,  0.0890, -0.3501, -0.0555],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.8066, -1.9355,  0.4927,  ...,  0.9541, -3.5371, -3.2441],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0438, -0.0194,  0.0043,  ..., -0.0008,  0.0034,  0.0220],
        [-0.0006,  0.0330,  0.0061,  ...,  0.0023, -0.0084,  0.0044],
        [ 0.0014,  0.0099,  0.0260,  ..., -0.0123, -0.0016,  0.0036],
        ...,
        [ 0.0204, -0.0090,  0.0044,  ...,  0.0343,  0.0090,  0.0068],
        [ 0.0068,  0.0186,  0.0007,  ...,  0.0020,  0.0037,  0.0062],
        [-0.0023,  0.0117, -0.0088,  ...,  0.0035, -0.0214,  0.0335]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.7275, -1.7500,  0.3494,  ...,  1.3691, -3.6562, -3.0957]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 22:54:37 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To marry again is to remarry
To upload again is to reupload
To publish again is to republish
To investigate again is to reinvestigate
To consider again is to reconsider
To unite again is to reunite
To send again is to resend
To locate again is to
2024-07-30 22:54:37 root INFO     [order_1_approx] starting weight calculation for To marry again is to remarry
To investigate again is to reinvestigate
To unite again is to reunite
To send again is to resend
To publish again is to republish
To locate again is to relocate
To upload again is to reupload
To consider again is to
2024-07-30 22:54:37 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 22:55:27 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0127,  0.0212, -0.4102,  ...,  0.3423, -0.1461,  0.1580],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.4053, -3.7266,  1.5527,  ..., -2.0273, -1.6709, -0.1455],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 6.6833e-02, -1.6693e-02,  1.2154e-02,  ..., -9.9487e-03,
         -3.2532e-02, -1.8494e-02],
        [ 1.3885e-02,  3.6743e-02, -1.0925e-02,  ..., -9.2125e-04,
         -2.7046e-03, -2.4414e-02],
        [ 2.6672e-02, -1.3519e-02,  4.1931e-02,  ..., -9.9106e-03,
         -1.4793e-02, -3.4065e-03],
        ...,
        [ 1.4145e-02,  1.5930e-02, -7.8278e-03,  ...,  6.2561e-02,
          9.4528e-03, -1.6327e-02],
        [ 1.4931e-02,  5.2452e-05, -9.0332e-03,  ...,  4.3182e-03,
          3.0533e-02, -8.1482e-03],
        [ 1.6129e-02,  1.2360e-03,  6.0501e-03,  ...,  6.4812e-03,
          1.1673e-03,  5.1697e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.5205, -3.9082,  1.4727,  ..., -2.2090, -1.7051, -0.2830]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 22:55:28 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A singer is a member of a choir
A secretary is a member of a staff
A spouse is a member of a couple
A acrobat is a member of a troupe
A book is a member of a library
A cow is a member of a herd
A calf is a member of a cattle
A nomad is a member of a
2024-07-30 22:55:28 root INFO     [order_1_approx] starting weight calculation for A singer is a member of a choir
A calf is a member of a cattle
A spouse is a member of a couple
A acrobat is a member of a troupe
A nomad is a member of a horde
A book is a member of a library
A cow is a member of a herd
A secretary is a member of a
2024-07-30 22:55:28 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-30 22:57:10 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2048,  0.1228, -0.2944,  ...,  0.1788,  0.1375,  0.1118],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.2261, -4.4336,  1.9961,  ...,  0.1948, -2.5918, -3.6602],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0466, -0.0247,  0.0170,  ..., -0.0100, -0.0096,  0.0147],
        [ 0.0030,  0.0027,  0.0026,  ...,  0.0213, -0.0109,  0.0019],
        [-0.0080,  0.0198,  0.0479,  ..., -0.0235, -0.0068,  0.0220],
        ...,
        [ 0.0185, -0.0045,  0.0082,  ...,  0.0546,  0.0204,  0.0097],
        [-0.0047,  0.0356,  0.0044,  ..., -0.0042,  0.0094,  0.0008],
        [ 0.0035, -0.0131,  0.0076,  ..., -0.0050, -0.0135,  0.0192]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.0273, -4.1523,  1.7285,  ...,  1.1172, -3.2422, -3.1191]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 22:57:11 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To marry again is to remarry
To investigate again is to reinvestigate
To unite again is to reunite
To send again is to resend
To publish again is to republish
To locate again is to relocate
To upload again is to reupload
To consider again is to
2024-07-30 22:57:11 root INFO     [order_1_approx] starting weight calculation for To consider again is to reconsider
To send again is to resend
To locate again is to relocate
To upload again is to reupload
To publish again is to republish
To unite again is to reunite
To investigate again is to reinvestigate
To marry again is to
2024-07-30 22:57:11 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 22:58:06 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0874, -0.2385, -0.2449,  ...,  0.1667, -0.1475, -0.0042],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.4102, -3.6172,  3.7852,  ..., -0.2412, -1.5410, -1.8906],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0529, -0.0116,  0.0276,  ...,  0.0020,  0.0075,  0.0132],
        [-0.0070,  0.0316, -0.0134,  ...,  0.0235, -0.0228, -0.0206],
        [ 0.0120, -0.0076,  0.0416,  ..., -0.0095,  0.0116,  0.0093],
        ...,
        [ 0.0289,  0.0455,  0.0466,  ...,  0.0600,  0.0366, -0.0174],
        [ 0.0456,  0.0162, -0.0419,  ...,  0.0252,  0.0277, -0.0007],
        [ 0.0033, -0.0131,  0.0087,  ...,  0.0016,  0.0317,  0.0364]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.7891, -3.4043,  3.5918,  ..., -0.7515, -1.4844, -1.7402]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 22:58:07 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A singer is a member of a choir
A calf is a member of a cattle
A spouse is a member of a couple
A acrobat is a member of a troupe
A nomad is a member of a horde
A book is a member of a library
A cow is a member of a herd
A secretary is a member of a
2024-07-30 22:58:07 root INFO     [order_1_approx] starting weight calculation for A singer is a member of a choir
A calf is a member of a cattle
A spouse is a member of a couple
A cow is a member of a herd
A acrobat is a member of a troupe
A secretary is a member of a staff
A nomad is a member of a horde
A book is a member of a
2024-07-30 22:58:07 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-30 22:59:46 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1083,  0.1471, -0.2554,  ...,  0.0274, -0.6138,  0.2078],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.7344, -2.5742,  2.8223,  ..., -0.8867, -3.9062, -3.3574],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 2.6413e-02,  1.1688e-02,  1.7609e-02,  ...,  2.5654e-03,
         -1.0544e-02,  1.3458e-02],
        [ 1.5974e-03,  1.4679e-02,  6.6833e-03,  ...,  1.5457e-02,
          1.0071e-03,  1.5869e-02],
        [ 2.8854e-02,  7.0000e-03,  2.7267e-02,  ..., -1.2268e-02,
         -1.3687e-02,  2.5742e-02],
        ...,
        [ 1.2482e-02, -2.7962e-03,  1.5900e-02,  ...,  2.8748e-02,
          2.4471e-03, -1.6647e-02],
        [ 9.0485e-03, -3.6945e-03, -9.9182e-05,  ...,  8.3466e-03,
          1.3916e-02,  7.6942e-03],
        [ 1.6968e-02, -4.2038e-03, -1.1162e-02,  ...,  1.8873e-03,
         -1.1848e-02,  4.6112e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.6450, -2.6504,  2.6543,  ..., -0.5410, -3.4141, -3.4414]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 22:59:46 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To consider again is to reconsider
To send again is to resend
To locate again is to relocate
To upload again is to reupload
To publish again is to republish
To unite again is to reunite
To investigate again is to reinvestigate
To marry again is to
2024-07-30 22:59:47 root INFO     [order_1_approx] starting weight calculation for To consider again is to reconsider
To investigate again is to reinvestigate
To marry again is to remarry
To unite again is to reunite
To send again is to resend
To publish again is to republish
To locate again is to relocate
To upload again is to
2024-07-30 22:59:47 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 23:00:47 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1090, -0.0485, -0.2466,  ...,  0.1649, -0.1443, -0.0181],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.9277, -3.7852,  0.5957,  ..., -0.3838, -2.6191, -2.5469],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0391,  0.0285,  0.0077,  ..., -0.0008, -0.0084,  0.0141],
        [ 0.0081,  0.0343, -0.0056,  ...,  0.0170, -0.0028, -0.0208],
        [-0.0046, -0.0141,  0.0367,  ..., -0.0196,  0.0022,  0.0051],
        ...,
        [ 0.0086, -0.0034, -0.0062,  ...,  0.0390, -0.0202, -0.0360],
        [-0.0021, -0.0011, -0.0131,  ..., -0.0054,  0.0370,  0.0024],
        [ 0.0014,  0.0166,  0.0090,  ..., -0.0130, -0.0102,  0.0279]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.8242, -3.9258,  1.1621,  ...,  0.1777, -2.9844, -2.3848]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 23:00:48 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A singer is a member of a choir
A calf is a member of a cattle
A spouse is a member of a couple
A cow is a member of a herd
A acrobat is a member of a troupe
A secretary is a member of a staff
A nomad is a member of a horde
A book is a member of a
2024-07-30 23:00:48 root INFO     total operator prediction time: 1277.4380276203156 seconds
2024-07-30 23:00:48 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on antonyms - binary
2024-07-30 23:00:48 root INFO     building operator antonyms - binary
2024-07-30 23:00:48 root INFO     [order_1_approx] starting weight calculation for The opposite of proceed is retreat
The opposite of dynamic is static
The opposite of input is output
The opposite of top is bottom
The opposite of after is before
The opposite of before is after
The opposite of decrement is increment
The opposite of west is
2024-07-30 23:00:48 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-30 23:02:20 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.4683, -0.1091, -0.2280,  ..., -0.0287, -0.3604,  0.0141],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.1840, -3.4844,  0.7739,  ...,  1.1230, -3.6270, -2.1855],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0411,  0.0044,  0.0082,  ..., -0.0134,  0.0020,  0.0133],
        [-0.0166,  0.0128, -0.0028,  ...,  0.0148, -0.0020,  0.0078],
        [ 0.0063,  0.0008,  0.0276,  ..., -0.0132, -0.0080, -0.0073],
        ...,
        [ 0.0128, -0.0113,  0.0067,  ...,  0.0432,  0.0178, -0.0125],
        [-0.0094,  0.0160, -0.0007,  ..., -0.0072, -0.0021, -0.0067],
        [-0.0140,  0.0107, -0.0130,  ..., -0.0023, -0.0147,  0.0379]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.0654, -3.2832,  1.0791,  ...,  1.3496, -3.9141, -2.4941]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 23:02:21 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To consider again is to reconsider
To investigate again is to reinvestigate
To marry again is to remarry
To unite again is to reunite
To send again is to resend
To publish again is to republish
To locate again is to relocate
To upload again is to
2024-07-30 23:02:21 root INFO     [order_1_approx] starting weight calculation for To send again is to resend
To investigate again is to reinvestigate
To publish again is to republish
To marry again is to remarry
To locate again is to relocate
To upload again is to reupload
To consider again is to reconsider
To unite again is to
2024-07-30 23:02:21 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 23:03:26 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.3179, -0.1388,  0.0068,  ...,  0.0997,  0.1927,  0.0380],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.2539, -2.6680, -1.8506,  ..., -1.2383, -0.1006, -1.2588],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0556, -0.0318,  0.0064,  ...,  0.0110,  0.0282, -0.0004],
        [ 0.0237,  0.0142,  0.0220,  ..., -0.0069, -0.0020, -0.0118],
        [-0.0242, -0.0439,  0.0091,  ...,  0.0234,  0.0174,  0.0253],
        ...,
        [ 0.0259, -0.0146, -0.0024,  ...,  0.0278,  0.0132, -0.0298],
        [ 0.0170, -0.0048,  0.0053,  ...,  0.0211,  0.0584,  0.0267],
        [ 0.0340,  0.0006,  0.0064,  ...,  0.0262, -0.0080,  0.0152]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.4365, -2.4863, -2.0352,  ..., -0.8955,  0.4678, -1.2920]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 23:03:27 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of proceed is retreat
The opposite of dynamic is static
The opposite of input is output
The opposite of top is bottom
The opposite of after is before
The opposite of before is after
The opposite of decrement is increment
The opposite of west is
2024-07-30 23:03:27 root INFO     [order_1_approx] starting weight calculation for The opposite of input is output
The opposite of west is east
The opposite of proceed is retreat
The opposite of before is after
The opposite of after is before
The opposite of top is bottom
The opposite of dynamic is static
The opposite of decrement is
2024-07-30 23:03:27 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-30 23:04:55 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1683, -0.2286, -0.3574,  ...,  0.0984, -0.4348,  0.4231],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.3413, -3.6855,  2.6855,  ...,  2.1719, -3.7207, -1.0156],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0426, -0.0159,  0.0214,  ...,  0.0085, -0.0090, -0.0019],
        [-0.0066,  0.0239,  0.0015,  ...,  0.0127, -0.0188, -0.0092],
        [ 0.0001,  0.0224,  0.0343,  ..., -0.0061, -0.0028, -0.0045],
        ...,
        [ 0.0168,  0.0019, -0.0004,  ...,  0.0279, -0.0246, -0.0199],
        [-0.0061,  0.0113,  0.0132,  ...,  0.0069,  0.0218, -0.0028],
        [-0.0015, -0.0073,  0.0254,  ..., -0.0087, -0.0152,  0.0299]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.7480, -3.8047,  2.5000,  ...,  2.2402, -3.5117, -1.5234]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 23:04:57 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To send again is to resend
To investigate again is to reinvestigate
To publish again is to republish
To marry again is to remarry
To locate again is to relocate
To upload again is to reupload
To consider again is to reconsider
To unite again is to
2024-07-30 23:04:57 root INFO     [order_1_approx] starting weight calculation for To upload again is to reupload
To unite again is to reunite
To investigate again is to reinvestigate
To send again is to resend
To marry again is to remarry
To consider again is to reconsider
To locate again is to relocate
To publish again is to
2024-07-30 23:04:57 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 23:06:05 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.4678,  0.3813,  0.0521,  ...,  0.0094, -0.1920,  0.0116],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.2495, -1.0283, -1.2988,  ...,  0.8345, -2.3496, -0.7129],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0175, -0.0109,  0.0075,  ...,  0.0262, -0.0047,  0.0430],
        [ 0.0099,  0.0146, -0.0034,  ...,  0.0441, -0.0063, -0.0130],
        [-0.0091, -0.0114,  0.0009,  ..., -0.0384,  0.0047, -0.0157],
        ...,
        [ 0.0067,  0.0247,  0.0247,  ..., -0.0099,  0.0500, -0.0126],
        [-0.0130,  0.0305, -0.0136,  ..., -0.0386,  0.0323, -0.0103],
        [ 0.0105, -0.0003, -0.0106,  ..., -0.0040, -0.0162,  0.0330]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.3086, -1.2754, -1.7197,  ..., -0.0601, -2.3555, -0.6494]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 23:06:06 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of input is output
The opposite of west is east
The opposite of proceed is retreat
The opposite of before is after
The opposite of after is before
The opposite of top is bottom
The opposite of dynamic is static
The opposite of decrement is
2024-07-30 23:06:06 root INFO     [order_1_approx] starting weight calculation for The opposite of decrement is increment
The opposite of west is east
The opposite of proceed is retreat
The opposite of input is output
The opposite of after is before
The opposite of dynamic is static
The opposite of before is after
The opposite of top is
2024-07-30 23:06:06 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-30 23:07:30 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1057,  0.2031, -0.0026,  ...,  0.1094, -0.2208,  0.2905],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.7861, -2.5820, -0.1464,  ...,  1.2490, -3.3398, -2.2285],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0613, -0.0099,  0.0151,  ...,  0.0015, -0.0175,  0.0170],
        [-0.0100,  0.0345, -0.0032,  ...,  0.0157, -0.0079,  0.0035],
        [ 0.0188,  0.0010,  0.0375,  ..., -0.0102, -0.0184, -0.0031],
        ...,
        [ 0.0205, -0.0140, -0.0067,  ...,  0.0418,  0.0041,  0.0051],
        [ 0.0006, -0.0123, -0.0031,  ...,  0.0096,  0.0221, -0.0099],
        [ 0.0037,  0.0018, -0.0018,  ...,  0.0001, -0.0323,  0.0131]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.8530, -2.7422,  0.1021,  ...,  1.1719, -3.0254, -2.3125]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 23:07:32 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To upload again is to reupload
To unite again is to reunite
To investigate again is to reinvestigate
To send again is to resend
To marry again is to remarry
To consider again is to reconsider
To locate again is to relocate
To publish again is to
2024-07-30 23:07:32 root INFO     [order_1_approx] starting weight calculation for To unite again is to reunite
To locate again is to relocate
To consider again is to reconsider
To publish again is to republish
To send again is to resend
To upload again is to reupload
To marry again is to remarry
To investigate again is to
2024-07-30 23:07:32 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 23:08:46 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 1.7548e-04, -2.8906e-01,  2.5952e-01,  ...,  3.2379e-02,
        -8.0505e-02,  1.6016e-01], device='cuda:0', dtype=torch.float16,
       grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.6172, -2.1172,  0.3020,  ..., -3.2266,  2.3086, -4.5078],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0723, -0.0420,  0.0197,  ..., -0.0153,  0.0089,  0.0080],
        [ 0.0163,  0.0539,  0.0173,  ..., -0.0273, -0.0022, -0.0189],
        [-0.0002, -0.0098, -0.0151,  ...,  0.0020, -0.0152,  0.0041],
        ...,
        [ 0.0135, -0.0087,  0.0165,  ...,  0.0496,  0.0260, -0.0160],
        [ 0.0173, -0.0129, -0.0127,  ...,  0.0109,  0.0203, -0.0122],
        [ 0.0436, -0.0340,  0.0268,  ...,  0.0066,  0.0308,  0.0380]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.6191, -1.9209, -0.2424,  ..., -3.2832,  2.3223, -4.5000]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 23:08:47 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of decrement is increment
The opposite of west is east
The opposite of proceed is retreat
The opposite of input is output
The opposite of after is before
The opposite of dynamic is static
The opposite of before is after
The opposite of top is
2024-07-30 23:08:47 root INFO     [order_1_approx] starting weight calculation for The opposite of after is before
The opposite of input is output
The opposite of decrement is increment
The opposite of top is bottom
The opposite of west is east
The opposite of dynamic is static
The opposite of proceed is retreat
The opposite of before is
2024-07-30 23:08:47 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-30 23:10:05 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0209,  0.3755, -0.2278,  ..., -0.0844, -0.4590, -0.1387],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.0840, -3.3770,  2.6895,  ...,  0.2314, -1.2119, -3.4531],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0630,  0.0132,  0.0062,  ..., -0.0101,  0.0125, -0.0072],
        [ 0.0013,  0.0222,  0.0048,  ...,  0.0123,  0.0022,  0.0181],
        [ 0.0016,  0.0152,  0.0408,  ..., -0.0103,  0.0300,  0.0088],
        ...,
        [ 0.0221,  0.0017,  0.0067,  ...,  0.0344, -0.0058,  0.0010],
        [-0.0269,  0.0082,  0.0064,  ...,  0.0187,  0.0174,  0.0131],
        [-0.0046,  0.0090, -0.0049,  ...,  0.0042, -0.0157,  0.0138]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.9390, -3.6914,  2.7402,  ...,  0.2761, -0.9189, -3.1016]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 23:10:06 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To unite again is to reunite
To locate again is to relocate
To consider again is to reconsider
To publish again is to republish
To send again is to resend
To upload again is to reupload
To marry again is to remarry
To investigate again is to
2024-07-30 23:10:06 root INFO     [order_1_approx] starting weight calculation for To publish again is to republish
To upload again is to reupload
To marry again is to remarry
To unite again is to reunite
To investigate again is to reinvestigate
To consider again is to reconsider
To locate again is to relocate
To send again is to
2024-07-30 23:10:06 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 23:11:26 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2043, -0.0797, -0.1440,  ..., -0.2295, -0.4299, -0.0096],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.4766, -2.8438, -1.3027,  ..., -0.2395, -2.5762, -3.0156],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0605, -0.0424, -0.0456,  ...,  0.0051,  0.0083, -0.0045],
        [-0.0369,  0.0175, -0.0168,  ...,  0.0048,  0.0065, -0.0234],
        [ 0.0040,  0.0059,  0.0323,  ..., -0.0031,  0.0127,  0.0399],
        ...,
        [-0.0067,  0.0057,  0.0199,  ...,  0.0178,  0.0450,  0.0031],
        [-0.0022, -0.0267,  0.0333,  ...,  0.0179,  0.0441, -0.0184],
        [-0.0126,  0.0013,  0.0173,  ..., -0.0045,  0.0040,  0.0652]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.7109, -2.6250, -0.8213,  ..., -0.7412, -3.6562, -3.2852]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 23:11:27 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of after is before
The opposite of input is output
The opposite of decrement is increment
The opposite of top is bottom
The opposite of west is east
The opposite of dynamic is static
The opposite of proceed is retreat
The opposite of before is
2024-07-30 23:11:27 root INFO     [order_1_approx] starting weight calculation for The opposite of proceed is retreat
The opposite of dynamic is static
The opposite of before is after
The opposite of west is east
The opposite of top is bottom
The opposite of after is before
The opposite of decrement is increment
The opposite of input is
2024-07-30 23:11:27 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-30 23:12:40 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0771,  0.1351,  0.0067,  ..., -0.0056, -0.2212, -0.0322],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.9287, -3.4414, -1.8809,  ...,  0.2861, -2.9219, -3.1562],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 4.9866e-02, -4.0619e-02,  5.6381e-03,  ...,  1.1826e-03,
         -7.0839e-03,  1.5526e-02],
        [ 6.1493e-03,  2.5604e-02, -9.2697e-04,  ...,  4.4518e-03,
         -3.1109e-03, -1.2741e-02],
        [ 1.7044e-02, -1.3351e-05,  2.5604e-02,  ..., -9.7961e-03,
         -1.8005e-03,  4.2267e-03],
        ...,
        [ 5.4626e-03, -1.4793e-02,  8.5754e-03,  ...,  3.4576e-02,
         -3.3226e-03,  2.2202e-03],
        [-1.4099e-02,  2.5467e-02,  1.9302e-03,  ..., -1.5076e-02,
          7.6828e-03, -9.7885e-03],
        [-7.6408e-03, -2.2217e-02, -3.8185e-03,  ...,  1.0204e-04,
         -1.4717e-02,  3.3325e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.4844, -3.8555, -1.6982,  ...,  0.2698, -3.1855, -3.0293]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 23:12:50 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To publish again is to republish
To upload again is to reupload
To marry again is to remarry
To unite again is to reunite
To investigate again is to reinvestigate
To consider again is to reconsider
To locate again is to relocate
To send again is to
2024-07-30 23:12:50 root INFO     total operator prediction time: 1247.3439729213715 seconds
2024-07-30 23:12:50 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on un+adj_reg
2024-07-30 23:12:50 root INFO     building operator un+adj_reg
2024-07-30 23:12:50 root INFO     [order_1_approx] starting weight calculation for The opposite of comfortable is uncomfortable
The opposite of lawful is unlawful
The opposite of controlled is uncontrolled
The opposite of veiled is unveiled
The opposite of specified is unspecified
The opposite of authorized is unauthorized
The opposite of identified is unidentified
The opposite of predictable is
2024-07-30 23:12:50 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 23:14:06 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.3665,  0.0347, -0.1166,  ...,  0.0429, -0.1099,  0.1952],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.3398, -0.7852, -0.4377,  ..., -0.7227, -0.8594, -3.2383],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0663, -0.0041,  0.0144,  ...,  0.0451,  0.0178,  0.0358],
        [-0.0093,  0.0416,  0.0107,  ...,  0.0081,  0.0016,  0.0267],
        [-0.0182, -0.0010,  0.0146,  ..., -0.0232, -0.0414, -0.0312],
        ...,
        [-0.0063,  0.0363, -0.0048,  ..., -0.0029, -0.0226,  0.0004],
        [ 0.0038, -0.0153, -0.0330,  ..., -0.0364,  0.0519, -0.0076],
        [ 0.0255,  0.0168,  0.0010,  ..., -0.0079,  0.0053,  0.0314]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.0710, -0.8862, -0.6006,  ..., -0.6411, -0.8833, -3.1895]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 23:14:07 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of proceed is retreat
The opposite of dynamic is static
The opposite of before is after
The opposite of west is east
The opposite of top is bottom
The opposite of after is before
The opposite of decrement is increment
The opposite of input is
2024-07-30 23:14:07 root INFO     [order_1_approx] starting weight calculation for The opposite of top is bottom
The opposite of proceed is retreat
The opposite of decrement is increment
The opposite of before is after
The opposite of dynamic is static
The opposite of west is east
The opposite of input is output
The opposite of after is
2024-07-30 23:14:07 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-30 23:15:24 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3022, -0.0038, -0.0574,  ...,  0.0706, -0.0728,  0.0188],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.8203,  0.5312, -1.1582,  ...,  1.1875, -0.3584, -1.9688],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0288,  0.0038, -0.0111,  ...,  0.0183, -0.0077,  0.0363],
        [-0.0064,  0.0048,  0.0085,  ...,  0.0227,  0.0287, -0.0043],
        [ 0.0006, -0.0033,  0.0068,  ...,  0.0270, -0.0186,  0.0363],
        ...,
        [ 0.0001,  0.0138, -0.0080,  ..., -0.0040,  0.0036, -0.0144],
        [ 0.0234,  0.0070,  0.0199,  ..., -0.0132,  0.0182, -0.0079],
        [-0.0092,  0.0077, -0.0120,  ..., -0.0080,  0.0047,  0.0066]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.1992,  0.3315, -0.7656,  ...,  1.4199, -0.5781, -2.2734]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 23:15:25 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of comfortable is uncomfortable
The opposite of lawful is unlawful
The opposite of controlled is uncontrolled
The opposite of veiled is unveiled
The opposite of specified is unspecified
The opposite of authorized is unauthorized
The opposite of identified is unidentified
The opposite of predictable is
2024-07-30 23:15:25 root INFO     [order_1_approx] starting weight calculation for The opposite of predictable is unpredictable
The opposite of controlled is uncontrolled
The opposite of authorized is unauthorized
The opposite of specified is unspecified
The opposite of identified is unidentified
The opposite of lawful is unlawful
The opposite of veiled is unveiled
The opposite of comfortable is
2024-07-30 23:15:25 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 23:16:46 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0876, -0.0373, -0.3535,  ..., -0.3381, -0.0237,  0.1193],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.6562, -2.4219, -0.4661,  ...,  1.0029, -1.7812, -4.8047],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0356,  0.0004, -0.0269,  ...,  0.0088, -0.0065,  0.0243],
        [-0.0077,  0.0261, -0.0321,  ...,  0.0225, -0.0090, -0.0091],
        [-0.0068, -0.0336,  0.0097,  ...,  0.0134,  0.0016,  0.0334],
        ...,
        [ 0.0110, -0.0273,  0.0333,  ..., -0.0014,  0.0217, -0.0219],
        [ 0.0190, -0.0247,  0.0219,  ...,  0.0179,  0.0460, -0.0124],
        [ 0.0306, -0.0124, -0.0554,  ...,  0.0636,  0.0025,  0.0133]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.4141, -1.6670, -0.9014,  ...,  0.3833, -2.2227, -4.0117]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 23:16:47 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of top is bottom
The opposite of proceed is retreat
The opposite of decrement is increment
The opposite of before is after
The opposite of dynamic is static
The opposite of west is east
The opposite of input is output
The opposite of after is
2024-07-30 23:16:47 root INFO     [order_1_approx] starting weight calculation for The opposite of west is east
The opposite of proceed is retreat
The opposite of input is output
The opposite of decrement is increment
The opposite of top is bottom
The opposite of after is before
The opposite of before is after
The opposite of dynamic is
2024-07-30 23:16:47 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-30 23:18:00 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1466,  0.0421, -0.1934,  ..., -0.4148, -0.3838,  0.4790],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.0762, -0.1833,  1.7773,  ..., -0.6348,  0.5137,  1.0273],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0434, -0.0080,  0.0112,  ..., -0.0087, -0.0083,  0.0257],
        [-0.0123,  0.0378,  0.0055,  ...,  0.0100,  0.0164, -0.0169],
        [-0.0031, -0.0096,  0.0089,  ...,  0.0242, -0.0114,  0.0090],
        ...,
        [ 0.0109,  0.0186, -0.0029,  ...,  0.0172,  0.0138, -0.0169],
        [ 0.0057,  0.0059,  0.0150,  ..., -0.0247,  0.0145, -0.0205],
        [-0.0192, -0.0349, -0.0144,  ...,  0.0069, -0.0015,  0.0096]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.4531, -0.2678,  1.3877,  ..., -0.5420, -0.0513,  0.7305]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 23:18:01 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of predictable is unpredictable
The opposite of controlled is uncontrolled
The opposite of authorized is unauthorized
The opposite of specified is unspecified
The opposite of identified is unidentified
The opposite of lawful is unlawful
The opposite of veiled is unveiled
The opposite of comfortable is
2024-07-30 23:18:01 root INFO     [order_1_approx] starting weight calculation for The opposite of identified is unidentified
The opposite of comfortable is uncomfortable
The opposite of controlled is uncontrolled
The opposite of predictable is unpredictable
The opposite of lawful is unlawful
The opposite of specified is unspecified
The opposite of authorized is unauthorized
The opposite of veiled is
2024-07-30 23:18:01 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 23:19:26 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0347,  0.2646, -0.1104,  ..., -0.0013, -0.2112,  0.2441],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.0881, -0.4438,  1.8467,  ...,  0.5977, -4.1445, -3.0410],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0507,  0.0177, -0.0148,  ...,  0.0006,  0.0182, -0.0171],
        [ 0.0027,  0.0172,  0.0540,  ...,  0.0526, -0.0176,  0.0216],
        [-0.0278,  0.0054, -0.0172,  ..., -0.0188, -0.0003,  0.0073],
        ...,
        [ 0.0289,  0.0256,  0.0108,  ...,  0.0271, -0.0056,  0.0083],
        [-0.0073, -0.0084, -0.0338,  ..., -0.0142,  0.0598, -0.0181],
        [ 0.0657, -0.0259,  0.0360,  ...,  0.0557, -0.0019,  0.0618]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.7520, -0.6387,  1.8203,  ...,  0.4600, -3.5625, -3.0195]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 23:19:27 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of west is east
The opposite of proceed is retreat
The opposite of input is output
The opposite of decrement is increment
The opposite of top is bottom
The opposite of after is before
The opposite of before is after
The opposite of dynamic is
2024-07-30 23:19:27 root INFO     [order_1_approx] starting weight calculation for The opposite of after is before
The opposite of west is east
The opposite of input is output
The opposite of dynamic is static
The opposite of decrement is increment
The opposite of before is after
The opposite of top is bottom
The opposite of proceed is
2024-07-30 23:19:27 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-30 23:20:35 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1515, -0.2971, -0.1071,  ...,  0.1389, -0.0967,  0.3103],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.4287,  0.6152,  0.2100,  ...,  3.3379, -3.1152, -0.0469],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0528, -0.0087,  0.0075,  ...,  0.0001, -0.0039,  0.0006],
        [-0.0025,  0.0404, -0.0203,  ...,  0.0069, -0.0068, -0.0121],
        [-0.0175,  0.0004,  0.0104,  ...,  0.0262, -0.0257, -0.0231],
        ...,
        [ 0.0223, -0.0030,  0.0266,  ...,  0.0260,  0.0233,  0.0169],
        [ 0.0064, -0.0002, -0.0052,  ...,  0.0040,  0.0450, -0.0150],
        [ 0.0233, -0.0199,  0.0024,  ...,  0.0091,  0.0150,  0.0518]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.6284,  0.6011,  0.3811,  ...,  3.3848, -3.2598,  0.2561]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 23:20:36 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of identified is unidentified
The opposite of comfortable is uncomfortable
The opposite of controlled is uncontrolled
The opposite of predictable is unpredictable
The opposite of lawful is unlawful
The opposite of specified is unspecified
The opposite of authorized is unauthorized
The opposite of veiled is
2024-07-30 23:20:37 root INFO     [order_1_approx] starting weight calculation for The opposite of comfortable is uncomfortable
The opposite of veiled is unveiled
The opposite of specified is unspecified
The opposite of lawful is unlawful
The opposite of controlled is uncontrolled
The opposite of predictable is unpredictable
The opposite of authorized is unauthorized
The opposite of identified is
2024-07-30 23:20:37 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 23:22:06 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1973, -0.1809, -0.2039,  ..., -0.1932, -0.2759,  0.3572],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.0977, -2.5664,  2.5273,  ...,  2.0977, -3.9219, -3.2109],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0387, -0.0177, -0.0270,  ...,  0.0695, -0.0334, -0.0138],
        [-0.0928,  0.0298, -0.0105,  ...,  0.0810, -0.0127, -0.0149],
        [-0.0545,  0.0068,  0.0422,  ..., -0.0383, -0.0004, -0.0464],
        ...,
        [-0.0267,  0.0474,  0.0293,  ...,  0.0679, -0.0099, -0.0128],
        [ 0.0183,  0.0179, -0.0060,  ...,  0.0334,  0.0170, -0.0036],
        [ 0.0381,  0.0072, -0.0219,  ...,  0.0200, -0.0035,  0.0707]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.3613, -2.4414,  2.4395,  ...,  1.8545, -3.6973, -3.3164]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 23:22:20 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of after is before
The opposite of west is east
The opposite of input is output
The opposite of dynamic is static
The opposite of decrement is increment
The opposite of before is after
The opposite of top is bottom
The opposite of proceed is
2024-07-30 23:22:20 root INFO     total operator prediction time: 1292.727948665619 seconds
2024-07-30 23:22:20 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on hyponyms - misc
2024-07-30 23:22:20 root INFO     building operator hyponyms - misc
2024-07-30 23:22:21 root INFO     [order_1_approx] starting weight calculation for A more specific term for a backpack is daypack
A more specific term for a railway is monorail
A more specific term for a oven is broiler
A more specific term for a burger is hamburger
A more specific term for a shoes is sneakers
A more specific term for a season is spring
A more specific term for a mixer is blender
A more specific term for a citrus is
2024-07-30 23:22:21 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-30 23:23:11 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0180,  0.1801, -0.5190,  ..., -0.0497, -0.1946,  0.2195],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.4395,  0.4519,  1.7041,  ...,  0.7559, -1.1465, -1.2109],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0386,  0.0149,  0.0023,  ...,  0.0419, -0.0288,  0.0113],
        [-0.0066,  0.0056,  0.0021,  ...,  0.0183, -0.0042, -0.0142],
        [-0.0126, -0.0199, -0.0024,  ...,  0.0404, -0.0071, -0.0121],
        ...,
        [ 0.0125, -0.0024, -0.0227,  ...,  0.0018, -0.0195, -0.0298],
        [-0.0003,  0.0023,  0.0394,  ...,  0.0058,  0.0519, -0.0214],
        [-0.0057, -0.0201, -0.0257,  ..., -0.0081, -0.0026,  0.0003]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.2910,  0.2372,  2.1855,  ...,  0.8926, -1.4180, -0.8384]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 23:23:12 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of comfortable is uncomfortable
The opposite of veiled is unveiled
The opposite of specified is unspecified
The opposite of lawful is unlawful
The opposite of controlled is uncontrolled
The opposite of predictable is unpredictable
The opposite of authorized is unauthorized
The opposite of identified is
2024-07-30 23:23:12 root INFO     [order_1_approx] starting weight calculation for The opposite of predictable is unpredictable
The opposite of lawful is unlawful
The opposite of specified is unspecified
The opposite of veiled is unveiled
The opposite of authorized is unauthorized
The opposite of comfortable is uncomfortable
The opposite of identified is unidentified
The opposite of controlled is
2024-07-30 23:23:12 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 23:24:59 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.3115, -0.1006,  0.0160,  ..., -0.0490,  0.0060, -0.2542],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.7305, -5.7734, -1.7852,  ..., -1.2344, -6.2383, -3.4766],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0441,  0.0061, -0.0004,  ...,  0.0024, -0.0142,  0.0090],
        [ 0.0082,  0.0243,  0.0149,  ...,  0.0079,  0.0185,  0.0237],
        [-0.0032, -0.0063,  0.0636,  ...,  0.0122, -0.0117,  0.0215],
        ...,
        [ 0.0038, -0.0224,  0.0031,  ...,  0.0468, -0.0242, -0.0071],
        [ 0.0030, -0.0131,  0.0005,  ...,  0.0229,  0.0201,  0.0129],
        [ 0.0268,  0.0130,  0.0216,  ..., -0.0006, -0.0020,  0.0424]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.3770, -5.5938, -1.8418,  ..., -0.9307, -6.1875, -3.5703]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 23:25:00 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more specific term for a backpack is daypack
A more specific term for a railway is monorail
A more specific term for a oven is broiler
A more specific term for a burger is hamburger
A more specific term for a shoes is sneakers
A more specific term for a season is spring
A more specific term for a mixer is blender
A more specific term for a citrus is
2024-07-30 23:25:00 root INFO     [order_1_approx] starting weight calculation for A more specific term for a backpack is daypack
A more specific term for a citrus is lemon
A more specific term for a burger is hamburger
A more specific term for a shoes is sneakers
A more specific term for a season is spring
A more specific term for a oven is broiler
A more specific term for a mixer is blender
A more specific term for a railway is
2024-07-30 23:25:00 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-30 23:25:44 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0631,  0.0417, -0.4294,  ..., -0.2993,  0.0499,  0.1858],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.7617, -0.2671,  1.1250,  ...,  1.6592,  2.2676, -2.0098],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0411,  0.0049, -0.0253,  ...,  0.0227, -0.0039,  0.0145],
        [-0.0042,  0.0217,  0.0016,  ...,  0.0164,  0.0257, -0.0084],
        [-0.0275,  0.0119,  0.0034,  ...,  0.0220, -0.0024, -0.0047],
        ...,
        [ 0.0177,  0.0375, -0.0075,  ...,  0.0110, -0.0117,  0.0092],
        [ 0.0063,  0.0218,  0.0208,  ...,  0.0026,  0.0436, -0.0120],
        [-0.0271,  0.0018, -0.0035,  ...,  0.0078,  0.0142,  0.0056]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.1777, -0.7798,  1.2246,  ...,  1.5898,  1.8848, -1.8467]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 23:25:45 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of predictable is unpredictable
The opposite of lawful is unlawful
The opposite of specified is unspecified
The opposite of veiled is unveiled
The opposite of authorized is unauthorized
The opposite of comfortable is uncomfortable
The opposite of identified is unidentified
The opposite of controlled is
2024-07-30 23:25:46 root INFO     [order_1_approx] starting weight calculation for The opposite of identified is unidentified
The opposite of veiled is unveiled
The opposite of predictable is unpredictable
The opposite of lawful is unlawful
The opposite of controlled is uncontrolled
The opposite of comfortable is uncomfortable
The opposite of specified is unspecified
The opposite of authorized is
2024-07-30 23:25:46 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 23:27:40 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0107,  0.1792,  0.0878,  ..., -0.0956,  0.3103, -0.2375],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.4658, -7.8281,  2.9902,  ...,  2.4824, -0.1514,  0.0811],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0596, -0.0072,  0.0086,  ...,  0.0150, -0.0167,  0.0180],
        [ 0.0033,  0.0077,  0.0060,  ...,  0.0082,  0.0247, -0.0257],
        [ 0.0086,  0.0170,  0.0483,  ..., -0.0079, -0.0438,  0.0221],
        ...,
        [ 0.0320,  0.0169,  0.0073,  ...,  0.0466,  0.0199, -0.0385],
        [-0.0159, -0.0081,  0.0103,  ...,  0.0053,  0.0399,  0.0174],
        [ 0.0293,  0.0271,  0.0040,  ..., -0.0335,  0.0235, -0.0021]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.4492, -7.1562,  2.7148,  ...,  2.2461, -0.4163,  0.5195]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 23:27:41 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more specific term for a backpack is daypack
A more specific term for a citrus is lemon
A more specific term for a burger is hamburger
A more specific term for a shoes is sneakers
A more specific term for a season is spring
A more specific term for a oven is broiler
A more specific term for a mixer is blender
A more specific term for a railway is
2024-07-30 23:27:41 root INFO     [order_1_approx] starting weight calculation for A more specific term for a season is spring
A more specific term for a citrus is lemon
A more specific term for a mixer is blender
A more specific term for a oven is broiler
A more specific term for a backpack is daypack
A more specific term for a burger is hamburger
A more specific term for a railway is monorail
A more specific term for a shoes is
2024-07-30 23:27:42 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-30 23:28:20 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1346,  0.1335, -0.2837,  ..., -0.0818,  0.1014,  0.1550],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.2114, -1.8066,  1.8418,  ...,  0.8428, -0.4370, -1.2285],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0557, -0.0086,  0.0068,  ...,  0.0410, -0.0331,  0.0116],
        [-0.0035,  0.0390, -0.0087,  ..., -0.0085,  0.0175, -0.0121],
        [-0.0174, -0.0062,  0.0451,  ...,  0.0380, -0.0331, -0.0044],
        ...,
        [ 0.0223,  0.0175, -0.0007,  ...,  0.0241, -0.0089, -0.0040],
        [-0.0159, -0.0070,  0.0111,  ..., -0.0046,  0.0526, -0.0216],
        [ 0.0064, -0.0120, -0.0117,  ..., -0.0081, -0.0079,  0.0411]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.4016, -1.6152,  1.8066,  ...,  1.0986, -0.6084, -1.5000]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 23:28:21 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of identified is unidentified
The opposite of veiled is unveiled
The opposite of predictable is unpredictable
The opposite of lawful is unlawful
The opposite of controlled is uncontrolled
The opposite of comfortable is uncomfortable
The opposite of specified is unspecified
The opposite of authorized is
2024-07-30 23:28:21 root INFO     [order_1_approx] starting weight calculation for The opposite of identified is unidentified
The opposite of predictable is unpredictable
The opposite of comfortable is uncomfortable
The opposite of lawful is unlawful
The opposite of controlled is uncontrolled
The opposite of veiled is unveiled
The opposite of authorized is unauthorized
The opposite of specified is
2024-07-30 23:28:21 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 23:30:16 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0886, -0.3555,  0.0829,  ...,  0.4504, -0.1821, -0.3091],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 6.3477, -6.9531, -1.1289,  ...,  1.3926,  0.7422,  2.7090],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 3.0899e-03, -2.0203e-02, -1.7609e-02,  ...,  1.3092e-02,
         -1.1650e-02,  4.9744e-03],
        [-1.2230e-02,  2.4872e-02,  3.1071e-03,  ..., -2.1534e-03,
         -4.2686e-03, -2.4857e-02],
        [ 6.0959e-03, -5.1270e-03,  5.0629e-02,  ..., -9.7427e-03,
         -3.3722e-02,  1.8600e-02],
        ...,
        [ 4.8065e-03,  1.6737e-03, -7.1335e-03,  ...,  4.9591e-03,
          4.0092e-03, -1.4715e-03],
        [-8.1406e-03, -1.2100e-02,  3.4752e-03,  ..., -5.3787e-04,
         -6.4850e-05, -6.2332e-03],
        [-5.9013e-03, -6.9122e-03,  1.1047e-02,  ..., -1.8036e-02,
          1.3229e-02,  3.9215e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 6.2891, -6.6367, -1.2461,  ...,  1.6797,  0.5205,  2.6133]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 23:30:18 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more specific term for a season is spring
A more specific term for a citrus is lemon
A more specific term for a mixer is blender
A more specific term for a oven is broiler
A more specific term for a backpack is daypack
A more specific term for a burger is hamburger
A more specific term for a railway is monorail
A more specific term for a shoes is
2024-07-30 23:30:18 root INFO     [order_1_approx] starting weight calculation for A more specific term for a mixer is blender
A more specific term for a backpack is daypack
A more specific term for a shoes is sneakers
A more specific term for a railway is monorail
A more specific term for a oven is broiler
A more specific term for a season is spring
A more specific term for a citrus is lemon
A more specific term for a burger is
2024-07-30 23:30:18 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-30 23:30:55 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2208,  0.1581, -0.3372,  ..., -0.1863, -0.0874,  0.0565],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.5527,  0.9697,  1.0049,  ...,  2.5449,  0.5547, -0.5820],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0613,  0.0187, -0.0111,  ...,  0.0123, -0.0120,  0.0067],
        [-0.0126,  0.0215,  0.0273,  ...,  0.0049,  0.0466, -0.0046],
        [-0.0312,  0.0246, -0.0051,  ...,  0.0249,  0.0064,  0.0225],
        ...,
        [ 0.0013,  0.0165,  0.0055,  ...,  0.0049,  0.0174, -0.0250],
        [ 0.0062,  0.0003,  0.0541,  ...,  0.0190,  0.0419,  0.0032],
        [-0.0260, -0.0081, -0.0077,  ..., -0.0151,  0.0295,  0.0306]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.6826,  0.5859,  1.3330,  ...,  2.5449,  0.0593, -0.6064]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 23:30:56 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of identified is unidentified
The opposite of predictable is unpredictable
The opposite of comfortable is uncomfortable
The opposite of lawful is unlawful
The opposite of controlled is uncontrolled
The opposite of veiled is unveiled
The opposite of authorized is unauthorized
The opposite of specified is
2024-07-30 23:30:56 root INFO     [order_1_approx] starting weight calculation for The opposite of comfortable is uncomfortable
The opposite of specified is unspecified
The opposite of predictable is unpredictable
The opposite of veiled is unveiled
The opposite of controlled is uncontrolled
The opposite of identified is unidentified
The opposite of authorized is unauthorized
The opposite of lawful is
2024-07-30 23:30:56 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 23:32:58 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0229,  0.5420,  0.0605,  ...,  0.1078, -0.2937, -0.1760],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.4248, -4.5938,  1.9717,  ..., -0.6855, -4.6680, -2.8242],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 4.2450e-02,  1.3695e-02, -6.3858e-03,  ...,  6.1951e-03,
         -1.7700e-03, -7.6065e-03],
        [-7.3624e-04,  4.9500e-02, -4.7302e-03,  ...,  6.1035e-05,
          2.5665e-02, -1.0559e-02],
        [ 5.8746e-03, -1.3939e-02,  4.5959e-02,  ..., -4.8523e-03,
          2.4834e-03, -1.4999e-02],
        ...,
        [ 3.3234e-02,  1.7075e-02, -6.4926e-03,  ...,  3.3234e-02,
          2.2964e-03, -2.1439e-02],
        [ 2.3590e-02, -2.1881e-02,  1.2413e-02,  ...,  2.9068e-03,
          4.4342e-02,  4.0817e-04],
        [ 5.6381e-03,  1.0056e-02, -4.4403e-03,  ...,  5.3062e-03,
         -2.0599e-02,  7.0801e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.2180, -4.7773,  2.3125,  ..., -0.3145, -4.6797, -3.3086]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 23:32:59 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more specific term for a mixer is blender
A more specific term for a backpack is daypack
A more specific term for a shoes is sneakers
A more specific term for a railway is monorail
A more specific term for a oven is broiler
A more specific term for a season is spring
A more specific term for a citrus is lemon
A more specific term for a burger is
2024-07-30 23:32:59 root INFO     [order_1_approx] starting weight calculation for A more specific term for a burger is hamburger
A more specific term for a railway is monorail
A more specific term for a backpack is daypack
A more specific term for a citrus is lemon
A more specific term for a oven is broiler
A more specific term for a shoes is sneakers
A more specific term for a season is spring
A more specific term for a mixer is
2024-07-30 23:32:59 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-30 23:33:29 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4324,  0.2181, -0.0804,  ...,  0.0233, -0.1066,  0.0139],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.7158, -2.0605,  1.1982,  ...,  2.7637,  0.0889, -0.5884],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0673, -0.0313, -0.0193,  ...,  0.0457, -0.0171,  0.0149],
        [ 0.0146,  0.0371, -0.0073,  ...,  0.0208,  0.0011,  0.0014],
        [ 0.0177,  0.0215,  0.0143,  ...,  0.0193, -0.0544, -0.0210],
        ...,
        [ 0.0225,  0.0054, -0.0224,  ..., -0.0109,  0.0070, -0.0175],
        [ 0.0057, -0.0101,  0.0504,  ...,  0.0002,  0.0263, -0.0333],
        [-0.0006,  0.0013, -0.0393,  ...,  0.0033, -0.0227,  0.0251]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.1406, -2.4453,  1.3359,  ...,  2.6055, -0.4375, -0.7979]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 23:33:30 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of comfortable is uncomfortable
The opposite of specified is unspecified
The opposite of predictable is unpredictable
The opposite of veiled is unveiled
The opposite of controlled is uncontrolled
The opposite of identified is unidentified
The opposite of authorized is unauthorized
The opposite of lawful is
2024-07-30 23:33:30 root INFO     total operator prediction time: 1240.3678538799286 seconds
2024-07-30 23:33:30 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on verb+able_reg
2024-07-30 23:33:30 root INFO     building operator verb+able_reg
2024-07-30 23:33:30 root INFO     [order_1_approx] starting weight calculation for If you can represent something, that thing is representable
If you can avoid something, that thing is avoidable
If you can recommend something, that thing is recommendable
If you can observe something, that thing is observable
If you can extend something, that thing is extendable
If you can define something, that thing is definable
If you can understand something, that thing is understandable
If you can achieve something, that thing is
2024-07-30 23:33:30 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 23:35:34 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1334, -0.2800,  0.0140,  ...,  0.5586, -0.4858, -0.1857],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.8408, -5.4102, -1.8652,  ...,  0.5557, -2.5586,  0.1758],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0407, -0.0121, -0.0134,  ...,  0.0179, -0.0012, -0.0183],
        [ 0.0343,  0.0446, -0.0045,  ..., -0.0013,  0.0040,  0.0003],
        [-0.0131, -0.0377,  0.0786,  ..., -0.0273,  0.0130,  0.0421],
        ...,
        [ 0.0468,  0.0373, -0.0018,  ...,  0.0841, -0.0223, -0.0382],
        [-0.0601, -0.0059, -0.0381,  ...,  0.0135,  0.0878,  0.0109],
        [ 0.0281,  0.0371,  0.0494,  ..., -0.0216, -0.0395,  0.0199]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.7617, -5.3047, -2.1074,  ...,  0.5977, -2.1758, -0.1909]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 23:35:35 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more specific term for a burger is hamburger
A more specific term for a railway is monorail
A more specific term for a backpack is daypack
A more specific term for a citrus is lemon
A more specific term for a oven is broiler
A more specific term for a shoes is sneakers
A more specific term for a season is spring
A more specific term for a mixer is
2024-07-30 23:35:35 root INFO     [order_1_approx] starting weight calculation for A more specific term for a shoes is sneakers
A more specific term for a backpack is daypack
A more specific term for a season is spring
A more specific term for a burger is hamburger
A more specific term for a mixer is blender
A more specific term for a railway is monorail
A more specific term for a citrus is lemon
A more specific term for a oven is
2024-07-30 23:35:35 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-30 23:36:04 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2278,  0.1830, -0.0293,  ...,  0.1835, -0.3608,  0.1417],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.2441,  0.1709, -1.8066,  ..., -4.2148, -8.6094, -3.4238],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 5.4817e-03,  6.3515e-04, -1.5783e-03,  ...,  1.9653e-02,
         -4.7731e-04,  1.0529e-02],
        [ 1.8435e-03,  1.4183e-02,  6.7596e-03,  ...,  6.4392e-03,
         -1.2115e-02, -1.1383e-02],
        [ 1.9623e-02, -1.9379e-02,  8.0643e-03,  ..., -7.7605e-05,
         -7.0992e-03,  6.2447e-03],
        ...,
        [ 6.6185e-03,  9.8267e-03,  9.7961e-03,  ...,  6.8359e-03,
          1.4999e-02, -1.1642e-02],
        [ 2.9404e-02,  3.1677e-02,  2.4223e-04,  ..., -1.6174e-02,
          1.3092e-02,  5.3596e-04],
        [ 8.9874e-03,  8.9951e-03, -4.0932e-03,  ..., -5.5580e-03,
         -2.3544e-02,  9.5901e-03]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.2878, -0.1062, -1.6670,  ..., -3.9727, -8.8828, -3.2461]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 23:36:05 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you can represent something, that thing is representable
If you can avoid something, that thing is avoidable
If you can recommend something, that thing is recommendable
If you can observe something, that thing is observable
If you can extend something, that thing is extendable
If you can define something, that thing is definable
If you can understand something, that thing is understandable
If you can achieve something, that thing is
2024-07-30 23:36:05 root INFO     [order_1_approx] starting weight calculation for If you can extend something, that thing is extendable
If you can recommend something, that thing is recommendable
If you can define something, that thing is definable
If you can achieve something, that thing is achieveable
If you can avoid something, that thing is avoidable
If you can represent something, that thing is representable
If you can observe something, that thing is observable
If you can understand something, that thing is
2024-07-30 23:36:05 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 23:38:10 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0858, -0.1829, -0.0972,  ..., -0.0804, -0.3047,  0.0049],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.4297, -4.3281,  2.7988,  ..., -3.2363, -2.8750,  2.5898],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0172, -0.0271, -0.0172,  ...,  0.0134, -0.0130,  0.0223],
        [ 0.0091,  0.0502, -0.0024,  ..., -0.0097,  0.0400, -0.0086],
        [-0.0613, -0.0184,  0.0457,  ..., -0.0028,  0.0246, -0.0114],
        ...,
        [-0.0259,  0.0081,  0.0025,  ...,  0.0422, -0.0034, -0.0045],
        [-0.0307, -0.0099,  0.0011,  ...,  0.0079,  0.0610, -0.0291],
        [-0.0133, -0.0052, -0.0006,  ..., -0.0153, -0.0153,  0.0244]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.0742, -4.0586,  2.8555,  ..., -2.8418, -2.3125,  2.6719]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 23:38:15 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more specific term for a shoes is sneakers
A more specific term for a backpack is daypack
A more specific term for a season is spring
A more specific term for a burger is hamburger
A more specific term for a mixer is blender
A more specific term for a railway is monorail
A more specific term for a citrus is lemon
A more specific term for a oven is
2024-07-30 23:38:17 root INFO     [order_1_approx] starting weight calculation for A more specific term for a mixer is blender
A more specific term for a burger is hamburger
A more specific term for a shoes is sneakers
A more specific term for a backpack is daypack
A more specific term for a citrus is lemon
A more specific term for a railway is monorail
A more specific term for a oven is broiler
A more specific term for a season is
2024-07-30 23:38:17 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-30 23:38:39 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1072,  0.4036,  0.0569,  ...,  0.3730,  0.0288,  0.0024],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.0664,  1.7930,  2.3555,  ..., -2.7715, -7.2344,  0.7988],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 9.3231e-03,  5.0735e-04,  3.9749e-03,  ...,  1.6031e-03,
         -7.7095e-03,  8.6746e-03],
        [ 1.1826e-03,  1.5228e-02,  2.6993e-02,  ...,  6.5079e-03,
          1.2207e-03,  9.5825e-03],
        [ 1.3214e-02,  1.2321e-03,  9.7351e-03,  ..., -9.3994e-03,
          1.6088e-03, -4.9820e-03],
        ...,
        [ 5.5161e-03,  1.8311e-03,  2.3773e-02,  ...,  1.7319e-02,
          7.9727e-04, -2.2678e-03],
        [ 1.2531e-03,  6.3858e-03,  2.2240e-03,  ..., -4.9553e-03,
         -1.8845e-03, -1.0658e-02],
        [ 1.0284e-02,  1.3638e-04,  1.2878e-02,  ...,  6.8665e-05,
         -1.7227e-02, -1.4511e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.4717,  1.5117,  2.7109,  ..., -2.7109, -7.1875,  0.9214]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 23:38:40 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you can extend something, that thing is extendable
If you can recommend something, that thing is recommendable
If you can define something, that thing is definable
If you can achieve something, that thing is achieveable
If you can avoid something, that thing is avoidable
If you can represent something, that thing is representable
If you can observe something, that thing is observable
If you can understand something, that thing is
2024-07-30 23:38:40 root INFO     [order_1_approx] starting weight calculation for If you can achieve something, that thing is achieveable
If you can observe something, that thing is observable
If you can understand something, that thing is understandable
If you can represent something, that thing is representable
If you can recommend something, that thing is recommendable
If you can avoid something, that thing is avoidable
If you can extend something, that thing is extendable
If you can define something, that thing is
2024-07-30 23:38:40 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 23:40:58 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.4556,  0.2573,  0.0847,  ..., -0.2057, -0.0587, -0.2108],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.8984, -4.3555,  1.1816,  ...,  3.4004, -1.5156, -1.7119],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0073,  0.0165, -0.0156,  ..., -0.0018, -0.0046,  0.0166],
        [ 0.0212,  0.0299, -0.0008,  ...,  0.0161,  0.0176,  0.0218],
        [-0.0611,  0.0008,  0.0624,  ..., -0.0364,  0.0023, -0.0022],
        ...,
        [-0.0148, -0.0137,  0.0023,  ...,  0.0308,  0.0068, -0.0016],
        [-0.0371, -0.0175,  0.0252,  ..., -0.0249,  0.0461,  0.0183],
        [ 0.0229,  0.0124, -0.0301,  ...,  0.0350,  0.0309,  0.0528]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.1250, -4.6055,  0.2603,  ...,  3.1426, -2.0371, -1.1055]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 23:40:59 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more specific term for a mixer is blender
A more specific term for a burger is hamburger
A more specific term for a shoes is sneakers
A more specific term for a backpack is daypack
A more specific term for a citrus is lemon
A more specific term for a railway is monorail
A more specific term for a oven is broiler
A more specific term for a season is
2024-07-30 23:40:59 root INFO     [order_1_approx] starting weight calculation for A more specific term for a railway is monorail
A more specific term for a citrus is lemon
A more specific term for a mixer is blender
A more specific term for a shoes is sneakers
A more specific term for a oven is broiler
A more specific term for a season is spring
A more specific term for a burger is hamburger
A more specific term for a backpack is
2024-07-30 23:40:59 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-30 23:41:11 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3677, -0.0772,  0.2244,  ...,  0.2861, -0.0310, -0.1638],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.8604, -0.2988,  3.7891,  ..., -2.9141, -8.5234, -2.2891],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0285,  0.0035, -0.0055,  ...,  0.0016, -0.0045,  0.0089],
        [-0.0136,  0.0364,  0.0385,  ..., -0.0048, -0.0129, -0.0047],
        [ 0.0013,  0.0015,  0.0331,  ..., -0.0053,  0.0162, -0.0015],
        ...,
        [ 0.0232,  0.0234,  0.0199,  ...,  0.0279,  0.0098,  0.0096],
        [ 0.0140, -0.0040, -0.0013,  ..., -0.0077,  0.0247,  0.0072],
        [-0.0211,  0.0051,  0.0287,  ..., -0.0270, -0.0194,  0.0251]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.2676, -0.1292,  3.9180,  ..., -3.0547, -8.5859, -2.1895]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 23:41:12 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you can achieve something, that thing is achieveable
If you can observe something, that thing is observable
If you can understand something, that thing is understandable
If you can represent something, that thing is representable
If you can recommend something, that thing is recommendable
If you can avoid something, that thing is avoidable
If you can extend something, that thing is extendable
If you can define something, that thing is
2024-07-30 23:41:12 root INFO     [order_1_approx] starting weight calculation for If you can achieve something, that thing is achieveable
If you can understand something, that thing is understandable
If you can define something, that thing is definable
If you can recommend something, that thing is recommendable
If you can observe something, that thing is observable
If you can avoid something, that thing is avoidable
If you can represent something, that thing is representable
If you can extend something, that thing is
2024-07-30 23:41:12 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 23:43:33 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0458, -0.1165,  0.2098,  ...,  0.2505, -0.4912, -0.1350],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.9277, -3.6719, -0.7798,  ...,  1.3047,  2.1504,  0.0947],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 6.6650e-02,  1.2405e-02, -6.5613e-03,  ...,  1.2898e-04,
         -5.7678e-03,  1.6754e-02],
        [-1.6098e-02,  4.7272e-02, -2.3010e-02,  ..., -1.2375e-02,
          8.8730e-03, -2.8229e-02],
        [-2.6665e-03,  1.0651e-02,  2.8259e-02,  ..., -7.6294e-06,
         -5.6915e-03,  1.4145e-02],
        ...,
        [ 2.1530e-02,  1.0941e-02, -2.8397e-02,  ...,  2.9709e-02,
         -2.5024e-02, -2.4063e-02],
        [-1.1353e-02, -1.4143e-03,  1.3046e-02,  ..., -3.6373e-03,
          2.0630e-02, -9.6741e-03],
        [-1.1864e-02,  1.1269e-02,  2.1927e-02,  ..., -8.5907e-03,
         -1.8723e-02,  5.4321e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.9238, -3.3418, -0.8481,  ...,  1.7158,  2.2930, -0.1041]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 23:43:34 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more specific term for a railway is monorail
A more specific term for a citrus is lemon
A more specific term for a mixer is blender
A more specific term for a shoes is sneakers
A more specific term for a oven is broiler
A more specific term for a season is spring
A more specific term for a burger is hamburger
A more specific term for a backpack is
2024-07-30 23:43:34 root INFO     total operator prediction time: 1273.5441195964813 seconds
2024-07-30 23:43:34 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on hypernyms - animals
2024-07-30 23:43:34 root INFO     building operator hypernyms - animals
2024-07-30 23:43:34 root INFO     [order_1_approx] starting weight calculation for The goat falls into the category of bovid
The stegosaurus falls into the category of dinosaur
The gorilla falls into the category of primate
The eagle falls into the category of raptor
The hawk falls into the category of raptor
The tyrannosaurus falls into the category of dinosaur
The orangutan falls into the category of primate
The goose falls into the category of
2024-07-30 23:43:34 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-30 23:43:43 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0590, -0.1385, -0.1198,  ...,  0.0284, -0.2471,  0.3867],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.8008, -1.0215, -1.4170,  ..., -3.7695, -8.7266, -4.2305],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0004,  0.0080, -0.0158,  ...,  0.0239, -0.0114,  0.0293],
        [-0.0220,  0.0521,  0.0201,  ...,  0.0089,  0.0006, -0.0038],
        [ 0.0120,  0.0007,  0.0451,  ...,  0.0104,  0.0167, -0.0046],
        ...,
        [ 0.0015,  0.0316,  0.0182,  ...,  0.0437,  0.0087,  0.0137],
        [ 0.0309, -0.0124, -0.0224,  ..., -0.0092,  0.0135, -0.0053],
        [ 0.0033,  0.0002, -0.0069,  ..., -0.0235, -0.0178,  0.0091]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.1562, -1.0996, -1.1807,  ..., -3.8867, -8.5703, -4.1680]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 23:43:44 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you can achieve something, that thing is achieveable
If you can understand something, that thing is understandable
If you can define something, that thing is definable
If you can recommend something, that thing is recommendable
If you can observe something, that thing is observable
If you can avoid something, that thing is avoidable
If you can represent something, that thing is representable
If you can extend something, that thing is
2024-07-30 23:43:44 root INFO     [order_1_approx] starting weight calculation for If you can recommend something, that thing is recommendable
If you can represent something, that thing is representable
If you can avoid something, that thing is avoidable
If you can achieve something, that thing is achieveable
If you can understand something, that thing is understandable
If you can define something, that thing is definable
If you can extend something, that thing is extendable
If you can observe something, that thing is
2024-07-30 23:43:44 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 23:46:07 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1172, -0.3274,  0.0198,  ...,  0.2247, -0.1931, -0.0378],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.7070, -2.3262,  3.4180,  ..., -1.1445, -8.5469,  0.4941],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0398, -0.0071, -0.0305,  ..., -0.0184, -0.0239, -0.0091],
        [ 0.0363,  0.0386,  0.0075,  ...,  0.0263,  0.0063,  0.0009],
        [ 0.0049, -0.0045,  0.0587,  ...,  0.0007, -0.0461, -0.0238],
        ...,
        [ 0.0398,  0.0170,  0.0135,  ...,  0.0583,  0.0070,  0.0081],
        [ 0.0051,  0.0080,  0.0058,  ...,  0.0180,  0.0578,  0.0004],
        [ 0.0210, -0.0195,  0.0019,  ..., -0.0281,  0.0224,  0.0473]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.0176, -2.2891,  3.0938,  ..., -1.2432, -8.8281,  0.9307]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 23:46:08 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The goat falls into the category of bovid
The stegosaurus falls into the category of dinosaur
The gorilla falls into the category of primate
The eagle falls into the category of raptor
The hawk falls into the category of raptor
The tyrannosaurus falls into the category of dinosaur
The orangutan falls into the category of primate
The goose falls into the category of
2024-07-30 23:46:08 root INFO     [order_1_approx] starting weight calculation for The hawk falls into the category of raptor
The gorilla falls into the category of primate
The eagle falls into the category of raptor
The goat falls into the category of bovid
The orangutan falls into the category of primate
The stegosaurus falls into the category of dinosaur
The goose falls into the category of fowl
The tyrannosaurus falls into the category of
2024-07-30 23:46:08 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-30 23:46:17 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1376,  0.3906, -0.0371,  ...,  0.1273, -0.1184, -0.1527],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-2.9688, -1.9326, -1.0801,  ..., -3.9844, -6.1094, -0.6807],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0514,  0.0020, -0.0129,  ...,  0.0095, -0.0077,  0.0135],
        [ 0.0032,  0.0410,  0.0036,  ...,  0.0108, -0.0058, -0.0066],
        [ 0.0049, -0.0110,  0.0280,  ...,  0.0069, -0.0141, -0.0097],
        ...,
        [ 0.0191,  0.0103, -0.0048,  ...,  0.0516, -0.0010, -0.0106],
        [ 0.0078,  0.0029, -0.0144,  ..., -0.0122,  0.0282,  0.0045],
        [-0.0029, -0.0013,  0.0051,  ...,  0.0052, -0.0230,  0.0099]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-2.9180, -1.8975, -1.4395,  ..., -3.8496, -5.6992, -0.4971]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 23:46:18 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you can recommend something, that thing is recommendable
If you can represent something, that thing is representable
If you can avoid something, that thing is avoidable
If you can achieve something, that thing is achieveable
If you can understand something, that thing is understandable
If you can define something, that thing is definable
If you can extend something, that thing is extendable
If you can observe something, that thing is
2024-07-30 23:46:18 root INFO     [order_1_approx] starting weight calculation for If you can define something, that thing is definable
If you can extend something, that thing is extendable
If you can recommend something, that thing is recommendable
If you can understand something, that thing is understandable
If you can achieve something, that thing is achieveable
If you can avoid something, that thing is avoidable
If you can observe something, that thing is observable
If you can represent something, that thing is
2024-07-30 23:46:18 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 23:48:46 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0707, -0.2174, -0.5010,  ...,  0.0843, -0.2408,  0.1143],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.3926, -2.0762,  1.3584,  ..., -2.4375, -5.7148, -2.0840],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0275, -0.0338,  0.0134,  ...,  0.0063,  0.0109,  0.0056],
        [-0.0004,  0.0126,  0.0035,  ..., -0.0016, -0.0038,  0.0066],
        [ 0.0006,  0.0013, -0.0017,  ..., -0.0213, -0.0179, -0.0082],
        ...,
        [ 0.0054,  0.0019,  0.0049,  ...,  0.0341, -0.0001,  0.0064],
        [-0.0156,  0.0083, -0.0087,  ...,  0.0184,  0.0203,  0.0058],
        [ 0.0053, -0.0269,  0.0053,  ...,  0.0042,  0.0063,  0.0316]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.2852, -1.9756,  1.2832,  ..., -2.4238, -6.0469, -1.9033]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 23:48:47 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The hawk falls into the category of raptor
The gorilla falls into the category of primate
The eagle falls into the category of raptor
The goat falls into the category of bovid
The orangutan falls into the category of primate
The stegosaurus falls into the category of dinosaur
The goose falls into the category of fowl
The tyrannosaurus falls into the category of
2024-07-30 23:48:47 root INFO     [order_1_approx] starting weight calculation for The goat falls into the category of bovid
The tyrannosaurus falls into the category of dinosaur
The hawk falls into the category of raptor
The stegosaurus falls into the category of dinosaur
The eagle falls into the category of raptor
The orangutan falls into the category of primate
The goose falls into the category of fowl
The gorilla falls into the category of
2024-07-30 23:48:48 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-30 23:48:51 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0766,  0.1658, -0.1302,  ...,  0.1812,  0.0033, -0.1504],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-2.5039,  2.4238,  1.0820,  ..., -2.5742, -7.9102, -1.1963],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0205,  0.0008,  0.0037,  ..., -0.0044,  0.0004, -0.0010],
        [-0.0064,  0.0562,  0.0069,  ..., -0.0063, -0.0034, -0.0082],
        [ 0.0096,  0.0010,  0.0074,  ..., -0.0046,  0.0004, -0.0024],
        ...,
        [ 0.0058,  0.0203,  0.0037,  ...,  0.0449,  0.0065,  0.0039],
        [ 0.0077, -0.0051, -0.0054,  ..., -0.0169,  0.0192, -0.0033],
        [-0.0144, -0.0047,  0.0052,  ..., -0.0034, -0.0034,  0.0212]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-2.9902,  2.4434,  1.1172,  ..., -2.6230, -7.9219, -1.1143]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 23:48:52 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you can define something, that thing is definable
If you can extend something, that thing is extendable
If you can recommend something, that thing is recommendable
If you can understand something, that thing is understandable
If you can achieve something, that thing is achieveable
If you can avoid something, that thing is avoidable
If you can observe something, that thing is observable
If you can represent something, that thing is
2024-07-30 23:48:52 root INFO     [order_1_approx] starting weight calculation for If you can extend something, that thing is extendable
If you can understand something, that thing is understandable
If you can recommend something, that thing is recommendable
If you can observe something, that thing is observable
If you can define something, that thing is definable
If you can represent something, that thing is representable
If you can achieve something, that thing is achieveable
If you can avoid something, that thing is
2024-07-30 23:48:52 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 23:51:24 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1801,  0.3999, -0.0980,  ...,  0.1157,  0.1929,  0.1848],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.2676, -0.2461, -3.2109,  ..., -0.9204, -6.6797, -1.8359],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0305,  0.0017,  0.0042,  ...,  0.0191,  0.0156,  0.0030],
        [ 0.0011,  0.0291,  0.0093,  ..., -0.0053,  0.0115,  0.0055],
        [ 0.0273, -0.0138,  0.0248,  ...,  0.0003, -0.0138,  0.0055],
        ...,
        [ 0.0242,  0.0175,  0.0147,  ...,  0.0247, -0.0277,  0.0013],
        [ 0.0119,  0.0156, -0.0014,  ...,  0.0018,  0.0164, -0.0025],
        [-0.0026,  0.0073,  0.0245,  ..., -0.0235, -0.0275, -0.0056]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.1084, -0.8271, -3.2246,  ..., -0.9941, -6.9297, -1.9131]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 23:51:26 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you can extend something, that thing is extendable
If you can understand something, that thing is understandable
If you can recommend something, that thing is recommendable
If you can observe something, that thing is observable
If you can define something, that thing is definable
If you can represent something, that thing is representable
If you can achieve something, that thing is achieveable
If you can avoid something, that thing is
2024-07-30 23:51:26 root INFO     [order_1_approx] starting weight calculation for If you can observe something, that thing is observable
If you can achieve something, that thing is achieveable
If you can represent something, that thing is representable
If you can understand something, that thing is understandable
If you can extend something, that thing is extendable
If you can avoid something, that thing is avoidable
If you can define something, that thing is definable
If you can recommend something, that thing is
2024-07-30 23:51:26 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 23:51:28 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1281, -0.2300, -0.1404,  ...,  0.0485, -0.5239,  0.1014],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.0312, -4.9727,  0.4561,  ..., -2.8418, -8.2969,  1.2646],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0196, -0.0011,  0.0065,  ..., -0.0051, -0.0139,  0.0155],
        [ 0.0121,  0.0211, -0.0045,  ..., -0.0070,  0.0253, -0.0088],
        [ 0.0084,  0.0105,  0.0273,  ..., -0.0301,  0.0021, -0.0312],
        ...,
        [ 0.0028,  0.0240, -0.0091,  ...,  0.0250,  0.0085,  0.0039],
        [ 0.0112, -0.0207,  0.0133,  ...,  0.0020,  0.0334, -0.0080],
        [-0.0227, -0.0052, -0.0194,  ..., -0.0143,  0.0198,  0.0287]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.6055, -5.0234,  0.5645,  ..., -3.0723, -8.4375,  1.2393]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 23:51:29 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The goat falls into the category of bovid
The tyrannosaurus falls into the category of dinosaur
The hawk falls into the category of raptor
The stegosaurus falls into the category of dinosaur
The eagle falls into the category of raptor
The orangutan falls into the category of primate
The goose falls into the category of fowl
The gorilla falls into the category of
2024-07-30 23:51:29 root INFO     [order_1_approx] starting weight calculation for The goat falls into the category of bovid
The stegosaurus falls into the category of dinosaur
The tyrannosaurus falls into the category of dinosaur
The goose falls into the category of fowl
The gorilla falls into the category of primate
The hawk falls into the category of raptor
The orangutan falls into the category of primate
The eagle falls into the category of
2024-07-30 23:51:29 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-30 23:53:54 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0116,  0.4014,  0.0632,  ...,  0.4890, -0.0564,  0.0235],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.1201,  0.9419, -0.6943,  ..., -1.2744, -8.5156, -4.0469],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0251, -0.0074, -0.0030,  ...,  0.0226, -0.0205,  0.0310],
        [ 0.0025,  0.0086, -0.0139,  ...,  0.0060, -0.0072,  0.0244],
        [ 0.0281, -0.0030,  0.0226,  ...,  0.0011,  0.0003, -0.0241],
        ...,
        [ 0.0267,  0.0130, -0.0087,  ...,  0.0495,  0.0097,  0.0257],
        [ 0.0172,  0.0235, -0.0105,  ..., -0.0224, -0.0096, -0.0144],
        [ 0.0026, -0.0117, -0.0026,  ..., -0.0121, -0.0032,  0.0314]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.3091,  1.1904, -0.8882,  ..., -1.0391, -8.0547, -4.4805]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 23:53:55 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you can observe something, that thing is observable
If you can achieve something, that thing is achieveable
If you can represent something, that thing is representable
If you can understand something, that thing is understandable
If you can extend something, that thing is extendable
If you can avoid something, that thing is avoidable
If you can define something, that thing is definable
If you can recommend something, that thing is
2024-07-30 23:53:55 root INFO     total operator prediction time: 1224.3572895526886 seconds
2024-07-30 23:53:55 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on verb+tion_irreg
2024-07-30 23:53:55 root INFO     building operator verb+tion_irreg
2024-07-30 23:53:55 root INFO     [order_1_approx] starting weight calculation for To improvize results in improvization
To continue results in continuation
To determine results in determination
To perspire results in perspiration
To randomize results in randomization
To minimize results in minimization
To restore results in restoration
To declare results in
2024-07-30 23:53:55 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 23:54:11 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2297, -0.1416, -0.2084,  ...,  0.0424, -0.2014, -0.2035],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.1504, -2.6875,  0.8262,  ..., -0.8091, -5.4023,  0.3242],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0592,  0.0006, -0.0359,  ..., -0.0257, -0.0249, -0.0025],
        [ 0.0067,  0.0374,  0.0152,  ...,  0.0208,  0.0083, -0.0077],
        [ 0.0086,  0.0027,  0.0383,  ..., -0.0180, -0.0247, -0.0371],
        ...,
        [ 0.0191,  0.0262,  0.0187,  ...,  0.0471, -0.0114, -0.0034],
        [-0.0017, -0.0127,  0.0206,  ...,  0.0428,  0.0370,  0.0102],
        [ 0.0016, -0.0239,  0.0056,  ..., -0.0490, -0.0021,  0.0361]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.2559, -2.5273,  0.1636,  ..., -0.4185, -5.1055,  0.1420]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 23:54:12 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The goat falls into the category of bovid
The stegosaurus falls into the category of dinosaur
The tyrannosaurus falls into the category of dinosaur
The goose falls into the category of fowl
The gorilla falls into the category of primate
The hawk falls into the category of raptor
The orangutan falls into the category of primate
The eagle falls into the category of
2024-07-30 23:54:13 root INFO     [order_1_approx] starting weight calculation for The stegosaurus falls into the category of dinosaur
The eagle falls into the category of raptor
The gorilla falls into the category of primate
The goose falls into the category of fowl
The hawk falls into the category of raptor
The orangutan falls into the category of primate
The tyrannosaurus falls into the category of dinosaur
The goat falls into the category of
2024-07-30 23:54:13 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-30 23:56:26 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1608,  0.1855, -0.3638,  ...,  0.1093, -0.3325, -0.0273],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.6348, -5.0859,  3.5391,  ...,  2.3672, -4.1719,  0.3672],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0768,  0.0371, -0.0043,  ..., -0.0044,  0.0161,  0.0058],
        [-0.0220,  0.0089, -0.0044,  ...,  0.0269, -0.0395,  0.0288],
        [ 0.0018,  0.0208,  0.0327,  ..., -0.0066,  0.0163, -0.0245],
        ...,
        [-0.0127,  0.0133, -0.0141,  ...,  0.0581, -0.0200,  0.0082],
        [ 0.0115,  0.0058,  0.0040,  ...,  0.0264,  0.0619,  0.0141],
        [ 0.0126, -0.0037, -0.0084,  ...,  0.0111, -0.0309,  0.0519]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.1738, -4.2617,  2.3320,  ...,  2.4980, -3.6523, -0.2700]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 23:56:28 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To improvize results in improvization
To continue results in continuation
To determine results in determination
To perspire results in perspiration
To randomize results in randomization
To minimize results in minimization
To restore results in restoration
To declare results in
2024-07-30 23:56:28 root INFO     [order_1_approx] starting weight calculation for To randomize results in randomization
To restore results in restoration
To minimize results in minimization
To determine results in determination
To perspire results in perspiration
To improvize results in improvization
To declare results in declaration
To continue results in
2024-07-30 23:56:28 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 23:56:51 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1197, -0.2756, -0.0846,  ...,  0.1797, -0.2225,  0.1772],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.5947, -4.7266,  1.7686,  ..., -0.8516, -6.6094, -1.5996],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0565,  0.0204, -0.0005,  ..., -0.0042, -0.0140, -0.0096],
        [ 0.0086,  0.0380, -0.0051,  ...,  0.0179, -0.0041, -0.0030],
        [ 0.0054,  0.0157,  0.0315,  ..., -0.0075,  0.0073, -0.0105],
        ...,
        [-0.0014,  0.0279, -0.0070,  ...,  0.0231, -0.0001,  0.0249],
        [-0.0146,  0.0042, -0.0033,  ...,  0.0026,  0.0723,  0.0083],
        [ 0.0106, -0.0086, -0.0151,  ..., -0.0304,  0.0219,  0.0635]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.2837, -4.5117,  1.0381,  ..., -0.7422, -6.5938, -1.2900]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 23:56:52 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The stegosaurus falls into the category of dinosaur
The eagle falls into the category of raptor
The gorilla falls into the category of primate
The goose falls into the category of fowl
The hawk falls into the category of raptor
The orangutan falls into the category of primate
The tyrannosaurus falls into the category of dinosaur
The goat falls into the category of
2024-07-30 23:56:52 root INFO     [order_1_approx] starting weight calculation for The hawk falls into the category of raptor
The orangutan falls into the category of primate
The tyrannosaurus falls into the category of dinosaur
The gorilla falls into the category of primate
The goat falls into the category of bovid
The goose falls into the category of fowl
The eagle falls into the category of raptor
The stegosaurus falls into the category of
2024-07-30 23:56:52 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-30 23:59:01 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0661, -0.0910, -0.4858,  ..., -0.1484, -0.3301,  0.2188],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.2500, -7.8125,  1.3027,  ...,  0.8296, -0.7266, -2.4844],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0511,  0.0008, -0.0037,  ...,  0.0071,  0.0063,  0.0188],
        [ 0.0050,  0.0396,  0.0128,  ...,  0.0287, -0.0201,  0.0138],
        [ 0.0049, -0.0185,  0.0174,  ..., -0.0010, -0.0073, -0.0032],
        ...,
        [ 0.0077,  0.0165,  0.0157,  ...,  0.0394,  0.0032,  0.0034],
        [-0.0188,  0.0007, -0.0021,  ..., -0.0067,  0.0112, -0.0468],
        [ 0.0034, -0.0211,  0.0195,  ...,  0.0057, -0.0236,  0.0626]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.3320, -7.6133,  1.2842,  ...,  1.0381, -0.7524, -2.7012]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 23:59:02 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To randomize results in randomization
To restore results in restoration
To minimize results in minimization
To determine results in determination
To perspire results in perspiration
To improvize results in improvization
To declare results in declaration
To continue results in
2024-07-30 23:59:02 root INFO     [order_1_approx] starting weight calculation for To perspire results in perspiration
To declare results in declaration
To continue results in continuation
To determine results in determination
To randomize results in randomization
To restore results in restoration
To improvize results in improvization
To minimize results in
2024-07-30 23:59:02 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-30 23:59:31 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0605, -0.3711, -0.5410,  ...,  0.1697, -0.4167, -0.0221],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.0898, -2.9570,  2.0039,  ..., -2.1035, -3.9844, -2.6387],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0219, -0.0020, -0.0025,  ...,  0.0114, -0.0029, -0.0004],
        [ 0.0052,  0.0038,  0.0171,  ...,  0.0185, -0.0061, -0.0172],
        [-0.0011,  0.0036,  0.0043,  ..., -0.0314, -0.0123,  0.0075],
        ...,
        [ 0.0160, -0.0120,  0.0088,  ...,  0.0422,  0.0011,  0.0088],
        [-0.0107, -0.0038,  0.0011,  ...,  0.0025,  0.0229,  0.0043],
        [ 0.0249, -0.0140,  0.0170,  ...,  0.0240, -0.0080,  0.0316]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.7788, -2.8164,  2.1016,  ..., -1.6289, -3.8105, -2.4551]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 23:59:32 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The hawk falls into the category of raptor
The orangutan falls into the category of primate
The tyrannosaurus falls into the category of dinosaur
The gorilla falls into the category of primate
The goat falls into the category of bovid
The goose falls into the category of fowl
The eagle falls into the category of raptor
The stegosaurus falls into the category of
2024-07-30 23:59:32 root INFO     [order_1_approx] starting weight calculation for The hawk falls into the category of raptor
The gorilla falls into the category of primate
The goose falls into the category of fowl
The eagle falls into the category of raptor
The tyrannosaurus falls into the category of dinosaur
The goat falls into the category of bovid
The stegosaurus falls into the category of dinosaur
The orangutan falls into the category of
2024-07-30 23:59:32 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-31 00:01:35 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0977, -0.1003, -0.3052,  ..., -0.2639,  0.1730, -0.0703],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.1377, -1.3301,  1.9834,  ..., -0.9434, -2.6855, -2.8945],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 2.9816e-02,  7.2250e-03, -5.2490e-02,  ..., -6.7078e-02,
          2.4414e-04,  1.9379e-02],
        [ 3.6831e-03,  2.8809e-02,  3.0502e-02,  ...,  4.6356e-02,
         -1.1024e-02, -9.9792e-03],
        [-1.0956e-02, -1.1574e-02,  1.9714e-02,  ..., -1.2955e-02,
         -4.5853e-03,  3.9444e-03],
        ...,
        [-9.5062e-03, -9.9182e-05,  2.3899e-03,  ...,  6.7017e-02,
         -6.6261e-03,  1.0193e-02],
        [-5.0583e-03,  1.6212e-04,  2.2964e-03,  ...,  9.4299e-03,
          4.3854e-02, -5.4131e-03],
        [-1.0368e-02,  5.6915e-03,  8.6441e-03,  ...,  3.5229e-03,
         -1.6602e-02,  3.3142e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.8765, -0.8462,  1.9131,  ..., -0.4048, -2.8496, -2.6797]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 00:01:35 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To perspire results in perspiration
To declare results in declaration
To continue results in continuation
To determine results in determination
To randomize results in randomization
To restore results in restoration
To improvize results in improvization
To minimize results in
2024-07-31 00:01:36 root INFO     [order_1_approx] starting weight calculation for To minimize results in minimization
To restore results in restoration
To improvize results in improvization
To continue results in continuation
To declare results in declaration
To randomize results in randomization
To determine results in determination
To perspire results in
2024-07-31 00:01:36 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-31 00:02:04 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2502, -0.4326, -0.1685,  ...,  0.0548, -0.3276, -0.2307],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.3037, -3.8594,  0.0596,  ..., -4.0195, -6.8047,  1.5098],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0197, -0.0068,  0.0029,  ..., -0.0014, -0.0086,  0.0041],
        [ 0.0107,  0.0106,  0.0026,  ..., -0.0053,  0.0174,  0.0009],
        [-0.0015, -0.0034,  0.0125,  ..., -0.0046, -0.0052, -0.0059],
        ...,
        [ 0.0049, -0.0041, -0.0094,  ...,  0.0074,  0.0053,  0.0087],
        [-0.0056, -0.0068, -0.0017,  ...,  0.0071,  0.0178,  0.0005],
        [ 0.0078, -0.0005, -0.0029,  ..., -0.0029,  0.0019,  0.0098]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.2344, -3.6289, -0.0854,  ..., -4.0352, -6.8594,  1.6865]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 00:02:05 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The hawk falls into the category of raptor
The gorilla falls into the category of primate
The goose falls into the category of fowl
The eagle falls into the category of raptor
The tyrannosaurus falls into the category of dinosaur
The goat falls into the category of bovid
The stegosaurus falls into the category of dinosaur
The orangutan falls into the category of
2024-07-31 00:02:05 root INFO     [order_1_approx] starting weight calculation for The stegosaurus falls into the category of dinosaur
The goat falls into the category of bovid
The gorilla falls into the category of primate
The tyrannosaurus falls into the category of dinosaur
The goose falls into the category of fowl
The orangutan falls into the category of primate
The eagle falls into the category of raptor
The hawk falls into the category of
2024-07-31 00:02:05 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-31 00:04:02 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1415, -0.1659, -0.7954,  ..., -0.2559, -0.3057, -0.2690],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.8281, -5.3203,  0.5337,  ..., -1.3652, -1.9365, -0.3223],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0422,  0.0098, -0.0112,  ..., -0.0245,  0.0114, -0.0070],
        [-0.0055,  0.0609,  0.0189,  ...,  0.0507, -0.0225,  0.0259],
        [ 0.0069,  0.0169,  0.0496,  ...,  0.0020, -0.0083, -0.0040],
        ...,
        [ 0.0038, -0.0057, -0.0141,  ...,  0.0685,  0.0009,  0.0111],
        [-0.0320, -0.0159, -0.0096,  ..., -0.0166,  0.0356, -0.0143],
        [ 0.0053, -0.0133,  0.0011,  ...,  0.0325, -0.0154,  0.0736]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.7305, -5.2344,  0.0598,  ..., -1.1494, -1.6553, -0.2927]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 00:04:03 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To minimize results in minimization
To restore results in restoration
To improvize results in improvization
To continue results in continuation
To declare results in declaration
To randomize results in randomization
To determine results in determination
To perspire results in
2024-07-31 00:04:03 root INFO     [order_1_approx] starting weight calculation for To declare results in declaration
To continue results in continuation
To improvize results in improvization
To determine results in determination
To perspire results in perspiration
To minimize results in minimization
To randomize results in randomization
To restore results in
2024-07-31 00:04:03 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-31 00:04:46 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0304, -0.0875,  0.0612,  ...,  0.1597, -0.1106, -0.3184],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.1904, -3.1914,  2.2344,  ..., -0.9097, -4.2188,  0.4062],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 2.1301e-02,  3.3760e-03, -1.0422e-02,  ...,  4.1733e-03,
         -1.7548e-02, -6.3248e-03],
        [ 5.2719e-03,  2.6581e-02, -3.2654e-03,  ..., -1.7643e-04,
          5.9938e-04,  8.3466e-03],
        [ 2.6417e-03,  3.5143e-04,  2.2354e-02,  ..., -7.4806e-03,
         -3.2768e-03, -1.4847e-02],
        ...,
        [ 3.3360e-03,  1.0902e-02, -9.8343e-03,  ...,  1.5717e-02,
         -8.1024e-03,  5.1022e-05],
        [ 9.8877e-03,  6.0844e-04,  1.2413e-02,  ...,  1.1330e-03,
          2.3758e-02,  1.4786e-02],
        [-6.5117e-03, -8.2550e-03,  4.7531e-03,  ..., -6.6528e-03,
         -3.6240e-03,  1.4374e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.1797, -3.0859,  2.0176,  ..., -0.7603, -4.1016,  0.5176]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 00:04:47 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The stegosaurus falls into the category of dinosaur
The goat falls into the category of bovid
The gorilla falls into the category of primate
The tyrannosaurus falls into the category of dinosaur
The goose falls into the category of fowl
The orangutan falls into the category of primate
The eagle falls into the category of raptor
The hawk falls into the category of
2024-07-31 00:04:47 root INFO     total operator prediction time: 1272.994680404663 seconds
2024-07-31 00:04:47 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on synonyms - intensity
2024-07-31 00:04:47 root INFO     building operator synonyms - intensity
2024-07-31 00:04:47 root INFO     [order_1_approx] starting weight calculation for A more intense word for jog is run
A more intense word for doze is sleep
A more intense word for indulge is pamper
A more intense word for faith is fanatism
A more intense word for boring is tedious
A more intense word for monkey is gorilla
A more intense word for sea is ocean
A more intense word for bad is
2024-07-31 00:04:47 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-31 00:06:31 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0505, -0.1214, -0.8652,  ..., -0.4768, -0.0667,  0.2690],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.7051, -4.3672,  0.6260,  ...,  0.5708, -2.3105, -0.8760],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0373, -0.0159, -0.0050,  ...,  0.0108,  0.0108,  0.0353],
        [-0.0224,  0.0523, -0.0118,  ...,  0.0342, -0.0020, -0.0057],
        [ 0.0127, -0.0131,  0.0298,  ..., -0.0041, -0.0018, -0.0091],
        ...,
        [-0.0100,  0.0068, -0.0363,  ...,  0.0207,  0.0035, -0.0331],
        [ 0.0135,  0.0118, -0.0094,  ...,  0.0099,  0.0305, -0.0006],
        [ 0.0083,  0.0020, -0.0275,  ...,  0.0072, -0.0120,  0.0571]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.8101, -4.3359,  0.9321,  ...,  0.8398, -2.6191, -0.9517]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 00:06:32 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To declare results in declaration
To continue results in continuation
To improvize results in improvization
To determine results in determination
To perspire results in perspiration
To minimize results in minimization
To randomize results in randomization
To restore results in
2024-07-31 00:06:32 root INFO     [order_1_approx] starting weight calculation for To perspire results in perspiration
To determine results in determination
To improvize results in improvization
To continue results in continuation
To declare results in declaration
To minimize results in minimization
To restore results in restoration
To randomize results in
2024-07-31 00:06:32 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-31 00:07:26 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0922,  0.0198,  0.0341,  ..., -0.0169, -0.1143, -0.0983],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.2500, -1.8223,  1.6514,  ..., -0.1519, -4.3320,  0.2644],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0376,  0.0047,  0.0426,  ..., -0.0287, -0.0291,  0.0593],
        [-0.0591,  0.0563,  0.0524,  ..., -0.0241,  0.0158, -0.0344],
        [ 0.0354, -0.0291,  0.0471,  ...,  0.0492,  0.0006,  0.0178],
        ...,
        [ 0.0213,  0.0093, -0.0159,  ...,  0.0381, -0.0145, -0.0266],
        [ 0.0349, -0.0145, -0.0187,  ...,  0.0437,  0.0359, -0.0473],
        [ 0.0085, -0.0104, -0.0276,  ...,  0.0269, -0.0021, -0.0019]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.1250, -2.5664,  1.7627,  ..., -0.7759, -4.6328, -0.3464]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 00:07:27 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more intense word for jog is run
A more intense word for doze is sleep
A more intense word for indulge is pamper
A more intense word for faith is fanatism
A more intense word for boring is tedious
A more intense word for monkey is gorilla
A more intense word for sea is ocean
A more intense word for bad is
2024-07-31 00:07:27 root INFO     [order_1_approx] starting weight calculation for A more intense word for doze is sleep
A more intense word for faith is fanatism
A more intense word for sea is ocean
A more intense word for monkey is gorilla
A more intense word for indulge is pamper
A more intense word for jog is run
A more intense word for bad is awful
A more intense word for boring is
2024-07-31 00:07:27 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-31 00:08:59 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2598,  0.3779, -0.3296,  ...,  0.1748, -0.4260, -0.2866],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.3330, -1.9482, -0.1465,  ...,  2.0762, -2.9922, -3.2422],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0513,  0.0334, -0.0064,  ..., -0.0519, -0.0016, -0.0116],
        [ 0.0062,  0.0306,  0.0270,  ...,  0.0522, -0.0083, -0.0074],
        [-0.0288, -0.0018,  0.0173,  ..., -0.0266,  0.0126,  0.0071],
        ...,
        [ 0.0092,  0.0020,  0.0111,  ...,  0.0833, -0.0094,  0.0151],
        [-0.0100,  0.0191,  0.0102,  ...,  0.0242,  0.0414,  0.0082],
        [-0.0021, -0.0213,  0.0102,  ...,  0.0232, -0.0183,  0.0677]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.0801, -2.1094, -0.1997,  ...,  2.2031, -2.7871, -2.9336]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 00:09:00 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To perspire results in perspiration
To determine results in determination
To improvize results in improvization
To continue results in continuation
To declare results in declaration
To minimize results in minimization
To restore results in restoration
To randomize results in
2024-07-31 00:09:00 root INFO     [order_1_approx] starting weight calculation for To improvize results in improvization
To perspire results in perspiration
To declare results in declaration
To randomize results in randomization
To restore results in restoration
To continue results in continuation
To minimize results in minimization
To determine results in
2024-07-31 00:09:00 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-31 00:10:06 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0526,  0.1195,  0.0413,  ..., -0.0143, -0.3516, -0.0326],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.3066, -1.4521,  5.1680,  ..., -2.8379, -5.3516, -1.4453],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0482,  0.0141,  0.0076,  ..., -0.0022, -0.0049,  0.0240],
        [-0.0080,  0.0786,  0.0334,  ..., -0.0175, -0.0238, -0.0141],
        [-0.0095,  0.0006,  0.0228,  ...,  0.0149,  0.0222,  0.0191],
        ...,
        [ 0.0540, -0.0081,  0.0369,  ...,  0.0255, -0.0247, -0.0219],
        [ 0.0140, -0.0137,  0.0558,  ...,  0.0186,  0.0104, -0.0006],
        [ 0.0286,  0.0185,  0.0095,  ...,  0.0074, -0.0182,  0.0323]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.5020, -1.9268,  5.0312,  ..., -2.8711, -5.5156, -1.4072]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 00:10:07 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more intense word for doze is sleep
A more intense word for faith is fanatism
A more intense word for sea is ocean
A more intense word for monkey is gorilla
A more intense word for indulge is pamper
A more intense word for jog is run
A more intense word for bad is awful
A more intense word for boring is
2024-07-31 00:10:07 root INFO     [order_1_approx] starting weight calculation for A more intense word for doze is sleep
A more intense word for sea is ocean
A more intense word for bad is awful
A more intense word for monkey is gorilla
A more intense word for indulge is pamper
A more intense word for jog is run
A more intense word for boring is tedious
A more intense word for faith is
2024-07-31 00:10:07 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-31 00:11:29 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1982,  0.1658, -0.3101,  ..., -0.1183, -0.4453, -0.1508],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.9961, -4.0391,  1.3691,  ...,  0.1171, -3.9434, -1.1709],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0086,  0.1117, -0.0062,  ..., -0.0328,  0.0289, -0.0322],
        [ 0.0504, -0.0443, -0.0008,  ...,  0.0440, -0.0167,  0.0534],
        [-0.0097,  0.0202,  0.0109,  ..., -0.0122, -0.0111, -0.0238],
        ...,
        [ 0.0039, -0.0280,  0.0116,  ...,  0.0525, -0.0172,  0.0421],
        [ 0.0045, -0.0084,  0.0024,  ...,  0.0140,  0.0134, -0.0056],
        [ 0.0186, -0.0195,  0.0141,  ...,  0.0219, -0.0284,  0.0325]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.8975, -2.8633,  1.0508,  ...,  0.7842, -3.7734, -0.9214]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 00:11:30 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To improvize results in improvization
To perspire results in perspiration
To declare results in declaration
To randomize results in randomization
To restore results in restoration
To continue results in continuation
To minimize results in minimization
To determine results in
2024-07-31 00:11:30 root INFO     [order_1_approx] starting weight calculation for To determine results in determination
To restore results in restoration
To continue results in continuation
To perspire results in perspiration
To declare results in declaration
To minimize results in minimization
To randomize results in randomization
To improvize results in
2024-07-31 00:11:30 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-31 00:12:44 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0352,  0.1237, -0.0160,  ...,  0.1315, -0.1184,  0.5137],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 5.1602, -5.5977,  0.7212,  ..., -2.3086, -5.7617, -0.4448],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0279,  0.0199, -0.0154,  ...,  0.0029, -0.0229, -0.0117],
        [ 0.0040,  0.0555,  0.0430,  ..., -0.0214, -0.0117, -0.0055],
        [ 0.0054, -0.0200,  0.0294,  ..., -0.0138, -0.0155, -0.0032],
        ...,
        [ 0.0126, -0.0023, -0.0122,  ...,  0.0354, -0.0241, -0.0141],
        [ 0.0143, -0.0165, -0.0124,  ...,  0.0094,  0.0447,  0.0184],
        [ 0.0095, -0.0088, -0.0216,  ...,  0.0180,  0.0030,  0.0352]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.9609, -5.1328,  0.8770,  ..., -2.2598, -5.8828, -0.7695]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 00:12:45 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more intense word for doze is sleep
A more intense word for sea is ocean
A more intense word for bad is awful
A more intense word for monkey is gorilla
A more intense word for indulge is pamper
A more intense word for jog is run
A more intense word for boring is tedious
A more intense word for faith is
2024-07-31 00:12:45 root INFO     [order_1_approx] starting weight calculation for A more intense word for bad is awful
A more intense word for faith is fanatism
A more intense word for sea is ocean
A more intense word for monkey is gorilla
A more intense word for boring is tedious
A more intense word for indulge is pamper
A more intense word for doze is sleep
A more intense word for jog is
2024-07-31 00:12:45 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-31 00:14:02 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0411,  0.2778, -0.4358,  ..., -0.1663, -0.1589,  0.2781],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.8955, -3.2227,  1.8398,  ...,  3.7969, -1.9795, -2.5801],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0631,  0.0026, -0.0277,  ..., -0.0232,  0.0029,  0.0079],
        [-0.0317,  0.0385,  0.0208,  ...,  0.0386, -0.0061,  0.0167],
        [-0.0162, -0.0085,  0.0327,  ...,  0.0080,  0.0142, -0.0072],
        ...,
        [-0.0165,  0.0096,  0.0182,  ...,  0.0672, -0.0061,  0.0041],
        [-0.0041,  0.0099,  0.0061,  ...,  0.0130,  0.0496,  0.0057],
        [-0.0159, -0.0052,  0.0037,  ..., -0.0017, -0.0217,  0.0446]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.1494, -2.2598,  1.7324,  ...,  4.3125, -1.7412, -2.2598]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 00:14:03 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To determine results in determination
To restore results in restoration
To continue results in continuation
To perspire results in perspiration
To declare results in declaration
To minimize results in minimization
To randomize results in randomization
To improvize results in
2024-07-31 00:14:03 root INFO     total operator prediction time: 1207.9784789085388 seconds
2024-07-31 00:14:03 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on adj+ly_reg
2024-07-31 00:14:03 root INFO     building operator adj+ly_reg
2024-07-31 00:14:03 root INFO     [order_1_approx] starting weight calculation for The adjective form of federal is federally
The adjective form of huge is hugely
The adjective form of cultural is culturally
The adjective form of according is accordingly
The adjective form of interesting is interestingly
The adjective form of famous is famously
The adjective form of unique is uniquely
The adjective form of different is
2024-07-31 00:14:03 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-31 00:15:22 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0184,  0.0684,  0.0475,  ..., -0.1790, -0.3767, -0.1475],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.9316, -5.7305,  2.3535,  ...,  3.6504, -4.5469, -1.6523],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0693, -0.0331,  0.0349,  ..., -0.0171, -0.0050,  0.0197],
        [-0.0173,  0.0427,  0.0337,  ...,  0.0232,  0.0009, -0.0410],
        [-0.0219, -0.0121,  0.0495,  ...,  0.0282, -0.0052,  0.0360],
        ...,
        [ 0.0413,  0.0052,  0.0202,  ...,  0.0478,  0.0071, -0.0344],
        [ 0.0047, -0.0274, -0.0115,  ...,  0.0318,  0.0244, -0.0317],
        [ 0.0001,  0.0044,  0.0292,  ..., -0.0489,  0.0027,  0.0581]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.9697, -5.8672,  2.4199,  ...,  3.2461, -4.7031, -1.7988]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 00:15:23 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more intense word for bad is awful
A more intense word for faith is fanatism
A more intense word for sea is ocean
A more intense word for monkey is gorilla
A more intense word for boring is tedious
A more intense word for indulge is pamper
A more intense word for doze is sleep
A more intense word for jog is
2024-07-31 00:15:24 root INFO     [order_1_approx] starting weight calculation for A more intense word for faith is fanatism
A more intense word for indulge is pamper
A more intense word for bad is awful
A more intense word for boring is tedious
A more intense word for jog is run
A more intense word for doze is sleep
A more intense word for monkey is gorilla
A more intense word for sea is
2024-07-31 00:15:24 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-31 00:16:29 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1664, -0.1865, -0.0930,  ..., -0.2312, -0.2651,  0.2563],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.5039, -1.8535,  2.7109,  ..., -1.8125, -1.1641, -1.6543],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0515, -0.0441, -0.0179,  ..., -0.0131,  0.0422,  0.0100],
        [ 0.0137,  0.0246,  0.0119,  ...,  0.0343,  0.0149, -0.0013],
        [ 0.0171,  0.0017,  0.0197,  ..., -0.0291,  0.0237,  0.0016],
        ...,
        [-0.0012,  0.0116, -0.0208,  ...,  0.0391,  0.0147, -0.0211],
        [ 0.0061,  0.0207,  0.0145,  ...,  0.0053,  0.0215,  0.0124],
        [-0.0111, -0.0020,  0.0039,  ..., -0.0065, -0.0066,  0.0178]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.6064, -1.9004,  2.6211,  ..., -2.1055, -1.0312, -1.4453]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 00:16:30 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The adjective form of federal is federally
The adjective form of huge is hugely
The adjective form of cultural is culturally
The adjective form of according is accordingly
The adjective form of interesting is interestingly
The adjective form of famous is famously
The adjective form of unique is uniquely
The adjective form of different is
2024-07-31 00:16:30 root INFO     [order_1_approx] starting weight calculation for The adjective form of unique is uniquely
The adjective form of cultural is culturally
The adjective form of according is accordingly
The adjective form of famous is famously
The adjective form of interesting is interestingly
The adjective form of huge is hugely
The adjective form of different is differently
The adjective form of federal is
2024-07-31 00:16:30 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-31 00:18:01 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0836, -0.0303, -0.0642,  ..., -0.2900, -0.0277, -0.1210],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.9019, -6.1016,  0.2666,  ..., -2.8574, -1.2539,  0.4590],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 4.3427e-02, -1.1292e-02, -7.6294e-06,  ...,  1.9150e-02,
         -6.2752e-04,  2.1423e-02],
        [-4.4403e-03,  4.2053e-02, -4.3091e-02,  ...,  5.2872e-03,
          1.0345e-02, -3.0029e-02],
        [ 8.9493e-03, -1.5442e-02,  6.7261e-02,  ..., -2.6855e-02,
          1.1272e-03,  2.4292e-02],
        ...,
        [-2.3174e-03,  3.3875e-02, -4.1016e-02,  ...,  6.5308e-02,
          2.0752e-02, -1.2016e-03],
        [-7.8430e-03, -9.0027e-03,  3.8971e-02,  ...,  2.1019e-03,
          4.1412e-02,  1.4915e-03],
        [-1.2482e-02, -2.7588e-02, -1.1215e-02,  ...,  2.2034e-02,
         -7.2403e-03,  4.4464e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.6748, -5.6016,  0.2429,  ..., -2.9199, -1.2393,  0.3818]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 00:18:02 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more intense word for faith is fanatism
A more intense word for indulge is pamper
A more intense word for bad is awful
A more intense word for boring is tedious
A more intense word for jog is run
A more intense word for doze is sleep
A more intense word for monkey is gorilla
A more intense word for sea is
2024-07-31 00:18:02 root INFO     [order_1_approx] starting weight calculation for A more intense word for bad is awful
A more intense word for jog is run
A more intense word for doze is sleep
A more intense word for sea is ocean
A more intense word for monkey is gorilla
A more intense word for faith is fanatism
A more intense word for boring is tedious
A more intense word for indulge is
2024-07-31 00:18:02 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-31 00:19:02 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3682,  0.1677, -0.4182,  ..., -0.3394, -0.3401,  0.1450],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.5664, -1.6484,  3.6914,  ..., -1.3457, -1.1230, -1.3047],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0576, -0.0534, -0.0293,  ...,  0.0063,  0.0030, -0.0007],
        [-0.0076,  0.0488, -0.0221,  ...,  0.0143,  0.0032, -0.0308],
        [ 0.0064,  0.0149,  0.0303,  ..., -0.0254, -0.0130, -0.0162],
        ...,
        [-0.0087, -0.0014, -0.0140,  ...,  0.0291,  0.0196, -0.0235],
        [-0.0198, -0.0020, -0.0019,  ..., -0.0003,  0.0269, -0.0404],
        [ 0.0283,  0.0043,  0.0211,  ...,  0.0130,  0.0054,  0.0368]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.2422, -1.7158,  3.3496,  ..., -0.9639, -1.5137, -1.4287]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 00:19:03 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The adjective form of unique is uniquely
The adjective form of cultural is culturally
The adjective form of according is accordingly
The adjective form of famous is famously
The adjective form of interesting is interestingly
The adjective form of huge is hugely
The adjective form of different is differently
The adjective form of federal is
2024-07-31 00:19:03 root INFO     [order_1_approx] starting weight calculation for The adjective form of according is accordingly
The adjective form of different is differently
The adjective form of famous is famously
The adjective form of interesting is interestingly
The adjective form of huge is hugely
The adjective form of cultural is culturally
The adjective form of federal is federally
The adjective form of unique is
2024-07-31 00:19:03 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-31 00:20:38 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1254, -0.0847, -0.3386,  ..., -0.1531, -0.6475,  0.4199],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.5156, -2.7051, -2.5000,  ...,  1.7109, -3.7207,  2.3770],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0583,  0.0231,  0.0129,  ...,  0.0268,  0.0030, -0.0074],
        [-0.0004,  0.0349,  0.0059,  ..., -0.0170, -0.0224, -0.0009],
        [-0.0259, -0.0373,  0.0474,  ...,  0.0058, -0.0178, -0.0027],
        ...,
        [ 0.0011, -0.0244, -0.0213,  ...,  0.0426,  0.0033, -0.0108],
        [-0.0264,  0.0204,  0.0191,  ..., -0.0033,  0.0241,  0.0003],
        [-0.0084, -0.0478, -0.0148,  ..., -0.0411, -0.0130,  0.0478]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.2324, -2.3223, -2.0117,  ...,  1.8213, -3.8359,  2.4434]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 00:20:39 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more intense word for bad is awful
A more intense word for jog is run
A more intense word for doze is sleep
A more intense word for sea is ocean
A more intense word for monkey is gorilla
A more intense word for faith is fanatism
A more intense word for boring is tedious
A more intense word for indulge is
2024-07-31 00:20:39 root INFO     [order_1_approx] starting weight calculation for A more intense word for boring is tedious
A more intense word for monkey is gorilla
A more intense word for indulge is pamper
A more intense word for sea is ocean
A more intense word for jog is run
A more intense word for faith is fanatism
A more intense word for bad is awful
A more intense word for doze is
2024-07-31 00:20:39 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-31 00:21:36 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1683, -0.0341, -0.2302,  ...,  0.0625, -0.1897,  0.2515],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.0197, -2.1270,  0.9678,  ..., -1.6240, -2.8867, -1.2715],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0321, -0.0330,  0.0010,  ...,  0.0342,  0.0020,  0.0167],
        [-0.0060,  0.0542, -0.0006,  ..., -0.0090,  0.0230, -0.0096],
        [ 0.0093, -0.0114,  0.0357,  ..., -0.0034,  0.0050, -0.0200],
        ...,
        [ 0.0067, -0.0002, -0.0066,  ...,  0.0437, -0.0023, -0.0077],
        [ 0.0378,  0.0229,  0.0139,  ...,  0.0189,  0.0241,  0.0004],
        [ 0.0082,  0.0018,  0.0036,  ..., -0.0203, -0.0147,  0.0111]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.3843, -2.3574,  0.9502,  ..., -1.2119, -2.8672, -1.4043]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 00:21:37 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The adjective form of according is accordingly
The adjective form of different is differently
The adjective form of famous is famously
The adjective form of interesting is interestingly
The adjective form of huge is hugely
The adjective form of cultural is culturally
The adjective form of federal is federally
The adjective form of unique is
2024-07-31 00:21:37 root INFO     [order_1_approx] starting weight calculation for The adjective form of federal is federally
The adjective form of cultural is culturally
The adjective form of unique is uniquely
The adjective form of huge is hugely
The adjective form of interesting is interestingly
The adjective form of according is accordingly
The adjective form of different is differently
The adjective form of famous is
2024-07-31 00:21:38 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-31 00:23:17 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0500, -0.0684,  0.0397,  ..., -0.4985, -0.5024,  0.1920],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.6270, -4.7109,  2.1914,  ...,  0.6816, -2.5156,  0.8770],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0442, -0.0222,  0.0159,  ...,  0.0302, -0.0213,  0.0168],
        [ 0.0075,  0.0754, -0.0076,  ...,  0.0118, -0.0067, -0.0047],
        [-0.0560, -0.0359,  0.0270,  ...,  0.0090, -0.0257, -0.0142],
        ...,
        [ 0.0041,  0.0154,  0.0125,  ...,  0.0443,  0.0227, -0.0539],
        [ 0.0112, -0.0129, -0.0200,  ...,  0.0290, -0.0231, -0.0169],
        [ 0.0201, -0.0040, -0.0100,  ...,  0.0262, -0.0415,  0.0271]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.5078, -4.9414,  1.9287,  ...,  0.8071, -2.6426,  0.8999]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 00:23:18 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more intense word for boring is tedious
A more intense word for monkey is gorilla
A more intense word for indulge is pamper
A more intense word for sea is ocean
A more intense word for jog is run
A more intense word for faith is fanatism
A more intense word for bad is awful
A more intense word for doze is
2024-07-31 00:23:18 root INFO     [order_1_approx] starting weight calculation for A more intense word for doze is sleep
A more intense word for bad is awful
A more intense word for boring is tedious
A more intense word for indulge is pamper
A more intense word for jog is run
A more intense word for sea is ocean
A more intense word for faith is fanatism
A more intense word for monkey is
2024-07-31 00:23:18 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-31 00:24:11 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4175,  0.1409, -0.3032,  ..., -0.1084, -0.3896,  0.0806],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.1621, -2.0391,  2.6973,  ..., -1.2256, -3.3105, -2.5723],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 4.3182e-02, -2.5650e-02, -5.0735e-03,  ...,  2.0935e-02,
          1.7548e-02,  1.6724e-02],
        [-7.5531e-03,  4.4067e-02,  9.1171e-03,  ...,  9.4452e-03,
          3.5706e-02, -1.8509e-02],
        [ 7.3509e-03, -2.7786e-02,  4.5258e-02,  ...,  4.4899e-03,
         -1.4893e-02,  2.1935e-03],
        ...,
        [ 1.7563e-02,  2.7985e-02,  2.0401e-02,  ...,  4.5166e-02,
          4.1962e-03, -2.5444e-03],
        [-3.1395e-03,  2.9419e-02,  8.8043e-03,  ..., -8.4686e-04,
          3.1921e-02,  2.6382e-02],
        [-7.1335e-04, -1.2497e-02, -6.6223e-03,  ...,  2.4281e-03,
         -1.5259e-05,  9.7351e-03]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.1992, -2.1484,  3.1484,  ..., -1.3291, -3.6992, -2.6309]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 00:24:12 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The adjective form of federal is federally
The adjective form of cultural is culturally
The adjective form of unique is uniquely
The adjective form of huge is hugely
The adjective form of interesting is interestingly
The adjective form of according is accordingly
The adjective form of different is differently
The adjective form of famous is
2024-07-31 00:24:12 root INFO     [order_1_approx] starting weight calculation for The adjective form of according is accordingly
The adjective form of different is differently
The adjective form of federal is federally
The adjective form of famous is famously
The adjective form of unique is uniquely
The adjective form of huge is hugely
The adjective form of interesting is interestingly
The adjective form of cultural is
2024-07-31 00:24:13 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-31 00:26:00 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1833, -0.0594, -0.0483,  ...,  0.0515, -0.4302,  0.1215],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.7676, -5.5469,  2.3770,  ...,  0.2415, -3.5098,  1.8135],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0825,  0.0196, -0.0124,  ..., -0.0017,  0.0021, -0.0133],
        [-0.0092,  0.0496, -0.0108,  ..., -0.0338, -0.0136, -0.0259],
        [-0.0334, -0.0107,  0.0556,  ..., -0.0175,  0.0388, -0.0127],
        ...,
        [ 0.0153,  0.0125, -0.0208,  ...,  0.0760, -0.0469,  0.0167],
        [ 0.0242,  0.0004, -0.0495,  ...,  0.0345,  0.0130, -0.0107],
        [-0.0223,  0.0179,  0.0026,  ..., -0.0006, -0.0215,  0.0588]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.6504, -4.9375,  2.3047,  ...,  0.6748, -3.5391,  1.8584]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 00:26:01 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more intense word for doze is sleep
A more intense word for bad is awful
A more intense word for boring is tedious
A more intense word for indulge is pamper
A more intense word for jog is run
A more intense word for sea is ocean
A more intense word for faith is fanatism
A more intense word for monkey is
2024-07-31 00:26:01 root INFO     total operator prediction time: 1273.681070804596 seconds
2024-07-31 00:26:01 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on meronyms - substance
2024-07-31 00:26:01 root INFO     building operator meronyms - substance
2024-07-31 00:26:01 root INFO     [order_1_approx] starting weight calculation for A desk is made up of wood
A glacier is made up of ice
A yogurt is made up of milk
A lawn is made up of grass
A chocolate is made up of cocoa
A clothing is made up of fabric
A beard is made up of hair
A wire is made up of
2024-07-31 00:26:01 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-31 00:26:46 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4114,  0.0527, -0.2698,  ..., -0.3921, -0.5068,  0.1759],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.1499, -1.1914,  3.0879,  ..., -1.0527, -0.1594,  0.7998],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0615, -0.0613, -0.0143,  ...,  0.0118, -0.0222,  0.0116],
        [-0.0187,  0.0762,  0.0295,  ...,  0.0293,  0.0395, -0.0133],
        [ 0.0123, -0.0082,  0.0246,  ...,  0.0145, -0.0179,  0.0079],
        ...,
        [ 0.0273,  0.0004, -0.0087,  ...,  0.0578,  0.0132, -0.0038],
        [-0.0086,  0.0143,  0.0011,  ..., -0.0116,  0.0345, -0.0087],
        [ 0.0185, -0.0146, -0.0023,  ...,  0.0157,  0.0040,  0.0058]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.1885, -1.0049,  3.1211,  ..., -0.7930, -0.9863,  1.1133]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 00:26:47 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The adjective form of according is accordingly
The adjective form of different is differently
The adjective form of federal is federally
The adjective form of famous is famously
The adjective form of unique is uniquely
The adjective form of huge is hugely
The adjective form of interesting is interestingly
The adjective form of cultural is
2024-07-31 00:26:47 root INFO     [order_1_approx] starting weight calculation for The adjective form of famous is famously
The adjective form of huge is hugely
The adjective form of according is accordingly
The adjective form of cultural is culturally
The adjective form of federal is federally
The adjective form of unique is uniquely
The adjective form of different is differently
The adjective form of interesting is
2024-07-31 00:26:47 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-31 00:28:41 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0130, -0.0770, -0.3652,  ..., -0.0164, -0.0078,  0.0505],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.0977, -5.0000, -0.8828,  ..., -1.9531, -0.0439, -1.2158],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0268, -0.0385,  0.0069,  ...,  0.0230, -0.0125, -0.0062],
        [-0.0164,  0.0458, -0.0081,  ..., -0.0046,  0.0023, -0.0260],
        [-0.0014,  0.0296,  0.0371,  ..., -0.0049,  0.0027, -0.0315],
        ...,
        [ 0.0103,  0.0113,  0.0450,  ...,  0.0359,  0.0176, -0.0145],
        [-0.0039, -0.0006,  0.0018,  ..., -0.0053,  0.0180,  0.0010],
        [ 0.0026,  0.0023, -0.0440,  ..., -0.0217,  0.0037,  0.0316]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.3984, -5.6953, -0.4888,  ..., -1.6348, -0.6318, -0.9287]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 00:28:42 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A desk is made up of wood
A glacier is made up of ice
A yogurt is made up of milk
A lawn is made up of grass
A chocolate is made up of cocoa
A clothing is made up of fabric
A beard is made up of hair
A wire is made up of
2024-07-31 00:28:42 root INFO     [order_1_approx] starting weight calculation for A beard is made up of hair
A chocolate is made up of cocoa
A clothing is made up of fabric
A desk is made up of wood
A lawn is made up of grass
A wire is made up of metal
A yogurt is made up of milk
A glacier is made up of
2024-07-31 00:28:42 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-31 00:29:20 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0421,  0.0402,  0.0176,  ...,  0.1016, -0.4478,  0.0940],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.0430, -1.5371,  1.6738,  ..., -1.6523, -2.6875, -2.2422],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0133, -0.0475, -0.0045,  ..., -0.0232,  0.0140, -0.0038],
        [ 0.0010,  0.0408,  0.0073,  ..., -0.0082,  0.0068, -0.0198],
        [ 0.0251, -0.0016,  0.0253,  ...,  0.0143,  0.0019,  0.0111],
        ...,
        [ 0.0202,  0.0229, -0.0110,  ...,  0.0458, -0.0001,  0.0064],
        [ 0.0002,  0.0229,  0.0163,  ...,  0.0307,  0.0338, -0.0153],
        [-0.0011,  0.0152,  0.0067,  ..., -0.0051, -0.0027,  0.0003]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.0283, -1.4912,  1.7969,  ..., -1.6367, -2.4688, -2.2344]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 00:29:21 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The adjective form of famous is famously
The adjective form of huge is hugely
The adjective form of according is accordingly
The adjective form of cultural is culturally
The adjective form of federal is federally
The adjective form of unique is uniquely
The adjective form of different is differently
The adjective form of interesting is
2024-07-31 00:29:21 root INFO     [order_1_approx] starting weight calculation for The adjective form of interesting is interestingly
The adjective form of different is differently
The adjective form of famous is famously
The adjective form of federal is federally
The adjective form of cultural is culturally
The adjective form of unique is uniquely
The adjective form of huge is hugely
The adjective form of according is
2024-07-31 00:29:21 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-31 00:31:23 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2095,  0.3525, -0.3450,  ..., -0.2059, -0.4683,  0.4490],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.0469, -6.3359,  1.2275,  ..., -3.5586,  0.7622, -2.4883],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0706, -0.0246,  0.0154,  ..., -0.0027,  0.0058, -0.0112],
        [ 0.0179,  0.0265,  0.0168,  ...,  0.0421, -0.0029, -0.0188],
        [ 0.0021,  0.0121, -0.0065,  ..., -0.0116,  0.0174, -0.0119],
        ...,
        [ 0.0010,  0.0090,  0.0081,  ...,  0.0751,  0.0067, -0.0062],
        [ 0.0032,  0.0201, -0.0104,  ...,  0.0414, -0.0127,  0.0129],
        [ 0.0114, -0.0363, -0.0062,  ..., -0.0182,  0.0042,  0.0375]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.4336, -6.3672,  0.8643,  ..., -3.4297,  0.5684, -2.0254]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 00:31:24 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A beard is made up of hair
A chocolate is made up of cocoa
A clothing is made up of fabric
A desk is made up of wood
A lawn is made up of grass
A wire is made up of metal
A yogurt is made up of milk
A glacier is made up of
2024-07-31 00:31:24 root INFO     [order_1_approx] starting weight calculation for A chocolate is made up of cocoa
A clothing is made up of fabric
A yogurt is made up of milk
A wire is made up of metal
A beard is made up of hair
A lawn is made up of grass
A glacier is made up of ice
A desk is made up of
2024-07-31 00:31:24 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-31 00:31:55 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3677, -0.0589, -0.4666,  ..., -0.1409, -0.4785,  0.1379],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.3379, -3.8359,  1.7959,  ...,  2.5859, -1.7305, -0.7637],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0506, -0.0604, -0.0356,  ...,  0.0073,  0.0026,  0.0455],
        [-0.0333,  0.0695, -0.0015,  ...,  0.0033,  0.0018, -0.0027],
        [ 0.0182, -0.0150,  0.0276,  ..., -0.0316, -0.0222,  0.0197],
        ...,
        [-0.0148,  0.0635,  0.0345,  ...,  0.0801,  0.0257, -0.0363],
        [ 0.0035, -0.0116,  0.0315,  ..., -0.0029,  0.0359, -0.0544],
        [-0.0162, -0.0152,  0.0036,  ..., -0.0201, -0.0195,  0.0115]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.3650, -3.2422,  2.3223,  ...,  1.8164, -1.9570, -0.8384]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 00:31:56 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The adjective form of interesting is interestingly
The adjective form of different is differently
The adjective form of famous is famously
The adjective form of federal is federally
The adjective form of cultural is culturally
The adjective form of unique is uniquely
The adjective form of huge is hugely
The adjective form of according is
2024-07-31 00:31:56 root INFO     [order_1_approx] starting weight calculation for The adjective form of famous is famously
The adjective form of federal is federally
The adjective form of cultural is culturally
The adjective form of different is differently
The adjective form of interesting is interestingly
The adjective form of unique is uniquely
The adjective form of according is accordingly
The adjective form of huge is
2024-07-31 00:31:56 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-31 00:34:03 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2312, -0.0423, -0.2134,  ...,  0.3250, -0.5386, -0.1794],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.7656, -5.2344,  2.0820,  ..., -4.1914,  0.0273, -1.7832],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0362, -0.0039,  0.0044,  ...,  0.0251, -0.0187,  0.0135],
        [ 0.0080,  0.0556, -0.0027,  ..., -0.0092, -0.0073,  0.0048],
        [ 0.0148,  0.0220,  0.0169,  ...,  0.0056, -0.0197,  0.0065],
        ...,
        [ 0.0050, -0.0117,  0.0187,  ...,  0.0425, -0.0152,  0.0171],
        [-0.0139, -0.0021, -0.0163,  ..., -0.0140,  0.0152, -0.0170],
        [ 0.0087, -0.0014,  0.0202,  ..., -0.0057,  0.0078,  0.0223]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.4082, -5.1602,  1.7549,  ..., -4.0117, -0.2883, -1.6562]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 00:34:04 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A chocolate is made up of cocoa
A clothing is made up of fabric
A yogurt is made up of milk
A wire is made up of metal
A beard is made up of hair
A lawn is made up of grass
A glacier is made up of ice
A desk is made up of
2024-07-31 00:34:04 root INFO     [order_1_approx] starting weight calculation for A beard is made up of hair
A glacier is made up of ice
A chocolate is made up of cocoa
A wire is made up of metal
A clothing is made up of fabric
A lawn is made up of grass
A desk is made up of wood
A yogurt is made up of
2024-07-31 00:34:04 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-31 00:34:29 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3267, -0.1389, -0.0582,  ..., -0.2173, -0.2805,  0.1302],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.1367, -2.4766,  1.6816,  ..., -3.8262, -7.3906, -1.3750],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 5.8868e-02,  2.5482e-02, -4.3259e-03,  ...,  1.5656e-02,
          2.6123e-02,  1.1917e-02],
        [-8.5297e-03,  2.0020e-02, -4.6959e-03,  ...,  1.7578e-02,
          4.1199e-03, -1.8101e-03],
        [ 1.6617e-02, -4.2786e-02,  4.7333e-02,  ...,  1.2451e-02,
          2.7283e-02,  3.1799e-02],
        ...,
        [ 1.7838e-02, -1.3294e-03,  1.4267e-02,  ...,  5.2795e-02,
          1.3283e-02, -2.7679e-02],
        [ 2.8015e-02, -8.5068e-03,  6.1874e-03,  ..., -6.1035e-05,
          3.6865e-02, -9.9945e-04],
        [-1.4130e-02,  2.0638e-03,  9.4604e-03,  ...,  1.0208e-02,
         -1.0437e-02,  8.2169e-03]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.1523, -2.6172,  1.7012,  ..., -3.6758, -7.3008, -1.4785]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 00:34:30 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The adjective form of famous is famously
The adjective form of federal is federally
The adjective form of cultural is culturally
The adjective form of different is differently
The adjective form of interesting is interestingly
The adjective form of unique is uniquely
The adjective form of according is accordingly
The adjective form of huge is
2024-07-31 00:34:30 root INFO     total operator prediction time: 1227.3225095272064 seconds
2024-07-31 00:34:30 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on over+adj_reg
2024-07-31 00:34:30 root INFO     building operator over+adj_reg
2024-07-31 00:34:30 root INFO     [order_1_approx] starting weight calculation for If something is too heard, it is overheard
If something is too dressed, it is overdressed
If something is too cooked, it is overcooked
If something is too inflated, it is overinflated
If something is too arching, it is overarching
If something is too sold, it is oversold
If something is too laid, it is overlaid
If something is too stimulated, it is
2024-07-31 00:34:30 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-31 00:36:42 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2864, -0.2573, -0.2042,  ...,  0.0617, -0.4033,  0.0164],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.9688e+00, -3.2266e+00,  1.9521e+00,  ..., -2.5371e+00,
        -1.8340e+00, -2.9297e-03], device='cuda:0', dtype=torch.float16,
       grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0093, -0.0212, -0.0183,  ..., -0.0023, -0.0109, -0.0055],
        [-0.0074,  0.0416, -0.0050,  ...,  0.0004,  0.0184,  0.0063],
        [-0.0014,  0.0010, -0.0129,  ...,  0.0202, -0.0035,  0.0107],
        ...,
        [ 0.0097,  0.0096,  0.0095,  ...,  0.0656, -0.0016, -0.0138],
        [-0.0233,  0.0250, -0.0117,  ...,  0.0173,  0.0182,  0.0116],
        [ 0.0098, -0.0106,  0.0176,  ..., -0.0186,  0.0200,  0.0376]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.7461, -3.8906,  1.9199,  ..., -2.4160, -1.9609,  0.0483]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 00:36:43 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A beard is made up of hair
A glacier is made up of ice
A chocolate is made up of cocoa
A wire is made up of metal
A clothing is made up of fabric
A lawn is made up of grass
A desk is made up of wood
A yogurt is made up of
2024-07-31 00:36:43 root INFO     [order_1_approx] starting weight calculation for A glacier is made up of ice
A clothing is made up of fabric
A wire is made up of metal
A chocolate is made up of cocoa
A yogurt is made up of milk
A lawn is made up of grass
A desk is made up of wood
A beard is made up of
2024-07-31 00:36:44 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-31 00:37:02 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0835, -0.3049, -0.6431,  ..., -0.1418, -0.6763, -0.0137],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.3828e+00, -3.0859e+00,  1.2148e+00,  ...,  1.2207e-04,
        -2.5918e+00, -3.3125e+00], device='cuda:1', dtype=torch.float16,
       grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 4.2603e-02,  1.8356e-02, -3.4485e-03,  ..., -8.6441e-03,
          2.7809e-03,  1.3573e-02],
        [ 8.4763e-03,  5.6763e-02,  4.6272e-03,  ..., -7.5302e-03,
         -3.9139e-03, -4.4556e-03],
        [ 1.6129e-02,  1.7258e-02,  1.6724e-02,  ...,  6.2943e-05,
          5.7907e-03,  1.6289e-03],
        ...,
        [ 1.3969e-02,  2.4948e-02, -1.1002e-02,  ...,  3.9642e-02,
          1.8326e-02,  8.5144e-03],
        [-3.0098e-03,  7.6675e-03,  2.1324e-03,  ..., -2.3632e-03,
          1.0620e-02, -2.8381e-02],
        [-1.5823e-02, -7.4692e-03, -6.4125e-03,  ...,  9.2850e-03,
         -1.5251e-02,  3.5583e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.4570, -3.1621,  1.2793,  ...,  0.3003, -2.6543, -3.3242]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 00:37:03 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is too heard, it is overheard
If something is too dressed, it is overdressed
If something is too cooked, it is overcooked
If something is too inflated, it is overinflated
If something is too arching, it is overarching
If something is too sold, it is oversold
If something is too laid, it is overlaid
If something is too stimulated, it is
2024-07-31 00:37:03 root INFO     [order_1_approx] starting weight calculation for If something is too cooked, it is overcooked
If something is too sold, it is oversold
If something is too laid, it is overlaid
If something is too dressed, it is overdressed
If something is too stimulated, it is overstimulated
If something is too inflated, it is overinflated
If something is too heard, it is overheard
If something is too arching, it is
2024-07-31 00:37:04 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-31 00:39:21 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.4263,  0.1932, -0.1708,  ..., -0.1975, -0.1448, -0.1672],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.3555, -5.3320, -3.0430,  ..., -2.5312,  1.1621, -1.1826],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0240, -0.0189, -0.0149,  ...,  0.0233, -0.0269,  0.0096],
        [-0.0047,  0.0299,  0.0029,  ..., -0.0384,  0.0044, -0.0151],
        [-0.0191, -0.0114,  0.0131,  ..., -0.0163, -0.0158, -0.0117],
        ...,
        [ 0.0169,  0.0170,  0.0237,  ...,  0.0442,  0.0047, -0.0483],
        [-0.0224,  0.0395, -0.0435,  ...,  0.0211,  0.0251, -0.0127],
        [ 0.0191, -0.0203,  0.0347,  ..., -0.0103, -0.0063,  0.0491]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.2344, -5.1875, -3.0625,  ..., -2.3750,  1.1904, -0.7285]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 00:39:22 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A glacier is made up of ice
A clothing is made up of fabric
A wire is made up of metal
A chocolate is made up of cocoa
A yogurt is made up of milk
A lawn is made up of grass
A desk is made up of wood
A beard is made up of
2024-07-31 00:39:23 root INFO     [order_1_approx] starting weight calculation for A beard is made up of hair
A clothing is made up of fabric
A wire is made up of metal
A yogurt is made up of milk
A glacier is made up of ice
A chocolate is made up of cocoa
A desk is made up of wood
A lawn is made up of
2024-07-31 00:39:23 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-31 00:39:34 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1777, -0.5986, -0.1669,  ..., -0.0602, -0.3740, -0.6162],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.8145, -4.1953,  2.0820,  ...,  1.2842, -1.8613, -3.4785],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0578,  0.0073,  0.0026,  ...,  0.0041,  0.0133,  0.0090],
        [-0.0027,  0.0540,  0.0025,  ..., -0.0032, -0.0124, -0.0073],
        [-0.0056,  0.0037,  0.0396,  ...,  0.0068,  0.0025,  0.0014],
        ...,
        [ 0.0176,  0.0197,  0.0057,  ...,  0.0318,  0.0111,  0.0054],
        [ 0.0296, -0.0040,  0.0195,  ..., -0.0061,  0.0287, -0.0241],
        [-0.0257, -0.0076, -0.0171,  ..., -0.0178, -0.0219,  0.0330]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.7480, -4.0586,  1.5449,  ...,  1.3984, -1.7158, -3.2109]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 00:39:35 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is too cooked, it is overcooked
If something is too sold, it is oversold
If something is too laid, it is overlaid
If something is too dressed, it is overdressed
If something is too stimulated, it is overstimulated
If something is too inflated, it is overinflated
If something is too heard, it is overheard
If something is too arching, it is
2024-07-31 00:39:35 root INFO     [order_1_approx] starting weight calculation for If something is too stimulated, it is overstimulated
If something is too laid, it is overlaid
If something is too sold, it is oversold
If something is too cooked, it is overcooked
If something is too dressed, it is overdressed
If something is too inflated, it is overinflated
If something is too arching, it is overarching
If something is too heard, it is
2024-07-31 00:39:35 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-31 00:41:57 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2142,  0.4031, -0.3413,  ..., -0.0757, -0.1126, -0.1869],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 5.7852, -5.6367, -2.6758,  ..., -1.4160,  2.7969, -1.1318],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0364,  0.0064, -0.0057,  ...,  0.0080, -0.0115,  0.0122],
        [ 0.0113,  0.0115,  0.0104,  ..., -0.0067, -0.0001, -0.0050],
        [-0.0125, -0.0137,  0.0295,  ..., -0.0123, -0.0042,  0.0026],
        ...,
        [ 0.0117, -0.0013,  0.0172,  ...,  0.0615, -0.0011, -0.0194],
        [ 0.0229,  0.0270, -0.0463,  ..., -0.0036,  0.0068,  0.0032],
        [ 0.0056, -0.0303,  0.0012,  ...,  0.0008, -0.0020,  0.0246]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 5.7109, -5.6211, -2.6348,  ..., -1.1484,  2.0098, -0.7881]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 00:41:58 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A beard is made up of hair
A clothing is made up of fabric
A wire is made up of metal
A yogurt is made up of milk
A glacier is made up of ice
A chocolate is made up of cocoa
A desk is made up of wood
A lawn is made up of
2024-07-31 00:41:59 root INFO     [order_1_approx] starting weight calculation for A chocolate is made up of cocoa
A yogurt is made up of milk
A lawn is made up of grass
A glacier is made up of ice
A beard is made up of hair
A wire is made up of metal
A desk is made up of wood
A clothing is made up of
2024-07-31 00:41:59 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-31 00:42:07 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0276, -0.2380, -0.1802,  ..., -0.2067, -0.3645,  0.2360],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.7051, -2.7891,  0.7119,  ...,  0.6558, -2.1387, -4.3281],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 5.3009e-02, -1.3565e-02,  3.4515e-02,  ..., -1.6449e-02,
          1.6052e-02,  2.0294e-02],
        [-5.3940e-03,  6.0883e-02, -1.0956e-02,  ...,  2.0584e-02,
          5.0125e-03, -5.5817e-02],
        [ 1.6373e-02,  1.0414e-03,  6.7200e-02,  ...,  7.4272e-03,
         -8.7128e-03,  2.5970e-02],
        ...,
        [ 1.5259e-02, -1.8341e-02,  2.2949e-02,  ...,  4.4708e-02,
          1.5495e-02,  1.6495e-02],
        [ 2.3483e-02, -1.5854e-02, -2.2888e-05,  ...,  3.2715e-02,
          4.1321e-02, -8.5907e-03],
        [-1.2680e-02, -1.1490e-02,  7.6218e-03,  ..., -7.5150e-03,
         -9.0332e-03,  1.4069e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.0215, -2.6211,  0.5552,  ...,  0.6299, -2.2246, -3.6172]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 00:42:08 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is too stimulated, it is overstimulated
If something is too laid, it is overlaid
If something is too sold, it is oversold
If something is too cooked, it is overcooked
If something is too dressed, it is overdressed
If something is too inflated, it is overinflated
If something is too arching, it is overarching
If something is too heard, it is
2024-07-31 00:42:08 root INFO     [order_1_approx] starting weight calculation for If something is too dressed, it is overdressed
If something is too heard, it is overheard
If something is too inflated, it is overinflated
If something is too laid, it is overlaid
If something is too cooked, it is overcooked
If something is too arching, it is overarching
If something is too stimulated, it is overstimulated
If something is too sold, it is
2024-07-31 00:42:08 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-31 00:44:37 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0380, -0.2083, -0.3984,  ...,  0.1489, -0.1149,  0.0497],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 5.8555, -8.6172,  1.4033,  ..., -0.3164, -1.4355,  1.0732],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0064, -0.0065, -0.0020,  ...,  0.0362, -0.0168,  0.0255],
        [ 0.0045,  0.0065, -0.0023,  ...,  0.0215, -0.0038,  0.0009],
        [-0.0036,  0.0201, -0.0028,  ...,  0.0199, -0.0271, -0.0062],
        ...,
        [ 0.0241, -0.0090,  0.0085,  ...,  0.0523, -0.0014, -0.0137],
        [-0.0017,  0.0115, -0.0178,  ...,  0.0027,  0.0041, -0.0166],
        [ 0.0058, -0.0088, -0.0036,  ..., -0.0203,  0.0295,  0.0235]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 5.7734e+00, -8.7578e+00,  1.2002e+00,  ..., -6.8359e-03,
         -1.7949e+00,  5.9570e-01]], device='cuda:0', dtype=torch.float16,
       grad_fn=<SubBackward0>) 

                    
2024-07-31 00:44:38 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A chocolate is made up of cocoa
A yogurt is made up of milk
A lawn is made up of grass
A glacier is made up of ice
A beard is made up of hair
A wire is made up of metal
A desk is made up of wood
A clothing is made up of
2024-07-31 00:44:38 root INFO     [order_1_approx] starting weight calculation for A glacier is made up of ice
A beard is made up of hair
A wire is made up of metal
A clothing is made up of fabric
A desk is made up of wood
A lawn is made up of grass
A yogurt is made up of milk
A chocolate is made up of
2024-07-31 00:44:38 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-31 00:44:40 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0938, -0.2610, -0.1444,  ..., -0.0472, -0.2079,  0.2588],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.9736, -3.4961, -0.1021,  ..., -0.9678, -3.2539, -1.3818],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0610, -0.0221, -0.0072,  ...,  0.0168,  0.0154,  0.0211],
        [ 0.0094,  0.0553, -0.0034,  ...,  0.0075, -0.0128, -0.0076],
        [ 0.0188, -0.0025,  0.0385,  ...,  0.0080,  0.0063,  0.0132],
        ...,
        [ 0.0090,  0.0009,  0.0238,  ...,  0.0340,  0.0061,  0.0254],
        [-0.0067,  0.0237, -0.0010,  ...,  0.0002,  0.0336, -0.0118],
        [ 0.0017,  0.0290, -0.0036,  ...,  0.0066, -0.0225,  0.0393]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.9785, -3.5508,  0.0837,  ..., -0.7695, -3.2012, -1.2793]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 00:44:41 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is too dressed, it is overdressed
If something is too heard, it is overheard
If something is too inflated, it is overinflated
If something is too laid, it is overlaid
If something is too cooked, it is overcooked
If something is too arching, it is overarching
If something is too stimulated, it is overstimulated
If something is too sold, it is
2024-07-31 00:44:41 root INFO     [order_1_approx] starting weight calculation for If something is too sold, it is oversold
If something is too cooked, it is overcooked
If something is too laid, it is overlaid
If something is too heard, it is overheard
If something is too stimulated, it is overstimulated
If something is too inflated, it is overinflated
If something is too arching, it is overarching
If something is too dressed, it is
2024-07-31 00:44:41 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-31 00:47:11 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1576,  0.0271, -0.4312,  ..., -0.0526, -0.3521, -0.1843],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.8652, -3.7461, -1.0176,  ..., -3.3535, -4.2812,  6.4648],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0061, -0.0073,  0.0090,  ...,  0.0027, -0.0014,  0.0030],
        [-0.0103,  0.0208,  0.0006,  ...,  0.0008,  0.0005, -0.0077],
        [-0.0061,  0.0064,  0.0018,  ..., -0.0013,  0.0058, -0.0027],
        ...,
        [ 0.0093,  0.0051,  0.0167,  ...,  0.0191, -0.0062,  0.0045],
        [-0.0057, -0.0054, -0.0177,  ...,  0.0189,  0.0018,  0.0055],
        [-0.0015, -0.0083, -0.0072,  ..., -0.0035, -0.0042,  0.0116]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.7305, -3.6582, -0.9497,  ..., -3.1719, -4.2656,  6.5391]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 00:47:12 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1835, -0.3066, -0.2537,  ...,  0.0157, -0.3521,  0.0478],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.8750, -4.4492, -0.7812,  ...,  1.8965, -4.5938, -2.2930],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0377, -0.0126, -0.0072,  ..., -0.0012,  0.0102, -0.0022],
        [-0.0096,  0.0437, -0.0022,  ..., -0.0030, -0.0121,  0.0039],
        [ 0.0373, -0.0075,  0.0103,  ...,  0.0036,  0.0195,  0.0251],
        ...,
        [ 0.0088,  0.0146, -0.0011,  ...,  0.0437,  0.0125, -0.0052],
        [-0.0046, -0.0053,  0.0007,  ...,  0.0080,  0.0185, -0.0205],
        [ 0.0001, -0.0039,  0.0201,  ...,  0.0121, -0.0196,  0.0209]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.6611, -4.4141, -0.9116,  ...,  2.0645, -4.0859, -2.3320]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 00:47:12 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A glacier is made up of ice
A beard is made up of hair
A wire is made up of metal
A clothing is made up of fabric
A desk is made up of wood
A lawn is made up of grass
A yogurt is made up of milk
A chocolate is made up of
2024-07-31 00:47:12 root INFO     total operator prediction time: 1271.5556342601776 seconds
2024-07-31 00:47:12 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on hypernyms - misc
2024-07-31 00:47:12 root INFO     building operator hypernyms - misc
2024-07-31 00:47:13 root INFO     [order_1_approx] starting weight calculation for The tub falls into the category of container
The sidewalk falls into the category of walk
The notebook falls into the category of book
The deodorant falls into the category of toiletry
The vase falls into the category of jar
The necklace falls into the category of jewelry
The fridge falls into the category of appliance
The pastry falls into the category of
2024-07-31 00:47:13 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is too sold, it is oversold
If something is too cooked, it is overcooked
If something is too laid, it is overlaid
If something is too heard, it is overheard
If something is too stimulated, it is overstimulated
If something is too inflated, it is overinflated
If something is too arching, it is overarching
If something is too dressed, it is
2024-07-31 00:47:13 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-31 00:47:13 root INFO     [order_1_approx] starting weight calculation for If something is too heard, it is overheard
If something is too cooked, it is overcooked
If something is too stimulated, it is overstimulated
If something is too sold, it is oversold
If something is too dressed, it is overdressed
If something is too laid, it is overlaid
If something is too arching, it is overarching
If something is too inflated, it is
2024-07-31 00:47:13 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-31 00:49:46 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2413, -0.3462, -0.1586,  ...,  0.2705, -0.0765,  0.2277],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.1465, -3.2168,  1.5508,  ..., -0.6025, -0.1735, -2.8770],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 5.8350e-02, -5.8517e-03, -1.8402e-02,  ...,  1.2024e-02,
          7.5684e-03,  1.2646e-03],
        [-2.1927e-02,  4.9500e-02,  8.7662e-03,  ..., -2.7905e-03,
          4.7226e-03, -8.9645e-05],
        [ 7.1793e-03,  7.3395e-03,  2.9907e-02,  ..., -8.5831e-03,
         -1.1284e-02,  1.3161e-04],
        ...,
        [ 1.5533e-02,  1.7685e-02, -7.3700e-03,  ...,  6.0120e-02,
         -6.2370e-03,  1.2604e-02],
        [ 2.0752e-02,  2.2995e-02,  2.9774e-03,  ...,  1.6127e-03,
          4.3549e-02, -2.9312e-02],
        [-1.1215e-02,  1.5282e-02,  3.8544e-02,  ...,  3.0060e-03,
         -4.0207e-03,  5.5725e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.5020, -3.4844,  1.4600,  ..., -0.3857, -0.4565, -3.4707]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 00:49:47 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is too heard, it is overheard
If something is too cooked, it is overcooked
If something is too stimulated, it is overstimulated
If something is too sold, it is oversold
If something is too dressed, it is overdressed
If something is too laid, it is overlaid
If something is too arching, it is overarching
If something is too inflated, it is
2024-07-31 00:49:48 root INFO     [order_1_approx] starting weight calculation for If something is too cooked, it is overcooked
If something is too arching, it is overarching
If something is too heard, it is overheard
If something is too stimulated, it is overstimulated
If something is too inflated, it is overinflated
If something is too sold, it is oversold
If something is too dressed, it is overdressed
If something is too laid, it is
2024-07-31 00:49:48 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-31 00:49:51 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0195, -0.0612,  0.2024,  ...,  0.0981, -0.3672,  0.0741],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.6484, -6.6328, -0.0942,  ..., -2.1074, -3.3008,  0.7803],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 3.4149e-02,  1.8936e-02, -9.4528e-03,  ...,  6.4392e-03,
         -2.1545e-02,  2.1088e-02],
        [-5.0507e-03,  3.8940e-02,  3.5492e-02,  ...,  2.8610e-03,
         -1.9333e-02,  1.7853e-03],
        [-2.0859e-02,  4.6921e-04,  1.6846e-02,  ...,  1.6235e-02,
         -2.0584e-02,  5.5237e-03],
        ...,
        [ 7.7934e-03,  2.0523e-02,  1.1391e-02,  ...,  5.2460e-02,
         -2.7679e-02, -7.5150e-03],
        [ 4.8981e-03, -1.4069e-02, -6.4392e-03,  ..., -9.8343e-03,
          5.2521e-02, -1.0071e-02],
        [ 7.4005e-03, -6.8665e-05,  2.9587e-02,  ..., -1.5747e-02,
          2.7069e-02,  5.2521e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.5234, -6.0742, -0.8921,  ..., -1.8750, -3.2734,  1.6650]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 00:49:52 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The tub falls into the category of container
The sidewalk falls into the category of walk
The notebook falls into the category of book
The deodorant falls into the category of toiletry
The vase falls into the category of jar
The necklace falls into the category of jewelry
The fridge falls into the category of appliance
The pastry falls into the category of
2024-07-31 00:49:52 root INFO     [order_1_approx] starting weight calculation for The vase falls into the category of jar
The fridge falls into the category of appliance
The necklace falls into the category of jewelry
The pastry falls into the category of food
The tub falls into the category of container
The notebook falls into the category of book
The sidewalk falls into the category of walk
The deodorant falls into the category of
2024-07-31 00:49:53 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-31 00:52:19 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2500,  0.3894, -0.2603,  ..., -0.2825, -0.3547,  0.0651],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.7852, -3.0176,  0.1016,  ...,  1.4316, -2.1777, -2.6055],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 6.8665e-02, -1.9165e-02,  1.9722e-03,  ...,  1.7090e-03,
         -5.5237e-03,  9.6893e-03],
        [-5.5313e-04,  6.2408e-02,  5.7755e-03,  ...,  4.9515e-03,
         -1.7578e-02, -1.1200e-02],
        [ 2.4094e-02, -3.3722e-02,  5.2094e-02,  ..., -1.3981e-03,
         -2.2934e-02, -5.1270e-03],
        ...,
        [ 2.3514e-02,  1.7670e-02, -1.9379e-02,  ...,  4.8706e-02,
          2.1896e-02, -4.9591e-05],
        [ 4.8523e-03, -1.7960e-02, -8.3618e-03,  ...,  1.6663e-02,
          4.2267e-02, -4.1138e-02],
        [-1.3077e-02, -1.6174e-02,  1.2733e-02,  ..., -4.4975e-03,
         -1.9928e-02,  4.3945e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.4336, -2.9199, -0.1093,  ...,  1.6318, -2.0391, -2.3223]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 00:52:20 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is too cooked, it is overcooked
If something is too arching, it is overarching
If something is too heard, it is overheard
If something is too stimulated, it is overstimulated
If something is too inflated, it is overinflated
If something is too sold, it is oversold
If something is too dressed, it is overdressed
If something is too laid, it is
2024-07-31 00:52:20 root INFO     [order_1_approx] starting weight calculation for If something is too inflated, it is overinflated
If something is too stimulated, it is overstimulated
If something is too laid, it is overlaid
If something is too heard, it is overheard
If something is too dressed, it is overdressed
If something is too arching, it is overarching
If something is too sold, it is oversold
If something is too cooked, it is
2024-07-31 00:52:20 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-31 00:52:28 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1492, -0.6152,  0.0294,  ...,  0.0261, -0.3647, -0.3555],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.3086, -2.8945,  0.6133,  ..., -2.7324, -4.1211,  0.4668],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0200, -0.0009, -0.0078,  ..., -0.0040, -0.0032,  0.0090],
        [-0.0009,  0.0043, -0.0157,  ...,  0.0086, -0.0110,  0.0129],
        [-0.0087,  0.0058,  0.0122,  ..., -0.0009, -0.0117, -0.0035],
        ...,
        [ 0.0162, -0.0028,  0.0084,  ...,  0.0360, -0.0042,  0.0041],
        [-0.0120,  0.0062,  0.0103,  ...,  0.0044,  0.0297,  0.0010],
        [ 0.0006, -0.0085,  0.0035,  ...,  0.0057, -0.0066,  0.0344]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.1777, -3.0762,  0.5981,  ..., -2.7012, -3.9668,  0.3743]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 00:52:29 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The vase falls into the category of jar
The fridge falls into the category of appliance
The necklace falls into the category of jewelry
The pastry falls into the category of food
The tub falls into the category of container
The notebook falls into the category of book
The sidewalk falls into the category of walk
The deodorant falls into the category of
2024-07-31 00:52:29 root INFO     [order_1_approx] starting weight calculation for The tub falls into the category of container
The pastry falls into the category of food
The vase falls into the category of jar
The deodorant falls into the category of toiletry
The necklace falls into the category of jewelry
The fridge falls into the category of appliance
The notebook falls into the category of book
The sidewalk falls into the category of
2024-07-31 00:52:29 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-31 00:54:53 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0019, -0.2085, -0.1703,  ..., -0.3665, -0.6611,  0.2268],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.4824, -2.8672,  0.3823,  ..., -0.5293, -1.8447, -1.5361],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0476,  0.0147,  0.0155,  ...,  0.0121, -0.0098,  0.0031],
        [ 0.0046,  0.0246,  0.0020,  ..., -0.0022,  0.0034, -0.0283],
        [ 0.0075, -0.0231,  0.0087,  ...,  0.0087, -0.0058,  0.0206],
        ...,
        [ 0.0060, -0.0128,  0.0131,  ...,  0.0466, -0.0017,  0.0157],
        [ 0.0030, -0.0018, -0.0151,  ...,  0.0086,  0.0323, -0.0120],
        [-0.0123, -0.0045, -0.0020,  ...,  0.0064, -0.0153,  0.0474]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.6758, -2.7441,  0.4277,  ..., -0.5229, -1.7480, -1.5303]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 00:54:53 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is too inflated, it is overinflated
If something is too stimulated, it is overstimulated
If something is too laid, it is overlaid
If something is too heard, it is overheard
If something is too dressed, it is overdressed
If something is too arching, it is overarching
If something is too sold, it is oversold
If something is too cooked, it is
2024-07-31 00:54:54 root INFO     total operator prediction time: 1223.6279377937317 seconds
2024-07-31 00:54:54 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on verb+er_irreg
2024-07-31 00:54:54 root INFO     building operator verb+er_irreg
2024-07-31 00:54:54 root INFO     [order_1_approx] starting weight calculation for If you promote something, you are a promoter
If you begin something, you are a beginner
If you defend something, you are a defender
If you provide something, you are a provider
If you develop something, you are a developer
If you believe something, you are a believer
If you eat something, you are a eater
If you receive something, you are a
2024-07-31 00:54:54 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-31 00:55:07 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1176,  0.0731, -0.1995,  ...,  0.1921, -0.2197, -0.1331],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.6436, -3.8691,  1.8604,  ...,  0.1178, -3.5586, -0.0283],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0775, -0.0060, -0.0278,  ...,  0.0169, -0.0036, -0.0107],
        [-0.0068,  0.0227,  0.0238,  ..., -0.0065, -0.0086, -0.0078],
        [-0.0277,  0.0348,  0.0486,  ..., -0.0375,  0.0137,  0.0175],
        ...,
        [-0.0052,  0.0033,  0.0100,  ...,  0.0434, -0.0114, -0.0072],
        [ 0.0133, -0.0200,  0.0215,  ..., -0.0115,  0.0434,  0.0176],
        [ 0.0054, -0.0142,  0.0144,  ...,  0.0035,  0.0089,  0.0214]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.8945, -3.8789,  1.6641,  ...,  0.1680, -3.2500,  0.5620]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 00:55:08 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The tub falls into the category of container
The pastry falls into the category of food
The vase falls into the category of jar
The deodorant falls into the category of toiletry
The necklace falls into the category of jewelry
The fridge falls into the category of appliance
The notebook falls into the category of book
The sidewalk falls into the category of
2024-07-31 00:55:08 root INFO     [order_1_approx] starting weight calculation for The vase falls into the category of jar
The necklace falls into the category of jewelry
The fridge falls into the category of appliance
The notebook falls into the category of book
The deodorant falls into the category of toiletry
The sidewalk falls into the category of walk
The pastry falls into the category of food
The tub falls into the category of
2024-07-31 00:55:08 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-31 00:57:25 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1037,  0.0757, -0.3550,  ..., -0.1677, -0.0463, -0.0483],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.6152, -0.1533, -1.6914,  ..., -1.8721, -3.7168, -3.4570],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0433, -0.0110,  0.0274,  ...,  0.0148,  0.0157,  0.0152],
        [-0.0233,  0.0294,  0.0115,  ...,  0.0157, -0.0131, -0.0071],
        [-0.0026, -0.0025,  0.0091,  ..., -0.0095,  0.0127,  0.0093],
        ...,
        [ 0.0378, -0.0078, -0.0075,  ...,  0.0554, -0.0035,  0.0076],
        [ 0.0148,  0.0150, -0.0005,  ..., -0.0208,  0.0317,  0.0060],
        [ 0.0035,  0.0014, -0.0096,  ..., -0.0101,  0.0001,  0.0131]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.4941,  0.2817, -1.6562,  ..., -1.3086, -4.1094, -3.9102]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 00:57:26 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you promote something, you are a promoter
If you begin something, you are a beginner
If you defend something, you are a defender
If you provide something, you are a provider
If you develop something, you are a developer
If you believe something, you are a believer
If you eat something, you are a eater
If you receive something, you are a
2024-07-31 00:57:26 root INFO     [order_1_approx] starting weight calculation for If you receive something, you are a receiver
If you eat something, you are a eater
If you promote something, you are a promoter
If you develop something, you are a developer
If you defend something, you are a defender
If you begin something, you are a beginner
If you provide something, you are a provider
If you believe something, you are a
2024-07-31 00:57:26 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-31 00:57:45 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2578, -0.4280,  0.2754,  ..., -0.1705, -0.1943,  0.0628],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.2566, -2.2617,  3.4805,  ..., -0.8643, -2.3906,  1.8027],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0652,  0.0177, -0.0223,  ..., -0.0034, -0.0282,  0.0183],
        [-0.0102,  0.0377,  0.0214,  ...,  0.0146,  0.0097, -0.0202],
        [ 0.0115,  0.0213,  0.0422,  ..., -0.0173, -0.0385,  0.0263],
        ...,
        [ 0.0505,  0.0182,  0.0197,  ...,  0.0333,  0.0190, -0.0230],
        [ 0.0072,  0.0035, -0.0013,  ...,  0.0200,  0.0392, -0.0047],
        [ 0.0044, -0.0120,  0.0042,  ...,  0.0075,  0.0204,  0.0259]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.1799, -2.4316,  2.9766,  ..., -1.3750, -2.1855,  1.6387]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 00:57:46 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The vase falls into the category of jar
The necklace falls into the category of jewelry
The fridge falls into the category of appliance
The notebook falls into the category of book
The deodorant falls into the category of toiletry
The sidewalk falls into the category of walk
The pastry falls into the category of food
The tub falls into the category of
2024-07-31 00:57:46 root INFO     [order_1_approx] starting weight calculation for The pastry falls into the category of food
The fridge falls into the category of appliance
The tub falls into the category of container
The sidewalk falls into the category of walk
The vase falls into the category of jar
The notebook falls into the category of book
The deodorant falls into the category of toiletry
The necklace falls into the category of
2024-07-31 00:57:46 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-31 00:59:58 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2588,  0.3140, -0.1578,  ...,  0.2886, -0.1384,  0.3052],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.9609, -3.5625,  3.1426,  ..., -0.6758, -4.6094, -3.3887],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0149, -0.0086, -0.0079,  ...,  0.0195,  0.0127,  0.0007],
        [-0.0168,  0.0236,  0.0221,  ...,  0.0014,  0.0004, -0.0089],
        [ 0.0105, -0.0076,  0.0197,  ...,  0.0080, -0.0053,  0.0351],
        ...,
        [ 0.0103,  0.0149,  0.0161,  ...,  0.0103,  0.0011,  0.0032],
        [-0.0060, -0.0031,  0.0028,  ..., -0.0012,  0.0027, -0.0066],
        [ 0.0030,  0.0004, -0.0085,  ..., -0.0069, -0.0117, -0.0016]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.9844, -3.7070,  2.8926,  ..., -0.4888, -4.6562, -3.5859]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 00:59:59 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you receive something, you are a receiver
If you eat something, you are a eater
If you promote something, you are a promoter
If you develop something, you are a developer
If you defend something, you are a defender
If you begin something, you are a beginner
If you provide something, you are a provider
If you believe something, you are a
2024-07-31 00:59:59 root INFO     [order_1_approx] starting weight calculation for If you eat something, you are a eater
If you provide something, you are a provider
If you begin something, you are a beginner
If you defend something, you are a defender
If you promote something, you are a promoter
If you believe something, you are a believer
If you receive something, you are a receiver
If you develop something, you are a
2024-07-31 00:59:59 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-31 01:00:26 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0345,  0.0197, -0.1616,  ..., -0.1333, -0.1921, -0.1522],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.9941, -7.5625, -3.7266,  ..., -0.4644, -5.0547,  1.4414],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0438, -0.0044,  0.0065,  ..., -0.0228,  0.0146,  0.0253],
        [-0.0014,  0.0331,  0.0024,  ..., -0.0220, -0.0088, -0.0009],
        [ 0.0298, -0.0205,  0.0252,  ...,  0.0344, -0.0200,  0.0015],
        ...,
        [ 0.0099,  0.0012,  0.0099,  ...,  0.0227,  0.0251, -0.0222],
        [ 0.0070, -0.0241, -0.0036,  ...,  0.0223,  0.0437, -0.0074],
        [ 0.0032,  0.0060,  0.0272,  ..., -0.0350,  0.0052,  0.0397]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.6377, -6.9727, -3.4414,  ..., -0.3792, -4.7148,  1.4717]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 01:00:27 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The pastry falls into the category of food
The fridge falls into the category of appliance
The tub falls into the category of container
The sidewalk falls into the category of walk
The vase falls into the category of jar
The notebook falls into the category of book
The deodorant falls into the category of toiletry
The necklace falls into the category of
2024-07-31 01:00:27 root INFO     [order_1_approx] starting weight calculation for The pastry falls into the category of food
The vase falls into the category of jar
The necklace falls into the category of jewelry
The deodorant falls into the category of toiletry
The notebook falls into the category of book
The sidewalk falls into the category of walk
The tub falls into the category of container
The fridge falls into the category of
2024-07-31 01:00:28 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-31 01:02:29 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1063, -0.0400, -0.4768,  ..., -0.0174, -0.1722, -0.0635],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.3555, -3.8359,  3.0645,  ...,  2.4570, -5.3711, -3.8477],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0284,  0.0029,  0.0173,  ..., -0.0037,  0.0090,  0.0094],
        [-0.0025,  0.0356, -0.0002,  ...,  0.0139, -0.0067, -0.0029],
        [-0.0070, -0.0019,  0.0341,  ..., -0.0262, -0.0139,  0.0002],
        ...,
        [ 0.0178,  0.0172,  0.0158,  ...,  0.0218, -0.0112,  0.0112],
        [ 0.0009,  0.0046, -0.0128,  ...,  0.0045,  0.0142, -0.0035],
        [ 0.0058,  0.0064, -0.0193,  ...,  0.0045, -0.0234,  0.0158]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.2422, -3.8496,  2.6992,  ...,  2.4785, -5.3945, -4.0742]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 01:02:30 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you eat something, you are a eater
If you provide something, you are a provider
If you begin something, you are a beginner
If you defend something, you are a defender
If you promote something, you are a promoter
If you believe something, you are a believer
If you receive something, you are a receiver
If you develop something, you are a
2024-07-31 01:02:30 root INFO     [order_1_approx] starting weight calculation for If you begin something, you are a beginner
If you believe something, you are a believer
If you receive something, you are a receiver
If you eat something, you are a eater
If you develop something, you are a developer
If you provide something, you are a provider
If you defend something, you are a defender
If you promote something, you are a
2024-07-31 01:02:30 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-31 01:03:08 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.3071, -0.0126,  0.0071,  ...,  0.0276, -0.4766,  0.0466],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.0105, -5.6992,  4.8477,  ..., -1.0840, -2.5234,  0.6367],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0658, -0.0246, -0.0317,  ..., -0.0016, -0.0075, -0.0020],
        [-0.0086,  0.0400,  0.0281,  ..., -0.0243, -0.0049, -0.0059],
        [-0.0060, -0.0028,  0.0028,  ...,  0.0035,  0.0002,  0.0185],
        ...,
        [ 0.0105,  0.0151,  0.0082,  ...,  0.0360, -0.0184, -0.0046],
        [ 0.0199,  0.0079, -0.0106,  ..., -0.0071,  0.0522, -0.0136],
        [-0.0032,  0.0160, -0.0020,  ..., -0.0089,  0.0149,  0.0508]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.5811, -5.8164,  4.6523,  ..., -0.9883, -2.3652,  0.0161]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 01:03:08 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The pastry falls into the category of food
The vase falls into the category of jar
The necklace falls into the category of jewelry
The deodorant falls into the category of toiletry
The notebook falls into the category of book
The sidewalk falls into the category of walk
The tub falls into the category of container
The fridge falls into the category of
2024-07-31 01:03:09 root INFO     [order_1_approx] starting weight calculation for The tub falls into the category of container
The necklace falls into the category of jewelry
The fridge falls into the category of appliance
The pastry falls into the category of food
The vase falls into the category of jar
The deodorant falls into the category of toiletry
The sidewalk falls into the category of walk
The notebook falls into the category of
2024-07-31 01:03:09 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-31 01:05:01 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2196,  0.1833, -0.1653,  ...,  0.4072,  0.1405,  0.1899],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.4219, -3.0957,  1.6738,  ...,  1.8916, -4.8438, -3.7500],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0218,  0.0015,  0.0160,  ...,  0.0242, -0.0038,  0.0032],
        [-0.0055,  0.0152,  0.0134,  ...,  0.0034,  0.0042, -0.0170],
        [ 0.0025, -0.0066,  0.0157,  ...,  0.0098, -0.0063,  0.0099],
        ...,
        [ 0.0052,  0.0109, -0.0066,  ...,  0.0327, -0.0100, -0.0077],
        [ 0.0069,  0.0008, -0.0182,  ..., -0.0306,  0.0132, -0.0088],
        [ 0.0228, -0.0089, -0.0138,  ..., -0.0132, -0.0184,  0.0226]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 5.0039, -3.4785,  1.6445,  ...,  1.8164, -5.1836, -4.0273]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 01:05:02 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you begin something, you are a beginner
If you believe something, you are a believer
If you receive something, you are a receiver
If you eat something, you are a eater
If you develop something, you are a developer
If you provide something, you are a provider
If you defend something, you are a defender
If you promote something, you are a
2024-07-31 01:05:02 root INFO     [order_1_approx] starting weight calculation for If you eat something, you are a eater
If you promote something, you are a promoter
If you provide something, you are a provider
If you begin something, you are a beginner
If you develop something, you are a developer
If you receive something, you are a receiver
If you believe something, you are a believer
If you defend something, you are a
2024-07-31 01:05:02 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-31 01:05:45 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.5322, -0.0531, -0.1523,  ...,  0.2764, -0.3118, -0.1071],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.0781, -4.0156,  2.2109,  ..., -1.7480, -2.9902, -0.8804],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0355,  0.0019, -0.0024,  ..., -0.0125,  0.0069,  0.0174],
        [ 0.0075,  0.0321,  0.0082,  ...,  0.0007, -0.0161, -0.0045],
        [-0.0016, -0.0161,  0.0415,  ..., -0.0077, -0.0363,  0.0097],
        ...,
        [ 0.0355,  0.0045,  0.0045,  ...,  0.0351, -0.0336, -0.0026],
        [ 0.0008, -0.0003,  0.0174,  ...,  0.0260,  0.0381, -0.0054],
        [ 0.0024,  0.0005,  0.0303,  ..., -0.0262, -0.0011,  0.0471]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.9453, -4.1094,  1.8203,  ..., -1.8984, -2.9941, -0.8525]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 01:05:45 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The tub falls into the category of container
The necklace falls into the category of jewelry
The fridge falls into the category of appliance
The pastry falls into the category of food
The vase falls into the category of jar
The deodorant falls into the category of toiletry
The sidewalk falls into the category of walk
The notebook falls into the category of
2024-07-31 01:05:46 root INFO     [order_1_approx] starting weight calculation for The deodorant falls into the category of toiletry
The pastry falls into the category of food
The fridge falls into the category of appliance
The tub falls into the category of container
The notebook falls into the category of book
The necklace falls into the category of jewelry
The sidewalk falls into the category of walk
The vase falls into the category of
2024-07-31 01:05:46 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-31 01:07:32 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1982,  0.1810, -0.2578,  ...,  0.1667, -0.0328,  0.3916],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.8574, -4.5234,  2.8477,  ..., -3.2637, -3.5977, -4.0898],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 2.7756e-02,  8.8806e-03,  1.4603e-02,  ...,  3.6240e-03,
          1.5350e-02, -8.0566e-03],
        [ 1.0509e-03,  1.8951e-02,  3.9558e-03,  ..., -3.6964e-03,
          1.7395e-02, -2.3689e-03],
        [ 4.5242e-03,  9.8343e-03,  2.3041e-02,  ..., -1.2146e-02,
          2.4658e-02, -7.9575e-03],
        ...,
        [ 1.9547e-02,  1.1086e-02, -1.3397e-02,  ...,  2.4979e-02,
          9.6512e-03,  7.9803e-03],
        [ 3.9406e-03,  3.8605e-03, -1.6754e-02,  ..., -7.4883e-03,
          1.5602e-02, -7.0610e-03],
        [ 5.0735e-03,  7.6294e-06, -6.0463e-03,  ...,  1.5697e-03,
         -1.3550e-02,  5.3940e-03]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.1914, -4.7891,  2.5586,  ..., -2.7129, -3.7402, -4.2148]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 01:07:33 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you eat something, you are a eater
If you promote something, you are a promoter
If you provide something, you are a provider
If you begin something, you are a beginner
If you develop something, you are a developer
If you receive something, you are a receiver
If you believe something, you are a believer
If you defend something, you are a
2024-07-31 01:07:33 root INFO     [order_1_approx] starting weight calculation for If you receive something, you are a receiver
If you develop something, you are a developer
If you defend something, you are a defender
If you believe something, you are a believer
If you eat something, you are a eater
If you promote something, you are a promoter
If you begin something, you are a beginner
If you provide something, you are a
2024-07-31 01:07:33 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-31 01:08:23 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1582, -0.1804,  0.0275,  ...,  0.0973, -0.1212, -0.3215],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.1328, -2.6250,  0.4155,  ..., -2.8516, -3.8164,  1.5635],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0659,  0.0211, -0.0246,  ...,  0.0079, -0.0005,  0.0411],
        [ 0.0059,  0.0536,  0.0234,  ...,  0.0013, -0.0306, -0.0043],
        [-0.0069, -0.0160,  0.0180,  ..., -0.0146, -0.0098,  0.0003],
        ...,
        [ 0.0142, -0.0363,  0.0246,  ...,  0.0267, -0.0021, -0.0292],
        [ 0.0012,  0.0012,  0.0038,  ...,  0.0321,  0.0292,  0.0100],
        [ 0.0183, -0.0153,  0.0309,  ..., -0.0373,  0.0194,  0.0233]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.0742, -2.8379,  0.3120,  ..., -2.3770, -3.2305,  1.1504]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 01:08:23 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The deodorant falls into the category of toiletry
The pastry falls into the category of food
The fridge falls into the category of appliance
The tub falls into the category of container
The notebook falls into the category of book
The necklace falls into the category of jewelry
The sidewalk falls into the category of walk
The vase falls into the category of
2024-07-31 01:08:23 root INFO     total operator prediction time: 1271.1721391677856 seconds
2024-07-31 01:08:23 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on synonyms - exact
2024-07-31 01:08:23 root INFO     building operator synonyms - exact
2024-07-31 01:08:24 root INFO     [order_1_approx] starting weight calculation for Another word for intelligent is clever
Another word for package is parcel
Another word for sofa is couch
Another word for sweets is confectionery
Another word for clothes is clothing
Another word for shore is coast
Another word for new is modern
Another word for auto is
2024-07-31 01:08:24 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-31 01:10:05 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0886, -0.1100, -0.4480,  ...,  0.2993, -0.0637, -0.0688],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.7930, -6.2070,  1.9404,  ...,  0.3955, -4.2930, -1.9473],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0489, -0.0016,  0.0166,  ...,  0.0118,  0.0073,  0.0093],
        [-0.0155,  0.0102,  0.0048,  ...,  0.0147, -0.0043, -0.0017],
        [-0.0051, -0.0117,  0.0453,  ..., -0.0203,  0.0048,  0.0003],
        ...,
        [ 0.0089,  0.0118,  0.0134,  ...,  0.0189,  0.0125,  0.0158],
        [ 0.0134, -0.0095, -0.0235,  ...,  0.0029,  0.0237, -0.0078],
        [ 0.0021,  0.0061, -0.0074,  ..., -0.0011, -0.0116,  0.0273]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.7715, -5.9609,  1.7100,  ...,  0.6396, -4.0664, -2.5684]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 01:10:06 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you receive something, you are a receiver
If you develop something, you are a developer
If you defend something, you are a defender
If you believe something, you are a believer
If you eat something, you are a eater
If you promote something, you are a promoter
If you begin something, you are a beginner
If you provide something, you are a
2024-07-31 01:10:06 root INFO     [order_1_approx] starting weight calculation for If you begin something, you are a beginner
If you believe something, you are a believer
If you defend something, you are a defender
If you develop something, you are a developer
If you promote something, you are a promoter
If you receive something, you are a receiver
If you provide something, you are a provider
If you eat something, you are a
2024-07-31 01:10:07 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-31 01:11:04 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0753,  0.2720,  0.0446,  ..., -0.0626, -0.2554,  0.2253],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.3740, -6.0000,  2.0527,  ..., -0.7505, -0.2888,  1.3506],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0778, -0.0311,  0.0247,  ...,  0.0099,  0.0564, -0.0120],
        [-0.0414,  0.0554,  0.0204,  ..., -0.0206,  0.0290, -0.0432],
        [ 0.0132,  0.0195,  0.0750,  ..., -0.0121, -0.0111,  0.0053],
        ...,
        [-0.0176, -0.0069, -0.0128,  ...,  0.0511,  0.0123, -0.0238],
        [ 0.0208, -0.0002, -0.0051,  ...,  0.0337,  0.0549, -0.0281],
        [-0.0135, -0.0007, -0.0203,  ..., -0.0225,  0.0016,  0.0466]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.9863, -6.0508,  1.7812,  ..., -0.5889, -0.4587,  1.4375]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 01:11:05 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Another word for intelligent is clever
Another word for package is parcel
Another word for sofa is couch
Another word for sweets is confectionery
Another word for clothes is clothing
Another word for shore is coast
Another word for new is modern
Another word for auto is
2024-07-31 01:11:05 root INFO     [order_1_approx] starting weight calculation for Another word for clothes is clothing
Another word for new is modern
Another word for shore is coast
Another word for sofa is couch
Another word for auto is car
Another word for package is parcel
Another word for intelligent is clever
Another word for sweets is
2024-07-31 01:11:05 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-31 01:12:37 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2322, -0.0852, -0.1453,  ..., -0.1837, -0.3599,  0.2451],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.2383,  0.3901,  0.8979,  ...,  0.6934, -6.3594, -2.8066],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0176, -0.0014,  0.0203,  ...,  0.0215,  0.0085,  0.0012],
        [ 0.0052,  0.0297, -0.0132,  ..., -0.0081, -0.0007, -0.0210],
        [ 0.0125,  0.0018,  0.0281,  ..., -0.0090, -0.0116,  0.0169],
        ...,
        [ 0.0144,  0.0030,  0.0084,  ...,  0.0149,  0.0052, -0.0061],
        [-0.0025,  0.0073, -0.0135,  ..., -0.0009,  0.0101, -0.0031],
        [ 0.0149, -0.0179, -0.0033,  ...,  0.0015, -0.0181,  0.0315]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.5312,  0.1508,  0.8164,  ...,  0.7617, -6.0391, -2.9902]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 01:12:38 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you begin something, you are a beginner
If you believe something, you are a believer
If you defend something, you are a defender
If you develop something, you are a developer
If you promote something, you are a promoter
If you receive something, you are a receiver
If you provide something, you are a provider
If you eat something, you are a
2024-07-31 01:12:39 root INFO     [order_1_approx] starting weight calculation for If you believe something, you are a believer
If you eat something, you are a eater
If you develop something, you are a developer
If you receive something, you are a receiver
If you promote something, you are a promoter
If you defend something, you are a defender
If you provide something, you are a provider
If you begin something, you are a
2024-07-31 01:12:39 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-31 01:13:46 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1313, -0.0483,  0.4907,  ..., -0.1356, -0.2720, -0.1399],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.5234, -6.4570,  0.2812,  ..., -2.2871, -1.3975,  3.0078],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0430, -0.0134,  0.0110,  ..., -0.0173, -0.0060,  0.0229],
        [-0.0144,  0.0523,  0.0163,  ...,  0.0115,  0.0013, -0.0282],
        [-0.0022, -0.0164,  0.0240,  ...,  0.0162, -0.0147,  0.0035],
        ...,
        [ 0.0220,  0.0356, -0.0123,  ...,  0.0555,  0.0014,  0.0043],
        [-0.0050,  0.0019, -0.0317,  ...,  0.0051,  0.0243, -0.0101],
        [-0.0295, -0.0108, -0.0084,  ..., -0.0122,  0.0181,  0.0466]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.4570, -6.6562, -0.1987,  ..., -2.2305, -1.3555,  2.8887]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 01:13:46 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Another word for clothes is clothing
Another word for new is modern
Another word for shore is coast
Another word for sofa is couch
Another word for auto is car
Another word for package is parcel
Another word for intelligent is clever
Another word for sweets is
2024-07-31 01:13:47 root INFO     [order_1_approx] starting weight calculation for Another word for auto is car
Another word for clothes is clothing
Another word for new is modern
Another word for intelligent is clever
Another word for sweets is confectionery
Another word for package is parcel
Another word for sofa is couch
Another word for shore is
2024-07-31 01:13:47 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-31 01:15:10 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0009,  0.0440, -0.2271,  ...,  0.2585, -0.4333, -0.0862],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.0098, -2.1035,  0.4907,  ...,  3.4766, -3.5859, -3.1211],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0243, -0.0109,  0.0166,  ...,  0.0282,  0.0218, -0.0066],
        [-0.0002,  0.0367,  0.0161,  ...,  0.0109, -0.0180,  0.0061],
        [-0.0014,  0.0018,  0.0251,  ..., -0.0112, -0.0178, -0.0001],
        ...,
        [ 0.0258,  0.0153,  0.0086,  ...,  0.0210,  0.0014,  0.0083],
        [-0.0070,  0.0247, -0.0080,  ..., -0.0067,  0.0189, -0.0094],
        [ 0.0073,  0.0041,  0.0016,  ..., -0.0027, -0.0116,  0.0164]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.3633, -2.2266,  0.1279,  ...,  3.3223, -3.2910, -3.6172]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 01:15:11 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you believe something, you are a believer
If you eat something, you are a eater
If you develop something, you are a developer
If you receive something, you are a receiver
If you promote something, you are a promoter
If you defend something, you are a defender
If you provide something, you are a provider
If you begin something, you are a
2024-07-31 01:15:11 root INFO     total operator prediction time: 1217.4911007881165 seconds
2024-07-31 01:15:11 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on adj - superlative
2024-07-31 01:15:11 root INFO     building operator adj - superlative
2024-07-31 01:15:11 root INFO     [order_1_approx] starting weight calculation for If something is the most lengthy, it is lengthiest
If something is the most strange, it is strangest
If something is the most mild, it is mildest
If something is the most cute, it is cutest
If something is the most cruel, it is cruelest
If something is the most rude, it is rudest
If something is the most hungry, it is hungriest
If something is the most weak, it is
2024-07-31 01:15:11 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-31 01:16:26 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0200,  0.2585, -0.0709,  ..., -0.2009, -0.0723,  0.2191],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.4414, -3.7266,  0.6914,  ...,  3.5352, -0.2300, -1.9023],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 6.6895e-02, -2.8137e-02, -1.0338e-02,  ...,  4.6387e-02,
         -1.7944e-02,  2.1317e-02],
        [ 7.3395e-03,  6.3110e-02,  1.6357e-02,  ..., -1.3275e-03,
         -9.7275e-05, -1.8845e-02],
        [-5.1453e-02,  1.2558e-02,  9.0637e-02,  ..., -1.2985e-02,
         -3.1071e-03, -1.5793e-02],
        ...,
        [ 9.7198e-03, -6.8932e-03,  1.8967e-02,  ...,  5.6610e-02,
          1.4687e-02, -3.6560e-02],
        [-3.0518e-02, -8.7280e-03,  3.5858e-02,  ...,  1.2779e-02,
          8.9050e-02, -4.4525e-02],
        [-1.1154e-02,  4.5395e-03, -1.4511e-02,  ..., -4.1382e-02,
          3.5934e-03,  6.8665e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.7305, -3.3418,  0.6113,  ...,  2.9648,  0.1113, -1.5117]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 01:16:27 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Another word for auto is car
Another word for clothes is clothing
Another word for new is modern
Another word for intelligent is clever
Another word for sweets is confectionery
Another word for package is parcel
Another word for sofa is couch
Another word for shore is
2024-07-31 01:16:27 root INFO     [order_1_approx] starting weight calculation for Another word for new is modern
Another word for sweets is confectionery
Another word for intelligent is clever
Another word for package is parcel
Another word for auto is car
Another word for shore is coast
Another word for clothes is clothing
Another word for sofa is
2024-07-31 01:16:27 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-31 01:17:42 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1743, -0.0008, -0.3767,  ..., -0.1293, -0.2283,  0.0401],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.1582, -4.5117, -2.6406,  ..., -4.0742,  2.0078, -4.1484],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0115, -0.0063, -0.0039,  ..., -0.0101,  0.0039,  0.0172],
        [-0.0057,  0.0134,  0.0007,  ...,  0.0025, -0.0013,  0.0013],
        [-0.0017, -0.0032,  0.0043,  ...,  0.0103, -0.0118, -0.0046],
        ...,
        [ 0.0113,  0.0122,  0.0100,  ...,  0.0265, -0.0032,  0.0048],
        [ 0.0028, -0.0023, -0.0038,  ...,  0.0040,  0.0059, -0.0419],
        [ 0.0175, -0.0234,  0.0033,  ..., -0.0015, -0.0041, -0.0064]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.6230, -4.2852, -2.9375,  ..., -4.1445,  1.7881, -3.9512]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 01:17:44 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is the most lengthy, it is lengthiest
If something is the most strange, it is strangest
If something is the most mild, it is mildest
If something is the most cute, it is cutest
If something is the most cruel, it is cruelest
If something is the most rude, it is rudest
If something is the most hungry, it is hungriest
If something is the most weak, it is
2024-07-31 01:17:44 root INFO     [order_1_approx] starting weight calculation for If something is the most lengthy, it is lengthiest
If something is the most cute, it is cutest
If something is the most cruel, it is cruelest
If something is the most weak, it is weakest
If something is the most hungry, it is hungriest
If something is the most rude, it is rudest
If something is the most mild, it is mildest
If something is the most strange, it is
2024-07-31 01:17:44 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-31 01:19:06 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2122, -0.1044,  0.1207,  ...,  0.2122, -0.2524, -0.1018],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.5781, -3.2734,  4.0781,  ..., -0.8760, -2.2480, -2.2246],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0566, -0.0123, -0.0121,  ...,  0.0208, -0.0205,  0.0050],
        [-0.0028,  0.0624,  0.0087,  ...,  0.0079,  0.0065, -0.0181],
        [-0.0261,  0.0022,  0.0566,  ...,  0.0014, -0.0208, -0.0120],
        ...,
        [ 0.0361,  0.0281, -0.0178,  ...,  0.0715, -0.0046, -0.0059],
        [ 0.0243,  0.0181, -0.0357,  ..., -0.0100,  0.0656,  0.0043],
        [ 0.0103, -0.0025, -0.0148,  ..., -0.0233,  0.0022,  0.0181]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.3652, -2.6934,  3.4844,  ..., -0.8613, -1.9492, -1.9727]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 01:19:07 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Another word for new is modern
Another word for sweets is confectionery
Another word for intelligent is clever
Another word for package is parcel
Another word for auto is car
Another word for shore is coast
Another word for clothes is clothing
Another word for sofa is
2024-07-31 01:19:07 root INFO     [order_1_approx] starting weight calculation for Another word for sweets is confectionery
Another word for sofa is couch
Another word for package is parcel
Another word for new is modern
Another word for auto is car
Another word for shore is coast
Another word for intelligent is clever
Another word for clothes is
2024-07-31 01:19:07 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-31 01:20:15 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0845,  0.0865, -0.1649,  ..., -0.0953, -0.0358,  0.0785],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.7656, -3.9727, -2.4043,  ..., -1.0117, -1.2021, -2.5273],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0038,  0.0131,  0.0037,  ..., -0.0176, -0.0038,  0.0077],
        [ 0.0176,  0.0295,  0.0063,  ...,  0.0147, -0.0031, -0.0045],
        [-0.0019, -0.0100,  0.0310,  ..., -0.0102, -0.0233,  0.0157],
        ...,
        [-0.0017,  0.0333, -0.0007,  ...,  0.0514,  0.0130, -0.0003],
        [ 0.0090,  0.0123,  0.0151,  ...,  0.0205,  0.0144, -0.0319],
        [-0.0009, -0.0074,  0.0117,  ..., -0.0023, -0.0143,  0.0137]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.0703, -4.2227, -2.2637,  ..., -1.0303, -1.6113, -2.5566]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 01:20:16 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is the most lengthy, it is lengthiest
If something is the most cute, it is cutest
If something is the most cruel, it is cruelest
If something is the most weak, it is weakest
If something is the most hungry, it is hungriest
If something is the most rude, it is rudest
If something is the most mild, it is mildest
If something is the most strange, it is
2024-07-31 01:20:16 root INFO     [order_1_approx] starting weight calculation for If something is the most lengthy, it is lengthiest
If something is the most weak, it is weakest
If something is the most cute, it is cutest
If something is the most hungry, it is hungriest
If something is the most cruel, it is cruelest
If something is the most rude, it is rudest
If something is the most strange, it is strangest
If something is the most mild, it is
2024-07-31 01:20:16 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-31 01:21:43 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0366, -0.1897, -0.1460,  ...,  0.1439, -0.0721,  0.1801],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.3008, -3.2559,  0.6816,  ..., -1.5967, -2.7461, -1.6387],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0252, -0.0130,  0.0402,  ..., -0.0087, -0.0036,  0.0284],
        [ 0.0023,  0.0363,  0.0026,  ..., -0.0109,  0.0080, -0.0018],
        [-0.0038,  0.0079,  0.0326,  ...,  0.0096, -0.0243,  0.0067],
        ...,
        [ 0.0115, -0.0192,  0.0261,  ...,  0.0245, -0.0165, -0.0126],
        [-0.0245, -0.0119, -0.0022,  ...,  0.0182,  0.0715, -0.0124],
        [-0.0124,  0.0050,  0.0275,  ..., -0.0130, -0.0113,  0.0094]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.2207, -2.6738,  0.8955,  ..., -1.3916, -2.6289, -1.1045]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 01:21:44 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Another word for sweets is confectionery
Another word for sofa is couch
Another word for package is parcel
Another word for new is modern
Another word for auto is car
Another word for shore is coast
Another word for intelligent is clever
Another word for clothes is
2024-07-31 01:21:44 root INFO     [order_1_approx] starting weight calculation for Another word for sofa is couch
Another word for auto is car
Another word for sweets is confectionery
Another word for clothes is clothing
Another word for shore is coast
Another word for intelligent is clever
Another word for package is parcel
Another word for new is
2024-07-31 01:21:44 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-31 01:22:44 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2764,  0.1846, -0.1707,  ...,  0.0154,  0.0239, -0.1130],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.2070, -3.3828, -0.9072,  ..., -2.1465, -1.5596, -2.6699],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0194, -0.0084, -0.0091,  ...,  0.0058, -0.0039, -0.0115],
        [ 0.0175,  0.0275,  0.0003,  ...,  0.0071,  0.0069, -0.0008],
        [ 0.0020, -0.0055,  0.0396,  ..., -0.0069, -0.0249, -0.0004],
        ...,
        [ 0.0229,  0.0319,  0.0133,  ...,  0.0530,  0.0232, -0.0163],
        [-0.0016, -0.0152,  0.0093,  ...,  0.0041,  0.0270, -0.0266],
        [-0.0090, -0.0175,  0.0037,  ...,  0.0003,  0.0025,  0.0063]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.2910, -3.6309, -1.1699,  ..., -1.5078, -1.6074, -2.5664]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 01:22:45 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is the most lengthy, it is lengthiest
If something is the most weak, it is weakest
If something is the most cute, it is cutest
If something is the most hungry, it is hungriest
If something is the most cruel, it is cruelest
If something is the most rude, it is rudest
If something is the most strange, it is strangest
If something is the most mild, it is
2024-07-31 01:22:46 root INFO     [order_1_approx] starting weight calculation for If something is the most weak, it is weakest
If something is the most rude, it is rudest
If something is the most cruel, it is cruelest
If something is the most lengthy, it is lengthiest
If something is the most mild, it is mildest
If something is the most strange, it is strangest
If something is the most hungry, it is hungriest
If something is the most cute, it is
2024-07-31 01:22:46 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-31 01:24:22 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0418, -0.0032, -0.2617,  ...,  0.0274, -0.0662,  0.2617],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.6406, -2.4219, -0.4187,  ...,  3.0840, -3.4492, -0.6924],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0565, -0.0317, -0.0015,  ...,  0.0069,  0.0116, -0.0059],
        [ 0.0135, -0.0028,  0.0468,  ..., -0.0179,  0.0276, -0.0293],
        [ 0.0032, -0.0159,  0.0476,  ...,  0.0036,  0.0067, -0.0060],
        ...,
        [ 0.0130,  0.0066,  0.0090,  ...,  0.0170, -0.0102, -0.0072],
        [-0.0161,  0.0391, -0.0016,  ..., -0.0126,  0.0372,  0.0172],
        [ 0.0282, -0.0372, -0.0116,  ..., -0.0347, -0.0108,  0.0295]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.1621, -2.1367,  0.0159,  ...,  2.6934, -3.1602, -0.4419]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 01:24:23 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Another word for sofa is couch
Another word for auto is car
Another word for sweets is confectionery
Another word for clothes is clothing
Another word for shore is coast
Another word for intelligent is clever
Another word for package is parcel
Another word for new is
2024-07-31 01:24:23 root INFO     [order_1_approx] starting weight calculation for Another word for sweets is confectionery
Another word for clothes is clothing
Another word for auto is car
Another word for new is modern
Another word for sofa is couch
Another word for shore is coast
Another word for package is parcel
Another word for intelligent is
2024-07-31 01:24:23 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-31 01:25:14 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1306,  0.1760,  0.0059,  ..., -0.2122, -0.4534,  0.0985],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-2.1719, -1.7031, -1.8252,  ..., -1.2451, -0.3633,  1.2217],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0115, -0.0190,  0.0066,  ..., -0.0036, -0.0099,  0.0116],
        [-0.0061,  0.0400,  0.0024,  ...,  0.0123,  0.0069,  0.0153],
        [ 0.0054,  0.0053,  0.0217,  ...,  0.0066, -0.0330, -0.0190],
        ...,
        [-0.0206,  0.0306,  0.0215,  ...,  0.0281,  0.0069, -0.0006],
        [ 0.0213, -0.0139,  0.0082,  ..., -0.0276, -0.0066, -0.0167],
        [-0.0155, -0.0102,  0.0159,  ...,  0.0003, -0.0171,  0.0108]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.7715, -1.8086, -2.2168,  ..., -0.9688, -0.3647,  0.9629]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 01:25:15 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is the most weak, it is weakest
If something is the most rude, it is rudest
If something is the most cruel, it is cruelest
If something is the most lengthy, it is lengthiest
If something is the most mild, it is mildest
If something is the most strange, it is strangest
If something is the most hungry, it is hungriest
If something is the most cute, it is
2024-07-31 01:25:15 root INFO     [order_1_approx] starting weight calculation for If something is the most lengthy, it is lengthiest
If something is the most cute, it is cutest
If something is the most rude, it is rudest
If something is the most cruel, it is cruelest
If something is the most mild, it is mildest
If something is the most weak, it is weakest
If something is the most strange, it is strangest
If something is the most hungry, it is
2024-07-31 01:25:16 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-31 01:27:01 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0278,  0.1707, -0.0041,  ..., -0.0804, -0.0025,  0.0779],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.4756, -0.4109,  0.6621,  ...,  1.5195, -3.9414,  0.2920],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0388,  0.0059,  0.0098,  ...,  0.0050,  0.0071,  0.0095],
        [-0.0332,  0.0163,  0.0276,  ..., -0.0038,  0.0202,  0.0026],
        [-0.0152, -0.0108,  0.0565,  ..., -0.0058,  0.0024,  0.0055],
        ...,
        [ 0.0327,  0.0258, -0.0203,  ...,  0.0578,  0.0042, -0.0250],
        [ 0.0044, -0.0075,  0.0066,  ..., -0.0130,  0.0108, -0.0105],
        [-0.0032,  0.0041, -0.0004,  ..., -0.0002, -0.0104,  0.0147]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.3760, -0.5244,  0.4434,  ...,  1.2773, -3.9805,  0.5698]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 01:27:03 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Another word for sweets is confectionery
Another word for clothes is clothing
Another word for auto is car
Another word for new is modern
Another word for sofa is couch
Another word for shore is coast
Another word for package is parcel
Another word for intelligent is
2024-07-31 01:27:03 root INFO     [order_1_approx] starting weight calculation for Another word for shore is coast
Another word for sweets is confectionery
Another word for auto is car
Another word for clothes is clothing
Another word for sofa is couch
Another word for new is modern
Another word for intelligent is clever
Another word for package is
2024-07-31 01:27:03 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-31 01:27:39 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0327, -0.4756, -0.4136,  ...,  0.0078, -0.4670,  0.1907],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.4058, -5.1172,  1.4932,  ..., -2.3164, -3.7305, -1.9688],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 1.5617e-02, -5.8708e-03,  2.9846e-02,  ..., -5.7526e-03,
          1.8101e-03,  1.5549e-02],
        [-2.6798e-03,  1.8219e-02,  5.1193e-03,  ..., -7.2021e-03,
          5.0201e-03, -2.8019e-03],
        [ 1.9913e-02, -6.1846e-04,  1.5930e-02,  ...,  6.0692e-03,
         -9.3079e-03, -1.1997e-03],
        ...,
        [ 1.9073e-02,  1.3618e-02,  3.3989e-03,  ...,  3.7048e-02,
         -2.1362e-02,  9.9258e-03],
        [-3.4637e-03,  4.7150e-03,  1.3992e-02,  ..., -4.9591e-05,
          3.6316e-02, -2.7557e-02],
        [-1.0567e-02, -2.0081e-02,  4.4250e-03,  ..., -6.3591e-03,
         -2.3880e-02,  1.3443e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.2119, -4.7070,  1.0537,  ..., -2.4863, -3.5273, -1.8203]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 01:27:40 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is the most lengthy, it is lengthiest
If something is the most cute, it is cutest
If something is the most rude, it is rudest
If something is the most cruel, it is cruelest
If something is the most mild, it is mildest
If something is the most weak, it is weakest
If something is the most strange, it is strangest
If something is the most hungry, it is
2024-07-31 01:27:40 root INFO     [order_1_approx] starting weight calculation for If something is the most hungry, it is hungriest
If something is the most cruel, it is cruelest
If something is the most cute, it is cutest
If something is the most weak, it is weakest
If something is the most lengthy, it is lengthiest
If something is the most mild, it is mildest
If something is the most strange, it is strangest
If something is the most rude, it is
2024-07-31 01:27:40 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-31 01:29:34 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0098, -0.0912,  0.0135,  ...,  0.0483, -0.1339,  0.0581],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.4102, -2.4336, -1.7891,  ..., -1.4072, -0.8892, -0.7666],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0623,  0.0048,  0.0091,  ...,  0.0307, -0.0630,  0.0195],
        [ 0.0037,  0.0859,  0.0128,  ...,  0.0018,  0.0378, -0.0173],
        [-0.0296, -0.0135,  0.0925,  ...,  0.0187, -0.0166, -0.0159],
        ...,
        [ 0.0099,  0.0033,  0.0421,  ...,  0.0469, -0.0147,  0.0032],
        [ 0.0188,  0.0036, -0.0301,  ...,  0.0020,  0.0500, -0.0191],
        [-0.0170, -0.0029,  0.0054,  ..., -0.0306, -0.0223,  0.0706]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.8594, -3.0723, -1.6475,  ..., -1.9678, -0.8154, -0.3005]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 01:29:35 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Another word for shore is coast
Another word for sweets is confectionery
Another word for auto is car
Another word for clothes is clothing
Another word for sofa is couch
Another word for new is modern
Another word for intelligent is clever
Another word for package is
2024-07-31 01:29:35 root INFO     total operator prediction time: 1271.32679605484 seconds
2024-07-31 01:29:35 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on animal - youth
2024-07-31 01:29:35 root INFO     building operator animal - youth
2024-07-31 01:29:35 root INFO     [order_1_approx] starting weight calculation for The offspring of a cat is referred to as a kitten
The offspring of a wolf is referred to as a cub
The offspring of a monkey is referred to as a infant
The offspring of a ox is referred to as a calf
The offspring of a herring is referred to as a fingerling
The offspring of a tiger is referred to as a cub
The offspring of a woodchuck is referred to as a kit
The offspring of a sheep is referred to as a
2024-07-31 01:29:35 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-31 01:30:12 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1576,  0.1648, -0.0776,  ...,  0.0885, -0.1082, -0.2046],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-2.0898, -4.9023,  0.4036,  ..., -2.7188, -0.8486, -1.4541],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0268, -0.0092,  0.0092,  ..., -0.0087,  0.0145, -0.0153],
        [-0.0160,  0.0276,  0.0157,  ..., -0.0178,  0.0070,  0.0239],
        [-0.0271,  0.0238,  0.0453,  ..., -0.0045, -0.0319,  0.0012],
        ...,
        [ 0.0014,  0.0386,  0.0110,  ...,  0.0362, -0.0119,  0.0108],
        [ 0.0026, -0.0058,  0.0037,  ...,  0.0054,  0.0255, -0.0306],
        [ 0.0015, -0.0048,  0.0084,  ...,  0.0012, -0.0052,  0.0056]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.8477, -4.7383,  0.6001,  ..., -2.6738, -0.8545, -1.1650]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 01:30:13 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is the most hungry, it is hungriest
If something is the most cruel, it is cruelest
If something is the most cute, it is cutest
If something is the most weak, it is weakest
If something is the most lengthy, it is lengthiest
If something is the most mild, it is mildest
If something is the most strange, it is strangest
If something is the most rude, it is
2024-07-31 01:30:13 root INFO     [order_1_approx] starting weight calculation for If something is the most weak, it is weakest
If something is the most mild, it is mildest
If something is the most hungry, it is hungriest
If something is the most cute, it is cutest
If something is the most cruel, it is cruelest
If something is the most strange, it is strangest
If something is the most rude, it is rudest
If something is the most lengthy, it is
2024-07-31 01:30:14 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-31 01:32:18 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2383,  0.0484, -0.0755,  ...,  0.0653, -0.1005,  0.1692],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.9102, -2.4648,  0.6328,  ...,  2.1152, -2.2285, -1.9551],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0001, -0.0140, -0.0215,  ...,  0.0055, -0.0228, -0.0063],
        [ 0.0021,  0.0247,  0.0082,  ..., -0.0013, -0.0132, -0.0362],
        [ 0.0260,  0.0009,  0.0518,  ..., -0.0209, -0.0220, -0.0079],
        ...,
        [ 0.0172,  0.0182,  0.0162,  ...,  0.0648,  0.0252, -0.0295],
        [ 0.0241,  0.0161,  0.0058,  ...,  0.0096,  0.0253,  0.0016],
        [-0.0042,  0.0206, -0.0299,  ..., -0.0295, -0.0187,  0.0287]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.7344, -2.1680,  0.4580,  ...,  2.5352, -2.0410, -1.8779]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 01:32:19 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The offspring of a cat is referred to as a kitten
The offspring of a wolf is referred to as a cub
The offspring of a monkey is referred to as a infant
The offspring of a ox is referred to as a calf
The offspring of a herring is referred to as a fingerling
The offspring of a tiger is referred to as a cub
The offspring of a woodchuck is referred to as a kit
The offspring of a sheep is referred to as a
2024-07-31 01:32:19 root INFO     [order_1_approx] starting weight calculation for The offspring of a ox is referred to as a calf
The offspring of a monkey is referred to as a infant
The offspring of a cat is referred to as a kitten
The offspring of a woodchuck is referred to as a kit
The offspring of a herring is referred to as a fingerling
The offspring of a sheep is referred to as a lamb
The offspring of a tiger is referred to as a cub
The offspring of a wolf is referred to as a
2024-07-31 01:32:19 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-31 01:32:47 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2151,  0.0033, -0.3904,  ...,  0.0776, -0.3901, -0.1220],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.9878, -4.8867, -1.0547,  ..., -3.0508, -2.2285, -3.4355],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0094, -0.0088,  0.0067,  ..., -0.0014, -0.0041,  0.0079],
        [-0.0072,  0.0302,  0.0166,  ..., -0.0047,  0.0173,  0.0076],
        [-0.0048,  0.0027,  0.0249,  ...,  0.0021, -0.0088,  0.0024],
        ...,
        [ 0.0049,  0.0249,  0.0290,  ...,  0.0207, -0.0079,  0.0169],
        [ 0.0233,  0.0129,  0.0161,  ...,  0.0156,  0.0223, -0.0148],
        [-0.0101,  0.0067, -0.0046,  ..., -0.0149, -0.0036, -0.0118]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.0107, -4.8438, -1.1504,  ..., -2.9512, -2.1309, -3.3984]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 01:32:48 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is the most weak, it is weakest
If something is the most mild, it is mildest
If something is the most hungry, it is hungriest
If something is the most cute, it is cutest
If something is the most cruel, it is cruelest
If something is the most strange, it is strangest
If something is the most rude, it is rudest
If something is the most lengthy, it is
2024-07-31 01:32:48 root INFO     [order_1_approx] starting weight calculation for If something is the most strange, it is strangest
If something is the most hungry, it is hungriest
If something is the most weak, it is weakest
If something is the most rude, it is rudest
If something is the most mild, it is mildest
If something is the most lengthy, it is lengthiest
If something is the most cute, it is cutest
If something is the most cruel, it is
2024-07-31 01:32:48 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-31 01:35:00 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1433,  0.1429,  0.2451,  ...,  0.0561, -0.2720, -0.2358],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.4668, -6.3516, -2.7988,  ...,  0.4019, -2.3125,  2.2930],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0034, -0.0123, -0.0224,  ...,  0.0175, -0.0306,  0.0020],
        [-0.0002,  0.0291,  0.0111,  ..., -0.0161,  0.0091, -0.0088],
        [ 0.0148, -0.0010,  0.0030,  ...,  0.0045, -0.0045, -0.0229],
        ...,
        [-0.0018,  0.0164, -0.0103,  ...,  0.0267,  0.0111, -0.0159],
        [ 0.0047, -0.0208,  0.0198,  ...,  0.0312,  0.0150, -0.0008],
        [-0.0054, -0.0206,  0.0101,  ..., -0.0145, -0.0161,  0.0068]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.2754, -5.5469, -1.9531,  ...,  0.7021, -1.9639,  1.6973]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 01:35:01 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The offspring of a ox is referred to as a calf
The offspring of a monkey is referred to as a infant
The offspring of a cat is referred to as a kitten
The offspring of a woodchuck is referred to as a kit
The offspring of a herring is referred to as a fingerling
The offspring of a sheep is referred to as a lamb
The offspring of a tiger is referred to as a cub
The offspring of a wolf is referred to as a
2024-07-31 01:35:01 root INFO     [order_1_approx] starting weight calculation for The offspring of a sheep is referred to as a lamb
The offspring of a ox is referred to as a calf
The offspring of a cat is referred to as a kitten
The offspring of a wolf is referred to as a cub
The offspring of a tiger is referred to as a cub
The offspring of a woodchuck is referred to as a kit
The offspring of a herring is referred to as a fingerling
The offspring of a monkey is referred to as a
2024-07-31 01:35:01 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-31 01:35:21 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0533,  0.1356,  0.0900,  ..., -0.1648,  0.0648,  0.1837],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.3938, -4.0039, -1.4541,  ..., -1.3320,  0.5107,  0.8135],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0320, -0.0022,  0.0136,  ..., -0.0108, -0.0179,  0.0115],
        [ 0.0097,  0.0154,  0.0118,  ..., -0.0094,  0.0111,  0.0035],
        [ 0.0016, -0.0047,  0.0238,  ..., -0.0147, -0.0028,  0.0002],
        ...,
        [ 0.0082,  0.0386,  0.0096,  ...,  0.0318,  0.0136, -0.0135],
        [ 0.0126,  0.0023,  0.0197,  ..., -0.0029,  0.0221, -0.0172],
        [ 0.0040, -0.0068,  0.0057,  ...,  0.0077, -0.0070, -0.0022]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.7344, -3.7715, -1.3369,  ..., -1.1338,  0.5264,  1.1562]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 01:35:22 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is the most strange, it is strangest
If something is the most hungry, it is hungriest
If something is the most weak, it is weakest
If something is the most rude, it is rudest
If something is the most mild, it is mildest
If something is the most lengthy, it is lengthiest
If something is the most cute, it is cutest
If something is the most cruel, it is
2024-07-31 01:35:22 root INFO     total operator prediction time: 1210.7688245773315 seconds
2024-07-31 01:35:22 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on verb_3pSg - Ved
2024-07-31 01:35:22 root INFO     building operator verb_3pSg - Ved
2024-07-31 01:35:22 root INFO     [order_1_approx] starting weight calculation for When he performs something, something has been performed
When he receives something, something has been received
When he represents something, something has been represented
When he loses something, something has been lost
When he publishes something, something has been published
When he consists something, something has been consisted
When he contains something, something has been contained
When he remains something, something has been
2024-07-31 01:35:22 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-31 01:37:45 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0359, -0.0612, -0.0055,  ...,  0.1656, -0.5776,  0.0719],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.2578, -3.3262, -0.8242,  ..., -0.4639, -3.8125,  2.4688],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0466, -0.0070, -0.0032,  ...,  0.0151, -0.0121, -0.0072],
        [-0.0134,  0.0598,  0.0017,  ...,  0.0110, -0.0114, -0.0258],
        [-0.0018,  0.0075,  0.0350,  ..., -0.0024,  0.0068, -0.0108],
        ...,
        [ 0.0099,  0.0288, -0.0029,  ...,  0.0225,  0.0075, -0.0093],
        [-0.0100, -0.0017,  0.0258,  ...,  0.0040, -0.0041,  0.0123],
        [-0.0120,  0.0047, -0.0202,  ..., -0.0203, -0.0055,  0.0066]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.1094, -2.8496, -0.9087,  ..., -0.3472, -3.3047,  2.3594]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 01:37:45 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The offspring of a sheep is referred to as a lamb
The offspring of a ox is referred to as a calf
The offspring of a cat is referred to as a kitten
The offspring of a wolf is referred to as a cub
The offspring of a tiger is referred to as a cub
The offspring of a woodchuck is referred to as a kit
The offspring of a herring is referred to as a fingerling
The offspring of a monkey is referred to as a
2024-07-31 01:37:46 root INFO     [order_1_approx] starting weight calculation for The offspring of a sheep is referred to as a lamb
The offspring of a ox is referred to as a calf
The offspring of a cat is referred to as a kitten
The offspring of a herring is referred to as a fingerling
The offspring of a monkey is referred to as a infant
The offspring of a wolf is referred to as a cub
The offspring of a woodchuck is referred to as a kit
The offspring of a tiger is referred to as a
2024-07-31 01:37:46 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-31 01:37:56 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2037,  0.1431, -0.2876,  ..., -0.1598, -0.1316,  0.0922],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.2588,  0.5430,  1.6250,  ..., -2.5078, -0.5400, -0.8770],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0069, -0.0200, -0.0020,  ..., -0.0098, -0.0014,  0.0026],
        [-0.0226,  0.0329,  0.0061,  ...,  0.0206,  0.0209,  0.0141],
        [ 0.0008, -0.0121,  0.0077,  ..., -0.0262, -0.0097,  0.0024],
        ...,
        [ 0.0026,  0.0065,  0.0091,  ...,  0.0070,  0.0016,  0.0208],
        [ 0.0059, -0.0104, -0.0044,  ..., -0.0072,  0.0038, -0.0185],
        [-0.0039, -0.0063,  0.0212,  ...,  0.0024, -0.0078, -0.0166]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.4741,  0.4180,  1.8740,  ..., -2.4414, -0.1838, -1.1152]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 01:37:56 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When he performs something, something has been performed
When he receives something, something has been received
When he represents something, something has been represented
When he loses something, something has been lost
When he publishes something, something has been published
When he consists something, something has been consisted
When he contains something, something has been contained
When he remains something, something has been
2024-07-31 01:37:57 root INFO     [order_1_approx] starting weight calculation for When he contains something, something has been contained
When he remains something, something has been remained
When he represents something, something has been represented
When he publishes something, something has been published
When he performs something, something has been performed
When he receives something, something has been received
When he consists something, something has been consisted
When he loses something, something has been
2024-07-31 01:37:57 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-31 01:40:22 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0901,  0.2175, -0.0494,  ...,  0.2383, -0.2822, -0.0903],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.6738, -5.6289, -1.9912,  ...,  0.1548, -1.6650,  1.0020],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0110, -0.0131, -0.0227,  ..., -0.0064, -0.0249, -0.0150],
        [ 0.0061,  0.0222, -0.0012,  ...,  0.0059, -0.0077, -0.0227],
        [ 0.0077,  0.0027,  0.0479,  ...,  0.0030,  0.0207,  0.0138],
        ...,
        [ 0.0180,  0.0062,  0.0237,  ...,  0.0481,  0.0071, -0.0328],
        [ 0.0142, -0.0263,  0.0063,  ...,  0.0302, -0.0023,  0.0047],
        [-0.0059, -0.0143, -0.0326,  ..., -0.0238, -0.0107,  0.0246]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.2520, -4.9297, -1.5742,  ...,  0.4849, -0.9233,  0.7051]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 01:40:23 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The offspring of a sheep is referred to as a lamb
The offspring of a ox is referred to as a calf
The offspring of a cat is referred to as a kitten
The offspring of a herring is referred to as a fingerling
The offspring of a monkey is referred to as a infant
The offspring of a wolf is referred to as a cub
The offspring of a woodchuck is referred to as a kit
The offspring of a tiger is referred to as a
2024-07-31 01:40:23 root INFO     [order_1_approx] starting weight calculation for The offspring of a cat is referred to as a kitten
The offspring of a monkey is referred to as a infant
The offspring of a tiger is referred to as a cub
The offspring of a herring is referred to as a fingerling
The offspring of a wolf is referred to as a cub
The offspring of a sheep is referred to as a lamb
The offspring of a ox is referred to as a calf
The offspring of a woodchuck is referred to as a
2024-07-31 01:40:23 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-31 01:40:28 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1599,  0.4238, -0.2432,  ..., -0.1301,  0.2642,  0.0255],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.2646, -0.3037,  1.0176,  ..., -1.2227,  0.3574, -1.6660],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0195,  0.0109,  0.0199,  ..., -0.0192, -0.0054, -0.0003],
        [-0.0110,  0.0414,  0.0315,  ...,  0.0191, -0.0011, -0.0091],
        [ 0.0132, -0.0250,  0.0214,  ..., -0.0071, -0.0044,  0.0072],
        ...,
        [-0.0060,  0.0153, -0.0161,  ...,  0.0076, -0.0062,  0.0143],
        [ 0.0004,  0.0011, -0.0043,  ...,  0.0040,  0.0208, -0.0067],
        [-0.0061,  0.0083,  0.0283,  ..., -0.0135, -0.0070, -0.0020]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.5010, -0.5557,  1.2549,  ..., -1.3682,  0.3855, -1.4424]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 01:40:29 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When he contains something, something has been contained
When he remains something, something has been remained
When he represents something, something has been represented
When he publishes something, something has been published
When he performs something, something has been performed
When he receives something, something has been received
When he consists something, something has been consisted
When he loses something, something has been
2024-07-31 01:40:29 root INFO     [order_1_approx] starting weight calculation for When he remains something, something has been remained
When he represents something, something has been represented
When he loses something, something has been lost
When he performs something, something has been performed
When he publishes something, something has been published
When he consists something, something has been consisted
When he contains something, something has been contained
When he receives something, something has been
2024-07-31 01:40:29 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-31 01:43:00 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2053,  0.3357, -0.3687,  ..., -0.2129, -0.0248, -0.1368],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.1699,  1.0801,  0.2170,  ..., -2.0586, -2.2227, -0.6689],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0505, -0.0276,  0.0303,  ..., -0.0086, -0.0190,  0.0292],
        [-0.0198,  0.0283,  0.0118,  ...,  0.0160,  0.0030, -0.0075],
        [-0.0052,  0.0004,  0.0009,  ..., -0.0210, -0.0039, -0.0147],
        ...,
        [ 0.0155,  0.0022,  0.0005,  ...,  0.0235,  0.0039,  0.0130],
        [-0.0001,  0.0059, -0.0133,  ...,  0.0012,  0.0472, -0.0238],
        [ 0.0008,  0.0159,  0.0131,  ..., -0.0056,  0.0021, -0.0024]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.3604,  1.1348,  0.3438,  ..., -1.8789, -1.6484, -0.8228]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 01:43:01 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When he remains something, something has been remained
When he represents something, something has been represented
When he loses something, something has been lost
When he performs something, something has been performed
When he publishes something, something has been published
When he consists something, something has been consisted
When he contains something, something has been contained
When he receives something, something has been
2024-07-31 01:43:01 root INFO     [order_1_approx] starting weight calculation for When he publishes something, something has been published
When he remains something, something has been remained
When he represents something, something has been represented
When he receives something, something has been received
When he contains something, something has been contained
When he loses something, something has been lost
When he consists something, something has been consisted
When he performs something, something has been
2024-07-31 01:43:02 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-31 01:43:05 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1298, -0.1692, -0.1912,  ...,  0.1025, -0.7583, -0.3230],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.7363, -3.9453,  1.1631,  ..., -2.7324, -1.8506,  0.5312],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 3.3600e-02, -1.8890e-02,  3.0930e-02,  ...,  1.9180e-02,
         -6.0394e-02,  2.3300e-02],
        [-4.9896e-03,  2.9922e-02, -1.2331e-03,  ...,  4.9820e-03,
          5.2795e-02, -1.3123e-02],
        [ 2.3613e-03, -1.2009e-02,  2.9083e-02,  ..., -1.1940e-02,
          1.7883e-02, -1.1902e-02],
        ...,
        [ 2.0782e-02,  2.8443e-04, -7.0038e-03,  ...,  4.3549e-02,
          6.4850e-05,  8.0948e-03],
        [-1.6388e-02, -2.0752e-02,  1.9104e-02,  ...,  2.5299e-02,
          2.9266e-02, -9.7809e-03],
        [-1.3412e-02, -1.2863e-02, -2.3300e-02,  ..., -9.0179e-03,
         -9.2773e-03,  6.7673e-03]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.6543, -3.8125,  0.8740,  ..., -2.4297, -1.9736,  0.9697]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 01:43:06 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The offspring of a cat is referred to as a kitten
The offspring of a monkey is referred to as a infant
The offspring of a tiger is referred to as a cub
The offspring of a herring is referred to as a fingerling
The offspring of a wolf is referred to as a cub
The offspring of a sheep is referred to as a lamb
The offspring of a ox is referred to as a calf
The offspring of a woodchuck is referred to as a
2024-07-31 01:43:07 root INFO     [order_1_approx] starting weight calculation for The offspring of a tiger is referred to as a cub
The offspring of a wolf is referred to as a cub
The offspring of a sheep is referred to as a lamb
The offspring of a cat is referred to as a kitten
The offspring of a monkey is referred to as a infant
The offspring of a ox is referred to as a calf
The offspring of a woodchuck is referred to as a kit
The offspring of a herring is referred to as a
2024-07-31 01:43:07 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-31 01:45:34 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2898,  0.5796,  0.0182,  ...,  0.0852, -0.0732, -0.1731],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.6699, -0.7061,  4.5547,  ..., -1.2480, -2.3613, -0.0918],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0186, -0.0049,  0.0137,  ..., -0.0030, -0.0066,  0.0134],
        [-0.0107,  0.0381,  0.0068,  ...,  0.0176,  0.0157, -0.0023],
        [ 0.0054,  0.0035, -0.0051,  ..., -0.0068, -0.0075,  0.0098],
        ...,
        [-0.0060,  0.0125, -0.0024,  ...,  0.0044,  0.0090,  0.0041],
        [ 0.0146, -0.0068,  0.0050,  ...,  0.0042,  0.0157, -0.0082],
        [-0.0016,  0.0099,  0.0091,  ..., -0.0008,  0.0064, -0.0072]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.7334, -0.7607,  4.5625,  ..., -1.2754, -1.9160, -0.0241]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 01:45:36 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When he publishes something, something has been published
When he remains something, something has been remained
When he represents something, something has been represented
When he receives something, something has been received
When he contains something, something has been contained
When he loses something, something has been lost
When he consists something, something has been consisted
When he performs something, something has been
2024-07-31 01:45:36 root INFO     [order_1_approx] starting weight calculation for When he contains something, something has been contained
When he loses something, something has been lost
When he remains something, something has been remained
When he publishes something, something has been published
When he represents something, something has been represented
When he performs something, something has been performed
When he receives something, something has been received
When he consists something, something has been
2024-07-31 01:45:36 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-31 01:45:49 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1042, -0.0776, -0.2104,  ...,  0.0445, -0.1709, -0.2212],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.3418, -1.5742, -3.1543,  ..., -0.0303, -3.2949, -0.6973],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0107,  0.0016, -0.0203,  ...,  0.0065, -0.0419, -0.0238],
        [ 0.0119,  0.0608,  0.0258,  ...,  0.0093,  0.0302, -0.0104],
        [ 0.0250,  0.0181,  0.0366,  ..., -0.0073, -0.0137,  0.0009],
        ...,
        [-0.0024,  0.0035, -0.0114,  ...,  0.0277, -0.0003,  0.0212],
        [ 0.0076,  0.0278,  0.0283,  ...,  0.0329,  0.0378,  0.0178],
        [-0.0247, -0.0041, -0.0266,  ..., -0.0129,  0.0299,  0.0072]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.6279, -1.6045, -2.8867,  ...,  0.1133, -3.3730, -0.6997]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 01:45:50 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The offspring of a tiger is referred to as a cub
The offspring of a wolf is referred to as a cub
The offspring of a sheep is referred to as a lamb
The offspring of a cat is referred to as a kitten
The offspring of a monkey is referred to as a infant
The offspring of a ox is referred to as a calf
The offspring of a woodchuck is referred to as a kit
The offspring of a herring is referred to as a
2024-07-31 01:45:50 root INFO     [order_1_approx] starting weight calculation for The offspring of a monkey is referred to as a infant
The offspring of a tiger is referred to as a cub
The offspring of a woodchuck is referred to as a kit
The offspring of a wolf is referred to as a cub
The offspring of a ox is referred to as a calf
The offspring of a sheep is referred to as a lamb
The offspring of a herring is referred to as a fingerling
The offspring of a cat is referred to as a
2024-07-31 01:45:50 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-31 01:48:07 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1043, -0.0420, -0.7061,  ...,  0.1986, -0.5591,  0.0353],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.9023,  2.5039,  1.9287,  ..., -0.4458, -0.0959,  0.2754],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0104, -0.0132, -0.0223,  ..., -0.0014,  0.0203,  0.0110],
        [-0.0050,  0.0445,  0.0381,  ...,  0.0207, -0.0207,  0.0004],
        [-0.0032,  0.0055,  0.0187,  ..., -0.0156, -0.0256,  0.0027],
        ...,
        [ 0.0200,  0.0239,  0.0016,  ...,  0.0181,  0.0113,  0.0222],
        [-0.0136,  0.0065, -0.0032,  ...,  0.0126,  0.0187,  0.0135],
        [ 0.0034,  0.0007,  0.0073,  ...,  0.0025,  0.0012, -0.0058]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.0664,  2.8809,  1.5771,  ..., -0.1052, -0.3477,  0.4507]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 01:48:08 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When he contains something, something has been contained
When he loses something, something has been lost
When he remains something, something has been remained
When he publishes something, something has been published
When he represents something, something has been represented
When he performs something, something has been performed
When he receives something, something has been received
When he consists something, something has been
2024-07-31 01:48:09 root INFO     [order_1_approx] starting weight calculation for When he performs something, something has been performed
When he contains something, something has been contained
When he loses something, something has been lost
When he publishes something, something has been published
When he remains something, something has been remained
When he receives something, something has been received
When he consists something, something has been consisted
When he represents something, something has been
2024-07-31 01:48:09 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-31 01:48:31 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0729, -0.0607,  0.0979,  ...,  0.2766, -0.2825,  0.0163],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.9961, -3.3633, -2.1328,  ..., -0.6816,  0.3896, -0.3882],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0173, -0.0415, -0.0152,  ..., -0.0088, -0.0155,  0.0040],
        [-0.0070,  0.0194,  0.0067,  ...,  0.0016,  0.0181, -0.0211],
        [-0.0021,  0.0020,  0.0318,  ..., -0.0012, -0.0045, -0.0066],
        ...,
        [-0.0021, -0.0139, -0.0199,  ...,  0.0709,  0.0184, -0.0015],
        [ 0.0157,  0.0238,  0.0214,  ...,  0.0467,  0.0310,  0.0082],
        [ 0.0045, -0.0055, -0.0136,  ..., -0.0329, -0.0142,  0.0319]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.1309, -2.9531, -1.9346,  ..., -0.3203,  0.1768, -0.7295]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 01:48:32 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The offspring of a monkey is referred to as a infant
The offspring of a tiger is referred to as a cub
The offspring of a woodchuck is referred to as a kit
The offspring of a wolf is referred to as a cub
The offspring of a ox is referred to as a calf
The offspring of a sheep is referred to as a lamb
The offspring of a herring is referred to as a fingerling
The offspring of a cat is referred to as a
2024-07-31 01:48:32 root INFO     [order_1_approx] starting weight calculation for The offspring of a sheep is referred to as a lamb
The offspring of a monkey is referred to as a infant
The offspring of a tiger is referred to as a cub
The offspring of a wolf is referred to as a cub
The offspring of a woodchuck is referred to as a kit
The offspring of a cat is referred to as a kitten
The offspring of a herring is referred to as a fingerling
The offspring of a ox is referred to as a
2024-07-31 01:48:32 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-31 01:50:42 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1830,  0.4797, -0.5366,  ...,  0.0452, -0.0684, -0.2311],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.7383,  1.4863,  2.4824,  ...,  0.1841, -1.1445, -0.1074],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0253, -0.0300, -0.0009,  ...,  0.0104,  0.0038,  0.0202],
        [-0.0149,  0.0478,  0.0141,  ...,  0.0023,  0.0078, -0.0015],
        [ 0.0011, -0.0036,  0.0057,  ..., -0.0039, -0.0236,  0.0026],
        ...,
        [-0.0096, -0.0028, -0.0026,  ...,  0.0261, -0.0105,  0.0308],
        [ 0.0085,  0.0208, -0.0124,  ..., -0.0189,  0.0352, -0.0194],
        [-0.0095, -0.0061,  0.0126,  ...,  0.0008,  0.0042,  0.0087]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.5850,  1.3438,  2.4727,  ..., -0.0251, -1.1797, -0.2107]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 01:50:42 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When he performs something, something has been performed
When he contains something, something has been contained
When he loses something, something has been lost
When he publishes something, something has been published
When he remains something, something has been remained
When he receives something, something has been received
When he consists something, something has been consisted
When he represents something, something has been
2024-07-31 01:50:43 root INFO     [order_1_approx] starting weight calculation for When he loses something, something has been lost
When he publishes something, something has been published
When he remains something, something has been remained
When he performs something, something has been performed
When he consists something, something has been consisted
When he receives something, something has been received
When he represents something, something has been represented
When he contains something, something has been
2024-07-31 01:50:43 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-31 01:51:14 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0219,  0.1017,  0.3186,  ...,  0.0373, -0.0588,  0.0016],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.1406, -2.6660, -1.6250,  ...,  0.8809, -0.9170,  0.2119],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0349, -0.0032,  0.0104,  ..., -0.0127, -0.0269, -0.0056],
        [ 0.0095,  0.0083, -0.0085,  ..., -0.0082,  0.0056, -0.0112],
        [ 0.0230, -0.0030,  0.0287,  ..., -0.0262, -0.0383, -0.0105],
        ...,
        [ 0.0167,  0.0020, -0.0038,  ...,  0.0450,  0.0311, -0.0036],
        [ 0.0198,  0.0222,  0.0137,  ...,  0.0190,  0.0564,  0.0200],
        [ 0.0168, -0.0041, -0.0216,  ..., -0.0330,  0.0173,  0.0045]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.1465, -2.6191, -1.4775,  ...,  0.7319, -1.2109,  0.1768]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 01:51:15 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The offspring of a sheep is referred to as a lamb
The offspring of a monkey is referred to as a infant
The offspring of a tiger is referred to as a cub
The offspring of a wolf is referred to as a cub
The offspring of a woodchuck is referred to as a kit
The offspring of a cat is referred to as a kitten
The offspring of a herring is referred to as a fingerling
The offspring of a ox is referred to as a
2024-07-31 01:51:15 root INFO     total operator prediction time: 1300.5961463451385 seconds
2024-07-31 01:51:15 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on animal - sound
2024-07-31 01:51:15 root INFO     building operator animal - sound
2024-07-31 01:51:16 root INFO     [order_1_approx] starting weight calculation for The sound that a coyote makes is called a howl
The sound that a horse makes is called a neigh
The sound that a duck makes is called a quack
The sound that a seal makes is called a bark
The sound that a raven makes is called a caw
The sound that a songbird makes is called a chirrup
The sound that a crow makes is called a caw
The sound that a chicken makes is called a
2024-07-31 01:51:16 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-31 01:53:15 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1343, -0.2871, -0.3716,  ...,  0.3594,  0.1128, -0.2891],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.3818,  2.1426,  3.2051,  ..., -2.1211, -0.6494, -2.2891],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0209, -0.0145,  0.0040,  ...,  0.0020, -0.0035,  0.0306],
        [-0.0090,  0.0548,  0.0236,  ...,  0.0068, -0.0149,  0.0116],
        [ 0.0089,  0.0083,  0.0138,  ..., -0.0124, -0.0119, -0.0106],
        ...,
        [ 0.0146,  0.0124,  0.0064,  ...,  0.0184,  0.0157,  0.0152],
        [ 0.0109, -0.0023, -0.0030,  ..., -0.0008,  0.0249,  0.0075],
        [ 0.0097, -0.0106,  0.0102,  ..., -0.0154, -0.0153, -0.0069]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.8047,  1.9697,  2.9648,  ..., -2.2207, -0.4438, -2.3184]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 01:53:16 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When he loses something, something has been lost
When he publishes something, something has been published
When he remains something, something has been remained
When he performs something, something has been performed
When he consists something, something has been consisted
When he receives something, something has been received
When he represents something, something has been represented
When he contains something, something has been
2024-07-31 01:53:16 root INFO     [order_1_approx] starting weight calculation for When he loses something, something has been lost
When he performs something, something has been performed
When he consists something, something has been consisted
When he contains something, something has been contained
When he represents something, something has been represented
When he remains something, something has been remained
When he receives something, something has been received
When he publishes something, something has been
2024-07-31 01:53:16 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-31 01:53:51 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0735,  0.0013, -0.1316,  ...,  0.1093, -0.0744,  0.1204],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.3379, -4.1836,  3.1406,  ...,  0.4551,  0.1394,  1.0898],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0406, -0.0040, -0.0070,  ..., -0.0258, -0.0124,  0.0019],
        [-0.0165,  0.0508,  0.0039,  ..., -0.0001,  0.0146, -0.0201],
        [ 0.0091,  0.0020,  0.0349,  ..., -0.0101,  0.0033, -0.0018],
        ...,
        [ 0.0106,  0.0025, -0.0012,  ...,  0.0507, -0.0084,  0.0019],
        [ 0.0044,  0.0078, -0.0064,  ...,  0.0197,  0.0356, -0.0169],
        [ 0.0054, -0.0141,  0.0001,  ..., -0.0124, -0.0021,  0.0177]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.0898, -4.0352,  2.9746,  ...,  0.2769,  0.1475,  0.9727]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 01:53:52 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The sound that a coyote makes is called a howl
The sound that a horse makes is called a neigh
The sound that a duck makes is called a quack
The sound that a seal makes is called a bark
The sound that a raven makes is called a caw
The sound that a songbird makes is called a chirrup
The sound that a crow makes is called a caw
The sound that a chicken makes is called a
2024-07-31 01:53:52 root INFO     [order_1_approx] starting weight calculation for The sound that a songbird makes is called a chirrup
The sound that a duck makes is called a quack
The sound that a chicken makes is called a cluck
The sound that a crow makes is called a caw
The sound that a coyote makes is called a howl
The sound that a seal makes is called a bark
The sound that a raven makes is called a caw
The sound that a horse makes is called a
2024-07-31 01:53:52 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-31 01:55:48 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.3372,  0.1636, -0.2180,  ...,  0.2781, -0.0720,  0.1113],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.2617, -2.0273,  2.2871,  ..., -1.9541, -1.7529,  1.4863],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 9.9640e-03,  6.9427e-03,  3.1700e-03,  ..., -6.0463e-03,
         -4.8637e-04,  1.4503e-02],
        [-1.3275e-02,  6.7215e-03,  1.7548e-02,  ..., -1.8311e-03,
          2.1149e-02,  4.8752e-03],
        [ 5.3253e-03,  1.7252e-03, -9.4986e-03,  ..., -2.4246e-02,
         -4.5967e-03,  2.3136e-03],
        ...,
        [ 5.0278e-03,  8.7433e-03,  4.2572e-03,  ...,  1.3176e-02,
          1.3260e-02, -3.8147e-03],
        [ 7.9575e-03, -9.5367e-06, -2.1820e-02,  ..., -3.7155e-03,
          1.4473e-02, -2.4612e-02],
        [-1.6899e-03,  1.9516e-02,  1.2589e-02,  ...,  1.1108e-02,
         -1.0246e-02, -2.4719e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.2031, -1.9434,  2.4531,  ..., -2.1250, -1.6943,  1.2949]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 01:55:49 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When he loses something, something has been lost
When he performs something, something has been performed
When he consists something, something has been consisted
When he contains something, something has been contained
When he represents something, something has been represented
When he remains something, something has been remained
When he receives something, something has been received
When he publishes something, something has been
2024-07-31 01:55:49 root INFO     total operator prediction time: 1227.2288784980774 seconds
2024-07-31 01:55:49 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on noun - plural_reg
2024-07-31 01:55:49 root INFO     building operator noun - plural_reg
2024-07-31 01:55:49 root INFO     [order_1_approx] starting weight calculation for The plural form of year is years
The plural form of system is systems
The plural form of application is applications
The plural form of development is developments
The plural form of customer is customers
The plural form of period is periods
The plural form of village is villages
The plural form of member is
2024-07-31 01:55:49 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-31 01:56:34 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.3323, -0.0737, -0.0313,  ...,  0.0092,  0.0306,  0.2029],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.3691, -1.3633, -1.8779,  ...,  2.0039,  0.1152,  1.9199],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 4.3213e-02,  4.3449e-03, -7.2479e-03,  ..., -9.6130e-03,
          5.6686e-03, -7.9727e-04],
        [ 4.3793e-03,  2.4033e-02,  1.0986e-03,  ...,  2.5024e-02,
          1.2375e-02, -2.3972e-02],
        [ 9.2697e-04,  2.5997e-03,  3.9001e-02,  ..., -1.9531e-02,
          3.3073e-03, -4.5776e-05],
        ...,
        [ 3.7384e-03,  4.9858e-03, -3.6678e-03,  ...,  1.3496e-02,
         -3.1738e-02,  3.6507e-03],
        [ 8.7547e-04, -1.6289e-03, -2.6150e-03,  ...,  1.3565e-02,
          1.2985e-02, -5.8365e-03],
        [ 1.6418e-02,  2.0638e-03,  1.3771e-02,  ..., -1.9928e-02,
         -7.2899e-03,  9.9087e-04]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.2107, -1.1035, -2.2461,  ...,  2.0801, -0.3738,  1.8047]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 01:56:35 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The sound that a songbird makes is called a chirrup
The sound that a duck makes is called a quack
The sound that a chicken makes is called a cluck
The sound that a crow makes is called a caw
The sound that a coyote makes is called a howl
The sound that a seal makes is called a bark
The sound that a raven makes is called a caw
The sound that a horse makes is called a
2024-07-31 01:56:35 root INFO     [order_1_approx] starting weight calculation for The sound that a seal makes is called a bark
The sound that a coyote makes is called a howl
The sound that a duck makes is called a quack
The sound that a chicken makes is called a cluck
The sound that a raven makes is called a caw
The sound that a crow makes is called a caw
The sound that a horse makes is called a neigh
The sound that a songbird makes is called a
2024-07-31 01:56:35 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-31 01:58:23 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.5527,  0.0405, -0.1565,  ...,  0.0090,  0.0302,  0.1316],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.0439, -1.8643,  1.2129,  ..., -1.4355,  0.6304, -3.1953],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 5.7922e-02,  7.0801e-03,  3.7575e-03,  ...,  1.2398e-02,
          5.2452e-04,  1.5808e-02],
        [ 2.8381e-03,  3.3691e-02, -4.1246e-05,  ...,  6.5155e-03,
         -1.5381e-02, -8.1253e-04],
        [-1.3412e-02,  6.2943e-03,  8.8806e-03,  ..., -3.6507e-03,
         -1.5610e-02,  1.2650e-02],
        ...,
        [-1.1414e-02,  2.1057e-02, -8.8272e-03,  ...,  3.8330e-02,
         -9.7809e-03,  2.2751e-02],
        [-3.3203e-02,  3.0823e-02, -6.5460e-03,  ..., -2.7344e-02,
          3.8574e-02, -2.0706e-02],
        [ 8.5602e-03, -1.3351e-03, -2.0538e-02,  ...,  1.0401e-04,
         -9.5520e-03,  4.3945e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.6494, -1.7588,  1.2021,  ..., -1.6455, -0.0718, -2.5156]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 01:58:24 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of year is years
The plural form of system is systems
The plural form of application is applications
The plural form of development is developments
The plural form of customer is customers
The plural form of period is periods
The plural form of village is villages
The plural form of member is
2024-07-31 01:58:24 root INFO     [order_1_approx] starting weight calculation for The plural form of village is villages
The plural form of application is applications
The plural form of period is periods
The plural form of system is systems
The plural form of customer is customers
The plural form of development is developments
The plural form of member is members
The plural form of year is
2024-07-31 01:58:24 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-31 01:59:17 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1313,  0.0486,  0.1338,  ...,  0.1396, -0.0760, -0.1536],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.9478, -2.9688,  2.4980,  ...,  0.0117, -1.0557, -0.9951],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0211,  0.0110, -0.0093,  ..., -0.0027, -0.0338,  0.0200],
        [-0.0121,  0.0146,  0.0196,  ...,  0.0100,  0.0208, -0.0309],
        [-0.0099, -0.0039,  0.0220,  ..., -0.0115, -0.0166,  0.0163],
        ...,
        [-0.0142,  0.0061, -0.0037,  ...,  0.0388,  0.0016, -0.0093],
        [-0.0052,  0.0060,  0.0051,  ...,  0.0181,  0.0140, -0.0107],
        [-0.0184,  0.0027, -0.0165,  ..., -0.0232,  0.0087,  0.0422]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.8687, -3.2402,  2.6680,  ...,  0.0370, -1.5029, -1.0098]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 01:59:18 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The sound that a seal makes is called a bark
The sound that a coyote makes is called a howl
The sound that a duck makes is called a quack
The sound that a chicken makes is called a cluck
The sound that a raven makes is called a caw
The sound that a crow makes is called a caw
The sound that a horse makes is called a neigh
The sound that a songbird makes is called a
2024-07-31 01:59:18 root INFO     [order_1_approx] starting weight calculation for The sound that a songbird makes is called a chirrup
The sound that a horse makes is called a neigh
The sound that a seal makes is called a bark
The sound that a raven makes is called a caw
The sound that a chicken makes is called a cluck
The sound that a crow makes is called a caw
The sound that a duck makes is called a quack
The sound that a coyote makes is called a
2024-07-31 01:59:18 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-31 02:00:58 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1079, -0.0039, -0.1713,  ..., -0.3369, -0.2413,  0.2588],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.4199, -4.5469,  2.3027,  ..., -1.7734, -0.1721, -3.9824],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0305,  0.0228,  0.0060,  ...,  0.0148,  0.0072,  0.0031],
        [ 0.0028,  0.0297, -0.0044,  ...,  0.0293, -0.0129, -0.0357],
        [ 0.0151,  0.0176,  0.0255,  ..., -0.0043, -0.0095,  0.0317],
        ...,
        [ 0.0071,  0.0056, -0.0178,  ...,  0.0202, -0.0246,  0.0142],
        [-0.0377,  0.0399,  0.0206,  ...,  0.0216,  0.0328, -0.0138],
        [-0.0092, -0.0189, -0.0282,  ...,  0.0175, -0.0213,  0.0300]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.6509, -4.3906,  2.2383,  ..., -1.4971, -0.6709, -3.2188]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 02:00:59 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of village is villages
The plural form of application is applications
The plural form of period is periods
The plural form of system is systems
The plural form of customer is customers
The plural form of development is developments
The plural form of member is members
The plural form of year is
2024-07-31 02:00:59 root INFO     [order_1_approx] starting weight calculation for The plural form of member is members
The plural form of application is applications
The plural form of year is years
The plural form of period is periods
The plural form of system is systems
The plural form of customer is customers
The plural form of development is developments
The plural form of village is
2024-07-31 02:00:59 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-31 02:01:54 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0295,  0.0670, -0.2854,  ...,  0.0712, -0.1902,  0.1362],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.1133, -5.9453, -0.9053,  ..., -2.9824,  0.1450,  2.1562],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0294,  0.0021,  0.0005,  ..., -0.0309, -0.0154,  0.0158],
        [-0.0295,  0.0035, -0.0036,  ...,  0.0012,  0.0005, -0.0256],
        [ 0.0046,  0.0105,  0.0322,  ..., -0.0453, -0.0096, -0.0082],
        ...,
        [-0.0098,  0.0188, -0.0045,  ...,  0.0609, -0.0220, -0.0110],
        [ 0.0083, -0.0157, -0.0153,  ...,  0.0164,  0.0021, -0.0012],
        [-0.0069, -0.0110, -0.0403,  ..., -0.0095, -0.0212, -0.0011]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.7002, -5.7500, -0.7529,  ..., -3.2852,  0.6948,  1.9531]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 02:01:55 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The sound that a songbird makes is called a chirrup
The sound that a horse makes is called a neigh
The sound that a seal makes is called a bark
The sound that a raven makes is called a caw
The sound that a chicken makes is called a cluck
The sound that a crow makes is called a caw
The sound that a duck makes is called a quack
The sound that a coyote makes is called a
2024-07-31 02:01:55 root INFO     [order_1_approx] starting weight calculation for The sound that a crow makes is called a caw
The sound that a duck makes is called a quack
The sound that a seal makes is called a bark
The sound that a songbird makes is called a chirrup
The sound that a coyote makes is called a howl
The sound that a horse makes is called a neigh
The sound that a chicken makes is called a cluck
The sound that a raven makes is called a
2024-07-31 02:01:56 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-31 02:03:32 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3879,  0.4653, -0.0006,  ..., -0.3413, -0.2803,  0.0812],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.6357, -5.3906,  2.6367,  ..., -2.2129,  1.0488, -0.7295],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0693,  0.0116,  0.0383,  ...,  0.0144,  0.0125, -0.0053],
        [ 0.0135,  0.0204, -0.0007,  ...,  0.0062, -0.0195,  0.0003],
        [-0.0197,  0.0049,  0.0472,  ...,  0.0138, -0.0303,  0.0112],
        ...,
        [ 0.0246,  0.0346, -0.0297,  ...,  0.0446, -0.0043,  0.0045],
        [-0.0265,  0.0110,  0.0134,  ..., -0.0175,  0.0468, -0.0337],
        [-0.0158, -0.0115, -0.0193,  ...,  0.0195, -0.0246,  0.0502]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.0820, -4.8945,  1.9053,  ..., -2.2500,  0.9014,  0.1069]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 02:03:33 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of member is members
The plural form of application is applications
The plural form of year is years
The plural form of period is periods
The plural form of system is systems
The plural form of customer is customers
The plural form of development is developments
The plural form of village is
2024-07-31 02:03:33 root INFO     [order_1_approx] starting weight calculation for The plural form of member is members
The plural form of period is periods
The plural form of system is systems
The plural form of year is years
The plural form of application is applications
The plural form of village is villages
The plural form of development is developments
The plural form of customer is
2024-07-31 02:03:33 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-31 02:04:38 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0588, -0.2969, -0.1501,  ...,  0.0879, -0.2842,  0.1186],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.9590, -2.0488,  0.9141,  ..., -2.2363,  0.3013,  1.6152],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 5.8533e-02,  2.5391e-02, -6.7291e-03,  ..., -4.0771e-02,
         -5.9204e-02, -9.1858e-03],
        [-4.7180e-02,  3.1052e-02, -1.6022e-02,  ...,  3.3508e-02,
          4.9225e-02, -4.1199e-02],
        [-4.5013e-03, -3.0029e-02,  6.2378e-02,  ..., -3.5553e-02,
         -2.7145e-02, -1.9806e-02],
        ...,
        [ 1.9150e-02,  7.7896e-03, -2.5330e-02,  ...,  6.7566e-02,
          4.6577e-03, -9.0122e-05],
        [-3.3894e-03, -2.8198e-02,  5.2376e-03,  ...,  3.9886e-02,
         -9.4910e-03, -1.4465e-02],
        [-5.5504e-03, -3.4218e-03, -1.9974e-02,  ..., -1.8036e-02,
         -2.3438e-02,  8.5602e-03]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.5557, -1.7988,  0.4290,  ..., -2.3281, -0.0444,  1.0020]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 02:04:39 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The sound that a crow makes is called a caw
The sound that a duck makes is called a quack
The sound that a seal makes is called a bark
The sound that a songbird makes is called a chirrup
The sound that a coyote makes is called a howl
The sound that a horse makes is called a neigh
The sound that a chicken makes is called a cluck
The sound that a raven makes is called a
2024-07-31 02:04:39 root INFO     [order_1_approx] starting weight calculation for The sound that a songbird makes is called a chirrup
The sound that a chicken makes is called a cluck
The sound that a horse makes is called a neigh
The sound that a raven makes is called a caw
The sound that a duck makes is called a quack
The sound that a coyote makes is called a howl
The sound that a seal makes is called a bark
The sound that a crow makes is called a
2024-07-31 02:04:39 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-31 02:06:07 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1726,  0.1858, -0.2556,  ..., -0.3218, -0.0540,  0.1049],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.1729, -1.2383,  2.1777,  ..., -1.9375, -1.4854, -0.5469],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0159, -0.0099,  0.0122,  ...,  0.0183, -0.0172, -0.0006],
        [-0.0200,  0.0337,  0.0186,  ...,  0.0095, -0.0075, -0.0011],
        [-0.0195, -0.0096,  0.0329,  ...,  0.0172, -0.0091,  0.0013],
        ...,
        [ 0.0010,  0.0106, -0.0090,  ...,  0.0338, -0.0086,  0.0276],
        [-0.0219,  0.0087, -0.0155,  ..., -0.0219,  0.0238,  0.0032],
        [-0.0056, -0.0010, -0.0435,  ...,  0.0034,  0.0010,  0.0228]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.1689, -1.1709,  2.0293,  ..., -2.2148, -1.6152, -0.1199]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 02:06:08 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of member is members
The plural form of period is periods
The plural form of system is systems
The plural form of year is years
The plural form of application is applications
The plural form of village is villages
The plural form of development is developments
The plural form of customer is
2024-07-31 02:06:09 root INFO     [order_1_approx] starting weight calculation for The plural form of period is periods
The plural form of member is members
The plural form of year is years
The plural form of development is developments
The plural form of customer is customers
The plural form of application is applications
The plural form of village is villages
The plural form of system is
2024-07-31 02:06:09 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-31 02:07:17 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0421, -0.2354,  0.0387,  ...,  0.0698, -0.1913, -0.0337],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.9414, -2.6992,  1.4395,  ..., -2.0996, -0.3486,  1.2500],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0719,  0.0486,  0.0356,  ..., -0.0587, -0.0643,  0.0103],
        [-0.0154,  0.0396,  0.0046,  ...,  0.0542,  0.0589, -0.0318],
        [-0.0105,  0.0128,  0.0760,  ..., -0.0427, -0.0350, -0.0120],
        ...,
        [ 0.0201, -0.0009, -0.0103,  ...,  0.0806, -0.0048, -0.0027],
        [-0.0207, -0.0247, -0.0351,  ...,  0.0189,  0.0020,  0.0003],
        [ 0.0100,  0.0032,  0.0072,  ..., -0.0441, -0.0097,  0.0385]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.6250, -2.2559,  1.0273,  ..., -1.8740, -1.1338,  0.8032]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 02:07:18 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The sound that a songbird makes is called a chirrup
The sound that a chicken makes is called a cluck
The sound that a horse makes is called a neigh
The sound that a raven makes is called a caw
The sound that a duck makes is called a quack
The sound that a coyote makes is called a howl
The sound that a seal makes is called a bark
The sound that a crow makes is called a
2024-07-31 02:07:18 root INFO     [order_1_approx] starting weight calculation for The sound that a crow makes is called a caw
The sound that a raven makes is called a caw
The sound that a horse makes is called a neigh
The sound that a songbird makes is called a chirrup
The sound that a seal makes is called a bark
The sound that a coyote makes is called a howl
The sound that a chicken makes is called a cluck
The sound that a duck makes is called a
2024-07-31 02:07:18 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-31 02:08:42 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1663,  0.0944, -0.1222,  ..., -0.2822, -0.3220,  0.1530],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.0762, -2.4062,  0.1292,  ..., -0.8901, -0.5645, -1.4551],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0350,  0.0101,  0.0230,  ..., -0.0108,  0.0003, -0.0052],
        [-0.0146,  0.0413,  0.0053,  ...,  0.0159, -0.0090, -0.0082],
        [-0.0072,  0.0021,  0.0363,  ...,  0.0048, -0.0099,  0.0054],
        ...,
        [-0.0154,  0.0093, -0.0122,  ...,  0.0257, -0.0001,  0.0139],
        [-0.0302,  0.0144, -0.0001,  ...,  0.0199,  0.0435, -0.0114],
        [ 0.0036, -0.0075, -0.0063,  ...,  0.0134, -0.0123,  0.0234]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.5879, -2.4512,  0.2466,  ..., -0.8364, -0.7588, -0.8105]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 02:08:43 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of period is periods
The plural form of member is members
The plural form of year is years
The plural form of development is developments
The plural form of customer is customers
The plural form of application is applications
The plural form of village is villages
The plural form of system is
2024-07-31 02:08:43 root INFO     [order_1_approx] starting weight calculation for The plural form of member is members
The plural form of customer is customers
The plural form of application is applications
The plural form of system is systems
The plural form of year is years
The plural form of village is villages
The plural form of development is developments
The plural form of period is
2024-07-31 02:08:43 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-31 02:10:00 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0674, -0.1306,  0.3071,  ...,  0.1211, -0.2407,  0.0460],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.2070, -3.7637,  2.4863,  ...,  0.7910, -3.5410,  2.8203],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0301, -0.0056, -0.0057,  ...,  0.0009, -0.0081, -0.0037],
        [-0.0002,  0.0275,  0.0157,  ...,  0.0014, -0.0214, -0.0133],
        [ 0.0022, -0.0028,  0.0301,  ..., -0.0193,  0.0025,  0.0039],
        ...,
        [ 0.0019,  0.0130, -0.0180,  ...,  0.0409, -0.0070, -0.0062],
        [-0.0010, -0.0055,  0.0059,  ...,  0.0053,  0.0169, -0.0169],
        [ 0.0068,  0.0032,  0.0091,  ..., -0.0187, -0.0068,  0.0065]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.1877, -3.7090,  2.4277,  ...,  0.8975, -3.7129,  2.7617]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 02:10:01 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The sound that a crow makes is called a caw
The sound that a raven makes is called a caw
The sound that a horse makes is called a neigh
The sound that a songbird makes is called a chirrup
The sound that a seal makes is called a bark
The sound that a coyote makes is called a howl
The sound that a chicken makes is called a cluck
The sound that a duck makes is called a
2024-07-31 02:10:02 root INFO     [order_1_approx] starting weight calculation for The sound that a crow makes is called a caw
The sound that a raven makes is called a caw
The sound that a coyote makes is called a howl
The sound that a duck makes is called a quack
The sound that a songbird makes is called a chirrup
The sound that a horse makes is called a neigh
The sound that a chicken makes is called a cluck
The sound that a seal makes is called a
2024-07-31 02:10:02 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-31 02:11:14 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3584,  0.0977, -0.0847,  ..., -0.2438, -0.1318, -0.0009],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.4236, -3.6152,  1.6699,  ..., -0.5312, -0.5518, -1.0801],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0461,  0.0081,  0.0211,  ...,  0.0097, -0.0166, -0.0095],
        [ 0.0097,  0.0429,  0.0072,  ...,  0.0234, -0.0244, -0.0154],
        [-0.0112, -0.0053,  0.0513,  ..., -0.0084, -0.0175,  0.0005],
        ...,
        [ 0.0092,  0.0053, -0.0080,  ...,  0.0537, -0.0172,  0.0187],
        [-0.0288,  0.0147,  0.0117,  ...,  0.0174,  0.0512,  0.0010],
        [-0.0084,  0.0118, -0.0181,  ...,  0.0127, -0.0002,  0.0518]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.6016, -3.4141,  1.7002,  ..., -0.6211, -1.0703, -0.7251]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 02:11:15 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of member is members
The plural form of customer is customers
The plural form of application is applications
The plural form of system is systems
The plural form of year is years
The plural form of village is villages
The plural form of development is developments
The plural form of period is
2024-07-31 02:11:15 root INFO     [order_1_approx] starting weight calculation for The plural form of system is systems
The plural form of development is developments
The plural form of member is members
The plural form of period is periods
The plural form of village is villages
The plural form of year is years
The plural form of customer is customers
The plural form of application is
2024-07-31 02:11:15 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-31 02:12:40 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1345, -0.0887, -0.1373,  ..., -0.2115, -0.1016,  0.2432],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.9863,  0.0389, -0.3936,  ..., -1.2852,  0.2803,  1.8545],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0613, -0.0089, -0.0312,  ..., -0.0297, -0.0316,  0.0065],
        [ 0.0360,  0.0286, -0.0236,  ..., -0.0083, -0.0368, -0.0156],
        [ 0.0169,  0.0068,  0.0375,  ..., -0.0570, -0.0289, -0.0070],
        ...,
        [ 0.0133, -0.0046,  0.0070,  ...,  0.0644,  0.0184, -0.0090],
        [-0.0149, -0.0111, -0.0031,  ...,  0.0258,  0.0385, -0.0555],
        [-0.0112, -0.0031, -0.0043,  ...,  0.0154,  0.0018,  0.0396]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.8340, -0.1187, -0.6909,  ..., -1.3184,  0.4856,  1.6475]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 02:12:41 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The sound that a crow makes is called a caw
The sound that a raven makes is called a caw
The sound that a coyote makes is called a howl
The sound that a duck makes is called a quack
The sound that a songbird makes is called a chirrup
The sound that a horse makes is called a neigh
The sound that a chicken makes is called a cluck
The sound that a seal makes is called a
2024-07-31 02:12:41 root INFO     total operator prediction time: 1285.3729150295258 seconds
2024-07-31 02:12:41 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on things - color
2024-07-31 02:12:41 root INFO     building operator things - color
2024-07-31 02:12:41 root INFO     [order_1_approx] starting weight calculation for The potato is colored brown
The raven is colored black
The chocolate is colored white
The tea is colored black
The broccoli is colored green
The leaves is colored green
The fridge is colored white
The blood is colored
2024-07-31 02:12:41 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-31 02:13:48 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1252,  0.1810, -0.2976,  ...,  0.1736, -0.3618,  0.1224],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.1553, -1.8379, -1.1963,  ..., -0.6533, -3.7305, -1.3467],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0463, -0.0032,  0.0180,  ...,  0.0049,  0.0072,  0.0195],
        [ 0.0021,  0.0441,  0.0240,  ...,  0.0044,  0.0047,  0.0206],
        [-0.0114, -0.0008,  0.0356,  ..., -0.0033,  0.0044,  0.0107],
        ...,
        [ 0.0017,  0.0037, -0.0117,  ...,  0.0707, -0.0196,  0.0006],
        [-0.0234,  0.0327, -0.0281,  ..., -0.0187,  0.0241, -0.0334],
        [-0.0021, -0.0222,  0.0076,  ...,  0.0131, -0.0224,  0.0540]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.6997, -1.7139, -0.5566,  ..., -1.0586, -3.7812, -0.6831]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 02:13:49 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of system is systems
The plural form of development is developments
The plural form of member is members
The plural form of period is periods
The plural form of village is villages
The plural form of year is years
The plural form of customer is customers
The plural form of application is
2024-07-31 02:13:49 root INFO     [order_1_approx] starting weight calculation for The plural form of member is members
The plural form of period is periods
The plural form of customer is customers
The plural form of application is applications
The plural form of year is years
The plural form of village is villages
The plural form of system is systems
The plural form of development is
2024-07-31 02:13:49 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-31 02:15:22 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1504, -0.1567, -0.4851,  ..., -0.1554, -0.2295, -0.0726],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.1533, -9.8906, -1.7246,  ..., -3.4375,  1.1777, -2.9297],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0563, -0.0048,  0.0214,  ...,  0.0110, -0.0043, -0.0046],
        [ 0.0304,  0.0138, -0.0081,  ..., -0.0096,  0.0051, -0.0121],
        [-0.0063, -0.0132,  0.0083,  ...,  0.0231, -0.0176,  0.0115],
        ...,
        [ 0.0162,  0.0054, -0.0092,  ...,  0.0164, -0.0139, -0.0124],
        [-0.0218,  0.0232,  0.0035,  ...,  0.0232,  0.0265,  0.0033],
        [ 0.0013, -0.0101, -0.0092,  ...,  0.0012, -0.0112,  0.0214]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ -0.9272, -10.0469,  -1.7480,  ...,  -3.6465,   1.4004,  -3.0137]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 02:15:23 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The potato is colored brown
The raven is colored black
The chocolate is colored white
The tea is colored black
The broccoli is colored green
The leaves is colored green
The fridge is colored white
The blood is colored
2024-07-31 02:15:23 root INFO     [order_1_approx] starting weight calculation for The chocolate is colored white
The raven is colored black
The potato is colored brown
The fridge is colored white
The broccoli is colored green
The blood is colored red
The tea is colored black
The leaves is colored
2024-07-31 02:15:23 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-31 02:16:23 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4277,  0.4277, -0.1481,  ...,  0.0051, -0.0496,  0.1265],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.3008, -2.1816,  0.3872,  ..., -2.0742, -2.8574, -2.3984],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0484,  0.0378, -0.0059,  ..., -0.0100,  0.0036, -0.0268],
        [ 0.0134,  0.0260,  0.0182,  ...,  0.0333, -0.0102,  0.0130],
        [-0.0050, -0.0097,  0.0300,  ...,  0.0015, -0.0150,  0.0126],
        ...,
        [ 0.0121, -0.0016, -0.0140,  ...,  0.0526, -0.0286,  0.0246],
        [-0.0383,  0.0319, -0.0135,  ..., -0.0134,  0.0475, -0.0012],
        [ 0.0150, -0.0155, -0.0030,  ...,  0.0256, -0.0215,  0.0447]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.6074, -1.9180,  0.5117,  ..., -2.0820, -2.9863, -1.6875]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 02:16:24 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of member is members
The plural form of period is periods
The plural form of customer is customers
The plural form of application is applications
The plural form of year is years
The plural form of village is villages
The plural form of system is systems
The plural form of development is
2024-07-31 02:16:24 root INFO     total operator prediction time: 1235.190838098526 seconds
2024-07-31 02:16:24 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on verb_Ving - 3pSg
2024-07-31 02:16:24 root INFO     building operator verb_Ving - 3pSg
2024-07-31 02:16:24 root INFO     [order_1_approx] starting weight calculation for When something is seeming, it seems
When something is promoting, it promotes
When something is providing, it provides
When something is enabling, it enables
When something is sitting, it sits
When something is allowing, it allows
When something is referring, it refers
When something is involving, it
2024-07-31 02:16:24 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-31 02:18:04 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0804,  0.2554, -0.2512,  ..., -0.2749,  0.0345, -0.2930],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.6289, -7.4766,  0.0621,  ...,  0.0977,  0.3958, -2.9180],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0518,  0.0188,  0.0021,  ...,  0.0061, -0.0037, -0.0028],
        [ 0.0077,  0.0443,  0.0157,  ...,  0.0062, -0.0104, -0.0114],
        [-0.0009,  0.0096,  0.0361,  ...,  0.0079, -0.0081,  0.0016],
        ...,
        [ 0.0073,  0.0206, -0.0122,  ...,  0.0220, -0.0143,  0.0292],
        [ 0.0174, -0.0100,  0.0026,  ...,  0.0268,  0.0405, -0.0213],
        [-0.0110,  0.0027,  0.0091,  ...,  0.0027,  0.0090,  0.0460]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.8643, -7.3516,  0.3950,  ...,  0.0681, -0.0256, -2.9062]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 02:18:05 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The chocolate is colored white
The raven is colored black
The potato is colored brown
The fridge is colored white
The broccoli is colored green
The blood is colored red
The tea is colored black
The leaves is colored
2024-07-31 02:18:05 root INFO     [order_1_approx] starting weight calculation for The tea is colored black
The blood is colored red
The chocolate is colored white
The broccoli is colored green
The leaves is colored green
The raven is colored black
The potato is colored brown
The fridge is colored
2024-07-31 02:18:05 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-31 02:18:58 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0775,  0.4529, -0.2981,  ...,  0.0244, -0.3293, -0.1175],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.4648, -2.1738,  3.2793,  ...,  0.0986, -3.4590, -4.1953],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0199,  0.0117,  0.0211,  ...,  0.0223, -0.0046,  0.0105],
        [-0.0267,  0.0478,  0.0201,  ...,  0.0075, -0.0056,  0.0008],
        [ 0.0038, -0.0068,  0.0182,  ..., -0.0080,  0.0118, -0.0157],
        ...,
        [ 0.0340,  0.0140, -0.0324,  ...,  0.0188, -0.0131,  0.0070],
        [-0.0173,  0.0216, -0.0147,  ...,  0.0072,  0.0446, -0.0255],
        [-0.0194,  0.0049,  0.0249,  ...,  0.0030, -0.0243,  0.0054]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.2773, -2.0391,  3.1602,  ...,  0.6265, -3.8848, -4.1953]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 02:18:59 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When something is seeming, it seems
When something is promoting, it promotes
When something is providing, it provides
When something is enabling, it enables
When something is sitting, it sits
When something is allowing, it allows
When something is referring, it refers
When something is involving, it
2024-07-31 02:19:00 root INFO     [order_1_approx] starting weight calculation for When something is allowing, it allows
When something is providing, it provides
When something is seeming, it seems
When something is promoting, it promotes
When something is referring, it refers
When something is sitting, it sits
When something is involving, it involves
When something is enabling, it
2024-07-31 02:19:00 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-31 02:20:45 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2017, -0.0436, -0.0993,  ..., -0.0198, -0.4648,  0.0046],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.2051, -9.0781,  0.4182,  ...,  0.3555, -3.4688, -1.6953],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0679,  0.0120,  0.0039,  ..., -0.0035, -0.0154,  0.0392],
        [ 0.0273,  0.0227, -0.0039,  ..., -0.0280, -0.0083,  0.0092],
        [-0.0241, -0.0017,  0.0047,  ...,  0.0338, -0.0235, -0.0119],
        ...,
        [-0.0028,  0.0039, -0.0015,  ...,  0.0474, -0.0020, -0.0171],
        [-0.0169,  0.0054,  0.0010,  ...,  0.0031,  0.0290, -0.0280],
        [ 0.0009, -0.0239,  0.0161,  ..., -0.0175,  0.0204,  0.0373]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.1631, -9.6328,  0.5444,  ..., -0.0161, -3.1543, -1.7705]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 02:20:46 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The tea is colored black
The blood is colored red
The chocolate is colored white
The broccoli is colored green
The leaves is colored green
The raven is colored black
The potato is colored brown
The fridge is colored
2024-07-31 02:20:46 root INFO     [order_1_approx] starting weight calculation for The tea is colored black
The leaves is colored green
The blood is colored red
The fridge is colored white
The raven is colored black
The chocolate is colored white
The broccoli is colored green
The potato is colored
2024-07-31 02:20:46 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-31 02:21:33 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0007,  0.0552, -0.3438,  ...,  0.1498, -0.1432,  0.1477],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.0381, -2.8672, -0.5645,  ..., -1.0205, -7.3242, -2.6992],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0431,  0.0059,  0.0155,  ..., -0.0079, -0.0067,  0.0062],
        [-0.0109,  0.0382, -0.0027,  ...,  0.0053, -0.0101, -0.0086],
        [ 0.0010, -0.0062,  0.0300,  ..., -0.0096, -0.0018, -0.0107],
        ...,
        [ 0.0187,  0.0172, -0.0180,  ...,  0.0293,  0.0031,  0.0011],
        [ 0.0020, -0.0025, -0.0190,  ...,  0.0110,  0.0397, -0.0263],
        [-0.0178, -0.0044,  0.0205,  ..., -0.0103, -0.0248,  0.0442]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.1193, -2.7090, -0.2468,  ..., -0.9673, -7.4570, -3.0078]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 02:21:34 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When something is allowing, it allows
When something is providing, it provides
When something is seeming, it seems
When something is promoting, it promotes
When something is referring, it refers
When something is sitting, it sits
When something is involving, it involves
When something is enabling, it
2024-07-31 02:21:34 root INFO     [order_1_approx] starting weight calculation for When something is involving, it involves
When something is allowing, it allows
When something is referring, it refers
When something is enabling, it enables
When something is seeming, it seems
When something is sitting, it sits
When something is providing, it provides
When something is promoting, it
2024-07-31 02:21:35 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-31 02:23:26 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0115,  0.1833, -0.0481,  ..., -0.2189, -0.4531,  0.0773],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.7070, -4.8359,  0.1191,  ..., -4.8750, -2.8711, -2.7266],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0490,  0.0083,  0.0054,  ...,  0.0041,  0.0014, -0.0018],
        [ 0.0224,  0.0127,  0.0140,  ..., -0.0095, -0.0161, -0.0235],
        [-0.0275,  0.0029,  0.0515,  ...,  0.0366, -0.0081,  0.0074],
        ...,
        [-0.0028, -0.0370, -0.0159,  ...,  0.0758, -0.0245,  0.0110],
        [ 0.0324,  0.0253, -0.0091,  ...,  0.0045,  0.0104,  0.0241],
        [-0.0121,  0.0031, -0.0217,  ...,  0.0152, -0.0081,  0.0537]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.3154, -4.7969,  0.2449,  ..., -4.8008, -2.5176, -2.3203]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 02:23:27 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The tea is colored black
The leaves is colored green
The blood is colored red
The fridge is colored white
The raven is colored black
The chocolate is colored white
The broccoli is colored green
The potato is colored
2024-07-31 02:23:27 root INFO     [order_1_approx] starting weight calculation for The leaves is colored green
The raven is colored black
The chocolate is colored white
The fridge is colored white
The broccoli is colored green
The potato is colored brown
The blood is colored red
The tea is colored
2024-07-31 02:23:27 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-31 02:24:08 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0632,  0.3123, -0.1439,  ...,  0.2551,  0.1749, -0.0163],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.2227, -4.0898, -0.5820,  ..., -0.1123, -6.0547,  0.6289],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 3.3661e-02, -2.2888e-05,  8.5602e-03,  ...,  1.3344e-02,
         -1.0056e-02,  1.6846e-02],
        [-7.4844e-03,  4.0283e-02, -1.6159e-02,  ...,  2.1378e-02,
          6.2218e-03,  1.0956e-02],
        [ 1.7715e-02,  1.4771e-02,  1.7685e-02,  ..., -5.8327e-03,
         -4.0169e-03,  1.1435e-03],
        ...,
        [ 1.3985e-02, -2.7866e-03, -3.5515e-03,  ...,  3.4851e-02,
         -4.6844e-03,  1.1497e-02],
        [ 6.7596e-03,  3.1209e-04, -2.1439e-02,  ..., -1.5869e-02,
          2.2934e-02, -3.3447e-02],
        [-2.5272e-03, -5.5695e-03,  7.9060e-04,  ..., -7.4806e-03,
         -1.2566e-02,  2.5406e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.3750, -3.8730, -0.5269,  ...,  0.0477, -6.0586,  0.5376]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 02:24:09 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When something is involving, it involves
When something is allowing, it allows
When something is referring, it refers
When something is enabling, it enables
When something is seeming, it seems
When something is sitting, it sits
When something is providing, it provides
When something is promoting, it
2024-07-31 02:24:09 root INFO     [order_1_approx] starting weight calculation for When something is enabling, it enables
When something is referring, it refers
When something is sitting, it sits
When something is allowing, it allows
When something is promoting, it promotes
When something is seeming, it seems
When something is involving, it involves
When something is providing, it
2024-07-31 02:24:09 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-31 02:26:05 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0016, -0.3813, -0.1945,  ..., -0.1013, -0.2468, -0.0925],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.5322, -2.9219, -0.6206,  ..., -3.6797, -0.1729,  0.2783],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0442,  0.0178,  0.0109,  ..., -0.0089, -0.0014,  0.0162],
        [-0.0068,  0.0392,  0.0050,  ..., -0.0028, -0.0108, -0.0135],
        [-0.0134, -0.0202,  0.0190,  ...,  0.0203,  0.0001,  0.0088],
        ...,
        [ 0.0156, -0.0148, -0.0042,  ...,  0.0474, -0.0180,  0.0018],
        [ 0.0013,  0.0037, -0.0128,  ...,  0.0195,  0.0223,  0.0002],
        [-0.0211, -0.0162,  0.0026,  ..., -0.0142,  0.0145,  0.0305]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.2507, -3.3965, -0.6465,  ..., -3.9004, -0.4026,  0.1973]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 02:26:06 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The leaves is colored green
The raven is colored black
The chocolate is colored white
The fridge is colored white
The broccoli is colored green
The potato is colored brown
The blood is colored red
The tea is colored
2024-07-31 02:26:06 root INFO     [order_1_approx] starting weight calculation for The blood is colored red
The potato is colored brown
The chocolate is colored white
The leaves is colored green
The fridge is colored white
The tea is colored black
The broccoli is colored green
The raven is colored
2024-07-31 02:26:06 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-31 02:26:43 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2751, -0.1477, -0.2678,  ..., -0.0234,  0.1300, -0.1942],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.3760, -6.6602,  0.3340,  ..., -0.7109, -5.7734, -0.6924],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0518, -0.0004,  0.0305,  ...,  0.0098, -0.0016,  0.0464],
        [-0.0046,  0.0293,  0.0080,  ...,  0.0179, -0.0141,  0.0124],
        [-0.0052,  0.0020,  0.0284,  ..., -0.0096, -0.0041, -0.0095],
        ...,
        [ 0.0097,  0.0088,  0.0076,  ...,  0.0417, -0.0155,  0.0096],
        [ 0.0089, -0.0064, -0.0162,  ...,  0.0025,  0.0359, -0.0471],
        [-0.0104, -0.0025,  0.0038,  ..., -0.0139, -0.0093,  0.0424]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.1426, -6.0312,  0.5537,  ..., -0.6045, -5.6094, -0.8110]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 02:26:44 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When something is enabling, it enables
When something is referring, it refers
When something is sitting, it sits
When something is allowing, it allows
When something is promoting, it promotes
When something is seeming, it seems
When something is involving, it involves
When something is providing, it
2024-07-31 02:26:45 root INFO     [order_1_approx] starting weight calculation for When something is sitting, it sits
When something is enabling, it enables
When something is promoting, it promotes
When something is seeming, it seems
When something is referring, it refers
When something is providing, it provides
When something is involving, it involves
When something is allowing, it
2024-07-31 02:26:45 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-31 02:28:45 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0668, -0.0282, -0.1865,  ..., -0.1542, -0.0122,  0.2241],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.3164e+00, -4.8164e+00,  2.1406e+00,  ...,  2.9297e-03,
         2.9219e+00, -1.7979e+00], device='cuda:0', dtype=torch.float16,
       grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0621,  0.0114, -0.0008,  ..., -0.0119,  0.0053, -0.0117],
        [ 0.0069,  0.0266,  0.0584,  ...,  0.0156, -0.0109, -0.0101],
        [-0.0311, -0.0172,  0.0571,  ..., -0.0045, -0.0056, -0.0069],
        ...,
        [ 0.0155,  0.0378,  0.0120,  ...,  0.0704, -0.0090,  0.0087],
        [-0.0179,  0.0140,  0.0228,  ...,  0.0113,  0.0320, -0.0339],
        [ 0.0276, -0.0149, -0.0173,  ..., -0.0221, -0.0335,  0.0607]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.2363, -5.0977,  2.0156,  ..., -0.2759,  2.2793, -1.6084]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 02:28:46 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The blood is colored red
The potato is colored brown
The chocolate is colored white
The leaves is colored green
The fridge is colored white
The tea is colored black
The broccoli is colored green
The raven is colored
2024-07-31 02:28:47 root INFO     [order_1_approx] starting weight calculation for The broccoli is colored green
The fridge is colored white
The raven is colored black
The tea is colored black
The potato is colored brown
The leaves is colored green
The blood is colored red
The chocolate is colored
2024-07-31 02:28:47 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-31 02:29:19 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0903,  0.3662, -0.2024,  ..., -0.1144, -0.0090, -0.0817],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.7188, -3.9180, -0.3359,  ..., -1.2900, -6.1094,  0.6699],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0482,  0.0098,  0.0042,  ..., -0.0059, -0.0057,  0.0036],
        [-0.0039,  0.0530, -0.0095,  ...,  0.0292, -0.0188,  0.0084],
        [-0.0061, -0.0076,  0.0249,  ..., -0.0108,  0.0003, -0.0094],
        ...,
        [ 0.0080,  0.0049,  0.0045,  ...,  0.0212, -0.0029,  0.0109],
        [-0.0002,  0.0065, -0.0193,  ..., -0.0052,  0.0317, -0.0341],
        [-0.0227,  0.0051, -0.0041,  ...,  0.0063, -0.0126,  0.0187]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.5605, -3.9355,  0.0820,  ..., -0.7192, -6.0078,  0.4468]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 02:29:20 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When something is sitting, it sits
When something is enabling, it enables
When something is promoting, it promotes
When something is seeming, it seems
When something is referring, it refers
When something is providing, it provides
When something is involving, it involves
When something is allowing, it
2024-07-31 02:29:20 root INFO     [order_1_approx] starting weight calculation for When something is allowing, it allows
When something is seeming, it seems
When something is involving, it involves
When something is promoting, it promotes
When something is providing, it provides
When something is referring, it refers
When something is enabling, it enables
When something is sitting, it
2024-07-31 02:29:20 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-31 02:31:27 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2974, -0.3225, -0.5288,  ...,  0.0068, -0.3171,  0.0098],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.3311, -5.8359, -1.1104,  ..., -3.6055, -3.0840,  2.4180],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0298,  0.0093,  0.0121,  ..., -0.0052,  0.0029,  0.0094],
        [ 0.0207,  0.0200,  0.0085,  ..., -0.0055, -0.0146, -0.0151],
        [-0.0124,  0.0109,  0.0130,  ...,  0.0170, -0.0021, -0.0038],
        ...,
        [ 0.0080, -0.0191,  0.0093,  ...,  0.0272, -0.0159, -0.0089],
        [-0.0016, -0.0085, -0.0081,  ...,  0.0102, -0.0008, -0.0068],
        [ 0.0015,  0.0035, -0.0072,  ...,  0.0032,  0.0038,  0.0104]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.2048, -6.0664, -1.1475,  ..., -3.7402, -3.0020,  2.4023]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 02:31:28 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The broccoli is colored green
The fridge is colored white
The raven is colored black
The tea is colored black
The potato is colored brown
The leaves is colored green
The blood is colored red
The chocolate is colored
2024-07-31 02:31:29 root INFO     [order_1_approx] starting weight calculation for The fridge is colored white
The leaves is colored green
The tea is colored black
The raven is colored black
The blood is colored red
The chocolate is colored white
The potato is colored brown
The broccoli is colored
2024-07-31 02:31:29 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-31 02:31:54 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1311,  0.0485, -0.3003,  ...,  0.2023, -0.3743,  0.0959],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.3711, -4.2422, -0.0195,  ..., -2.7695, -3.5820, -1.3154],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0362, -0.0115,  0.0229,  ...,  0.0133, -0.0115, -0.0197],
        [ 0.0005,  0.0437,  0.0112,  ..., -0.0034,  0.0138,  0.0079],
        [-0.0143, -0.0319,  0.0319,  ..., -0.0081, -0.0088,  0.0075],
        ...,
        [ 0.0221, -0.0109,  0.0039,  ...,  0.0491,  0.0029,  0.0168],
        [ 0.0068,  0.0500, -0.0161,  ..., -0.0166,  0.0357, -0.0023],
        [-0.0154,  0.0091,  0.0252,  ..., -0.0157, -0.0100,  0.0303]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.9785, -4.4141,  0.1947,  ..., -2.3945, -4.0938, -1.4785]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 02:31:55 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When something is allowing, it allows
When something is seeming, it seems
When something is involving, it involves
When something is promoting, it promotes
When something is providing, it provides
When something is referring, it refers
When something is enabling, it enables
When something is sitting, it
2024-07-31 02:31:55 root INFO     [order_1_approx] starting weight calculation for When something is enabling, it enables
When something is allowing, it allows
When something is promoting, it promotes
When something is involving, it involves
When something is providing, it provides
When something is referring, it refers
When something is sitting, it sits
When something is seeming, it
2024-07-31 02:31:55 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-31 02:34:09 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1467,  0.1512, -0.3582,  ..., -0.3149, -0.3171,  0.1661],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.7236, -6.1172, -0.0703,  ...,  0.2441,  0.8145, -1.1641],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0164,  0.0107,  0.0054,  ...,  0.0024,  0.0057,  0.0029],
        [ 0.0023,  0.0210,  0.0015,  ..., -0.0093,  0.0058, -0.0144],
        [-0.0248, -0.0020,  0.0227,  ...,  0.0317, -0.0117,  0.0082],
        ...,
        [-0.0112, -0.0117, -0.0051,  ...,  0.0375, -0.0027, -0.0003],
        [-0.0076,  0.0081, -0.0093,  ...,  0.0059,  0.0049,  0.0002],
        [-0.0034,  0.0049,  0.0062,  ...,  0.0012, -0.0054,  0.0181]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.9629, -6.0781, -0.2527,  ...,  0.3774,  0.8877, -1.1064]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 02:34:10 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The fridge is colored white
The leaves is colored green
The tea is colored black
The raven is colored black
The blood is colored red
The chocolate is colored white
The potato is colored brown
The broccoli is colored
2024-07-31 02:34:10 root INFO     total operator prediction time: 1289.1861913204193 seconds
2024-07-31 02:34:10 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on country - capital
2024-07-31 02:34:10 root INFO     building operator country - capital
2024-07-31 02:34:10 root INFO     [order_1_approx] starting weight calculation for The country with tbilisi as its capital is known as georgia
The country with ankara as its capital is known as turkey
The country with cairo as its capital is known as egypt
The country with dhaka as its capital is known as bangladesh
The country with abuja as its capital is known as nigeria
The country with paris as its capital is known as france
The country with havana as its capital is known as cuba
The country with hanoi as its capital is known as
2024-07-31 02:34:10 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-31 02:34:28 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1309,  0.2209,  0.0353,  ...,  0.0637, -0.3867,  0.0448],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.2637, -1.8779, -1.7314,  ...,  1.8926, -3.4902, -2.1172],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0392, -0.0079,  0.0024,  ...,  0.0048,  0.0085,  0.0036],
        [ 0.0098,  0.0326, -0.0008,  ..., -0.0011,  0.0041,  0.0084],
        [ 0.0158, -0.0070,  0.0219,  ..., -0.0058, -0.0071, -0.0034],
        ...,
        [ 0.0093,  0.0108, -0.0051,  ...,  0.0267, -0.0129,  0.0208],
        [-0.0316,  0.0364, -0.0150,  ..., -0.0288,  0.0226, -0.0473],
        [-0.0112,  0.0074,  0.0172,  ..., -0.0025, -0.0014,  0.0137]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.4043, -1.7227, -1.9121,  ...,  2.1055, -4.0430, -2.1387]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 02:34:30 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When something is enabling, it enables
When something is allowing, it allows
When something is promoting, it promotes
When something is involving, it involves
When something is providing, it provides
When something is referring, it refers
When something is sitting, it sits
When something is seeming, it
2024-07-31 02:34:30 root INFO     [order_1_approx] starting weight calculation for When something is allowing, it allows
When something is providing, it provides
When something is involving, it involves
When something is promoting, it promotes
When something is seeming, it seems
When something is sitting, it sits
When something is enabling, it enables
When something is referring, it
2024-07-31 02:34:30 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-31 02:36:49 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2262, -0.3467, -0.2178,  ..., -0.0111, -0.2793,  0.2192],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.8682, -5.7734,  0.2932,  ..., -1.9023, -2.0742, -3.3262],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 1.0162e-02,  2.0733e-03, -8.5297e-03,  ...,  1.2466e-02,
         -1.7410e-02, -1.5289e-02],
        [-4.1580e-03,  6.0196e-03, -2.1591e-03,  ..., -9.8877e-03,
         -6.6090e-04, -2.5330e-02],
        [ 2.2705e-02,  4.8866e-03,  2.4780e-02,  ..., -6.5727e-03,
         -5.2719e-03, -7.9803e-03],
        ...,
        [ 1.0872e-02, -1.8402e-02, -6.2370e-03,  ...,  1.2047e-02,
          1.1246e-02, -1.4397e-02],
        [ 5.6725e-03, -1.4664e-02, -4.5738e-03,  ..., -1.7578e-02,
          1.1742e-02,  1.4839e-03],
        [-1.0681e-02, -1.9958e-02,  1.3332e-03,  ..., -5.5771e-03,
          9.0256e-03,  7.1526e-06]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.9780, -5.4922,  0.3049,  ..., -1.8242, -2.0938, -3.4180]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 02:36:50 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country with tbilisi as its capital is known as georgia
The country with ankara as its capital is known as turkey
The country with cairo as its capital is known as egypt
The country with dhaka as its capital is known as bangladesh
The country with abuja as its capital is known as nigeria
The country with paris as its capital is known as france
The country with havana as its capital is known as cuba
The country with hanoi as its capital is known as
2024-07-31 02:36:51 root INFO     [order_1_approx] starting weight calculation for The country with dhaka as its capital is known as bangladesh
The country with paris as its capital is known as france
The country with cairo as its capital is known as egypt
The country with havana as its capital is known as cuba
The country with tbilisi as its capital is known as georgia
The country with abuja as its capital is known as nigeria
The country with hanoi as its capital is known as vietnam
The country with ankara as its capital is known as
2024-07-31 02:36:51 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-31 02:36:58 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2371,  0.0127, -0.3103,  ...,  0.0963, -0.1609, -0.0842],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.3909, -4.3828,  2.5391,  ...,  1.1846, -4.4688, -0.7217],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0388, -0.0049,  0.0194,  ...,  0.0131, -0.0052,  0.0126],
        [-0.0288,  0.0599,  0.0274,  ...,  0.0131, -0.0168,  0.0139],
        [ 0.0051,  0.0011,  0.0253,  ..., -0.0099, -0.0199, -0.0127],
        ...,
        [ 0.0224,  0.0261, -0.0154,  ...,  0.0605, -0.0024,  0.0221],
        [ 0.0283, -0.0063, -0.0083,  ..., -0.0072,  0.0331, -0.0562],
        [ 0.0033,  0.0119,  0.0127,  ..., -0.0202, -0.0020,  0.0226]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.5654, -4.4180,  2.8340,  ...,  1.4180, -4.0938, -0.7793]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 02:36:59 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When something is allowing, it allows
When something is providing, it provides
When something is involving, it involves
When something is promoting, it promotes
When something is seeming, it seems
When something is sitting, it sits
When something is enabling, it enables
When something is referring, it
2024-07-31 02:36:59 root INFO     total operator prediction time: 1234.8389987945557 seconds
2024-07-31 02:36:59 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on verb_inf - 3pSg
2024-07-31 02:36:59 root INFO     building operator verb_inf - 3pSg
2024-07-31 02:36:59 root INFO     [order_1_approx] starting weight calculation for I follow, he follows
I ask, he asks
I refer, he refers
I occur, he occurs
I promote, he promotes
I explain, he explains
I apply, he applies
I tell, he
2024-07-31 02:36:59 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-31 02:39:26 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1377, -0.2224, -0.0667,  ...,  0.0279, -0.1489, -0.0425],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([  2.1445,  -1.3740,   0.3652,  ...,   0.8447, -11.1406,  -1.6562],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 4.1748e-02, -2.1915e-03, -1.2184e-02,  ...,  4.5586e-03,
          9.2697e-03,  2.8641e-02],
        [-6.5956e-03,  1.7746e-02, -6.6223e-03,  ..., -6.4621e-03,
          1.2465e-03, -1.6403e-02],
        [-8.5526e-03,  3.5477e-03,  1.3519e-02,  ..., -1.9363e-02,
         -1.2230e-02,  4.2000e-03],
        ...,
        [ 4.5738e-03,  1.0582e-02,  8.2779e-03,  ..., -4.3869e-03,
          8.3313e-03, -7.6485e-03],
        [-1.1658e-02,  3.0689e-03, -2.4567e-02,  ...,  1.9646e-03,
          8.3389e-03, -2.1687e-03],
        [ 2.2079e-02,  7.6294e-05, -9.7504e-03,  ..., -1.1475e-02,
         -5.4474e-03, -3.7155e-03]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[  2.2480,  -1.1895,   0.2588,  ...,   1.1855, -11.3359,  -1.5498]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 02:39:27 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for I follow, he follows
I ask, he asks
I refer, he refers
I occur, he occurs
I promote, he promotes
I explain, he explains
I apply, he applies
I tell, he
2024-07-31 02:39:27 root INFO     [order_1_approx] starting weight calculation for I follow, he follows
I promote, he promotes
I explain, he explains
I occur, he occurs
I ask, he asks
I refer, he refers
I tell, he tells
I apply, he
2024-07-31 02:39:27 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-31 02:39:30 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0651, -0.1477, -0.8989,  ...,  0.2798, -0.3555, -0.1104],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.4805, -4.0195, -0.6011,  ..., -0.1165,  2.2598, -3.6328],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0254, -0.0012, -0.0178,  ...,  0.0195, -0.0077, -0.0126],
        [ 0.0154,  0.0237,  0.0220,  ...,  0.0188,  0.0015, -0.0092],
        [-0.0295,  0.0137,  0.0282,  ..., -0.0029,  0.0114, -0.0206],
        ...,
        [ 0.0059,  0.0276, -0.0061,  ...,  0.0297, -0.0086, -0.0044],
        [-0.0081, -0.0065, -0.0056,  ..., -0.0056,  0.0220, -0.0076],
        [-0.0078,  0.0093, -0.0007,  ..., -0.0004, -0.0022,  0.0250]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.0635, -3.4570, -0.5283,  ..., -0.2009,  2.2598, -3.3887]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 02:39:31 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country with dhaka as its capital is known as bangladesh
The country with paris as its capital is known as france
The country with cairo as its capital is known as egypt
The country with havana as its capital is known as cuba
The country with tbilisi as its capital is known as georgia
The country with abuja as its capital is known as nigeria
The country with hanoi as its capital is known as vietnam
The country with ankara as its capital is known as
2024-07-31 02:39:32 root INFO     [order_1_approx] starting weight calculation for The country with havana as its capital is known as cuba
The country with abuja as its capital is known as nigeria
The country with cairo as its capital is known as egypt
The country with hanoi as its capital is known as vietnam
The country with dhaka as its capital is known as bangladesh
The country with tbilisi as its capital is known as georgia
The country with ankara as its capital is known as turkey
The country with paris as its capital is known as
2024-07-31 02:39:32 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-31 02:41:56 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0768,  0.0307,  0.0734,  ...,  0.1211, -0.2227,  0.1371],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.6895, -2.5957, -1.4512,  ..., -0.0322, -8.5938, -1.2168],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0474,  0.0167,  0.0034,  ...,  0.0167,  0.0079,  0.0269],
        [-0.0065,  0.0152,  0.0120,  ..., -0.0123,  0.0260, -0.0089],
        [ 0.0211,  0.0132,  0.0027,  ..., -0.0200,  0.0123, -0.0099],
        ...,
        [ 0.0015,  0.0061,  0.0049,  ...,  0.0206,  0.0328,  0.0092],
        [-0.0107,  0.0137, -0.0213,  ..., -0.0033, -0.0089, -0.0224],
        [-0.0178,  0.0260,  0.0037,  ..., -0.0040, -0.0182, -0.0008]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.4863, -2.3594, -1.2451,  ...,  0.3313, -9.1250, -1.1270]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 02:41:57 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for I follow, he follows
I promote, he promotes
I explain, he explains
I occur, he occurs
I ask, he asks
I refer, he refers
I tell, he tells
I apply, he
2024-07-31 02:41:57 root INFO     [order_1_approx] starting weight calculation for I follow, he follows
I promote, he promotes
I occur, he occurs
I apply, he applies
I explain, he explains
I tell, he tells
I refer, he refers
I ask, he
2024-07-31 02:41:57 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-31 02:42:09 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1092, -0.1211, -0.4141,  ...,  0.3477,  0.0682,  0.1144],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.5967, -5.6953,  0.1646,  ..., -2.1816,  0.9512, -3.3594],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 2.3758e-02, -1.3649e-02, -9.8572e-03,  ..., -2.7695e-03,
          8.9111e-03,  6.3095e-03],
        [ 1.4381e-02,  1.7532e-02, -1.1292e-03,  ..., -1.2493e-03,
         -2.1408e-02, -2.5253e-02],
        [-9.3002e-03,  1.1436e-02,  3.8879e-02,  ...,  2.7420e-02,
         -1.1139e-03, -5.9738e-03],
        ...,
        [-7.7553e-03,  2.5291e-03,  4.9591e-05,  ...,  4.5593e-02,
         -5.3406e-03, -1.8082e-02],
        [ 7.0000e-04, -1.1230e-02,  6.0883e-03,  ..., -1.4046e-02,
          1.5091e-02,  2.5902e-03],
        [-1.2436e-02, -1.9562e-02, -9.5367e-03,  ...,  2.0050e-02,
         -6.5002e-03,  1.7563e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.5879, -5.4180,  0.0190,  ..., -1.9844,  0.9536, -3.1992]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 02:42:10 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country with havana as its capital is known as cuba
The country with abuja as its capital is known as nigeria
The country with cairo as its capital is known as egypt
The country with hanoi as its capital is known as vietnam
The country with dhaka as its capital is known as bangladesh
The country with tbilisi as its capital is known as georgia
The country with ankara as its capital is known as turkey
The country with paris as its capital is known as
2024-07-31 02:42:10 root INFO     [order_1_approx] starting weight calculation for The country with havana as its capital is known as cuba
The country with hanoi as its capital is known as vietnam
The country with dhaka as its capital is known as bangladesh
The country with ankara as its capital is known as turkey
The country with paris as its capital is known as france
The country with abuja as its capital is known as nigeria
The country with tbilisi as its capital is known as georgia
The country with cairo as its capital is known as
2024-07-31 02:42:10 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-31 02:44:30 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1345,  0.3167, -0.0422,  ...,  0.0484, -0.2856, -0.5088],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.1289, -4.0117, -2.6055,  ..., -0.0865, -8.0625,  0.3281],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0373,  0.0106,  0.0017,  ...,  0.0130, -0.0181,  0.0098],
        [-0.0145,  0.0290, -0.0077,  ...,  0.0019,  0.0140, -0.0105],
        [-0.0150,  0.0006, -0.0046,  ..., -0.0367, -0.0040, -0.0004],
        ...,
        [-0.0054, -0.0036,  0.0003,  ...,  0.0087,  0.0260, -0.0168],
        [-0.0199, -0.0011, -0.0150,  ..., -0.0006,  0.0125, -0.0147],
        [-0.0130,  0.0184, -0.0018,  ...,  0.0038, -0.0022, -0.0047]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.9355, -3.7188, -2.3320,  ...,  0.4604, -8.5469,  0.4360]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 02:44:32 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for I follow, he follows
I promote, he promotes
I occur, he occurs
I apply, he applies
I explain, he explains
I tell, he tells
I refer, he refers
I ask, he
2024-07-31 02:44:32 root INFO     [order_1_approx] starting weight calculation for I tell, he tells
I apply, he applies
I occur, he occurs
I ask, he asks
I promote, he promotes
I explain, he explains
I follow, he follows
I refer, he
2024-07-31 02:44:32 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-31 02:44:49 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0015, -0.1201, -0.4937,  ...,  0.4150, -0.5112,  0.0506],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.4414, -3.3359,  1.7207,  ..., -0.8027,  0.6108, -1.7119],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0188,  0.0023,  0.0003,  ...,  0.0127, -0.0185, -0.0003],
        [ 0.0144,  0.0264,  0.0250,  ...,  0.0111, -0.0068, -0.0026],
        [-0.0098,  0.0249,  0.0090,  ...,  0.0146, -0.0239, -0.0116],
        ...,
        [ 0.0036,  0.0279,  0.0047,  ...,  0.0368, -0.0144, -0.0106],
        [ 0.0042, -0.0135,  0.0042,  ..., -0.0076,  0.0080, -0.0101],
        [-0.0126, -0.0025, -0.0217,  ...,  0.0215, -0.0099,  0.0136]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.2891, -3.0039,  1.3574,  ..., -0.6255,  0.3616, -1.7324]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 02:44:50 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country with havana as its capital is known as cuba
The country with hanoi as its capital is known as vietnam
The country with dhaka as its capital is known as bangladesh
The country with ankara as its capital is known as turkey
The country with paris as its capital is known as france
The country with abuja as its capital is known as nigeria
The country with tbilisi as its capital is known as georgia
The country with cairo as its capital is known as
2024-07-31 02:44:50 root INFO     [order_1_approx] starting weight calculation for The country with paris as its capital is known as france
The country with havana as its capital is known as cuba
The country with hanoi as its capital is known as vietnam
The country with tbilisi as its capital is known as georgia
The country with abuja as its capital is known as nigeria
The country with ankara as its capital is known as turkey
The country with cairo as its capital is known as egypt
The country with dhaka as its capital is known as
2024-07-31 02:44:50 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-31 02:47:05 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.3003,  0.0978, -0.3542,  ...,  0.1516, -0.2871, -0.2039],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.5029, -4.0664, -0.0391,  ...,  1.0430, -9.0156, -1.7422],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0458, -0.0067,  0.0078,  ...,  0.0055,  0.0097,  0.0229],
        [-0.0249,  0.0311, -0.0164,  ..., -0.0116,  0.0048, -0.0110],
        [ 0.0242, -0.0033, -0.0063,  ..., -0.0232,  0.0055, -0.0083],
        ...,
        [ 0.0267,  0.0031, -0.0151,  ...,  0.0341,  0.0179,  0.0078],
        [ 0.0065, -0.0104, -0.0064,  ..., -0.0108, -0.0101, -0.0168],
        [ 0.0052,  0.0116,  0.0047,  ..., -0.0245, -0.0251,  0.0248]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.7061, -3.8379,  0.4136,  ...,  1.0039, -8.7969, -1.4980]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 02:47:06 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for I tell, he tells
I apply, he applies
I occur, he occurs
I ask, he asks
I promote, he promotes
I explain, he explains
I follow, he follows
I refer, he
2024-07-31 02:47:06 root INFO     [order_1_approx] starting weight calculation for I promote, he promotes
I follow, he follows
I refer, he refers
I ask, he asks
I tell, he tells
I apply, he applies
I occur, he occurs
I explain, he
2024-07-31 02:47:06 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-31 02:47:28 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.4336, -0.2771, -0.4478,  ...,  0.2698, -0.2683,  0.1702],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.3096, -4.8633,  0.0264,  ..., -1.7412, -0.2915, -4.8203],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0028,  0.0046,  0.0013,  ..., -0.0002, -0.0154, -0.0090],
        [-0.0126,  0.0203, -0.0064,  ...,  0.0023, -0.0033, -0.0318],
        [-0.0024,  0.0063,  0.0451,  ..., -0.0164,  0.0224, -0.0294],
        ...,
        [ 0.0032,  0.0174,  0.0045,  ...,  0.0359,  0.0103, -0.0020],
        [-0.0002,  0.0146, -0.0045,  ..., -0.0092,  0.0125,  0.0021],
        [-0.0127, -0.0060,  0.0040,  ...,  0.0024,  0.0174, -0.0165]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.1477, -4.8125,  0.4485,  ..., -1.4609, -0.4011, -4.4414]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 02:47:29 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country with paris as its capital is known as france
The country with havana as its capital is known as cuba
The country with hanoi as its capital is known as vietnam
The country with tbilisi as its capital is known as georgia
The country with abuja as its capital is known as nigeria
The country with ankara as its capital is known as turkey
The country with cairo as its capital is known as egypt
The country with dhaka as its capital is known as
2024-07-31 02:47:29 root INFO     [order_1_approx] starting weight calculation for The country with hanoi as its capital is known as vietnam
The country with paris as its capital is known as france
The country with tbilisi as its capital is known as georgia
The country with dhaka as its capital is known as bangladesh
The country with ankara as its capital is known as turkey
The country with havana as its capital is known as cuba
The country with cairo as its capital is known as egypt
The country with abuja as its capital is known as
2024-07-31 02:47:30 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-31 02:49:40 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1318,  0.1199, -0.1616,  ..., -0.0815, -0.2864, -0.0846],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.4844, -2.8262,  0.9609,  ...,  0.8242, -7.4961, -0.1172],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0074,  0.0060, -0.0010,  ...,  0.0110,  0.0102,  0.0315],
        [-0.0114,  0.0196,  0.0064,  ..., -0.0232,  0.0021, -0.0085],
        [-0.0046,  0.0170,  0.0137,  ..., -0.0267,  0.0088, -0.0051],
        ...,
        [ 0.0060, -0.0104,  0.0151,  ...,  0.0248,  0.0103,  0.0053],
        [ 0.0058, -0.0023,  0.0051,  ..., -0.0143, -0.0081, -0.0223],
        [ 0.0099,  0.0067,  0.0019,  ..., -0.0181, -0.0171, -0.0089]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.3125, -2.5840,  1.2451,  ...,  1.0488, -7.6094, -0.1580]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 02:49:41 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for I promote, he promotes
I follow, he follows
I refer, he refers
I ask, he asks
I tell, he tells
I apply, he applies
I occur, he occurs
I explain, he
2024-07-31 02:49:41 root INFO     [order_1_approx] starting weight calculation for I follow, he follows
I refer, he refers
I apply, he applies
I ask, he asks
I explain, he explains
I occur, he occurs
I tell, he tells
I promote, he
2024-07-31 02:49:41 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-31 02:50:09 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0850, -0.0717, -0.3340,  ...,  0.1514, -0.3643,  0.3213],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.7764, -3.9121, -1.1943,  ..., -1.1523, -0.2642, -2.0410],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0354, -0.0209, -0.0050,  ...,  0.0154, -0.0091,  0.0097],
        [-0.0132,  0.0325,  0.0271,  ..., -0.0164, -0.0224, -0.0190],
        [-0.0265,  0.0202,  0.0186,  ...,  0.0028, -0.0013, -0.0370],
        ...,
        [ 0.0084,  0.0145,  0.0007,  ...,  0.0222, -0.0113,  0.0055],
        [ 0.0093,  0.0122, -0.0156,  ...,  0.0322,  0.0122, -0.0300],
        [ 0.0126, -0.0138,  0.0102,  ...,  0.0400,  0.0060,  0.0419]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.0547, -4.2578, -1.6299,  ..., -1.0898, -0.5083, -1.6914]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 02:50:10 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country with hanoi as its capital is known as vietnam
The country with paris as its capital is known as france
The country with tbilisi as its capital is known as georgia
The country with dhaka as its capital is known as bangladesh
The country with ankara as its capital is known as turkey
The country with havana as its capital is known as cuba
The country with cairo as its capital is known as egypt
The country with abuja as its capital is known as
2024-07-31 02:50:10 root INFO     [order_1_approx] starting weight calculation for The country with abuja as its capital is known as nigeria
The country with cairo as its capital is known as egypt
The country with ankara as its capital is known as turkey
The country with dhaka as its capital is known as bangladesh
The country with hanoi as its capital is known as vietnam
The country with havana as its capital is known as cuba
The country with paris as its capital is known as france
The country with tbilisi as its capital is known as
2024-07-31 02:50:10 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-31 02:52:14 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0424,  0.0879, -0.2693,  ...,  0.1379, -0.0706,  0.1009],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.4062e+00, -3.5859e+00,  3.0273e-01,  ...,  8.3008e-03,
        -9.0547e+00, -8.5352e-01], device='cuda:1', dtype=torch.float16,
       grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0507, -0.0058,  0.0068,  ...,  0.0034, -0.0038,  0.0195],
        [-0.0219,  0.0152, -0.0140,  ...,  0.0023,  0.0087,  0.0010],
        [ 0.0098,  0.0158,  0.0164,  ..., -0.0138,  0.0043,  0.0056],
        ...,
        [ 0.0077, -0.0155, -0.0284,  ...,  0.0272,  0.0063, -0.0054],
        [-0.0001,  0.0063, -0.0234,  ...,  0.0021,  0.0021, -0.0119],
        [ 0.0076, -0.0017, -0.0205,  ..., -0.0197, -0.0110,  0.0084]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.4648, -3.3164,  0.5312,  ...,  0.5767, -9.0078, -0.6567]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 02:52:15 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for I follow, he follows
I refer, he refers
I apply, he applies
I ask, he asks
I explain, he explains
I occur, he occurs
I tell, he tells
I promote, he
2024-07-31 02:52:15 root INFO     [order_1_approx] starting weight calculation for I explain, he explains
I refer, he refers
I occur, he occurs
I tell, he tells
I apply, he applies
I promote, he promotes
I ask, he asks
I follow, he
2024-07-31 02:52:15 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-31 02:52:51 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0180, -0.4077, -0.5918,  ...,  0.1720, -0.2500,  0.1051],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.7871, -5.7969, -0.9194,  ..., -2.9922,  0.6680, -3.2793],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0059,  0.0035, -0.0057,  ...,  0.0189, -0.0055,  0.0043],
        [ 0.0005,  0.0201,  0.0041,  ...,  0.0048, -0.0057, -0.0231],
        [-0.0217,  0.0049,  0.0068,  ...,  0.0085, -0.0063, -0.0151],
        ...,
        [ 0.0040,  0.0033, -0.0138,  ...,  0.0229, -0.0007,  0.0009],
        [ 0.0011,  0.0105, -0.0090,  ...,  0.0163,  0.0156,  0.0021],
        [-0.0097, -0.0114, -0.0127,  ...,  0.0170,  0.0078,  0.0031]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.4648, -5.8555, -0.9170,  ..., -3.0254,  0.6484, -3.1016]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 02:52:52 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country with abuja as its capital is known as nigeria
The country with cairo as its capital is known as egypt
The country with ankara as its capital is known as turkey
The country with dhaka as its capital is known as bangladesh
The country with hanoi as its capital is known as vietnam
The country with havana as its capital is known as cuba
The country with paris as its capital is known as france
The country with tbilisi as its capital is known as
2024-07-31 02:52:52 root INFO     [order_1_approx] starting weight calculation for The country with dhaka as its capital is known as bangladesh
The country with hanoi as its capital is known as vietnam
The country with cairo as its capital is known as egypt
The country with abuja as its capital is known as nigeria
The country with tbilisi as its capital is known as georgia
The country with paris as its capital is known as france
The country with ankara as its capital is known as turkey
The country with havana as its capital is known as
2024-07-31 02:52:52 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-31 02:54:48 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0667, -0.0887, -0.3726,  ..., -0.0503,  0.2079, -0.0729],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.6328, -3.5996,  0.9707,  ..., -0.5327, -9.2891, -2.2285],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 3.2288e-02,  1.9608e-02,  1.4572e-03,  ...,  1.0963e-02,
          1.1978e-03,  2.4078e-02],
        [-6.5308e-03,  1.1375e-02, -1.5579e-02,  ...,  3.3736e-05,
          4.2114e-03, -1.3489e-02],
        [-5.1155e-03,  2.5787e-02,  1.6708e-02,  ..., -3.2715e-02,
          7.2327e-03, -7.8201e-03],
        ...,
        [ 3.9749e-03,  6.2981e-03, -2.7924e-02,  ...,  1.7120e-02,
          2.3163e-02, -3.7956e-03],
        [-1.8311e-03,  1.1826e-03, -1.3496e-02,  ..., -1.9547e-02,
          9.0332e-03, -1.9424e-02],
        [-2.8400e-03,  4.6616e-03, -6.6986e-03,  ..., -1.2939e-02,
         -1.6006e-02, -1.2650e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.5605, -3.4062,  0.3921,  ..., -0.5269, -9.6328, -2.3516]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 02:54:49 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for I explain, he explains
I refer, he refers
I occur, he occurs
I tell, he tells
I apply, he applies
I promote, he promotes
I ask, he asks
I follow, he
2024-07-31 02:54:49 root INFO     [order_1_approx] starting weight calculation for I ask, he asks
I apply, he applies
I promote, he promotes
I refer, he refers
I follow, he follows
I explain, he explains
I tell, he tells
I occur, he
2024-07-31 02:54:49 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-31 02:55:35 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.3735, -0.2542, -0.3635,  ...,  0.1014, -0.2410, -0.2039],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.1797, -4.1992, -1.1250,  ...,  1.0312,  1.5830, -1.9756],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0272,  0.0067,  0.0181,  ...,  0.0107, -0.0253, -0.0134],
        [ 0.0013,  0.0272,  0.0341,  ..., -0.0269,  0.0130, -0.0107],
        [-0.0029,  0.0228,  0.0342,  ..., -0.0118,  0.0062, -0.0194],
        ...,
        [ 0.0165,  0.0134,  0.0011,  ...,  0.0438, -0.0343,  0.0008],
        [ 0.0077, -0.0130, -0.0031,  ..., -0.0192,  0.0173, -0.0127],
        [ 0.0036,  0.0025,  0.0086,  ..., -0.0087, -0.0145,  0.0032]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.0352, -4.1523, -1.5000,  ...,  1.2275,  1.3730, -1.5908]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 02:55:36 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country with dhaka as its capital is known as bangladesh
The country with hanoi as its capital is known as vietnam
The country with cairo as its capital is known as egypt
The country with abuja as its capital is known as nigeria
The country with tbilisi as its capital is known as georgia
The country with paris as its capital is known as france
The country with ankara as its capital is known as turkey
The country with havana as its capital is known as
2024-07-31 02:55:36 root INFO     total operator prediction time: 1286.21182346344 seconds
2024-07-31 02:55:36 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on name - occupation
2024-07-31 02:55:36 root INFO     building operator name - occupation
2024-07-31 02:55:36 root INFO     [order_1_approx] starting weight calculation for lincoln was known for their work as a  president
mozart was known for their work as a  composer
truman was known for their work as a  president
stalin was known for their work as a  dictator
moses was known for their work as a  prophet
napoleon was known for their work as a  emperor
newton was known for their work as a  scientist
kepler was known for their work as a 
2024-07-31 02:55:37 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-31 02:57:20 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1931, -0.0446, -0.4072,  ..., -0.1080, -0.3284, -0.2534],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.0137, -3.0918, -2.2227,  ..., -1.4160, -7.1406,  0.1387],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0168, -0.0042,  0.0193,  ...,  0.0111,  0.0065,  0.0374],
        [-0.0083,  0.0403,  0.0123,  ...,  0.0200,  0.0185, -0.0046],
        [-0.0005,  0.0111,  0.0151,  ..., -0.0141, -0.0049, -0.0065],
        ...,
        [ 0.0182,  0.0038,  0.0218,  ...,  0.0247, -0.0085,  0.0195],
        [-0.0256, -0.0027,  0.0126,  ..., -0.0197, -0.0054, -0.0479],
        [ 0.0040,  0.0118, -0.0102,  ..., -0.0287, -0.0057,  0.0076]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.0576, -3.2930, -2.1133,  ..., -1.1436, -7.5195,  0.4092]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 02:57:21 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for I ask, he asks
I apply, he applies
I promote, he promotes
I refer, he refers
I follow, he follows
I explain, he explains
I tell, he tells
I occur, he
2024-07-31 02:57:21 root INFO     total operator prediction time: 1221.62837433815 seconds
2024-07-31 02:57:21 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on verb_inf - Ved
2024-07-31 02:57:21 root INFO     building operator verb_inf - Ved
2024-07-31 02:57:21 root INFO     [order_1_approx] starting weight calculation for If the present form is locate, the past form is located
If the present form is identify, the past form is identified
If the present form is hear, the past form is heard
If the present form is become, the past form is became
If the present form is develop, the past form is developed
If the present form is remain, the past form is remained
If the present form is receive, the past form is received
If the present form is decide, the past form is
2024-07-31 02:57:21 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-31 02:58:12 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1600,  0.1254,  0.0132,  ..., -0.0227, -0.1986,  0.2520],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.5156, -5.6602,  1.8721,  ..., -6.9453, -0.8262,  0.3438],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0615, -0.0088,  0.0018,  ...,  0.0007, -0.0130, -0.0164],
        [ 0.0176,  0.0692,  0.0057,  ...,  0.0119,  0.0007,  0.0124],
        [ 0.0099,  0.0286,  0.0462,  ..., -0.0049, -0.0066,  0.0028],
        ...,
        [ 0.0183,  0.0149,  0.0147,  ...,  0.0767,  0.0136,  0.0094],
        [ 0.0095,  0.0218,  0.0176,  ..., -0.0022,  0.0494, -0.0065],
        [-0.0045,  0.0266,  0.0085,  ...,  0.0045,  0.0078,  0.0599]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.6055, -5.6680,  1.3818,  ..., -6.5039, -0.5488,  0.6172]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 02:58:13 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for lincoln was known for their work as a  president
mozart was known for their work as a  composer
truman was known for their work as a  president
stalin was known for their work as a  dictator
moses was known for their work as a  prophet
napoleon was known for their work as a  emperor
newton was known for their work as a  scientist
kepler was known for their work as a 
2024-07-31 02:58:14 root INFO     [order_1_approx] starting weight calculation for stalin was known for their work as a  dictator
truman was known for their work as a  president
newton was known for their work as a  scientist
kepler was known for their work as a  mathematician
mozart was known for their work as a  composer
moses was known for their work as a  prophet
napoleon was known for their work as a  emperor
lincoln was known for their work as a 
2024-07-31 02:58:14 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-31 02:59:52 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1448,  0.1989, -0.4351,  ..., -0.1232, -0.1936, -0.0549],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.1016, -2.6504,  2.4336,  ..., -1.3457, -2.8301, -0.1094],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 2.3132e-02, -1.2772e-02,  2.6703e-05,  ..., -6.3362e-03,
          1.8587e-03,  2.1572e-03],
        [-3.8776e-03,  3.3112e-02,  1.9058e-02,  ..., -1.0475e-02,
         -6.8016e-03, -1.6830e-02],
        [ 1.3153e-02,  1.7792e-02,  5.7983e-04,  ...,  1.3039e-02,
         -2.0462e-02, -1.2634e-02],
        ...,
        [-6.3705e-03,  1.9562e-02,  5.6915e-03,  ...,  4.5990e-02,
          1.4297e-02,  6.9771e-03],
        [ 1.5617e-02, -6.7673e-03,  8.2245e-03,  ..., -1.5625e-02,
          2.0752e-02, -1.0757e-02],
        [ 3.6316e-03,  6.2637e-03, -7.8125e-03,  ...,  5.3635e-03,
         -2.8839e-02,  1.2833e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.7578, -2.6543,  2.5586,  ..., -1.1953, -2.3809,  0.1161]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 02:59:53 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If the present form is locate, the past form is located
If the present form is identify, the past form is identified
If the present form is hear, the past form is heard
If the present form is become, the past form is became
If the present form is develop, the past form is developed
If the present form is remain, the past form is remained
If the present form is receive, the past form is received
If the present form is decide, the past form is
2024-07-31 02:59:53 root INFO     [order_1_approx] starting weight calculation for If the present form is hear, the past form is heard
If the present form is decide, the past form is decided
If the present form is become, the past form is became
If the present form is locate, the past form is located
If the present form is develop, the past form is developed
If the present form is identify, the past form is identified
If the present form is remain, the past form is remained
If the present form is receive, the past form is
2024-07-31 02:59:53 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-31 03:00:50 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0686,  0.0401, -0.3411,  ...,  0.0389, -0.2274, -0.1105],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.7754, -3.3984,  2.9746,  ..., -2.4180,  1.5713, -1.5117],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0239,  0.0117, -0.0019,  ..., -0.0027, -0.0198, -0.0022],
        [ 0.0003,  0.0239,  0.0021,  ...,  0.0036, -0.0101,  0.0066],
        [ 0.0195, -0.0123,  0.0258,  ..., -0.0123, -0.0157, -0.0130],
        ...,
        [ 0.0044,  0.0116,  0.0125,  ...,  0.0461,  0.0100, -0.0022],
        [-0.0107,  0.0128, -0.0083,  ...,  0.0021,  0.0006,  0.0023],
        [ 0.0067, -0.0043, -0.0202,  ..., -0.0038, -0.0051,  0.0319]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.2402, -3.1973,  2.6367,  ..., -2.4805,  1.8906, -1.2979]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 03:00:51 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for stalin was known for their work as a  dictator
truman was known for their work as a  president
newton was known for their work as a  scientist
kepler was known for their work as a  mathematician
mozart was known for their work as a  composer
moses was known for their work as a  prophet
napoleon was known for their work as a  emperor
lincoln was known for their work as a 
2024-07-31 03:00:51 root INFO     [order_1_approx] starting weight calculation for lincoln was known for their work as a  president
newton was known for their work as a  scientist
truman was known for their work as a  president
moses was known for their work as a  prophet
napoleon was known for their work as a  emperor
kepler was known for their work as a  mathematician
mozart was known for their work as a  composer
stalin was known for their work as a 
2024-07-31 03:00:51 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-31 03:02:26 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2422,  0.0139, -0.3318,  ..., -0.2605, -0.2637, -0.0232],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.8008, -0.1382, -0.9209,  ..., -3.5508, -2.0137, -1.4336],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0493, -0.0133,  0.0410,  ..., -0.0144,  0.0009,  0.0203],
        [-0.0324,  0.0607,  0.0405,  ..., -0.0001, -0.0125, -0.0207],
        [ 0.0160, -0.0059, -0.0047,  ..., -0.0181, -0.0300,  0.0047],
        ...,
        [ 0.0029, -0.0242, -0.0021,  ...,  0.0281,  0.0060, -0.0193],
        [ 0.0112, -0.0144, -0.0112,  ..., -0.0284,  0.0296, -0.0063],
        [-0.0107, -0.0013,  0.0144,  ..., -0.0063, -0.0047,  0.0133]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.8457, -0.3145, -0.9131,  ..., -3.1445, -1.4873, -1.2139]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 03:02:27 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If the present form is hear, the past form is heard
If the present form is decide, the past form is decided
If the present form is become, the past form is became
If the present form is locate, the past form is located
If the present form is develop, the past form is developed
If the present form is identify, the past form is identified
If the present form is remain, the past form is remained
If the present form is receive, the past form is
2024-07-31 03:02:27 root INFO     [order_1_approx] starting weight calculation for If the present form is hear, the past form is heard
If the present form is decide, the past form is decided
If the present form is identify, the past form is identified
If the present form is locate, the past form is located
If the present form is develop, the past form is developed
If the present form is remain, the past form is remained
If the present form is receive, the past form is received
If the present form is become, the past form is
2024-07-31 03:02:27 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-31 03:03:31 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0481, -0.0977, -0.4580,  ...,  0.1779, -0.0851,  0.1614],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 5.1016, -4.4375,  3.0391,  ..., -1.8008, -0.2007, -2.8516],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0179, -0.0074,  0.0242,  ...,  0.0122,  0.0030, -0.0035],
        [ 0.0010,  0.0234,  0.0036,  ..., -0.0112,  0.0003, -0.0039],
        [ 0.0089, -0.0116,  0.0379,  ...,  0.0146, -0.0174,  0.0020],
        ...,
        [-0.0051,  0.0136,  0.0061,  ...,  0.0650,  0.0170, -0.0216],
        [ 0.0131,  0.0144, -0.0024,  ..., -0.0134, -0.0076,  0.0092],
        [-0.0084,  0.0118, -0.0063,  ...,  0.0034,  0.0103,  0.0409]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 5.2305, -4.0820,  3.2773,  ..., -1.5859, -0.2422, -2.2500]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 03:03:32 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for lincoln was known for their work as a  president
newton was known for their work as a  scientist
truman was known for their work as a  president
moses was known for their work as a  prophet
napoleon was known for their work as a  emperor
kepler was known for their work as a  mathematician
mozart was known for their work as a  composer
stalin was known for their work as a 
2024-07-31 03:03:32 root INFO     [order_1_approx] starting weight calculation for mozart was known for their work as a  composer
moses was known for their work as a  prophet
newton was known for their work as a  scientist
kepler was known for their work as a  mathematician
stalin was known for their work as a  dictator
truman was known for their work as a  president
lincoln was known for their work as a  president
napoleon was known for their work as a 
2024-07-31 03:03:32 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-31 03:04:58 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1584,  0.3079,  0.0260,  ..., -0.1051, -0.3164,  0.2067],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.8174,  0.1891,  1.0137,  ...,  0.3245,  0.8438, -1.1572],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0178, -0.0291,  0.0416,  ...,  0.0214,  0.0062,  0.0066],
        [-0.0081,  0.0389,  0.0033,  ...,  0.0064, -0.0171, -0.0247],
        [ 0.0132,  0.0097,  0.0215,  ...,  0.0009, -0.0285, -0.0085],
        ...,
        [ 0.0036,  0.0086,  0.0022,  ...,  0.0437,  0.0232, -0.0128],
        [ 0.0039,  0.0219,  0.0099,  ...,  0.0136,  0.0083, -0.0041],
        [-0.0052,  0.0163,  0.0280,  ..., -0.0117, -0.0130,  0.0159]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.8159, -0.1329,  0.2500,  ...,  0.9014,  0.6094, -1.0547]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 03:04:59 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If the present form is hear, the past form is heard
If the present form is decide, the past form is decided
If the present form is identify, the past form is identified
If the present form is locate, the past form is located
If the present form is develop, the past form is developed
If the present form is remain, the past form is remained
If the present form is receive, the past form is received
If the present form is become, the past form is
2024-07-31 03:04:59 root INFO     [order_1_approx] starting weight calculation for If the present form is locate, the past form is located
If the present form is receive, the past form is received
If the present form is become, the past form is became
If the present form is decide, the past form is decided
If the present form is identify, the past form is identified
If the present form is hear, the past form is heard
If the present form is develop, the past form is developed
If the present form is remain, the past form is
2024-07-31 03:04:59 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-31 03:06:07 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1907, -0.0438, -0.1599,  ...,  0.1146,  0.0134,  0.0460],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.2065, -5.3516,  0.5767,  ...,  0.1262,  1.4199, -0.1514],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0482,  0.0066,  0.0053,  ...,  0.0080, -0.0126,  0.0159],
        [-0.0074,  0.0168,  0.0021,  ..., -0.0018, -0.0118, -0.0095],
        [ 0.0312, -0.0055,  0.0242,  ..., -0.0265, -0.0123,  0.0098],
        ...,
        [-0.0096,  0.0149,  0.0045,  ...,  0.0394,  0.0018,  0.0074],
        [-0.0053,  0.0046, -0.0060,  ...,  0.0043,  0.0110,  0.0026],
        [-0.0056, -0.0154, -0.0146,  ..., -0.0049,  0.0094,  0.0128]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.2698, -5.3047,  0.3530,  ..., -0.0375,  1.3721,  0.0699]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 03:06:08 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for mozart was known for their work as a  composer
moses was known for their work as a  prophet
newton was known for their work as a  scientist
kepler was known for their work as a  mathematician
stalin was known for their work as a  dictator
truman was known for their work as a  president
lincoln was known for their work as a  president
napoleon was known for their work as a 
2024-07-31 03:06:08 root INFO     [order_1_approx] starting weight calculation for truman was known for their work as a  president
napoleon was known for their work as a  emperor
kepler was known for their work as a  mathematician
mozart was known for their work as a  composer
lincoln was known for their work as a  president
newton was known for their work as a  scientist
stalin was known for their work as a  dictator
moses was known for their work as a 
2024-07-31 03:06:08 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-31 03:07:30 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0475,  0.0506, -0.0694,  ..., -0.4006, -0.0552,  0.2291],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.4380, -0.7363,  0.4199,  ..., -2.4531, -0.6157, -1.5566],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0565, -0.0268,  0.0123,  ...,  0.0004,  0.0256,  0.0070],
        [-0.0407,  0.0311,  0.0059,  ...,  0.0020,  0.0080, -0.0204],
        [-0.0210,  0.0300,  0.0508,  ..., -0.0200, -0.0376, -0.0064],
        ...,
        [-0.0062,  0.0162,  0.0070,  ...,  0.0334,  0.0159,  0.0021],
        [ 0.0076, -0.0140,  0.0106,  ...,  0.0027,  0.0162, -0.0092],
        [-0.0218,  0.0113, -0.0044,  ..., -0.0055, -0.0053,  0.0039]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.4019, -0.8369,  0.7812,  ..., -1.8613, -0.2019, -1.4404]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 03:07:31 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If the present form is locate, the past form is located
If the present form is receive, the past form is received
If the present form is become, the past form is became
If the present form is decide, the past form is decided
If the present form is identify, the past form is identified
If the present form is hear, the past form is heard
If the present form is develop, the past form is developed
If the present form is remain, the past form is
2024-07-31 03:07:32 root INFO     [order_1_approx] starting weight calculation for If the present form is become, the past form is became
If the present form is locate, the past form is located
If the present form is identify, the past form is identified
If the present form is remain, the past form is remained
If the present form is hear, the past form is heard
If the present form is receive, the past form is received
If the present form is decide, the past form is decided
If the present form is develop, the past form is
2024-07-31 03:07:32 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-31 03:08:51 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0806,  0.2367, -0.2832,  ..., -0.0818, -0.1866,  0.3130],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.2539, -4.5625,  0.4321,  ..., -5.8828,  3.1719, -1.1406],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0461,  0.0164,  0.0138,  ...,  0.0098, -0.0153,  0.0125],
        [ 0.0228,  0.0097,  0.0095,  ..., -0.0370, -0.0026, -0.0043],
        [ 0.0332, -0.0204,  0.0362,  ..., -0.0189,  0.0056,  0.0169],
        ...,
        [ 0.0274,  0.0370,  0.0381,  ...,  0.0338,  0.0087, -0.0005],
        [ 0.0152,  0.0042, -0.0119,  ..., -0.0005,  0.0163,  0.0018],
        [-0.0161, -0.0084,  0.0040,  ..., -0.0098, -0.0215,  0.0170]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.8647, -3.9316,  0.6484,  ..., -5.7266,  3.1836, -1.0908]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 03:08:52 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for truman was known for their work as a  president
napoleon was known for their work as a  emperor
kepler was known for their work as a  mathematician
mozart was known for their work as a  composer
lincoln was known for their work as a  president
newton was known for their work as a  scientist
stalin was known for their work as a  dictator
moses was known for their work as a 
2024-07-31 03:08:52 root INFO     [order_1_approx] starting weight calculation for mozart was known for their work as a  composer
lincoln was known for their work as a  president
kepler was known for their work as a  mathematician
moses was known for their work as a  prophet
stalin was known for their work as a  dictator
napoleon was known for their work as a  emperor
newton was known for their work as a  scientist
truman was known for their work as a 
2024-07-31 03:08:52 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-31 03:09:59 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0610, -0.1453, -0.0183,  ..., -0.1772, -0.2588,  0.1741],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.8486, -1.0566,  3.3047,  ..., -1.4736, -1.8291, -1.7012],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 2.0355e-02, -1.5839e-02,  5.1689e-03,  ..., -7.2746e-03,
         -4.6844e-03,  3.6713e-02],
        [-1.9970e-03,  6.8726e-02,  1.3206e-02,  ...,  1.9058e-02,
         -6.5155e-03, -2.5314e-02],
        [ 1.3374e-02,  9.9335e-03,  9.1858e-03,  ..., -3.2616e-03,
         -2.4124e-02,  5.4626e-03],
        ...,
        [ 1.5610e-02,  8.3694e-03, -5.2643e-03,  ...,  3.4882e-02,
         -6.9618e-05,  1.8906e-02],
        [ 2.1393e-02, -1.1963e-02, -4.3068e-03,  ...,  2.1378e-02,
          2.0294e-02, -1.4847e-02],
        [-1.2894e-03, -8.5144e-03,  1.0147e-02,  ...,  9.9792e-03,
         -2.3087e-02,  1.4439e-03]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.6104, -1.2812,  3.0566,  ..., -1.2148, -1.8330, -1.9912]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 03:10:00 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If the present form is become, the past form is became
If the present form is locate, the past form is located
If the present form is identify, the past form is identified
If the present form is remain, the past form is remained
If the present form is hear, the past form is heard
If the present form is receive, the past form is received
If the present form is decide, the past form is decided
If the present form is develop, the past form is
2024-07-31 03:10:00 root INFO     [order_1_approx] starting weight calculation for If the present form is remain, the past form is remained
If the present form is receive, the past form is received
If the present form is identify, the past form is identified
If the present form is develop, the past form is developed
If the present form is decide, the past form is decided
If the present form is hear, the past form is heard
If the present form is become, the past form is became
If the present form is locate, the past form is
2024-07-31 03:10:00 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-31 03:11:32 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2783,  0.1354, -0.4253,  ...,  0.1650, -0.5054,  0.0875],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 6.1836, -2.3281,  3.4531,  ..., -3.1953,  1.1953, -0.0474],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0321,  0.0268,  0.0110,  ...,  0.0182, -0.0181, -0.0060],
        [-0.0230,  0.0158,  0.0054,  ..., -0.0166,  0.0024,  0.0280],
        [-0.0100,  0.0198,  0.0315,  ...,  0.0068, -0.0311, -0.0029],
        ...,
        [ 0.0052,  0.0117,  0.0016,  ...,  0.0380,  0.0094,  0.0264],
        [ 0.0169,  0.0231, -0.0105,  ...,  0.0163,  0.0250,  0.0020],
        [ 0.0226, -0.0028, -0.0165,  ..., -0.0065, -0.0072,  0.0633]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 6.1641, -2.7031,  3.2559,  ..., -3.2773,  1.5645,  0.1039]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 03:11:33 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for mozart was known for their work as a  composer
lincoln was known for their work as a  president
kepler was known for their work as a  mathematician
moses was known for their work as a  prophet
stalin was known for their work as a  dictator
napoleon was known for their work as a  emperor
newton was known for their work as a  scientist
truman was known for their work as a 
2024-07-31 03:11:33 root INFO     [order_1_approx] starting weight calculation for stalin was known for their work as a  dictator
lincoln was known for their work as a  president
truman was known for their work as a  president
mozart was known for their work as a  composer
napoleon was known for their work as a  emperor
moses was known for their work as a  prophet
kepler was known for their work as a  mathematician
newton was known for their work as a 
2024-07-31 03:11:33 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-31 03:12:31 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0634,  0.1802, -0.7783,  ...,  0.1398, -0.3394, -0.0955],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.0293, -1.2070, -1.1182,  ..., -2.1914, -1.8887, -2.1582],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 5.0018e-02, -8.7128e-03, -5.9557e-04,  ..., -5.4932e-03,
         -6.0272e-04,  1.5297e-02],
        [-8.2397e-03,  5.7770e-02,  1.0056e-02,  ..., -6.7291e-03,
         -9.4223e-03, -9.9258e-03],
        [ 1.3237e-02,  1.2032e-02,  2.3315e-02,  ..., -6.7444e-03,
         -1.5205e-02, -7.1049e-05],
        ...,
        [-4.6120e-03,  2.0203e-02, -8.1940e-03,  ...,  4.8645e-02,
          6.0616e-03,  1.1368e-02],
        [ 7.0953e-03, -3.4180e-02, -1.1673e-02,  ..., -3.1128e-03,
          1.0910e-02, -7.3967e-03],
        [ 9.9182e-04, -2.2980e-02, -8.4534e-03,  ..., -2.5543e-02,
         -2.3911e-02,  4.6570e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.2197, -0.9111, -1.2783,  ..., -2.0234, -1.5840, -1.8125]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 03:12:32 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If the present form is remain, the past form is remained
If the present form is receive, the past form is received
If the present form is identify, the past form is identified
If the present form is develop, the past form is developed
If the present form is decide, the past form is decided
If the present form is hear, the past form is heard
If the present form is become, the past form is became
If the present form is locate, the past form is
2024-07-31 03:12:32 root INFO     [order_1_approx] starting weight calculation for If the present form is receive, the past form is received
If the present form is decide, the past form is decided
If the present form is hear, the past form is heard
If the present form is locate, the past form is located
If the present form is become, the past form is became
If the present form is develop, the past form is developed
If the present form is remain, the past form is remained
If the present form is identify, the past form is
2024-07-31 03:12:32 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-31 03:14:12 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1248, -0.1130, -0.0606,  ..., -0.1737, -0.0540,  0.2480],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.8828, -4.0469,  1.3906,  ..., -7.4961,  0.5410, -1.5498],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0181,  0.0044,  0.0127,  ..., -0.0083, -0.0038, -0.0090],
        [-0.0141,  0.0284, -0.0134,  ...,  0.0009,  0.0035, -0.0085],
        [ 0.0070, -0.0086,  0.0598,  ..., -0.0063, -0.0005, -0.0044],
        ...,
        [ 0.0054,  0.0311,  0.0028,  ...,  0.0529,  0.0231,  0.0028],
        [ 0.0110, -0.0044,  0.0112,  ...,  0.0175,  0.0196,  0.0193],
        [-0.0074,  0.0068, -0.0039,  ...,  0.0204,  0.0056,  0.0400]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.7188, -4.3750,  1.0869,  ..., -7.3711,  0.5820, -1.2021]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 03:14:13 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for stalin was known for their work as a  dictator
lincoln was known for their work as a  president
truman was known for their work as a  president
mozart was known for their work as a  composer
napoleon was known for their work as a  emperor
moses was known for their work as a  prophet
kepler was known for their work as a  mathematician
newton was known for their work as a 
2024-07-31 03:14:13 root INFO     [order_1_approx] starting weight calculation for kepler was known for their work as a  mathematician
napoleon was known for their work as a  emperor
stalin was known for their work as a  dictator
lincoln was known for their work as a  president
newton was known for their work as a  scientist
moses was known for their work as a  prophet
truman was known for their work as a  president
mozart was known for their work as a 
2024-07-31 03:14:14 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-31 03:15:03 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2759, -0.0577, -0.4189,  ...,  0.2959, -0.3333, -0.0471],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.5391,  0.6055,  1.9424,  ..., -1.4424, -1.8965, -0.2148],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0409, -0.0173,  0.0028,  ..., -0.0024, -0.0073,  0.0102],
        [-0.0221,  0.0408,  0.0166,  ...,  0.0070, -0.0116, -0.0101],
        [ 0.0112,  0.0030,  0.0010,  ..., -0.0016, -0.0155, -0.0030],
        ...,
        [-0.0038,  0.0027, -0.0052,  ...,  0.0273,  0.0146,  0.0097],
        [-0.0012,  0.0132,  0.0030,  ..., -0.0009,  0.0041, -0.0087],
        [-0.0140,  0.0092,  0.0219,  ..., -0.0123, -0.0298,  0.0105]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.5674,  0.3140,  1.7393,  ..., -1.3711, -1.6133, -0.3201]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 03:15:04 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If the present form is receive, the past form is received
If the present form is decide, the past form is decided
If the present form is hear, the past form is heard
If the present form is locate, the past form is located
If the present form is become, the past form is became
If the present form is develop, the past form is developed
If the present form is remain, the past form is remained
If the present form is identify, the past form is
2024-07-31 03:15:04 root INFO     [order_1_approx] starting weight calculation for If the present form is become, the past form is became
If the present form is remain, the past form is remained
If the present form is develop, the past form is developed
If the present form is receive, the past form is received
If the present form is identify, the past form is identified
If the present form is decide, the past form is decided
If the present form is locate, the past form is located
If the present form is hear, the past form is
2024-07-31 03:15:04 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-31 03:16:58 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.3560,  0.2529, -0.2886,  ..., -0.0549, -0.1938, -0.0568],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.0039, -4.9688,  1.8164,  ..., -3.5449,  1.8350, -0.5996],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0319, -0.0078,  0.0174,  ..., -0.0005, -0.0170,  0.0158],
        [-0.0041,  0.0069,  0.0079,  ..., -0.0036,  0.0010, -0.0051],
        [ 0.0062,  0.0003,  0.0396,  ...,  0.0077, -0.0066,  0.0045],
        ...,
        [ 0.0102,  0.0114,  0.0061,  ...,  0.0513,  0.0195,  0.0122],
        [ 0.0111,  0.0052,  0.0133,  ...,  0.0031,  0.0107,  0.0041],
        [-0.0048, -0.0050,  0.0012,  ..., -0.0078, -0.0133,  0.0359]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.2227, -4.8008,  1.9072,  ..., -3.5254,  2.1543, -0.7236]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 03:16:58 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for kepler was known for their work as a  mathematician
napoleon was known for their work as a  emperor
stalin was known for their work as a  dictator
lincoln was known for their work as a  president
newton was known for their work as a  scientist
moses was known for their work as a  prophet
truman was known for their work as a  president
mozart was known for their work as a 
2024-07-31 03:16:58 root INFO     total operator prediction time: 1282.261748790741 seconds
2024-07-31 03:16:58 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on male - female
2024-07-31 03:16:58 root INFO     building operator male - female
2024-07-31 03:16:59 root INFO     [order_1_approx] starting weight calculation for A female buck is known as a doe
A female king is known as a queen
A female uncle is known as a aunt
A female brother is known as a sister
A female batman is known as a batwoman
A female god is known as a goddess
A female manager is known as a manageress
A female heir is known as a
2024-07-31 03:16:59 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-31 03:17:36 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0495, -0.0387,  0.0021,  ...,  0.3408, -0.1633,  0.1285],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.8516, -1.3447,  1.1338,  ..., -0.1750, -3.8027, -3.0703],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0648, -0.0129,  0.0192,  ...,  0.0116,  0.0279,  0.0239],
        [ 0.0022,  0.0716,  0.0107,  ...,  0.0114, -0.0155, -0.0286],
        [ 0.0055,  0.0022,  0.0369,  ..., -0.0072, -0.0170,  0.0140],
        ...,
        [ 0.0069, -0.0017,  0.0004,  ...,  0.0285,  0.0055, -0.0103],
        [ 0.0017, -0.0187, -0.0145,  ..., -0.0091,  0.0051,  0.0059],
        [-0.0078,  0.0166,  0.0110,  ...,  0.0161,  0.0122,  0.0358]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.0361, -1.1738,  0.8516,  ...,  0.2104, -3.1504, -3.0527]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 03:17:37 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If the present form is become, the past form is became
If the present form is remain, the past form is remained
If the present form is develop, the past form is developed
If the present form is receive, the past form is received
If the present form is identify, the past form is identified
If the present form is decide, the past form is decided
If the present form is locate, the past form is located
If the present form is hear, the past form is
2024-07-31 03:17:37 root INFO     total operator prediction time: 1216.060879945755 seconds
2024-07-31 03:17:37 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on verb_Ving - Ved
2024-07-31 03:17:37 root INFO     building operator verb_Ving - Ved
2024-07-31 03:17:37 root INFO     [order_1_approx] starting weight calculation for After something is locating, it has located
After something is performing, it has performed
After something is teaching, it has taught
After something is describing, it has described
After something is understanding, it has understood
After something is considering, it has considered
After something is becoming, it has became
After something is telling, it has
2024-07-31 03:17:37 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-31 03:19:38 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2905,  0.0701, -0.1564,  ...,  0.0854, -0.3237, -0.0813],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.1211, -2.8438,  2.4258,  ..., -2.8398, -5.0234,  1.6670],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 3.5065e-02, -1.7242e-02,  5.3253e-03,  ...,  6.8436e-03,
          7.8354e-03, -1.5497e-04],
        [ 6.0425e-03,  2.1805e-02,  3.1567e-03,  ...,  1.9882e-02,
          3.7842e-02, -1.3786e-02],
        [-4.0771e-02,  4.1313e-03,  4.4708e-02,  ..., -1.5808e-02,
          1.0483e-02, -1.5182e-02],
        ...,
        [ 2.7847e-02,  2.8267e-03,  4.0855e-03,  ...,  3.0289e-02,
          2.1133e-02, -3.7518e-03],
        [ 2.2812e-02,  2.1271e-02, -2.9564e-03,  ..., -8.5354e-05,
          4.4891e-02,  9.3842e-03],
        [ 9.3765e-03,  1.6235e-02,  1.8740e-03,  ..., -8.4381e-03,
          2.6566e-02,  3.2288e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.2949, -2.9531,  2.3516,  ..., -2.6309, -5.0508,  1.8516]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 03:19:39 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A female buck is known as a doe
A female king is known as a queen
A female uncle is known as a aunt
A female brother is known as a sister
A female batman is known as a batwoman
A female god is known as a goddess
A female manager is known as a manageress
A female heir is known as a
2024-07-31 03:19:39 root INFO     [order_1_approx] starting weight calculation for A female brother is known as a sister
A female god is known as a goddess
A female batman is known as a batwoman
A female heir is known as a heiress
A female uncle is known as a aunt
A female manager is known as a manageress
A female buck is known as a doe
A female king is known as a
2024-07-31 03:19:39 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-31 03:20:11 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0600, -0.0324, -0.0324,  ...,  0.2080, -0.1268, -0.3813],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.6504, -0.3323,  2.6758,  ...,  1.7314, -4.3594, -2.2480],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0267,  0.0039,  0.0085,  ...,  0.0152, -0.0096,  0.0442],
        [-0.0257,  0.0550,  0.0087,  ...,  0.0088, -0.0136, -0.0140],
        [-0.0058, -0.0464,  0.0373,  ...,  0.0084, -0.0148, -0.0108],
        ...,
        [ 0.0142,  0.0376, -0.0098,  ...,  0.0241,  0.0051,  0.0198],
        [-0.0148, -0.0070, -0.0159,  ..., -0.0146,  0.0339,  0.0025],
        [-0.0027,  0.0364,  0.0198,  ..., -0.0069, -0.0077,  0.0244]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.5898, -0.0718,  2.9492,  ...,  1.5801, -3.9883, -2.6543]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 03:20:12 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for After something is locating, it has located
After something is performing, it has performed
After something is teaching, it has taught
After something is describing, it has described
After something is understanding, it has understood
After something is considering, it has considered
After something is becoming, it has became
After something is telling, it has
2024-07-31 03:20:12 root INFO     [order_1_approx] starting weight calculation for After something is performing, it has performed
After something is considering, it has considered
After something is teaching, it has taught
After something is understanding, it has understood
After something is becoming, it has became
After something is locating, it has located
After something is telling, it has told
After something is describing, it has
2024-07-31 03:20:12 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-31 03:22:20 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4570,  0.5249, -0.0826,  ...,  0.0684, -0.0977,  0.1101],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.6006, -3.4707,  0.8281,  ..., -3.3008, -3.5059, -1.3955],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0532,  0.0020,  0.0401,  ..., -0.0248, -0.0142,  0.0100],
        [-0.0049,  0.0308, -0.0068,  ...,  0.0173,  0.0276,  0.0082],
        [-0.0015,  0.0060,  0.0236,  ..., -0.0085, -0.0219,  0.0164],
        ...,
        [-0.0149,  0.0082, -0.0331,  ...,  0.0403, -0.0003, -0.0042],
        [ 0.0228, -0.0161,  0.0225,  ..., -0.0386, -0.0033, -0.0043],
        [ 0.0224, -0.0108,  0.0018,  ..., -0.0177, -0.0002,  0.0331]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.6841, -3.8945,  0.6157,  ..., -3.1309, -3.6152, -1.5527]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 03:22:21 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A female brother is known as a sister
A female god is known as a goddess
A female batman is known as a batwoman
A female heir is known as a heiress
A female uncle is known as a aunt
A female manager is known as a manageress
A female buck is known as a doe
A female king is known as a
2024-07-31 03:22:22 root INFO     [order_1_approx] starting weight calculation for A female king is known as a queen
A female brother is known as a sister
A female god is known as a goddess
A female buck is known as a doe
A female manager is known as a manageress
A female heir is known as a heiress
A female batman is known as a batwoman
A female uncle is known as a
2024-07-31 03:22:22 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-31 03:22:44 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1091, -0.1924, -0.0062,  ...,  0.0864,  0.1959, -0.3740],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.1465, -1.3203,  3.9414,  ...,  0.0806, -0.9873, -2.2070],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0183, -0.0141, -0.0236,  ...,  0.0179, -0.0209,  0.0142],
        [-0.0220,  0.0362,  0.0238,  ...,  0.0221, -0.0030, -0.0206],
        [ 0.0051, -0.0290,  0.0050,  ...,  0.0023, -0.0165, -0.0135],
        ...,
        [ 0.0080,  0.0294, -0.0034,  ...,  0.0232,  0.0051,  0.0061],
        [ 0.0244,  0.0033, -0.0114,  ..., -0.0158,  0.0170,  0.0111],
        [ 0.0001,  0.0106, -0.0135,  ..., -0.0054, -0.0183,  0.0082]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.9824, -1.1816,  3.7871,  ...,  0.5098, -1.0332, -2.2207]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 03:22:45 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for After something is performing, it has performed
After something is considering, it has considered
After something is teaching, it has taught
After something is understanding, it has understood
After something is becoming, it has became
After something is locating, it has located
After something is telling, it has told
After something is describing, it has
2024-07-31 03:22:45 root INFO     [order_1_approx] starting weight calculation for After something is telling, it has told
After something is describing, it has described
After something is becoming, it has became
After something is performing, it has performed
After something is understanding, it has understood
After something is locating, it has located
After something is considering, it has considered
After something is teaching, it has
2024-07-31 03:22:45 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-31 03:25:02 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0413,  0.3948,  0.0281,  ..., -0.0541, -0.3752, -0.1270],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.4766, -1.2930, -1.6084,  ...,  0.3262, -4.8633, -1.4951],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0123, -0.0150,  0.0288,  ...,  0.0025, -0.0199,  0.0193],
        [ 0.0433,  0.0310, -0.0017,  ...,  0.0472,  0.0009,  0.0076],
        [ 0.0354, -0.0131,  0.0525,  ..., -0.0241, -0.0056,  0.0023],
        ...,
        [ 0.0128, -0.0045,  0.0039,  ...,  0.0046,  0.0118, -0.0035],
        [-0.0641, -0.0441,  0.0421,  ..., -0.0094, -0.0097,  0.0101],
        [ 0.0370,  0.0086, -0.0112,  ...,  0.0373,  0.0322,  0.0225]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.1465, -1.3613, -1.6992,  ..., -0.1609, -4.8633, -1.1025]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 03:25:03 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A female king is known as a queen
A female brother is known as a sister
A female god is known as a goddess
A female buck is known as a doe
A female manager is known as a manageress
A female heir is known as a heiress
A female batman is known as a batwoman
A female uncle is known as a
2024-07-31 03:25:03 root INFO     [order_1_approx] starting weight calculation for A female uncle is known as a aunt
A female heir is known as a heiress
A female batman is known as a batwoman
A female buck is known as a doe
A female king is known as a queen
A female manager is known as a manageress
A female brother is known as a sister
A female god is known as a
2024-07-31 03:25:03 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-31 03:25:17 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1541,  0.2324, -0.0234,  ...,  0.1098, -0.1658, -0.0049],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.5957, -0.0946,  3.2461,  ...,  0.1904, -3.7461, -4.8672],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0208,  0.0058,  0.0160,  ...,  0.0011, -0.0136,  0.0159],
        [-0.0275,  0.0431, -0.0036,  ..., -0.0044, -0.0112, -0.0147],
        [-0.0017,  0.0005,  0.0154,  ...,  0.0072, -0.0003,  0.0012],
        ...,
        [ 0.0115,  0.0204, -0.0100,  ...,  0.0106,  0.0181,  0.0016],
        [ 0.0186, -0.0051, -0.0102,  ...,  0.0027,  0.0202, -0.0036],
        [ 0.0052,  0.0058,  0.0147,  ..., -0.0043, -0.0080,  0.0012]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.7676, -0.1220,  3.3125,  ...,  0.2620, -3.8164, -5.0859]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 03:25:17 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for After something is telling, it has told
After something is describing, it has described
After something is becoming, it has became
After something is performing, it has performed
After something is understanding, it has understood
After something is locating, it has located
After something is considering, it has considered
After something is teaching, it has
2024-07-31 03:25:18 root INFO     [order_1_approx] starting weight calculation for After something is becoming, it has became
After something is considering, it has considered
After something is telling, it has told
After something is describing, it has described
After something is teaching, it has taught
After something is understanding, it has understood
After something is performing, it has performed
After something is locating, it has
2024-07-31 03:25:18 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-31 03:27:39 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1708,  0.4761, -0.0578,  ...,  0.1609, -0.4409, -0.3640],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.9492, -6.2734,  0.2427,  ..., -1.0430, -1.0469, -0.2834],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0166, -0.0115,  0.0224,  ..., -0.0017, -0.0039, -0.0039],
        [-0.0045,  0.0295, -0.0043,  ...,  0.0067,  0.0153, -0.0101],
        [-0.0132, -0.0019,  0.0512,  ...,  0.0101, -0.0032,  0.0013],
        ...,
        [-0.0074,  0.0064, -0.0126,  ...,  0.0321, -0.0074, -0.0125],
        [ 0.0076,  0.0026,  0.0062,  ..., -0.0103, -0.0065, -0.0026],
        [ 0.0028,  0.0109, -0.0045,  ..., -0.0096,  0.0005,  0.0219]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.6445, -6.0508, -0.1575,  ..., -0.6631, -1.3223, -0.1370]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 03:27:39 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A female uncle is known as a aunt
A female heir is known as a heiress
A female batman is known as a batwoman
A female buck is known as a doe
A female king is known as a queen
A female manager is known as a manageress
A female brother is known as a sister
A female god is known as a
2024-07-31 03:27:40 root INFO     [order_1_approx] starting weight calculation for A female heir is known as a heiress
A female king is known as a queen
A female batman is known as a batwoman
A female uncle is known as a aunt
A female manager is known as a manageress
A female brother is known as a sister
A female god is known as a goddess
A female buck is known as a
2024-07-31 03:27:40 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-31 03:27:51 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2078,  0.2130, -0.5566,  ...,  0.2401, -0.2139, -0.2115],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.5430, -1.6396, -1.7510,  ..., -1.9209, -3.2090, -3.5059],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0351, -0.0126, -0.0107,  ...,  0.0169, -0.0067,  0.0182],
        [-0.0084,  0.0389,  0.0068,  ..., -0.0067,  0.0007, -0.0081],
        [ 0.0285, -0.0275,  0.0076,  ..., -0.0065,  0.0014, -0.0094],
        ...,
        [-0.0019,  0.0251, -0.0035,  ...,  0.0018, -0.0003,  0.0234],
        [ 0.0186, -0.0133, -0.0038,  ..., -0.0092,  0.0018, -0.0057],
        [-0.0047,  0.0214,  0.0141,  ...,  0.0071, -0.0259,  0.0105]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.0000, -1.7910, -1.4160,  ..., -1.7090, -3.0117, -3.6836]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 03:27:52 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for After something is becoming, it has became
After something is considering, it has considered
After something is telling, it has told
After something is describing, it has described
After something is teaching, it has taught
After something is understanding, it has understood
After something is performing, it has performed
After something is locating, it has
2024-07-31 03:27:52 root INFO     [order_1_approx] starting weight calculation for After something is describing, it has described
After something is locating, it has located
After something is teaching, it has taught
After something is considering, it has considered
After something is becoming, it has became
After something is telling, it has told
After something is performing, it has performed
After something is understanding, it has
2024-07-31 03:27:52 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-31 03:30:19 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4163,  0.2428,  0.1895,  ...,  0.0297, -0.3335,  0.3005],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.6016, -3.1074, -1.5586,  ...,  2.1113, -5.6836,  1.0059],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0391,  0.0167,  0.0156,  ...,  0.0012,  0.0023, -0.0163],
        [-0.0225,  0.0569, -0.0007,  ...,  0.0301,  0.0473,  0.0181],
        [-0.0026, -0.0160,  0.0221,  ..., -0.0122,  0.0025, -0.0203],
        ...,
        [-0.0142, -0.0210,  0.0146,  ...,  0.0567,  0.0296, -0.0174],
        [-0.0019,  0.0014,  0.0048,  ..., -0.0258, -0.0120, -0.0210],
        [ 0.0022, -0.0193, -0.0225,  ..., -0.0219, -0.0024,  0.0198]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.7539, -3.3711, -1.3105,  ...,  1.9658, -5.6836,  1.4775]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 03:30:20 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A female heir is known as a heiress
A female king is known as a queen
A female batman is known as a batwoman
A female uncle is known as a aunt
A female manager is known as a manageress
A female brother is known as a sister
A female god is known as a goddess
A female buck is known as a
2024-07-31 03:30:20 root INFO     [order_1_approx] starting weight calculation for A female god is known as a goddess
A female heir is known as a heiress
A female batman is known as a batwoman
A female king is known as a queen
A female buck is known as a doe
A female uncle is known as a aunt
A female brother is known as a sister
A female manager is known as a
2024-07-31 03:30:20 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-31 03:30:26 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.3098,  0.3792, -0.2081,  ...,  0.3647, -0.0356, -0.2197],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.2383,  1.2305,  1.3242,  ..., -0.9209, -1.9863,  0.7676],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0073, -0.0265,  0.0015,  ..., -0.0123, -0.0009,  0.0137],
        [-0.0119,  0.0651,  0.0109,  ...,  0.0236, -0.0283, -0.0113],
        [ 0.0192, -0.0352,  0.0172,  ..., -0.0059,  0.0088, -0.0190],
        ...,
        [ 0.0056,  0.0400, -0.0061,  ...,  0.0291, -0.0024,  0.0040],
        [ 0.0101, -0.0194,  0.0145,  ..., -0.0259,  0.0283, -0.0155],
        [-0.0089,  0.0410,  0.0092,  ...,  0.0050, -0.0177, -0.0021]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.2383,  1.1484,  1.3828,  ..., -0.8823, -1.3555,  0.4141]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 03:30:27 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for After something is describing, it has described
After something is locating, it has located
After something is teaching, it has taught
After something is considering, it has considered
After something is becoming, it has became
After something is telling, it has told
After something is performing, it has performed
After something is understanding, it has
2024-07-31 03:30:27 root INFO     [order_1_approx] starting weight calculation for After something is understanding, it has understood
After something is locating, it has located
After something is becoming, it has became
After something is considering, it has considered
After something is telling, it has told
After something is teaching, it has taught
After something is describing, it has described
After something is performing, it has
2024-07-31 03:30:27 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-31 03:32:59 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0829,  0.3682, -0.1074,  ...,  0.4846, -0.4421, -0.3777],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 5.2500, -4.3477,  1.0781,  ...,  1.6768, -0.4854, -3.7734],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0454, -0.0111, -0.0315,  ...,  0.0287,  0.0041,  0.0118],
        [ 0.0008,  0.0343, -0.0059,  ...,  0.0233,  0.0007, -0.0162],
        [-0.0164,  0.0096,  0.0607,  ..., -0.0278, -0.0356,  0.0105],
        ...,
        [ 0.0096,  0.0100, -0.0022,  ...,  0.0360,  0.0216, -0.0210],
        [ 0.0103,  0.0173,  0.0265,  ..., -0.0085,  0.0159, -0.0132],
        [ 0.0245, -0.0226, -0.0197,  ...,  0.0077,  0.0220,  0.0148]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.9492, -4.2305,  0.8086,  ...,  1.6055, -0.5781, -3.4883]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 03:32:59 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2034,  0.0944, -0.1704,  ..., -0.0463, -0.0287, -0.0246],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.8926, -1.5879,  3.7637,  ..., -1.5459, -2.7168, -1.1426],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 1.0399e-02, -4.8294e-03,  6.7596e-03,  ...,  1.6968e-02,
         -1.9302e-02,  1.8295e-02],
        [-3.5919e-02,  5.1727e-02,  1.6342e-02,  ...,  9.6512e-03,
          2.2690e-02, -3.0853e-02],
        [-4.3640e-03, -4.2267e-03,  7.1487e-03,  ..., -3.1891e-03,
          1.1703e-02,  2.9968e-02],
        ...,
        [-1.1780e-02,  1.2077e-02, -2.2064e-02,  ...,  8.9951e-03,
          7.7438e-03,  7.2784e-03],
        [ 3.5828e-02,  1.7424e-03,  8.1635e-03,  ...,  8.0566e-03,
          1.3245e-02, -3.6469e-03],
        [ 2.8248e-03,  2.2583e-02, -4.0283e-03,  ...,  6.1035e-05,
         -6.5079e-03, -9.6893e-03]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.0059, -1.3936,  4.3516,  ..., -1.1895, -2.4434, -1.3496]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 03:33:01 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for After something is understanding, it has understood
After something is locating, it has located
After something is becoming, it has became
After something is considering, it has considered
After something is telling, it has told
After something is teaching, it has taught
After something is describing, it has described
After something is performing, it has
2024-07-31 03:33:01 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A female god is known as a goddess
A female heir is known as a heiress
A female batman is known as a batwoman
A female king is known as a queen
A female buck is known as a doe
A female uncle is known as a aunt
A female brother is known as a sister
A female manager is known as a
2024-07-31 03:33:01 root INFO     [order_1_approx] starting weight calculation for After something is teaching, it has taught
After something is describing, it has described
After something is locating, it has located
After something is telling, it has told
After something is performing, it has performed
After something is understanding, it has understood
After something is becoming, it has became
After something is considering, it has
2024-07-31 03:33:01 root INFO     [order_1_approx] starting weight calculation for A female brother is known as a sister
A female manager is known as a manageress
A female god is known as a goddess
A female king is known as a queen
A female uncle is known as a aunt
A female heir is known as a heiress
A female buck is known as a doe
A female batman is known as a
2024-07-31 03:33:01 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-31 03:33:01 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-31 03:35:34 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1267,  0.1866, -0.2317,  ...,  0.0249,  0.1543, -0.2415],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.5449, -2.1660,  3.2207,  ..., -2.0645, -1.8555, -1.1855],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0496,  0.0079, -0.0111,  ...,  0.0366,  0.0087,  0.0196],
        [-0.0261,  0.0213,  0.0250,  ...,  0.0049, -0.0177, -0.0157],
        [-0.0200, -0.0286,  0.0418,  ..., -0.0011, -0.0037, -0.0022],
        ...,
        [ 0.0086,  0.0215,  0.0116,  ...,  0.0145,  0.0095,  0.0264],
        [ 0.0082,  0.0121,  0.0201,  ..., -0.0197,  0.0169,  0.0038],
        [ 0.0122,  0.0244,  0.0215,  ...,  0.0017, -0.0142,  0.0021]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.8672, -1.9795,  2.9883,  ..., -1.5703, -2.1719, -1.4814]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 03:35:35 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for After something is teaching, it has taught
After something is describing, it has described
After something is locating, it has located
After something is telling, it has told
After something is performing, it has performed
After something is understanding, it has understood
After something is becoming, it has became
After something is considering, it has
2024-07-31 03:35:35 root INFO     [order_1_approx] starting weight calculation for After something is teaching, it has taught
After something is performing, it has performed
After something is locating, it has located
After something is considering, it has considered
After something is telling, it has told
After something is understanding, it has understood
After something is describing, it has described
After something is becoming, it has
2024-07-31 03:35:35 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-31 03:35:40 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1709,  0.3274, -0.0916,  ..., -0.1221, -0.3037,  0.1492],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.1797, -5.1016,  2.5371,  ..., -1.0918, -1.3213, -0.6792],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0146, -0.0204,  0.0286,  ...,  0.0079, -0.0175,  0.0126],
        [ 0.0195,  0.0255, -0.0097,  ..., -0.0042,  0.0175,  0.0048],
        [-0.0016,  0.0179, -0.0119,  ..., -0.0022, -0.0006, -0.0125],
        ...,
        [ 0.0173,  0.0040, -0.0145,  ...,  0.0293, -0.0034,  0.0008],
        [-0.0165,  0.0029,  0.0102,  ...,  0.0148, -0.0138,  0.0202],
        [ 0.0136, -0.0110, -0.0080,  ..., -0.0040,  0.0285,  0.0093]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.1602, -5.0664,  2.5762,  ..., -1.0273, -1.3555, -0.7632]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 03:35:41 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A female brother is known as a sister
A female manager is known as a manageress
A female god is known as a goddess
A female king is known as a queen
A female uncle is known as a aunt
A female heir is known as a heiress
A female buck is known as a doe
A female batman is known as a
2024-07-31 03:35:41 root INFO     [order_1_approx] starting weight calculation for A female batman is known as a batwoman
A female buck is known as a doe
A female heir is known as a heiress
A female manager is known as a manageress
A female king is known as a queen
A female god is known as a goddess
A female uncle is known as a aunt
A female brother is known as a
2024-07-31 03:35:41 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-31 03:38:09 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1257,  0.2979,  0.1417,  ...,  0.0988, -0.0762, -0.1467],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.2500,  0.4014,  2.6992,  ..., -0.3994,  0.2847, -1.8086],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0131,  0.0166,  0.0121,  ...,  0.0257,  0.0238,  0.0135],
        [-0.0188,  0.0438,  0.0126,  ...,  0.0166, -0.0236, -0.0107],
        [-0.0048, -0.0320,  0.0279,  ...,  0.0035,  0.0059,  0.0160],
        ...,
        [-0.0106,  0.0230, -0.0363,  ...,  0.0257,  0.0092,  0.0157],
        [ 0.0365,  0.0180, -0.0094,  ...,  0.0034,  0.0316, -0.0100],
        [-0.0069,  0.0132,  0.0239,  ...,  0.0008, -0.0015, -0.0056]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.6094,  0.2542,  3.1680,  ..., -0.2324, -0.2632, -1.8125]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 03:38:10 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for After something is teaching, it has taught
After something is performing, it has performed
After something is locating, it has located
After something is considering, it has considered
After something is telling, it has told
After something is understanding, it has understood
After something is describing, it has described
After something is becoming, it has
2024-07-31 03:38:10 root INFO     total operator prediction time: 1232.9043610095978 seconds
2024-07-31 03:38:10 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on Ving - verb_inf
2024-07-31 03:38:10 root INFO     building operator Ving - verb_inf
2024-07-31 03:38:10 root INFO     [order_1_approx] starting weight calculation for existing is the active form of exist
containing is the active form of contain
applying is the active form of apply
remaining is the active form of remain
appearing is the active form of appear
receiving is the active form of receive
preventing is the active form of prevent
promoting is the active form of
2024-07-31 03:38:10 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-31 03:38:17 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3958,  0.5439,  0.1869,  ...,  0.1556, -0.3838,  0.0318],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.6719, -3.0176, -3.1875,  ...,  1.1455, -0.1562, -1.7930],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0040, -0.0030,  0.0388,  ...,  0.0293, -0.0120,  0.0223],
        [ 0.0374,  0.0248, -0.0006,  ...,  0.0031,  0.0067,  0.0048],
        [ 0.0146, -0.0245,  0.0639,  ..., -0.0193, -0.0102,  0.0032],
        ...,
        [ 0.0077,  0.0106, -0.0243,  ...,  0.0410,  0.0212, -0.0114],
        [-0.0594,  0.0262,  0.0531,  ...,  0.0333, -0.0089,  0.0035],
        [ 0.0583, -0.0501, -0.0436,  ..., -0.0345,  0.0178, -0.0103]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.7871, -2.2891, -3.5332,  ...,  1.7910, -1.8301, -0.8115]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 03:38:18 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A female batman is known as a batwoman
A female buck is known as a doe
A female heir is known as a heiress
A female manager is known as a manageress
A female king is known as a queen
A female god is known as a goddess
A female uncle is known as a aunt
A female brother is known as a
2024-07-31 03:38:18 root INFO     total operator prediction time: 1279.3791937828064 seconds
2024-07-31 03:38:18 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on animal - shelter
2024-07-31 03:38:18 root INFO     building operator animal - shelter
2024-07-31 03:38:18 root INFO     [order_1_approx] starting weight calculation for The place hippopotamus lives in is called river
The place termite lives in is called hill
The place mouse lives in is called nest
The place bee lives in is called hive
The place hornet lives in is called nest
The place whale lives in is called sea
The place crow lives in is called nest
The place chimpanzee lives in is called
2024-07-31 03:38:18 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-31 03:40:43 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1471,  0.2703, -0.1581,  ...,  0.0052,  0.4326,  0.0924],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.1758, -3.5312, -0.4790,  ...,  2.0430, -2.4922, -1.6475],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0417, -0.0068,  0.0073,  ...,  0.0047, -0.0325,  0.0019],
        [-0.0037,  0.0478, -0.0146,  ...,  0.0040, -0.0016, -0.0087],
        [ 0.0073, -0.0002,  0.0244,  ..., -0.0076, -0.0057,  0.0084],
        ...,
        [ 0.0129,  0.0090, -0.0002,  ...,  0.0331, -0.0011,  0.0086],
        [ 0.0124, -0.0040, -0.0219,  ...,  0.0163,  0.0267, -0.0048],
        [ 0.0071,  0.0079, -0.0296,  ..., -0.0039, -0.0135,  0.0237]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.9883, -3.4883, -0.6440,  ...,  1.9590, -2.1152, -1.6650]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 03:40:44 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for existing is the active form of exist
containing is the active form of contain
applying is the active form of apply
remaining is the active form of remain
appearing is the active form of appear
receiving is the active form of receive
preventing is the active form of prevent
promoting is the active form of
2024-07-31 03:40:44 root INFO     [order_1_approx] starting weight calculation for receiving is the active form of receive
promoting is the active form of promote
existing is the active form of exist
applying is the active form of apply
remaining is the active form of remain
appearing is the active form of appear
preventing is the active form of prevent
containing is the active form of
2024-07-31 03:40:44 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-31 03:40:53 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1166, -0.2188, -0.2145,  ..., -0.1229, -0.5566,  0.0703],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.3945, -8.7109,  3.8105,  ..., -1.0898, -2.1270, -0.3125],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0047, -0.0079,  0.0077,  ..., -0.0022, -0.0016, -0.0095],
        [-0.0092,  0.0179, -0.0035,  ...,  0.0005, -0.0117,  0.0060],
        [-0.0050, -0.0058,  0.0036,  ..., -0.0064,  0.0068,  0.0015],
        ...,
        [-0.0042,  0.0111, -0.0041,  ...,  0.0168, -0.0022,  0.0041],
        [ 0.0058,  0.0021, -0.0038,  ..., -0.0076,  0.0064, -0.0032],
        [-0.0020, -0.0046, -0.0012,  ..., -0.0049, -0.0024,  0.0126]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.4258, -8.7109,  3.8047,  ..., -1.0820, -2.1875, -0.5039]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 03:40:54 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The place hippopotamus lives in is called river
The place termite lives in is called hill
The place mouse lives in is called nest
The place bee lives in is called hive
The place hornet lives in is called nest
The place whale lives in is called sea
The place crow lives in is called nest
The place chimpanzee lives in is called
2024-07-31 03:40:54 root INFO     [order_1_approx] starting weight calculation for The place termite lives in is called hill
The place bee lives in is called hive
The place hippopotamus lives in is called river
The place whale lives in is called sea
The place chimpanzee lives in is called grove
The place hornet lives in is called nest
The place mouse lives in is called nest
The place crow lives in is called
2024-07-31 03:40:54 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-31 03:43:17 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0330, -0.4792, -0.4702,  ...,  0.1048,  0.0492, -0.1326],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.3896, -1.6797,  2.1328,  ..., -0.0518, -1.2461, -2.0820],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0561, -0.0012,  0.0051,  ...,  0.0222, -0.0241,  0.0166],
        [ 0.0004,  0.0551, -0.0002,  ..., -0.0097, -0.0133, -0.0073],
        [ 0.0081,  0.0024,  0.0371,  ..., -0.0132,  0.0085, -0.0094],
        ...,
        [ 0.0061,  0.0051, -0.0051,  ...,  0.0287, -0.0068, -0.0014],
        [-0.0018, -0.0042, -0.0090,  ..., -0.0061,  0.0289,  0.0047],
        [-0.0041,  0.0043, -0.0122,  ..., -0.0137, -0.0070,  0.0327]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.4746, -1.8398,  2.0625,  ..., -0.2639, -1.1006, -2.1426]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 03:43:18 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for receiving is the active form of receive
promoting is the active form of promote
existing is the active form of exist
applying is the active form of apply
remaining is the active form of remain
appearing is the active form of appear
preventing is the active form of prevent
containing is the active form of
2024-07-31 03:43:19 root INFO     [order_1_approx] starting weight calculation for applying is the active form of apply
receiving is the active form of receive
containing is the active form of contain
remaining is the active form of remain
appearing is the active form of appear
existing is the active form of exist
promoting is the active form of promote
preventing is the active form of
2024-07-31 03:43:19 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-31 03:43:26 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1981, -0.1782, -0.1035,  ...,  0.1812, -0.1184, -0.0432],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.4453, -7.3672,  2.2109,  ..., -0.9424, -0.0522, -2.5977],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0668,  0.0119,  0.0012,  ..., -0.0211, -0.0030, -0.0039],
        [ 0.0464,  0.0569,  0.0189,  ...,  0.0066,  0.0126,  0.0194],
        [-0.0226,  0.0224,  0.0503,  ...,  0.0135, -0.0172, -0.0106],
        ...,
        [ 0.0002, -0.0032,  0.0313,  ...,  0.1074,  0.0215,  0.0214],
        [ 0.0015, -0.0057, -0.0181,  ...,  0.0269,  0.0359,  0.0026],
        [-0.0319, -0.0203, -0.0176,  ..., -0.0178, -0.0332,  0.0464]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.2422, -7.7969,  2.1426,  ..., -1.3037, -0.6201, -1.9043]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 03:43:27 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The place termite lives in is called hill
The place bee lives in is called hive
The place hippopotamus lives in is called river
The place whale lives in is called sea
The place chimpanzee lives in is called grove
The place hornet lives in is called nest
The place mouse lives in is called nest
The place crow lives in is called
2024-07-31 03:43:27 root INFO     [order_1_approx] starting weight calculation for The place whale lives in is called sea
The place crow lives in is called nest
The place hornet lives in is called nest
The place chimpanzee lives in is called grove
The place termite lives in is called hill
The place hippopotamus lives in is called river
The place mouse lives in is called nest
The place bee lives in is called
2024-07-31 03:43:27 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-31 03:45:52 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.3833,  0.0499, -0.1964,  ..., -0.3135,  0.3518, -0.0284],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.2129, -2.7500, -1.0957,  ...,  1.8613, -0.5781, -2.6211],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0153, -0.0089,  0.0059,  ...,  0.0055, -0.0146,  0.0067],
        [-0.0016,  0.0266, -0.0014,  ..., -0.0021,  0.0080, -0.0024],
        [ 0.0063, -0.0082,  0.0006,  ..., -0.0124, -0.0124,  0.0009],
        ...,
        [ 0.0136,  0.0051, -0.0003,  ...,  0.0036,  0.0072,  0.0034],
        [ 0.0109,  0.0054, -0.0085,  ...,  0.0034,  0.0254,  0.0024],
        [-0.0030,  0.0055, -0.0116,  ..., -0.0015,  0.0073,  0.0004]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.2549, -2.9746, -1.0449,  ...,  1.9834, -0.7266, -2.6914]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 03:45:53 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for applying is the active form of apply
receiving is the active form of receive
containing is the active form of contain
remaining is the active form of remain
appearing is the active form of appear
existing is the active form of exist
promoting is the active form of promote
preventing is the active form of
2024-07-31 03:45:53 root INFO     [order_1_approx] starting weight calculation for promoting is the active form of promote
receiving is the active form of receive
appearing is the active form of appear
existing is the active form of exist
applying is the active form of apply
preventing is the active form of prevent
containing is the active form of contain
remaining is the active form of
2024-07-31 03:45:53 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-31 03:45:59 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2278, -0.2178,  0.1820,  ...,  0.0887,  0.0831, -0.2440],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.3281, -7.1328,  1.9248,  ..., -3.7070,  0.4216, -1.2139],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0233, -0.0055,  0.0152,  ..., -0.0078, -0.0045, -0.0083],
        [ 0.0045,  0.0248,  0.0030,  ...,  0.0096, -0.0018, -0.0077],
        [ 0.0091,  0.0291,  0.0378,  ...,  0.0211, -0.0127,  0.0005],
        ...,
        [-0.0088, -0.0023, -0.0079,  ...,  0.0421,  0.0177,  0.0167],
        [-0.0048,  0.0205,  0.0133,  ...,  0.0279,  0.0129, -0.0006],
        [-0.0072, -0.0101,  0.0093,  ..., -0.0135, -0.0240,  0.0247]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.6797, -6.8555,  1.7773,  ..., -3.5820,  0.3433, -1.0723]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 03:46:00 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The place whale lives in is called sea
The place crow lives in is called nest
The place hornet lives in is called nest
The place chimpanzee lives in is called grove
The place termite lives in is called hill
The place hippopotamus lives in is called river
The place mouse lives in is called nest
The place bee lives in is called
2024-07-31 03:46:00 root INFO     [order_1_approx] starting weight calculation for The place hippopotamus lives in is called river
The place crow lives in is called nest
The place termite lives in is called hill
The place bee lives in is called hive
The place whale lives in is called sea
The place mouse lives in is called nest
The place chimpanzee lives in is called grove
The place hornet lives in is called
2024-07-31 03:46:00 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-31 03:48:27 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0533,  0.1078, -0.2163,  ..., -0.4231,  0.1371,  0.2373],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.0049, -3.4980, -0.2788,  ..., -0.8315, -0.2979, -2.9883],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0339, -0.0137,  0.0109,  ...,  0.0068,  0.0031,  0.0183],
        [-0.0063,  0.0375,  0.0079,  ...,  0.0107,  0.0082,  0.0036],
        [ 0.0006, -0.0053,  0.0275,  ...,  0.0020, -0.0003, -0.0069],
        ...,
        [ 0.0128, -0.0024, -0.0106,  ...,  0.0242,  0.0002, -0.0030],
        [ 0.0048,  0.0035, -0.0061,  ...,  0.0063,  0.0251,  0.0021],
        [-0.0035,  0.0080, -0.0119,  ..., -0.0150, -0.0115,  0.0286]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.0775, -3.4180, -0.0599,  ..., -0.7388, -0.3818, -2.8965]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 03:48:28 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for promoting is the active form of promote
receiving is the active form of receive
appearing is the active form of appear
existing is the active form of exist
applying is the active form of apply
preventing is the active form of prevent
containing is the active form of contain
remaining is the active form of
2024-07-31 03:48:28 root INFO     [order_1_approx] starting weight calculation for appearing is the active form of appear
containing is the active form of contain
promoting is the active form of promote
preventing is the active form of prevent
remaining is the active form of remain
existing is the active form of exist
applying is the active form of apply
receiving is the active form of
2024-07-31 03:48:28 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-31 03:48:36 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0604,  0.0557,  0.3179,  ...,  0.4143,  0.0986, -0.1500],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.8320, -5.6250,  2.7266,  ..., -2.5742, -0.1069, -1.7598],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0438, -0.0036, -0.0245,  ...,  0.0115, -0.0211, -0.0114],
        [ 0.0009,  0.0658,  0.0228,  ...,  0.0429,  0.0150,  0.0062],
        [-0.0173,  0.0420,  0.0482,  ...,  0.0078, -0.0167,  0.0016],
        ...,
        [-0.0069, -0.0276,  0.0242,  ...,  0.0631,  0.0300,  0.0169],
        [-0.0057,  0.0124, -0.0159,  ...,  0.0198, -0.0240,  0.0135],
        [-0.0191, -0.0098, -0.0061,  ...,  0.0076, -0.0267,  0.0290]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.1270, -5.4922,  2.8652,  ..., -2.2266, -0.5605, -1.6182]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 03:48:37 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The place hippopotamus lives in is called river
The place crow lives in is called nest
The place termite lives in is called hill
The place bee lives in is called hive
The place whale lives in is called sea
The place mouse lives in is called nest
The place chimpanzee lives in is called grove
The place hornet lives in is called
2024-07-31 03:48:37 root INFO     [order_1_approx] starting weight calculation for The place termite lives in is called hill
The place hippopotamus lives in is called river
The place hornet lives in is called nest
The place crow lives in is called nest
The place chimpanzee lives in is called grove
The place bee lives in is called hive
The place mouse lives in is called nest
The place whale lives in is called
2024-07-31 03:48:37 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-31 03:50:59 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0398,  0.2944, -0.1638,  ..., -0.1373,  0.2700,  0.1193],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.5996, -2.7363, -1.7715,  ...,  0.1187, -0.6240, -3.5508],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0499, -0.0065,  0.0244,  ...,  0.0094, -0.0070,  0.0112],
        [-0.0078,  0.0468, -0.0070,  ..., -0.0104, -0.0032,  0.0015],
        [ 0.0089,  0.0037,  0.0135,  ..., -0.0174, -0.0004, -0.0057],
        ...,
        [ 0.0111, -0.0107, -0.0099,  ...,  0.0400, -0.0051,  0.0038],
        [ 0.0057,  0.0018, -0.0077,  ..., -0.0101,  0.0453, -0.0078],
        [-0.0003,  0.0153, -0.0168,  ..., -0.0102, -0.0153,  0.0253]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.2415, -2.9629, -1.8877,  ...,  0.2656, -0.5186, -3.4727]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 03:51:00 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for appearing is the active form of appear
containing is the active form of contain
promoting is the active form of promote
preventing is the active form of prevent
remaining is the active form of remain
existing is the active form of exist
applying is the active form of apply
receiving is the active form of
2024-07-31 03:51:00 root INFO     [order_1_approx] starting weight calculation for applying is the active form of apply
containing is the active form of contain
promoting is the active form of promote
receiving is the active form of receive
appearing is the active form of appear
remaining is the active form of remain
preventing is the active form of prevent
existing is the active form of
2024-07-31 03:51:00 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-31 03:51:15 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2620, -0.1909, -0.1214,  ..., -0.3000,  0.0419,  0.0826],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.7012, -5.9219,  0.1460,  ..., -1.0840, -0.8379,  0.2305],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0366, -0.0040, -0.0038,  ...,  0.0188, -0.0139, -0.0039],
        [ 0.0047,  0.0257,  0.0086,  ...,  0.0562, -0.0128, -0.0071],
        [-0.0231,  0.0208,  0.0310,  ..., -0.0231,  0.0069, -0.0151],
        ...,
        [-0.0111,  0.0075,  0.0061,  ...,  0.0493, -0.0010, -0.0066],
        [ 0.0016,  0.0141, -0.0094,  ..., -0.0043, -0.0079,  0.0062],
        [-0.0079, -0.0271,  0.0102,  ...,  0.0091, -0.0161,  0.0367]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.9316, -5.7031,  0.3601,  ..., -1.3887, -0.9375,  0.0352]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 03:51:16 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The place termite lives in is called hill
The place hippopotamus lives in is called river
The place hornet lives in is called nest
The place crow lives in is called nest
The place chimpanzee lives in is called grove
The place bee lives in is called hive
The place mouse lives in is called nest
The place whale lives in is called
2024-07-31 03:51:16 root INFO     [order_1_approx] starting weight calculation for The place whale lives in is called sea
The place hornet lives in is called nest
The place hippopotamus lives in is called river
The place termite lives in is called hill
The place crow lives in is called nest
The place bee lives in is called hive
The place chimpanzee lives in is called grove
The place mouse lives in is called
2024-07-31 03:51:16 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-31 03:53:33 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0588, -0.0190, -0.6084,  ..., -0.1868, -0.1689, -0.0781],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.4180, -2.5820,  0.7852,  ...,  0.7476, -1.8525, -1.6045],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 2.9556e-02, -1.6907e-02, -4.0054e-05,  ...,  2.7294e-03,
         -6.9714e-04,  9.0637e-03],
        [ 8.6517e-03,  4.7211e-02, -7.1220e-03,  ..., -7.8049e-03,
          1.3161e-02, -1.1311e-03],
        [ 1.2115e-02, -4.1580e-03,  1.7853e-02,  ...,  3.3951e-03,
          7.0724e-03, -2.0370e-02],
        ...,
        [ 5.9128e-03,  7.7858e-03, -1.6693e-02,  ...,  2.7283e-02,
         -7.7248e-03,  1.9608e-03],
        [ 5.4207e-03,  2.1095e-03, -8.7357e-04,  ..., -4.4250e-04,
          3.7476e-02,  7.6981e-03],
        [-8.4839e-03,  1.3565e-02, -7.5150e-03,  ..., -1.4992e-03,
         -1.6098e-03,  1.6830e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.3398, -2.5449,  1.0732,  ...,  0.8540, -1.9697, -1.7686]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 03:53:34 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for applying is the active form of apply
containing is the active form of contain
promoting is the active form of promote
receiving is the active form of receive
appearing is the active form of appear
remaining is the active form of remain
preventing is the active form of prevent
existing is the active form of
2024-07-31 03:53:34 root INFO     [order_1_approx] starting weight calculation for appearing is the active form of appear
containing is the active form of contain
existing is the active form of exist
promoting is the active form of promote
preventing is the active form of prevent
remaining is the active form of remain
receiving is the active form of receive
applying is the active form of
2024-07-31 03:53:34 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-31 03:53:54 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1238, -0.2162,  0.0099,  ...,  0.0027, -0.0269, -0.0537],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.1455, -6.0391,  2.7734,  ..., -0.5664, -1.4102,  0.9365],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0479, -0.0112,  0.0327,  ...,  0.0037, -0.0208, -0.0062],
        [ 0.0025,  0.0386,  0.0081,  ..., -0.0012, -0.0100, -0.0301],
        [-0.0383,  0.0190,  0.0456,  ..., -0.0463,  0.0267,  0.0180],
        ...,
        [-0.0108, -0.0098,  0.0077,  ...,  0.0395,  0.0160, -0.0059],
        [ 0.0091,  0.0263, -0.0079,  ...,  0.0214,  0.0243,  0.0019],
        [-0.0263, -0.0026,  0.0239,  ..., -0.0078, -0.0212,  0.0316]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.7246, -5.7344,  2.4922,  ..., -0.6323, -1.2725,  0.9272]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 03:53:55 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The place whale lives in is called sea
The place hornet lives in is called nest
The place hippopotamus lives in is called river
The place termite lives in is called hill
The place crow lives in is called nest
The place bee lives in is called hive
The place chimpanzee lives in is called grove
The place mouse lives in is called
2024-07-31 03:53:56 root INFO     [order_1_approx] starting weight calculation for The place bee lives in is called hive
The place chimpanzee lives in is called grove
The place crow lives in is called nest
The place mouse lives in is called nest
The place termite lives in is called hill
The place hornet lives in is called nest
The place whale lives in is called sea
The place hippopotamus lives in is called
2024-07-31 03:53:56 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-31 03:56:08 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0790, -0.1804,  0.0554,  ...,  0.1031,  0.0166,  0.1793],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.6211, -3.3945, -0.7695,  ...,  2.5859, -2.6367, -2.5684],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0894, -0.0330,  0.0344,  ...,  0.0185, -0.0205,  0.0123],
        [-0.0094,  0.0792,  0.0097,  ...,  0.0120, -0.0246,  0.0033],
        [ 0.0216, -0.0115,  0.0201,  ..., -0.0035,  0.0215,  0.0073],
        ...,
        [-0.0080,  0.0195, -0.0115,  ...,  0.0556,  0.0029, -0.0016],
        [-0.0014, -0.0179, -0.0027,  ..., -0.0330,  0.0646,  0.0021],
        [-0.0014,  0.0127, -0.0188,  ..., -0.0317, -0.0137,  0.0444]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.1404, -4.1406, -0.5459,  ...,  2.4805, -2.0781, -2.7461]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 03:56:09 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for appearing is the active form of appear
containing is the active form of contain
existing is the active form of exist
promoting is the active form of promote
preventing is the active form of prevent
remaining is the active form of remain
receiving is the active form of receive
applying is the active form of
2024-07-31 03:56:10 root INFO     [order_1_approx] starting weight calculation for preventing is the active form of prevent
existing is the active form of exist
applying is the active form of apply
containing is the active form of contain
remaining is the active form of remain
promoting is the active form of promote
receiving is the active form of receive
appearing is the active form of
2024-07-31 03:56:10 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-31 03:56:32 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2080, -0.2651,  0.1849,  ...,  0.0327, -0.2957, -0.1101],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.6094, -6.1953,  1.1602,  ..., -2.9062,  1.4639, -0.6826],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0002, -0.0083,  0.0098,  ...,  0.0047,  0.0022, -0.0082],
        [-0.0032,  0.0228,  0.0061,  ..., -0.0123, -0.0193,  0.0093],
        [-0.0152,  0.0060,  0.0091,  ...,  0.0023,  0.0042, -0.0021],
        ...,
        [-0.0005,  0.0070, -0.0010,  ...,  0.0116,  0.0028,  0.0040],
        [-0.0002, -0.0018,  0.0041,  ...,  0.0101,  0.0202, -0.0049],
        [-0.0043, -0.0006,  0.0005,  ..., -0.0076, -0.0044,  0.0163]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.6348, -6.0156,  1.1445,  ..., -2.9238,  1.3701, -0.5317]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 03:56:33 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The place bee lives in is called hive
The place chimpanzee lives in is called grove
The place crow lives in is called nest
The place mouse lives in is called nest
The place termite lives in is called hill
The place hornet lives in is called nest
The place whale lives in is called sea
The place hippopotamus lives in is called
2024-07-31 03:56:33 root INFO     [order_1_approx] starting weight calculation for The place crow lives in is called nest
The place hippopotamus lives in is called river
The place whale lives in is called sea
The place bee lives in is called hive
The place mouse lives in is called nest
The place hornet lives in is called nest
The place chimpanzee lives in is called grove
The place termite lives in is called
2024-07-31 03:56:34 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-31 03:58:40 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1334,  0.1025, -0.2177,  ...,  0.0095,  0.0457, -0.1052],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.7852, -3.6094,  0.1365,  ...,  3.5684, -2.8066, -1.8994],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 4.3274e-02, -7.4768e-03,  1.4191e-02,  ..., -2.0065e-03,
         -3.2310e-03,  1.4771e-02],
        [-4.3488e-03,  4.4037e-02, -1.0429e-02,  ...,  9.8038e-04,
         -6.5613e-03, -8.5373e-03],
        [ 1.1322e-02,  5.7144e-03,  9.6970e-03,  ...,  7.7972e-03,
         -7.8506e-03, -1.2833e-02],
        ...,
        [-1.1497e-02,  5.8975e-03, -2.0462e-02,  ...,  2.6611e-02,
          4.1389e-03,  1.4481e-02],
        [-1.7004e-03,  3.6602e-03,  7.8201e-05,  ...,  5.5542e-03,
          3.0670e-02, -8.6975e-04],
        [-1.3943e-03,  2.2949e-02, -2.4529e-03,  ..., -3.8395e-03,
         -5.2338e-03,  2.0294e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.9106, -3.8125,  0.1919,  ...,  3.5176, -2.9160, -2.2637]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 03:58:42 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for preventing is the active form of prevent
existing is the active form of exist
applying is the active form of apply
containing is the active form of contain
remaining is the active form of remain
promoting is the active form of promote
receiving is the active form of receive
appearing is the active form of
2024-07-31 03:58:42 root INFO     total operator prediction time: 1232.4643375873566 seconds
2024-07-31 03:58:42 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on noun - plural_irreg
2024-07-31 03:58:42 root INFO     building operator noun - plural_irreg
2024-07-31 03:58:43 root INFO     [order_1_approx] starting weight calculation for The plural form of species is species
The plural form of majority is majorities
The plural form of life is lives
The plural form of energy is energies
The plural form of formula is formulae
The plural form of woman is women
The plural form of success is successes
The plural form of facility is
2024-07-31 03:58:43 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-31 03:59:11 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0694, -0.2583,  0.0177,  ...,  0.2202, -0.1398,  0.0416],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.4219, -6.3984,  1.9570,  ..., -3.2422,  1.5283, -1.8594],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 6.2073e-02,  6.1951e-03,  1.3458e-02,  ...,  3.9459e-02,
         -6.9809e-03, -2.3327e-03],
        [ 1.6754e-02,  3.5126e-02, -1.9913e-03,  ...,  1.5450e-02,
         -3.6774e-03, -1.6891e-02],
        [-3.3325e-02,  5.4199e-02,  5.0171e-02,  ..., -6.9962e-03,
         -2.2415e-02,  7.9346e-03],
        ...,
        [ 1.7424e-03,  8.2092e-03,  1.0498e-02,  ...,  4.6661e-02,
          2.6764e-02,  1.5671e-02],
        [-1.2711e-02,  1.7990e-02,  2.8782e-03,  ...,  2.2354e-02,
          3.3936e-02,  3.2257e-02],
        [-1.3542e-04, -1.2772e-02, -9.4604e-03,  ..., -2.0981e-05,
         -3.7567e-02,  5.6580e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.9531, -6.1445,  1.7227,  ..., -3.0723,  1.5693, -1.6816]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 03:59:12 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The place crow lives in is called nest
The place hippopotamus lives in is called river
The place whale lives in is called sea
The place bee lives in is called hive
The place mouse lives in is called nest
The place hornet lives in is called nest
The place chimpanzee lives in is called grove
The place termite lives in is called
2024-07-31 03:59:12 root INFO     total operator prediction time: 1254.4406824111938 seconds
2024-07-31 03:59:12 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on country - language
2024-07-31 03:59:12 root INFO     building operator country - language
2024-07-31 03:59:13 root INFO     [order_1_approx] starting weight calculation for The country of jamaica primarily speaks the language of english
The country of bangladesh primarily speaks the language of bengali
The country of jordan primarily speaks the language of arabic
The country of ethiopia primarily speaks the language of amharic
The country of iraq primarily speaks the language of arabic
The country of colombia primarily speaks the language of spanish
The country of guam primarily speaks the language of english
The country of norway primarily speaks the language of
2024-07-31 03:59:13 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-31 04:01:14 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0757,  0.1298, -0.2764,  ..., -0.3403, -0.0675,  0.2898],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.8984, -2.7578,  3.7930,  ...,  0.3469, -1.2402, -1.8867],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0652, -0.0112, -0.0028,  ...,  0.0100,  0.0006,  0.0346],
        [-0.0074,  0.0656, -0.0104,  ...,  0.0370,  0.0008, -0.0133],
        [-0.0033,  0.0045,  0.0245,  ...,  0.0043, -0.0291, -0.0031],
        ...,
        [-0.0282,  0.0174, -0.0467,  ...,  0.0490,  0.0029,  0.0049],
        [-0.0184,  0.0103,  0.0069,  ...,  0.0377,  0.0499, -0.0146],
        [-0.0075, -0.0085, -0.0093,  ...,  0.0211,  0.0160,  0.0429]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.3672, -2.6836,  3.7266,  ...,  0.0520, -1.1943, -1.9287]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 04:01:15 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of species is species
The plural form of majority is majorities
The plural form of life is lives
The plural form of energy is energies
The plural form of formula is formulae
The plural form of woman is women
The plural form of success is successes
The plural form of facility is
2024-07-31 04:01:15 root INFO     [order_1_approx] starting weight calculation for The plural form of facility is facilities
The plural form of energy is energies
The plural form of life is lives
The plural form of woman is women
The plural form of majority is majorities
The plural form of success is successes
The plural form of formula is formulae
The plural form of species is
2024-07-31 04:01:15 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-31 04:01:57 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2603, -0.2854, -0.0961,  ...,  0.2915,  0.1600,  0.2539],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.9844, -2.1641, -2.0352,  ..., -1.8525, -0.2959, -1.1865],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0285, -0.0052,  0.0022,  ..., -0.0139,  0.0232, -0.0120],
        [ 0.0066,  0.0173,  0.0052,  ...,  0.0052, -0.0033,  0.0011],
        [-0.0121,  0.0092,  0.0334,  ..., -0.0018, -0.0039,  0.0104],
        ...,
        [-0.0147,  0.0077,  0.0003,  ...,  0.0355, -0.0023,  0.0076],
        [ 0.0170,  0.0120, -0.0013,  ...,  0.0098,  0.0423, -0.0062],
        [-0.0141, -0.0140, -0.0144,  ..., -0.0007, -0.0205,  0.0059]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.3623, -2.0820, -1.7578,  ..., -1.8008, -0.2666, -1.3828]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 04:01:58 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country of jamaica primarily speaks the language of english
The country of bangladesh primarily speaks the language of bengali
The country of jordan primarily speaks the language of arabic
The country of ethiopia primarily speaks the language of amharic
The country of iraq primarily speaks the language of arabic
The country of colombia primarily speaks the language of spanish
The country of guam primarily speaks the language of english
The country of norway primarily speaks the language of
2024-07-31 04:01:58 root INFO     [order_1_approx] starting weight calculation for The country of norway primarily speaks the language of norwegian
The country of iraq primarily speaks the language of arabic
The country of bangladesh primarily speaks the language of bengali
The country of guam primarily speaks the language of english
The country of ethiopia primarily speaks the language of amharic
The country of jordan primarily speaks the language of arabic
The country of jamaica primarily speaks the language of english
The country of colombia primarily speaks the language of
2024-07-31 04:01:58 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-31 04:03:43 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2495, -0.0378, -0.3279,  ..., -0.0925, -0.0545,  0.2478],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.8315, -3.4707,  0.2388,  ...,  0.0098, -3.7266, -3.0840],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0587, -0.0197,  0.0071,  ...,  0.0084,  0.0019,  0.0018],
        [ 0.0068,  0.0459, -0.0073,  ...,  0.0034,  0.0053, -0.0260],
        [-0.0054, -0.0493,  0.0005,  ..., -0.0014, -0.0126,  0.0130],
        ...,
        [-0.0148,  0.0009, -0.0108,  ...,  0.0240,  0.0492,  0.0019],
        [-0.0162,  0.0176, -0.0074,  ...,  0.0169,  0.0127, -0.0060],
        [ 0.0173, -0.0007, -0.0321,  ..., -0.0194, -0.0124,  0.0259]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.5938, -3.4414,  0.5527,  ...,  0.4719, -4.0273, -2.8984]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 04:03:44 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of facility is facilities
The plural form of energy is energies
The plural form of life is lives
The plural form of woman is women
The plural form of majority is majorities
The plural form of success is successes
The plural form of formula is formulae
The plural form of species is
2024-07-31 04:03:44 root INFO     [order_1_approx] starting weight calculation for The plural form of formula is formulae
The plural form of facility is facilities
The plural form of success is successes
The plural form of energy is energies
The plural form of species is species
The plural form of woman is women
The plural form of majority is majorities
The plural form of life is
2024-07-31 04:03:44 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-31 04:04:38 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2544, -0.0248, -0.4182,  ...,  0.1523, -0.2050, -0.1377],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.7998, -1.8418,  1.7979,  ..., -0.2478,  0.6055, -2.8164],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0255, -0.0073,  0.0028,  ..., -0.0027, -0.0065, -0.0115],
        [ 0.0030,  0.0177,  0.0084,  ..., -0.0031, -0.0134, -0.0067],
        [-0.0240,  0.0122,  0.0133,  ..., -0.0031,  0.0107, -0.0009],
        ...,
        [-0.0150, -0.0002, -0.0078,  ...,  0.0121,  0.0193,  0.0011],
        [ 0.0059,  0.0009,  0.0019,  ...,  0.0080,  0.0094, -0.0071],
        [-0.0034,  0.0023, -0.0034,  ..., -0.0016, -0.0057,  0.0044]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.0928, -1.8818,  1.3652,  ..., -0.4556,  0.7412, -2.8125]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 04:04:39 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country of norway primarily speaks the language of norwegian
The country of iraq primarily speaks the language of arabic
The country of bangladesh primarily speaks the language of bengali
The country of guam primarily speaks the language of english
The country of ethiopia primarily speaks the language of amharic
The country of jordan primarily speaks the language of arabic
The country of jamaica primarily speaks the language of english
The country of colombia primarily speaks the language of
2024-07-31 04:04:39 root INFO     [order_1_approx] starting weight calculation for The country of guam primarily speaks the language of english
The country of bangladesh primarily speaks the language of bengali
The country of jamaica primarily speaks the language of english
The country of colombia primarily speaks the language of spanish
The country of iraq primarily speaks the language of arabic
The country of norway primarily speaks the language of norwegian
The country of ethiopia primarily speaks the language of amharic
The country of jordan primarily speaks the language of
2024-07-31 04:04:39 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-31 04:06:17 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4001,  0.1769, -0.2308,  ..., -0.1882, -0.2917,  0.1392],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.1895, -2.7461,  0.1052,  ..., -1.7764, -3.1777, -2.2148],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 4.8401e-02,  1.0750e-02,  2.6535e-02,  ...,  2.2034e-02,
          8.9111e-03,  1.6052e-02],
        [ 2.8324e-03,  5.7983e-02,  6.0234e-03,  ...,  2.7130e-02,
         -3.3051e-02, -1.1215e-02],
        [ 8.5831e-06, -9.9564e-03,  2.0767e-02,  ..., -3.3092e-04,
         -1.7563e-02,  2.2186e-02],
        ...,
        [ 1.1223e-02,  1.6296e-02, -3.5217e-02,  ...,  1.9226e-02,
         -1.3641e-02,  6.0654e-03],
        [-1.1101e-02,  1.2100e-02, -1.7365e-02,  ..., -1.4771e-02,
          1.7227e-02, -1.3039e-02],
        [-8.1482e-03,  1.0529e-03, -2.3300e-02,  ...,  1.8768e-03,
         -1.9424e-02,  3.9795e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.7822, -2.8652, -0.1405,  ..., -1.4004, -3.0547, -2.0781]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 04:06:18 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of formula is formulae
The plural form of facility is facilities
The plural form of success is successes
The plural form of energy is energies
The plural form of species is species
The plural form of woman is women
The plural form of majority is majorities
The plural form of life is
2024-07-31 04:06:18 root INFO     [order_1_approx] starting weight calculation for The plural form of life is lives
The plural form of woman is women
The plural form of energy is energies
The plural form of species is species
The plural form of facility is facilities
The plural form of formula is formulae
The plural form of majority is majorities
The plural form of success is
2024-07-31 04:06:18 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-31 04:07:20 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1752, -0.0105, -0.2788,  ...,  0.0735, -0.4575, -0.1854],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-2.6348, -2.1328,  0.7705,  ..., -0.6504,  0.5352, -0.9771],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0215,  0.0174, -0.0033,  ..., -0.0249, -0.0043,  0.0115],
        [ 0.0083,  0.0178,  0.0114,  ..., -0.0001,  0.0037, -0.0130],
        [-0.0180, -0.0038,  0.0168,  ..., -0.0003, -0.0097, -0.0123],
        ...,
        [-0.0122,  0.0050,  0.0023,  ...,  0.0440, -0.0050, -0.0156],
        [-0.0089, -0.0007,  0.0031,  ..., -0.0028,  0.0128, -0.0063],
        [ 0.0024, -0.0099,  0.0046,  ...,  0.0150, -0.0084,  0.0105]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-2.2266, -1.9678,  0.5977,  ..., -0.8604,  0.4082, -1.0732]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 04:07:21 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country of guam primarily speaks the language of english
The country of bangladesh primarily speaks the language of bengali
The country of jamaica primarily speaks the language of english
The country of colombia primarily speaks the language of spanish
The country of iraq primarily speaks the language of arabic
The country of norway primarily speaks the language of norwegian
The country of ethiopia primarily speaks the language of amharic
The country of jordan primarily speaks the language of
2024-07-31 04:07:22 root INFO     [order_1_approx] starting weight calculation for The country of jamaica primarily speaks the language of english
The country of jordan primarily speaks the language of arabic
The country of colombia primarily speaks the language of spanish
The country of iraq primarily speaks the language of arabic
The country of bangladesh primarily speaks the language of bengali
The country of guam primarily speaks the language of english
The country of norway primarily speaks the language of norwegian
The country of ethiopia primarily speaks the language of
2024-07-31 04:07:22 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-31 04:08:51 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0215,  0.2773,  0.1682,  ..., -0.0441, -0.2637,  0.1194],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.9863, -0.4497, -1.1250,  ..., -1.5703, -2.7969, -2.6914],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0676, -0.0067,  0.0066,  ..., -0.0054,  0.0120,  0.0089],
        [-0.0294,  0.0582, -0.0154,  ...,  0.0366,  0.0059, -0.0011],
        [ 0.0263, -0.0098,  0.0137,  ...,  0.0150, -0.0074, -0.0031],
        ...,
        [ 0.0048, -0.0066, -0.0158,  ...,  0.0285, -0.0229, -0.0045],
        [-0.0417,  0.0252, -0.0083,  ..., -0.0163,  0.0137, -0.0391],
        [-0.0024, -0.0175, -0.0150,  ...,  0.0200, -0.0073,  0.0330]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.7021, -0.9194, -0.7998,  ..., -1.1094, -2.5918, -2.4941]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 04:08:52 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of life is lives
The plural form of woman is women
The plural form of energy is energies
The plural form of species is species
The plural form of facility is facilities
The plural form of formula is formulae
The plural form of majority is majorities
The plural form of success is
2024-07-31 04:08:52 root INFO     [order_1_approx] starting weight calculation for The plural form of facility is facilities
The plural form of life is lives
The plural form of majority is majorities
The plural form of species is species
The plural form of formula is formulae
The plural form of woman is women
The plural form of success is successes
The plural form of energy is
2024-07-31 04:08:52 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-31 04:10:04 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0934, -0.3479, -0.1758,  ..., -0.0811, -0.2769, -0.0450],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.7446, -2.6738,  4.0938,  ..., -2.5234, -1.0273, -4.0195],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 1.4343e-03, -8.4305e-04,  5.2261e-03,  ..., -3.2959e-03,
         -2.2163e-03, -3.1853e-03],
        [ 5.0735e-03,  1.1902e-02,  4.8447e-03,  ..., -9.5596e-03,
         -1.0195e-03, -3.8338e-03],
        [-1.0056e-02, -3.3760e-03,  1.0994e-02,  ..., -2.6608e-03,
          7.6370e-03,  3.5152e-03],
        ...,
        [ 1.5259e-05, -5.1498e-03, -3.8109e-03,  ...,  7.7019e-03,
          7.9269e-03,  8.6260e-04],
        [ 5.6458e-03, -3.9597e-03,  1.8473e-03,  ...,  8.1635e-03,
          6.3248e-03, -1.5535e-03],
        [-2.9373e-04,  3.2558e-03,  1.2312e-03,  ..., -2.6321e-03,
         -9.6283e-03,  1.1244e-03]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.6680, -2.6816,  3.9570,  ..., -2.5527, -0.9351, -3.9121]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 04:10:05 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country of jamaica primarily speaks the language of english
The country of jordan primarily speaks the language of arabic
The country of colombia primarily speaks the language of spanish
The country of iraq primarily speaks the language of arabic
The country of bangladesh primarily speaks the language of bengali
The country of guam primarily speaks the language of english
The country of norway primarily speaks the language of norwegian
The country of ethiopia primarily speaks the language of
2024-07-31 04:10:05 root INFO     [order_1_approx] starting weight calculation for The country of norway primarily speaks the language of norwegian
The country of colombia primarily speaks the language of spanish
The country of jamaica primarily speaks the language of english
The country of jordan primarily speaks the language of arabic
The country of ethiopia primarily speaks the language of amharic
The country of guam primarily speaks the language of english
The country of iraq primarily speaks the language of arabic
The country of bangladesh primarily speaks the language of
2024-07-31 04:10:05 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-31 04:11:27 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2355, -0.0050, -0.2319,  ..., -0.2217, -0.0418,  0.0780],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.8828,  0.4648,  1.4238,  ..., -2.4785, -2.6973, -2.8965],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0504, -0.0324, -0.0036,  ..., -0.0098, -0.0036, -0.0116],
        [-0.0102,  0.0494,  0.0095,  ...,  0.0387,  0.0189,  0.0114],
        [-0.0182,  0.0061,  0.0237,  ..., -0.0083,  0.0020,  0.0112],
        ...,
        [ 0.0091,  0.0068, -0.0233,  ...,  0.0119, -0.0018, -0.0008],
        [-0.0054,  0.0296,  0.0060,  ..., -0.0068,  0.0296, -0.0219],
        [ 0.0095, -0.0220,  0.0027,  ...,  0.0023, -0.0141,  0.0105]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.4395, -0.1030,  0.9341,  ..., -1.7637, -3.3477, -2.4414]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 04:11:28 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of facility is facilities
The plural form of life is lives
The plural form of majority is majorities
The plural form of species is species
The plural form of formula is formulae
The plural form of woman is women
The plural form of success is successes
The plural form of energy is
2024-07-31 04:11:28 root INFO     [order_1_approx] starting weight calculation for The plural form of facility is facilities
The plural form of energy is energies
The plural form of species is species
The plural form of majority is majorities
The plural form of woman is women
The plural form of success is successes
The plural form of life is lives
The plural form of formula is
2024-07-31 04:11:28 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-31 04:12:40 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1098, -0.2827, -0.3970,  ...,  0.1531, -0.4307,  0.2419],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.6211, -2.4551,  0.5132,  ..., -0.9941, -2.4863, -2.8164],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0141,  0.0056,  0.0133,  ..., -0.0182, -0.0050, -0.0060],
        [-0.0022,  0.0106,  0.0159,  ..., -0.0224,  0.0026, -0.0081],
        [-0.0161,  0.0079, -0.0006,  ...,  0.0119,  0.0175, -0.0103],
        ...,
        [-0.0023,  0.0046, -0.0112,  ...,  0.0163,  0.0053,  0.0056],
        [-0.0148,  0.0041,  0.0203,  ..., -0.0060,  0.0094, -0.0049],
        [-0.0061, -0.0107, -0.0046,  ..., -0.0160, -0.0096,  0.0207]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.5918, -2.2363,  0.2373,  ..., -1.0127, -2.0469, -2.5957]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 04:12:41 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country of norway primarily speaks the language of norwegian
The country of colombia primarily speaks the language of spanish
The country of jamaica primarily speaks the language of english
The country of jordan primarily speaks the language of arabic
The country of ethiopia primarily speaks the language of amharic
The country of guam primarily speaks the language of english
The country of iraq primarily speaks the language of arabic
The country of bangladesh primarily speaks the language of
2024-07-31 04:12:41 root INFO     [order_1_approx] starting weight calculation for The country of norway primarily speaks the language of norwegian
The country of ethiopia primarily speaks the language of amharic
The country of bangladesh primarily speaks the language of bengali
The country of jordan primarily speaks the language of arabic
The country of guam primarily speaks the language of english
The country of colombia primarily speaks the language of spanish
The country of jamaica primarily speaks the language of english
The country of iraq primarily speaks the language of
2024-07-31 04:12:41 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-31 04:14:01 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.5552, -0.0313, -0.0627,  ..., -0.1204, -0.3201,  0.0894],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.2090, -1.3135,  4.1719,  ..., -0.4197, -2.7305, -0.4395],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0638,  0.0042, -0.0207,  ..., -0.0739, -0.0036, -0.0351],
        [ 0.0157,  0.0496,  0.0399,  ...,  0.0507, -0.0536,  0.0275],
        [-0.0255,  0.0138,  0.0193,  ...,  0.0232,  0.0368,  0.0122],
        ...,
        [ 0.0406, -0.0158,  0.0139,  ...,  0.0657, -0.0390,  0.0285],
        [-0.0149,  0.0254, -0.0059,  ..., -0.0129,  0.0776, -0.0163],
        [ 0.0154, -0.0161,  0.0204,  ...,  0.0427, -0.0387,  0.0626]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.3494, -1.3379,  4.2188,  ..., -0.1879, -3.2715, -0.4709]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 04:14:02 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of facility is facilities
The plural form of energy is energies
The plural form of species is species
The plural form of majority is majorities
The plural form of woman is women
The plural form of success is successes
The plural form of life is lives
The plural form of formula is
2024-07-31 04:14:02 root INFO     [order_1_approx] starting weight calculation for The plural form of species is species
The plural form of facility is facilities
The plural form of woman is women
The plural form of energy is energies
The plural form of success is successes
The plural form of formula is formulae
The plural form of life is lives
The plural form of majority is
2024-07-31 04:14:02 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-31 04:15:20 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1154, -0.3259, -0.3584,  ...,  0.1326, -0.3762,  0.1980],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.8789, -2.3965,  1.1523,  ..., -1.5791,  0.2139, -2.1719],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0098,  0.0017, -0.0007,  ..., -0.0137,  0.0010,  0.0051],
        [ 0.0097,  0.0105,  0.0068,  ..., -0.0004,  0.0046, -0.0095],
        [-0.0144,  0.0004,  0.0180,  ...,  0.0033,  0.0026, -0.0161],
        ...,
        [ 0.0042,  0.0016, -0.0125,  ...,  0.0246,  0.0097, -0.0016],
        [-0.0040,  0.0004,  0.0123,  ..., -0.0069,  0.0231, -0.0010],
        [-0.0039, -0.0059, -0.0025,  ...,  0.0063, -0.0017,  0.0167]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.3555, -2.1152,  0.8589,  ..., -1.6748,  0.4258, -2.3320]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 04:15:21 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country of norway primarily speaks the language of norwegian
The country of ethiopia primarily speaks the language of amharic
The country of bangladesh primarily speaks the language of bengali
The country of jordan primarily speaks the language of arabic
The country of guam primarily speaks the language of english
The country of colombia primarily speaks the language of spanish
The country of jamaica primarily speaks the language of english
The country of iraq primarily speaks the language of
2024-07-31 04:15:21 root INFO     [order_1_approx] starting weight calculation for The country of ethiopia primarily speaks the language of amharic
The country of colombia primarily speaks the language of spanish
The country of jordan primarily speaks the language of arabic
The country of norway primarily speaks the language of norwegian
The country of bangladesh primarily speaks the language of bengali
The country of iraq primarily speaks the language of arabic
The country of jamaica primarily speaks the language of english
The country of guam primarily speaks the language of
2024-07-31 04:15:22 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-31 04:16:35 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3777,  0.2126, -0.1835,  ..., -0.0715, -0.3157,  0.3159],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.2324, -0.7441, -1.0781,  ..., -5.6016, -1.6797, -2.1113],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 5.2704e-02,  2.9053e-02,  1.3885e-02,  ...,  8.0872e-03,
         -9.9869e-03,  2.6627e-03],
        [ 1.9440e-02,  5.9692e-02,  1.8677e-02,  ...,  4.2633e-02,
         -2.8290e-02,  1.5793e-02],
        [ 1.6602e-02,  4.2175e-02,  6.8909e-02,  ..., -1.7944e-02,
         -2.0004e-02,  8.5297e-03],
        ...,
        [-3.6488e-03,  1.0231e-02,  1.7822e-02,  ...,  2.7481e-02,
         -5.2704e-02,  1.9531e-02],
        [-3.9001e-02,  5.5603e-02, -4.3549e-02,  ...,  2.4796e-05,
          9.3994e-03, -2.2873e-02],
        [ 1.3733e-02, -8.6975e-03, -1.8677e-02,  ...,  1.5259e-04,
          9.0637e-03,  7.4402e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.8809, -0.8076, -1.5293,  ..., -5.1836, -2.5000, -2.0488]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 04:16:36 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of species is species
The plural form of facility is facilities
The plural form of woman is women
The plural form of energy is energies
The plural form of success is successes
The plural form of formula is formulae
The plural form of life is lives
The plural form of majority is
2024-07-31 04:16:36 root INFO     [order_1_approx] starting weight calculation for The plural form of facility is facilities
The plural form of life is lives
The plural form of success is successes
The plural form of energy is energies
The plural form of majority is majorities
The plural form of formula is formulae
The plural form of species is species
The plural form of woman is
2024-07-31 04:16:36 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-31 04:18:00 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2336, -0.2822, -0.2035,  ...,  0.2421, -0.5347,  0.0171],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.7827,  1.0430,  2.5996,  ..., -0.4202, -1.2607, -2.9023],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0019,  0.0257, -0.0073,  ...,  0.0025,  0.0064, -0.0171],
        [ 0.0127,  0.0316,  0.0034,  ...,  0.0021, -0.0136, -0.0073],
        [ 0.0030, -0.0165,  0.0506,  ...,  0.0086,  0.0276, -0.0223],
        ...,
        [ 0.0340,  0.0185, -0.0013,  ...,  0.0574, -0.0061, -0.0212],
        [ 0.0059,  0.0134,  0.0230,  ...,  0.0135,  0.0233,  0.0136],
        [ 0.0086, -0.0232, -0.0103,  ..., -0.0196,  0.0055,  0.0526]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.1104,  1.5312,  2.5723,  ..., -0.6455, -1.0625, -2.9121]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 04:18:01 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country of ethiopia primarily speaks the language of amharic
The country of colombia primarily speaks the language of spanish
The country of jordan primarily speaks the language of arabic
The country of norway primarily speaks the language of norwegian
The country of bangladesh primarily speaks the language of bengali
The country of iraq primarily speaks the language of arabic
The country of jamaica primarily speaks the language of english
The country of guam primarily speaks the language of
2024-07-31 04:18:01 root INFO     [order_1_approx] starting weight calculation for The country of colombia primarily speaks the language of spanish
The country of ethiopia primarily speaks the language of amharic
The country of bangladesh primarily speaks the language of bengali
The country of jordan primarily speaks the language of arabic
The country of norway primarily speaks the language of norwegian
The country of guam primarily speaks the language of english
The country of iraq primarily speaks the language of arabic
The country of jamaica primarily speaks the language of
2024-07-31 04:18:02 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-31 04:19:10 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1412,  0.0721,  0.0081,  ..., -0.0707, -0.3784,  0.2031],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.4922, -5.2031,  2.7383,  ..., -0.2437, -1.2109, -0.4268],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0522, -0.0043,  0.0198,  ..., -0.0202,  0.0064,  0.0228],
        [-0.0033,  0.0363, -0.0230,  ...,  0.0285,  0.0108, -0.0088],
        [-0.0148,  0.0087,  0.0075,  ...,  0.0277, -0.0174,  0.0220],
        ...,
        [-0.0364, -0.0102, -0.0115,  ...,  0.0311, -0.0090, -0.0052],
        [-0.0135,  0.0403,  0.0031,  ..., -0.0138,  0.0058, -0.0320],
        [ 0.0176, -0.0042, -0.0101,  ..., -0.0097,  0.0204,  0.0527]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.2012, -4.5898,  2.7617,  ...,  0.1523, -1.6729, -0.5054]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 04:19:11 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of facility is facilities
The plural form of life is lives
The plural form of success is successes
The plural form of energy is energies
The plural form of majority is majorities
The plural form of formula is formulae
The plural form of species is species
The plural form of woman is
2024-07-31 04:19:11 root INFO     total operator prediction time: 1228.9443924427032 seconds
2024-07-31 04:19:11 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on meronyms - member
2024-07-31 04:19:11 root INFO     building operator meronyms - member
2024-07-31 04:19:11 root INFO     [order_1_approx] starting weight calculation for A acrobat is a member of a troupe
A county is a member of a state
A nomad is a member of a horde
A cat is a member of a clowder
A musician is a member of a orchestra
A galaxy is a member of a universe
A letter is a member of a alphabet
A singer is a member of a
2024-07-31 04:19:11 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-31 04:20:38 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0379, -0.0015, -0.4680,  ...,  0.1671, -0.2700, -0.2141],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.7285,  0.2705,  2.1406,  ...,  0.8008,  1.0039, -2.2168],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0193, -0.0096,  0.0076,  ..., -0.0133, -0.0049, -0.0017],
        [ 0.0069,  0.0050, -0.0041,  ...,  0.0002,  0.0069, -0.0071],
        [-0.0148, -0.0015,  0.0296,  ..., -0.0043,  0.0095,  0.0002],
        ...,
        [-0.0044,  0.0057, -0.0004,  ...,  0.0195,  0.0126,  0.0100],
        [-0.0155,  0.0137,  0.0167,  ...,  0.0013,  0.0249,  0.0005],
        [-0.0020, -0.0024, -0.0113,  ..., -0.0059,  0.0056,  0.0139]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.5977,  0.5000,  2.0488,  ...,  0.7070,  1.1797, -2.1328]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 04:20:38 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country of colombia primarily speaks the language of spanish
The country of ethiopia primarily speaks the language of amharic
The country of bangladesh primarily speaks the language of bengali
The country of jordan primarily speaks the language of arabic
The country of norway primarily speaks the language of norwegian
The country of guam primarily speaks the language of english
The country of iraq primarily speaks the language of arabic
The country of jamaica primarily speaks the language of
2024-07-31 04:20:38 root INFO     total operator prediction time: 1286.1114673614502 seconds
2024-07-31 04:20:38 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on name - nationality
2024-07-31 04:20:38 root INFO     building operator name - nationality
2024-07-31 04:20:39 root INFO     [order_1_approx] starting weight calculation for aristotle was greek
lincoln was american
rousseau was french
pascal was french
balzac was french
depp was american
hume was scottish
jolie was
2024-07-31 04:20:39 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-31 04:21:44 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0245,  0.0516, -0.2783,  ...,  0.2014, -0.3167,  0.1268],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.2930, -5.0391,  3.6211,  ..., -1.0273, -0.3450, -2.4688],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0374, -0.0345,  0.0214,  ...,  0.0087,  0.0392,  0.0134],
        [-0.0029,  0.0516, -0.0006,  ...,  0.0050, -0.0082, -0.0314],
        [ 0.0187, -0.0122,  0.0446,  ...,  0.0007, -0.0109,  0.0009],
        ...,
        [ 0.0179,  0.0162,  0.0104,  ...,  0.0480,  0.0108, -0.0066],
        [ 0.0078,  0.0176, -0.0113,  ...,  0.0142,  0.0214,  0.0283],
        [ 0.0005, -0.0020, -0.0082,  ...,  0.0017, -0.0134,  0.0458]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.3418, -4.9336,  3.4980,  ..., -0.9141, -0.7256, -2.1348]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 04:21:45 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A acrobat is a member of a troupe
A county is a member of a state
A nomad is a member of a horde
A cat is a member of a clowder
A musician is a member of a orchestra
A galaxy is a member of a universe
A letter is a member of a alphabet
A singer is a member of a
2024-07-31 04:21:45 root INFO     [order_1_approx] starting weight calculation for A galaxy is a member of a universe
A musician is a member of a orchestra
A singer is a member of a choir
A nomad is a member of a horde
A county is a member of a state
A letter is a member of a alphabet
A cat is a member of a clowder
A acrobat is a member of a
2024-07-31 04:21:45 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-31 04:23:15 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1188,  0.3333, -0.2942,  ...,  0.2109, -0.3691,  0.1549],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.0586, -1.1133, -0.3633,  ..., -1.4258, -0.2168, -0.3037],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0290,  0.0054, -0.0119,  ...,  0.0269, -0.0010, -0.0104],
        [ 0.0219,  0.0294,  0.0356,  ..., -0.0067,  0.0029, -0.0075],
        [-0.0114,  0.0216,  0.0458,  ...,  0.0320, -0.0030,  0.0047],
        ...,
        [ 0.0255, -0.0167,  0.0074,  ...,  0.0165, -0.0147,  0.0091],
        [-0.0004,  0.0025, -0.0071,  ...,  0.0020, -0.0063, -0.0070],
        [ 0.0035,  0.0013, -0.0088,  ..., -0.0044, -0.0137,  0.0359]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.0898, -0.9600, -0.5459,  ..., -1.2246, -0.2859, -0.5596]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 04:23:16 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for aristotle was greek
lincoln was american
rousseau was french
pascal was french
balzac was french
depp was american
hume was scottish
jolie was
2024-07-31 04:23:16 root INFO     [order_1_approx] starting weight calculation for balzac was french
jolie was american
depp was american
hume was scottish
pascal was french
lincoln was american
aristotle was greek
rousseau was
2024-07-31 04:23:16 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-31 04:24:18 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1599, -0.0830,  0.2043,  ..., -0.0188, -0.3521,  0.4075],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.5645, -5.7578,  3.3613,  ...,  1.5957,  0.1924, -0.1567],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0142, -0.0031,  0.0181,  ...,  0.0129,  0.0019,  0.0051],
        [-0.0102,  0.0164,  0.0012,  ..., -0.0040, -0.0086, -0.0008],
        [-0.0068,  0.0042,  0.0432,  ..., -0.0077,  0.0030,  0.0028],
        ...,
        [ 0.0073,  0.0363,  0.0197,  ...,  0.0677, -0.0240, -0.0072],
        [-0.0064,  0.0249, -0.0050,  ...,  0.0151,  0.0411, -0.0025],
        [-0.0127, -0.0274,  0.0033,  ...,  0.0030, -0.0219,  0.0267]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.5176, -5.1445,  2.9238,  ...,  1.2168, -0.4087,  0.3833]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 04:24:19 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A galaxy is a member of a universe
A musician is a member of a orchestra
A singer is a member of a choir
A nomad is a member of a horde
A county is a member of a state
A letter is a member of a alphabet
A cat is a member of a clowder
A acrobat is a member of a
2024-07-31 04:24:20 root INFO     [order_1_approx] starting weight calculation for A musician is a member of a orchestra
A letter is a member of a alphabet
A cat is a member of a clowder
A singer is a member of a choir
A nomad is a member of a horde
A county is a member of a state
A acrobat is a member of a troupe
A galaxy is a member of a
2024-07-31 04:24:20 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-31 04:25:56 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1692, -0.1982, -0.5244,  ..., -0.0268,  0.0056,  0.1381],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.9121, -4.8242,  0.6035,  ..., -4.9297, -0.0859,  2.2773],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0433,  0.0187,  0.0010,  ...,  0.0094,  0.0016, -0.0232],
        [-0.0177,  0.0312,  0.0133,  ...,  0.0035,  0.0038, -0.0055],
        [-0.0023,  0.0109,  0.0453,  ..., -0.0067,  0.0198,  0.0003],
        ...,
        [ 0.0142, -0.0120,  0.0109,  ...,  0.0549, -0.0123,  0.0144],
        [-0.0002, -0.0089,  0.0095,  ...,  0.0186,  0.0230,  0.0118],
        [-0.0263,  0.0110, -0.0004,  ..., -0.0122, -0.0027,  0.0626]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.8262, -4.5273,  0.3601,  ..., -4.8750, -0.0189,  2.5254]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 04:25:56 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for balzac was french
jolie was american
depp was american
hume was scottish
pascal was french
lincoln was american
aristotle was greek
rousseau was
2024-07-31 04:25:57 root INFO     [order_1_approx] starting weight calculation for balzac was french
aristotle was greek
hume was scottish
pascal was french
jolie was american
rousseau was french
depp was american
lincoln was
2024-07-31 04:25:57 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-31 04:26:50 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0919,  0.0045, -0.3787,  ..., -0.0429, -0.3369,  0.1170],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.4180e-03, -1.6738e+00,  6.4258e+00,  ..., -3.1816e+00,
        -1.7686e+00, -2.0859e+00], device='cuda:1', dtype=torch.float16,
       grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0120,  0.0005,  0.0060,  ...,  0.0033, -0.0120,  0.0057],
        [-0.0035, -0.0010,  0.0111,  ...,  0.0115,  0.0081, -0.0033],
        [-0.0124,  0.0099,  0.0087,  ..., -0.0165,  0.0035, -0.0003],
        ...,
        [ 0.0020, -0.0001, -0.0041,  ...,  0.0154,  0.0067, -0.0008],
        [-0.0049,  0.0085, -0.0099,  ..., -0.0087,  0.0094, -0.0062],
        [ 0.0076, -0.0098,  0.0034,  ..., -0.0042, -0.0145,  0.0167]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.1517, -1.3906,  6.1719,  ..., -3.0332, -1.9463, -1.8066]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 04:26:51 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A musician is a member of a orchestra
A letter is a member of a alphabet
A cat is a member of a clowder
A singer is a member of a choir
A nomad is a member of a horde
A county is a member of a state
A acrobat is a member of a troupe
A galaxy is a member of a
2024-07-31 04:26:51 root INFO     [order_1_approx] starting weight calculation for A nomad is a member of a horde
A galaxy is a member of a universe
A cat is a member of a clowder
A county is a member of a state
A acrobat is a member of a troupe
A singer is a member of a choir
A musician is a member of a orchestra
A letter is a member of a
2024-07-31 04:26:51 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-31 04:28:37 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 2.4414e-04,  6.1981e-02, -5.0781e-01,  ..., -1.5210e-01,
        -1.6943e-01, -4.2236e-02], device='cuda:0', dtype=torch.float16,
       grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.4043, -1.7227,  1.7949,  ..., -3.6641,  2.0781, -2.5352],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0072, -0.0038, -0.0426,  ...,  0.0101, -0.0345, -0.0270],
        [ 0.0104,  0.0430,  0.0500,  ...,  0.0003, -0.0031,  0.0097],
        [ 0.0002,  0.0034,  0.0364,  ..., -0.0080,  0.0004,  0.0034],
        ...,
        [ 0.0483,  0.0045,  0.0286,  ...,  0.0418,  0.0032,  0.0191],
        [-0.0211, -0.0075, -0.0152,  ...,  0.0087,  0.0346, -0.0262],
        [-0.0012,  0.0120,  0.0244,  ...,  0.0047,  0.0153,  0.0517]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.3555, -1.3271,  1.4307,  ..., -3.8164,  1.8672, -2.2637]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 04:28:38 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for balzac was french
aristotle was greek
hume was scottish
pascal was french
jolie was american
rousseau was french
depp was american
lincoln was
2024-07-31 04:28:38 root INFO     [order_1_approx] starting weight calculation for rousseau was french
pascal was french
depp was american
aristotle was greek
jolie was american
balzac was french
lincoln was american
hume was
2024-07-31 04:28:38 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-31 04:29:24 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1052,  0.0692, -0.4673,  ...,  0.0255,  0.0248,  0.0114],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.8379, -3.3535, -0.0610,  ...,  0.8403, -3.1016, -1.8379],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 9.1980e-02, -1.9150e-02, -3.2654e-02,  ..., -2.0203e-02,
          1.0958e-03,  1.7181e-02],
        [-2.0508e-02,  7.7148e-02,  1.5038e-02,  ...,  2.6337e-02,
         -1.1383e-02,  7.9193e-03],
        [ 1.6998e-02, -5.8228e-02,  2.4750e-02,  ...,  5.0476e-02,
         -2.9358e-02, -3.2593e-02],
        ...,
        [ 2.0874e-02,  4.2969e-02,  1.7212e-02,  ...,  4.1321e-02,
          5.1025e-02, -1.4008e-02],
        [-3.3798e-03, -5.7220e-05, -2.7351e-03,  ...,  3.4760e-02,
          2.5879e-02,  1.1215e-02],
        [ 7.1907e-03, -4.5258e-02,  2.2217e-02,  ...,  3.8513e-02,
          1.4244e-02,  4.4312e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.9116, -3.6680,  1.0078,  ...,  0.1401, -2.9395, -0.9502]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 04:29:25 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A nomad is a member of a horde
A galaxy is a member of a universe
A cat is a member of a clowder
A county is a member of a state
A acrobat is a member of a troupe
A singer is a member of a choir
A musician is a member of a orchestra
A letter is a member of a
2024-07-31 04:29:26 root INFO     [order_1_approx] starting weight calculation for A musician is a member of a orchestra
A galaxy is a member of a universe
A county is a member of a state
A cat is a member of a clowder
A letter is a member of a alphabet
A acrobat is a member of a troupe
A singer is a member of a choir
A nomad is a member of a
2024-07-31 04:29:26 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-31 04:31:17 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.3298,  0.2205, -0.1907,  ...,  0.0174,  0.4209,  0.0736],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.6113, -2.1953,  1.4570,  ..., -3.8574, -0.7783, -1.1484],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0474,  0.0200,  0.0004,  ...,  0.0146, -0.0044, -0.0159],
        [ 0.0037,  0.0415,  0.0266,  ...,  0.0074,  0.0001, -0.0168],
        [ 0.0009, -0.0083,  0.0385,  ...,  0.0069, -0.0032, -0.0143],
        ...,
        [ 0.0318,  0.0135,  0.0186,  ...,  0.0604,  0.0025,  0.0300],
        [ 0.0154, -0.0013, -0.0136,  ...,  0.0331,  0.0137,  0.0095],
        [-0.0158,  0.0255,  0.0014,  ...,  0.0007, -0.0164,  0.0660]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.6816, -2.2578,  1.1416,  ..., -3.6582, -1.2129, -1.0518]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 04:31:18 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for rousseau was french
pascal was french
depp was american
aristotle was greek
jolie was american
balzac was french
lincoln was american
hume was
2024-07-31 04:31:18 root INFO     [order_1_approx] starting weight calculation for rousseau was french
lincoln was american
hume was scottish
depp was american
jolie was american
pascal was french
balzac was french
aristotle was
2024-07-31 04:31:18 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-31 04:31:59 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0359,  0.2046, -0.3313,  ...,  0.1616, -0.1798,  0.3403],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.5898, -2.8633,  1.3896,  ..., -1.3320, -1.8691, -0.2432],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0363, -0.0169,  0.0174,  ..., -0.0013, -0.0183, -0.0083],
        [ 0.0111,  0.0363, -0.0140,  ..., -0.0089, -0.0055, -0.0235],
        [ 0.0264, -0.0185,  0.0373,  ..., -0.0032, -0.0085,  0.0114],
        ...,
        [ 0.0208,  0.0190, -0.0066,  ...,  0.0535,  0.0187, -0.0104],
        [ 0.0055, -0.0025, -0.0158,  ...,  0.0043,  0.0333, -0.0100],
        [ 0.0049,  0.0037,  0.0027,  ...,  0.0149, -0.0021,  0.0464]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.6035, -2.9941,  1.3115,  ..., -1.4014, -1.6787, -0.2666]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 04:32:00 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A musician is a member of a orchestra
A galaxy is a member of a universe
A county is a member of a state
A cat is a member of a clowder
A letter is a member of a alphabet
A acrobat is a member of a troupe
A singer is a member of a choir
A nomad is a member of a
2024-07-31 04:32:00 root INFO     [order_1_approx] starting weight calculation for A cat is a member of a clowder
A nomad is a member of a horde
A singer is a member of a choir
A acrobat is a member of a troupe
A letter is a member of a alphabet
A musician is a member of a orchestra
A galaxy is a member of a universe
A county is a member of a
2024-07-31 04:32:00 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-31 04:33:59 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0989, -0.1771, -0.6396,  ..., -0.2047, -0.1152, -0.0262],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.2578, -5.5312, -0.6621,  ..., -4.7773, -0.7188, -0.3647],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0329, -0.0027, -0.0028,  ..., -0.0052, -0.0211, -0.0150],
        [ 0.0033,  0.0142,  0.0037,  ..., -0.0134,  0.0006, -0.0072],
        [-0.0033, -0.0016,  0.0486,  ...,  0.0025, -0.0018, -0.0032],
        ...,
        [ 0.0395, -0.0190, -0.0098,  ...,  0.0429, -0.0059, -0.0170],
        [ 0.0123, -0.0029,  0.0083,  ...,  0.0016,  0.0188,  0.0105],
        [-0.0086,  0.0001,  0.0053,  ...,  0.0074, -0.0122,  0.0451]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.4844, -5.6680, -1.0469,  ..., -4.8789, -0.5479, -0.2690]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 04:34:00 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for rousseau was french
lincoln was american
hume was scottish
depp was american
jolie was american
pascal was french
balzac was french
aristotle was
2024-07-31 04:34:00 root INFO     [order_1_approx] starting weight calculation for rousseau was french
jolie was american
aristotle was greek
lincoln was american
balzac was french
pascal was french
hume was scottish
depp was
2024-07-31 04:34:00 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-31 04:34:32 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0064,  0.0723, -0.4866,  ..., -0.1561, -0.0583,  0.2661],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.0337, -5.7500,  3.4219,  ..., -6.0078,  3.2090, -4.3594],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0320,  0.0279,  0.0401,  ...,  0.0168,  0.0216,  0.0043],
        [-0.0211, -0.0189, -0.0320,  ...,  0.0215, -0.0226,  0.0184],
        [ 0.0021,  0.0345,  0.0492,  ..., -0.0282, -0.0195, -0.0272],
        ...,
        [-0.0080, -0.0217, -0.0409,  ...,  0.0416,  0.0090, -0.0087],
        [ 0.0134,  0.0282,  0.0033,  ..., -0.0193,  0.0431, -0.0025],
        [-0.0184, -0.0405, -0.0190,  ...,  0.0219, -0.0267,  0.0475]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.0133, -4.5117,  2.8086,  ..., -5.4492,  2.5801, -3.8613]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 04:34:33 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A cat is a member of a clowder
A nomad is a member of a horde
A singer is a member of a choir
A acrobat is a member of a troupe
A letter is a member of a alphabet
A musician is a member of a orchestra
A galaxy is a member of a universe
A county is a member of a
2024-07-31 04:34:33 root INFO     [order_1_approx] starting weight calculation for A acrobat is a member of a troupe
A nomad is a member of a horde
A county is a member of a state
A galaxy is a member of a universe
A cat is a member of a clowder
A letter is a member of a alphabet
A singer is a member of a choir
A musician is a member of a
2024-07-31 04:34:33 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-31 04:36:40 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0072,  0.0687,  0.0529,  ...,  0.3787, -0.3479,  0.0962],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.3711, -1.8760,  0.8135,  ..., -1.6836,  1.0410, -1.6445],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0669, -0.0246, -0.0085,  ..., -0.0380, -0.0042, -0.0209],
        [-0.0100,  0.0439,  0.0354,  ...,  0.0267,  0.0110,  0.0048],
        [-0.0057,  0.0220,  0.0489,  ..., -0.0075, -0.0170, -0.0021],
        ...,
        [ 0.0129, -0.0117,  0.0012,  ...,  0.0715, -0.0127, -0.0023],
        [-0.0014,  0.0129,  0.0115,  ...,  0.0062,  0.0116,  0.0021],
        [ 0.0079, -0.0204,  0.0013,  ..., -0.0129, -0.0077,  0.0533]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.6094, -2.2227,  0.9370,  ..., -1.5605,  0.8594, -1.3125]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 04:36:41 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for rousseau was french
jolie was american
aristotle was greek
lincoln was american
balzac was french
pascal was french
hume was scottish
depp was
2024-07-31 04:36:41 root INFO     [order_1_approx] starting weight calculation for aristotle was greek
rousseau was french
lincoln was american
jolie was american
depp was american
hume was scottish
balzac was french
pascal was
2024-07-31 04:36:41 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-31 04:37:07 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0189,  0.2817,  0.3403,  ..., -0.2749, -0.0637,  0.0375],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.3398, -6.4453,  2.8711,  ..., -2.7852, -2.3281, -2.8047],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0130,  0.0043,  0.0246,  ...,  0.0241, -0.0068,  0.0030],
        [ 0.0030,  0.0111,  0.0051,  ..., -0.0140,  0.0155, -0.0172],
        [-0.0032,  0.0002,  0.0350,  ..., -0.0069, -0.0077, -0.0052],
        ...,
        [ 0.0150,  0.0213,  0.0094,  ...,  0.0184, -0.0009, -0.0058],
        [ 0.0244, -0.0007, -0.0107,  ...,  0.0080,  0.0112,  0.0069],
        [ 0.0047, -0.0086, -0.0068,  ..., -0.0236,  0.0068,  0.0263]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.4941, -6.3164,  3.0410,  ..., -2.5547, -2.6543, -2.6855]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 04:37:08 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A acrobat is a member of a troupe
A nomad is a member of a horde
A county is a member of a state
A galaxy is a member of a universe
A cat is a member of a clowder
A letter is a member of a alphabet
A singer is a member of a choir
A musician is a member of a
2024-07-31 04:37:08 root INFO     [order_1_approx] starting weight calculation for A nomad is a member of a horde
A galaxy is a member of a universe
A letter is a member of a alphabet
A acrobat is a member of a troupe
A county is a member of a state
A musician is a member of a orchestra
A singer is a member of a choir
A cat is a member of a
2024-07-31 04:37:08 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-31 04:39:20 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0936, -0.0831, -0.2659,  ..., -0.2017,  0.0463,  0.4688],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.9219, -0.4509,  2.0762,  ..., -4.9688, -0.3828,  2.2383],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0490, -0.0099, -0.0319,  ..., -0.0013, -0.0310, -0.0409],
        [ 0.0231,  0.0428,  0.0323,  ...,  0.0213, -0.0057, -0.0028],
        [-0.0029,  0.0113,  0.0574,  ...,  0.0054,  0.0005,  0.0013],
        ...,
        [-0.0012, -0.0004,  0.0036,  ...,  0.0562,  0.0278,  0.0198],
        [-0.0067, -0.0064,  0.0148,  ..., -0.0065,  0.0253,  0.0191],
        [ 0.0036,  0.0191, -0.0034,  ...,  0.0281, -0.0227,  0.0435]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.3633, -0.4717,  1.8242,  ..., -4.2773, -0.2686,  1.8174]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 04:39:21 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for aristotle was greek
rousseau was french
lincoln was american
jolie was american
depp was american
hume was scottish
balzac was french
pascal was
2024-07-31 04:39:21 root INFO     [order_1_approx] starting weight calculation for pascal was french
lincoln was american
jolie was american
hume was scottish
depp was american
rousseau was french
aristotle was greek
balzac was
2024-07-31 04:39:21 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-31 04:39:42 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1981, -0.0037,  0.0343,  ..., -0.1108, -0.1744,  0.0779],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.7051, -4.4727,  3.2539,  ..., -3.6797, -1.1123, -1.3711],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0439,  0.0254, -0.0103,  ...,  0.0154, -0.0085,  0.0082],
        [ 0.0115,  0.0241,  0.0200,  ...,  0.0012,  0.0085,  0.0097],
        [ 0.0042, -0.0019,  0.0358,  ..., -0.0146,  0.0218,  0.0022],
        ...,
        [-0.0086, -0.0169,  0.0048,  ...,  0.0307,  0.0199, -0.0088],
        [ 0.0575,  0.0387, -0.0090,  ...,  0.0260,  0.0328, -0.0094],
        [ 0.0023, -0.0356, -0.0115,  ..., -0.0238, -0.0085,  0.0635]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.6875, -4.4180,  2.9434,  ..., -3.4590, -1.9922, -0.6348]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 04:39:43 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A nomad is a member of a horde
A galaxy is a member of a universe
A letter is a member of a alphabet
A acrobat is a member of a troupe
A county is a member of a state
A musician is a member of a orchestra
A singer is a member of a choir
A cat is a member of a
2024-07-31 04:39:43 root INFO     total operator prediction time: 1231.4661724567413 seconds
2024-07-31 04:39:43 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on antonyms - binary
2024-07-31 04:39:43 root INFO     building operator antonyms - binary
2024-07-31 04:39:43 root INFO     [order_1_approx] starting weight calculation for The opposite of climb is descend
The opposite of toward is away
The opposite of interior is exterior
The opposite of down is up
The opposite of inbound is outbound
The opposite of employ is dismiss
The opposite of backward is forward
The opposite of input is
2024-07-31 04:39:43 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-31 04:42:00 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1401, -0.0560, -0.6294,  ...,  0.0722, -0.1324, -0.0956],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.7383, -3.2344,  1.2354,  ..., -4.4648,  0.8916,  0.9072],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0439, -0.0014,  0.0092,  ...,  0.0149, -0.0261, -0.0173],
        [-0.0103,  0.0328,  0.0226,  ...,  0.0134,  0.0014, -0.0086],
        [ 0.0179,  0.0080,  0.0513,  ..., -0.0046,  0.0175,  0.0015],
        ...,
        [ 0.0087, -0.0226,  0.0044,  ...,  0.0617, -0.0015,  0.0096],
        [-0.0084, -0.0126,  0.0097,  ...,  0.0157,  0.0219,  0.0087],
        [-0.0105,  0.0190, -0.0078,  ..., -0.0089, -0.0004,  0.0456]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.4648, -3.1152,  1.2090,  ..., -4.6484,  0.7349,  1.2051]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 04:42:01 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for pascal was french
lincoln was american
jolie was american
hume was scottish
depp was american
rousseau was french
aristotle was greek
balzac was
2024-07-31 04:42:01 root INFO     total operator prediction time: 1282.12251329422 seconds
2024-07-31 04:42:01 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on UK_city - county
2024-07-31 04:42:01 root INFO     building operator UK_city - county
2024-07-31 04:42:01 root INFO     [order_1_approx] starting weight calculation for In the United Kingdom, the city of plymouth is in the county of devon
In the United Kingdom, the city of newcastle is in the county of northumberland
In the United Kingdom, the city of crawley is in the county of sussex
In the United Kingdom, the city of dundee is in the county of lowlands
In the United Kingdom, the city of chester is in the county of cheshire
In the United Kingdom, the city of inverness is in the county of highlands
In the United Kingdom, the city of brighton is in the county of sussex
In the United Kingdom, the city of aberdeen is in the county of
2024-07-31 04:42:01 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-31 04:42:16 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.4143, -0.1763, -0.0437,  ...,  0.0526, -0.0991,  0.1741],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.5459, -1.3691, -0.2939,  ..., -0.5049, -0.1006, -2.3418],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0757, -0.0140, -0.0180,  ...,  0.0444,  0.0264,  0.0176],
        [-0.0289,  0.0669,  0.0125,  ...,  0.0259,  0.0056,  0.0252],
        [ 0.0082, -0.0132,  0.0268,  ..., -0.0220, -0.0224, -0.0452],
        ...,
        [-0.0157,  0.0299, -0.0043,  ...,  0.0272, -0.0077,  0.0105],
        [-0.0074, -0.0071, -0.0199,  ..., -0.0245,  0.0662, -0.0054],
        [-0.0104,  0.0209,  0.0068,  ..., -0.0048,  0.0080,  0.0245]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.5029, -1.6445, -0.6777,  ..., -0.5820, -0.2769, -2.0605]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 04:42:17 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of climb is descend
The opposite of toward is away
The opposite of interior is exterior
The opposite of down is up
The opposite of inbound is outbound
The opposite of employ is dismiss
The opposite of backward is forward
The opposite of input is
2024-07-31 04:42:17 root INFO     [order_1_approx] starting weight calculation for The opposite of input is output
The opposite of toward is away
The opposite of climb is descend
The opposite of employ is dismiss
The opposite of backward is forward
The opposite of interior is exterior
The opposite of down is up
The opposite of inbound is
2024-07-31 04:42:17 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-31 04:44:50 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0288,  0.1273,  0.1010,  ..., -0.1393,  0.3503,  0.1426],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.0684, -1.5840, -0.1624,  ..., -0.7627,  0.6104, -2.7578],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0479,  0.0077,  0.0215,  ..., -0.0015,  0.0107,  0.0320],
        [-0.0271,  0.0657, -0.0043,  ...,  0.0370,  0.0188, -0.0081],
        [-0.0005, -0.0257, -0.0043,  ..., -0.0082, -0.0146, -0.0107],
        ...,
        [-0.0334,  0.0407, -0.0153,  ...,  0.0448, -0.0087, -0.0076],
        [ 0.0250, -0.0008, -0.0052,  ...,  0.0464,  0.0486,  0.0059],
        [ 0.0065,  0.0292,  0.0134,  ...,  0.0019,  0.0115,  0.0538]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.0713, -2.2266, -0.3071,  ..., -1.0801,  0.8145, -2.9082]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 04:44:51 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of input is output
The opposite of toward is away
The opposite of climb is descend
The opposite of employ is dismiss
The opposite of backward is forward
The opposite of interior is exterior
The opposite of down is up
The opposite of inbound is
2024-07-31 04:44:52 root INFO     [order_1_approx] starting weight calculation for The opposite of employ is dismiss
The opposite of toward is away
The opposite of climb is descend
The opposite of backward is forward
The opposite of inbound is outbound
The opposite of down is up
The opposite of input is output
The opposite of interior is
2024-07-31 04:44:52 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-31 04:45:12 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1588, -0.0774, -0.1627,  ...,  0.0657, -0.2566,  0.3481],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.0664, -7.9805,  1.0244,  ..., -5.3047, -2.1445, -1.5078],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0091,  0.0020,  0.0139,  ...,  0.0043, -0.0024, -0.0064],
        [-0.0024,  0.0065,  0.0169,  ...,  0.0094,  0.0050, -0.0161],
        [-0.0145, -0.0022,  0.0232,  ...,  0.0187,  0.0135, -0.0154],
        ...,
        [-0.0034, -0.0013, -0.0048,  ...,  0.0137,  0.0141, -0.0019],
        [ 0.0107, -0.0057, -0.0039,  ..., -0.0076, -0.0109, -0.0042],
        [ 0.0052, -0.0106, -0.0037,  ..., -0.0024, -0.0165,  0.0120]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.0557, -8.0391,  0.8984,  ..., -5.0625, -1.9580, -1.5879]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 04:45:13 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for In the United Kingdom, the city of plymouth is in the county of devon
In the United Kingdom, the city of newcastle is in the county of northumberland
In the United Kingdom, the city of crawley is in the county of sussex
In the United Kingdom, the city of dundee is in the county of lowlands
In the United Kingdom, the city of chester is in the county of cheshire
In the United Kingdom, the city of inverness is in the county of highlands
In the United Kingdom, the city of brighton is in the county of sussex
In the United Kingdom, the city of aberdeen is in the county of
2024-07-31 04:45:13 root INFO     [order_1_approx] starting weight calculation for In the United Kingdom, the city of crawley is in the county of sussex
In the United Kingdom, the city of newcastle is in the county of northumberland
In the United Kingdom, the city of brighton is in the county of sussex
In the United Kingdom, the city of inverness is in the county of highlands
In the United Kingdom, the city of plymouth is in the county of devon
In the United Kingdom, the city of aberdeen is in the county of aberdeenshire
In the United Kingdom, the city of chester is in the county of cheshire
In the United Kingdom, the city of dundee is in the county of
2024-07-31 04:45:13 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-31 04:47:24 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0463, -0.2184, -0.0064,  ..., -0.1978,  0.2368,  0.5474],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.3521, -1.5654,  2.9590,  ..., -0.8564, -1.1631, -3.0957],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 2.4734e-02,  2.1572e-03, -1.0300e-02,  ..., -2.7695e-03,
         -2.8122e-02, -1.7410e-02],
        [ 1.7609e-02,  6.2042e-02,  2.2888e-05,  ...,  8.4839e-03,
          1.1543e-02, -4.9400e-03],
        [-1.7052e-03, -2.1057e-02, -9.6283e-03,  ..., -1.5121e-02,
         -2.0844e-02,  1.6388e-02],
        ...,
        [ 3.3325e-02,  1.2459e-02,  1.3214e-02,  ...,  2.1835e-02,
          3.8361e-02, -1.6418e-02],
        [-1.3905e-03,  2.0508e-02, -4.1138e-02,  ...,  2.9541e-02,
          3.7598e-02, -6.6071e-03],
        [ 2.2469e-03,  7.4806e-03, -3.4393e-02,  ...,  2.7939e-02,
          3.2166e-02,  3.9703e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.7812, -1.7803,  2.6934,  ..., -0.7861, -1.5771, -3.2812]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 04:47:25 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of employ is dismiss
The opposite of toward is away
The opposite of climb is descend
The opposite of backward is forward
The opposite of inbound is outbound
The opposite of down is up
The opposite of input is output
The opposite of interior is
2024-07-31 04:47:25 root INFO     [order_1_approx] starting weight calculation for The opposite of down is up
The opposite of toward is away
The opposite of inbound is outbound
The opposite of interior is exterior
The opposite of climb is descend
The opposite of backward is forward
The opposite of input is output
The opposite of employ is
2024-07-31 04:47:25 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-31 04:48:21 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0314, -0.1592,  0.0337,  ...,  0.3384, -0.1572, -0.0832],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.2207, -0.9160,  1.0391,  ..., -2.4473, -4.4805, -0.0879],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0028,  0.0140,  0.0184,  ...,  0.0251, -0.0029, -0.0123],
        [ 0.0031,  0.0176,  0.0077,  ...,  0.0138,  0.0213, -0.0075],
        [-0.0228,  0.0216,  0.0324,  ...,  0.0131,  0.0217, -0.0124],
        ...,
        [-0.0115,  0.0124,  0.0051,  ...,  0.0168,  0.0283, -0.0073],
        [-0.0025, -0.0142, -0.0020,  ..., -0.0046, -0.0166, -0.0061],
        [ 0.0032, -0.0029, -0.0083,  ...,  0.0013,  0.0063,  0.0189]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.8818, -0.9102,  0.6216,  ..., -2.0664, -4.2930, -0.0719]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 04:48:22 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for In the United Kingdom, the city of crawley is in the county of sussex
In the United Kingdom, the city of newcastle is in the county of northumberland
In the United Kingdom, the city of brighton is in the county of sussex
In the United Kingdom, the city of inverness is in the county of highlands
In the United Kingdom, the city of plymouth is in the county of devon
In the United Kingdom, the city of aberdeen is in the county of aberdeenshire
In the United Kingdom, the city of chester is in the county of cheshire
In the United Kingdom, the city of dundee is in the county of
2024-07-31 04:48:23 root INFO     [order_1_approx] starting weight calculation for In the United Kingdom, the city of brighton is in the county of sussex
In the United Kingdom, the city of aberdeen is in the county of aberdeenshire
In the United Kingdom, the city of dundee is in the county of lowlands
In the United Kingdom, the city of chester is in the county of cheshire
In the United Kingdom, the city of newcastle is in the county of northumberland
In the United Kingdom, the city of plymouth is in the county of devon
In the United Kingdom, the city of crawley is in the county of sussex
In the United Kingdom, the city of inverness is in the county of
2024-07-31 04:48:23 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-31 04:49:57 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0359,  0.2294,  0.0050,  ..., -0.0044, -0.1826,  0.3562],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.6797, -2.3477,  1.9424,  ...,  1.1768, -2.7773, -1.2285],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0618, -0.0101,  0.0273,  ...,  0.0568,  0.0144, -0.0027],
        [-0.0077,  0.0408,  0.0094,  ...,  0.0279,  0.0192, -0.0035],
        [ 0.0109,  0.0055,  0.0335,  ..., -0.0226,  0.0212, -0.0059],
        ...,
        [ 0.0092,  0.0183,  0.0037,  ...,  0.0061,  0.0193, -0.0088],
        [-0.0066, -0.0039, -0.0108,  ..., -0.0315,  0.0235,  0.0063],
        [ 0.0150, -0.0031,  0.0221,  ...,  0.0283,  0.0327,  0.0104]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.4380, -2.8320,  1.3672,  ...,  1.1914, -2.6328, -1.1074]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 04:49:58 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of down is up
The opposite of toward is away
The opposite of inbound is outbound
The opposite of interior is exterior
The opposite of climb is descend
The opposite of backward is forward
The opposite of input is output
The opposite of employ is
2024-07-31 04:49:58 root INFO     [order_1_approx] starting weight calculation for The opposite of climb is descend
The opposite of inbound is outbound
The opposite of backward is forward
The opposite of toward is away
The opposite of input is output
The opposite of interior is exterior
The opposite of employ is dismiss
The opposite of down is
2024-07-31 04:49:59 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-31 04:51:28 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 9.8877e-02,  5.1392e-02, -6.0089e-02,  ...,  4.8157e-02,
         4.2358e-02, -6.1035e-05], device='cuda:0', dtype=torch.float16,
       grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.3452, -6.1250,  2.0840,  ..., -6.5000, -1.7129, -3.0840],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 6.1607e-04,  1.9569e-03,  2.4662e-03,  ...,  3.5114e-03,
         -1.3191e-02,  1.1276e-02],
        [ 3.8166e-03,  2.3376e-02,  1.0712e-02,  ...,  6.6757e-06,
          6.5613e-03, -3.2074e-02],
        [-2.3758e-02,  6.2485e-03,  2.7237e-02,  ..., -1.0967e-03,
          1.6769e-02,  5.4359e-03],
        ...,
        [ 1.0521e-02,  2.5345e-02, -3.7346e-03,  ...,  3.0411e-02,
          2.3788e-02, -1.1620e-02],
        [-2.2221e-03, -6.0272e-03, -7.7362e-03,  ..., -1.5259e-05,
         -9.0637e-03,  6.4316e-03],
        [-7.7591e-03,  3.1471e-05, -1.2726e-02,  ..., -9.8495e-03,
          3.7594e-03,  1.5015e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.1628, -5.7812,  2.1699,  ..., -5.5039, -2.0957, -3.1699]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 04:51:29 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for In the United Kingdom, the city of brighton is in the county of sussex
In the United Kingdom, the city of aberdeen is in the county of aberdeenshire
In the United Kingdom, the city of dundee is in the county of lowlands
In the United Kingdom, the city of chester is in the county of cheshire
In the United Kingdom, the city of newcastle is in the county of northumberland
In the United Kingdom, the city of plymouth is in the county of devon
In the United Kingdom, the city of crawley is in the county of sussex
In the United Kingdom, the city of inverness is in the county of
2024-07-31 04:51:29 root INFO     [order_1_approx] starting weight calculation for In the United Kingdom, the city of dundee is in the county of lowlands
In the United Kingdom, the city of aberdeen is in the county of aberdeenshire
In the United Kingdom, the city of crawley is in the county of sussex
In the United Kingdom, the city of chester is in the county of cheshire
In the United Kingdom, the city of plymouth is in the county of devon
In the United Kingdom, the city of brighton is in the county of sussex
In the United Kingdom, the city of inverness is in the county of highlands
In the United Kingdom, the city of newcastle is in the county of
2024-07-31 04:51:29 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-31 04:52:30 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1300, -0.2881, -0.2074,  ..., -0.1997, -0.1207,  0.2148],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.6426, -4.6172,  0.8496,  ...,  0.4746, -0.2476, -3.6816],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0414, -0.0659, -0.0398,  ...,  0.0002, -0.0087,  0.0241],
        [-0.0046,  0.0964, -0.0035,  ...,  0.0295,  0.0104, -0.0013],
        [-0.0321, -0.0352,  0.0054,  ...,  0.0067, -0.0153, -0.0058],
        ...,
        [ 0.0273,  0.0124,  0.0056,  ...,  0.0107,  0.0077, -0.0173],
        [ 0.0274,  0.0162,  0.0351,  ...,  0.0101,  0.0639, -0.0062],
        [-0.0189, -0.0233, -0.0137,  ...,  0.0073,  0.0297,  0.0212]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.7227, -4.0938,  0.8799,  ..., -0.0552, -0.9419, -3.7969]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 04:52:32 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of climb is descend
The opposite of inbound is outbound
The opposite of backward is forward
The opposite of toward is away
The opposite of input is output
The opposite of interior is exterior
The opposite of employ is dismiss
The opposite of down is
2024-07-31 04:52:32 root INFO     [order_1_approx] starting weight calculation for The opposite of climb is descend
The opposite of input is output
The opposite of employ is dismiss
The opposite of down is up
The opposite of inbound is outbound
The opposite of toward is away
The opposite of interior is exterior
The opposite of backward is
2024-07-31 04:52:32 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-31 04:54:40 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3408,  0.2288, -0.2871,  ...,  0.3711, -0.4233,  0.3699],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.6055, -3.6211,  2.0762,  ..., -2.4492, -2.7852, -0.8169],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 3.9062e-02, -2.3956e-02,  2.0233e-02,  ...,  8.3084e-03,
          2.9221e-03, -1.4450e-02],
        [ 4.6997e-03,  1.4610e-03,  3.0731e-02,  ...,  3.6163e-02,
          4.7989e-03, -3.0106e-02],
        [-4.1237e-03, -7.7972e-03,  2.9617e-02,  ...,  1.6388e-02,
         -1.7548e-04, -2.0752e-02],
        ...,
        [-2.0504e-05, -1.6602e-02,  2.0523e-03,  ...,  4.2542e-02,
         -1.4473e-02, -2.5864e-03],
        [ 3.5278e-02, -2.1103e-02, -7.6294e-03,  ...,  2.0447e-03,
          2.9846e-02,  5.3253e-03],
        [ 1.2680e-02, -2.8839e-02, -9.2926e-03,  ..., -1.2039e-02,
         -2.9724e-02,  1.8829e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.6719, -3.4688,  2.0898,  ..., -2.2988, -3.0488, -0.4539]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 04:54:41 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for In the United Kingdom, the city of dundee is in the county of lowlands
In the United Kingdom, the city of aberdeen is in the county of aberdeenshire
In the United Kingdom, the city of crawley is in the county of sussex
In the United Kingdom, the city of chester is in the county of cheshire
In the United Kingdom, the city of plymouth is in the county of devon
In the United Kingdom, the city of brighton is in the county of sussex
In the United Kingdom, the city of inverness is in the county of highlands
In the United Kingdom, the city of newcastle is in the county of
2024-07-31 04:54:41 root INFO     [order_1_approx] starting weight calculation for In the United Kingdom, the city of newcastle is in the county of northumberland
In the United Kingdom, the city of dundee is in the county of lowlands
In the United Kingdom, the city of brighton is in the county of sussex
In the United Kingdom, the city of aberdeen is in the county of aberdeenshire
In the United Kingdom, the city of chester is in the county of cheshire
In the United Kingdom, the city of inverness is in the county of highlands
In the United Kingdom, the city of plymouth is in the county of devon
In the United Kingdom, the city of crawley is in the county of
2024-07-31 04:54:41 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-31 04:55:04 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2023,  0.2412, -0.4006,  ..., -0.1348,  0.2075,  0.1134],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.4316, -2.1211,  1.5811,  ..., -0.5342, -2.5078, -0.8057],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0609,  0.0036,  0.0058,  ..., -0.0139, -0.0174,  0.0187],
        [-0.0124,  0.0398,  0.0002,  ...,  0.0211, -0.0038, -0.0188],
        [ 0.0147, -0.0503,  0.0108,  ...,  0.0371,  0.0111, -0.0051],
        ...,
        [-0.0113,  0.0359, -0.0007,  ...,  0.0371,  0.0326,  0.0026],
        [-0.0069, -0.0156, -0.0103,  ...,  0.0250,  0.0609, -0.0202],
        [-0.0082,  0.0115,  0.0118,  ..., -0.0293, -0.0282,  0.0271]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.0039, -2.0781,  1.4531,  ..., -0.7231, -2.7363, -1.3418]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 04:55:05 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of climb is descend
The opposite of input is output
The opposite of employ is dismiss
The opposite of down is up
The opposite of inbound is outbound
The opposite of toward is away
The opposite of interior is exterior
The opposite of backward is
2024-07-31 04:55:05 root INFO     [order_1_approx] starting weight calculation for The opposite of down is up
The opposite of inbound is outbound
The opposite of climb is descend
The opposite of backward is forward
The opposite of interior is exterior
The opposite of employ is dismiss
The opposite of input is output
The opposite of toward is
2024-07-31 04:55:05 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-31 04:57:38 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1700, -0.1393, -0.3948,  ..., -0.2776, -0.0041,  0.3562],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.4160, -3.3789,  1.4902,  ..., -1.4014, -0.8936, -4.4688],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 3.1097e-02, -5.2979e-02, -1.9852e-02,  ...,  9.7900e-02,
         -6.1493e-03,  2.0416e-02],
        [-6.2027e-03,  3.4515e-02, -8.1635e-03,  ...,  2.6276e-02,
         -5.2223e-03, -2.2087e-03],
        [-9.3699e-04, -2.3098e-03, -1.2493e-04,  ...,  3.9093e-02,
         -2.0645e-02,  1.8204e-02],
        ...,
        [ 1.4030e-02, -5.6076e-03, -2.7122e-03,  ...,  4.6600e-02,
          2.6703e-05, -1.8215e-03],
        [ 1.4153e-02, -3.5057e-03,  4.4922e-02,  ...,  8.8959e-03,
          5.0598e-02, -6.9809e-03],
        [ 2.4399e-02, -1.3237e-02, -2.8473e-02,  ...,  4.2664e-02,
          4.7607e-02,  8.8272e-03]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.3672, -3.2656,  1.9121,  ..., -0.8955, -1.1631, -3.6973]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 04:57:39 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of down is up
The opposite of inbound is outbound
The opposite of climb is descend
The opposite of backward is forward
The opposite of interior is exterior
The opposite of employ is dismiss
The opposite of input is output
The opposite of toward is
2024-07-31 04:57:39 root INFO     [order_1_approx] starting weight calculation for The opposite of down is up
The opposite of input is output
The opposite of backward is forward
The opposite of employ is dismiss
The opposite of interior is exterior
The opposite of inbound is outbound
The opposite of toward is away
The opposite of climb is
2024-07-31 04:57:39 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-31 04:57:45 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3020,  0.0464, -0.2280,  ...,  0.5679, -0.0192, -0.0517],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.8887, -6.8945,  0.7183,  ..., -3.8984,  0.8242, -0.9209],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0248,  0.0124, -0.0025,  ..., -0.0010, -0.0264, -0.0128],
        [-0.0025,  0.0347,  0.0176,  ...,  0.0087, -0.0061, -0.0352],
        [-0.0254, -0.0009,  0.0042,  ..., -0.0017, -0.0045,  0.0303],
        ...,
        [-0.0086,  0.0083, -0.0029,  ...,  0.0170, -0.0115, -0.0222],
        [ 0.0055,  0.0004,  0.0222,  ...,  0.0274, -0.0002,  0.0011],
        [-0.0100,  0.0110, -0.0197,  ..., -0.0066, -0.0270, -0.0179]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.7637, -7.4336,  0.7217,  ..., -4.2344,  0.7339, -1.5312]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 04:57:46 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for In the United Kingdom, the city of newcastle is in the county of northumberland
In the United Kingdom, the city of dundee is in the county of lowlands
In the United Kingdom, the city of brighton is in the county of sussex
In the United Kingdom, the city of aberdeen is in the county of aberdeenshire
In the United Kingdom, the city of chester is in the county of cheshire
In the United Kingdom, the city of inverness is in the county of highlands
In the United Kingdom, the city of plymouth is in the county of devon
In the United Kingdom, the city of crawley is in the county of
2024-07-31 04:57:46 root INFO     [order_1_approx] starting weight calculation for In the United Kingdom, the city of crawley is in the county of sussex
In the United Kingdom, the city of aberdeen is in the county of aberdeenshire
In the United Kingdom, the city of inverness is in the county of highlands
In the United Kingdom, the city of newcastle is in the county of northumberland
In the United Kingdom, the city of chester is in the county of cheshire
In the United Kingdom, the city of dundee is in the county of lowlands
In the United Kingdom, the city of plymouth is in the county of devon
In the United Kingdom, the city of brighton is in the county of
2024-07-31 04:57:46 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-31 05:00:12 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0526, -0.0426,  0.0664,  ..., -0.3442, -0.4517,  0.4268],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.8418, -1.4043,  3.4336,  ..., -0.9565, -4.1133, -1.3848],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0541, -0.0139, -0.0261,  ...,  0.0171,  0.0155,  0.0161],
        [ 0.0019,  0.0431, -0.0186,  ...,  0.0157, -0.0072, -0.0111],
        [-0.0057,  0.0031, -0.0089,  ..., -0.0262, -0.0195,  0.0113],
        ...,
        [ 0.0003,  0.0316, -0.0218,  ...,  0.0186,  0.0142, -0.0043],
        [-0.0048,  0.0250,  0.0136,  ...,  0.0108,  0.0279,  0.0162],
        [ 0.0222,  0.0211,  0.0070,  ...,  0.0229,  0.0026,  0.0118]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.6719, -1.7305,  3.4219,  ..., -1.1514, -4.3242, -2.0723]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 05:00:13 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of down is up
The opposite of input is output
The opposite of backward is forward
The opposite of employ is dismiss
The opposite of interior is exterior
The opposite of inbound is outbound
The opposite of toward is away
The opposite of climb is
2024-07-31 05:00:13 root INFO     total operator prediction time: 1230.854059457779 seconds
2024-07-31 05:00:13 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on hyponyms - misc
2024-07-31 05:00:13 root INFO     building operator hyponyms - misc
2024-07-31 05:00:14 root INFO     [order_1_approx] starting weight calculation for A more specific term for a cup is teacup
A more specific term for a camera is camcorder
A more specific term for a dress is gown
A more specific term for a cushion is pincushion
A more specific term for a car is limousine
A more specific term for a month is january
A more specific term for a mixer is blender
A more specific term for a bag is
2024-07-31 05:00:14 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-31 05:01:01 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3840,  0.0140,  0.0364,  ...,  0.6660, -0.0634, -0.1379],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.7539, -6.4844,  0.1650,  ..., -3.9863,  0.8125, -0.6758],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0076, -0.0044,  0.0061,  ..., -0.0125, -0.0049, -0.0195],
        [ 0.0025,  0.0378,  0.0295,  ...,  0.0226, -0.0170, -0.0078],
        [-0.0241, -0.0165,  0.0127,  ...,  0.0172, -0.0038,  0.0176],
        ...,
        [ 0.0176,  0.0007, -0.0014,  ...,  0.0100, -0.0010,  0.0021],
        [ 0.0064,  0.0080,  0.0028,  ...,  0.0221,  0.0074,  0.0010],
        [-0.0010,  0.0044,  0.0026,  ..., -0.0021, -0.0026,  0.0076]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.8730, -6.8203, -0.1733,  ..., -3.9414,  0.6270, -0.6953]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 05:01:02 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for In the United Kingdom, the city of crawley is in the county of sussex
In the United Kingdom, the city of aberdeen is in the county of aberdeenshire
In the United Kingdom, the city of inverness is in the county of highlands
In the United Kingdom, the city of newcastle is in the county of northumberland
In the United Kingdom, the city of chester is in the county of cheshire
In the United Kingdom, the city of dundee is in the county of lowlands
In the United Kingdom, the city of plymouth is in the county of devon
In the United Kingdom, the city of brighton is in the county of
2024-07-31 05:01:02 root INFO     [order_1_approx] starting weight calculation for In the United Kingdom, the city of chester is in the county of cheshire
In the United Kingdom, the city of brighton is in the county of sussex
In the United Kingdom, the city of aberdeen is in the county of aberdeenshire
In the United Kingdom, the city of dundee is in the county of lowlands
In the United Kingdom, the city of inverness is in the county of highlands
In the United Kingdom, the city of newcastle is in the county of northumberland
In the United Kingdom, the city of crawley is in the county of sussex
In the United Kingdom, the city of plymouth is in the county of
2024-07-31 05:01:02 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-31 05:02:47 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3416,  0.2727, -0.0374,  ...,  0.3188, -0.4106, -0.2544],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 5.1133, -3.4258, -3.5215,  ...,  0.5322,  1.0840,  1.6816],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0293, -0.0058, -0.0150,  ..., -0.0012, -0.0239,  0.0242],
        [-0.0119,  0.0484, -0.0084,  ..., -0.0081,  0.0137, -0.0137],
        [ 0.0220, -0.0016,  0.0616,  ...,  0.0378, -0.0196,  0.0081],
        ...,
        [ 0.0154,  0.0189, -0.0116,  ...,  0.0146,  0.0092, -0.0344],
        [-0.0224,  0.0050, -0.0114,  ...,  0.0016,  0.0341, -0.0126],
        [-0.0178,  0.0220, -0.0224,  ..., -0.0053,  0.0125,  0.0415]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.7031, -3.3711, -3.3066,  ...,  0.5483,  1.0420,  1.2393]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 05:02:48 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more specific term for a cup is teacup
A more specific term for a camera is camcorder
A more specific term for a dress is gown
A more specific term for a cushion is pincushion
A more specific term for a car is limousine
A more specific term for a month is january
A more specific term for a mixer is blender
A more specific term for a bag is
2024-07-31 05:02:48 root INFO     [order_1_approx] starting weight calculation for A more specific term for a mixer is blender
A more specific term for a cup is teacup
A more specific term for a bag is pouch
A more specific term for a car is limousine
A more specific term for a dress is gown
A more specific term for a camera is camcorder
A more specific term for a cushion is pincushion
A more specific term for a month is
2024-07-31 05:02:48 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-31 05:04:11 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1487, -0.0059,  0.0085,  ...,  0.2866, -0.2666, -0.0603],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 5.7383, -7.6484,  2.8281,  ..., -5.7617,  0.5938, -1.4922],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0060, -0.0011,  0.0021,  ..., -0.0063, -0.0064,  0.0087],
        [-0.0043,  0.0148,  0.0098,  ...,  0.0217,  0.0120, -0.0137],
        [-0.0283,  0.0091, -0.0005,  ...,  0.0298,  0.0126, -0.0010],
        ...,
        [-0.0060,  0.0091,  0.0008,  ...,  0.0268,  0.0143, -0.0271],
        [-0.0041, -0.0028, -0.0077,  ..., -0.0120, -0.0129,  0.0065],
        [-0.0082,  0.0041, -0.0039,  ...,  0.0051, -0.0066, -0.0166]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 5.4609, -7.7109,  2.6777,  ..., -5.5039,  0.7065, -1.5186]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 05:04:12 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for In the United Kingdom, the city of chester is in the county of cheshire
In the United Kingdom, the city of brighton is in the county of sussex
In the United Kingdom, the city of aberdeen is in the county of aberdeenshire
In the United Kingdom, the city of dundee is in the county of lowlands
In the United Kingdom, the city of inverness is in the county of highlands
In the United Kingdom, the city of newcastle is in the county of northumberland
In the United Kingdom, the city of crawley is in the county of sussex
In the United Kingdom, the city of plymouth is in the county of
2024-07-31 05:04:12 root INFO     [order_1_approx] starting weight calculation for In the United Kingdom, the city of crawley is in the county of sussex
In the United Kingdom, the city of inverness is in the county of highlands
In the United Kingdom, the city of brighton is in the county of sussex
In the United Kingdom, the city of aberdeen is in the county of aberdeenshire
In the United Kingdom, the city of dundee is in the county of lowlands
In the United Kingdom, the city of newcastle is in the county of northumberland
In the United Kingdom, the city of plymouth is in the county of devon
In the United Kingdom, the city of chester is in the county of
2024-07-31 05:04:12 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-31 05:05:20 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1699, -0.2061, -0.4177,  ..., -0.0196,  0.0294,  0.3108],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.3777, -3.7129,  1.9717,  ..., -0.6167,  0.5337,  0.1006],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0314,  0.0468, -0.0017,  ..., -0.0099, -0.0235,  0.0344],
        [ 0.0391,  0.0257, -0.0027,  ..., -0.0231, -0.0227, -0.0480],
        [-0.0782,  0.0385,  0.0451,  ...,  0.0211,  0.0076,  0.0726],
        ...,
        [ 0.0294,  0.0405, -0.0075,  ...,  0.0530, -0.0168, -0.0174],
        [-0.0257,  0.0177,  0.0057,  ...,  0.0141,  0.0619,  0.0350],
        [ 0.0482, -0.0019, -0.0317,  ...,  0.0122, -0.0099,  0.0211]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.2737, -3.3828, -0.3096,  ..., -1.2656,  0.8457,  1.3184]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 05:05:21 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more specific term for a mixer is blender
A more specific term for a cup is teacup
A more specific term for a bag is pouch
A more specific term for a car is limousine
A more specific term for a dress is gown
A more specific term for a camera is camcorder
A more specific term for a cushion is pincushion
A more specific term for a month is
2024-07-31 05:05:21 root INFO     [order_1_approx] starting weight calculation for A more specific term for a cup is teacup
A more specific term for a month is january
A more specific term for a camera is camcorder
A more specific term for a bag is pouch
A more specific term for a dress is gown
A more specific term for a cushion is pincushion
A more specific term for a mixer is blender
A more specific term for a car is
2024-07-31 05:05:21 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-31 05:07:20 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0961,  0.1442, -0.1238,  ...,  0.1096, -0.3828,  0.0983],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 6.3711, -5.8906,  1.2598,  ..., -4.1875,  0.3750, -1.6787],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0049, -0.0011, -0.0121,  ..., -0.0043, -0.0168, -0.0044],
        [ 0.0105,  0.0405,  0.0222,  ...,  0.0434, -0.0043, -0.0231],
        [-0.0376, -0.0013,  0.0165,  ...,  0.0310, -0.0022, -0.0097],
        ...,
        [ 0.0271,  0.0060,  0.0049,  ...,  0.0451,  0.0371, -0.0134],
        [-0.0027, -0.0029, -0.0004,  ..., -0.0142, -0.0285, -0.0035],
        [ 0.0134,  0.0008, -0.0015,  ..., -0.0173, -0.0178, -0.0078]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 5.7109, -5.6797,  1.3418,  ..., -3.6699,  0.0879, -1.8506]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 05:07:21 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for In the United Kingdom, the city of crawley is in the county of sussex
In the United Kingdom, the city of inverness is in the county of highlands
In the United Kingdom, the city of brighton is in the county of sussex
In the United Kingdom, the city of aberdeen is in the county of aberdeenshire
In the United Kingdom, the city of dundee is in the county of lowlands
In the United Kingdom, the city of newcastle is in the county of northumberland
In the United Kingdom, the city of plymouth is in the county of devon
In the United Kingdom, the city of chester is in the county of
2024-07-31 05:07:21 root INFO     total operator prediction time: 1520.2012326717377 seconds
2024-07-31 05:07:21 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on verb+ment_irreg
2024-07-31 05:07:21 root INFO     building operator verb+ment_irreg
2024-07-31 05:07:21 root INFO     [order_1_approx] starting weight calculation for To adjust results in a adjustment
To require results in a requirement
To detach results in a detachment
To punish results in a punishment
To align results in a alignment
To develop results in a development
To disagree results in a disagreement
To involve results in a
2024-07-31 05:07:21 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-31 05:07:54 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0435,  0.1392, -0.0669,  ...,  0.0515, -0.1736,  0.0517],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.8320, -7.5000,  0.0205,  ...,  0.1606, -2.5078, -0.4746],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0306, -0.0135,  0.0100,  ...,  0.0037, -0.0041,  0.0126],
        [ 0.0026,  0.0054,  0.0060,  ...,  0.0124,  0.0124, -0.0306],
        [ 0.0002,  0.0087,  0.0347,  ..., -0.0110, -0.0111,  0.0174],
        ...,
        [ 0.0066,  0.0087, -0.0128,  ...,  0.0160,  0.0349, -0.0032],
        [-0.0131,  0.0046,  0.0054,  ..., -0.0026,  0.0393, -0.0154],
        [ 0.0083, -0.0004, -0.0183,  ..., -0.0104, -0.0166,  0.0445]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.7485, -7.2578, -0.1895,  ..., -0.1475, -2.3965,  0.0591]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 05:07:55 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more specific term for a cup is teacup
A more specific term for a month is january
A more specific term for a camera is camcorder
A more specific term for a bag is pouch
A more specific term for a dress is gown
A more specific term for a cushion is pincushion
A more specific term for a mixer is blender
A more specific term for a car is
2024-07-31 05:07:55 root INFO     [order_1_approx] starting weight calculation for A more specific term for a car is limousine
A more specific term for a cup is teacup
A more specific term for a dress is gown
A more specific term for a bag is pouch
A more specific term for a mixer is blender
A more specific term for a camera is camcorder
A more specific term for a month is january
A more specific term for a cushion is
2024-07-31 05:07:55 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-31 05:09:59 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0527,  0.1790, -0.2465,  ...,  0.0454, -0.4875, -0.2080],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.2305, -3.1602,  2.2402,  ...,  2.1270,  0.3037, -4.0547],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0400, -0.0083, -0.0013,  ...,  0.0330, -0.0152,  0.0118],
        [-0.0275,  0.0346,  0.0139,  ...,  0.0141,  0.0010, -0.0058],
        [ 0.0006, -0.0260,  0.0090,  ...,  0.0081, -0.0155, -0.0255],
        ...,
        [ 0.0056,  0.0222, -0.0072,  ...,  0.0534, -0.0032,  0.0262],
        [ 0.0188,  0.0002,  0.0098,  ...,  0.0108,  0.0128, -0.0156],
        [ 0.0205,  0.0183,  0.0077,  ..., -0.0070, -0.0287,  0.0206]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.2637, -3.2461,  2.1660,  ...,  2.0371, -0.0054, -4.1562]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 05:10:00 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To adjust results in a adjustment
To require results in a requirement
To detach results in a detachment
To punish results in a punishment
To align results in a alignment
To develop results in a development
To disagree results in a disagreement
To involve results in a
2024-07-31 05:10:00 root INFO     [order_1_approx] starting weight calculation for To require results in a requirement
To involve results in a involvement
To disagree results in a disagreement
To develop results in a development
To punish results in a punishment
To align results in a alignment
To adjust results in a adjustment
To detach results in a
2024-07-31 05:10:01 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-31 05:10:24 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3147, -0.1412,  0.0650,  ...,  0.0889, -0.4092,  0.0829],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.9082, -6.0859,  1.2383,  ..., -0.3086, -2.5957,  0.6099],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0561, -0.0063, -0.0036,  ...,  0.0147, -0.0050,  0.0029],
        [ 0.0002,  0.0156,  0.0172,  ..., -0.0018,  0.0293, -0.0082],
        [ 0.0116, -0.0207,  0.0440,  ...,  0.0117, -0.0058, -0.0033],
        ...,
        [ 0.0150,  0.0167,  0.0004,  ...,  0.0375, -0.0035, -0.0184],
        [-0.0013,  0.0145, -0.0021,  ..., -0.0035,  0.0248, -0.0251],
        [-0.0123,  0.0136,  0.0030,  ...,  0.0027,  0.0098,  0.0235]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.6631, -5.5703,  1.3799,  ..., -0.1260, -2.5547,  0.7070]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 05:10:25 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more specific term for a car is limousine
A more specific term for a cup is teacup
A more specific term for a dress is gown
A more specific term for a bag is pouch
A more specific term for a mixer is blender
A more specific term for a camera is camcorder
A more specific term for a month is january
A more specific term for a cushion is
2024-07-31 05:10:25 root INFO     [order_1_approx] starting weight calculation for A more specific term for a mixer is blender
A more specific term for a camera is camcorder
A more specific term for a cup is teacup
A more specific term for a bag is pouch
A more specific term for a car is limousine
A more specific term for a cushion is pincushion
A more specific term for a month is january
A more specific term for a dress is
2024-07-31 05:10:25 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-31 05:12:38 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2064,  0.1802, -0.1798,  ..., -0.0398, -0.0715, -0.0702],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.9805, -3.4766,  0.3669,  ...,  2.4023, -1.9629, -2.3086],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0769, -0.0143,  0.0009,  ..., -0.0238,  0.0182, -0.0104],
        [-0.0298,  0.0548,  0.0107,  ...,  0.0373,  0.0013,  0.0181],
        [ 0.0035, -0.0161,  0.0239,  ..., -0.0083, -0.0132, -0.0093],
        ...,
        [ 0.0038,  0.0292,  0.0050,  ...,  0.0812, -0.0027,  0.0397],
        [-0.0032, -0.0020, -0.0184,  ...,  0.0054,  0.0394,  0.0021],
        [-0.0026,  0.0275,  0.0090,  ...,  0.0143, -0.0265,  0.0610]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.2358, -2.4297,  0.0337,  ...,  2.8613, -1.8760, -1.7998]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 05:12:39 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To require results in a requirement
To involve results in a involvement
To disagree results in a disagreement
To develop results in a development
To punish results in a punishment
To align results in a alignment
To adjust results in a adjustment
To detach results in a
2024-07-31 05:12:39 root INFO     [order_1_approx] starting weight calculation for To adjust results in a adjustment
To align results in a alignment
To disagree results in a disagreement
To require results in a requirement
To punish results in a punishment
To detach results in a detachment
To involve results in a involvement
To develop results in a
2024-07-31 05:12:39 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-31 05:12:59 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2554,  0.0101, -0.0372,  ...,  0.1492, -0.3625,  0.0094],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.8887, -4.2109, -1.0703,  ...,  1.0879, -2.3086,  2.0234],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0403, -0.0196,  0.0206,  ..., -0.0169,  0.0424,  0.0083],
        [-0.0054,  0.0446,  0.0010,  ..., -0.0075, -0.0074,  0.0066],
        [ 0.0255, -0.0170,  0.0441,  ...,  0.0093, -0.0120, -0.0191],
        ...,
        [-0.0408,  0.0024, -0.0141,  ...,  0.0144,  0.0131, -0.0234],
        [-0.0252,  0.0272, -0.0194,  ..., -0.0029,  0.0258, -0.0094],
        [ 0.0372,  0.0043,  0.0150,  ..., -0.0291, -0.0171,  0.0259]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.2949, -4.2305, -0.7671,  ...,  1.2266, -2.2949,  1.7617]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 05:13:00 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more specific term for a mixer is blender
A more specific term for a camera is camcorder
A more specific term for a cup is teacup
A more specific term for a bag is pouch
A more specific term for a car is limousine
A more specific term for a cushion is pincushion
A more specific term for a month is january
A more specific term for a dress is
2024-07-31 05:13:00 root INFO     [order_1_approx] starting weight calculation for A more specific term for a car is limousine
A more specific term for a bag is pouch
A more specific term for a cup is teacup
A more specific term for a month is january
A more specific term for a mixer is blender
A more specific term for a cushion is pincushion
A more specific term for a dress is gown
A more specific term for a camera is
2024-07-31 05:13:00 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-31 05:15:17 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0488,  0.3069,  0.0760,  ..., -0.0118, -0.3140,  0.2581],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.0117, -5.4062,  1.5420,  ...,  3.7070, -1.5146, -2.8691],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0557,  0.0128,  0.0025,  ...,  0.0092, -0.0284,  0.0173],
        [-0.0202,  0.0462, -0.0031,  ...,  0.0346,  0.0105, -0.0079],
        [-0.0109, -0.0256,  0.0292,  ...,  0.0110, -0.0031,  0.0217],
        ...,
        [ 0.0061, -0.0019, -0.0043,  ...,  0.0495, -0.0299,  0.0110],
        [ 0.0095,  0.0116,  0.0054,  ...,  0.0110,  0.0524, -0.0241],
        [ 0.0031, -0.0040, -0.0008,  ...,  0.0051, -0.0396,  0.0404]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.7070, -5.2578,  1.5713,  ...,  3.4492, -2.2832, -3.1680]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 05:15:18 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To adjust results in a adjustment
To align results in a alignment
To disagree results in a disagreement
To require results in a requirement
To punish results in a punishment
To detach results in a detachment
To involve results in a involvement
To develop results in a
2024-07-31 05:15:18 root INFO     [order_1_approx] starting weight calculation for To develop results in a development
To punish results in a punishment
To require results in a requirement
To adjust results in a adjustment
To detach results in a detachment
To involve results in a involvement
To align results in a alignment
To disagree results in a
2024-07-31 05:15:18 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-31 05:15:33 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1099, -0.0969, -0.0378,  ..., -0.0914, -0.1708, -0.2487],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.0737, -2.6289, -0.0469,  ..., -0.1689,  1.6387, -0.6621],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0378, -0.0128, -0.0156,  ...,  0.0107, -0.0017,  0.0208],
        [ 0.0119,  0.0622, -0.0127,  ...,  0.0014,  0.0112, -0.0015],
        [-0.0136,  0.0270,  0.0361,  ..., -0.0094, -0.0161, -0.0073],
        ...,
        [ 0.0209, -0.0045, -0.0003,  ...,  0.0399,  0.0173,  0.0159],
        [-0.0304,  0.0048,  0.0022,  ...,  0.0052,  0.0482, -0.0214],
        [-0.0169,  0.0041,  0.0077,  ..., -0.0066, -0.0185,  0.0520]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.2405, -2.3301,  0.2100,  ..., -0.1595,  2.3359, -0.6934]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 05:15:34 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more specific term for a car is limousine
A more specific term for a bag is pouch
A more specific term for a cup is teacup
A more specific term for a month is january
A more specific term for a mixer is blender
A more specific term for a cushion is pincushion
A more specific term for a dress is gown
A more specific term for a camera is
2024-07-31 05:15:35 root INFO     [order_1_approx] starting weight calculation for A more specific term for a dress is gown
A more specific term for a bag is pouch
A more specific term for a month is january
A more specific term for a cushion is pincushion
A more specific term for a camera is camcorder
A more specific term for a cup is teacup
A more specific term for a car is limousine
A more specific term for a mixer is
2024-07-31 05:15:35 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-31 05:17:56 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2058,  0.1586, -0.1799,  ...,  0.2563, -0.2615, -0.1763],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.4414, -4.3594,  1.8965,  ..., -0.0287,  0.9092, -0.8115],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0196,  0.0005, -0.0179,  ..., -0.0121,  0.0083, -0.0029],
        [ 0.0417,  0.0263,  0.0435,  ..., -0.0092,  0.0251,  0.0369],
        [ 0.0061, -0.0132,  0.0009,  ...,  0.0082, -0.0135,  0.0104],
        ...,
        [ 0.0195,  0.0032,  0.0424,  ...,  0.0366, -0.0095,  0.0335],
        [-0.0183, -0.0181, -0.0064,  ...,  0.0182,  0.0140, -0.0005],
        [-0.0050,  0.0018,  0.0268,  ...,  0.0064, -0.0377,  0.0519]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.9922, -3.3848,  1.5469,  ...,  0.5854,  0.8662, -0.4780]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 05:17:57 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To develop results in a development
To punish results in a punishment
To require results in a requirement
To adjust results in a adjustment
To detach results in a detachment
To involve results in a involvement
To align results in a alignment
To disagree results in a
2024-07-31 05:17:57 root INFO     [order_1_approx] starting weight calculation for To disagree results in a disagreement
To develop results in a development
To involve results in a involvement
To detach results in a detachment
To align results in a alignment
To adjust results in a adjustment
To punish results in a punishment
To require results in a
2024-07-31 05:17:57 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-31 05:18:07 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2196, -0.0844, -0.0276,  ...,  0.6089, -0.5386, -0.1353],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.6045, -5.6133, -1.8047,  ...,  0.7910, -3.4375,  0.0215],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0609, -0.0036, -0.0077,  ...,  0.0234, -0.0022, -0.0075],
        [ 0.0321,  0.0659,  0.0109,  ..., -0.0113,  0.0038, -0.0054],
        [-0.0084, -0.0314,  0.0561,  ..., -0.0259,  0.0193,  0.0462],
        ...,
        [ 0.0369,  0.0444, -0.0201,  ...,  0.0623, -0.0269, -0.0320],
        [-0.0471, -0.0048, -0.0264,  ...,  0.0316,  0.0940, -0.0115],
        [ 0.0139,  0.0300,  0.0129,  ..., -0.0251, -0.0360,  0.0432]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.3799, -5.5000, -1.8135,  ...,  0.8965, -3.0391, -0.0552]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 05:18:08 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more specific term for a dress is gown
A more specific term for a bag is pouch
A more specific term for a month is january
A more specific term for a cushion is pincushion
A more specific term for a camera is camcorder
A more specific term for a cup is teacup
A more specific term for a car is limousine
A more specific term for a mixer is
2024-07-31 05:18:08 root INFO     [order_1_approx] starting weight calculation for A more specific term for a bag is pouch
A more specific term for a mixer is blender
A more specific term for a car is limousine
A more specific term for a cushion is pincushion
A more specific term for a camera is camcorder
A more specific term for a month is january
A more specific term for a dress is gown
A more specific term for a cup is
2024-07-31 05:18:08 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-31 05:20:35 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0984,  0.2678, -0.1888,  ..., -0.0875, -0.2681, -0.1432],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.3828, -3.3203, -0.3384,  ...,  0.0610, -3.5859, -2.3105],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0413,  0.0063,  0.0195,  ...,  0.0250, -0.0371,  0.0273],
        [-0.0302,  0.0128, -0.0096,  ...,  0.0179, -0.0007,  0.0162],
        [-0.0072, -0.0046,  0.0417,  ...,  0.0012, -0.0158,  0.0062],
        ...,
        [ 0.0021,  0.0130,  0.0110,  ...,  0.0251,  0.0130,  0.0132],
        [ 0.0706,  0.0272, -0.0183,  ..., -0.0183,  0.0140, -0.0439],
        [-0.0008, -0.0061, -0.0193,  ...,  0.0063, -0.0110,  0.0417]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.4258, -2.9668, -0.1307,  ..., -0.0165, -4.3125, -2.3223]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 05:20:36 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To disagree results in a disagreement
To develop results in a development
To involve results in a involvement
To detach results in a detachment
To align results in a alignment
To adjust results in a adjustment
To punish results in a punishment
To require results in a
2024-07-31 05:20:36 root INFO     [order_1_approx] starting weight calculation for To develop results in a development
To require results in a requirement
To involve results in a involvement
To disagree results in a disagreement
To punish results in a punishment
To detach results in a detachment
To align results in a alignment
To adjust results in a
2024-07-31 05:20:36 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-31 05:20:39 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2283, -0.3127,  0.3235,  ...,  0.2428, -0.2698,  0.1858],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.9414, -0.3799, -1.0869,  ..., -1.0791,  0.8818, -1.0371],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0245, -0.0305, -0.0073,  ..., -0.0049,  0.0185,  0.0027],
        [ 0.0056,  0.0420, -0.0038,  ...,  0.0063, -0.0130,  0.0033],
        [ 0.0162,  0.0253,  0.0534,  ...,  0.0159, -0.0155,  0.0104],
        ...,
        [ 0.0044, -0.0058,  0.0147,  ...,  0.0466, -0.0046, -0.0050],
        [-0.0119, -0.0309, -0.0124,  ..., -0.0164,  0.0096, -0.0294],
        [-0.0083,  0.0080,  0.0040,  ..., -0.0064,  0.0066,  0.0260]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.8516, -0.5308, -0.9746,  ..., -0.9336,  1.1211, -0.6201]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 05:20:40 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more specific term for a bag is pouch
A more specific term for a mixer is blender
A more specific term for a car is limousine
A more specific term for a cushion is pincushion
A more specific term for a camera is camcorder
A more specific term for a month is january
A more specific term for a dress is gown
A more specific term for a cup is
2024-07-31 05:20:40 root INFO     total operator prediction time: 1226.704711675644 seconds
2024-07-31 05:20:40 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on hypernyms - animals
2024-07-31 05:20:40 root INFO     building operator hypernyms - animals
2024-07-31 05:20:40 root INFO     [order_1_approx] starting weight calculation for The porcupine falls into the category of rodent
The gibbon falls into the category of primate
The chicken falls into the category of fowl
The fox falls into the category of canine
The mouse falls into the category of rodent
The chinchilla falls into the category of rodent
The mamba falls into the category of snake
The ant falls into the category of
2024-07-31 05:20:40 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-31 05:23:13 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0933, -0.2240, -0.1359,  ..., -0.0795, -0.3164, -0.2947],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.7935, -4.1406,  1.9160,  ..., -2.0117, -4.6641, -1.7217],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0610,  0.0383, -0.0044,  ...,  0.0002, -0.0083, -0.0302],
        [ 0.0174,  0.0380,  0.0244,  ...,  0.0168,  0.0027, -0.0244],
        [ 0.0105,  0.0425,  0.0551,  ..., -0.0390, -0.0035,  0.0065],
        ...,
        [ 0.0195,  0.0122,  0.0057,  ...,  0.0666,  0.0047,  0.0061],
        [-0.0205,  0.0240,  0.0126,  ..., -0.0102,  0.0318,  0.0099],
        [-0.0192, -0.0353, -0.0078,  ..., -0.0002,  0.0089,  0.0382]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.3547, -4.2578,  0.9668,  ..., -2.0293, -5.1445, -0.8413]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 05:23:14 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2427,  0.2656, -0.5195,  ..., -0.1826, -0.0632,  0.0267],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.2070, -3.1699, -1.8232,  ...,  1.2930, -1.7852, -1.0039],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0376,  0.0057,  0.0066,  ...,  0.0323, -0.0194,  0.0255],
        [-0.0112,  0.0170,  0.0103,  ..., -0.0078,  0.0076, -0.0014],
        [-0.0255, -0.0285,  0.0189,  ...,  0.0142, -0.0076,  0.0058],
        ...,
        [ 0.0032,  0.0129,  0.0051,  ...,  0.0432,  0.0103,  0.0037],
        [-0.0012,  0.0008, -0.0218,  ..., -0.0170,  0.0276, -0.0071],
        [ 0.0166,  0.0004, -0.0134,  ...,  0.0131, -0.0221,  0.0176]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.2402, -2.8516, -1.5547,  ...,  1.0742, -1.8623, -1.3779]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 05:23:14 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The porcupine falls into the category of rodent
The gibbon falls into the category of primate
The chicken falls into the category of fowl
The fox falls into the category of canine
The mouse falls into the category of rodent
The chinchilla falls into the category of rodent
The mamba falls into the category of snake
The ant falls into the category of
2024-07-31 05:23:14 root INFO     [order_1_approx] starting weight calculation for The fox falls into the category of canine
The mamba falls into the category of snake
The porcupine falls into the category of rodent
The gibbon falls into the category of primate
The chinchilla falls into the category of rodent
The chicken falls into the category of fowl
The ant falls into the category of insect
The mouse falls into the category of
2024-07-31 05:23:14 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-31 05:23:15 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To develop results in a development
To require results in a requirement
To involve results in a involvement
To disagree results in a disagreement
To punish results in a punishment
To detach results in a detachment
To align results in a alignment
To adjust results in a
2024-07-31 05:23:15 root INFO     [order_1_approx] starting weight calculation for To align results in a alignment
To develop results in a development
To disagree results in a disagreement
To require results in a requirement
To adjust results in a adjustment
To detach results in a detachment
To involve results in a involvement
To punish results in a
2024-07-31 05:23:15 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-31 05:25:47 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.3291, -0.3479, -0.2778,  ...,  0.1580, -0.3464, -0.0612],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.6650, -3.9141,  0.7773,  ..., -3.2246, -5.6172,  0.1641],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0427, -0.0243, -0.0065,  ...,  0.0024, -0.0204,  0.0047],
        [ 0.0015,  0.0384,  0.0114,  ...,  0.0021,  0.0154, -0.0278],
        [ 0.0070,  0.0051,  0.0493,  ..., -0.0313, -0.0019,  0.0079],
        ...,
        [ 0.0032,  0.0062,  0.0050,  ...,  0.0616,  0.0049, -0.0047],
        [-0.0137,  0.0098, -0.0089,  ..., -0.0171,  0.0696,  0.0018],
        [-0.0245, -0.0284, -0.0087,  ...,  0.0099, -0.0118,  0.0593]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.3213, -3.7734,  0.6387,  ..., -3.1211, -5.5273,  0.2480]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 05:25:48 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The fox falls into the category of canine
The mamba falls into the category of snake
The porcupine falls into the category of rodent
The gibbon falls into the category of primate
The chinchilla falls into the category of rodent
The chicken falls into the category of fowl
The ant falls into the category of insect
The mouse falls into the category of
2024-07-31 05:25:48 root INFO     [order_1_approx] starting weight calculation for The ant falls into the category of insect
The gibbon falls into the category of primate
The fox falls into the category of canine
The chicken falls into the category of fowl
The mamba falls into the category of snake
The porcupine falls into the category of rodent
The mouse falls into the category of rodent
The chinchilla falls into the category of
2024-07-31 05:25:48 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-31 05:25:53 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0969,  0.3311, -0.1978,  ...,  0.2054, -0.5034, -0.1426],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.6172, -4.6914,  0.6318,  ...,  0.5371,  0.7056, -0.0596],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0402, -0.0017,  0.0113,  ..., -0.0009, -0.0183,  0.0276],
        [-0.0218,  0.0227,  0.0096,  ...,  0.0281,  0.0083, -0.0204],
        [-0.0009, -0.0159,  0.0136,  ..., -0.0360, -0.0021,  0.0076],
        ...,
        [ 0.0078,  0.0065,  0.0007,  ...,  0.0102,  0.0127,  0.0276],
        [ 0.0151,  0.0172, -0.0200,  ...,  0.0099, -0.0021, -0.0203],
        [-0.0021, -0.0019, -0.0036,  ...,  0.0074, -0.0355,  0.0473]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.6641, -4.4102,  0.8657,  ...,  0.7100,  0.4470,  0.2974]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 05:25:54 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To align results in a alignment
To develop results in a development
To disagree results in a disagreement
To require results in a requirement
To adjust results in a adjustment
To detach results in a detachment
To involve results in a involvement
To punish results in a
2024-07-31 05:25:54 root INFO     [order_1_approx] starting weight calculation for To involve results in a involvement
To disagree results in a disagreement
To develop results in a development
To punish results in a punishment
To detach results in a detachment
To require results in a requirement
To adjust results in a adjustment
To align results in a
2024-07-31 05:25:54 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-31 05:28:21 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1505, -0.5479, -0.4065,  ...,  0.3044, -0.1505,  0.1326],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.4014, -4.8359,  1.2256,  ..., -2.3438, -5.5391, -1.1514],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0539, -0.0200, -0.0134,  ...,  0.0028, -0.0194, -0.0078],
        [-0.0009,  0.0368, -0.0003,  ..., -0.0144,  0.0242, -0.0348],
        [-0.0156,  0.0172,  0.0436,  ..., -0.0038, -0.0061, -0.0056],
        ...,
        [ 0.0184,  0.0225, -0.0061,  ...,  0.0716,  0.0090,  0.0156],
        [-0.0152, -0.0166, -0.0002,  ..., -0.0042,  0.0692,  0.0028],
        [-0.0089, -0.0080, -0.0210,  ..., -0.0074,  0.0059,  0.0460]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.1670, -4.9531,  0.9277,  ..., -2.5723, -4.9492, -0.8584]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 05:28:22 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The ant falls into the category of insect
The gibbon falls into the category of primate
The fox falls into the category of canine
The chicken falls into the category of fowl
The mamba falls into the category of snake
The porcupine falls into the category of rodent
The mouse falls into the category of rodent
The chinchilla falls into the category of
2024-07-31 05:28:22 root INFO     [order_1_approx] starting weight calculation for The chicken falls into the category of fowl
The mouse falls into the category of rodent
The fox falls into the category of canine
The porcupine falls into the category of rodent
The ant falls into the category of insect
The mamba falls into the category of snake
The chinchilla falls into the category of rodent
The gibbon falls into the category of
2024-07-31 05:28:22 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-31 05:28:31 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1804,  0.3245, -0.4331,  ...,  0.2240, -0.2722, -0.0555],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.4336, -2.9707, -0.9834,  ...,  3.3066, -2.1270, -0.1804],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0349,  0.0195, -0.0024,  ...,  0.0132, -0.0130,  0.0311],
        [-0.0075,  0.0467,  0.0020,  ...,  0.0002,  0.0078, -0.0066],
        [-0.0074, -0.0140,  0.0253,  ..., -0.0041, -0.0053,  0.0079],
        ...,
        [ 0.0126,  0.0053,  0.0109,  ...,  0.0379, -0.0089, -0.0054],
        [-0.0175,  0.0009, -0.0144,  ..., -0.0002,  0.0491, -0.0183],
        [ 0.0059, -0.0102,  0.0157,  ...,  0.0171, -0.0348,  0.0419]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.9258, -2.6836, -0.6133,  ...,  3.2051, -1.9199, -0.0680]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 05:28:32 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To involve results in a involvement
To disagree results in a disagreement
To develop results in a development
To punish results in a punishment
To detach results in a detachment
To require results in a requirement
To adjust results in a adjustment
To align results in a
2024-07-31 05:28:32 root INFO     total operator prediction time: 1270.95579123497 seconds
2024-07-31 05:28:32 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on noun+less_reg
2024-07-31 05:28:32 root INFO     building operator noun+less_reg
2024-07-31 05:28:32 root INFO     [order_1_approx] starting weight calculation for Something without remorse is remorseless
Something without goal is goalless
Something without error is errorless
Something without defence is defenceless
Something without friend is friendless
Something without god is godless
Something without leg is legless
Something without odor is
2024-07-31 05:28:32 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-31 05:30:55 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3367, -0.1621,  0.1829,  ...,  0.2256, -0.8018,  0.5527],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.6855, -3.9395,  2.0117,  ..., -3.7715, -7.1484,  1.4102],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0727,  0.0049, -0.0066,  ..., -0.0015, -0.0041, -0.0159],
        [ 0.0028,  0.0264, -0.0147,  ...,  0.0175,  0.0123, -0.0074],
        [-0.0128,  0.0066,  0.0273,  ..., -0.0167, -0.0034, -0.0166],
        ...,
        [ 0.0153,  0.0318, -0.0134,  ...,  0.0344,  0.0071,  0.0004],
        [ 0.0007, -0.0070, -0.0110,  ...,  0.0205,  0.0262, -0.0150],
        [-0.0012, -0.0122, -0.0125,  ..., -0.0071, -0.0011,  0.0457]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.0449, -3.6836,  1.4844,  ..., -3.4375, -7.4375,  1.4268]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 05:30:56 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The chicken falls into the category of fowl
The mouse falls into the category of rodent
The fox falls into the category of canine
The porcupine falls into the category of rodent
The ant falls into the category of insect
The mamba falls into the category of snake
The chinchilla falls into the category of rodent
The gibbon falls into the category of
2024-07-31 05:30:57 root INFO     [order_1_approx] starting weight calculation for The mouse falls into the category of rodent
The chinchilla falls into the category of rodent
The chicken falls into the category of fowl
The gibbon falls into the category of primate
The ant falls into the category of insect
The fox falls into the category of canine
The porcupine falls into the category of rodent
The mamba falls into the category of
2024-07-31 05:30:57 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-31 05:31:10 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0657, -0.3091, -0.0344,  ..., -0.4155, -0.0082, -0.2214],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.3350, -4.1328, -0.7661,  ..., -4.4414, -6.7500, -1.5850],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0435, -0.0119,  0.0167,  ...,  0.0244,  0.0022,  0.0132],
        [ 0.0188,  0.0249, -0.0060,  ..., -0.0056,  0.0062,  0.0075],
        [-0.0024, -0.0110,  0.0475,  ...,  0.0051, -0.0118,  0.0105],
        ...,
        [ 0.0174,  0.0108,  0.0092,  ...,  0.0383, -0.0075, -0.0125],
        [ 0.0109, -0.0146,  0.0003,  ..., -0.0153,  0.0108, -0.0224],
        [ 0.0153, -0.0108,  0.0097,  ...,  0.0258, -0.0189, -0.0019]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.5586, -4.6406, -0.3240,  ..., -4.6484, -6.6328, -1.7080]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 05:31:11 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Something without remorse is remorseless
Something without goal is goalless
Something without error is errorless
Something without defence is defenceless
Something without friend is friendless
Something without god is godless
Something without leg is legless
Something without odor is
2024-07-31 05:31:11 root INFO     [order_1_approx] starting weight calculation for Something without defence is defenceless
Something without error is errorless
Something without odor is odorless
Something without friend is friendless
Something without leg is legless
Something without remorse is remorseless
Something without goal is goalless
Something without god is
2024-07-31 05:31:11 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-31 05:33:30 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1287, -0.1433, -0.3438,  ...,  0.2314, -0.5928, -0.0849],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.0859, -4.3125,  2.5645,  ..., -1.7109, -4.5352, -0.1777],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0574,  0.0117,  0.0062,  ...,  0.0118, -0.0050,  0.0045],
        [-0.0216,  0.0707, -0.0055,  ...,  0.0036,  0.0047, -0.0205],
        [ 0.0082, -0.0236,  0.0740,  ..., -0.0148, -0.0107,  0.0048],
        ...,
        [-0.0015,  0.0166, -0.0035,  ...,  0.0838,  0.0252, -0.0004],
        [ 0.0014,  0.0214,  0.0107,  ...,  0.0068,  0.0748, -0.0026],
        [-0.0269, -0.0002, -0.0068,  ..., -0.0004,  0.0085,  0.0524]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.0605, -4.7812,  2.0254,  ..., -1.7061, -5.1250, -0.0343]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 05:33:31 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The mouse falls into the category of rodent
The chinchilla falls into the category of rodent
The chicken falls into the category of fowl
The gibbon falls into the category of primate
The ant falls into the category of insect
The fox falls into the category of canine
The porcupine falls into the category of rodent
The mamba falls into the category of
2024-07-31 05:33:31 root INFO     [order_1_approx] starting weight calculation for The gibbon falls into the category of primate
The ant falls into the category of insect
The chicken falls into the category of fowl
The fox falls into the category of canine
The chinchilla falls into the category of rodent
The mouse falls into the category of rodent
The mamba falls into the category of snake
The porcupine falls into the category of
2024-07-31 05:33:31 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-31 05:33:50 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1630,  0.0264, -0.1155,  ..., -0.1947, -0.3086, -0.2920],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.5059, -2.4277,  0.6357,  ..., -2.5977, -1.0537, -0.3491],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0719,  0.0514,  0.0102,  ..., -0.0149,  0.0024,  0.0079],
        [ 0.0847, -0.0252, -0.0127,  ...,  0.0349, -0.0093, -0.0122],
        [-0.0256,  0.0067,  0.0112,  ..., -0.0170,  0.0015, -0.0022],
        ...,
        [ 0.0590, -0.0099, -0.0047,  ...,  0.0061, -0.0051, -0.0179],
        [-0.0397,  0.0177,  0.0082,  ..., -0.0075,  0.0132, -0.0411],
        [ 0.0337,  0.0075,  0.0049,  ...,  0.0077, -0.0140,  0.0064]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.3257, -2.6387,  0.6875,  ..., -2.5625, -0.8984, -0.5942]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 05:33:51 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Something without defence is defenceless
Something without error is errorless
Something without odor is odorless
Something without friend is friendless
Something without leg is legless
Something without remorse is remorseless
Something without goal is goalless
Something without god is
2024-07-31 05:33:51 root INFO     [order_1_approx] starting weight calculation for Something without remorse is remorseless
Something without leg is legless
Something without odor is odorless
Something without god is godless
Something without friend is friendless
Something without error is errorless
Something without defence is defenceless
Something without goal is
2024-07-31 05:33:51 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-31 05:36:04 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1520, -0.4558,  0.0173,  ...,  0.0317, -0.4529,  0.2800],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.9180, -3.4160,  0.3301,  ..., -2.3945, -4.0508, -0.5410],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0354, -0.0044, -0.0080,  ..., -0.0015, -0.0103, -0.0088],
        [-0.0020,  0.0248,  0.0043,  ...,  0.0058,  0.0167, -0.0072],
        [ 0.0046,  0.0167,  0.0176,  ..., -0.0147, -0.0105, -0.0092],
        ...,
        [ 0.0160,  0.0185, -0.0125,  ...,  0.0166,  0.0022,  0.0032],
        [-0.0174, -0.0078, -0.0065,  ..., -0.0109,  0.0412,  0.0014],
        [-0.0073,  0.0016, -0.0073,  ..., -0.0011,  0.0185,  0.0181]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.6270, -3.2578, -0.0361,  ..., -2.8496, -3.5742, -0.1172]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 05:36:05 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The gibbon falls into the category of primate
The ant falls into the category of insect
The chicken falls into the category of fowl
The fox falls into the category of canine
The chinchilla falls into the category of rodent
The mouse falls into the category of rodent
The mamba falls into the category of snake
The porcupine falls into the category of
2024-07-31 05:36:05 root INFO     [order_1_approx] starting weight calculation for The mamba falls into the category of snake
The chicken falls into the category of fowl
The mouse falls into the category of rodent
The chinchilla falls into the category of rodent
The ant falls into the category of insect
The gibbon falls into the category of primate
The porcupine falls into the category of rodent
The fox falls into the category of
2024-07-31 05:36:05 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-31 05:36:30 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1092,  0.0252, -0.0952,  ..., -0.2090, -0.1138, -0.0273],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.0796, -3.4141, -1.1367,  ..., -2.5918, -0.8887, -1.3662],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0276,  0.0079, -0.0092,  ...,  0.0194, -0.0150,  0.0088],
        [ 0.0018,  0.0316, -0.0112,  ...,  0.0047, -0.0090,  0.0051],
        [-0.0107, -0.0070,  0.0162,  ...,  0.0232, -0.0181,  0.0037],
        ...,
        [ 0.0254,  0.0309,  0.0031,  ...,  0.0049,  0.0002, -0.0249],
        [-0.0091,  0.0192, -0.0015,  ..., -0.0494,  0.0046, -0.0427],
        [ 0.0075, -0.0237,  0.0115,  ...,  0.0055, -0.0112, -0.0011]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.4805, -3.4551, -1.1865,  ..., -2.6797, -1.1484, -1.6104]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 05:36:31 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Something without remorse is remorseless
Something without leg is legless
Something without odor is odorless
Something without god is godless
Something without friend is friendless
Something without error is errorless
Something without defence is defenceless
Something without goal is
2024-07-31 05:36:31 root INFO     [order_1_approx] starting weight calculation for Something without odor is odorless
Something without remorse is remorseless
Something without leg is legless
Something without goal is goalless
Something without error is errorless
Something without friend is friendless
Something without god is godless
Something without defence is
2024-07-31 05:36:31 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-31 05:38:38 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3120,  0.1110, -0.1906,  ...,  0.0318, -0.1451, -0.1556],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.9746, -6.1328,  1.8438,  ..., -2.8945, -6.6992,  1.7520],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 4.6051e-02,  4.7951e-03, -1.1940e-02,  ...,  4.9210e-03,
         -3.9101e-03, -1.8625e-03],
        [ 2.1759e-02,  1.8661e-02,  8.6594e-03,  ...,  1.6159e-02,
         -3.3474e-04, -1.5587e-02],
        [ 1.8600e-02,  2.1225e-02,  5.5298e-02,  ..., -3.6682e-02,
         -3.4542e-03, -1.5839e-02],
        ...,
        [ 4.7684e-04,  1.0391e-02, -1.5450e-03,  ...,  7.1239e-04,
          2.6764e-02,  2.5597e-03],
        [ 6.9618e-05,  3.5458e-03,  8.8882e-04,  ...,  2.4414e-02,
          4.2572e-02,  1.3046e-03],
        [ 1.0773e-02, -1.5228e-02,  9.7504e-03,  ..., -1.0002e-02,
          1.0353e-02,  2.4017e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.0166, -6.0430,  1.0977,  ..., -2.7109, -6.7500,  1.5527]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 05:38:39 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The mamba falls into the category of snake
The chicken falls into the category of fowl
The mouse falls into the category of rodent
The chinchilla falls into the category of rodent
The ant falls into the category of insect
The gibbon falls into the category of primate
The porcupine falls into the category of rodent
The fox falls into the category of
2024-07-31 05:38:40 root INFO     [order_1_approx] starting weight calculation for The porcupine falls into the category of rodent
The mamba falls into the category of snake
The ant falls into the category of insect
The mouse falls into the category of rodent
The fox falls into the category of canine
The gibbon falls into the category of primate
The chinchilla falls into the category of rodent
The chicken falls into the category of
2024-07-31 05:38:40 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-31 05:39:09 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0527, -0.1592, -0.0215,  ..., -0.0637,  0.0062,  0.0006],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.3799, -5.4609,  0.5977,  ..., -2.5234, -2.9199, -1.9600],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0304,  0.0177, -0.0032,  ...,  0.0441, -0.0202,  0.0136],
        [-0.0149, -0.0053, -0.0028,  ..., -0.0190, -0.0198, -0.0086],
        [ 0.0163, -0.0182,  0.0236,  ...,  0.0393, -0.0391,  0.0089],
        ...,
        [ 0.0054,  0.0145, -0.0045,  ...,  0.0006,  0.0235, -0.0157],
        [-0.0193,  0.0039, -0.0034,  ..., -0.0133,  0.0261, -0.0241],
        [ 0.0202, -0.0296, -0.0216,  ..., -0.0049, -0.0071, -0.0083]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.3545, -5.6328,  1.2422,  ..., -2.2598, -3.1367, -2.0195]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 05:39:10 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Something without odor is odorless
Something without remorse is remorseless
Something without leg is legless
Something without goal is goalless
Something without error is errorless
Something without friend is friendless
Something without god is godless
Something without defence is
2024-07-31 05:39:10 root INFO     [order_1_approx] starting weight calculation for Something without leg is legless
Something without error is errorless
Something without god is godless
Something without odor is odorless
Something without friend is friendless
Something without defence is defenceless
Something without goal is goalless
Something without remorse is
2024-07-31 05:39:10 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-31 05:41:11 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3379, -0.0031, -0.4849,  ...,  0.1575, -0.1199,  0.2495],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.9902, -4.9688,  4.6172,  ..., -2.1816, -8.0234,  2.1777],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0409,  0.0117,  0.0059,  ...,  0.0178, -0.0121, -0.0039],
        [ 0.0109,  0.0473,  0.0103,  ...,  0.0048,  0.0024, -0.0062],
        [ 0.0153,  0.0148,  0.0304,  ...,  0.0121,  0.0025, -0.0048],
        ...,
        [ 0.0092,  0.0024,  0.0079,  ...,  0.0120,  0.0010, -0.0049],
        [-0.0006,  0.0064,  0.0006,  ...,  0.0067,  0.0381, -0.0013],
        [ 0.0077, -0.0095, -0.0043,  ...,  0.0057, -0.0071,  0.0339]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.0449, -4.3438,  3.8125,  ..., -2.1953, -8.0000,  2.6133]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 05:41:12 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The porcupine falls into the category of rodent
The mamba falls into the category of snake
The ant falls into the category of insect
The mouse falls into the category of rodent
The fox falls into the category of canine
The gibbon falls into the category of primate
The chinchilla falls into the category of rodent
The chicken falls into the category of
2024-07-31 05:41:12 root INFO     total operator prediction time: 1231.6805634498596 seconds
2024-07-31 05:41:12 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on synonyms - intensity
2024-07-31 05:41:12 root INFO     building operator synonyms - intensity
2024-07-31 05:41:12 root INFO     [order_1_approx] starting weight calculation for A more intense word for ask is beg
A more intense word for soon is immediately
A more intense word for lake is sea
A more intense word for monkey is gorilla
A more intense word for snack is meal
A more intense word for indulge is pamper
A more intense word for excited is agitated
A more intense word for doze is
2024-07-31 05:41:12 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-31 05:41:49 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0050,  0.0455, -0.0478,  ...,  0.2612, -0.0955, -0.0490],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.4180, -3.8809, -1.3105,  ..., -3.7129, -1.3027, -1.9775],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0276, -0.0017,  0.0099,  ..., -0.0003, -0.0186,  0.0077],
        [ 0.0157,  0.0142,  0.0192,  ..., -0.0049, -0.0081,  0.0076],
        [-0.0280,  0.0203,  0.0271,  ...,  0.0050, -0.0040, -0.0284],
        ...,
        [ 0.0117,  0.0298,  0.0089,  ..., -0.0013, -0.0013, -0.0044],
        [ 0.0072,  0.0159,  0.0192,  ..., -0.0182,  0.0258, -0.0041],
        [ 0.0039, -0.0018,  0.0070,  ..., -0.0290, -0.0370,  0.0352]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.0508, -3.6914, -2.0879,  ..., -3.4219, -1.2402, -2.1230]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 05:41:50 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Something without leg is legless
Something without error is errorless
Something without god is godless
Something without odor is odorless
Something without friend is friendless
Something without defence is defenceless
Something without goal is goalless
Something without remorse is
2024-07-31 05:41:51 root INFO     [order_1_approx] starting weight calculation for Something without remorse is remorseless
Something without friend is friendless
Something without odor is odorless
Something without goal is goalless
Something without god is godless
Something without defence is defenceless
Something without error is errorless
Something without leg is
2024-07-31 05:41:51 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-31 05:43:45 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2321, -0.1118,  0.3025,  ..., -0.3191, -0.5137,  0.3374],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.6484, -4.1094,  2.3438,  ...,  0.5396, -3.1816,  0.1514],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0533, -0.0259,  0.0063,  ...,  0.0419, -0.0227,  0.0090],
        [ 0.0322,  0.0528, -0.0096,  ..., -0.0037,  0.0214,  0.0098],
        [-0.0622, -0.0315,  0.0286,  ...,  0.0039, -0.0386, -0.0352],
        ...,
        [ 0.0069,  0.0267,  0.0117,  ...,  0.0415,  0.0112, -0.0391],
        [ 0.0018, -0.0193, -0.0157,  ..., -0.0032, -0.0365, -0.0249],
        [ 0.0202, -0.0133, -0.0134,  ...,  0.0017, -0.0335,  0.0298]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.4656, -4.0156,  2.1562,  ...,  0.4888, -3.4375, -0.0494]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 05:43:46 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more intense word for ask is beg
A more intense word for soon is immediately
A more intense word for lake is sea
A more intense word for monkey is gorilla
A more intense word for snack is meal
A more intense word for indulge is pamper
A more intense word for excited is agitated
A more intense word for doze is
2024-07-31 05:43:46 root INFO     [order_1_approx] starting weight calculation for A more intense word for doze is sleep
A more intense word for soon is immediately
A more intense word for ask is beg
A more intense word for snack is meal
A more intense word for indulge is pamper
A more intense word for lake is sea
A more intense word for excited is agitated
A more intense word for monkey is
2024-07-31 05:43:46 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-31 05:44:29 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3342, -0.0501,  0.0419,  ..., -0.1316, -0.0557, -0.3120],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.4014, -5.2422,  0.0654,  ..., -0.1978, -1.4668, -2.8711],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0520, -0.0259,  0.0038,  ..., -0.0016, -0.0294,  0.0239],
        [ 0.0102,  0.0118,  0.0118,  ..., -0.0020, -0.0262, -0.0118],
        [ 0.0060, -0.0167,  0.0220,  ..., -0.0097, -0.0315,  0.0014],
        ...,
        [ 0.0218,  0.0014,  0.0130,  ...,  0.0323,  0.0072,  0.0090],
        [-0.0033,  0.0178, -0.0219,  ..., -0.0066,  0.0541, -0.0531],
        [-0.0020,  0.0134,  0.0142,  ...,  0.0156, -0.0091,  0.0033]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.7207, -5.5430, -0.3081,  ..., -0.1858, -1.7578, -2.8477]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 05:44:30 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Something without remorse is remorseless
Something without friend is friendless
Something without odor is odorless
Something without goal is goalless
Something without god is godless
Something without defence is defenceless
Something without error is errorless
Something without leg is
2024-07-31 05:44:30 root INFO     [order_1_approx] starting weight calculation for Something without goal is goalless
Something without god is godless
Something without odor is odorless
Something without friend is friendless
Something without remorse is remorseless
Something without leg is legless
Something without defence is defenceless
Something without error is
2024-07-31 05:44:30 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-31 05:46:19 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1011, -0.0371, -0.0804,  ...,  0.1042, -0.4148,  0.3323],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.5576, -5.2188,  2.1992,  ...,  1.0137, -4.1602,  1.3125],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0647,  0.0068, -0.0069,  ..., -0.0058,  0.0102, -0.0064],
        [-0.0057,  0.0653, -0.0238,  ..., -0.0200, -0.0164, -0.0309],
        [-0.0035, -0.0182,  0.0566,  ..., -0.0328,  0.0135,  0.0047],
        ...,
        [-0.0280,  0.0164, -0.0064,  ...,  0.0779, -0.0277, -0.0062],
        [ 0.0243, -0.0223, -0.0490,  ...,  0.0359,  0.0197,  0.0163],
        [-0.0262,  0.0112,  0.0040,  ..., -0.0103, -0.0142,  0.0497]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.7627, -4.9414,  2.2402,  ...,  1.1680, -4.4062,  1.3369]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 05:46:20 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more intense word for doze is sleep
A more intense word for soon is immediately
A more intense word for ask is beg
A more intense word for snack is meal
A more intense word for indulge is pamper
A more intense word for lake is sea
A more intense word for excited is agitated
A more intense word for monkey is
2024-07-31 05:46:21 root INFO     [order_1_approx] starting weight calculation for A more intense word for doze is sleep
A more intense word for ask is beg
A more intense word for indulge is pamper
A more intense word for lake is sea
A more intense word for excited is agitated
A more intense word for soon is immediately
A more intense word for monkey is gorilla
A more intense word for snack is
2024-07-31 05:46:21 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-31 05:47:09 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1257,  0.1379, -0.2844,  ...,  0.1597, -0.0647, -0.1592],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.8418, -3.1523, -1.9746,  ..., -0.4053, -4.4219, -2.5742],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0060, -0.0235, -0.0011,  ..., -0.0649, -0.0608,  0.0240],
        [ 0.0020,  0.0588,  0.0384,  ...,  0.0707,  0.0463,  0.0046],
        [ 0.0228, -0.0166,  0.0297,  ..., -0.0042, -0.0169, -0.0286],
        ...,
        [ 0.0246,  0.0321,  0.0133,  ...,  0.0306,  0.0123, -0.0004],
        [ 0.0225,  0.0347,  0.0055,  ...,  0.0129,  0.0360, -0.0135],
        [ 0.0182,  0.0213,  0.0371,  ...,  0.0467,  0.0237,  0.0135]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.0518, -2.6191, -1.3477,  ..., -0.3042, -3.6875, -2.0176]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 05:47:10 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Something without goal is goalless
Something without god is godless
Something without odor is odorless
Something without friend is friendless
Something without remorse is remorseless
Something without leg is legless
Something without defence is defenceless
Something without error is
2024-07-31 05:47:10 root INFO     [order_1_approx] starting weight calculation for Something without error is errorless
Something without leg is legless
Something without odor is odorless
Something without goal is goalless
Something without remorse is remorseless
Something without defence is defenceless
Something without god is godless
Something without friend is
2024-07-31 05:47:10 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-31 05:48:54 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2859, -0.1821, -0.1511,  ...,  0.0109, -0.4504, -0.0154],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.2109, -2.8184,  0.4312,  ...,  1.9629, -5.4453, -0.5361],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0167, -0.0078,  0.0321,  ..., -0.0064, -0.0019,  0.0473],
        [ 0.0201,  0.0717,  0.0167,  ..., -0.0166, -0.0089, -0.0150],
        [-0.0140, -0.0591,  0.0603,  ..., -0.0026, -0.0326,  0.0069],
        ...,
        [ 0.0066,  0.0258,  0.0209,  ...,  0.0337, -0.0112,  0.0012],
        [-0.0061,  0.0198,  0.0198,  ...,  0.0095,  0.0334, -0.0141],
        [-0.0353, -0.0074, -0.0135,  ...,  0.0603,  0.0102,  0.0486]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.2773, -2.4531,  0.6348,  ...,  1.9307, -5.8594, -0.3459]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 05:48:55 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more intense word for doze is sleep
A more intense word for ask is beg
A more intense word for indulge is pamper
A more intense word for lake is sea
A more intense word for excited is agitated
A more intense word for soon is immediately
A more intense word for monkey is gorilla
A more intense word for snack is
2024-07-31 05:48:55 root INFO     [order_1_approx] starting weight calculation for A more intense word for snack is meal
A more intense word for lake is sea
A more intense word for soon is immediately
A more intense word for monkey is gorilla
A more intense word for indulge is pamper
A more intense word for excited is agitated
A more intense word for doze is sleep
A more intense word for ask is
2024-07-31 05:48:55 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-31 05:49:49 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0842, -0.3984, -0.2073,  ..., -0.2942,  0.0536, -0.3472],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.8159, -1.9229,  0.5850,  ..., -0.2690, -3.3086,  1.0498],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 3.8452e-02, -3.4332e-05, -6.2027e-03,  ..., -5.5618e-03,
         -3.6011e-02,  7.7782e-03],
        [ 8.9264e-03,  7.1411e-03,  1.6129e-02,  ..., -1.1749e-02,
         -4.8370e-03, -6.7787e-03],
        [ 1.1215e-02, -1.6205e-02,  9.9564e-03,  ..., -3.2234e-03,
         -2.0874e-02, -9.4910e-03],
        ...,
        [ 4.2725e-03,  1.8692e-02,  8.2207e-04,  ...,  3.8509e-03,
          1.0712e-02,  1.5774e-03],
        [-1.0361e-02,  1.7517e-02, -1.1917e-02,  ...,  9.8419e-03,
          2.2766e-02, -1.1650e-02],
        [ 8.5373e-03,  2.4300e-03, -3.7346e-03,  ..., -2.1255e-02,
          7.4158e-03,  1.2711e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.4734, -2.2832,  0.6240,  ..., -0.7168, -3.0977,  0.5557]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 05:49:50 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Something without error is errorless
Something without leg is legless
Something without odor is odorless
Something without goal is goalless
Something without remorse is remorseless
Something without defence is defenceless
Something without god is godless
Something without friend is
2024-07-31 05:49:50 root INFO     total operator prediction time: 1278.443769454956 seconds
2024-07-31 05:49:50 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on adj+ness_reg
2024-07-31 05:49:50 root INFO     building operator adj+ness_reg
2024-07-31 05:49:50 root INFO     [order_1_approx] starting weight calculation for The state of being interesting is interestingness
The state of being cheap is cheapness
The state of being related is relatedness
The state of being hot is hotness
The state of being broken is brokenness
The state of being massive is massiveness
The state of being strange is strangeness
The state of being distinctive is
2024-07-31 05:49:50 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-31 05:51:28 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0975,  0.2384, -0.1241,  ..., -0.0253, -0.1797,  0.0264],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.3008, -6.3359,  0.0718,  ...,  0.0977, -4.6953, -3.2148],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0381, -0.0091,  0.0137,  ...,  0.0197, -0.0123,  0.0370],
        [ 0.0061,  0.0157, -0.0069,  ..., -0.0113,  0.0053,  0.0167],
        [-0.0417, -0.0501,  0.0306,  ...,  0.0149,  0.0076, -0.0037],
        ...,
        [-0.0054,  0.0113, -0.0073,  ...,  0.0371,  0.0020, -0.0201],
        [-0.0166, -0.0073, -0.0279,  ...,  0.0162,  0.0180, -0.0209],
        [-0.0146, -0.0093, -0.0108,  ...,  0.0125, -0.0063,  0.0246]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.4609, -5.5156,  0.5850,  ..., -0.2605, -4.6016, -3.0547]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 05:51:29 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more intense word for snack is meal
A more intense word for lake is sea
A more intense word for soon is immediately
A more intense word for monkey is gorilla
A more intense word for indulge is pamper
A more intense word for excited is agitated
A more intense word for doze is sleep
A more intense word for ask is
2024-07-31 05:51:29 root INFO     [order_1_approx] starting weight calculation for A more intense word for excited is agitated
A more intense word for ask is beg
A more intense word for soon is immediately
A more intense word for lake is sea
A more intense word for monkey is gorilla
A more intense word for snack is meal
A more intense word for doze is sleep
A more intense word for indulge is
2024-07-31 05:51:29 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-31 05:52:30 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2544, -0.3125,  0.0136,  ...,  0.1470, -0.2595,  0.1272],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.1074, -3.3594, -0.6362,  ..., -2.7910, -5.1367, -1.7246],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 3.9368e-02, -8.9417e-03, -3.4027e-03,  ..., -6.5994e-03,
         -6.3210e-03,  1.1307e-02],
        [-2.8839e-02,  2.0691e-02,  1.9943e-02,  ...,  1.1292e-02,
          1.6708e-02, -1.2154e-02],
        [ 1.7670e-02, -1.3634e-02,  1.9272e-02,  ..., -8.2016e-05,
         -1.9806e-02, -2.0157e-02],
        ...,
        [ 6.8474e-04,  8.8348e-03, -2.5444e-03,  ...,  1.1803e-02,
         -3.4523e-03, -2.2110e-02],
        [ 9.5062e-03, -7.6675e-04,  4.0817e-03,  ..., -1.8654e-03,
          1.8784e-02,  1.0796e-02],
        [ 4.6120e-03,  1.9241e-02, -7.2098e-03,  ...,  1.5396e-02,
          6.4163e-03,  1.8784e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.0010, -3.2070, -0.7241,  ..., -2.7441, -5.4180, -2.0918]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 05:52:31 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The state of being interesting is interestingness
The state of being cheap is cheapness
The state of being related is relatedness
The state of being hot is hotness
The state of being broken is brokenness
The state of being massive is massiveness
The state of being strange is strangeness
The state of being distinctive is
2024-07-31 05:52:31 root INFO     [order_1_approx] starting weight calculation for The state of being interesting is interestingness
The state of being hot is hotness
The state of being related is relatedness
The state of being strange is strangeness
The state of being broken is brokenness
The state of being massive is massiveness
The state of being distinctive is distinctiveness
The state of being cheap is
2024-07-31 05:52:31 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-31 05:53:57 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1891,  0.0219, -0.2035,  ..., -0.2563, -0.5156,  0.3779],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.9609, -2.0352, -2.7148,  ...,  1.1680, -4.7305,  1.2510],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0572,  0.0101,  0.0040,  ...,  0.0127, -0.0010,  0.0065],
        [ 0.0105,  0.0450,  0.0041,  ...,  0.0010, -0.0090,  0.0040],
        [-0.0278, -0.0223,  0.0388,  ...,  0.0082, -0.0083, -0.0176],
        ...,
        [ 0.0117, -0.0093, -0.0101,  ...,  0.0326,  0.0070, -0.0031],
        [-0.0033,  0.0312,  0.0076,  ..., -0.0199,  0.0133,  0.0128],
        [-0.0093, -0.0222, -0.0053,  ..., -0.0100, -0.0073,  0.0302]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.9219, -1.8477, -2.5918,  ...,  1.2998, -4.7500,  1.0771]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 05:53:58 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more intense word for excited is agitated
A more intense word for ask is beg
A more intense word for soon is immediately
A more intense word for lake is sea
A more intense word for monkey is gorilla
A more intense word for snack is meal
A more intense word for doze is sleep
A more intense word for indulge is
2024-07-31 05:53:58 root INFO     [order_1_approx] starting weight calculation for A more intense word for ask is beg
A more intense word for indulge is pamper
A more intense word for monkey is gorilla
A more intense word for soon is immediately
A more intense word for doze is sleep
A more intense word for excited is agitated
A more intense word for snack is meal
A more intense word for lake is
2024-07-31 05:53:59 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-31 05:55:12 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1912, -0.1417,  0.1113,  ...,  0.3210, -0.1858, -0.0565],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-2.3281, -0.6748, -1.8750,  ..., -4.1133, -5.3984, -1.9062],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0455, -0.0360, -0.0057,  ..., -0.0303,  0.0048,  0.0294],
        [-0.0170,  0.0144,  0.0221,  ...,  0.0126,  0.0116,  0.0025],
        [ 0.0008, -0.0023,  0.0258,  ...,  0.0109, -0.0079,  0.0028],
        ...,
        [ 0.0028,  0.0041,  0.0040,  ...,  0.0131,  0.0135,  0.0143],
        [ 0.0099, -0.0013, -0.0194,  ..., -0.0231, -0.0143, -0.0238],
        [ 0.0030,  0.0222, -0.0327,  ...,  0.0139,  0.0480,  0.0386]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-2.2793, -0.8560, -2.3066,  ..., -4.1836, -5.7461, -1.8477]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 05:55:13 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The state of being interesting is interestingness
The state of being hot is hotness
The state of being related is relatedness
The state of being strange is strangeness
The state of being broken is brokenness
The state of being massive is massiveness
The state of being distinctive is distinctiveness
The state of being cheap is
2024-07-31 05:55:13 root INFO     [order_1_approx] starting weight calculation for The state of being interesting is interestingness
The state of being cheap is cheapness
The state of being distinctive is distinctiveness
The state of being related is relatedness
The state of being massive is massiveness
The state of being strange is strangeness
The state of being hot is hotness
The state of being broken is
2024-07-31 05:55:13 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-31 05:56:29 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0065,  0.1454,  0.0094,  ..., -0.3301, -0.1980,  0.2302],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.0449, -4.0625,  0.8354,  ..., -1.4863, -0.4736,  0.1006],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0859, -0.0116, -0.0046,  ...,  0.0193, -0.0044,  0.0218],
        [ 0.0014,  0.0573, -0.0306,  ...,  0.0441,  0.0054, -0.0169],
        [-0.0156,  0.0082,  0.0583,  ..., -0.0103, -0.0077,  0.0220],
        ...,
        [-0.0365,  0.0275, -0.0175,  ...,  0.0730,  0.0202, -0.0296],
        [-0.0145, -0.0037, -0.0067,  ..., -0.0012,  0.0462, -0.0101],
        [-0.0004,  0.0033,  0.0138,  ...,  0.0054, -0.0004,  0.0675]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.7866, -3.5625,  0.7397,  ..., -1.0127, -0.4827, -0.0493]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 05:56:30 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more intense word for ask is beg
A more intense word for indulge is pamper
A more intense word for monkey is gorilla
A more intense word for soon is immediately
A more intense word for doze is sleep
A more intense word for excited is agitated
A more intense word for snack is meal
A more intense word for lake is
2024-07-31 05:56:30 root INFO     [order_1_approx] starting weight calculation for A more intense word for snack is meal
A more intense word for doze is sleep
A more intense word for monkey is gorilla
A more intense word for lake is sea
A more intense word for indulge is pamper
A more intense word for ask is beg
A more intense word for excited is agitated
A more intense word for soon is
2024-07-31 05:56:30 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-31 05:57:53 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2605,  0.3462, -0.0199,  ...,  0.0814, -0.3770, -0.0121],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.0527, -5.1797, -1.1562,  ..., -2.4023,  0.2590, -0.2871],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0550,  0.0073, -0.0042,  ...,  0.0004,  0.0040,  0.0136],
        [ 0.0069,  0.0054,  0.0157,  ...,  0.0243,  0.0165,  0.0106],
        [ 0.0082, -0.0489,  0.0021,  ..., -0.0021,  0.0127,  0.0017],
        ...,
        [ 0.0159,  0.0152,  0.0080,  ...,  0.0167, -0.0144,  0.0074],
        [-0.0065,  0.0013, -0.0045,  ..., -0.0257,  0.0265, -0.0384],
        [ 0.0048,  0.0143, -0.0072,  ...,  0.0078,  0.0020,  0.0403]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.9902, -5.0742, -1.1533,  ..., -2.3184,  0.4375, -0.1936]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 05:57:54 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The state of being interesting is interestingness
The state of being cheap is cheapness
The state of being distinctive is distinctiveness
The state of being related is relatedness
The state of being massive is massiveness
The state of being strange is strangeness
The state of being hot is hotness
The state of being broken is
2024-07-31 05:57:54 root INFO     [order_1_approx] starting weight calculation for The state of being interesting is interestingness
The state of being cheap is cheapness
The state of being broken is brokenness
The state of being related is relatedness
The state of being strange is strangeness
The state of being distinctive is distinctiveness
The state of being massive is massiveness
The state of being hot is
2024-07-31 05:57:54 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-31 05:59:00 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0568, -0.3445, -0.1466,  ..., -0.3013, -0.2864,  0.6089],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 5.1172, -2.8789, -1.2432,  ..., -0.1196, -3.6621, -1.3887],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0334,  0.0086, -0.0356,  ..., -0.0046,  0.0228,  0.0216],
        [-0.0208,  0.0346, -0.0105,  ...,  0.0180, -0.0475, -0.0019],
        [ 0.0032, -0.0093,  0.0297,  ...,  0.0454,  0.0170,  0.0119],
        ...,
        [-0.0289,  0.0045, -0.0098,  ...,  0.0417,  0.0078, -0.0081],
        [ 0.0039, -0.0228,  0.0307,  ...,  0.0194,  0.0437, -0.0059],
        [ 0.0032, -0.0032, -0.0321,  ...,  0.0169, -0.0361,  0.0294]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 5.3008, -2.3594, -0.6470,  ..., -0.0988, -3.7227, -1.7178]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 05:59:01 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more intense word for snack is meal
A more intense word for doze is sleep
A more intense word for monkey is gorilla
A more intense word for lake is sea
A more intense word for indulge is pamper
A more intense word for ask is beg
A more intense word for excited is agitated
A more intense word for soon is
2024-07-31 05:59:01 root INFO     [order_1_approx] starting weight calculation for A more intense word for soon is immediately
A more intense word for doze is sleep
A more intense word for indulge is pamper
A more intense word for monkey is gorilla
A more intense word for ask is beg
A more intense word for lake is sea
A more intense word for snack is meal
A more intense word for excited is
2024-07-31 05:59:01 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-31 06:00:34 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1176, -0.0688,  0.2227,  ...,  0.1523, -0.3696, -0.0771],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.5781, -2.7070, -1.1875,  ..., -3.8125, -6.7188, -0.7456],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 4.3701e-02, -3.0304e-02,  1.2894e-03,  ..., -2.2308e-02,
         -1.5060e-02,  4.5990e-02],
        [ 5.0278e-03,  1.7700e-02,  7.1068e-03,  ...,  4.3793e-03,
         -4.8676e-03,  6.1760e-03],
        [-9.9945e-04,  2.1057e-03,  2.1866e-02,  ..., -1.2283e-02,
          1.8585e-02,  5.2185e-03],
        ...,
        [-7.5111e-03,  2.6550e-03,  3.7880e-03,  ...,  5.1880e-03,
         -2.5654e-03, -9.9869e-03],
        [ 3.6896e-02, -4.4556e-03, -2.0569e-02,  ..., -2.7634e-02,
          4.9042e-02, -2.5818e-02],
        [-8.5449e-03, -1.1871e-02, -2.0279e-02,  ..., -4.3154e-05,
          6.4926e-03,  4.7668e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.5479, -2.8438, -1.9336,  ..., -3.7461, -6.9414, -0.5186]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 06:00:35 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The state of being interesting is interestingness
The state of being cheap is cheapness
The state of being broken is brokenness
The state of being related is relatedness
The state of being strange is strangeness
The state of being distinctive is distinctiveness
The state of being massive is massiveness
The state of being hot is
2024-07-31 06:00:35 root INFO     [order_1_approx] starting weight calculation for The state of being broken is brokenness
The state of being hot is hotness
The state of being massive is massiveness
The state of being strange is strangeness
The state of being related is relatedness
The state of being cheap is cheapness
The state of being distinctive is distinctiveness
The state of being interesting is
2024-07-31 06:00:36 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-31 06:01:34 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0107, -0.1666, -0.3364,  ...,  0.0292, -0.2974,  0.4949],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.8047e+00, -1.9307e+00,  1.3926e+00,  ..., -3.0078e-01,
        -4.8984e+00,  1.9531e-03], device='cuda:1', dtype=torch.float16,
       grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 4.4098e-02,  4.1748e-02,  1.7792e-02,  ..., -9.5367e-06,
          1.1314e-02, -1.9455e-03],
        [ 5.6458e-03,  2.9907e-02, -3.1433e-03,  ..., -8.0109e-03,
         -8.9569e-03, -1.3016e-02],
        [-1.6037e-02, -4.2648e-03,  6.7627e-02,  ...,  2.3041e-02,
         -9.3689e-03, -2.0126e-02],
        ...,
        [ 2.7370e-03,  1.4954e-02, -2.9358e-02,  ...,  3.9886e-02,
         -2.8244e-02, -6.9771e-03],
        [-2.4033e-02, -2.1988e-02,  3.9368e-03,  ...,  1.4679e-02,
          2.5513e-02, -1.5427e-02],
        [-1.0368e-02,  5.9891e-04, -2.1866e-02,  ..., -8.0719e-03,
         -1.1063e-02,  4.8004e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.9092, -2.3184,  1.7559,  ..., -0.5889, -4.5938, -0.3049]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 06:01:35 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more intense word for soon is immediately
A more intense word for doze is sleep
A more intense word for indulge is pamper
A more intense word for monkey is gorilla
A more intense word for ask is beg
A more intense word for lake is sea
A more intense word for snack is meal
A more intense word for excited is
2024-07-31 06:01:35 root INFO     total operator prediction time: 1222.6513857841492 seconds
2024-07-31 06:01:35 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on meronyms - substance
2024-07-31 06:01:35 root INFO     building operator meronyms - substance
2024-07-31 06:01:35 root INFO     [order_1_approx] starting weight calculation for A flag is made up of fabric
A boots is made up of leather
A wine is made up of grapes
A candy is made up of sugar
A penny is made up of metal
A icicle is made up of ice
A cocktail is made up of alcohol
A jam is made up of
2024-07-31 06:01:35 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-31 06:03:15 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1401,  0.3450,  0.1098,  ...,  0.2710, -0.4292, -0.0559],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.9902, -3.0215, -0.7842,  ..., -1.6602, -3.2891, -1.9941],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0266,  0.0018, -0.0151,  ..., -0.0082, -0.0094, -0.0003],
        [-0.0300,  0.0135, -0.0006,  ...,  0.0004, -0.0017, -0.0257],
        [ 0.0294, -0.0089,  0.0165,  ..., -0.0078, -0.0154, -0.0167],
        ...,
        [ 0.0076, -0.0012,  0.0069,  ...,  0.0230,  0.0120,  0.0052],
        [ 0.0091,  0.0033,  0.0064,  ...,  0.0133,  0.0082, -0.0210],
        [ 0.0261,  0.0191,  0.0032,  ..., -0.0072, -0.0093,  0.0083]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.9590, -3.1289, -0.8130,  ..., -1.5342, -3.0723, -1.7021]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 06:03:16 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The state of being broken is brokenness
The state of being hot is hotness
The state of being massive is massiveness
The state of being strange is strangeness
The state of being related is relatedness
The state of being cheap is cheapness
The state of being distinctive is distinctiveness
The state of being interesting is
2024-07-31 06:03:16 root INFO     [order_1_approx] starting weight calculation for The state of being hot is hotness
The state of being massive is massiveness
The state of being interesting is interestingness
The state of being strange is strangeness
The state of being broken is brokenness
The state of being cheap is cheapness
The state of being distinctive is distinctiveness
The state of being related is
2024-07-31 06:03:16 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-31 06:04:09 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.3904,  0.0692, -0.0532,  ..., -0.0881, -0.1810, -0.0334],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.3242, -7.4297, -0.9795,  ..., -3.0195, -3.9863,  2.4863],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0387, -0.0151,  0.0016,  ..., -0.0044, -0.0296,  0.0329],
        [-0.0140,  0.0521,  0.0200,  ..., -0.0419,  0.0231, -0.0273],
        [-0.0002,  0.0257,  0.0370,  ..., -0.0015, -0.0155,  0.0062],
        ...,
        [ 0.0075,  0.0242,  0.0307,  ...,  0.0661,  0.0078, -0.0421],
        [ 0.0207,  0.0149, -0.0479,  ...,  0.0503,  0.0126, -0.0234],
        [ 0.0179, -0.0158,  0.0045,  ..., -0.0130, -0.0037,  0.0704]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.5508, -7.7461, -1.2432,  ..., -3.4375, -4.5938,  3.0059]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 06:04:10 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A flag is made up of fabric
A boots is made up of leather
A wine is made up of grapes
A candy is made up of sugar
A penny is made up of metal
A icicle is made up of ice
A cocktail is made up of alcohol
A jam is made up of
2024-07-31 06:04:10 root INFO     [order_1_approx] starting weight calculation for A penny is made up of metal
A cocktail is made up of alcohol
A jam is made up of fruit
A icicle is made up of ice
A flag is made up of fabric
A wine is made up of grapes
A candy is made up of sugar
A boots is made up of
2024-07-31 06:04:10 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-31 06:05:55 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0198,  0.0515, -0.2896,  ..., -0.0110, -0.5791,  0.0440],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.2266, -3.6816, -1.0840,  ...,  0.1531, -3.2695, -3.0605],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0318,  0.0200, -0.0021,  ..., -0.0126,  0.0189,  0.0283],
        [-0.0142,  0.0228,  0.0046,  ...,  0.0302,  0.0021,  0.0135],
        [ 0.0167,  0.0029,  0.0191,  ..., -0.0091,  0.0177, -0.0272],
        ...,
        [ 0.0116,  0.0178, -0.0118,  ...,  0.0116,  0.0095, -0.0053],
        [ 0.0051,  0.0015,  0.0133,  ...,  0.0032,  0.0126, -0.0421],
        [ 0.0158,  0.0158, -0.0250,  ...,  0.0089, -0.0089,  0.0538]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.2639, -3.2109, -1.2715,  ...,  0.2612, -3.5098, -2.8027]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 06:05:55 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The state of being hot is hotness
The state of being massive is massiveness
The state of being interesting is interestingness
The state of being strange is strangeness
The state of being broken is brokenness
The state of being cheap is cheapness
The state of being distinctive is distinctiveness
The state of being related is
2024-07-31 06:05:56 root INFO     [order_1_approx] starting weight calculation for The state of being broken is brokenness
The state of being hot is hotness
The state of being related is relatedness
The state of being distinctive is distinctiveness
The state of being massive is massiveness
The state of being cheap is cheapness
The state of being interesting is interestingness
The state of being strange is
2024-07-31 06:05:56 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-31 06:06:44 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0988, -0.1172,  0.0862,  ...,  0.2288, -0.2944, -0.0704],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.8594, -6.9141,  1.5664,  ...,  0.7402, -1.3604,  2.6699],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0380, -0.0042,  0.0145,  ..., -0.0009, -0.0153, -0.0193],
        [-0.0114,  0.0493, -0.0057,  ...,  0.0361, -0.0197, -0.0211],
        [-0.0002,  0.0248,  0.0255,  ...,  0.0041, -0.0242, -0.0241],
        ...,
        [-0.0072,  0.0109,  0.0069,  ...,  0.0439, -0.0107, -0.0004],
        [-0.0112,  0.0162, -0.0234,  ...,  0.0053,  0.0322, -0.0152],
        [-0.0178, -0.0181,  0.0248,  ...,  0.0051,  0.0155,  0.0533]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.2812, -6.9492,  0.7896,  ...,  0.3591, -2.1602,  3.0410]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 06:06:45 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A penny is made up of metal
A cocktail is made up of alcohol
A jam is made up of fruit
A icicle is made up of ice
A flag is made up of fabric
A wine is made up of grapes
A candy is made up of sugar
A boots is made up of
2024-07-31 06:06:45 root INFO     [order_1_approx] starting weight calculation for A icicle is made up of ice
A penny is made up of metal
A boots is made up of leather
A candy is made up of sugar
A wine is made up of grapes
A cocktail is made up of alcohol
A jam is made up of fruit
A flag is made up of
2024-07-31 06:06:45 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-31 06:08:36 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0643,  0.1174, -0.0154,  ..., -0.0042, -0.1034,  0.0088],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.4004, -2.5645, -2.7637,  ..., -3.2578, -4.4609, -1.8340],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 2.3514e-02,  2.4323e-02, -3.9124e-02,  ..., -5.3673e-03,
         -2.2354e-02,  4.4937e-03],
        [-8.6823e-03, -6.7215e-03,  2.6627e-03,  ...,  1.4648e-02,
         -4.3831e-03, -4.6492e-04],
        [ 1.2833e-02, -1.2131e-02,  1.9119e-02,  ...,  1.6968e-02,
         -1.0071e-02, -7.5912e-03],
        ...,
        [-1.3199e-02,  2.0462e-02,  6.7368e-03,  ...,  1.8631e-02,
          1.6212e-03, -4.9667e-03],
        [ 1.0902e-02,  1.6495e-02,  1.7975e-02,  ...,  1.0750e-02,
          1.6617e-02, -2.3376e-02],
        [ 1.3153e-02, -8.3923e-05,  6.2561e-04,  ...,  2.3560e-02,
         -2.4170e-02,  1.4702e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.2363, -2.6328, -2.8242,  ..., -3.4219, -4.7031, -2.0801]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 06:08:37 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The state of being broken is brokenness
The state of being hot is hotness
The state of being related is relatedness
The state of being distinctive is distinctiveness
The state of being massive is massiveness
The state of being cheap is cheapness
The state of being interesting is interestingness
The state of being strange is
2024-07-31 06:08:37 root INFO     [order_1_approx] starting weight calculation for The state of being strange is strangeness
The state of being distinctive is distinctiveness
The state of being cheap is cheapness
The state of being hot is hotness
The state of being broken is brokenness
The state of being related is relatedness
The state of being interesting is interestingness
The state of being massive is
2024-07-31 06:08:37 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-31 06:09:11 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2354,  0.2793, -0.5522,  ...,  0.2102, -0.1486, -0.0820],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.6211, -6.4805,  1.9229,  ..., -3.9023,  0.2578,  0.6729],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0314, -0.0192, -0.0241,  ..., -0.0173, -0.0225, -0.0279],
        [-0.0179,  0.0550,  0.0294,  ...,  0.0143,  0.0056,  0.0049],
        [-0.0058,  0.0110,  0.0137,  ...,  0.0021, -0.0203, -0.0303],
        ...,
        [ 0.0093,  0.0115,  0.0204,  ...,  0.0428,  0.0021, -0.0375],
        [-0.0237,  0.0008, -0.0159,  ...,  0.0083,  0.0232, -0.0041],
        [ 0.0407, -0.0151, -0.0076,  ..., -0.0136,  0.0081,  0.0386]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.2129, -6.5273,  1.6699,  ..., -4.1211, -0.7900,  1.0488]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 06:09:12 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A icicle is made up of ice
A penny is made up of metal
A boots is made up of leather
A candy is made up of sugar
A wine is made up of grapes
A cocktail is made up of alcohol
A jam is made up of fruit
A flag is made up of
2024-07-31 06:09:12 root INFO     [order_1_approx] starting weight calculation for A boots is made up of leather
A candy is made up of sugar
A jam is made up of fruit
A penny is made up of metal
A flag is made up of fabric
A cocktail is made up of alcohol
A wine is made up of grapes
A icicle is made up of
2024-07-31 06:09:12 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-31 06:11:16 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1945,  0.0255,  0.0608,  ...,  0.2236, -0.3228, -0.2336],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.7344, -4.4453, -2.9590,  ..., -4.5625, -5.4805, -4.3047],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0549, -0.0207, -0.0220,  ...,  0.0018,  0.0270,  0.0179],
        [-0.0169,  0.0346,  0.0043,  ..., -0.0374, -0.0143,  0.0135],
        [ 0.0062, -0.0614,  0.0471,  ...,  0.0093,  0.0071,  0.0396],
        ...,
        [-0.0040,  0.0137,  0.0140,  ...,  0.0240, -0.0319, -0.0164],
        [ 0.0291,  0.0237, -0.0218,  ..., -0.0116,  0.0145, -0.0033],
        [-0.0030,  0.0200, -0.0057,  ...,  0.0166, -0.0191,  0.0192]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.4495, -4.6562, -3.1934,  ..., -4.6680, -5.5156, -4.3164]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 06:11:17 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The state of being strange is strangeness
The state of being distinctive is distinctiveness
The state of being cheap is cheapness
The state of being hot is hotness
The state of being broken is brokenness
The state of being related is relatedness
The state of being interesting is interestingness
The state of being massive is
2024-07-31 06:11:17 root INFO     total operator prediction time: 1286.8659436702728 seconds
2024-07-31 06:11:17 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on re+verb_reg
2024-07-31 06:11:17 root INFO     building operator re+verb_reg
2024-07-31 06:11:17 root INFO     [order_1_approx] starting weight calculation for To submit again is to resubmit
To solve again is to resolve
To tell again is to retell
To assign again is to reassign
To write again is to rewrite
To organize again is to reorganize
To generate again is to regenerate
To appoint again is to
2024-07-31 06:11:17 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-31 06:11:45 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0546, -0.0858, -0.4656,  ..., -0.0512, -0.2117,  0.1718],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.9697, -4.7812, -0.0208,  ..., -5.0000,  0.6685, -0.7139],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0486, -0.0439, -0.0110,  ..., -0.0089,  0.0086, -0.0140],
        [ 0.0046,  0.0203,  0.0047,  ..., -0.0211, -0.0019, -0.0358],
        [-0.0050,  0.0458,  0.0332,  ...,  0.0291,  0.0173, -0.0026],
        ...,
        [ 0.0141,  0.0231,  0.0202,  ...,  0.0759,  0.0007, -0.0055],
        [-0.0414,  0.0569,  0.0039,  ...,  0.0504,  0.0270,  0.0235],
        [-0.0036, -0.0307, -0.0026,  ..., -0.0004,  0.0024,  0.0247]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.3145, -4.9297,  0.1420,  ..., -4.8789,  0.2346, -0.4800]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 06:11:46 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A boots is made up of leather
A candy is made up of sugar
A jam is made up of fruit
A penny is made up of metal
A flag is made up of fabric
A cocktail is made up of alcohol
A wine is made up of grapes
A icicle is made up of
2024-07-31 06:11:46 root INFO     [order_1_approx] starting weight calculation for A icicle is made up of ice
A boots is made up of leather
A penny is made up of metal
A flag is made up of fabric
A cocktail is made up of alcohol
A candy is made up of sugar
A jam is made up of fruit
A wine is made up of
2024-07-31 06:11:46 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-31 06:13:55 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2590,  0.4077, -0.1012,  ...,  0.0021, -0.3645, -0.0004],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.9458, -4.4648,  0.9414,  ...,  2.3945, -6.2891, -4.7227],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0497, -0.0075,  0.0225,  ...,  0.0007, -0.0085,  0.0068],
        [-0.0010,  0.0112,  0.0070,  ...,  0.0145, -0.0021, -0.0034],
        [-0.0166, -0.0020,  0.0200,  ..., -0.0094, -0.0018, -0.0081],
        ...,
        [ 0.0151,  0.0166, -0.0009,  ...,  0.0142, -0.0026, -0.0052],
        [ 0.0189,  0.0009, -0.0174,  ..., -0.0004,  0.0096, -0.0107],
        [ 0.0053, -0.0131,  0.0016,  ..., -0.0145, -0.0237,  0.0349]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.1182, -4.5938,  0.6992,  ...,  2.2148, -6.1562, -4.7188]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 06:13:56 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To submit again is to resubmit
To solve again is to resolve
To tell again is to retell
To assign again is to reassign
To write again is to rewrite
To organize again is to reorganize
To generate again is to regenerate
To appoint again is to
2024-07-31 06:13:56 root INFO     [order_1_approx] starting weight calculation for To solve again is to resolve
To assign again is to reassign
To submit again is to resubmit
To organize again is to reorganize
To write again is to rewrite
To generate again is to regenerate
To appoint again is to reappoint
To tell again is to
2024-07-31 06:13:56 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-31 06:14:20 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2106,  0.1406, -0.4744,  ..., -0.2185,  0.1619, -0.4236],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.0430, -5.6953, -2.4629,  ..., -3.5430,  1.3291, -1.9092],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 2.1194e-02, -1.0925e-02,  4.7760e-03,  ..., -1.8097e-02,
         -1.9775e-02,  4.3411e-03],
        [-2.0050e-02,  3.2593e-02,  8.7967e-03,  ...,  4.4632e-03,
          9.2316e-03, -1.9470e-02],
        [ 5.3482e-03, -3.6850e-03,  3.5126e-02,  ..., -7.6532e-05,
         -8.1787e-03,  1.0094e-02],
        ...,
        [-1.3535e-02,  5.5923e-03,  7.5493e-03,  ...,  3.9490e-02,
          7.7553e-03, -2.3682e-02],
        [ 8.7891e-03,  3.9062e-02, -3.7781e-02,  ...,  2.7573e-02,
          1.2207e-03,  4.1687e-02],
        [-1.2207e-03, -1.3474e-02,  1.2619e-02,  ..., -2.3346e-02,
          1.9516e-02,  2.0416e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.2461, -5.7969, -3.0352,  ..., -3.6348,  0.2861, -1.5635]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 06:14:21 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A icicle is made up of ice
A boots is made up of leather
A penny is made up of metal
A flag is made up of fabric
A cocktail is made up of alcohol
A candy is made up of sugar
A jam is made up of fruit
A wine is made up of
2024-07-31 06:14:22 root INFO     [order_1_approx] starting weight calculation for A boots is made up of leather
A jam is made up of fruit
A icicle is made up of ice
A wine is made up of grapes
A candy is made up of sugar
A flag is made up of fabric
A cocktail is made up of alcohol
A penny is made up of
2024-07-31 06:14:22 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-31 06:16:36 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1229,  0.0770,  0.0086,  ...,  0.0299, -0.1841, -0.0232],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.1313, -2.2070,  0.6113,  ...,  0.1211, -3.8516, -2.7324],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 3.3997e-02,  3.9902e-03,  2.7618e-02,  ..., -2.0065e-03,
         -2.2293e-02,  1.8616e-02],
        [-8.9645e-04,  1.6006e-02, -2.8458e-03,  ...,  3.6774e-03,
          6.3667e-03,  1.0157e-04],
        [-2.9404e-02, -8.6899e-03,  2.0523e-02,  ..., -3.3569e-04,
          1.9321e-03, -8.7128e-03],
        ...,
        [ 8.0566e-03, -6.6452e-03, -2.2507e-04,  ...,  3.5736e-02,
          1.0910e-02,  2.3842e-03],
        [ 9.3918e-03,  7.8812e-03, -3.7308e-03,  ..., -1.2100e-02,
          1.4923e-02,  2.3331e-02],
        [-1.2299e-02, -2.3392e-02, -1.6602e-02,  ..., -2.2650e-06,
          2.3071e-02,  9.5901e-03]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.1812, -2.0938,  0.7812,  ...,  0.1659, -3.3320, -2.8027]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 06:16:37 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To solve again is to resolve
To assign again is to reassign
To submit again is to resubmit
To organize again is to reorganize
To write again is to rewrite
To generate again is to regenerate
To appoint again is to reappoint
To tell again is to
2024-07-31 06:16:37 root INFO     [order_1_approx] starting weight calculation for To appoint again is to reappoint
To solve again is to resolve
To generate again is to regenerate
To organize again is to reorganize
To write again is to rewrite
To assign again is to reassign
To tell again is to retell
To submit again is to
2024-07-31 06:16:37 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-31 06:16:55 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1947,  0.0706, -0.3557,  ..., -0.0316, -0.0560,  0.0045],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.0664, -1.7969, -1.5811,  ..., -4.8906,  0.3020,  1.1240],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0740, -0.0673, -0.0251,  ..., -0.0226, -0.0183, -0.0183],
        [-0.0133,  0.0520,  0.0331,  ...,  0.0244, -0.0013, -0.0131],
        [ 0.0039,  0.0368,  0.0565,  ...,  0.0267, -0.0077,  0.0095],
        ...,
        [-0.0016,  0.0237,  0.0108,  ...,  0.0712, -0.0051, -0.0029],
        [ 0.0023,  0.0181, -0.0006,  ...,  0.0166,  0.0181, -0.0139],
        [-0.0099, -0.0003, -0.0107,  ..., -0.0173,  0.0080,  0.0424]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.8438, -1.7012, -1.8281,  ..., -5.2695,  0.1836,  1.5176]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 06:16:56 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A boots is made up of leather
A jam is made up of fruit
A icicle is made up of ice
A wine is made up of grapes
A candy is made up of sugar
A flag is made up of fabric
A cocktail is made up of alcohol
A penny is made up of
2024-07-31 06:16:56 root INFO     [order_1_approx] starting weight calculation for A boots is made up of leather
A jam is made up of fruit
A icicle is made up of ice
A flag is made up of fabric
A candy is made up of sugar
A wine is made up of grapes
A penny is made up of metal
A cocktail is made up of
2024-07-31 06:16:57 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-31 06:19:15 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0769, -0.1367, -0.3193,  ..., -0.0078, -0.3250,  0.1959],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.0957, -2.7910, -0.0432,  ...,  0.8447, -2.6992, -3.0430],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0471, -0.0286,  0.0183,  ...,  0.0017,  0.0047,  0.0200],
        [ 0.0053,  0.0254, -0.0012,  ...,  0.0056, -0.0100,  0.0033],
        [-0.0193,  0.0063,  0.0130,  ..., -0.0022,  0.0219, -0.0051],
        ...,
        [ 0.0204, -0.0068,  0.0268,  ...,  0.0367,  0.0088,  0.0032],
        [ 0.0117,  0.0059, -0.0025,  ..., -0.0263,  0.0103, -0.0048],
        [-0.0158, -0.0150, -0.0344,  ...,  0.0030, -0.0541,  0.0192]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.1826, -2.5703,  0.5283,  ...,  1.0771, -3.2520, -3.2930]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 06:19:16 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To appoint again is to reappoint
To solve again is to resolve
To generate again is to regenerate
To organize again is to reorganize
To write again is to rewrite
To assign again is to reassign
To tell again is to retell
To submit again is to
2024-07-31 06:19:16 root INFO     [order_1_approx] starting weight calculation for To organize again is to reorganize
To solve again is to resolve
To submit again is to resubmit
To write again is to rewrite
To tell again is to retell
To appoint again is to reappoint
To assign again is to reassign
To generate again is to
2024-07-31 06:19:16 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-31 06:19:30 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1332,  0.0176, -0.5713,  ...,  0.1343, -0.4888, -0.1674],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.3867, -6.8164, -3.5879,  ..., -2.3086, -0.9062, -4.5273],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0360, -0.0203, -0.0040,  ..., -0.0104, -0.0088,  0.0317],
        [ 0.0010,  0.0221,  0.0149,  ..., -0.0085,  0.0272, -0.0254],
        [-0.0015, -0.0045,  0.0290,  ..., -0.0078, -0.0179, -0.0051],
        ...,
        [-0.0360,  0.0376,  0.0060,  ...,  0.0652, -0.0087, -0.0255],
        [-0.0214,  0.0134, -0.0228,  ...,  0.0242,  0.0177,  0.0375],
        [ 0.0288, -0.0246, -0.0094,  ..., -0.0199,  0.0212,  0.0084]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.9941, -6.3711, -3.8477,  ..., -2.6602, -1.3994, -3.9961]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 06:19:31 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A boots is made up of leather
A jam is made up of fruit
A icicle is made up of ice
A flag is made up of fabric
A candy is made up of sugar
A wine is made up of grapes
A penny is made up of metal
A cocktail is made up of
2024-07-31 06:19:32 root INFO     [order_1_approx] starting weight calculation for A icicle is made up of ice
A wine is made up of grapes
A cocktail is made up of alcohol
A flag is made up of fabric
A penny is made up of metal
A jam is made up of fruit
A boots is made up of leather
A candy is made up of
2024-07-31 06:19:32 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-31 06:21:54 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0651,  0.0580, -0.0621,  ...,  0.4170, -0.0674,  0.0806],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.0697, -1.5840,  0.4004,  ...,  2.6289, -4.9766, -4.1445],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0222, -0.0026,  0.0292,  ...,  0.0283, -0.0083,  0.0056],
        [-0.0008,  0.0456,  0.0046,  ..., -0.0068,  0.0071,  0.0135],
        [-0.0013, -0.0137,  0.0179,  ..., -0.0109,  0.0118, -0.0118],
        ...,
        [ 0.0101, -0.0179,  0.0019,  ...,  0.0447, -0.0062,  0.0157],
        [ 0.0014,  0.0216, -0.0338,  ..., -0.0257,  0.0027, -0.0071],
        [-0.0430, -0.0255, -0.0078,  ..., -0.0167, -0.0125,  0.0379]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.1860, -1.8750,  0.8320,  ...,  2.5117, -4.8047, -4.0352]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 06:21:55 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To organize again is to reorganize
To solve again is to resolve
To submit again is to resubmit
To write again is to rewrite
To tell again is to retell
To appoint again is to reappoint
To assign again is to reassign
To generate again is to
2024-07-31 06:21:55 root INFO     [order_1_approx] starting weight calculation for To assign again is to reassign
To generate again is to regenerate
To solve again is to resolve
To submit again is to resubmit
To tell again is to retell
To write again is to rewrite
To appoint again is to reappoint
To organize again is to
2024-07-31 06:21:55 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-31 06:22:06 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.4377,  0.2314, -0.4624,  ..., -0.0677, -0.3691, -0.0436],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.5020, -5.8125, -0.7686,  ..., -3.1152, -1.7090,  5.4883],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0300, -0.0023,  0.0089,  ..., -0.0047, -0.0329,  0.0037],
        [-0.0059,  0.0388,  0.0062,  ..., -0.0073,  0.0314, -0.0204],
        [-0.0037,  0.0269,  0.0182,  ...,  0.0028, -0.0180, -0.0017],
        ...,
        [ 0.0008, -0.0167,  0.0193,  ...,  0.0366, -0.0027, -0.0045],
        [-0.0190,  0.0453, -0.0047,  ...,  0.0250,  0.0197,  0.0074],
        [ 0.0116,  0.0045, -0.0087,  ..., -0.0043,  0.0266,  0.0475]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.3799, -5.7031, -1.1152,  ..., -3.0000, -2.9863,  5.7656]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 06:22:07 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A icicle is made up of ice
A wine is made up of grapes
A cocktail is made up of alcohol
A flag is made up of fabric
A penny is made up of metal
A jam is made up of fruit
A boots is made up of leather
A candy is made up of
2024-07-31 06:22:07 root INFO     total operator prediction time: 1232.1731071472168 seconds
2024-07-31 06:22:07 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on hypernyms - misc
2024-07-31 06:22:07 root INFO     building operator hypernyms - misc
2024-07-31 06:22:07 root INFO     [order_1_approx] starting weight calculation for The lemon falls into the category of citrus
The sidewalk falls into the category of walk
The deodorant falls into the category of toiletry
The hairnet falls into the category of net
The sweater falls into the category of clothes
The croissant falls into the category of pastry
The hairpin falls into the category of pin
The denim falls into the category of
2024-07-31 06:22:07 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-31 06:24:32 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0432,  0.5078, -0.1405,  ..., -0.1547, -0.3218,  0.0953],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-2.0117, -3.5547,  2.0703,  ...,  1.4648, -2.5273, -4.7812],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 3.6194e-02,  6.2103e-03,  1.5213e-02,  ...,  1.8585e-02,
         -4.3564e-03, -1.8680e-04],
        [-5.5122e-03,  1.8036e-02,  4.8161e-05,  ...,  1.0719e-03,
         -2.6855e-02, -1.6144e-02],
        [-1.5228e-02,  3.4119e-02,  3.2406e-03,  ...,  2.7714e-03,
          1.2222e-02,  2.1057e-02],
        ...,
        [ 2.4643e-02,  2.7637e-03,  7.7782e-03,  ...,  1.5884e-02,
         -9.7656e-03, -3.7670e-03],
        [-1.0262e-02,  7.2289e-03, -1.0551e-02,  ...,  1.6365e-03,
         -1.5945e-03, -1.1658e-02],
        [-7.4272e-03, -5.0354e-04,  2.6493e-03,  ..., -2.2144e-03,
         -3.3951e-03,  2.7161e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-2.2266, -3.6250,  2.5996,  ...,  1.6123, -2.4316, -4.3281]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 06:24:34 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To assign again is to reassign
To generate again is to regenerate
To solve again is to resolve
To submit again is to resubmit
To tell again is to retell
To write again is to rewrite
To appoint again is to reappoint
To organize again is to
2024-07-31 06:24:34 root INFO     [order_1_approx] starting weight calculation for To tell again is to retell
To submit again is to resubmit
To generate again is to regenerate
To appoint again is to reappoint
To organize again is to reorganize
To solve again is to resolve
To assign again is to reassign
To write again is to
2024-07-31 06:24:34 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-31 06:24:39 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.3008, -0.0203, -0.5811,  ...,  0.5840, -0.4548,  0.0967],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 5.1250, -8.3594,  1.6172,  ..., -0.2703, -3.1641, -0.1045],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0465,  0.0060,  0.0023,  ..., -0.0133, -0.0143, -0.0059],
        [-0.0045,  0.0421, -0.0299,  ...,  0.0203, -0.0006,  0.0077],
        [-0.0209, -0.0135,  0.0506,  ..., -0.0144, -0.0138, -0.0041],
        ...,
        [ 0.0259, -0.0113, -0.0032,  ...,  0.0530,  0.0022, -0.0025],
        [ 0.0029, -0.0034, -0.0084,  ...,  0.0315,  0.0464, -0.0161],
        [ 0.0162, -0.0181,  0.0118,  ..., -0.0028,  0.0048,  0.0526]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.3945, -8.2422,  1.5391,  ..., -0.2593, -3.1016,  0.5015]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 06:24:40 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The lemon falls into the category of citrus
The sidewalk falls into the category of walk
The deodorant falls into the category of toiletry
The hairnet falls into the category of net
The sweater falls into the category of clothes
The croissant falls into the category of pastry
The hairpin falls into the category of pin
The denim falls into the category of
2024-07-31 06:24:40 root INFO     [order_1_approx] starting weight calculation for The denim falls into the category of fabric
The croissant falls into the category of pastry
The sidewalk falls into the category of walk
The lemon falls into the category of citrus
The sweater falls into the category of clothes
The hairpin falls into the category of pin
The deodorant falls into the category of toiletry
The hairnet falls into the category of
2024-07-31 06:24:40 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-31 06:27:12 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0428, -0.0942, -0.2188,  ..., -0.0535, -0.3154,  0.0742],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.1113, -3.6289,  1.1836,  ...,  2.6309, -6.6602, -2.4746],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0487, -0.0176,  0.0182,  ...,  0.0131, -0.0100,  0.0020],
        [ 0.0001,  0.0048,  0.0033,  ..., -0.0010, -0.0102, -0.0026],
        [ 0.0053, -0.0069,  0.0208,  ...,  0.0093, -0.0247, -0.0032],
        ...,
        [ 0.0127, -0.0074, -0.0016,  ...,  0.0145, -0.0031,  0.0121],
        [ 0.0074,  0.0158, -0.0012,  ..., -0.0062,  0.0008, -0.0038],
        [-0.0019,  0.0172, -0.0068,  ...,  0.0069, -0.0254,  0.0212]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.1582, -3.7012,  1.4355,  ...,  2.7832, -7.2305, -2.3008]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 06:27:12 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2542, -0.0836, -0.3694,  ...,  0.2181, -0.0221,  0.0392],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.1133, -3.6172,  1.6943,  ..., -1.8115, -4.1992,  3.9492],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 8.6731e-02, -3.0518e-05,  1.1299e-02,  ...,  3.2425e-04,
         -1.5762e-02,  5.4932e-03],
        [-1.8692e-02,  5.7587e-02, -2.2858e-02,  ...,  1.0651e-02,
         -5.4321e-03, -7.9041e-03],
        [-1.1543e-02,  1.2009e-02,  5.4749e-02,  ..., -5.8784e-03,
         -2.0935e-02, -9.7504e-03],
        ...,
        [ 1.5898e-03, -1.6037e-02,  2.1896e-02,  ...,  3.6499e-02,
          2.6077e-02,  1.3189e-03],
        [-4.0817e-03, -6.5193e-03,  3.5057e-03,  ...,  2.0538e-02,
          2.0889e-02, -5.8861e-03],
        [-4.0039e-02, -2.5620e-02, -1.2989e-03,  ..., -8.3466e-03,
         -4.3488e-04,  3.9185e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.6426, -3.7344,  0.7651,  ..., -1.8389, -3.8984,  3.8027]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 06:27:13 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To tell again is to retell
To submit again is to resubmit
To generate again is to regenerate
To appoint again is to reappoint
To organize again is to reorganize
To solve again is to resolve
To assign again is to reassign
To write again is to
2024-07-31 06:27:14 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The denim falls into the category of fabric
The croissant falls into the category of pastry
The sidewalk falls into the category of walk
The lemon falls into the category of citrus
The sweater falls into the category of clothes
The hairpin falls into the category of pin
The deodorant falls into the category of toiletry
The hairnet falls into the category of
2024-07-31 06:27:14 root INFO     [order_1_approx] starting weight calculation for To write again is to rewrite
To generate again is to regenerate
To submit again is to resubmit
To appoint again is to reappoint
To assign again is to reassign
To organize again is to reorganize
To tell again is to retell
To solve again is to
2024-07-31 06:27:14 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-31 06:27:14 root INFO     [order_1_approx] starting weight calculation for The hairnet falls into the category of net
The denim falls into the category of fabric
The hairpin falls into the category of pin
The deodorant falls into the category of toiletry
The sweater falls into the category of clothes
The sidewalk falls into the category of walk
The lemon falls into the category of citrus
The croissant falls into the category of
2024-07-31 06:27:14 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-31 06:29:45 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1978, -0.1218, -0.4668,  ...,  0.1655, -0.2656,  0.1141],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.5449, -5.7852, -0.8008,  ..., -1.5312, -2.9531,  1.2168],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0773,  0.0027, -0.0199,  ..., -0.0051, -0.0022,  0.0226],
        [ 0.0240,  0.0570,  0.0091,  ...,  0.0419,  0.0179, -0.0350],
        [-0.0065, -0.0322,  0.0488,  ..., -0.0140, -0.0052, -0.0032],
        ...,
        [-0.0007,  0.0127, -0.0076,  ...,  0.0784,  0.0144, -0.0176],
        [-0.0001,  0.0011,  0.0059,  ..., -0.0028,  0.0723, -0.0247],
        [-0.0129,  0.0034, -0.0182,  ...,  0.0053,  0.0106,  0.0500]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.4453, -5.5781, -1.3027,  ..., -1.5547, -2.7383,  1.6211]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 06:29:46 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The hairnet falls into the category of net
The denim falls into the category of fabric
The hairpin falls into the category of pin
The deodorant falls into the category of toiletry
The sweater falls into the category of clothes
The sidewalk falls into the category of walk
The lemon falls into the category of citrus
The croissant falls into the category of
2024-07-31 06:29:47 root INFO     [order_1_approx] starting weight calculation for The hairpin falls into the category of pin
The lemon falls into the category of citrus
The sidewalk falls into the category of walk
The hairnet falls into the category of net
The deodorant falls into the category of toiletry
The denim falls into the category of fabric
The croissant falls into the category of pastry
The sweater falls into the category of
2024-07-31 06:29:47 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-31 06:29:54 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0930,  0.1289, -0.1510,  ..., -0.2463, -0.4727,  0.0390],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.2240, -1.7422, -0.8257,  ...,  2.0547, -4.9062, -0.1035],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 4.5502e-02, -1.6846e-02,  4.5685e-02,  ...,  1.2177e-02,
          3.4103e-03,  1.8356e-02],
        [-1.9547e-02,  3.1342e-02,  1.8692e-04,  ...,  1.5457e-02,
         -3.9864e-03, -1.7822e-02],
        [-1.4191e-02, -3.0308e-03, -4.9591e-05,  ...,  9.3231e-03,
          2.4673e-02, -4.1504e-03],
        ...,
        [-6.1035e-03, -4.8370e-03,  2.3895e-02,  ...,  3.7292e-02,
          2.4628e-02, -6.8130e-03],
        [-2.3697e-02,  2.5787e-02, -1.1848e-02,  ..., -1.3901e-02,
         -3.3051e-02, -2.3727e-02],
        [-6.5422e-03, -1.4877e-03,  2.5711e-02,  ...,  7.1640e-03,
          1.3214e-02,  3.4058e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.0970, -1.7617, -0.5117,  ...,  1.9238, -4.8477, -0.2224]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 06:29:55 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To write again is to rewrite
To generate again is to regenerate
To submit again is to resubmit
To appoint again is to reappoint
To assign again is to reassign
To organize again is to reorganize
To tell again is to retell
To solve again is to
2024-07-31 06:29:55 root INFO     [order_1_approx] starting weight calculation for To solve again is to resolve
To organize again is to reorganize
To tell again is to retell
To write again is to rewrite
To generate again is to regenerate
To submit again is to resubmit
To appoint again is to reappoint
To assign again is to
2024-07-31 06:29:55 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-31 06:32:17 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0031, -0.1803,  0.0039,  ..., -0.0121, -0.5742,  0.1045],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.2598, -7.6484,  1.7490,  ...,  0.4551, -3.5039,  2.8047],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0329, -0.0044,  0.0030,  ...,  0.0193,  0.0152,  0.0053],
        [-0.0145,  0.0165,  0.0235,  ..., -0.0115, -0.0101, -0.0049],
        [ 0.0092,  0.0128,  0.0290,  ...,  0.0021, -0.0339, -0.0078],
        ...,
        [ 0.0233,  0.0038,  0.0006,  ...,  0.0486,  0.0189, -0.0078],
        [-0.0001,  0.0157,  0.0020,  ...,  0.0418,  0.0280, -0.0275],
        [-0.0191,  0.0093,  0.0119,  ...,  0.0034, -0.0027,  0.0268]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.0312, -7.0703,  1.3691,  ...,  0.3374, -3.2520,  2.8672]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 06:32:18 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The hairpin falls into the category of pin
The lemon falls into the category of citrus
The sidewalk falls into the category of walk
The hairnet falls into the category of net
The deodorant falls into the category of toiletry
The denim falls into the category of fabric
The croissant falls into the category of pastry
The sweater falls into the category of
2024-07-31 06:32:18 root INFO     [order_1_approx] starting weight calculation for The hairpin falls into the category of pin
The croissant falls into the category of pastry
The deodorant falls into the category of toiletry
The sidewalk falls into the category of walk
The hairnet falls into the category of net
The sweater falls into the category of clothes
The denim falls into the category of fabric
The lemon falls into the category of
2024-07-31 06:32:18 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-31 06:32:34 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1155,  0.4470, -0.1285,  ...,  0.0166, -0.3464, -0.0879],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.2891, -2.0879, -0.3000,  ...,  2.2246, -4.0820, -4.0273],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0392, -0.0102, -0.0060,  ..., -0.0055, -0.0116,  0.0066],
        [ 0.0068,  0.0116, -0.0039,  ...,  0.0139, -0.0023,  0.0053],
        [-0.0167, -0.0032,  0.0359,  ..., -0.0174, -0.0002, -0.0027],
        ...,
        [ 0.0357,  0.0044, -0.0071,  ...,  0.0341,  0.0076, -0.0087],
        [ 0.0106, -0.0024, -0.0112,  ..., -0.0032,  0.0200,  0.0063],
        [-0.0075,  0.0038, -0.0271,  ..., -0.0405, -0.0367,  0.0188]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.2197, -2.2324,  0.2078,  ...,  1.8086, -3.7930, -3.8008]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 06:32:35 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To solve again is to resolve
To organize again is to reorganize
To tell again is to retell
To write again is to rewrite
To generate again is to regenerate
To submit again is to resubmit
To appoint again is to reappoint
To assign again is to
2024-07-31 06:32:35 root INFO     total operator prediction time: 1277.6115567684174 seconds
2024-07-31 06:32:35 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on un+adj_reg
2024-07-31 06:32:35 root INFO     building operator un+adj_reg
2024-07-31 06:32:35 root INFO     [order_1_approx] starting weight calculation for The opposite of biased is unbiased
The opposite of paid is unpaid
The opposite of veiled is unveiled
The opposite of healthy is unhealthy
The opposite of restricted is unrestricted
The opposite of finished is unfinished
The opposite of noticed is unnoticed
The opposite of resolved is
2024-07-31 06:32:35 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-31 06:34:49 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2102, -0.2646, -0.5776,  ..., -0.1132, -0.1294, -0.2646],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.0488, -5.4805, -1.3418,  ..., -4.2969, -2.4238, -1.7910],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0555,  0.0065, -0.0084,  ...,  0.0297, -0.0038,  0.0104],
        [ 0.0038,  0.0398,  0.0356,  ...,  0.0128, -0.0186,  0.0211],
        [-0.0104, -0.0075,  0.0279,  ...,  0.0201, -0.0177, -0.0159],
        ...,
        [-0.0022, -0.0075,  0.0073,  ...,  0.0514,  0.0109, -0.0092],
        [ 0.0086, -0.0111, -0.0081,  ...,  0.0135,  0.0464, -0.0052],
        [-0.0209, -0.0122,  0.0348,  ..., -0.0249, -0.0076,  0.0469]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.0625, -5.1914, -1.6035,  ..., -3.9766, -2.3145, -1.0479]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 06:34:50 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The hairpin falls into the category of pin
The croissant falls into the category of pastry
The deodorant falls into the category of toiletry
The sidewalk falls into the category of walk
The hairnet falls into the category of net
The sweater falls into the category of clothes
The denim falls into the category of fabric
The lemon falls into the category of
2024-07-31 06:34:50 root INFO     [order_1_approx] starting weight calculation for The sweater falls into the category of clothes
The lemon falls into the category of citrus
The denim falls into the category of fabric
The hairnet falls into the category of net
The deodorant falls into the category of toiletry
The croissant falls into the category of pastry
The sidewalk falls into the category of walk
The hairpin falls into the category of
2024-07-31 06:34:50 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-31 06:35:15 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.3013,  0.0667, -0.5957,  ..., -0.2920, -0.3511,  0.0796],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.6094, -0.3027,  0.4897,  ...,  0.2009, -0.8936, -1.1035],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0533,  0.0154,  0.0084,  ...,  0.0147, -0.0271,  0.0129],
        [-0.0264,  0.0298,  0.0140,  ..., -0.0088,  0.0039, -0.0106],
        [ 0.0166, -0.0046,  0.0359,  ..., -0.0093, -0.0214,  0.0202],
        ...,
        [ 0.0132,  0.0234,  0.0068,  ...,  0.0324, -0.0155, -0.0065],
        [-0.0040,  0.0101, -0.0187,  ...,  0.0333,  0.0319, -0.0279],
        [ 0.0061,  0.0017,  0.0057,  ..., -0.0174,  0.0047,  0.0177]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.6880, -0.7559,  0.7793,  ...,  0.2397, -0.9233, -0.8203]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 06:35:16 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of biased is unbiased
The opposite of paid is unpaid
The opposite of veiled is unveiled
The opposite of healthy is unhealthy
The opposite of restricted is unrestricted
The opposite of finished is unfinished
The opposite of noticed is unnoticed
The opposite of resolved is
2024-07-31 06:35:16 root INFO     [order_1_approx] starting weight calculation for The opposite of biased is unbiased
The opposite of veiled is unveiled
The opposite of healthy is unhealthy
The opposite of noticed is unnoticed
The opposite of finished is unfinished
The opposite of resolved is unresolved
The opposite of paid is unpaid
The opposite of restricted is
2024-07-31 06:35:16 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-31 06:37:16 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0120, -0.4194, -0.1642,  ...,  0.3472,  0.1929, -0.2148],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.7109, -3.8340, -1.1172,  ..., -1.6074, -4.3828,  2.5645],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.1097, -0.0183, -0.0066,  ..., -0.0045, -0.0190,  0.0210],
        [-0.0081,  0.0281, -0.0123,  ..., -0.0162, -0.0294, -0.0361],
        [-0.0152,  0.0193,  0.0699,  ..., -0.0039, -0.0032, -0.0141],
        ...,
        [-0.0150, -0.0147,  0.0178,  ...,  0.0526,  0.0246, -0.0238],
        [ 0.0008, -0.0019,  0.0048,  ...,  0.0236,  0.0535,  0.0073],
        [-0.0238, -0.0257,  0.0057,  ..., -0.0128,  0.0054,  0.0370]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.7666, -3.9062, -1.8320,  ..., -1.0273, -4.2031,  2.6621]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 06:37:17 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The sweater falls into the category of clothes
The lemon falls into the category of citrus
The denim falls into the category of fabric
The hairnet falls into the category of net
The deodorant falls into the category of toiletry
The croissant falls into the category of pastry
The sidewalk falls into the category of walk
The hairpin falls into the category of
2024-07-31 06:37:17 root INFO     [order_1_approx] starting weight calculation for The lemon falls into the category of citrus
The hairnet falls into the category of net
The hairpin falls into the category of pin
The sweater falls into the category of clothes
The denim falls into the category of fabric
The croissant falls into the category of pastry
The deodorant falls into the category of toiletry
The sidewalk falls into the category of
2024-07-31 06:37:17 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-31 06:37:55 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0196, -0.0266, -0.5474,  ..., -0.1305,  0.0539,  0.1710],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.5850,  0.1008,  1.4492,  ...,  0.3618, -1.8057, -1.7539],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 5.8533e-02,  1.8997e-03, -2.8442e-02,  ..., -1.6556e-02,
          2.2125e-04,  1.1368e-02],
        [-2.0157e-02,  4.9988e-02,  1.9028e-02,  ..., -3.3447e-02,
         -4.1687e-02, -9.7122e-03],
        [-8.2016e-05,  7.3929e-03,  2.1301e-02,  ..., -2.1835e-02,
          4.8676e-03, -1.1360e-02],
        ...,
        [ 1.5060e-02,  5.3345e-02,  4.7035e-03,  ...,  3.9024e-03,
          1.9989e-03, -6.8998e-04],
        [ 2.2964e-03, -1.9699e-02, -1.6937e-02,  ...,  2.5024e-02,
          1.3489e-02,  9.0256e-03],
        [-1.6479e-02,  4.0588e-03, -2.9846e-02,  ...,  4.5166e-03,
          9.9487e-03,  2.8946e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.3086, -0.1160,  1.7070,  ...,  0.1116, -1.5166, -1.6289]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 06:37:56 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of biased is unbiased
The opposite of veiled is unveiled
The opposite of healthy is unhealthy
The opposite of noticed is unnoticed
The opposite of finished is unfinished
The opposite of resolved is unresolved
The opposite of paid is unpaid
The opposite of restricted is
2024-07-31 06:37:56 root INFO     [order_1_approx] starting weight calculation for The opposite of finished is unfinished
The opposite of veiled is unveiled
The opposite of paid is unpaid
The opposite of restricted is unrestricted
The opposite of resolved is unresolved
The opposite of biased is unbiased
The opposite of healthy is unhealthy
The opposite of noticed is
2024-07-31 06:37:56 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-31 06:39:45 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0735, -0.0448, -0.5376,  ...,  0.1702, -0.2715, -0.2333],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.9380, -5.0312,  1.2900,  ...,  0.0302, -3.5586, -0.0078],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0838,  0.0091, -0.0045,  ..., -0.0008, -0.0048, -0.0080],
        [-0.0116,  0.0214,  0.0340,  ..., -0.0014, -0.0180,  0.0050],
        [-0.0272,  0.0125,  0.0428,  ..., -0.0229,  0.0160, -0.0080],
        ...,
        [-0.0034, -0.0108,  0.0082,  ...,  0.0555,  0.0077, -0.0098],
        [ 0.0086, -0.0082,  0.0074,  ..., -0.0201,  0.0446,  0.0163],
        [ 0.0099, -0.0052,  0.0089,  ..., -0.0064,  0.0148,  0.0496]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.1523, -4.6680,  0.9736,  ...,  0.2391, -3.4277,  0.4631]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 06:39:46 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The lemon falls into the category of citrus
The hairnet falls into the category of net
The hairpin falls into the category of pin
The sweater falls into the category of clothes
The denim falls into the category of fabric
The croissant falls into the category of pastry
The deodorant falls into the category of toiletry
The sidewalk falls into the category of
2024-07-31 06:39:46 root INFO     [order_1_approx] starting weight calculation for The hairpin falls into the category of pin
The croissant falls into the category of pastry
The sweater falls into the category of clothes
The lemon falls into the category of citrus
The sidewalk falls into the category of walk
The denim falls into the category of fabric
The hairnet falls into the category of net
The deodorant falls into the category of
2024-07-31 06:39:46 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-31 06:40:34 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0480, -0.0362, -0.1506,  ..., -0.1326, -0.4094,  0.1371],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.6250,  0.4609, -1.2275,  ..., -3.6172, -2.5977, -1.3721],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0795, -0.0100,  0.0136,  ...,  0.0345,  0.0144,  0.0314],
        [-0.0233,  0.0663,  0.0128,  ..., -0.0075, -0.0130, -0.0334],
        [-0.0254,  0.0065,  0.0265,  ...,  0.0200, -0.0257, -0.0177],
        ...,
        [-0.0116,  0.0191,  0.0109,  ...,  0.0293,  0.0175,  0.0112],
        [-0.0057, -0.0026, -0.0240,  ...,  0.0076,  0.0844, -0.0046],
        [-0.0051,  0.0099, -0.0293,  ...,  0.0184, -0.0229,  0.0294]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.2549,  0.4321, -0.7617,  ..., -3.3281, -2.6328, -0.8281]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 06:40:35 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of finished is unfinished
The opposite of veiled is unveiled
The opposite of paid is unpaid
The opposite of restricted is unrestricted
The opposite of resolved is unresolved
The opposite of biased is unbiased
The opposite of healthy is unhealthy
The opposite of noticed is
2024-07-31 06:40:35 root INFO     [order_1_approx] starting weight calculation for The opposite of resolved is unresolved
The opposite of biased is unbiased
The opposite of noticed is unnoticed
The opposite of paid is unpaid
The opposite of healthy is unhealthy
The opposite of veiled is unveiled
The opposite of restricted is unrestricted
The opposite of finished is
2024-07-31 06:40:35 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-31 06:42:18 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1076, -0.5479, -0.1741,  ..., -0.1478, -0.3960, -0.2842],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.3105, -4.1484,  0.1392,  ..., -3.5938, -4.2266, -0.0918],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0191, -0.0048, -0.0054,  ...,  0.0002, -0.0054,  0.0114],
        [-0.0088,  0.0101, -0.0078,  ..., -0.0003, -0.0050,  0.0139],
        [-0.0121,  0.0026,  0.0244,  ..., -0.0119, -0.0092, -0.0119],
        ...,
        [ 0.0015, -0.0019, -0.0051,  ...,  0.0263,  0.0065,  0.0003],
        [-0.0001,  0.0007,  0.0055,  ...,  0.0068,  0.0138, -0.0015],
        [-0.0085, -0.0164,  0.0055,  ...,  0.0042,  0.0008,  0.0240]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.2793, -4.6875,  0.1771,  ..., -3.5352, -4.0547, -0.2632]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 06:42:19 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The hairpin falls into the category of pin
The croissant falls into the category of pastry
The sweater falls into the category of clothes
The lemon falls into the category of citrus
The sidewalk falls into the category of walk
The denim falls into the category of fabric
The hairnet falls into the category of net
The deodorant falls into the category of
2024-07-31 06:42:19 root INFO     total operator prediction time: 1212.258046388626 seconds
2024-07-31 06:42:19 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on synonyms - exact
2024-07-31 06:42:19 root INFO     building operator synonyms - exact
2024-07-31 06:42:19 root INFO     [order_1_approx] starting weight calculation for Another word for jewel is gem
Another word for airplane is aeroplane
Another word for monument is memorial
Another word for mother is mom
Another word for snake is serpent
Another word for harbor is seaport
Another word for mesh is gauze
Another word for spouse is
2024-07-31 06:42:19 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-31 06:43:12 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0485,  0.0786, -0.2637,  ..., -0.2671, -0.2681,  0.2803],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.7373, -2.1055,  0.2656,  ...,  0.7612,  0.9570, -2.1797],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0586,  0.0024, -0.0240,  ...,  0.0097,  0.0002, -0.0153],
        [ 0.0071,  0.0421, -0.0318,  ..., -0.0093, -0.0233, -0.0356],
        [ 0.0044, -0.0256, -0.0085,  ...,  0.0205,  0.0155,  0.0065],
        ...,
        [ 0.0073,  0.0223, -0.0093,  ...,  0.0219,  0.0012, -0.0133],
        [-0.0003,  0.0499,  0.0449,  ..., -0.0215,  0.0385,  0.0287],
        [ 0.0315, -0.0078, -0.0270,  ...,  0.0305,  0.0212, -0.0015]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.7397, -2.4727,  0.6865,  ...,  0.8887,  0.4612, -1.9531]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 06:43:13 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of resolved is unresolved
The opposite of biased is unbiased
The opposite of noticed is unnoticed
The opposite of paid is unpaid
The opposite of healthy is unhealthy
The opposite of veiled is unveiled
The opposite of restricted is unrestricted
The opposite of finished is
2024-07-31 06:43:13 root INFO     [order_1_approx] starting weight calculation for The opposite of veiled is unveiled
The opposite of resolved is unresolved
The opposite of healthy is unhealthy
The opposite of finished is unfinished
The opposite of restricted is unrestricted
The opposite of noticed is unnoticed
The opposite of paid is unpaid
The opposite of biased is
2024-07-31 06:43:13 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-31 06:44:51 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2878,  0.3994,  0.1345,  ...,  0.1727, -0.1979,  0.0143],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.4658, -1.9023,  2.2461,  ...,  1.0889, -1.0088,  1.7471],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0632, -0.0090,  0.0158,  ...,  0.0175,  0.0056,  0.0023],
        [-0.0080,  0.0434,  0.0279,  ...,  0.0057,  0.0213, -0.0001],
        [-0.0020, -0.0028,  0.0905,  ..., -0.0155, -0.0185, -0.0141],
        ...,
        [ 0.0059,  0.0271, -0.0012,  ...,  0.0493,  0.0128,  0.0222],
        [-0.0179,  0.0322, -0.0037,  ...,  0.0306,  0.0257, -0.0202],
        [-0.0012,  0.0087, -0.0110,  ..., -0.0203, -0.0088,  0.0433]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.6816, -1.3525,  2.1309,  ...,  1.4580, -1.1768,  1.0898]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 06:44:52 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Another word for jewel is gem
Another word for airplane is aeroplane
Another word for monument is memorial
Another word for mother is mom
Another word for snake is serpent
Another word for harbor is seaport
Another word for mesh is gauze
Another word for spouse is
2024-07-31 06:44:52 root INFO     [order_1_approx] starting weight calculation for Another word for mesh is gauze
Another word for harbor is seaport
Another word for spouse is partner
Another word for jewel is gem
Another word for snake is serpent
Another word for monument is memorial
Another word for airplane is aeroplane
Another word for mother is
2024-07-31 06:44:52 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-31 06:45:51 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0959, -0.2217, -0.3477,  ...,  0.3499, -0.2808,  0.2664],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.9473, -0.2993, -1.1289,  ..., -1.0674, -3.1914, -3.0039],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0363, -0.0123, -0.0160,  ...,  0.0118, -0.0080,  0.0013],
        [ 0.0007,  0.0506, -0.0005,  ..., -0.0028,  0.0149, -0.0224],
        [-0.0091, -0.0133,  0.0180,  ...,  0.0055, -0.0102, -0.0072],
        ...,
        [-0.0017,  0.0178,  0.0063,  ..., -0.0031,  0.0053,  0.0098],
        [ 0.0043,  0.0112,  0.0140,  ..., -0.0148,  0.0320,  0.0157],
        [-0.0105,  0.0127,  0.0021,  ...,  0.0030,  0.0176,  0.0222]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.8691, -0.8120, -0.6108,  ..., -1.7285, -3.6465, -3.1914]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 06:45:52 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of veiled is unveiled
The opposite of resolved is unresolved
The opposite of healthy is unhealthy
The opposite of finished is unfinished
The opposite of restricted is unrestricted
The opposite of noticed is unnoticed
The opposite of paid is unpaid
The opposite of biased is
2024-07-31 06:45:52 root INFO     [order_1_approx] starting weight calculation for The opposite of noticed is unnoticed
The opposite of restricted is unrestricted
The opposite of resolved is unresolved
The opposite of finished is unfinished
The opposite of paid is unpaid
The opposite of healthy is unhealthy
The opposite of biased is unbiased
The opposite of veiled is
2024-07-31 06:45:52 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-31 06:47:26 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2637,  0.1921,  0.2346,  ..., -0.0207, -0.0941,  0.0254],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.1055, -6.5078,  0.6958,  ..., -1.2363, -2.7227, -1.5986],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0881, -0.0376,  0.0336,  ..., -0.0103, -0.0072,  0.0177],
        [ 0.0352,  0.0245, -0.0057,  ..., -0.0122,  0.0239, -0.0210],
        [-0.0021,  0.0082,  0.0594,  ...,  0.0194,  0.0081, -0.0125],
        ...,
        [-0.0352,  0.0328,  0.0020,  ...,  0.0039,  0.0069, -0.0043],
        [-0.0101,  0.0263, -0.0200,  ...,  0.0353,  0.0219, -0.0154],
        [ 0.0076, -0.0146, -0.0020,  ..., -0.0101, -0.0035,  0.0443]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.1106, -5.9219,  1.1680,  ..., -1.1670, -2.1934, -1.7344]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 06:47:27 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Another word for mesh is gauze
Another word for harbor is seaport
Another word for spouse is partner
Another word for jewel is gem
Another word for snake is serpent
Another word for monument is memorial
Another word for airplane is aeroplane
Another word for mother is
2024-07-31 06:47:27 root INFO     [order_1_approx] starting weight calculation for Another word for spouse is partner
Another word for monument is memorial
Another word for snake is serpent
Another word for jewel is gem
Another word for airplane is aeroplane
Another word for mother is mom
Another word for harbor is seaport
Another word for mesh is
2024-07-31 06:47:27 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-31 06:48:32 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0973, -0.4629, -0.1288,  ...,  0.0593, -0.3093,  0.2764],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.1016,  0.9019, -0.3896,  ...,  2.7012, -2.4043, -0.1924],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0531,  0.0098, -0.0086,  ...,  0.0100, -0.0097,  0.0018],
        [-0.0099,  0.0547, -0.0095,  ...,  0.0175, -0.0065, -0.0042],
        [-0.0137, -0.0038,  0.0082,  ...,  0.0383, -0.0465, -0.0019],
        ...,
        [ 0.0204,  0.0204,  0.0312,  ...,  0.0195,  0.0175,  0.0103],
        [ 0.0078, -0.0052,  0.0017,  ...,  0.0019,  0.0408, -0.0094],
        [ 0.0206,  0.0073,  0.0062,  ...,  0.0094, -0.0069,  0.0518]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.4268,  1.0742, -0.6016,  ...,  2.6699, -2.9355, -0.1830]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 06:48:33 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of noticed is unnoticed
The opposite of restricted is unrestricted
The opposite of resolved is unresolved
The opposite of finished is unfinished
The opposite of paid is unpaid
The opposite of healthy is unhealthy
The opposite of biased is unbiased
The opposite of veiled is
2024-07-31 06:48:33 root INFO     [order_1_approx] starting weight calculation for The opposite of biased is unbiased
The opposite of resolved is unresolved
The opposite of veiled is unveiled
The opposite of healthy is unhealthy
The opposite of restricted is unrestricted
The opposite of noticed is unnoticed
The opposite of finished is unfinished
The opposite of paid is
2024-07-31 06:48:33 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-31 06:50:01 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4766,  0.0198, -0.0126,  ...,  0.2573, -0.0006,  0.4028],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.2256, -1.2988,  1.8457,  ...,  0.4463, -2.8867,  1.5996],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.1019,  0.0172, -0.0255,  ...,  0.0334,  0.0138,  0.0251],
        [ 0.0050,  0.0906,  0.0139,  ...,  0.0017, -0.0068, -0.0242],
        [ 0.0438,  0.0079,  0.1017,  ..., -0.0358,  0.0116, -0.0565],
        ...,
        [ 0.0179,  0.0014,  0.0388,  ...,  0.1178, -0.0150,  0.0145],
        [-0.0214,  0.0119, -0.0421,  ...,  0.0134,  0.0516, -0.0160],
        [-0.0300, -0.0070, -0.0106,  ..., -0.0081, -0.0251,  0.0746]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.9922, -1.6562,  1.5996,  ...,  0.4043, -2.8262,  1.1943]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 06:50:02 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Another word for spouse is partner
Another word for monument is memorial
Another word for snake is serpent
Another word for jewel is gem
Another word for airplane is aeroplane
Another word for mother is mom
Another word for harbor is seaport
Another word for mesh is
2024-07-31 06:50:02 root INFO     [order_1_approx] starting weight calculation for Another word for mesh is gauze
Another word for airplane is aeroplane
Another word for monument is memorial
Another word for jewel is gem
Another word for mother is mom
Another word for snake is serpent
Another word for spouse is partner
Another word for harbor is
2024-07-31 06:50:02 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-31 06:51:14 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1733, -0.2246, -0.2006,  ...,  0.0241, -0.3708, -0.0615],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.0762, -2.5586,  0.3401,  ..., -3.6387, -2.2480, -1.5312],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0513, -0.0299, -0.0084,  ..., -0.0065, -0.0199, -0.0008],
        [-0.0062,  0.0243,  0.0006,  ..., -0.0006, -0.0122, -0.0361],
        [-0.0103, -0.0044,  0.0248,  ...,  0.0247,  0.0215,  0.0068],
        ...,
        [ 0.0063,  0.0431, -0.0009,  ...,  0.0194,  0.0293, -0.0047],
        [-0.0182, -0.0126, -0.0213,  ...,  0.0284,  0.0535,  0.0005],
        [-0.0055,  0.0065, -0.0448,  ...,  0.0058,  0.0377,  0.0347]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.2383, -3.3340,  0.2517,  ..., -4.4844, -2.2656, -1.4639]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 06:51:15 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of biased is unbiased
The opposite of resolved is unresolved
The opposite of veiled is unveiled
The opposite of healthy is unhealthy
The opposite of restricted is unrestricted
The opposite of noticed is unnoticed
The opposite of finished is unfinished
The opposite of paid is
2024-07-31 06:51:15 root INFO     [order_1_approx] starting weight calculation for The opposite of noticed is unnoticed
The opposite of restricted is unrestricted
The opposite of finished is unfinished
The opposite of veiled is unveiled
The opposite of paid is unpaid
The opposite of biased is unbiased
The opposite of resolved is unresolved
The opposite of healthy is
2024-07-31 06:51:15 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-31 06:52:31 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0319,  0.1614, -0.0220,  ...,  0.0206, -0.0413,  0.3044],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.6694, -6.4023, -0.1621,  ...,  2.0664, -3.6250,  2.7598],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0746, -0.0212, -0.0074,  ...,  0.0075, -0.0236,  0.0032],
        [ 0.0011,  0.0771, -0.0022,  ...,  0.0240,  0.0039, -0.0208],
        [-0.0161, -0.0116,  0.0689,  ..., -0.0262,  0.0017, -0.0225],
        ...,
        [-0.0103,  0.0285, -0.0057,  ...,  0.0338,  0.0030, -0.0146],
        [-0.0346,  0.0430,  0.0083,  ...,  0.0089,  0.0500, -0.0324],
        [-0.0186,  0.0100,  0.0039,  ..., -0.0163, -0.0114,  0.0637]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.8096, -5.4219, -0.0092,  ...,  2.0137, -3.4238,  2.6777]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 06:52:32 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Another word for mesh is gauze
Another word for airplane is aeroplane
Another word for monument is memorial
Another word for jewel is gem
Another word for mother is mom
Another word for snake is serpent
Another word for spouse is partner
Another word for harbor is
2024-07-31 06:52:32 root INFO     [order_1_approx] starting weight calculation for Another word for mesh is gauze
Another word for mother is mom
Another word for jewel is gem
Another word for spouse is partner
Another word for harbor is seaport
Another word for airplane is aeroplane
Another word for monument is memorial
Another word for snake is
2024-07-31 06:52:32 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-31 06:53:55 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0582, -0.1404, -0.2063,  ..., -0.2161, -0.0807,  0.0758],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.9961, -1.4932, -0.2500,  ..., -2.2598, -1.3340, -1.4658],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 4.0283e-02, -2.6672e-02, -1.6357e-02,  ..., -1.4412e-02,
         -5.2490e-02,  6.2599e-03],
        [-2.1393e-02,  3.1311e-02,  2.2827e-02,  ..., -9.5367e-04,
          2.7954e-02, -7.0305e-03],
        [-1.8005e-02, -2.1149e-02,  1.5533e-02,  ...,  2.5681e-02,
         -3.1494e-02,  7.7591e-03],
        ...,
        [-8.1730e-04,  3.3386e-02,  8.2397e-03,  ..., -3.7537e-02,
          1.6769e-02, -1.6983e-02],
        [-1.7838e-02, -3.0197e-02,  2.8488e-02,  ...,  2.4128e-03,
          6.0005e-03, -2.9465e-02],
        [-3.3661e-02,  1.5114e-02, -7.3814e-03,  ...,  3.8147e-06,
          2.2705e-02, -5.1689e-03]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.1660, -1.4893,  0.8418,  ..., -2.3789, -1.3447, -1.4639]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 06:53:56 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of noticed is unnoticed
The opposite of restricted is unrestricted
The opposite of finished is unfinished
The opposite of veiled is unveiled
The opposite of paid is unpaid
The opposite of biased is unbiased
The opposite of resolved is unresolved
The opposite of healthy is
2024-07-31 06:53:56 root INFO     total operator prediction time: 1281.0986440181732 seconds
2024-07-31 06:53:56 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on verb+able_reg
2024-07-31 06:53:56 root INFO     building operator verb+able_reg
2024-07-31 06:53:56 root INFO     [order_1_approx] starting weight calculation for If you can improve something, that thing is improvable
If you can believe something, that thing is believeable
If you can maintain something, that thing is maintainable
If you can prefer something, that thing is preferable
If you can download something, that thing is downloadable
If you can identify something, that thing is identifiable
If you can adore something, that thing is adorable
If you can dispose something, that thing is
2024-07-31 06:53:56 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-31 06:55:06 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0340,  0.3389,  0.0636,  ..., -0.1969,  0.0826,  0.3486],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.4453, -6.0391,  2.2676,  ..., -0.7607, -1.5771, -0.3335],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0487,  0.0058,  0.0144,  ..., -0.0021,  0.0051,  0.0057],
        [ 0.0139,  0.0518,  0.0277,  ..., -0.0244,  0.0133, -0.0013],
        [-0.0189,  0.0309,  0.0889,  ..., -0.0411, -0.0031,  0.0096],
        ...,
        [ 0.0012,  0.0187,  0.0006,  ...,  0.0510, -0.0083, -0.0184],
        [-0.0078, -0.0010, -0.0140,  ...,  0.0045,  0.0352, -0.0065],
        [-0.0181, -0.0034, -0.0090,  ..., -0.0041, -0.0114,  0.0237]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.3818, -6.0664,  1.5332,  ..., -0.6074, -1.6484, -0.4170]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 06:55:07 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Another word for mesh is gauze
Another word for mother is mom
Another word for jewel is gem
Another word for spouse is partner
Another word for harbor is seaport
Another word for airplane is aeroplane
Another word for monument is memorial
Another word for snake is
2024-07-31 06:55:07 root INFO     [order_1_approx] starting weight calculation for Another word for jewel is gem
Another word for harbor is seaport
Another word for snake is serpent
Another word for spouse is partner
Another word for mother is mom
Another word for monument is memorial
Another word for mesh is gauze
Another word for airplane is
2024-07-31 06:55:07 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-31 06:56:34 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0603,  0.0303, -0.2593,  ...,  0.0700, -0.0595,  0.3071],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.1904, -2.8066, -0.9785,  ..., -3.7891, -5.1562, -1.8574],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0453,  0.0067,  0.0015,  ...,  0.0317,  0.0076, -0.0026],
        [-0.0209,  0.0320,  0.0228,  ..., -0.0094, -0.0055, -0.0204],
        [ 0.0213, -0.0003,  0.0240,  ..., -0.0215, -0.0069,  0.0025],
        ...,
        [ 0.0112,  0.0146, -0.0194,  ...,  0.0484, -0.0060, -0.0213],
        [ 0.0318,  0.0151, -0.0184,  ..., -0.0081,  0.0081, -0.0033],
        [ 0.0145,  0.0021,  0.0108,  ..., -0.0169, -0.0101,  0.0127]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.3164, -2.6387, -1.3047,  ..., -3.9121, -5.1562, -2.0098]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 06:56:36 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you can improve something, that thing is improvable
If you can believe something, that thing is believeable
If you can maintain something, that thing is maintainable
If you can prefer something, that thing is preferable
If you can download something, that thing is downloadable
If you can identify something, that thing is identifiable
If you can adore something, that thing is adorable
If you can dispose something, that thing is
2024-07-31 06:56:36 root INFO     [order_1_approx] starting weight calculation for If you can maintain something, that thing is maintainable
If you can adore something, that thing is adorable
If you can dispose something, that thing is disposable
If you can download something, that thing is downloadable
If you can prefer something, that thing is preferable
If you can believe something, that thing is believeable
If you can improve something, that thing is improvable
If you can identify something, that thing is
2024-07-31 06:56:36 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-31 06:57:34 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0215,  0.0021,  0.0209,  ...,  0.1558, -0.1777,  0.2620],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.0376, -2.9922,  3.3535,  ..., -1.0273, -2.8379,  1.2930],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 7.1472e-02, -1.3443e-02,  1.5427e-02,  ...,  2.1362e-02,
          2.2186e-02,  6.6833e-03],
        [ 2.1149e-02,  5.1453e-02,  4.3411e-03,  ...,  4.4250e-02,
          9.8190e-03, -3.0273e-02],
        [-1.0620e-02,  2.2675e-02,  7.3914e-02,  ..., -7.4615e-03,
         -1.4381e-02,  1.4206e-02],
        ...,
        [ 1.1749e-02,  1.0788e-02, -4.7874e-03,  ...,  4.9225e-02,
          1.8341e-02, -1.1513e-02],
        [-3.2288e-02, -6.7444e-03, -1.6830e-02,  ...,  1.6388e-02,
          3.2471e-02,  2.2919e-02],
        [ 5.3024e-04,  3.2082e-03,  6.8588e-03,  ..., -1.7365e-02,
         -4.0293e-05,  2.6443e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.1930, -2.6641,  3.0742,  ..., -1.1914, -2.7988,  1.2539]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 06:57:35 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Another word for jewel is gem
Another word for harbor is seaport
Another word for snake is serpent
Another word for spouse is partner
Another word for mother is mom
Another word for monument is memorial
Another word for mesh is gauze
Another word for airplane is
2024-07-31 06:57:35 root INFO     [order_1_approx] starting weight calculation for Another word for snake is serpent
Another word for mother is mom
Another word for jewel is gem
Another word for airplane is aeroplane
Another word for mesh is gauze
Another word for spouse is partner
Another word for harbor is seaport
Another word for monument is
2024-07-31 06:57:35 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-31 06:59:13 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2135,  0.1763, -0.1976,  ...,  0.5361, -0.3188, -0.1080],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.4414,  0.1943,  0.2051,  ..., -1.2559, -9.0000, -2.0039],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0360, -0.0433,  0.0260,  ...,  0.0227, -0.0074,  0.0160],
        [-0.0106,  0.0345,  0.0179,  ..., -0.0036, -0.0130, -0.0097],
        [ 0.0387, -0.0111,  0.0166,  ...,  0.0006,  0.0058, -0.0034],
        ...,
        [ 0.0262,  0.0087,  0.0014,  ...,  0.0425, -0.0198, -0.0096],
        [ 0.0204, -0.0114,  0.0078,  ..., -0.0112,  0.0070,  0.0039],
        [ 0.0176,  0.0218,  0.0210,  ..., -0.0049, -0.0305,  0.0152]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.8389,  0.2008,  0.0577,  ..., -1.3008, -8.8359, -2.2148]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 06:59:14 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you can maintain something, that thing is maintainable
If you can adore something, that thing is adorable
If you can dispose something, that thing is disposable
If you can download something, that thing is downloadable
If you can prefer something, that thing is preferable
If you can believe something, that thing is believeable
If you can improve something, that thing is improvable
If you can identify something, that thing is
2024-07-31 06:59:15 root INFO     [order_1_approx] starting weight calculation for If you can identify something, that thing is identifiable
If you can download something, that thing is downloadable
If you can adore something, that thing is adorable
If you can improve something, that thing is improvable
If you can dispose something, that thing is disposable
If you can prefer something, that thing is preferable
If you can believe something, that thing is believeable
If you can maintain something, that thing is
2024-07-31 06:59:15 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-31 07:00:03 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0462,  0.1504,  0.2866,  ..., -0.1129, -0.1990,  0.3320],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-2.7500, -3.8965,  1.3984,  ...,  0.2070, -3.8555, -1.5049],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.1133, -0.0069,  0.0148,  ...,  0.0144, -0.0219,  0.0137],
        [-0.0250,  0.0889,  0.0268,  ..., -0.0233,  0.0462, -0.0461],
        [ 0.0544, -0.0022,  0.0714,  ...,  0.0355, -0.0518,  0.0116],
        ...,
        [-0.0172,  0.0265,  0.0073,  ...,  0.0660,  0.0405, -0.0381],
        [-0.0325,  0.0511, -0.0075,  ...,  0.0403,  0.0454, -0.0230],
        [-0.0323,  0.0265,  0.0215,  ..., -0.0384,  0.0244,  0.0569]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.7188, -4.0859,  0.7422,  ...,  0.5361, -4.2422, -1.6035]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 07:00:04 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Another word for snake is serpent
Another word for mother is mom
Another word for jewel is gem
Another word for airplane is aeroplane
Another word for mesh is gauze
Another word for spouse is partner
Another word for harbor is seaport
Another word for monument is
2024-07-31 07:00:04 root INFO     [order_1_approx] starting weight calculation for Another word for harbor is seaport
Another word for mesh is gauze
Another word for spouse is partner
Another word for monument is memorial
Another word for mother is mom
Another word for snake is serpent
Another word for airplane is aeroplane
Another word for jewel is
2024-07-31 07:00:04 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-31 07:01:52 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2605,  0.0957, -0.0880,  ...,  0.1833, -0.1342,  0.1440],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.3340, -1.3887, -2.6094,  ..., -4.2773, -6.0703, -2.5078],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0308, -0.0290,  0.0009,  ...,  0.0346,  0.0086,  0.0145],
        [-0.0135,  0.0544,  0.0019,  ..., -0.0233,  0.0108, -0.0358],
        [ 0.0176, -0.0288,  0.0414,  ..., -0.0204, -0.0010,  0.0057],
        ...,
        [ 0.0464,  0.0168,  0.0065,  ...,  0.0178, -0.0151, -0.0020],
        [ 0.0327,  0.0199, -0.0016,  ..., -0.0358,  0.0078, -0.0185],
        [ 0.0071,  0.0094, -0.0055,  ..., -0.0220, -0.0040,  0.0006]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.2155, -1.4775, -2.8945,  ..., -4.7695, -6.0156, -3.0508]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 07:01:53 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you can identify something, that thing is identifiable
If you can download something, that thing is downloadable
If you can adore something, that thing is adorable
If you can improve something, that thing is improvable
If you can dispose something, that thing is disposable
If you can prefer something, that thing is preferable
If you can believe something, that thing is believeable
If you can maintain something, that thing is
2024-07-31 07:01:54 root INFO     [order_1_approx] starting weight calculation for If you can download something, that thing is downloadable
If you can adore something, that thing is adorable
If you can believe something, that thing is believeable
If you can improve something, that thing is improvable
If you can identify something, that thing is identifiable
If you can maintain something, that thing is maintainable
If you can dispose something, that thing is disposable
If you can prefer something, that thing is
2024-07-31 07:01:54 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-31 07:02:37 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0153,  0.2837,  0.0690,  ..., -0.0211, -0.0459,  0.1592],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.1016, -1.7617, -1.8164,  ..., -0.3882, -3.3105,  2.3789],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 5.5847e-02, -2.9449e-02,  7.4615e-03,  ..., -9.8724e-03,
         -8.5831e-03,  1.2253e-02],
        [-7.4043e-03,  3.8910e-02, -7.9298e-04,  ...,  4.5853e-03,
          2.6276e-02,  2.2568e-02],
        [-4.0131e-03, -5.2452e-05,  3.1769e-02,  ...,  5.3062e-03,
         -4.9744e-03,  1.9119e-02],
        ...,
        [-2.0187e-02,  2.2736e-02, -8.1177e-03,  ...,  4.8370e-02,
          1.2184e-02, -2.3788e-02],
        [-1.2604e-02,  9.4452e-03, -1.0567e-03,  ...,  2.2888e-02,
          3.5461e-02, -2.6226e-03],
        [ 6.3477e-03, -3.3379e-05,  6.6605e-03,  ..., -1.8219e-02,
         -5.3520e-03,  1.8356e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.3438, -1.4092, -1.8867,  ..., -0.3015, -3.4980,  2.4453]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 07:02:38 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Another word for harbor is seaport
Another word for mesh is gauze
Another word for spouse is partner
Another word for monument is memorial
Another word for mother is mom
Another word for snake is serpent
Another word for airplane is aeroplane
Another word for jewel is
2024-07-31 07:02:38 root INFO     total operator prediction time: 1218.4883222579956 seconds
2024-07-31 07:02:38 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on animal - youth
2024-07-31 07:02:38 root INFO     building operator animal - youth
2024-07-31 07:02:38 root INFO     [order_1_approx] starting weight calculation for The offspring of a fox is referred to as a cub
The offspring of a seal is referred to as a pup
The offspring of a beetle is referred to as a larva
The offspring of a chimpanzee is referred to as a baby
The offspring of a badger is referred to as a kit
The offspring of a dog is referred to as a puppy
The offspring of a tiger is referred to as a cub
The offspring of a camel is referred to as a
2024-07-31 07:02:38 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-31 07:04:31 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0044,  0.0178,  0.0981,  ..., -0.0424, -0.1945,  0.3589],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.2676e+00, -9.7656e-04, -1.2520e+00,  ...,  3.6450e-01,
        -6.9609e+00, -5.1562e+00], device='cuda:0', dtype=torch.float16,
       grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0334, -0.0041,  0.0120,  ...,  0.0007,  0.0044,  0.0375],
        [-0.0147,  0.0279,  0.0049,  ..., -0.0062,  0.0164,  0.0190],
        [ 0.0178, -0.0003,  0.0133,  ...,  0.0038, -0.0251,  0.0027],
        ...,
        [ 0.0038, -0.0040, -0.0113,  ...,  0.0558, -0.0007,  0.0181],
        [ 0.0312, -0.0027,  0.0097,  ..., -0.0089, -0.0136, -0.0132],
        [ 0.0059, -0.0173,  0.0025,  ..., -0.0179,  0.0046, -0.0141]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.8965,  0.0427, -1.1543,  ...,  0.1094, -7.3320, -5.3438]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 07:04:32 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you can download something, that thing is downloadable
If you can adore something, that thing is adorable
If you can believe something, that thing is believeable
If you can improve something, that thing is improvable
If you can identify something, that thing is identifiable
If you can maintain something, that thing is maintainable
If you can dispose something, that thing is disposable
If you can prefer something, that thing is
2024-07-31 07:04:32 root INFO     [order_1_approx] starting weight calculation for If you can improve something, that thing is improvable
If you can identify something, that thing is identifiable
If you can maintain something, that thing is maintainable
If you can prefer something, that thing is preferable
If you can believe something, that thing is believeable
If you can download something, that thing is downloadable
If you can dispose something, that thing is disposable
If you can adore something, that thing is
2024-07-31 07:04:33 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-31 07:05:05 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1296, -0.0596, -0.2300,  ..., -0.1088, -0.2450,  0.3738],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.7383, -2.3789, -0.2563,  ...,  0.9116, -2.6680,  1.1094],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0483, -0.0029,  0.0068,  ...,  0.0128, -0.0135, -0.0048],
        [ 0.0070,  0.0293,  0.0026,  ..., -0.0014, -0.0046, -0.0375],
        [-0.0074,  0.0167,  0.0266,  ..., -0.0205, -0.0096, -0.0243],
        ...,
        [ 0.0268,  0.0164, -0.0001,  ...,  0.0481,  0.0166, -0.0026],
        [ 0.0047, -0.0236,  0.0014,  ..., -0.0124,  0.0017,  0.0087],
        [-0.0098,  0.0083, -0.0244,  ..., -0.0294,  0.0312,  0.0427]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.3835, -1.8408, -0.4424,  ...,  0.6924, -2.2891,  1.1191]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 07:05:06 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The offspring of a fox is referred to as a cub
The offspring of a seal is referred to as a pup
The offspring of a beetle is referred to as a larva
The offspring of a chimpanzee is referred to as a baby
The offspring of a badger is referred to as a kit
The offspring of a dog is referred to as a puppy
The offspring of a tiger is referred to as a cub
The offspring of a camel is referred to as a
2024-07-31 07:05:07 root INFO     [order_1_approx] starting weight calculation for The offspring of a seal is referred to as a pup
The offspring of a tiger is referred to as a cub
The offspring of a beetle is referred to as a larva
The offspring of a camel is referred to as a calf
The offspring of a fox is referred to as a cub
The offspring of a chimpanzee is referred to as a baby
The offspring of a badger is referred to as a kit
The offspring of a dog is referred to as a
2024-07-31 07:05:07 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-31 07:07:12 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0356,  0.3040,  0.0546,  ..., -0.0674, -0.3467,  0.1643],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.7070, -0.5273, -4.7344,  ..., -1.6426, -5.6250, -2.9863],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0018,  0.0197, -0.0180,  ..., -0.0016,  0.0159,  0.0352],
        [-0.0156, -0.0003,  0.0289,  ...,  0.0108, -0.0038, -0.0213],
        [ 0.0414, -0.0097,  0.0251,  ...,  0.0115, -0.0113, -0.0018],
        ...,
        [ 0.0195, -0.0026,  0.0142,  ...,  0.0099,  0.0351, -0.0216],
        [ 0.0189,  0.0074,  0.0145,  ..., -0.0185, -0.0071,  0.0174],
        [-0.0006, -0.0184, -0.0142,  ..., -0.0121, -0.0326,  0.0075]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.6387, -0.3423, -5.4492,  ..., -1.6318, -5.7422, -3.0664]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 07:07:13 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you can improve something, that thing is improvable
If you can identify something, that thing is identifiable
If you can maintain something, that thing is maintainable
If you can prefer something, that thing is preferable
If you can believe something, that thing is believeable
If you can download something, that thing is downloadable
If you can dispose something, that thing is disposable
If you can adore something, that thing is
2024-07-31 07:07:13 root INFO     [order_1_approx] starting weight calculation for If you can maintain something, that thing is maintainable
If you can adore something, that thing is adorable
If you can identify something, that thing is identifiable
If you can download something, that thing is downloadable
If you can prefer something, that thing is preferable
If you can believe something, that thing is believeable
If you can dispose something, that thing is disposable
If you can improve something, that thing is
2024-07-31 07:07:13 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-31 07:07:38 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1948,  0.0233, -0.0440,  ...,  0.2522, -0.4944,  0.2230],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.8223, -5.3398, -1.3965,  ...,  0.8633, -2.5898,  2.3555],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0237, -0.0128,  0.0058,  ...,  0.0063, -0.0005,  0.0078],
        [ 0.0006,  0.0031, -0.0182,  ..., -0.0206,  0.0033, -0.0265],
        [-0.0009,  0.0016,  0.0120,  ..., -0.0142, -0.0089, -0.0068],
        ...,
        [ 0.0101,  0.0065,  0.0058,  ...,  0.0471,  0.0030, -0.0044],
        [ 0.0088,  0.0005,  0.0134,  ...,  0.0364,  0.0161, -0.0008],
        [-0.0058, -0.0042,  0.0010,  ...,  0.0033,  0.0048,  0.0268]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.0234, -4.6836, -1.1670,  ...,  1.0518, -2.9375,  2.4375]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 07:07:39 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The offspring of a seal is referred to as a pup
The offspring of a tiger is referred to as a cub
The offspring of a beetle is referred to as a larva
The offspring of a camel is referred to as a calf
The offspring of a fox is referred to as a cub
The offspring of a chimpanzee is referred to as a baby
The offspring of a badger is referred to as a kit
The offspring of a dog is referred to as a
2024-07-31 07:07:39 root INFO     [order_1_approx] starting weight calculation for The offspring of a badger is referred to as a kit
The offspring of a seal is referred to as a pup
The offspring of a chimpanzee is referred to as a baby
The offspring of a fox is referred to as a cub
The offspring of a camel is referred to as a calf
The offspring of a dog is referred to as a puppy
The offspring of a beetle is referred to as a larva
The offspring of a tiger is referred to as a
2024-07-31 07:07:39 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-31 07:09:48 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1318,  0.1365,  0.1327,  ...,  0.0798, -0.1777,  0.1249],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.3438, -1.1172, -0.6592,  ..., -1.5273, -8.2812, -3.2363],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0330,  0.0043,  0.0074,  ..., -0.0094, -0.0061,  0.0237],
        [ 0.0016,  0.0388,  0.0144,  ..., -0.0065, -0.0303, -0.0215],
        [-0.0069, -0.0028,  0.0131,  ...,  0.0045,  0.0297,  0.0022],
        ...,
        [ 0.0352, -0.0078,  0.0009,  ..., -0.0100, -0.0359, -0.0015],
        [ 0.0238, -0.0017,  0.0193,  ...,  0.0021, -0.0289,  0.0039],
        [-0.0073, -0.0081,  0.0146,  ..., -0.0067, -0.0437,  0.0077]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.6855, -1.0156, -0.6270,  ..., -1.6221, -8.8828, -3.6641]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 07:09:49 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you can maintain something, that thing is maintainable
If you can adore something, that thing is adorable
If you can identify something, that thing is identifiable
If you can download something, that thing is downloadable
If you can prefer something, that thing is preferable
If you can believe something, that thing is believeable
If you can dispose something, that thing is disposable
If you can improve something, that thing is
2024-07-31 07:09:50 root INFO     [order_1_approx] starting weight calculation for If you can improve something, that thing is improvable
If you can prefer something, that thing is preferable
If you can dispose something, that thing is disposable
If you can maintain something, that thing is maintainable
If you can download something, that thing is downloadable
If you can identify something, that thing is identifiable
If you can adore something, that thing is adorable
If you can believe something, that thing is
2024-07-31 07:09:50 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-31 07:10:08 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1310,  0.2037, -0.1492,  ...,  0.2383, -0.3103, -0.0334],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.1699, -4.9062, -2.3027,  ...,  0.5513, -1.2227,  0.9453],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 3.2135e-02, -1.8906e-02, -1.4969e-02,  ...,  1.6541e-02,
         -6.9504e-03, -4.4327e-03],
        [-3.2959e-03,  2.5726e-02, -1.0872e-03,  ..., -2.0248e-02,
         -8.2626e-03, -2.0370e-02],
        [ 1.2733e-02,  2.6646e-03,  4.4312e-02,  ...,  7.9632e-05,
          1.3550e-02, -1.2035e-03],
        ...,
        [ 3.8261e-03, -2.9755e-04,  1.4191e-02,  ...,  3.6804e-02,
          1.1024e-02, -1.9028e-02],
        [ 4.1618e-03, -2.5543e-02,  1.4404e-02,  ...,  2.0340e-02,
          9.0981e-04,  1.6388e-02],
        [-4.1237e-03,  3.8548e-03, -1.0773e-02,  ..., -2.6855e-02,
         -1.5961e-02,  2.4780e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.0078, -4.3359, -2.1504,  ...,  0.9844, -0.9473,  0.6826]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 07:10:09 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The offspring of a badger is referred to as a kit
The offspring of a seal is referred to as a pup
The offspring of a chimpanzee is referred to as a baby
The offspring of a fox is referred to as a cub
The offspring of a camel is referred to as a calf
The offspring of a dog is referred to as a puppy
The offspring of a beetle is referred to as a larva
The offspring of a tiger is referred to as a
2024-07-31 07:10:10 root INFO     [order_1_approx] starting weight calculation for The offspring of a camel is referred to as a calf
The offspring of a tiger is referred to as a cub
The offspring of a dog is referred to as a puppy
The offspring of a beetle is referred to as a larva
The offspring of a fox is referred to as a cub
The offspring of a seal is referred to as a pup
The offspring of a chimpanzee is referred to as a baby
The offspring of a badger is referred to as a
2024-07-31 07:10:10 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-31 07:12:29 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1583,  0.3198,  0.1274,  ..., -0.0474, -0.2185,  0.2852],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.7734, -1.2734, -0.1885,  ..., -3.1211, -6.8516, -2.9707],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0071, -0.0070, -0.0076,  ...,  0.0127,  0.0111,  0.0240],
        [-0.0090,  0.0147,  0.0193,  ..., -0.0043,  0.0137, -0.0031],
        [ 0.0136,  0.0008,  0.0100,  ...,  0.0030, -0.0268,  0.0232],
        ...,
        [ 0.0052, -0.0067,  0.0058,  ...,  0.0033, -0.0042, -0.0098],
        [ 0.0260, -0.0045,  0.0141,  ..., -0.0062, -0.0012, -0.0199],
        [ 0.0070, -0.0045, -0.0100,  ..., -0.0031, -0.0023,  0.0012]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.9590, -1.1914, -0.4106,  ..., -2.6680, -7.2656, -3.2480]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 07:12:30 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you can improve something, that thing is improvable
If you can prefer something, that thing is preferable
If you can dispose something, that thing is disposable
If you can maintain something, that thing is maintainable
If you can download something, that thing is downloadable
If you can identify something, that thing is identifiable
If you can adore something, that thing is adorable
If you can believe something, that thing is
2024-07-31 07:12:30 root INFO     [order_1_approx] starting weight calculation for If you can maintain something, that thing is maintainable
If you can identify something, that thing is identifiable
If you can believe something, that thing is believeable
If you can dispose something, that thing is disposable
If you can adore something, that thing is adorable
If you can improve something, that thing is improvable
If you can prefer something, that thing is preferable
If you can download something, that thing is
2024-07-31 07:12:30 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-31 07:12:42 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1088,  0.1880,  0.0537,  ...,  0.0187, -0.6504, -0.2004],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.5938, -1.4023, -0.7109,  ...,  1.1836, -1.5293,  1.0273],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0466, -0.0086,  0.0062,  ...,  0.0166, -0.0111, -0.0145],
        [-0.0055,  0.0477, -0.0075,  ...,  0.0182,  0.0303, -0.0312],
        [ 0.0028, -0.0086,  0.0315,  ...,  0.0038, -0.0348, -0.0223],
        ...,
        [-0.0135, -0.0049,  0.0095,  ...,  0.0290,  0.0330,  0.0103],
        [ 0.0172, -0.0067,  0.0341,  ...,  0.0113, -0.0104,  0.0200],
        [ 0.0007, -0.0210, -0.0190,  ..., -0.0084, -0.0177,  0.0255]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.3867, -1.6777, -0.3198,  ...,  1.4375, -1.6123,  1.3545]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 07:12:43 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The offspring of a camel is referred to as a calf
The offspring of a tiger is referred to as a cub
The offspring of a dog is referred to as a puppy
The offspring of a beetle is referred to as a larva
The offspring of a fox is referred to as a cub
The offspring of a seal is referred to as a pup
The offspring of a chimpanzee is referred to as a baby
The offspring of a badger is referred to as a
2024-07-31 07:12:43 root INFO     [order_1_approx] starting weight calculation for The offspring of a fox is referred to as a cub
The offspring of a chimpanzee is referred to as a baby
The offspring of a badger is referred to as a kit
The offspring of a tiger is referred to as a cub
The offspring of a camel is referred to as a calf
The offspring of a beetle is referred to as a larva
The offspring of a dog is referred to as a puppy
The offspring of a seal is referred to as a
2024-07-31 07:12:44 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-31 07:15:07 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0476,  0.0189,  0.0061,  ...,  0.1401, -0.2448, -0.0636],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.2441, -2.9570,  0.3926,  ..., -2.9238, -7.9961, -2.1680],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 4.3823e-02, -3.2166e-02,  2.2385e-02,  ...,  2.5238e-02,
          1.7258e-02,  1.9623e-02],
        [-2.3590e-02,  2.5375e-02,  7.3738e-03,  ...,  1.4572e-03,
         -1.2688e-02, -2.3956e-02],
        [ 1.2985e-02, -5.2032e-03,  3.1052e-02,  ..., -4.9591e-05,
         -4.5868e-02, -1.5274e-02],
        ...,
        [ 2.7176e-02,  2.4399e-02,  2.2919e-02,  ...,  4.3884e-02,
          2.1942e-02, -2.1696e-04],
        [ 1.5793e-02, -7.1335e-03, -9.2621e-03,  ..., -2.7435e-02,
          1.8066e-02, -4.7913e-03],
        [ 9.9564e-03, -1.6388e-02,  3.4084e-03,  ..., -1.0223e-02,
         -6.3438e-03,  2.2354e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.5322, -2.8750,  0.2822,  ..., -3.1484, -7.5234, -2.2441]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 07:15:08 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you can maintain something, that thing is maintainable
If you can identify something, that thing is identifiable
If you can believe something, that thing is believeable
If you can dispose something, that thing is disposable
If you can adore something, that thing is adorable
If you can improve something, that thing is improvable
If you can prefer something, that thing is preferable
If you can download something, that thing is
2024-07-31 07:15:08 root INFO     total operator prediction time: 1271.8026967048645 seconds
2024-07-31 07:15:08 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on verb+tion_irreg
2024-07-31 07:15:08 root INFO     building operator verb+tion_irreg
2024-07-31 07:15:08 root INFO     [order_1_approx] starting weight calculation for To improvize results in improvization
To randomize results in randomization
To inspire results in inspiration
To derive results in derivation
To characterize results in characterization
To civilize results in civilization
To examine results in examination
To stabilize results in
2024-07-31 07:15:08 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-31 07:15:12 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2839, -0.2183, -0.1633,  ..., -0.0909, -0.4604,  0.2173],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.8184, -3.5312, -2.8398,  ..., -0.5068, -3.2344,  2.4258],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 4.3335e-02, -3.1067e-02, -2.4292e-02,  ...,  2.6230e-02,
         -1.9104e-02,  9.2316e-04],
        [ 4.7684e-06,  4.5319e-02, -3.3741e-03,  ..., -1.6785e-02,
         -7.0953e-03, -1.6785e-02],
        [ 3.5057e-03, -1.2100e-02,  4.1138e-02,  ...,  2.3071e-02,
         -2.8553e-03, -3.7109e-02],
        ...,
        [ 1.1215e-02, -7.1640e-03,  1.6403e-02,  ...,  3.5828e-02,
          3.1952e-02, -1.4343e-02],
        [ 1.5297e-03, -1.3062e-02,  1.9699e-02,  ...,  4.6387e-02,
          2.7725e-02, -1.2047e-02],
        [-2.2934e-02, -1.2016e-02,  4.7531e-03,  ..., -1.2993e-02,
         -1.3229e-02,  2.2736e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.7681, -3.2305, -2.3984,  ..., -0.0266, -3.1250,  2.1230]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 07:15:13 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The offspring of a fox is referred to as a cub
The offspring of a chimpanzee is referred to as a baby
The offspring of a badger is referred to as a kit
The offspring of a tiger is referred to as a cub
The offspring of a camel is referred to as a calf
The offspring of a beetle is referred to as a larva
The offspring of a dog is referred to as a puppy
The offspring of a seal is referred to as a
2024-07-31 07:15:13 root INFO     [order_1_approx] starting weight calculation for The offspring of a seal is referred to as a pup
The offspring of a tiger is referred to as a cub
The offspring of a beetle is referred to as a larva
The offspring of a camel is referred to as a calf
The offspring of a dog is referred to as a puppy
The offspring of a chimpanzee is referred to as a baby
The offspring of a badger is referred to as a kit
The offspring of a fox is referred to as a
2024-07-31 07:15:13 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-31 07:17:45 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0663,  0.1072, -0.5898,  ..., -0.2119, -0.2791, -0.1165],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.2188, -3.5977,  0.4004,  ...,  1.3516, -4.5938, -3.8223],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0203, -0.0009,  0.0088,  ...,  0.0047, -0.0157,  0.0157],
        [ 0.0060,  0.0021,  0.0061,  ...,  0.0020,  0.0078,  0.0035],
        [-0.0055, -0.0007,  0.0113,  ..., -0.0035, -0.0079, -0.0009],
        ...,
        [-0.0030,  0.0023,  0.0065,  ...,  0.0078, -0.0002,  0.0147],
        [ 0.0009, -0.0011,  0.0075,  ...,  0.0008,  0.0274, -0.0067],
        [-0.0001, -0.0053,  0.0135,  ..., -0.0003, -0.0022,  0.0191]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.4492, -3.4258,  0.8462,  ...,  1.2959, -4.9141, -3.7871]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 07:17:45 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2085,  0.2952,  0.0336,  ..., -0.1722, -0.2374, -0.0579],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.3516, -2.9688, -2.4902,  ...,  1.7686, -2.3145,  2.9551],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 3.6224e-02, -9.1324e-03,  1.2321e-03,  ...,  1.8196e-03,
          1.3527e-02,  1.3962e-02],
        [ 6.3133e-04,  3.5065e-02, -6.9847e-03,  ..., -7.5531e-03,
          1.3374e-02, -2.0630e-02],
        [ 5.1994e-03, -7.0801e-03,  2.1240e-02,  ..., -1.1673e-02,
         -1.4503e-02, -1.2741e-02],
        ...,
        [-2.9564e-05,  2.7275e-03,  2.3603e-04,  ...,  1.1253e-02,
          3.0060e-02, -1.5549e-02],
        [-4.7569e-03, -6.4621e-03,  3.2288e-02,  ...,  1.5419e-02,
          5.9929e-03, -9.2621e-03],
        [-6.7329e-03, -1.0483e-02,  3.1929e-03,  ..., -7.4234e-03,
         -9.3765e-03,  1.3054e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.2617, -3.1465, -2.4785,  ...,  1.9893, -2.7812,  2.9746]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 07:17:46 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To improvize results in improvization
To randomize results in randomization
To inspire results in inspiration
To derive results in derivation
To characterize results in characterization
To civilize results in civilization
To examine results in examination
To stabilize results in
2024-07-31 07:17:47 root INFO     [order_1_approx] starting weight calculation for To characterize results in characterization
To derive results in derivation
To randomize results in randomization
To inspire results in inspiration
To improvize results in improvization
To stabilize results in stabilization
To civilize results in civilization
To examine results in
2024-07-31 07:17:47 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The offspring of a seal is referred to as a pup
The offspring of a tiger is referred to as a cub
The offspring of a beetle is referred to as a larva
The offspring of a camel is referred to as a calf
The offspring of a dog is referred to as a puppy
The offspring of a chimpanzee is referred to as a baby
The offspring of a badger is referred to as a kit
The offspring of a fox is referred to as a
2024-07-31 07:17:47 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-31 07:17:47 root INFO     [order_1_approx] starting weight calculation for The offspring of a camel is referred to as a calf
The offspring of a dog is referred to as a puppy
The offspring of a seal is referred to as a pup
The offspring of a fox is referred to as a cub
The offspring of a beetle is referred to as a larva
The offspring of a tiger is referred to as a cub
The offspring of a badger is referred to as a kit
The offspring of a chimpanzee is referred to as a
2024-07-31 07:17:47 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-31 07:20:18 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2522, -0.0558, -0.3057,  ..., -0.2427, -0.5166, -0.0453],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.0293, -3.1074, -1.2451,  ...,  0.0361, -3.8379,  2.7344],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0070,  0.0023,  0.0021,  ..., -0.0035,  0.0014, -0.0060],
        [-0.0015,  0.0034, -0.0032,  ...,  0.0059,  0.0004,  0.0014],
        [-0.0008,  0.0033,  0.0004,  ...,  0.0063, -0.0010,  0.0035],
        ...,
        [ 0.0024,  0.0028,  0.0006,  ...,  0.0037,  0.0052, -0.0004],
        [ 0.0039, -0.0079,  0.0092,  ...,  0.0079,  0.0026,  0.0055],
        [-0.0046, -0.0057, -0.0004,  ..., -0.0108, -0.0038, -0.0011]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.9297, -3.0703, -1.2734,  ...,  0.2402, -3.6172,  2.7168]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 07:20:20 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The offspring of a camel is referred to as a calf
The offspring of a dog is referred to as a puppy
The offspring of a seal is referred to as a pup
The offspring of a fox is referred to as a cub
The offspring of a beetle is referred to as a larva
The offspring of a tiger is referred to as a cub
The offspring of a badger is referred to as a kit
The offspring of a chimpanzee is referred to as a
2024-07-31 07:20:20 root INFO     [order_1_approx] starting weight calculation for The offspring of a dog is referred to as a puppy
The offspring of a seal is referred to as a pup
The offspring of a tiger is referred to as a cub
The offspring of a chimpanzee is referred to as a baby
The offspring of a fox is referred to as a cub
The offspring of a badger is referred to as a kit
The offspring of a camel is referred to as a calf
The offspring of a beetle is referred to as a
2024-07-31 07:20:20 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-31 07:20:24 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0334,  0.3188, -0.2291,  ...,  0.1584, -0.2266, -0.3342],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.7295, -2.0176,  1.3057,  ...,  0.9395, -1.8330, -3.5312],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0289,  0.0093,  0.0037,  ...,  0.0077,  0.0320,  0.0046],
        [-0.0190,  0.0414, -0.0020,  ...,  0.0306, -0.0181,  0.0056],
        [ 0.0272,  0.0024,  0.0189,  ..., -0.0181,  0.0089, -0.0077],
        ...,
        [ 0.0024, -0.0010,  0.0026,  ...,  0.0373, -0.0170, -0.0102],
        [-0.0350, -0.0089, -0.0010,  ...,  0.0026,  0.0472, -0.0024],
        [ 0.0222,  0.0247,  0.0246,  ...,  0.0406,  0.0126,  0.0179]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.3223, -1.8271,  1.3877,  ...,  1.3379, -2.6172, -3.5195]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 07:20:25 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To characterize results in characterization
To derive results in derivation
To randomize results in randomization
To inspire results in inspiration
To improvize results in improvization
To stabilize results in stabilization
To civilize results in civilization
To examine results in
2024-07-31 07:20:25 root INFO     [order_1_approx] starting weight calculation for To characterize results in characterization
To stabilize results in stabilization
To inspire results in inspiration
To examine results in examination
To improvize results in improvization
To civilize results in civilization
To derive results in derivation
To randomize results in
2024-07-31 07:20:25 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-31 07:22:49 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1963,  0.1272, -0.0723,  ..., -0.0005, -0.3022,  0.0778],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.7090, -1.2852, -0.7705,  ...,  1.0752, -0.4497, -0.6943],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 3.0731e-02, -2.5345e-02, -1.5030e-03,  ...,  1.4664e-02,
         -1.5656e-02, -1.6235e-02],
        [ 1.9363e-02,  1.8265e-02, -2.6703e-05,  ...,  1.4496e-02,
         -1.1536e-02, -2.0447e-02],
        [-5.9891e-04,  1.4782e-03,  3.4363e-02,  ..., -7.6485e-04,
          1.9073e-05, -1.6983e-02],
        ...,
        [ 1.1528e-02, -1.2306e-02, -1.7319e-02,  ...,  2.5513e-02,
          2.0493e-02, -9.2621e-03],
        [ 1.0872e-02, -1.2367e-02,  9.6588e-03,  ...,  3.8513e-02,
         -1.8204e-02,  3.7460e-03],
        [-5.1231e-03, -2.7905e-03, -3.3073e-03,  ..., -1.5610e-02,
         -1.4030e-02,  1.8326e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.6719, -1.1094, -0.9316,  ...,  1.6426,  0.0732, -0.6577]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 07:22:50 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The offspring of a dog is referred to as a puppy
The offspring of a seal is referred to as a pup
The offspring of a tiger is referred to as a cub
The offspring of a chimpanzee is referred to as a baby
The offspring of a fox is referred to as a cub
The offspring of a badger is referred to as a kit
The offspring of a camel is referred to as a calf
The offspring of a beetle is referred to as a
2024-07-31 07:22:50 root INFO     total operator prediction time: 1212.3146443367004 seconds
2024-07-31 07:22:50 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on animal - sound
2024-07-31 07:22:50 root INFO     building operator animal - sound
2024-07-31 07:22:50 root INFO     [order_1_approx] starting weight calculation for The sound that a raven makes is called a caw
The sound that a deer makes is called a bellow
The sound that a beetle makes is called a drone
The sound that a crow makes is called a caw
The sound that a donkey makes is called a bray
The sound that a frog makes is called a ribbit
The sound that a mule makes is called a bray
The sound that a wasp makes is called a
2024-07-31 07:22:50 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-31 07:23:03 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1627,  0.2067, -0.4033,  ...,  0.0874, -0.3494, -0.3511],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.9795, -2.7012,  0.4463,  ...,  1.2129, -3.7578, -3.8086],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0726, -0.0006, -0.0089,  ..., -0.0265, -0.0075,  0.0108],
        [-0.0101,  0.0227,  0.0097,  ...,  0.0157, -0.0202,  0.0150],
        [-0.0185, -0.0016,  0.0317,  ..., -0.0111, -0.0164, -0.0022],
        ...,
        [ 0.0026,  0.0171,  0.0061,  ...,  0.0469, -0.0276,  0.0029],
        [ 0.0091,  0.0108,  0.0190,  ...,  0.0274,  0.0386,  0.0002],
        [-0.0075,  0.0019,  0.0167,  ...,  0.0013, -0.0170,  0.0573]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.9985, -2.2930,  0.8540,  ...,  1.7012, -3.6973, -3.3223]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 07:23:04 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To characterize results in characterization
To stabilize results in stabilization
To inspire results in inspiration
To examine results in examination
To improvize results in improvization
To civilize results in civilization
To derive results in derivation
To randomize results in
2024-07-31 07:23:04 root INFO     [order_1_approx] starting weight calculation for To randomize results in randomization
To improvize results in improvization
To stabilize results in stabilization
To derive results in derivation
To characterize results in characterization
To examine results in examination
To inspire results in inspiration
To civilize results in
2024-07-31 07:23:04 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-31 07:25:22 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2318, -0.2324,  0.0254,  ...,  0.4038,  0.0623,  0.1292],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.1719, -2.4609,  2.3750,  ..., -0.8281, -0.9629,  1.5977],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0335, -0.0279, -0.0260,  ...,  0.0096, -0.0422,  0.0019],
        [-0.0203,  0.0656,  0.0017,  ...,  0.0059, -0.0082,  0.0041],
        [-0.0078,  0.0206,  0.0277,  ..., -0.0114, -0.0128, -0.0143],
        ...,
        [-0.0126,  0.0047,  0.0241,  ...,  0.0392, -0.0117, -0.0145],
        [-0.0118,  0.0013,  0.0035,  ...,  0.0167, -0.0063,  0.0026],
        [-0.0071,  0.0068, -0.0131,  ..., -0.0055, -0.0245,  0.0270]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.0723, -2.5918,  2.3281,  ..., -1.4404, -1.5449,  1.3994]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 07:25:23 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The sound that a raven makes is called a caw
The sound that a deer makes is called a bellow
The sound that a beetle makes is called a drone
The sound that a crow makes is called a caw
The sound that a donkey makes is called a bray
The sound that a frog makes is called a ribbit
The sound that a mule makes is called a bray
The sound that a wasp makes is called a
2024-07-31 07:25:23 root INFO     [order_1_approx] starting weight calculation for The sound that a wasp makes is called a buzz
The sound that a deer makes is called a bellow
The sound that a frog makes is called a ribbit
The sound that a donkey makes is called a bray
The sound that a raven makes is called a caw
The sound that a mule makes is called a bray
The sound that a beetle makes is called a drone
The sound that a crow makes is called a
2024-07-31 07:25:23 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-31 07:25:42 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2913,  0.5947, -0.7119,  ..., -0.3892, -0.4370,  0.0549],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.7217, -2.4570,  2.8652,  ...,  0.5093, -1.4707, -1.5283],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0187, -0.0094,  0.0230,  ..., -0.0015, -0.0185,  0.0230],
        [-0.0164,  0.0201, -0.0149,  ...,  0.0143, -0.0020,  0.0087],
        [-0.0093, -0.0069,  0.0293,  ...,  0.0114, -0.0070,  0.0022],
        ...,
        [ 0.0132,  0.0097, -0.0190,  ...,  0.0155,  0.0079,  0.0002],
        [ 0.0164,  0.0004, -0.0048,  ...,  0.0089,  0.0460, -0.0154],
        [-0.0015, -0.0096,  0.0098,  ...,  0.0048, -0.0035,  0.0239]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.4614, -2.3984,  2.8945,  ...,  0.3901, -1.5820, -1.5205]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 07:25:43 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To randomize results in randomization
To improvize results in improvization
To stabilize results in stabilization
To derive results in derivation
To characterize results in characterization
To examine results in examination
To inspire results in inspiration
To civilize results in
2024-07-31 07:25:43 root INFO     [order_1_approx] starting weight calculation for To examine results in examination
To stabilize results in stabilization
To randomize results in randomization
To characterize results in characterization
To civilize results in civilization
To derive results in derivation
To improvize results in improvization
To inspire results in
2024-07-31 07:25:43 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-31 07:27:55 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0183, -0.2500,  0.0450,  ...,  0.2612, -0.0565,  0.0251],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.2314, -4.3711,  1.0586,  ..., -1.7441, -0.1123,  0.6709],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0558,  0.0123,  0.0202,  ..., -0.0256, -0.0566, -0.0060],
        [-0.0206,  0.0302,  0.0206,  ...,  0.0385,  0.0508, -0.0247],
        [-0.0097,  0.0063,  0.0750,  ..., -0.0052, -0.0321, -0.0031],
        ...,
        [ 0.0138,  0.0060, -0.0056,  ...,  0.0787,  0.0093, -0.0042],
        [-0.0114,  0.0053, -0.0388,  ..., -0.0090,  0.0014, -0.0079],
        [ 0.0181, -0.0120,  0.0158,  ..., -0.0153, -0.0195,  0.0365]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.9639, -4.1367,  0.8579,  ..., -1.7520, -0.6274,  0.3494]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 07:27:56 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The sound that a wasp makes is called a buzz
The sound that a deer makes is called a bellow
The sound that a frog makes is called a ribbit
The sound that a donkey makes is called a bray
The sound that a raven makes is called a caw
The sound that a mule makes is called a bray
The sound that a beetle makes is called a drone
The sound that a crow makes is called a
2024-07-31 07:27:56 root INFO     [order_1_approx] starting weight calculation for The sound that a deer makes is called a bellow
The sound that a wasp makes is called a buzz
The sound that a donkey makes is called a bray
The sound that a beetle makes is called a drone
The sound that a mule makes is called a bray
The sound that a crow makes is called a caw
The sound that a frog makes is called a ribbit
The sound that a raven makes is called a
2024-07-31 07:27:56 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-31 07:28:15 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0186,  0.3708, -0.2764,  ...,  0.0740, -0.5669,  0.0198],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.3125, -2.7656,  0.9092,  ...,  4.4648, -1.3516, -1.4502],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0347,  0.0041,  0.0062,  ...,  0.0066, -0.0077,  0.0182],
        [-0.0157,  0.0135,  0.0019,  ...,  0.0090, -0.0095,  0.0078],
        [ 0.0046, -0.0160,  0.0135,  ..., -0.0104, -0.0146, -0.0003],
        ...,
        [-0.0018,  0.0156, -0.0072,  ...,  0.0109, -0.0017, -0.0016],
        [ 0.0157,  0.0017, -0.0020,  ..., -0.0028,  0.0287, -0.0150],
        [ 0.0081, -0.0015,  0.0067,  ...,  0.0131, -0.0102,  0.0260]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.4902, -2.6855,  1.2725,  ...,  4.3516, -1.7109, -1.3613]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 07:28:16 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To examine results in examination
To stabilize results in stabilization
To randomize results in randomization
To characterize results in characterization
To civilize results in civilization
To derive results in derivation
To improvize results in improvization
To inspire results in
2024-07-31 07:28:16 root INFO     [order_1_approx] starting weight calculation for To inspire results in inspiration
To randomize results in randomization
To civilize results in civilization
To derive results in derivation
To characterize results in characterization
To stabilize results in stabilization
To examine results in examination
To improvize results in
2024-07-31 07:28:16 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-31 07:30:28 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0770, -0.1193, -0.2185,  ...,  0.0669, -0.0842, -0.1290],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.3486, -3.0508, -0.5596,  ..., -2.0820,  0.2764,  1.4316],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0456,  0.0067,  0.0013,  ..., -0.0319, -0.0299, -0.0134],
        [-0.0317,  0.0460,  0.0010,  ...,  0.0295,  0.0310, -0.0655],
        [ 0.0019, -0.0199,  0.0779,  ..., -0.0297, -0.0375, -0.0158],
        ...,
        [ 0.0086,  0.0153, -0.0121,  ...,  0.0772, -0.0107, -0.0220],
        [-0.0166, -0.0269,  0.0021,  ...,  0.0363, -0.0120, -0.0358],
        [ 0.0083, -0.0121, -0.0185,  ..., -0.0315, -0.0116,  0.0242]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.0762, -2.7188, -0.6836,  ..., -2.5156, -0.2637,  1.3916]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 07:30:29 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The sound that a deer makes is called a bellow
The sound that a wasp makes is called a buzz
The sound that a donkey makes is called a bray
The sound that a beetle makes is called a drone
The sound that a mule makes is called a bray
The sound that a crow makes is called a caw
The sound that a frog makes is called a ribbit
The sound that a raven makes is called a
2024-07-31 07:30:29 root INFO     [order_1_approx] starting weight calculation for The sound that a mule makes is called a bray
The sound that a raven makes is called a caw
The sound that a donkey makes is called a bray
The sound that a deer makes is called a bellow
The sound that a crow makes is called a caw
The sound that a wasp makes is called a buzz
The sound that a frog makes is called a ribbit
The sound that a beetle makes is called a
2024-07-31 07:30:29 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-31 07:30:54 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1095,  0.2512, -0.3433,  ..., -0.1998, -0.1936,  0.1422],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.5312, -2.9258,  2.1133,  ...,  3.1699, -0.6704, -2.1387],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0458, -0.0139, -0.0106,  ..., -0.0146, -0.0122,  0.0202],
        [-0.0236,  0.0472,  0.0195,  ...,  0.0297, -0.0036,  0.0112],
        [-0.0352, -0.0210,  0.0364,  ...,  0.0160,  0.0214, -0.0163],
        ...,
        [-0.0038,  0.0219,  0.0210,  ...,  0.0717, -0.0244,  0.0070],
        [-0.0081,  0.0128, -0.0101,  ...,  0.0042,  0.0552, -0.0152],
        [ 0.0030,  0.0157,  0.0003,  ...,  0.0116, -0.0134,  0.0500]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.3652, -2.1602,  2.2227,  ...,  3.8086, -0.9326, -1.5566]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 07:30:55 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To inspire results in inspiration
To randomize results in randomization
To civilize results in civilization
To derive results in derivation
To characterize results in characterization
To stabilize results in stabilization
To examine results in examination
To improvize results in
2024-07-31 07:30:55 root INFO     [order_1_approx] starting weight calculation for To examine results in examination
To civilize results in civilization
To characterize results in characterization
To randomize results in randomization
To inspire results in inspiration
To stabilize results in stabilization
To improvize results in improvization
To derive results in
2024-07-31 07:30:55 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-31 07:33:02 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.3062,  0.0966, -0.0705,  ..., -0.0956, -0.0745,  0.0571],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.7109, -0.1973,  3.1836,  ...,  0.3545, -1.5312,  2.0879],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0451, -0.0056, -0.0147,  ..., -0.0210, -0.0240, -0.0041],
        [ 0.0007,  0.0395,  0.0027,  ...,  0.0214, -0.0249, -0.0189],
        [-0.0113,  0.0043,  0.0220,  ..., -0.0013, -0.0184, -0.0170],
        ...,
        [ 0.0209,  0.0131,  0.0034,  ...,  0.0232, -0.0079,  0.0148],
        [-0.0185, -0.0052,  0.0056,  ...,  0.0139,  0.0153, -0.0027],
        [-0.0065, -0.0002, -0.0023,  ..., -0.0069, -0.0271,  0.0180]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.9160, -0.5820,  2.9141,  ...,  0.3831, -1.8613,  1.8457]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 07:33:03 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The sound that a mule makes is called a bray
The sound that a raven makes is called a caw
The sound that a donkey makes is called a bray
The sound that a deer makes is called a bellow
The sound that a crow makes is called a caw
The sound that a wasp makes is called a buzz
The sound that a frog makes is called a ribbit
The sound that a beetle makes is called a
2024-07-31 07:33:03 root INFO     [order_1_approx] starting weight calculation for The sound that a donkey makes is called a bray
The sound that a beetle makes is called a drone
The sound that a mule makes is called a bray
The sound that a wasp makes is called a buzz
The sound that a crow makes is called a caw
The sound that a deer makes is called a bellow
The sound that a raven makes is called a caw
The sound that a frog makes is called a
2024-07-31 07:33:03 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-31 07:33:33 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2313,  0.2334,  0.1110,  ..., -0.0817, -0.3625,  0.2111],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.1006, -3.3398,  2.0762,  ...,  0.8931, -0.4883, -1.9854],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0598, -0.0011,  0.0090,  ...,  0.0080, -0.0200,  0.0190],
        [-0.0133,  0.0306,  0.0278,  ...,  0.0162,  0.0031, -0.0058],
        [-0.0100, -0.0015,  0.0588,  ...,  0.0394, -0.0002,  0.0114],
        ...,
        [ 0.0137,  0.0243, -0.0003,  ...,  0.0523,  0.0053, -0.0188],
        [-0.0171,  0.0068, -0.0371,  ..., -0.0096,  0.0645, -0.0368],
        [ 0.0190,  0.0028,  0.0257,  ...,  0.0205, -0.0261,  0.0424]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.0537, -3.0352,  1.8105,  ...,  1.2441, -1.4883, -1.6699]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 07:33:34 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To examine results in examination
To civilize results in civilization
To characterize results in characterization
To randomize results in randomization
To inspire results in inspiration
To stabilize results in stabilization
To improvize results in improvization
To derive results in
2024-07-31 07:33:34 root INFO     [order_1_approx] starting weight calculation for To inspire results in inspiration
To stabilize results in stabilization
To improvize results in improvization
To randomize results in randomization
To examine results in examination
To derive results in derivation
To civilize results in civilization
To characterize results in
2024-07-31 07:33:34 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-31 07:35:34 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1200, -0.1201, -0.1570,  ..., -0.2432, -0.1804,  0.2625],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.3413, -2.8750, -0.1162,  ...,  1.9766, -1.8965,  3.9023],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 6.2866e-02,  3.2883e-03,  1.7212e-02,  ..., -2.5272e-03,
         -1.4809e-02, -1.9836e-02],
        [-3.0518e-05,  3.0029e-02, -2.6321e-03,  ..., -2.3926e-02,
         -1.0788e-02, -1.8997e-02],
        [ 8.1329e-03, -8.0795e-03,  3.1021e-02,  ..., -3.1769e-02,
          5.1308e-04,  3.2558e-03],
        ...,
        [-1.6296e-02,  6.2866e-03, -1.6842e-03,  ...,  3.7384e-02,
          1.9409e-02, -1.4099e-02],
        [-3.3722e-03,  7.1030e-03,  4.9515e-03,  ...,  1.5961e-02,
          7.9956e-03, -1.4847e-02],
        [ 1.3008e-03, -1.4877e-02,  5.6801e-03,  ..., -1.7761e-02,
         -1.6651e-03,  4.1870e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.3691, -3.0527, -0.2705,  ...,  1.7480, -2.0020,  3.5449]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 07:35:35 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The sound that a donkey makes is called a bray
The sound that a beetle makes is called a drone
The sound that a mule makes is called a bray
The sound that a wasp makes is called a buzz
The sound that a crow makes is called a caw
The sound that a deer makes is called a bellow
The sound that a raven makes is called a caw
The sound that a frog makes is called a
2024-07-31 07:35:35 root INFO     [order_1_approx] starting weight calculation for The sound that a wasp makes is called a buzz
The sound that a mule makes is called a bray
The sound that a deer makes is called a bellow
The sound that a crow makes is called a caw
The sound that a frog makes is called a ribbit
The sound that a raven makes is called a caw
The sound that a beetle makes is called a drone
The sound that a donkey makes is called a
2024-07-31 07:35:35 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-31 07:36:12 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0858, -0.0116, -0.1975,  ..., -0.2732, -0.2949, -0.4062],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.8086, -1.0098,  3.4902,  ...,  1.9580, -1.8682, -1.7441],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 3.6621e-04, -2.8763e-02,  1.6403e-02,  ..., -1.5793e-03,
          2.5940e-02, -1.1169e-02],
        [ 4.1618e-03,  3.2684e-02,  1.1681e-02,  ...,  4.1618e-03,
          4.1656e-03,  2.8091e-02],
        [-1.0628e-02, -3.0548e-02,  1.1435e-03,  ...,  6.1874e-03,
         -8.4763e-03, -1.1780e-02],
        ...,
        [ 1.4114e-04, -5.6763e-03,  1.1543e-02,  ...,  1.3954e-02,
         -1.3565e-02,  2.3834e-02],
        [ 1.3863e-02,  1.1551e-02,  3.6316e-03,  ...,  5.2795e-03,
          3.2288e-02, -7.1406e-05],
        [ 1.0880e-02,  1.8997e-02,  1.1169e-02,  ...,  1.9646e-04,
         -2.3956e-02,  1.1269e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-2.4121, -0.5049,  3.2246,  ...,  2.1641, -1.9307, -1.5137]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 07:36:13 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To inspire results in inspiration
To stabilize results in stabilization
To improvize results in improvization
To randomize results in randomization
To examine results in examination
To derive results in derivation
To civilize results in civilization
To characterize results in
2024-07-31 07:36:13 root INFO     total operator prediction time: 1265.7215614318848 seconds
2024-07-31 07:36:13 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on adj+ly_reg
2024-07-31 07:36:13 root INFO     building operator adj+ly_reg
2024-07-31 07:36:14 root INFO     [order_1_approx] starting weight calculation for The adjective form of regional is regionally
The adjective form of visual is visually
The adjective form of actual is actually
The adjective form of similar is similarly
The adjective form of strong is strongly
The adjective form of mental is mentally
The adjective form of typical is typically
The adjective form of effective is
2024-07-31 07:36:14 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-31 07:38:06 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1960, -0.4060, -0.1248,  ...,  0.0705, -0.3218,  0.2959],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.3779, -4.0547, -0.0332,  ..., -1.4609, -1.8027,  1.8057],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0251,  0.0196, -0.0018,  ..., -0.0376, -0.0296,  0.0066],
        [ 0.0011,  0.0423, -0.0169,  ..., -0.0032, -0.0126, -0.0085],
        [-0.0347, -0.0053,  0.0522,  ..., -0.0407, -0.0411,  0.0070],
        ...,
        [ 0.0335,  0.0209, -0.0218,  ...,  0.0515, -0.0192, -0.0118],
        [-0.0007,  0.0194, -0.0145,  ..., -0.0003,  0.0333, -0.0032],
        [ 0.0108, -0.0238,  0.0224,  ...,  0.0012, -0.0266, -0.0061]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.3604, -4.1641, -0.5068,  ..., -1.4814, -1.5293,  1.7168]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 07:38:08 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The sound that a wasp makes is called a buzz
The sound that a mule makes is called a bray
The sound that a deer makes is called a bellow
The sound that a crow makes is called a caw
The sound that a frog makes is called a ribbit
The sound that a raven makes is called a caw
The sound that a beetle makes is called a drone
The sound that a donkey makes is called a
2024-07-31 07:38:08 root INFO     [order_1_approx] starting weight calculation for The sound that a deer makes is called a bellow
The sound that a donkey makes is called a bray
The sound that a crow makes is called a caw
The sound that a wasp makes is called a buzz
The sound that a frog makes is called a ribbit
The sound that a raven makes is called a caw
The sound that a beetle makes is called a drone
The sound that a mule makes is called a
2024-07-31 07:38:08 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-31 07:38:52 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1219,  0.0262,  0.0203,  ..., -0.0750, -0.4502, -0.0609],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.0676, -2.0840, -0.0850,  ..., -0.2683, -1.2510, -4.9609],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 3.0792e-02, -1.8982e-02, -1.9165e-02,  ..., -2.0950e-02,
          1.0757e-03,  1.8372e-02],
        [-1.4542e-02,  3.7354e-02,  2.4353e-02,  ...,  4.7874e-03,
          1.7426e-02, -1.4488e-02],
        [ 3.8940e-02, -8.4839e-03,  7.6256e-03,  ..., -2.2079e-02,
         -2.6226e-03,  2.3804e-03],
        ...,
        [ 3.9734e-02,  4.5593e-02, -9.5825e-03,  ...,  2.1255e-02,
         -9.8724e-03, -9.1095e-03],
        [ 1.4580e-02, -1.4572e-02,  1.1284e-02,  ...,  3.9429e-02,
          4.9652e-02, -2.4475e-02],
        [ 9.8801e-03, -1.5137e-02,  3.3379e-05,  ...,  2.2308e-02,
         -4.1962e-04,  2.3529e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.3794, -1.9395, -0.1176,  ...,  0.1052, -1.8438, -5.0117]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 07:38:53 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The adjective form of regional is regionally
The adjective form of visual is visually
The adjective form of actual is actually
The adjective form of similar is similarly
The adjective form of strong is strongly
The adjective form of mental is mentally
The adjective form of typical is typically
The adjective form of effective is
2024-07-31 07:38:54 root INFO     [order_1_approx] starting weight calculation for The adjective form of typical is typically
The adjective form of effective is effectively
The adjective form of strong is strongly
The adjective form of regional is regionally
The adjective form of mental is mentally
The adjective form of similar is similarly
The adjective form of actual is actually
The adjective form of visual is
2024-07-31 07:38:54 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-31 07:40:37 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0634, -0.1232,  0.1624,  ...,  0.0770, -0.1556,  0.3923],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.2715, -4.1953,  1.3164,  ..., -1.5605, -1.4668,  1.5234],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0403,  0.0197, -0.0475,  ..., -0.0181, -0.0223, -0.0146],
        [ 0.0380,  0.0557, -0.0151,  ...,  0.0086, -0.0063,  0.0087],
        [-0.0402, -0.0033,  0.0811,  ..., -0.0665, -0.0302, -0.0054],
        ...,
        [ 0.0465,  0.0158, -0.0408,  ...,  0.0410, -0.0102,  0.0048],
        [-0.0051,  0.0247,  0.0045,  ...,  0.0100,  0.0490, -0.0105],
        [-0.0286, -0.0366,  0.0293,  ..., -0.0241, -0.0562,  0.0078]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.0549, -4.2500,  0.8438,  ..., -1.6133, -1.3740,  1.6133]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 07:40:38 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The sound that a deer makes is called a bellow
The sound that a donkey makes is called a bray
The sound that a crow makes is called a caw
The sound that a wasp makes is called a buzz
The sound that a frog makes is called a ribbit
The sound that a raven makes is called a caw
The sound that a beetle makes is called a drone
The sound that a mule makes is called a
2024-07-31 07:40:38 root INFO     [order_1_approx] starting weight calculation for The sound that a mule makes is called a bray
The sound that a raven makes is called a caw
The sound that a frog makes is called a ribbit
The sound that a donkey makes is called a bray
The sound that a wasp makes is called a buzz
The sound that a beetle makes is called a drone
The sound that a crow makes is called a caw
The sound that a deer makes is called a
2024-07-31 07:40:38 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-31 07:41:32 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0296, -0.0704,  0.0030,  ...,  0.0389, -0.3420, -0.1608],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.6304, -2.8594,  1.0059,  ..., -2.1875, -1.1562, -1.1182],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0554, -0.0670, -0.0047,  ..., -0.0023, -0.0037,  0.0199],
        [-0.0109,  0.0518,  0.0042,  ..., -0.0023, -0.0164, -0.0151],
        [ 0.0130, -0.0332,  0.0241,  ...,  0.0108, -0.0077,  0.0224],
        ...,
        [ 0.0112,  0.0368, -0.0150,  ...,  0.0372, -0.0044, -0.0158],
        [ 0.0237,  0.0469, -0.0054,  ...,  0.0135,  0.0206,  0.0048],
        [-0.0033,  0.0032, -0.0028,  ...,  0.0158, -0.0169,  0.0155]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.3921, -2.4961,  1.1602,  ..., -1.9287, -1.6807, -1.1426]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 07:41:33 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The adjective form of typical is typically
The adjective form of effective is effectively
The adjective form of strong is strongly
The adjective form of regional is regionally
The adjective form of mental is mentally
The adjective form of similar is similarly
The adjective form of actual is actually
The adjective form of visual is
2024-07-31 07:41:33 root INFO     [order_1_approx] starting weight calculation for The adjective form of mental is mentally
The adjective form of effective is effectively
The adjective form of visual is visually
The adjective form of typical is typically
The adjective form of regional is regionally
The adjective form of actual is actually
The adjective form of similar is similarly
The adjective form of strong is
2024-07-31 07:41:33 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-31 07:43:10 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0325,  0.1095, -0.1770,  ...,  0.1234, -0.3201,  0.4041],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.5171, -1.1348, -0.5957,  ..., -0.2842, -1.8750, -0.2295],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0219, -0.0073, -0.0161,  ..., -0.0147, -0.0204,  0.0029],
        [ 0.0100,  0.0439,  0.0074,  ...,  0.0247, -0.0103, -0.0316],
        [-0.0286,  0.0129,  0.0276,  ..., -0.0294, -0.0086,  0.0035],
        ...,
        [-0.0106,  0.0314,  0.0081,  ...,  0.0652, -0.0087, -0.0068],
        [ 0.0138,  0.0179,  0.0013,  ...,  0.0021,  0.0427, -0.0054],
        [-0.0068, -0.0219, -0.0019,  ..., -0.0303, -0.0242,  0.0266]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.4316, -1.3340, -0.4487,  ..., -0.2695, -2.0566, -0.5469]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 07:43:11 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The sound that a mule makes is called a bray
The sound that a raven makes is called a caw
The sound that a frog makes is called a ribbit
The sound that a donkey makes is called a bray
The sound that a wasp makes is called a buzz
The sound that a beetle makes is called a drone
The sound that a crow makes is called a caw
The sound that a deer makes is called a
2024-07-31 07:43:11 root INFO     total operator prediction time: 1221.4680066108704 seconds
2024-07-31 07:43:11 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on things - color
2024-07-31 07:43:11 root INFO     building operator things - color
2024-07-31 07:43:12 root INFO     [order_1_approx] starting weight calculation for The raven is colored black
The swan is colored white
The tea is colored black
The potato is colored brown
The blackboard is colored black
The broccoli is colored green
The cauliflower is colored white
The tomato is colored
2024-07-31 07:43:12 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-31 07:44:14 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0445, -0.2944,  0.0017,  ...,  0.0740, -0.1260,  0.1393],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.2949, -2.8203, -1.0781,  ...,  0.1016, -2.5449, -4.3203],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0302, -0.0300,  0.0013,  ..., -0.0078, -0.0218,  0.0255],
        [-0.0098,  0.0262,  0.0384,  ...,  0.0059, -0.0067, -0.0146],
        [ 0.0251, -0.0395,  0.0099,  ..., -0.0095,  0.0001,  0.0079],
        ...,
        [-0.0313,  0.0431, -0.0355,  ...,  0.0326,  0.0012, -0.0037],
        [ 0.0090,  0.0276, -0.0052,  ...,  0.0187,  0.0381, -0.0198],
        [-0.0040, -0.0082,  0.0084,  ...,  0.0398, -0.0108,  0.0026]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.0820, -2.6426, -1.1602,  ...,  0.0662, -2.1992, -4.2734]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 07:44:15 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The adjective form of mental is mentally
The adjective form of effective is effectively
The adjective form of visual is visually
The adjective form of typical is typically
The adjective form of regional is regionally
The adjective form of actual is actually
The adjective form of similar is similarly
The adjective form of strong is
2024-07-31 07:44:16 root INFO     [order_1_approx] starting weight calculation for The adjective form of effective is effectively
The adjective form of typical is typically
The adjective form of strong is strongly
The adjective form of similar is similarly
The adjective form of actual is actually
The adjective form of visual is visually
The adjective form of regional is regionally
The adjective form of mental is
2024-07-31 07:44:16 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-31 07:45:44 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0684, -0.1835, -0.0337,  ..., -0.0337, -0.4961, -0.1901],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.8193, -8.8516,  0.3618,  ..., -1.9307,  0.1025, -1.5879],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0350, -0.0087,  0.0055,  ..., -0.0116,  0.0150, -0.0035],
        [-0.0070,  0.0108,  0.0316,  ...,  0.0065,  0.0281, -0.0173],
        [-0.0153,  0.0101,  0.0476,  ...,  0.0285, -0.0230,  0.0156],
        ...,
        [-0.0035, -0.0414, -0.0068,  ...,  0.0547, -0.0089,  0.0100],
        [-0.0095,  0.0177, -0.0090,  ...,  0.0329,  0.0032,  0.0009],
        [-0.0060, -0.0193, -0.0019,  ...,  0.0048,  0.0061,  0.0384]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.6055, -8.6328,  0.1616,  ..., -2.0430, -0.1675, -1.5449]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 07:45:45 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The raven is colored black
The swan is colored white
The tea is colored black
The potato is colored brown
The blackboard is colored black
The broccoli is colored green
The cauliflower is colored white
The tomato is colored
2024-07-31 07:45:45 root INFO     [order_1_approx] starting weight calculation for The cauliflower is colored white
The tomato is colored red
The broccoli is colored green
The tea is colored black
The potato is colored brown
The raven is colored black
The blackboard is colored black
The swan is colored
2024-07-31 07:45:45 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-31 07:46:55 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1031, -0.3799,  0.2512,  ..., -0.2200, -0.5029,  0.1010],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.0605,  0.1562,  2.0898,  ..., -2.8008, -2.2734, -1.9941],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 4.6967e-02, -1.6464e-02,  7.9041e-03,  ..., -7.1030e-03,
          1.3062e-02,  2.5024e-02],
        [-1.7715e-02,  6.1737e-02,  1.5259e-05,  ..., -4.4495e-02,
          1.2817e-03, -3.6316e-02],
        [ 1.0376e-03, -1.3420e-02,  3.8330e-02,  ...,  8.8577e-03,
         -1.9394e-02, -5.5351e-03],
        ...,
        [ 3.3356e-02,  4.6120e-03,  7.3624e-04,  ...,  5.3162e-02,
          7.2784e-03, -2.1423e-02],
        [ 5.7487e-03,  4.2191e-03, -1.4008e-02,  ...,  1.1337e-02,
          2.2614e-02, -1.3702e-02],
        [ 1.1063e-04,  1.0567e-02,  2.3651e-03,  ...,  6.1722e-03,
          5.1270e-03,  3.5324e-03]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.3926, -0.0258,  2.2324,  ..., -2.5254, -2.2012, -1.8730]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 07:46:56 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The adjective form of effective is effectively
The adjective form of typical is typically
The adjective form of strong is strongly
The adjective form of similar is similarly
The adjective form of actual is actually
The adjective form of visual is visually
The adjective form of regional is regionally
The adjective form of mental is
2024-07-31 07:46:56 root INFO     [order_1_approx] starting weight calculation for The adjective form of effective is effectively
The adjective form of typical is typically
The adjective form of mental is mentally
The adjective form of visual is visually
The adjective form of similar is similarly
The adjective form of actual is actually
The adjective form of strong is strongly
The adjective form of regional is
2024-07-31 07:46:56 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-31 07:48:14 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0677, -0.1475, -0.0523,  ...,  0.0302, -0.0997,  0.0736],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-3.2422, -2.0508,  0.7651,  ...,  0.1777, -2.6875,  2.0078],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0464, -0.0356, -0.0004,  ..., -0.0216,  0.0244,  0.0035],
        [-0.0226,  0.0612,  0.0107,  ...,  0.0281, -0.0043, -0.0183],
        [ 0.0059, -0.0055,  0.0424,  ...,  0.0059, -0.0155,  0.0148],
        ...,
        [-0.0164,  0.0007,  0.0205,  ...,  0.0656,  0.0041, -0.0079],
        [ 0.0028, -0.0169,  0.0104,  ...,  0.0258,  0.0410, -0.0414],
        [-0.0153, -0.0126, -0.0163,  ..., -0.0238, -0.0129,  0.0024]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-2.7461, -2.2246,  0.9473,  ...,  0.4395, -2.5762,  2.2285]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 07:48:15 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The cauliflower is colored white
The tomato is colored red
The broccoli is colored green
The tea is colored black
The potato is colored brown
The raven is colored black
The blackboard is colored black
The swan is colored
2024-07-31 07:48:15 root INFO     [order_1_approx] starting weight calculation for The blackboard is colored black
The potato is colored brown
The swan is colored white
The broccoli is colored green
The cauliflower is colored white
The tomato is colored red
The tea is colored black
The raven is colored
2024-07-31 07:48:15 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-31 07:49:34 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2000,  0.0480, -0.0713,  ..., -0.0430, -0.2051,  0.0290],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.0684, -2.6641,  1.3281,  ..., -4.5234, -1.7217, -3.0293],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0803, -0.0565, -0.0096,  ...,  0.0399,  0.0086, -0.0030],
        [ 0.0170,  0.0816,  0.0388,  ...,  0.0157, -0.0114, -0.0144],
        [ 0.0271, -0.0268, -0.0014,  ...,  0.0120, -0.0088,  0.0163],
        ...,
        [ 0.0136,  0.0201, -0.0454,  ...,  0.0539,  0.0171,  0.0199],
        [ 0.0119, -0.0041, -0.0092,  ...,  0.0235,  0.0310, -0.0332],
        [ 0.0002, -0.0179, -0.0098,  ..., -0.0066, -0.0315,  0.0352]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.0723, -2.6855,  1.5273,  ..., -3.8965, -1.7324, -3.3691]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 07:49:36 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The adjective form of effective is effectively
The adjective form of typical is typically
The adjective form of mental is mentally
The adjective form of visual is visually
The adjective form of similar is similarly
The adjective form of actual is actually
The adjective form of strong is strongly
The adjective form of regional is
2024-07-31 07:49:36 root INFO     [order_1_approx] starting weight calculation for The adjective form of mental is mentally
The adjective form of regional is regionally
The adjective form of strong is strongly
The adjective form of visual is visually
The adjective form of effective is effectively
The adjective form of typical is typically
The adjective form of actual is actually
The adjective form of similar is
2024-07-31 07:49:36 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-31 07:50:40 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0791,  0.0002, -0.1923,  ...,  0.0366, -0.2028,  0.0906],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.5957, -3.4297,  2.5898,  ..., -0.1001,  2.4180, -1.7363],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0588,  0.0143, -0.0019,  ...,  0.0103,  0.0225,  0.0038],
        [ 0.0026,  0.0446,  0.0512,  ...,  0.0310, -0.0261, -0.0184],
        [ 0.0035,  0.0085,  0.0734,  ...,  0.0199, -0.0027,  0.0276],
        ...,
        [ 0.0130,  0.0037,  0.0205,  ...,  0.0957, -0.0097,  0.0244],
        [ 0.0037,  0.0292,  0.0241,  ...,  0.0532,  0.0422, -0.0154],
        [-0.0170, -0.0054, -0.0236,  ...,  0.0017, -0.0344,  0.0455]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.9644, -3.5898,  1.8887,  ..., -0.4753,  1.6680, -1.5312]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 07:50:41 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The blackboard is colored black
The potato is colored brown
The swan is colored white
The broccoli is colored green
The cauliflower is colored white
The tomato is colored red
The tea is colored black
The raven is colored
2024-07-31 07:50:41 root INFO     [order_1_approx] starting weight calculation for The broccoli is colored green
The tea is colored black
The raven is colored black
The potato is colored brown
The tomato is colored red
The swan is colored white
The blackboard is colored black
The cauliflower is colored
2024-07-31 07:50:41 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-31 07:52:18 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1626, -0.2339, -0.0723,  ...,  0.0845, -0.2615,  0.0433],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.0449, -1.1162,  0.6992,  ..., -2.0742,  0.6255, -1.4043],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0517, -0.0385, -0.0098,  ...,  0.0201,  0.0125, -0.0087],
        [-0.0260,  0.0338,  0.0134,  ..., -0.0202,  0.0293,  0.0068],
        [ 0.0235,  0.0081,  0.0156,  ..., -0.0061, -0.0244, -0.0010],
        ...,
        [-0.0053,  0.0199,  0.0106,  ...,  0.0840,  0.0023,  0.0250],
        [ 0.0334,  0.0423,  0.0325,  ...,  0.0143, -0.0084, -0.0036],
        [ 0.0199, -0.0083,  0.0104,  ...,  0.0193, -0.0266,  0.0207]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.0020, -0.6934,  0.8149,  ..., -2.1250,  0.0557, -1.3262]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 07:52:19 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The adjective form of mental is mentally
The adjective form of regional is regionally
The adjective form of strong is strongly
The adjective form of visual is visually
The adjective form of effective is effectively
The adjective form of typical is typically
The adjective form of actual is actually
The adjective form of similar is
2024-07-31 07:52:19 root INFO     [order_1_approx] starting weight calculation for The adjective form of visual is visually
The adjective form of effective is effectively
The adjective form of actual is actually
The adjective form of similar is similarly
The adjective form of strong is strongly
The adjective form of mental is mentally
The adjective form of regional is regionally
The adjective form of typical is
2024-07-31 07:52:19 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-31 07:53:11 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0681, -0.3833, -0.1990,  ..., -0.2832, -0.4438,  0.1323],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.1777, -4.6445,  0.1138,  ..., -0.7158,  0.6104,  0.1855],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0134,  0.0112,  0.0125,  ..., -0.0160, -0.0107, -0.0161],
        [-0.0143, -0.0035, -0.0078,  ...,  0.0043, -0.0108, -0.0097],
        [-0.0085, -0.0150,  0.0053,  ...,  0.0142, -0.0141,  0.0093],
        ...,
        [-0.0008, -0.0242, -0.0057,  ...,  0.0420,  0.0008, -0.0032],
        [-0.0028,  0.0093,  0.0028,  ...,  0.0087,  0.0175,  0.0003],
        [ 0.0006,  0.0075,  0.0050,  ..., -0.0045, -0.0031,  0.0184]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.1172, -4.7422, -0.0760,  ..., -0.6924,  0.4983,  0.1284]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 07:53:12 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The broccoli is colored green
The tea is colored black
The raven is colored black
The potato is colored brown
The tomato is colored red
The swan is colored white
The blackboard is colored black
The cauliflower is colored
2024-07-31 07:53:12 root INFO     [order_1_approx] starting weight calculation for The raven is colored black
The tomato is colored red
The cauliflower is colored white
The tea is colored black
The broccoli is colored green
The swan is colored white
The potato is colored brown
The blackboard is colored
2024-07-31 07:53:12 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-31 07:54:59 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1318, -0.0812, -0.0264,  ...,  0.0555, -0.2781,  0.0245],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.7432, -1.1875,  1.0527,  ...,  0.8711, -5.2656, -3.2012],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0373, -0.0662,  0.0076,  ..., -0.0092, -0.0105,  0.0041],
        [-0.0214,  0.0587,  0.0042,  ..., -0.0070,  0.0308, -0.0157],
        [ 0.0106, -0.0002,  0.0097,  ..., -0.0159,  0.0209,  0.0188],
        ...,
        [-0.0291,  0.0192,  0.0092,  ...,  0.0496, -0.0005,  0.0070],
        [ 0.0480,  0.0042,  0.0004,  ...,  0.0319, -0.0275, -0.0228],
        [ 0.0179,  0.0245, -0.0076,  ...,  0.0041, -0.0170,  0.0050]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.3486, -1.3340,  0.8135,  ...,  0.9067, -4.8281, -3.3926]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 07:55:00 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The adjective form of visual is visually
The adjective form of effective is effectively
The adjective form of actual is actually
The adjective form of similar is similarly
The adjective form of strong is strongly
The adjective form of mental is mentally
The adjective form of regional is regionally
The adjective form of typical is
2024-07-31 07:55:00 root INFO     [order_1_approx] starting weight calculation for The adjective form of similar is similarly
The adjective form of effective is effectively
The adjective form of typical is typically
The adjective form of visual is visually
The adjective form of strong is strongly
The adjective form of mental is mentally
The adjective form of regional is regionally
The adjective form of actual is
2024-07-31 07:55:00 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-31 07:55:44 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2429,  0.1029, -0.3296,  ...,  0.1926, -0.1814, -0.2139],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.3545, -4.2305,  2.1719,  ...,  0.1367, -1.2793, -1.9395],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0464,  0.0083,  0.0033,  ..., -0.0148, -0.0058,  0.0082],
        [-0.0148,  0.0579,  0.0185,  ...,  0.0017, -0.0108,  0.0041],
        [-0.0234,  0.0323,  0.0446,  ...,  0.0124, -0.0017,  0.0132],
        ...,
        [ 0.0192,  0.0065, -0.0007,  ...,  0.0597, -0.0088, -0.0073],
        [-0.0032,  0.0093,  0.0109,  ...,  0.0058,  0.0372,  0.0019],
        [ 0.0158, -0.0231,  0.0083,  ...,  0.0114, -0.0040,  0.0528]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.0029, -4.5664,  1.8525,  ...,  0.5732, -1.2305, -1.8301]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 07:55:45 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The raven is colored black
The tomato is colored red
The cauliflower is colored white
The tea is colored black
The broccoli is colored green
The swan is colored white
The potato is colored brown
The blackboard is colored
2024-07-31 07:55:45 root INFO     [order_1_approx] starting weight calculation for The blackboard is colored black
The raven is colored black
The cauliflower is colored white
The tea is colored black
The swan is colored white
The tomato is colored red
The broccoli is colored green
The potato is colored
2024-07-31 07:55:45 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-31 07:57:41 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0672,  0.0088, -0.2064,  ..., -0.1897, -0.3313,  0.0132],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.9971, -2.7910,  1.1250,  ...,  0.0709, -1.9541, -1.0342],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0773, -0.0782, -0.0001,  ...,  0.0075,  0.0128,  0.0352],
        [ 0.0193,  0.0550, -0.0165,  ..., -0.0273,  0.0069, -0.0255],
        [ 0.0324,  0.0036,  0.0289,  ...,  0.0059, -0.0228, -0.0001],
        ...,
        [ 0.0363,  0.0764, -0.0101,  ...,  0.0220, -0.0239, -0.0174],
        [ 0.0164,  0.0083,  0.0016,  ...,  0.0242,  0.0195, -0.0252],
        [ 0.0569,  0.0177,  0.0046,  ..., -0.0430, -0.0160, -0.0012]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.9434, -2.7051,  1.5469,  ...,  0.1331, -2.0938, -0.9790]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 07:57:42 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The adjective form of similar is similarly
The adjective form of effective is effectively
The adjective form of typical is typically
The adjective form of visual is visually
The adjective form of strong is strongly
The adjective form of mental is mentally
The adjective form of regional is regionally
The adjective form of actual is
2024-07-31 07:57:42 root INFO     total operator prediction time: 1288.2043681144714 seconds
2024-07-31 07:57:42 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on over+adj_reg
2024-07-31 07:57:42 root INFO     building operator over+adj_reg
2024-07-31 07:57:42 root INFO     [order_1_approx] starting weight calculation for If something is too sized, it is oversized
If something is too arching, it is overarching
If something is too loaded, it is overloaded
If something is too played, it is overplayed
If something is too protective, it is overprotective
If something is too enthusiastic, it is overenthusiastic
If something is too painted, it is overpainted
If something is too laid, it is
2024-07-31 07:57:42 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-31 07:58:10 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0607,  0.1626,  0.0484,  ..., -0.3413, -0.4978, -0.0164],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.4688, -4.3047,  0.0830,  ..., -4.0156, -3.8633, -2.8594],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0430, -0.0050, -0.0063,  ...,  0.0023,  0.0173, -0.0088],
        [ 0.0109,  0.0171,  0.0289,  ..., -0.0049, -0.0016, -0.0021],
        [ 0.0030,  0.0100,  0.0506,  ...,  0.0150, -0.0273,  0.0143],
        ...,
        [-0.0221, -0.0334, -0.0186,  ...,  0.0557,  0.0110,  0.0222],
        [ 0.0078,  0.0028, -0.0114,  ...,  0.0195,  0.0331,  0.0110],
        [-0.0193, -0.0095, -0.0203,  ...,  0.0010, -0.0042,  0.0690]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.0801, -4.1328, -0.1711,  ..., -3.6875, -3.4648, -2.2188]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 07:58:11 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The blackboard is colored black
The raven is colored black
The cauliflower is colored white
The tea is colored black
The swan is colored white
The tomato is colored red
The broccoli is colored green
The potato is colored
2024-07-31 07:58:11 root INFO     [order_1_approx] starting weight calculation for The tomato is colored red
The potato is colored brown
The cauliflower is colored white
The blackboard is colored black
The tea is colored black
The swan is colored white
The raven is colored black
The broccoli is colored
2024-07-31 07:58:12 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-31 08:00:25 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1941,  0.1328, -0.1840,  ..., -0.1726, -0.4163,  0.0390],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.0801, -2.7266, -0.0684,  ...,  1.5879, -1.8066, -1.8760],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0844, -0.0105,  0.0114,  ...,  0.0040, -0.0151, -0.0052],
        [-0.0081,  0.0361,  0.0038,  ...,  0.0119, -0.0185, -0.0030],
        [ 0.0079, -0.0284,  0.0493,  ..., -0.0124, -0.0262,  0.0045],
        ...,
        [ 0.0244,  0.0383, -0.0012,  ...,  0.0669,  0.0202, -0.0044],
        [ 0.0181, -0.0346,  0.0011,  ..., -0.0104,  0.0677, -0.0348],
        [ 0.0005, -0.0045,  0.0033,  ..., -0.0017, -0.0113,  0.0412]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.1807, -2.6836,  0.0476,  ...,  1.6104, -2.5430, -1.7461]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 08:00:25 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is too sized, it is oversized
If something is too arching, it is overarching
If something is too loaded, it is overloaded
If something is too played, it is overplayed
If something is too protective, it is overprotective
If something is too enthusiastic, it is overenthusiastic
If something is too painted, it is overpainted
If something is too laid, it is
2024-07-31 08:00:26 root INFO     [order_1_approx] starting weight calculation for If something is too painted, it is overpainted
If something is too arching, it is overarching
If something is too enthusiastic, it is overenthusiastic
If something is too loaded, it is overloaded
If something is too protective, it is overprotective
If something is too played, it is overplayed
If something is too laid, it is overlaid
If something is too sized, it is
2024-07-31 08:00:26 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-31 08:00:35 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1793, -0.2925, -0.4778,  ..., -0.4106, -0.3679,  0.0564],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.5742, -4.4844, -0.7349,  ...,  0.6338,  0.6465, -1.2480],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0168,  0.0036, -0.0025,  ..., -0.0094, -0.0003, -0.0024],
        [-0.0004, -0.0019, -0.0018,  ..., -0.0069,  0.0087, -0.0071],
        [-0.0116, -0.0123,  0.0108,  ...,  0.0170, -0.0106,  0.0108],
        ...,
        [-0.0052, -0.0285, -0.0044,  ...,  0.0345, -0.0034,  0.0112],
        [-0.0087,  0.0166, -0.0051,  ...,  0.0107,  0.0160, -0.0027],
        [ 0.0023, -0.0012,  0.0034,  ...,  0.0014, -0.0033,  0.0188]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.7793, -4.3203, -1.0254,  ...,  0.8745,  0.6562, -1.3018]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 08:00:36 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The tomato is colored red
The potato is colored brown
The cauliflower is colored white
The blackboard is colored black
The tea is colored black
The swan is colored white
The raven is colored black
The broccoli is colored
2024-07-31 08:00:37 root INFO     [order_1_approx] starting weight calculation for The raven is colored black
The potato is colored brown
The blackboard is colored black
The broccoli is colored green
The tomato is colored red
The cauliflower is colored white
The swan is colored white
The tea is colored
2024-07-31 08:00:37 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-31 08:03:06 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2385, -0.3157, -0.3870,  ..., -0.1295, -0.1233, -0.0666],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.9185, -2.4473, -0.8003,  ..., -3.4199, -0.8467,  0.9580],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0327,  0.0189,  0.0194,  ..., -0.0025,  0.0081,  0.0055],
        [-0.0154,  0.0356,  0.0108,  ...,  0.0064,  0.0040,  0.0145],
        [ 0.0027,  0.0018,  0.0171,  ...,  0.0084, -0.0105,  0.0142],
        ...,
        [ 0.0138, -0.0220, -0.0201,  ...,  0.0395, -0.0079, -0.0051],
        [-0.0084,  0.0271, -0.0054,  ...,  0.0250,  0.0369, -0.0051],
        [-0.0123, -0.0217, -0.0113,  ..., -0.0171, -0.0037,  0.0250]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.7422, -2.8984, -0.8525,  ..., -3.4805, -0.9072,  0.9116]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 08:03:07 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The raven is colored black
The potato is colored brown
The blackboard is colored black
The broccoli is colored green
The tomato is colored red
The cauliflower is colored white
The swan is colored white
The tea is colored
2024-07-31 08:03:07 root INFO     total operator prediction time: 1195.9243476390839 seconds
2024-07-31 08:03:07 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on country - capital
2024-07-31 08:03:07 root INFO     building operator country - capital
2024-07-31 08:03:07 root INFO     [order_1_approx] starting weight calculation for The country with sofia as its capital is known as bulgaria
The country with dhaka as its capital is known as bangladesh
The country with islamabad as its capital is known as pakistan
The country with dublin as its capital is known as ireland
The country with warsaw as its capital is known as poland
The country with stockholm as its capital is known as sweden
The country with lisbon as its capital is known as portugal
The country with athens as its capital is known as
2024-07-31 08:03:07 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-31 08:03:08 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0246, -0.3057, -0.5713,  ..., -0.0443, -0.2070, -0.1068],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.8291, -4.0312, -1.1260,  ..., -0.7051, -3.7539,  0.4805],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0546, -0.0121,  0.0020,  ...,  0.0012,  0.0012,  0.0031],
        [-0.0083,  0.0359,  0.0282,  ...,  0.0044, -0.0246, -0.0104],
        [ 0.0092, -0.0017,  0.0401,  ..., -0.0028,  0.0031,  0.0133],
        ...,
        [ 0.0294, -0.0067,  0.0057,  ...,  0.0486,  0.0051,  0.0201],
        [ 0.0264,  0.0069, -0.0316,  ...,  0.0039,  0.0208, -0.0229],
        [-0.0083,  0.0107,  0.0170,  ...,  0.0047, -0.0247,  0.0264]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.6313, -3.8398, -1.4912,  ..., -0.4607, -3.6133,  0.3501]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 08:03:09 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is too painted, it is overpainted
If something is too arching, it is overarching
If something is too enthusiastic, it is overenthusiastic
If something is too loaded, it is overloaded
If something is too protective, it is overprotective
If something is too played, it is overplayed
If something is too laid, it is overlaid
If something is too sized, it is
2024-07-31 08:03:10 root INFO     [order_1_approx] starting weight calculation for If something is too arching, it is overarching
If something is too painted, it is overpainted
If something is too laid, it is overlaid
If something is too enthusiastic, it is overenthusiastic
If something is too played, it is overplayed
If something is too protective, it is overprotective
If something is too sized, it is oversized
If something is too loaded, it is
2024-07-31 08:03:10 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-31 08:05:33 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2803, -0.0364, -0.6343,  ...,  0.0468, -0.1818, -0.2542],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.6055, -5.4766, -3.0098,  ..., -0.0283,  1.5645, -2.8027],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0232,  0.0036, -0.0077,  ..., -0.0018, -0.0111,  0.0016],
        [ 0.0006,  0.0103,  0.0003,  ...,  0.0109, -0.0059, -0.0130],
        [-0.0054,  0.0196,  0.0491,  ...,  0.0091,  0.0027, -0.0135],
        ...,
        [-0.0129, -0.0002, -0.0105,  ...,  0.0276,  0.0163, -0.0149],
        [ 0.0027, -0.0086, -0.0032,  ..., -0.0067,  0.0125, -0.0014],
        [-0.0095, -0.0104, -0.0084,  ...,  0.0037, -0.0042,  0.0105]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.5742, -5.3125, -3.0645,  ...,  0.0226,  1.4395, -2.3691]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 08:05:34 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country with sofia as its capital is known as bulgaria
The country with dhaka as its capital is known as bangladesh
The country with islamabad as its capital is known as pakistan
The country with dublin as its capital is known as ireland
The country with warsaw as its capital is known as poland
The country with stockholm as its capital is known as sweden
The country with lisbon as its capital is known as portugal
The country with athens as its capital is known as
2024-07-31 08:05:34 root INFO     [order_1_approx] starting weight calculation for The country with dhaka as its capital is known as bangladesh
The country with athens as its capital is known as greece
The country with stockholm as its capital is known as sweden
The country with warsaw as its capital is known as poland
The country with dublin as its capital is known as ireland
The country with islamabad as its capital is known as pakistan
The country with lisbon as its capital is known as portugal
The country with sofia as its capital is known as
2024-07-31 08:05:34 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-31 08:05:51 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1414, -0.3936, -0.3560,  ..., -0.1261, -0.5366,  0.3391],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.1953, -4.0273,  0.9033,  ...,  1.1934, -2.9668, -1.0264],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0453, -0.0088, -0.0044,  ...,  0.0050,  0.0317,  0.0170],
        [ 0.0011,  0.0379,  0.0131,  ...,  0.0136, -0.0256, -0.0200],
        [ 0.0085,  0.0191,  0.0378,  ...,  0.0179,  0.0216,  0.0150],
        ...,
        [ 0.0195,  0.0337, -0.0095,  ...,  0.0525, -0.0323, -0.0120],
        [ 0.0120,  0.0138, -0.0090,  ...,  0.0006,  0.0328, -0.0198],
        [-0.0083,  0.0093,  0.0049,  ...,  0.0097, -0.0151,  0.0297]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.9785, -3.5469,  0.6885,  ...,  1.0156, -3.1719, -0.9648]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 08:05:52 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is too arching, it is overarching
If something is too painted, it is overpainted
If something is too laid, it is overlaid
If something is too enthusiastic, it is overenthusiastic
If something is too played, it is overplayed
If something is too protective, it is overprotective
If something is too sized, it is oversized
If something is too loaded, it is
2024-07-31 08:05:52 root INFO     [order_1_approx] starting weight calculation for If something is too loaded, it is overloaded
If something is too played, it is overplayed
If something is too laid, it is overlaid
If something is too enthusiastic, it is overenthusiastic
If something is too arching, it is overarching
If something is too sized, it is oversized
If something is too protective, it is overprotective
If something is too painted, it is
2024-07-31 08:05:53 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-31 08:08:05 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3286, -0.2959, -0.9810,  ...,  0.1533,  0.1577,  0.1632],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.0010, -4.5859, -0.7739,  ...,  0.2815,  0.6201, -5.1367],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0049, -0.0044, -0.0150,  ...,  0.0198, -0.0078,  0.0124],
        [-0.0016,  0.0171,  0.0144,  ..., -0.0061,  0.0163, -0.0153],
        [ 0.0212,  0.0184,  0.0350,  ..., -0.0010, -0.0227, -0.0138],
        ...,
        [-0.0032,  0.0068,  0.0020,  ...,  0.0364,  0.0005, -0.0094],
        [ 0.0104, -0.0040, -0.0122,  ..., -0.0079,  0.0286, -0.0003],
        [-0.0151, -0.0072, -0.0040,  ..., -0.0155,  0.0229,  0.0044]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.9741, -4.1914, -1.0205,  ...,  0.1960,  0.4182, -4.8477]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 08:08:06 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country with dhaka as its capital is known as bangladesh
The country with athens as its capital is known as greece
The country with stockholm as its capital is known as sweden
The country with warsaw as its capital is known as poland
The country with dublin as its capital is known as ireland
The country with islamabad as its capital is known as pakistan
The country with lisbon as its capital is known as portugal
The country with sofia as its capital is known as
2024-07-31 08:08:07 root INFO     [order_1_approx] starting weight calculation for The country with dublin as its capital is known as ireland
The country with dhaka as its capital is known as bangladesh
The country with stockholm as its capital is known as sweden
The country with lisbon as its capital is known as portugal
The country with athens as its capital is known as greece
The country with warsaw as its capital is known as poland
The country with sofia as its capital is known as bulgaria
The country with islamabad as its capital is known as
2024-07-31 08:08:07 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-31 08:08:33 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0270, -0.4485, -0.2981,  ..., -0.0019, -0.3723,  0.1367],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.4297, -3.3945, -0.5713,  ...,  0.0569, -2.1113, -2.1230],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0207,  0.0077, -0.0038,  ..., -0.0196,  0.0027,  0.0252],
        [-0.0088,  0.0199, -0.0055,  ...,  0.0293, -0.0072, -0.0200],
        [ 0.0162, -0.0015,  0.0277,  ..., -0.0079,  0.0021,  0.0251],
        ...,
        [ 0.0264,  0.0116,  0.0039,  ...,  0.0293,  0.0023,  0.0006],
        [ 0.0066, -0.0154, -0.0074,  ...,  0.0024,  0.0562, -0.0244],
        [ 0.0042,  0.0060,  0.0127,  ...,  0.0090, -0.0373,  0.0152]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.1963, -3.2344, -0.5522,  ...,  0.3892, -2.1094, -2.2656]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 08:08:34 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is too loaded, it is overloaded
If something is too played, it is overplayed
If something is too laid, it is overlaid
If something is too enthusiastic, it is overenthusiastic
If something is too arching, it is overarching
If something is too sized, it is oversized
If something is too protective, it is overprotective
If something is too painted, it is
2024-07-31 08:08:34 root INFO     [order_1_approx] starting weight calculation for If something is too played, it is overplayed
If something is too laid, it is overlaid
If something is too loaded, it is overloaded
If something is too enthusiastic, it is overenthusiastic
If something is too arching, it is overarching
If something is too painted, it is overpainted
If something is too sized, it is oversized
If something is too protective, it is
2024-07-31 08:08:34 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-31 08:10:37 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0585, -0.0055, -0.3213,  ...,  0.5059, -0.3428,  0.5869],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.1250, -6.8242, -0.4604,  ..., -0.6729, -0.8511, -1.9893],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0207,  0.0044,  0.0037,  ...,  0.0092, -0.0034, -0.0033],
        [-0.0093,  0.0122, -0.0174,  ..., -0.0138, -0.0085, -0.0067],
        [ 0.0109,  0.0460,  0.0456,  ..., -0.0058,  0.0123, -0.0308],
        ...,
        [ 0.0097, -0.0077, -0.0324,  ...,  0.0230,  0.0097,  0.0020],
        [-0.0177, -0.0066, -0.0018,  ...,  0.0172, -0.0159,  0.0152],
        [ 0.0008,  0.0007,  0.0077,  ...,  0.0087, -0.0082,  0.0129]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.9434, -6.5547, -0.9814,  ..., -0.4990, -0.7017, -2.2559]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 08:10:38 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country with dublin as its capital is known as ireland
The country with dhaka as its capital is known as bangladesh
The country with stockholm as its capital is known as sweden
The country with lisbon as its capital is known as portugal
The country with athens as its capital is known as greece
The country with warsaw as its capital is known as poland
The country with sofia as its capital is known as bulgaria
The country with islamabad as its capital is known as
2024-07-31 08:10:38 root INFO     [order_1_approx] starting weight calculation for The country with athens as its capital is known as greece
The country with dublin as its capital is known as ireland
The country with warsaw as its capital is known as poland
The country with dhaka as its capital is known as bangladesh
The country with islamabad as its capital is known as pakistan
The country with sofia as its capital is known as bulgaria
The country with stockholm as its capital is known as sweden
The country with lisbon as its capital is known as
2024-07-31 08:10:38 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-31 08:11:17 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1333, -0.3538, -0.2629,  ...,  0.2240, -0.3003, -0.1798],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.4668, -5.0703,  0.8867,  ...,  0.2930, -1.4678, -2.3906],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0323,  0.0106,  0.0032,  ..., -0.0060, -0.0007,  0.0052],
        [ 0.0297,  0.0291,  0.0106,  ..., -0.0005,  0.0138,  0.0154],
        [-0.0003,  0.0373,  0.0348,  ...,  0.0241, -0.0012, -0.0061],
        ...,
        [ 0.0167,  0.0118,  0.0043,  ...,  0.0179, -0.0046,  0.0065],
        [ 0.0107, -0.0207,  0.0125,  ..., -0.0028,  0.0132, -0.0222],
        [-0.0322, -0.0196, -0.0010,  ..., -0.0066, -0.0025,  0.0033]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.6260, -4.6875,  1.1768,  ...,  0.3152, -1.6240, -2.6797]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 08:11:18 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is too played, it is overplayed
If something is too laid, it is overlaid
If something is too loaded, it is overloaded
If something is too enthusiastic, it is overenthusiastic
If something is too arching, it is overarching
If something is too painted, it is overpainted
If something is too sized, it is oversized
If something is too protective, it is
2024-07-31 08:11:18 root INFO     [order_1_approx] starting weight calculation for If something is too painted, it is overpainted
If something is too sized, it is oversized
If something is too laid, it is overlaid
If something is too played, it is overplayed
If something is too arching, it is overarching
If something is too protective, it is overprotective
If something is too loaded, it is overloaded
If something is too enthusiastic, it is
2024-07-31 08:11:18 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-31 08:13:06 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1742, -0.2347, -0.6509,  ...,  0.2549, -0.0115, -0.1836],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.1133, -5.9922, -2.9961,  ...,  0.2155,  1.6562, -4.4766],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0207, -0.0008, -0.0094,  ...,  0.0127, -0.0146,  0.0090],
        [ 0.0105,  0.0287,  0.0156,  ..., -0.0096, -0.0024, -0.0025],
        [ 0.0079,  0.0166,  0.0345,  ..., -0.0050,  0.0157, -0.0125],
        ...,
        [ 0.0099,  0.0204,  0.0039,  ...,  0.0222, -0.0006,  0.0049],
        [ 0.0021, -0.0019, -0.0183,  ...,  0.0011,  0.0132, -0.0073],
        [ 0.0054, -0.0098, -0.0313,  ...,  0.0041, -0.0078,  0.0026]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.9219, -5.8008, -2.7461,  ...,  0.4609,  1.4131, -4.2773]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 08:13:07 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country with athens as its capital is known as greece
The country with dublin as its capital is known as ireland
The country with warsaw as its capital is known as poland
The country with dhaka as its capital is known as bangladesh
The country with islamabad as its capital is known as pakistan
The country with sofia as its capital is known as bulgaria
The country with stockholm as its capital is known as sweden
The country with lisbon as its capital is known as
2024-07-31 08:13:07 root INFO     [order_1_approx] starting weight calculation for The country with warsaw as its capital is known as poland
The country with sofia as its capital is known as bulgaria
The country with stockholm as its capital is known as sweden
The country with islamabad as its capital is known as pakistan
The country with lisbon as its capital is known as portugal
The country with athens as its capital is known as greece
The country with dublin as its capital is known as ireland
The country with dhaka as its capital is known as
2024-07-31 08:13:07 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-31 08:13:57 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1700, -0.1794, -0.1979,  ...,  0.2739, -0.4937, -0.1221],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.4629, -3.7441,  0.2310,  ...,  0.3823, -2.4629, -2.7793],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 3.7537e-02,  1.1093e-02,  3.3665e-04,  ..., -2.2003e-02,
          1.8196e-03,  1.2550e-02],
        [-1.7456e-02,  2.8641e-02,  2.1667e-03,  ...,  2.5253e-03,
         -3.4561e-03,  7.4348e-03],
        [ 1.3474e-02,  1.5884e-02,  2.8458e-02,  ...,  1.4145e-02,
         -3.5954e-03,  1.8646e-02],
        ...,
        [ 8.5068e-04,  1.0620e-02, -2.6569e-03,  ...,  3.0655e-02,
          7.0572e-05, -7.5960e-04],
        [-6.6032e-03, -2.2106e-03,  1.5259e-02,  ..., -1.4832e-02,
          2.4658e-02, -9.1400e-03],
        [-8.6517e-03,  1.3321e-02,  4.6082e-03,  ...,  5.4550e-03,
         -5.3139e-03,  1.9699e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.8618, -3.7168,  0.0297,  ...,  0.3298, -2.6074, -2.8457]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 08:13:58 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is too painted, it is overpainted
If something is too sized, it is oversized
If something is too laid, it is overlaid
If something is too played, it is overplayed
If something is too arching, it is overarching
If something is too protective, it is overprotective
If something is too loaded, it is overloaded
If something is too enthusiastic, it is
2024-07-31 08:13:58 root INFO     [order_1_approx] starting weight calculation for If something is too sized, it is oversized
If something is too played, it is overplayed
If something is too painted, it is overpainted
If something is too laid, it is overlaid
If something is too enthusiastic, it is overenthusiastic
If something is too loaded, it is overloaded
If something is too protective, it is overprotective
If something is too arching, it is
2024-07-31 08:13:58 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-31 08:15:35 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.3979, -0.2253, -0.6392,  ...,  0.3396, -0.2346,  0.2488],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.5601, -5.3125, -0.6494,  ..., -1.6250, -0.3994, -4.9805],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0214, -0.0006, -0.0108,  ...,  0.0072, -0.0099, -0.0060],
        [ 0.0006,  0.0230, -0.0050,  ..., -0.0030,  0.0028, -0.0221],
        [ 0.0007,  0.0256,  0.0385,  ..., -0.0130,  0.0052, -0.0257],
        ...,
        [ 0.0038,  0.0038, -0.0014,  ...,  0.0208,  0.0066, -0.0145],
        [ 0.0074,  0.0106, -0.0076,  ..., -0.0044,  0.0196,  0.0211],
        [-0.0141, -0.0061,  0.0004,  ..., -0.0015,  0.0097, -0.0032]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.3237, -5.2500, -0.8745,  ..., -1.3418, -0.1630, -4.9609]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 08:15:36 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country with warsaw as its capital is known as poland
The country with sofia as its capital is known as bulgaria
The country with stockholm as its capital is known as sweden
The country with islamabad as its capital is known as pakistan
The country with lisbon as its capital is known as portugal
The country with athens as its capital is known as greece
The country with dublin as its capital is known as ireland
The country with dhaka as its capital is known as
2024-07-31 08:15:36 root INFO     [order_1_approx] starting weight calculation for The country with islamabad as its capital is known as pakistan
The country with dhaka as its capital is known as bangladesh
The country with stockholm as its capital is known as sweden
The country with dublin as its capital is known as ireland
The country with lisbon as its capital is known as portugal
The country with sofia as its capital is known as bulgaria
The country with athens as its capital is known as greece
The country with warsaw as its capital is known as
2024-07-31 08:15:36 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-31 08:16:33 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1277, -0.3909, -0.0070,  ..., -0.0303, -0.5303, -0.4810],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.0703, -3.5137,  2.2109,  ...,  0.8818, -1.5527, -3.0371],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0448,  0.0099, -0.0062,  ...,  0.0089,  0.0008,  0.0003],
        [-0.0080,  0.0428,  0.0115,  ...,  0.0118, -0.0104,  0.0074],
        [-0.0036,  0.0075,  0.0431,  ..., -0.0013,  0.0036, -0.0042],
        ...,
        [ 0.0142,  0.0207,  0.0104,  ...,  0.0404, -0.0031,  0.0163],
        [ 0.0258, -0.0150,  0.0424,  ..., -0.0025,  0.0600, -0.0008],
        [-0.0171,  0.0030, -0.0220,  ...,  0.0003, -0.0257,  0.0239]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.1592, -3.5273,  1.9248,  ...,  1.0703, -1.6729, -3.1992]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 08:16:34 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is too sized, it is oversized
If something is too played, it is overplayed
If something is too painted, it is overpainted
If something is too laid, it is overlaid
If something is too enthusiastic, it is overenthusiastic
If something is too loaded, it is overloaded
If something is too protective, it is overprotective
If something is too arching, it is
2024-07-31 08:16:35 root INFO     [order_1_approx] starting weight calculation for If something is too laid, it is overlaid
If something is too enthusiastic, it is overenthusiastic
If something is too sized, it is oversized
If something is too protective, it is overprotective
If something is too arching, it is overarching
If something is too painted, it is overpainted
If something is too loaded, it is overloaded
If something is too played, it is
2024-07-31 08:16:35 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-31 08:17:58 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1934, -0.3657, -0.6460,  ...,  0.1980, -0.2380, -0.2568],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.2207, -6.5625, -2.2090,  ..., -0.6704,  1.6074, -4.3867],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0206,  0.0002, -0.0046,  ...,  0.0226, -0.0059,  0.0141],
        [ 0.0041,  0.0190,  0.0110,  ..., -0.0197, -0.0008, -0.0076],
        [-0.0099,  0.0445,  0.0217,  ..., -0.0008, -0.0069, -0.0041],
        ...,
        [-0.0008,  0.0125,  0.0075,  ...,  0.0411, -0.0019, -0.0021],
        [ 0.0131, -0.0013, -0.0182,  ...,  0.0171,  0.0122,  0.0004],
        [-0.0098,  0.0044, -0.0087,  ...,  0.0045, -0.0159,  0.0117]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.3008, -6.3359, -2.5391,  ..., -0.6318,  1.5020, -4.2266]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 08:17:59 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country with islamabad as its capital is known as pakistan
The country with dhaka as its capital is known as bangladesh
The country with stockholm as its capital is known as sweden
The country with dublin as its capital is known as ireland
The country with lisbon as its capital is known as portugal
The country with sofia as its capital is known as bulgaria
The country with athens as its capital is known as greece
The country with warsaw as its capital is known as
2024-07-31 08:17:59 root INFO     [order_1_approx] starting weight calculation for The country with sofia as its capital is known as bulgaria
The country with athens as its capital is known as greece
The country with lisbon as its capital is known as portugal
The country with warsaw as its capital is known as poland
The country with dhaka as its capital is known as bangladesh
The country with stockholm as its capital is known as sweden
The country with islamabad as its capital is known as pakistan
The country with dublin as its capital is known as
2024-07-31 08:17:59 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-31 08:19:12 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0870, -0.2905, -0.2498,  ..., -0.1318, -0.5752,  0.3052],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.9590, -2.8398,  0.5298,  ..., -0.0398, -0.3086, -3.1836],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0559,  0.0123,  0.0142,  ...,  0.0030,  0.0180,  0.0084],
        [-0.0264,  0.0399, -0.0049,  ...,  0.0237, -0.0415, -0.0268],
        [ 0.0257, -0.0088,  0.0273,  ...,  0.0188, -0.0035,  0.0210],
        ...,
        [ 0.0193, -0.0016,  0.0001,  ...,  0.0332,  0.0185, -0.0088],
        [ 0.0165,  0.0031, -0.0075,  ..., -0.0240,  0.0204, -0.0312],
        [-0.0111,  0.0082,  0.0082,  ...,  0.0056, -0.0240,  0.0295]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.0488, -2.9395,  0.4224,  ...,  0.3286, -0.3203, -3.3379]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 08:19:13 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is too laid, it is overlaid
If something is too enthusiastic, it is overenthusiastic
If something is too sized, it is oversized
If something is too protective, it is overprotective
If something is too arching, it is overarching
If something is too painted, it is overpainted
If something is too loaded, it is overloaded
If something is too played, it is
2024-07-31 08:19:13 root INFO     total operator prediction time: 1291.1906826496124 seconds
2024-07-31 08:19:13 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on verb+er_irreg
2024-07-31 08:19:13 root INFO     building operator verb+er_irreg
2024-07-31 08:19:13 root INFO     [order_1_approx] starting weight calculation for If you discover something, you are a discoverer
If you subscribe something, you are a subscriber
If you believe something, you are a believer
If you recommend something, you are a recommender
If you choreograph something, you are a choreographer
If you announce something, you are a announcer
If you examine something, you are a examiner
If you provide something, you are a
2024-07-31 08:19:13 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-31 08:20:31 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0556, -0.1096, -0.6309,  ...,  0.3423, -0.0070,  0.1595],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.6387, -5.7109, -1.2725,  ...,  1.8301, -0.9219, -6.8945],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0313, -0.0066, -0.0133,  ...,  0.0183, -0.0083,  0.0153],
        [ 0.0007,  0.0246, -0.0173,  ..., -0.0146, -0.0183, -0.0221],
        [-0.0034,  0.0313,  0.0384,  ...,  0.0102,  0.0053, -0.0105],
        ...,
        [-0.0010,  0.0072, -0.0025,  ...,  0.0188,  0.0051, -0.0174],
        [-0.0003,  0.0086, -0.0079,  ..., -0.0057, -0.0018, -0.0011],
        [ 0.0020, -0.0187,  0.0035,  ...,  0.0077,  0.0012,  0.0184]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.6934, -5.6992, -1.3564,  ...,  1.5781, -1.2090, -6.3086]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 08:20:32 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country with sofia as its capital is known as bulgaria
The country with athens as its capital is known as greece
The country with lisbon as its capital is known as portugal
The country with warsaw as its capital is known as poland
The country with dhaka as its capital is known as bangladesh
The country with stockholm as its capital is known as sweden
The country with islamabad as its capital is known as pakistan
The country with dublin as its capital is known as
2024-07-31 08:20:32 root INFO     [order_1_approx] starting weight calculation for The country with dublin as its capital is known as ireland
The country with islamabad as its capital is known as pakistan
The country with dhaka as its capital is known as bangladesh
The country with lisbon as its capital is known as portugal
The country with athens as its capital is known as greece
The country with warsaw as its capital is known as poland
The country with sofia as its capital is known as bulgaria
The country with stockholm as its capital is known as
2024-07-31 08:20:32 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-31 08:21:47 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1409,  0.2522, -0.2324,  ...,  0.3494, -0.1377, -0.2471],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.7129, -6.3594,  2.4473,  ...,  1.5908, -5.0195, -2.5586],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0373, -0.0027,  0.0115,  ..., -0.0008,  0.0082, -0.0033],
        [-0.0056, -0.0068, -0.0127,  ..., -0.0004, -0.0021, -0.0054],
        [ 0.0013, -0.0258,  0.0582,  ..., -0.0048, -0.0225, -0.0006],
        ...,
        [ 0.0143,  0.0301, -0.0054,  ...,  0.0091,  0.0361,  0.0161],
        [ 0.0328, -0.0007, -0.0074,  ..., -0.0135,  0.0172,  0.0019],
        [ 0.0145,  0.0201, -0.0080,  ...,  0.0057, -0.0258,  0.0065]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.6309, -6.5547,  2.2344,  ...,  1.6494, -5.0625, -2.8516]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 08:21:48 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you discover something, you are a discoverer
If you subscribe something, you are a subscriber
If you believe something, you are a believer
If you recommend something, you are a recommender
If you choreograph something, you are a choreographer
If you announce something, you are a announcer
If you examine something, you are a examiner
If you provide something, you are a
2024-07-31 08:21:48 root INFO     [order_1_approx] starting weight calculation for If you subscribe something, you are a subscriber
If you choreograph something, you are a choreographer
If you provide something, you are a provider
If you recommend something, you are a recommender
If you believe something, you are a believer
If you examine something, you are a examiner
If you announce something, you are a announcer
If you discover something, you are a
2024-07-31 08:21:48 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-31 08:23:01 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1702, -0.2123, -0.5264,  ...,  0.0630,  0.2715,  0.3765],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.6523, -5.9805, -2.2188,  ..., -1.1094, -1.2510, -3.4160],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0236,  0.0048, -0.0021,  ...,  0.0185, -0.0033,  0.0259],
        [ 0.0104,  0.0091,  0.0056,  ..., -0.0065,  0.0001, -0.0222],
        [-0.0093,  0.0174,  0.0301,  ..., -0.0008,  0.0173, -0.0054],
        ...,
        [ 0.0035,  0.0116,  0.0060,  ...,  0.0424,  0.0052, -0.0125],
        [ 0.0073,  0.0019, -0.0234,  ...,  0.0177,  0.0012,  0.0099],
        [-0.0113, -0.0258, -0.0224,  ...,  0.0077, -0.0202,  0.0086]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.7754, -6.0430, -2.5840,  ..., -0.8281, -0.9233, -3.2070]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 08:23:02 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country with dublin as its capital is known as ireland
The country with islamabad as its capital is known as pakistan
The country with dhaka as its capital is known as bangladesh
The country with lisbon as its capital is known as portugal
The country with athens as its capital is known as greece
The country with warsaw as its capital is known as poland
The country with sofia as its capital is known as bulgaria
The country with stockholm as its capital is known as
2024-07-31 08:23:02 root INFO     total operator prediction time: 1194.5876579284668 seconds
2024-07-31 08:23:02 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on name - occupation
2024-07-31 08:23:02 root INFO     building operator name - occupation
2024-07-31 08:23:02 root INFO     [order_1_approx] starting weight calculation for moses was known for their work as a  prophet
columbus was known for their work as a  explorer
darwin was known for their work as a  naturalist
spinoza was known for their work as a  philosopher
mencius was known for their work as a  philosopher
shakespeare was known for their work as a  playwright
mozart was known for their work as a  composer
haydn was known for their work as a 
2024-07-31 08:23:02 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-31 08:24:23 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0736,  0.3716, -0.0925,  ...,  0.0269, -0.2864, -0.0821],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.9355, -3.3320,  2.6953,  ..., -0.2339, -4.8359, -0.8896],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0196, -0.0073,  0.0041,  ...,  0.0093,  0.0156,  0.0072],
        [-0.0005,  0.0035,  0.0107,  ..., -0.0080, -0.0112,  0.0074],
        [ 0.0026, -0.0104,  0.0239,  ..., -0.0023, -0.0166, -0.0169],
        ...,
        [ 0.0316,  0.0099,  0.0025,  ...,  0.0131,  0.0066,  0.0058],
        [ 0.0110, -0.0110,  0.0072,  ..., -0.0302,  0.0092, -0.0096],
        [ 0.0139,  0.0128, -0.0019,  ...,  0.0142, -0.0352, -0.0043]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.8789, -3.6172,  2.4512,  ..., -0.1410, -4.8281, -1.2266]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 08:24:24 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you subscribe something, you are a subscriber
If you choreograph something, you are a choreographer
If you provide something, you are a provider
If you recommend something, you are a recommender
If you believe something, you are a believer
If you examine something, you are a examiner
If you announce something, you are a announcer
If you discover something, you are a
2024-07-31 08:24:24 root INFO     [order_1_approx] starting weight calculation for If you provide something, you are a provider
If you announce something, you are a announcer
If you choreograph something, you are a choreographer
If you believe something, you are a believer
If you recommend something, you are a recommender
If you subscribe something, you are a subscriber
If you discover something, you are a discoverer
If you examine something, you are a
2024-07-31 08:24:24 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-31 08:25:34 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0779,  0.2053, -0.2854,  ...,  0.0045, -0.2263,  0.1000],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.1250, -4.7344,  3.0371,  ..., -2.4570,  1.0957, -2.3730],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0366,  0.0030,  0.0085,  ...,  0.0183, -0.0018,  0.0099],
        [ 0.0126,  0.0348,  0.0057,  ...,  0.0005,  0.0003, -0.0067],
        [ 0.0208,  0.0060,  0.0474,  ...,  0.0009, -0.0103, -0.0017],
        ...,
        [ 0.0146,  0.0326,  0.0154,  ...,  0.0392,  0.0148,  0.0080],
        [ 0.0106, -0.0002,  0.0004,  ..., -0.0097,  0.0247,  0.0031],
        [-0.0062,  0.0069,  0.0084,  ...,  0.0046, -0.0144,  0.0226]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.8545, -4.4375,  3.0078,  ..., -2.7305,  1.0977, -2.4258]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 08:25:35 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for moses was known for their work as a  prophet
columbus was known for their work as a  explorer
darwin was known for their work as a  naturalist
spinoza was known for their work as a  philosopher
mencius was known for their work as a  philosopher
shakespeare was known for their work as a  playwright
mozart was known for their work as a  composer
haydn was known for their work as a 
2024-07-31 08:25:35 root INFO     [order_1_approx] starting weight calculation for columbus was known for their work as a  explorer
haydn was known for their work as a  composer
mozart was known for their work as a  composer
spinoza was known for their work as a  philosopher
mencius was known for their work as a  philosopher
shakespeare was known for their work as a  playwright
moses was known for their work as a  prophet
darwin was known for their work as a 
2024-07-31 08:25:35 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-31 08:27:01 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1339, -0.0587, -0.0693,  ..., -0.0069, -0.1475, -0.1903],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.2148, -2.4082,  1.0469,  ..., -2.2188, -4.3438, -5.3672],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0536, -0.0101,  0.0025,  ...,  0.0090, -0.0047,  0.0030],
        [-0.0035,  0.0328,  0.0244,  ..., -0.0052,  0.0062, -0.0109],
        [-0.0068,  0.0164,  0.0073,  ...,  0.0164,  0.0349,  0.0050],
        ...,
        [ 0.0194,  0.0146,  0.0010,  ...,  0.0190,  0.0075,  0.0050],
        [-0.0157,  0.0010, -0.0054,  ..., -0.0173, -0.0080, -0.0012],
        [-0.0079,  0.0057,  0.0097,  ...,  0.0264, -0.0042,  0.0180]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.2852, -2.4727,  0.9941,  ..., -1.8340, -4.3789, -5.3906]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 08:27:02 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you provide something, you are a provider
If you announce something, you are a announcer
If you choreograph something, you are a choreographer
If you believe something, you are a believer
If you recommend something, you are a recommender
If you subscribe something, you are a subscriber
If you discover something, you are a discoverer
If you examine something, you are a
2024-07-31 08:27:02 root INFO     [order_1_approx] starting weight calculation for If you announce something, you are a announcer
If you provide something, you are a provider
If you believe something, you are a believer
If you examine something, you are a examiner
If you recommend something, you are a recommender
If you discover something, you are a discoverer
If you subscribe something, you are a subscriber
If you choreograph something, you are a
2024-07-31 08:27:03 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-31 08:28:03 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3018, -0.2847, -0.1489,  ..., -0.0647, -0.0627,  0.1318],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.6699, -5.0781,  2.8164,  ..., -5.9102,  0.4502, -2.1074],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0399, -0.0268,  0.0035,  ..., -0.0177,  0.0156,  0.0206],
        [-0.0050,  0.0296, -0.0103,  ...,  0.0042, -0.0089, -0.0080],
        [ 0.0150,  0.0047,  0.0469,  ..., -0.0080, -0.0020, -0.0004],
        ...,
        [ 0.0086,  0.0135,  0.0202,  ...,  0.0461,  0.0164, -0.0142],
        [-0.0066,  0.0038,  0.0058,  ..., -0.0001,  0.0177,  0.0059],
        [-0.0029, -0.0128, -0.0001,  ..., -0.0117,  0.0115,  0.0470]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.8291, -4.8711,  2.7520,  ..., -5.6641,  0.8574, -1.7305]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 08:28:04 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for columbus was known for their work as a  explorer
haydn was known for their work as a  composer
mozart was known for their work as a  composer
spinoza was known for their work as a  philosopher
mencius was known for their work as a  philosopher
shakespeare was known for their work as a  playwright
moses was known for their work as a  prophet
darwin was known for their work as a 
2024-07-31 08:28:04 root INFO     [order_1_approx] starting weight calculation for mencius was known for their work as a  philosopher
shakespeare was known for their work as a  playwright
spinoza was known for their work as a  philosopher
haydn was known for their work as a  composer
columbus was known for their work as a  explorer
moses was known for their work as a  prophet
darwin was known for their work as a  naturalist
mozart was known for their work as a 
2024-07-31 08:28:04 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-31 08:29:42 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2673,  0.4048, -0.0852,  ..., -0.1532, -0.4219, -0.0529],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.1255, -3.4688,  3.1133,  ..., -0.9336, -3.6836, -1.9434],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0352, -0.0136,  0.0154,  ...,  0.0090,  0.0116, -0.0115],
        [ 0.0131,  0.0316, -0.0121,  ...,  0.0267,  0.0078, -0.0111],
        [-0.0204,  0.0041,  0.0120,  ...,  0.0102, -0.0055,  0.0150],
        ...,
        [ 0.0105,  0.0158, -0.0044,  ...,  0.0273,  0.0047, -0.0058],
        [ 0.0093,  0.0036, -0.0129,  ..., -0.0256,  0.0064, -0.0179],
        [ 0.0010, -0.0059,  0.0168,  ..., -0.0053, -0.0063,  0.0291]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.3936, -3.2344,  2.9141,  ..., -0.8462, -3.6113, -1.8877]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 08:29:43 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you announce something, you are a announcer
If you provide something, you are a provider
If you believe something, you are a believer
If you examine something, you are a examiner
If you recommend something, you are a recommender
If you discover something, you are a discoverer
If you subscribe something, you are a subscriber
If you choreograph something, you are a
2024-07-31 08:29:44 root INFO     [order_1_approx] starting weight calculation for If you recommend something, you are a recommender
If you choreograph something, you are a choreographer
If you discover something, you are a discoverer
If you examine something, you are a examiner
If you believe something, you are a believer
If you provide something, you are a provider
If you announce something, you are a announcer
If you subscribe something, you are a
2024-07-31 08:29:44 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-31 08:30:29 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1469,  0.1678, -0.2291,  ...,  0.1467, -0.1997, -0.2190],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.1582, -4.4766,  2.0430,  ..., -1.3828,  0.8750,  0.0889],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0235,  0.0059,  0.0023,  ...,  0.0119, -0.0004,  0.0141],
        [ 0.0028,  0.0150, -0.0016,  ...,  0.0004,  0.0003,  0.0039],
        [ 0.0148,  0.0104,  0.0421,  ..., -0.0048, -0.0223,  0.0036],
        ...,
        [ 0.0109,  0.0052,  0.0165,  ...,  0.0439,  0.0168,  0.0064],
        [ 0.0073,  0.0083,  0.0086,  ...,  0.0122,  0.0153,  0.0017],
        [-0.0117,  0.0018, -0.0050,  ..., -0.0113, -0.0141,  0.0301]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.0977, -4.2266,  1.7324,  ..., -1.1377,  0.6553,  0.2164]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 08:30:29 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for mencius was known for their work as a  philosopher
shakespeare was known for their work as a  playwright
spinoza was known for their work as a  philosopher
haydn was known for their work as a  composer
columbus was known for their work as a  explorer
moses was known for their work as a  prophet
darwin was known for their work as a  naturalist
mozart was known for their work as a 
2024-07-31 08:30:30 root INFO     [order_1_approx] starting weight calculation for haydn was known for their work as a  composer
moses was known for their work as a  prophet
darwin was known for their work as a  naturalist
mozart was known for their work as a  composer
columbus was known for their work as a  explorer
mencius was known for their work as a  philosopher
spinoza was known for their work as a  philosopher
shakespeare was known for their work as a 
2024-07-31 08:30:30 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-31 08:32:22 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0089,  0.1648, -0.2759,  ...,  0.2358, -0.0337,  0.0541],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.6426, -2.0625,  1.8320,  ...,  1.2500, -1.6025, -5.0391],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0304, -0.0152,  0.0028,  ...,  0.0152,  0.0180,  0.0100],
        [-0.0362,  0.0367,  0.0040,  ..., -0.0073, -0.0330, -0.0085],
        [ 0.0254, -0.0166,  0.0323,  ..., -0.0009, -0.0105, -0.0102],
        ...,
        [ 0.0544,  0.0376, -0.0005,  ...,  0.0285,  0.0314, -0.0033],
        [ 0.0113, -0.0130,  0.0122,  ..., -0.0011, -0.0088, -0.0072],
        [ 0.0239, -0.0085,  0.0067,  ..., -0.0056, -0.0389,  0.0109]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.7412, -2.2812,  1.9170,  ...,  1.2510, -1.3887, -5.5391]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 08:32:23 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you recommend something, you are a recommender
If you choreograph something, you are a choreographer
If you discover something, you are a discoverer
If you examine something, you are a examiner
If you believe something, you are a believer
If you provide something, you are a provider
If you announce something, you are a announcer
If you subscribe something, you are a
2024-07-31 08:32:23 root INFO     [order_1_approx] starting weight calculation for If you discover something, you are a discoverer
If you provide something, you are a provider
If you recommend something, you are a recommender
If you choreograph something, you are a choreographer
If you examine something, you are a examiner
If you subscribe something, you are a subscriber
If you announce something, you are a announcer
If you believe something, you are a
2024-07-31 08:32:23 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-31 08:32:57 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1111,  0.0071, -0.5850,  ...,  0.2360, -0.2283, -0.0442],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.3281, -4.6953,  3.9453,  ..., -3.1484, -1.6816,  1.3125],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0188,  0.0018,  0.0004,  ...,  0.0081,  0.0049,  0.0068],
        [-0.0028,  0.0180, -0.0008,  ...,  0.0075,  0.0075, -0.0014],
        [ 0.0060, -0.0083,  0.0171,  ..., -0.0007,  0.0079, -0.0015],
        ...,
        [ 0.0060,  0.0014,  0.0008,  ...,  0.0152,  0.0041,  0.0062],
        [-0.0155,  0.0030,  0.0109,  ...,  0.0147,  0.0024, -0.0011],
        [-0.0065,  0.0070, -0.0042,  ..., -0.0040, -0.0011,  0.0158]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.1055, -4.4492,  4.0000,  ..., -3.2246, -1.3438,  1.2949]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 08:32:58 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for haydn was known for their work as a  composer
moses was known for their work as a  prophet
darwin was known for their work as a  naturalist
mozart was known for their work as a  composer
columbus was known for their work as a  explorer
mencius was known for their work as a  philosopher
spinoza was known for their work as a  philosopher
shakespeare was known for their work as a 
2024-07-31 08:32:58 root INFO     [order_1_approx] starting weight calculation for haydn was known for their work as a  composer
spinoza was known for their work as a  philosopher
mencius was known for their work as a  philosopher
darwin was known for their work as a  naturalist
columbus was known for their work as a  explorer
shakespeare was known for their work as a  playwright
mozart was known for their work as a  composer
moses was known for their work as a 
2024-07-31 08:32:58 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-31 08:35:00 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0016,  0.1981, -0.0009,  ...,  0.2378, -0.2466,  0.2559],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.6719, -5.5664,  2.6953,  ...,  0.2197, -4.4531, -3.8145],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0166, -0.0045, -0.0034,  ...,  0.0076,  0.0100, -0.0041],
        [-0.0155,  0.0171,  0.0297,  ...,  0.0023,  0.0059, -0.0053],
        [-0.0047, -0.0134,  0.0234,  ...,  0.0063, -0.0053,  0.0324],
        ...,
        [ 0.0068, -0.0040,  0.0227,  ..., -0.0053,  0.0034,  0.0124],
        [ 0.0232, -0.0091,  0.0011,  ..., -0.0033, -0.0105, -0.0054],
        [ 0.0119,  0.0119, -0.0083,  ..., -0.0036, -0.0211, -0.0126]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.7773, -5.6602,  2.5000,  ...,  0.6396, -4.4688, -3.7578]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 08:35:01 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you discover something, you are a discoverer
If you provide something, you are a provider
If you recommend something, you are a recommender
If you choreograph something, you are a choreographer
If you examine something, you are a examiner
If you subscribe something, you are a subscriber
If you announce something, you are a announcer
If you believe something, you are a
2024-07-31 08:35:01 root INFO     [order_1_approx] starting weight calculation for If you examine something, you are a examiner
If you discover something, you are a discoverer
If you subscribe something, you are a subscriber
If you believe something, you are a believer
If you provide something, you are a provider
If you choreograph something, you are a choreographer
If you announce something, you are a announcer
If you recommend something, you are a
2024-07-31 08:35:02 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-31 08:35:28 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0836, -0.1176, -0.2356,  ..., -0.3154, -0.0826,  0.4600],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.7627, -4.7266,  0.8979,  ..., -5.7500,  3.4609, -0.0088],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0311,  0.0121,  0.0085,  ..., -0.0069,  0.0102, -0.0081],
        [-0.0074,  0.0054,  0.0054,  ..., -0.0138, -0.0084, -0.0267],
        [ 0.0294,  0.0004,  0.0378,  ..., -0.0055,  0.0079,  0.0149],
        ...,
        [ 0.0177,  0.0125,  0.0187,  ...,  0.0316, -0.0080,  0.0041],
        [ 0.0229,  0.0328,  0.0060,  ...,  0.0230,  0.0425,  0.0154],
        [-0.0135, -0.0173, -0.0072,  ..., -0.0116, -0.0283,  0.0038]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.8418, -4.4883,  0.9165,  ..., -5.1875,  3.1250,  0.1969]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 08:35:29 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for haydn was known for their work as a  composer
spinoza was known for their work as a  philosopher
mencius was known for their work as a  philosopher
darwin was known for their work as a  naturalist
columbus was known for their work as a  explorer
shakespeare was known for their work as a  playwright
mozart was known for their work as a  composer
moses was known for their work as a 
2024-07-31 08:35:29 root INFO     [order_1_approx] starting weight calculation for columbus was known for their work as a  explorer
shakespeare was known for their work as a  playwright
haydn was known for their work as a  composer
moses was known for their work as a  prophet
darwin was known for their work as a  naturalist
spinoza was known for their work as a  philosopher
mozart was known for their work as a  composer
mencius was known for their work as a 
2024-07-31 08:35:29 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-31 08:37:43 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1870,  0.3032,  0.1069,  ...,  0.4287, -0.1083, -0.2242],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.1074, -2.3398,  2.2773,  ...,  1.9365, -5.4766, -4.8398],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0167, -0.0083,  0.0009,  ...,  0.0329, -0.0181,  0.0274],
        [-0.0114,  0.0313,  0.0169,  ...,  0.0024, -0.0028, -0.0231],
        [-0.0080, -0.0164,  0.0161,  ...,  0.0012,  0.0072,  0.0221],
        ...,
        [ 0.0116,  0.0061, -0.0127,  ...,  0.0410,  0.0117,  0.0199],
        [ 0.0175,  0.0137, -0.0046,  ..., -0.0372,  0.0117, -0.0150],
        [ 0.0122, -0.0125,  0.0024,  ..., -0.0134, -0.0366,  0.0121]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.5801, -2.5449,  2.5195,  ...,  2.5703, -5.8594, -5.5273]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 08:37:44 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you examine something, you are a examiner
If you discover something, you are a discoverer
If you subscribe something, you are a subscriber
If you believe something, you are a believer
If you provide something, you are a provider
If you choreograph something, you are a choreographer
If you announce something, you are a announcer
If you recommend something, you are a
2024-07-31 08:37:44 root INFO     [order_1_approx] starting weight calculation for If you examine something, you are a examiner
If you provide something, you are a provider
If you subscribe something, you are a subscriber
If you recommend something, you are a recommender
If you believe something, you are a believer
If you choreograph something, you are a choreographer
If you discover something, you are a discoverer
If you announce something, you are a
2024-07-31 08:37:44 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-31 08:37:58 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2205,  0.1285, -0.5371,  ...,  0.4199, -0.2700,  0.1674],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.0205, -4.3828,  5.1055,  ..., -9.9766,  1.0635,  1.2510],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0554,  0.0006,  0.0082,  ..., -0.0003, -0.0119,  0.0241],
        [-0.0056,  0.0432,  0.0014,  ..., -0.0016, -0.0027, -0.0060],
        [ 0.0066,  0.0193,  0.0442,  ...,  0.0041,  0.0075, -0.0010],
        ...,
        [ 0.0278, -0.0132,  0.0123,  ...,  0.0542, -0.0056,  0.0066],
        [ 0.0027,  0.0194, -0.0122,  ...,  0.0198,  0.0161, -0.0044],
        [-0.0003,  0.0093, -0.0123,  ...,  0.0141, -0.0028,  0.0209]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.8940, -4.6562,  4.4844,  ..., -9.3125,  1.4463,  1.1455]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 08:37:59 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for columbus was known for their work as a  explorer
shakespeare was known for their work as a  playwright
haydn was known for their work as a  composer
moses was known for their work as a  prophet
darwin was known for their work as a  naturalist
spinoza was known for their work as a  philosopher
mozart was known for their work as a  composer
mencius was known for their work as a 
2024-07-31 08:37:59 root INFO     [order_1_approx] starting weight calculation for darwin was known for their work as a  naturalist
mozart was known for their work as a  composer
shakespeare was known for their work as a  playwright
haydn was known for their work as a  composer
mencius was known for their work as a  philosopher
spinoza was known for their work as a  philosopher
moses was known for their work as a  prophet
columbus was known for their work as a 
2024-07-31 08:37:59 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-31 08:40:24 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0638,  0.3599, -0.1677,  ...,  0.0456, -0.1516, -0.1367],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.8027, -4.4492,  1.8359,  ...,  3.8965, -5.0195, -2.3496],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0227,  0.0041, -0.0068,  ..., -0.0003, -0.0125,  0.0028],
        [ 0.0023,  0.0149,  0.0120,  ..., -0.0134,  0.0043, -0.0055],
        [-0.0007, -0.0062,  0.0142,  ..., -0.0056, -0.0007,  0.0099],
        ...,
        [ 0.0124,  0.0015, -0.0055,  ...,  0.0178,  0.0037, -0.0016],
        [ 0.0088, -0.0074, -0.0079,  ..., -0.0120,  0.0070,  0.0110],
        [ 0.0168,  0.0010, -0.0023,  ..., -0.0119, -0.0105,  0.0145]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.0801, -4.7500,  1.6895,  ...,  4.1992, -5.1523, -2.5977]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 08:40:25 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you examine something, you are a examiner
If you provide something, you are a provider
If you subscribe something, you are a subscriber
If you recommend something, you are a recommender
If you believe something, you are a believer
If you choreograph something, you are a choreographer
If you discover something, you are a discoverer
If you announce something, you are a
2024-07-31 08:40:25 root INFO     total operator prediction time: 1272.1934819221497 seconds
2024-07-31 08:40:25 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on adj - superlative
2024-07-31 08:40:25 root INFO     building operator adj - superlative
2024-07-31 08:40:25 root INFO     [order_1_approx] starting weight calculation for If something is the most rude, it is rudest
If something is the most handy, it is handiest
If something is the most cheap, it is cheapest
If something is the most pure, it is purest
If something is the most neat, it is neatest
If something is the most dense, it is densest
If something is the most ugly, it is ugliest
If something is the most fierce, it is
2024-07-31 08:40:25 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-31 08:40:25 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1260,  0.2100, -0.6265,  ...,  0.3047, -0.0526,  0.3123],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.9062, -3.8320, -1.9717,  ..., -2.6562,  1.7588,  0.1152],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0308,  0.0091,  0.0091,  ..., -0.0002,  0.0043,  0.0139],
        [ 0.0027,  0.0342, -0.0035,  ..., -0.0054, -0.0115, -0.0029],
        [ 0.0037, -0.0030,  0.0210,  ..., -0.0036,  0.0086,  0.0056],
        ...,
        [ 0.0057,  0.0087,  0.0098,  ...,  0.0388, -0.0070,  0.0016],
        [-0.0059,  0.0081,  0.0068,  ...,  0.0138,  0.0039,  0.0057],
        [ 0.0002,  0.0017, -0.0094,  ...,  0.0083, -0.0062,  0.0199]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.7832, -3.9609, -1.6133,  ..., -2.8027,  1.6670, -0.1392]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 08:40:26 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for darwin was known for their work as a  naturalist
mozart was known for their work as a  composer
shakespeare was known for their work as a  playwright
haydn was known for their work as a  composer
mencius was known for their work as a  philosopher
spinoza was known for their work as a  philosopher
moses was known for their work as a  prophet
columbus was known for their work as a 
2024-07-31 08:40:27 root INFO     [order_1_approx] starting weight calculation for moses was known for their work as a  prophet
haydn was known for their work as a  composer
darwin was known for their work as a  naturalist
mozart was known for their work as a  composer
shakespeare was known for their work as a  playwright
columbus was known for their work as a  explorer
mencius was known for their work as a  philosopher
spinoza was known for their work as a 
2024-07-31 08:40:27 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-31 08:42:57 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0106, -0.1191, -0.2313,  ...,  0.1639, -0.1309,  0.1615],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.2280, -2.6777,  3.7422,  ..., -7.2969,  1.2480, -3.0547],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0390,  0.0023,  0.0083,  ...,  0.0010, -0.0100,  0.0053],
        [ 0.0160,  0.0217,  0.0163,  ...,  0.0072, -0.0171, -0.0127],
        [ 0.0072,  0.0177,  0.0584,  ...,  0.0175, -0.0108, -0.0040],
        ...,
        [ 0.0051, -0.0131, -0.0009,  ...,  0.0396,  0.0163, -0.0071],
        [ 0.0035,  0.0038,  0.0005,  ...,  0.0043,  0.0146, -0.0068],
        [-0.0069, -0.0007, -0.0104,  ...,  0.0005, -0.0026,  0.0414]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.0732, -2.5195,  3.1836,  ..., -6.5938,  1.3008, -2.3535]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 08:42:59 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for moses was known for their work as a  prophet
haydn was known for their work as a  composer
darwin was known for their work as a  naturalist
mozart was known for their work as a  composer
shakespeare was known for their work as a  playwright
columbus was known for their work as a  explorer
mencius was known for their work as a  philosopher
spinoza was known for their work as a 
2024-07-31 08:42:59 root INFO     total operator prediction time: 1196.7000036239624 seconds
2024-07-31 08:42:59 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on male - female
2024-07-31 08:42:59 root INFO     building operator male - female
2024-07-31 08:42:59 root INFO     [order_1_approx] starting weight calculation for A female policeman is known as a policewoman
A female businessman is known as a businesswoman
A female son is known as a daughter
A female tiger is known as a tigress
A female nephew is known as a niece
A female sculptor is known as a sculptress
A female lion is known as a lioness
A female hero is known as a
2024-07-31 08:42:59 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-31 08:43:03 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2029,  0.2371, -0.1588,  ...,  0.1536, -0.1493, -0.1160],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-2.1738, -4.3672, -1.8018,  ..., -1.7090, -2.6172,  0.0596],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0028, -0.0044,  0.0277,  ..., -0.0011, -0.0247,  0.0035],
        [-0.0020,  0.0010, -0.0040,  ...,  0.0109,  0.0013,  0.0261],
        [-0.0004,  0.0021,  0.0184,  ..., -0.0208, -0.0091, -0.0163],
        ...,
        [ 0.0040,  0.0062,  0.0018,  ...,  0.0165,  0.0147, -0.0093],
        [ 0.0116, -0.0127, -0.0028,  ...,  0.0019,  0.0063, -0.0270],
        [-0.0071, -0.0062, -0.0033,  ...,  0.0059, -0.0078,  0.0041]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-2.3359, -4.0234, -2.0586,  ..., -1.2617, -2.8223,  0.2465]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 08:43:04 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is the most rude, it is rudest
If something is the most handy, it is handiest
If something is the most cheap, it is cheapest
If something is the most pure, it is purest
If something is the most neat, it is neatest
If something is the most dense, it is densest
If something is the most ugly, it is ugliest
If something is the most fierce, it is
2024-07-31 08:43:04 root INFO     [order_1_approx] starting weight calculation for If something is the most cheap, it is cheapest
If something is the most rude, it is rudest
If something is the most neat, it is neatest
If something is the most pure, it is purest
If something is the most dense, it is densest
If something is the most fierce, it is fiercest
If something is the most handy, it is handiest
If something is the most ugly, it is
2024-07-31 08:43:04 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-31 08:45:29 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1338,  0.6670,  0.0812,  ..., -0.1207, -0.4907,  0.0903],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.3477, -5.7031, -0.8711,  ..., -1.9473, -4.2578,  0.9111],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0297, -0.0116,  0.0179,  ...,  0.0255,  0.0134, -0.0035],
        [ 0.0165,  0.0050,  0.0067,  ...,  0.0054,  0.0036, -0.0147],
        [ 0.0077,  0.0067,  0.0379,  ...,  0.0053, -0.0197, -0.0006],
        ...,
        [ 0.0052, -0.0203,  0.0045,  ...,  0.0372, -0.0002, -0.0191],
        [ 0.0053,  0.0162,  0.0124,  ...,  0.0115, -0.0021,  0.0065],
        [ 0.0095, -0.0050, -0.0206,  ..., -0.0091,  0.0202,  0.0137]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.0703, -5.5195, -0.9219,  ..., -1.2588, -4.6758,  0.9531]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 08:45:30 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A female policeman is known as a policewoman
A female businessman is known as a businesswoman
A female son is known as a daughter
A female tiger is known as a tigress
A female nephew is known as a niece
A female sculptor is known as a sculptress
A female lion is known as a lioness
A female hero is known as a
2024-07-31 08:45:30 root INFO     [order_1_approx] starting weight calculation for A female lion is known as a lioness
A female tiger is known as a tigress
A female policeman is known as a policewoman
A female hero is known as a heroine
A female son is known as a daughter
A female nephew is known as a niece
A female sculptor is known as a sculptress
A female businessman is known as a
2024-07-31 08:45:30 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-31 08:45:43 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0866,  0.2937,  0.2301,  ..., -0.0090,  0.2773, -0.0720],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.3896, -4.4727, -1.8242,  ..., -1.5469, -2.1641,  0.7119],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 8.2474e-03, -1.0468e-02,  2.3026e-02,  ..., -1.4353e-03,
         -1.5526e-02,  2.2259e-03],
        [ 2.5192e-02,  7.0992e-03,  3.0792e-02,  ..., -1.3550e-02,
         -1.4854e-02,  1.3557e-02],
        [-6.6299e-03, -7.1411e-03,  2.6047e-02,  ..., -6.1951e-03,
         -1.0071e-02, -1.3588e-02],
        ...,
        [-1.5518e-02,  2.1179e-02, -2.0752e-03,  ...,  8.8654e-03,
         -1.9867e-02, -4.3411e-03],
        [-3.5324e-03,  1.1185e-02,  6.1188e-03,  ...,  2.0767e-02,
          1.1505e-02, -1.5686e-02],
        [-2.4471e-03,  1.1810e-02, -1.1322e-02,  ..., -6.3095e-03,
         -9.0485e-03, -7.8201e-05]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.2148, -5.0234, -1.6445,  ..., -1.4912, -1.6797,  0.4990]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 08:45:44 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is the most cheap, it is cheapest
If something is the most rude, it is rudest
If something is the most neat, it is neatest
If something is the most pure, it is purest
If something is the most dense, it is densest
If something is the most fierce, it is fiercest
If something is the most handy, it is handiest
If something is the most ugly, it is
2024-07-31 08:45:44 root INFO     [order_1_approx] starting weight calculation for If something is the most cheap, it is cheapest
If something is the most ugly, it is ugliest
If something is the most neat, it is neatest
If something is the most pure, it is purest
If something is the most handy, it is handiest
If something is the most rude, it is rudest
If something is the most fierce, it is fiercest
If something is the most dense, it is
2024-07-31 08:45:44 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-31 08:47:59 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4077,  0.4456, -0.1165,  ..., -0.1276, -0.2461,  0.4634],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.2266, -2.2656,  0.2791,  ...,  1.4883, -2.5000, -1.3281],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 1.8356e-02, -1.6312e-02,  2.8934e-03,  ..., -5.2643e-03,
          4.8752e-03, -8.0109e-03],
        [ 2.2564e-03,  1.1002e-02, -3.6621e-03,  ...,  2.1194e-02,
          6.2790e-03,  2.2531e-04],
        [ 3.3512e-03,  1.1032e-02,  3.6163e-02,  ..., -1.2428e-02,
          1.7044e-02, -3.4561e-03],
        ...,
        [-7.9041e-03,  2.5139e-03,  7.3051e-04,  ...,  5.0903e-02,
         -1.5869e-02, -4.8027e-03],
        [ 2.4452e-03, -2.8706e-03, -6.7711e-05,  ...,  4.5319e-03,
          1.8539e-02, -8.2922e-04],
        [-5.6839e-04, -5.5428e-03,  2.7943e-03,  ...,  1.4191e-03,
          9.6054e-03,  2.4124e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.2051, -2.4512,  0.6123,  ...,  1.2324, -2.2656, -1.2061]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 08:48:00 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A female lion is known as a lioness
A female tiger is known as a tigress
A female policeman is known as a policewoman
A female hero is known as a heroine
A female son is known as a daughter
A female nephew is known as a niece
A female sculptor is known as a sculptress
A female businessman is known as a
2024-07-31 08:48:01 root INFO     [order_1_approx] starting weight calculation for A female son is known as a daughter
A female hero is known as a heroine
A female lion is known as a lioness
A female businessman is known as a businesswoman
A female sculptor is known as a sculptress
A female nephew is known as a niece
A female tiger is known as a tigress
A female policeman is known as a
2024-07-31 08:48:01 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-31 08:48:24 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0669, -0.0062, -0.0332,  ...,  0.1002, -0.2505,  0.1680],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-2.2305, -3.4160,  0.3103,  ..., -4.9766, -3.2266, -2.3672],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0163, -0.0299, -0.0077,  ..., -0.0151,  0.0055,  0.0158],
        [-0.0110,  0.0353,  0.0340,  ..., -0.0129, -0.0432, -0.0047],
        [-0.0233,  0.0076,  0.0253,  ..., -0.0279, -0.0109,  0.0259],
        ...,
        [-0.0002,  0.0012,  0.0179,  ...,  0.0422, -0.0165, -0.0031],
        [-0.0103, -0.0051, -0.0078,  ...,  0.0081,  0.0525, -0.0407],
        [ 0.0084, -0.0188, -0.0085,  ..., -0.0211,  0.0199, -0.0023]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-2.4238, -3.5605,  0.2505,  ..., -4.5781, -3.4824, -2.2422]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 08:48:25 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is the most cheap, it is cheapest
If something is the most ugly, it is ugliest
If something is the most neat, it is neatest
If something is the most pure, it is purest
If something is the most handy, it is handiest
If something is the most rude, it is rudest
If something is the most fierce, it is fiercest
If something is the most dense, it is
2024-07-31 08:48:25 root INFO     [order_1_approx] starting weight calculation for If something is the most rude, it is rudest
If something is the most cheap, it is cheapest
If something is the most pure, it is purest
If something is the most fierce, it is fiercest
If something is the most dense, it is densest
If something is the most handy, it is handiest
If something is the most ugly, it is ugliest
If something is the most neat, it is
2024-07-31 08:48:25 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-31 08:50:33 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3699,  0.4009, -0.2141,  ..., -0.1068, -0.5210,  0.0302],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.1602, -4.9141,  3.6875,  ...,  0.1025, -0.2871, -0.1235],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0035,  0.0029,  0.0065,  ...,  0.0182,  0.0087, -0.0080],
        [ 0.0128,  0.0104,  0.0016,  ..., -0.0034,  0.0090, -0.0001],
        [-0.0084,  0.0162,  0.0100,  ...,  0.0046, -0.0030,  0.0023],
        ...,
        [ 0.0013, -0.0008,  0.0089,  ...,  0.0196,  0.0005,  0.0078],
        [ 0.0082,  0.0068,  0.0076,  ..., -0.0040,  0.0002, -0.0074],
        [-0.0005, -0.0001, -0.0120,  ..., -0.0013, -0.0043,  0.0055]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.9727e+00, -4.5977e+00,  3.5879e+00,  ...,  3.1128e-03,
         -1.9751e-01, -1.8140e-01]], device='cuda:1', dtype=torch.float16,
       grad_fn=<SubBackward0>) 

                    
2024-07-31 08:50:34 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A female son is known as a daughter
A female hero is known as a heroine
A female lion is known as a lioness
A female businessman is known as a businesswoman
A female sculptor is known as a sculptress
A female nephew is known as a niece
A female tiger is known as a tigress
A female policeman is known as a
2024-07-31 08:50:34 root INFO     [order_1_approx] starting weight calculation for A female policeman is known as a policewoman
A female son is known as a daughter
A female lion is known as a lioness
A female businessman is known as a businesswoman
A female nephew is known as a niece
A female hero is known as a heroine
A female sculptor is known as a sculptress
A female tiger is known as a
2024-07-31 08:50:34 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-31 08:51:10 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0636, -0.2778, -0.1807,  ...,  0.1694, -0.4258,  0.0190],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.5029, -1.0303, -2.4648,  ..., -1.8164, -1.9990, -3.5312],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0132, -0.0173,  0.0071,  ..., -0.0083, -0.0107, -0.0034],
        [-0.0113,  0.0295,  0.0204,  ..., -0.0041, -0.0142, -0.0015],
        [ 0.0012, -0.0181,  0.0034,  ..., -0.0114,  0.0032, -0.0072],
        ...,
        [-0.0247,  0.0381, -0.0027,  ...,  0.0163,  0.0092, -0.0091],
        [ 0.0072, -0.0145,  0.0069,  ..., -0.0039, -0.0016, -0.0093],
        [ 0.0383, -0.0005, -0.0111,  ..., -0.0028,  0.0005,  0.0083]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.8857, -1.3564, -2.4707,  ..., -1.6533, -1.6543, -4.0156]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 08:51:11 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is the most rude, it is rudest
If something is the most cheap, it is cheapest
If something is the most pure, it is purest
If something is the most fierce, it is fiercest
If something is the most dense, it is densest
If something is the most handy, it is handiest
If something is the most ugly, it is ugliest
If something is the most neat, it is
2024-07-31 08:51:11 root INFO     [order_1_approx] starting weight calculation for If something is the most neat, it is neatest
If something is the most ugly, it is ugliest
If something is the most fierce, it is fiercest
If something is the most rude, it is rudest
If something is the most dense, it is densest
If something is the most cheap, it is cheapest
If something is the most pure, it is purest
If something is the most handy, it is
2024-07-31 08:51:11 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-31 08:53:03 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1077,  0.2197, -0.4365,  ...,  0.1553, -0.4016,  0.1120],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.5811, -4.6875, -1.0527,  ..., -0.8838, -2.5508,  0.1982],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0065, -0.0063,  0.0160,  ..., -0.0035, -0.0006,  0.0056],
        [-0.0155,  0.0197, -0.0074,  ...,  0.0169,  0.0157, -0.0144],
        [ 0.0297,  0.0229,  0.0442,  ...,  0.0077, -0.0027, -0.0195],
        ...,
        [ 0.0157, -0.0288,  0.0063,  ...,  0.0512,  0.0235, -0.0141],
        [ 0.0240,  0.0281,  0.0037,  ..., -0.0029, -0.0043, -0.0037],
        [-0.0151,  0.0094, -0.0362,  ..., -0.0487, -0.0157,  0.0112]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.0352, -4.6562, -1.1348,  ..., -0.6968, -2.7188, -0.0986]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 08:53:04 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A female policeman is known as a policewoman
A female son is known as a daughter
A female lion is known as a lioness
A female businessman is known as a businesswoman
A female nephew is known as a niece
A female hero is known as a heroine
A female sculptor is known as a sculptress
A female tiger is known as a
2024-07-31 08:53:04 root INFO     [order_1_approx] starting weight calculation for A female tiger is known as a tigress
A female hero is known as a heroine
A female policeman is known as a policewoman
A female son is known as a daughter
A female lion is known as a lioness
A female sculptor is known as a sculptress
A female businessman is known as a businesswoman
A female nephew is known as a
2024-07-31 08:53:04 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-31 08:53:55 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0176,  0.1354,  0.1002,  ..., -0.1136, -0.3533, -0.1362],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.3428, -4.4297, -1.6396,  ..., -1.5107, -4.2578, -0.5312],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0144,  0.0107,  0.0146,  ..., -0.0027, -0.0164,  0.0186],
        [-0.0011,  0.0245,  0.0213,  ..., -0.0038, -0.0078,  0.0145],
        [ 0.0099,  0.0002,  0.0305,  ..., -0.0023, -0.0033,  0.0029],
        ...,
        [-0.0208,  0.0080, -0.0026,  ...,  0.0308,  0.0031, -0.0069],
        [ 0.0189, -0.0086, -0.0004,  ...,  0.0021,  0.0355, -0.0243],
        [ 0.0086,  0.0017, -0.0017,  ..., -0.0085, -0.0048,  0.0166]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.3389, -4.5781, -1.6309,  ..., -0.9253, -4.5742, -0.2878]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 08:53:56 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is the most neat, it is neatest
If something is the most ugly, it is ugliest
If something is the most fierce, it is fiercest
If something is the most rude, it is rudest
If something is the most dense, it is densest
If something is the most cheap, it is cheapest
If something is the most pure, it is purest
If something is the most handy, it is
2024-07-31 08:53:56 root INFO     [order_1_approx] starting weight calculation for If something is the most ugly, it is ugliest
If something is the most handy, it is handiest
If something is the most fierce, it is fiercest
If something is the most rude, it is rudest
If something is the most dense, it is densest
If something is the most cheap, it is cheapest
If something is the most neat, it is neatest
If something is the most pure, it is
2024-07-31 08:53:56 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
2024-07-31 08:55:34 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1497,  0.1048, -0.0034,  ...,  0.1412, -0.1681,  0.2136],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.4941, -0.9727, -0.3545,  ..., -0.5352, -3.9219, -1.6670],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-8.6365e-03,  8.2703e-03,  2.1408e-02,  ...,  1.8646e-02,
          1.3641e-02,  1.0925e-02],
        [ 3.5034e-02, -4.6158e-04, -4.1275e-03,  ...,  4.3030e-03,
          2.5864e-03,  1.2760e-03],
        [ 2.9617e-02, -2.5330e-02,  2.2797e-02,  ...,  4.3488e-03,
         -1.2154e-02,  6.6185e-03],
        ...,
        [-2.7065e-03, -3.3607e-03,  6.4316e-03,  ...,  1.2512e-02,
          1.1993e-02,  1.3702e-02],
        [-8.9340e-03,  2.8610e-02, -8.9169e-05,  ...,  4.6806e-03,
         -1.3649e-02, -4.1161e-03],
        [ 2.0813e-02,  9.6893e-03, -1.6220e-02,  ..., -6.0539e-03,
          8.4991e-03,  1.2238e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.2031, -0.6035, -0.0298,  ..., -0.6094, -4.4922, -1.7832]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 08:55:35 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A female tiger is known as a tigress
A female hero is known as a heroine
A female policeman is known as a policewoman
A female son is known as a daughter
A female lion is known as a lioness
A female sculptor is known as a sculptress
A female businessman is known as a businesswoman
A female nephew is known as a
2024-07-31 08:55:36 root INFO     [order_1_approx] starting weight calculation for A female policeman is known as a policewoman
A female lion is known as a lioness
A female businessman is known as a businesswoman
A female hero is known as a heroine
A female son is known as a daughter
A female tiger is known as a tigress
A female nephew is known as a niece
A female sculptor is known as a
2024-07-31 08:55:36 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.10
2024-07-31 08:56:36 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0804, -0.0311,  0.1122,  ..., -0.0565, -0.1027, -0.1052],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.2812, -4.1602, -2.7422,  ..., -1.8281, -1.0449, -1.7412],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0246, -0.0118,  0.0224,  ..., -0.0145, -0.0096,  0.0005],
        [-0.0018,  0.0161,  0.0248,  ..., -0.0048, -0.0040,  0.0139],
        [-0.0119,  0.0009,  0.0223,  ...,  0.0058,  0.0102,  0.0189],
        ...,
        [ 0.0013,  0.0162, -0.0098,  ...,  0.0160,  0.0116, -0.0053],
        [ 0.0080, -0.0055, -0.0167,  ...,  0.0022,  0.0092, -0.0184],
        [ 0.0021, -0.0082,  0.0008,  ...,  0.0208, -0.0142,  0.0089]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.2910, -4.2188, -2.5918,  ..., -1.6182, -1.3193, -1.9219]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 08:56:37 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is the most ugly, it is ugliest
If something is the most handy, it is handiest
If something is the most fierce, it is fiercest
If something is the most rude, it is rudest
If something is the most dense, it is densest
If something is the most cheap, it is cheapest
If something is the most neat, it is neatest
If something is the most pure, it is
2024-07-31 08:56:37 root INFO     [order_1_approx] starting weight calculation for If something is the most handy, it is handiest
If something is the most fierce, it is fiercest
If something is the most dense, it is densest
If something is the most pure, it is purest
If something is the most rude, it is rudest
If something is the most ugly, it is ugliest
If something is the most neat, it is neatest
If something is the most cheap, it is
2024-07-31 08:56:37 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.9
